{"pages":[{"title":"About","date":"2022-05-12T08:53:51.333Z","path":"about/index.html","text":"Welcome TaoLiu’s Blog"},{"title":"Categories","date":"2022-05-12T08:42:52.543Z","path":"categories/index.html","text":""},{"title":"Tags","date":"2022-05-12T08:42:52.567Z","path":"tags/index.html","text":""}],"posts":[{"title":"ElasticSearch-Springboot","date":"2022-01-02T06:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/ElasticSearch/ElasticSearch-Springboot/","text":"版本问题springboot 有一个 spring data 组件，可以用来连接各种数据源。 用来连接 elasticsearch 的是 spring-data-elasticsearch。 启动 elasticsearch运行elasticsearch.bat, 启动后, 可以看到左上角的版本号。 创建 springboot 项目:pom.xml各种jar包，主要是 spring-boot-starter-data-elastisearch 这个 jar包。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.howToElasticSearch&lt;/groupId&gt; &lt;artifactId&gt;springboot&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;springboot&lt;/name&gt; &lt;description&gt;springboot&lt;/description&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.9.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- servlet依赖. --&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- tomcat的支持.--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt; &lt;artifactId&gt;tomcat-embed-jasper&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;!-- 这个需要为 true 热部署才有效 --&gt; &lt;/dependency&gt; &lt;!-- mysql--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.21&lt;/version&gt; &lt;/dependency&gt; &lt;!-- elastisearch依赖包 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-elasticsearch&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; Category.javaCategory 实体类，其中的 @Document就表明了要连接到 ElasticSearch 的哪个索引和哪个 type 上 @Document(indexName &#x3D; “howToElasticSearch”,type &#x3D; “category”)索引相当于就是数据库，type 相当于就是表 1234567891011121314151617181920212223package cn.peach.springboot.pojo; import org.springframework.data.elasticsearch.annotations.Document; @Document(indexName = &quot;howToElasticSearch&quot;,type = &quot;category&quot;)public class Category &#123; private int id; private String name; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; &#125; 控制类：CategoryController.java控制类提供 CRUD 一套 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889package cn.peach.springboot.web;import java.text.SimpleDateFormat;import java.util.Date;import org.elasticsearch.index.query.QueryBuilders;import org.elasticsearch.index.query.functionscore.FunctionScoreQueryBuilder;import org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.domain.Page;import org.springframework.data.domain.PageRequest;import org.springframework.data.domain.Pageable;import org.springframework.data.domain.Sort;import org.springframework.data.elasticsearch.core.query.NativeSearchQueryBuilder;import org.springframework.data.elasticsearch.core.query.SearchQuery;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam;import cn.peach.springboot.dao.CategoryDAO;import cn.peach.springboot.pojo.Category; @Controllerpublic class CategoryController &#123; @Autowired CategoryDAO categoryDAO; //每页数量 @GetMapping(&quot;/listCategory&quot;) public String listCategory(Model m,@RequestParam(value = &quot;start&quot;, defaultValue = &quot;0&quot;) int start,@RequestParam(value = &quot;size&quot;, defaultValue = &quot;5&quot;) int size)&#123; String query = &quot;商品&quot;; //查询条件，但是并未使用，放在这里，为的是将来使用，方便参考，知道如何用 SearchQuery searchQuery=getEntitySearchQuery(start,size,query); Page&lt;Category&gt; page = categoryDAO.search(searchQuery); m.addAttribute(&quot;page&quot;, page); return &quot;listCategory&quot;; &#125; private SearchQuery getEntitySearchQuery(int start, int size, String searchContent) &#123; FunctionScoreQueryBuilder functionScoreQueryBuilder = QueryBuilders.functionScoreQuery() .add(QueryBuilders.matchAllQuery(), //查询所有 ScoreFunctionBuilders.weightFactorFunction(100))// 查询条件，但是并未使用，放在这里，为的是将来使用，方便参考，知道如何用// .add(QueryBuilders.matchPhraseQuery(&quot;name&quot;, searchContent),// ScoreFunctionBuilders.weightFactorFunction(100)) //设置权重分 求和模式 .scoreMode(&quot;sum&quot;) //设置权重分最低分 .setMinScore(10); // 设置分页 Sort sort = new Sort(Sort.Direction.DESC,&quot;id&quot;); Pageable pageable = new PageRequest(start, size,sort); return new NativeSearchQueryBuilder() .withPageable(pageable) .withQuery(functionScoreQueryBuilder).build(); &#125; @RequestMapping(&quot;/addCategory&quot;) public String addCategory(Category c) throws Exception &#123; int id = currentTime(); c.setId(id); categoryDAO.save(c); return &quot;redirect:listCategory&quot;; &#125; private int currentTime() &#123; SimpleDateFormat sdf = new SimpleDateFormat(&quot;MMddHHmmss&quot;); String time= sdf.format(new Date()); return Integer.parseInt(time); &#125; @RequestMapping(&quot;/deleteCategory&quot;) public String deleteCategory(Category c) throws Exception &#123; categoryDAO.delete(c); return &quot;redirect:listCategory&quot;; &#125; @RequestMapping(&quot;/updateCategory&quot;) public String updateCategory(Category c) throws Exception &#123; categoryDAO.save(c); return &quot;redirect:listCategory&quot;; &#125; @RequestMapping(&quot;/editCategory&quot;) public String ediitCategory(int id,Model m) throws Exception &#123; Category c= categoryDAO.findOne(id); m.addAttribute(&quot;c&quot;, c); return &quot;editCategory&quot;; &#125;&#125; 配置文件：application.properties配置 jsp 作为视图配置spring端口 为8080配置 elastic链接地址为 127.0.0.1:9300 1234spring.mvc.view.prefix=/WEB-INF/jsp/spring.mvc.view.suffix=.jspserver.port=8080spring.data.elasticsearch.cluster-nodes = 127.0.0.1:9300 启动并测试:运行 Application.java 启动项目, 接着访问地址： 1http://127.0.0.1:8080/listCategory kibana查看数据启动 kibana 并访问: http://127.0.0.1:5601, 选择索引刚开始是没有选定索引的，所以要自己指定索引。 把默认勾选的 Index contians time-based evens 去掉 输入 howToElasticSearch 点击 Create 按钮 查看数据然后点击上面的Discover，就可以看到左边是当前的索引 :howToElasticSearch. 右边就是数据了。","tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"http://example.com/tags/ElasticSearch/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"ElasticSearch","slug":"工具和中间件/搜索引擎技术/ElasticSearch","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/ElasticSearch/"}]},{"title":"ElasticSearch工具-Kibana","date":"2022-01-02T05:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/ElasticSearch/ElasticSearch工具-Kibana/","text":"Kibana 是什么Kibana 是一个针对 ElasticSearch 的开源分析及可视化平台，用来搜索、查看交互存储在 ElasticSearch 索引中的数据。使用 Kibana，可以通过各种图表进行高级数据分析及展示。 Kibana 是在ElasticSearch 有了相当多的数据之后，进行分析这些数据用的工具。 但是现在还么有数据呀，为什么就要介绍这个工具呢？ 因为Kibana 里面有一个叫做 Dev Tools的，可以很方便地以Restful 风格向 ElasticSearch 服务器提交请求。Kibana 让海量数据更容易理解。它操作简单，基于浏览器的用户界面可以快速创建仪表板（DashBoard）实时显示 ElasticSearch 查询动态。 官网下载(https://www.elastic.co/cn/kibana/)下载rar，并解压。 假设下载路径在：C:\\Users\\X7TI运行启动中的 kibana.bat 1C:\\Users\\X7TI\\Downloads\\kibana-6.2.2-windows-x86_64\\bin\\kibana.bat 验证启动浏览器输入 http://localhost:5601/app/kibana#/dev_tools/console?_g=(), 打开当前的开发工具 Dev Tools 界面 运行测试在控制台里输入 1GET /_cat/health?v 然后点击绿色箭头进行运行，就可以看到右侧出现查询结果GET &#x2F;_cat&#x2F;health?v 这个命令用来查看服务器状态（健康度）， green 表示一切OK。 索引概念索引相当于就是一个数据库服务器上的某个数据库，所以索引也可以看成是Elastic Search里的某个数据库 Restful 风格管理索引，管理无非就是增删改查，即 CRUD。在使用Restful风格之前，进行所以管理需要这样的访问地址： add,delete,update,get 等不同的访问地址来表示不同的业务请求。但是使用Restful 风格，就通过提交不同的method 来表示 CRUD： PUT 表示增加 GET 表示获取 DELETE 表示删除 POST表示更新 增加索引:在 kibana 控制台中输入如下命令：打开 kibana控制台： 1http://localhost:5601/app/kibana#/dev_tools/console?_g=() 运行如下命令： 1PUT /howToKibana?pretty 返回： 12345&#123; &quot;acknowledged&quot;: true, &quot;shards_acknowledged&quot;: true, &quot;index&quot;: &quot;howToKibana&quot;&#125; 表示创建成功了，索引名称是howToKibana注： 要运行kibana控制台，需要先安装kibana: 查询运行如下命令： 1GET /_cat/indices?v 可以观察到新建立的索引 删除运行如下命令：DELETE &#x2F;howToKibana?pretty再运行 1GET /_cat/indices?v 可以观察到索引howToKibana被删除了，右侧一个索引也看不到了 修改修改两种方式， 第一种还是用PUT，PUT本来用来做增加的，但是当输入的id已经存在的时候，就自动变成修改功能了; 第二种使用 POST，这才是正规的修改，其实和第一种效果一样的。 批量导入批量导入两条数据在 kibana 控制台中输入如下命令：打开 kibana控制台： 1http://localhost:5601/app/kibana#/dev_tools/console?_g=() 运行如下命令： 12345POST _bulk&#123;&quot;index&quot;:&#123;&quot;_index&quot;:&quot;howToKibana&quot;,&quot;_type&quot;:&quot;product&quot;,&quot;_id&quot;:10001&#125;&#125;&#123;&quot;code&quot;:&quot;540785126782&quot;,&quot;price&quot;:398,&quot;name&quot;:&quot;房屋卫士自流平美缝剂瓷砖地砖专用双组份真瓷胶防水填缝剂镏金色&quot;,&quot;place&quot;:&quot;上海&quot;,&quot;category&quot;:&quot;品质建材&quot;&#125;&#123;&quot;index&quot;:&#123;&quot;_index&quot;:&quot;howToKibana&quot;,&quot;_type&quot;:&quot;product&quot;,&quot;_id&quot;:10002&#125;&#125;&#123;&quot;code&quot;:&quot;24727352473&quot;,&quot;price&quot;:21.799999237060547,&quot;name&quot;:&quot;艾瑞泽手工大号小号调温热熔胶枪玻璃胶枪硅胶条热溶胶棒20W-100W&quot;,&quot;place&quot;:&quot;山东青岛&quot;,&quot;category&quot;:&quot;品质建材&quot;&#125; 注： 要运行kibana控制台，需要先安装kibana并启动 注： 其中的product在elastic search里是type的概念，相当于数据库里的表，这里就相当于向 product 表里插入了一条数据 验证插入的数据使用命令查询howToKibana 索引里所有的数据： 1234GET /howToKibana/_search&#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;&#125; 可以看到刚刚批量插入的两条数据.","tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"http://example.com/tags/ElasticSearch/"},{"name":"Kibana","slug":"Kibana","permalink":"http://example.com/tags/Kibana/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"ElasticSearch","slug":"工具和中间件/搜索引擎技术/ElasticSearch","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/ElasticSearch/"}]},{"title":"ElasticSearch进阶","date":"2022-01-02T04:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/ElasticSearch/ElasticSearch进阶/","text":"分值计算首先根据用户query条件,过滤出包含指定term的doc,Field-length norm即field长度越长相关度越弱。 123query &quot;hello world&quot; --&gt; hello / world / hello &amp; worldbool --&gt; must/must not/should --&gt; 过滤 --&gt; 包含 / 不包含 / 可能包含doc --&gt; 不打分数 --&gt; 正或反 true or false --&gt; 为了减少后续要计算的doc的数量,提升性能 relevance score算法：计算出一个 索引中文本 与 搜索文本 之间 关联匹配程度,ES使用 term frequency/inverse document frequency算法 简称为 TF/IDF 算法。 Term frequency 即 搜索文本 中 各个词条 在 field 文本中 出现次数,次数越多越相关 。Inverse document frequency 即 搜索文本 中 各个词条 在 整个索引所有文档 中 出现次数,出现次数越多越不相关 。 向量空间模型vector space model向量空间模型,多个term对一个doc的总分数,es会根据查询字符串在所有doc中的评分情况,计算出一个 query vector 即 query向量,会给每一个doc,拿每个term计算出一个分数来。每个doc vector计算出对 query vector 的 弧度,最后基于该弧度给出一个doc相对于query中多个term的总分数,弧度越大分数越低,弧度越小分数越高 。若是多个term,那么就是线性代数来计算,无法用图表示若查询条件字符串为hello world,hello这个term,给的基于所有doc的一个评分就是3,world这个term,给的基于所有doc的一个评分就是6,则 query向量 为 [3, 6],若3个doc一个包含hello,一个包含world,一个包含hello和world,doc向量分别为[3, 0]、[0, 6]、[3, 6] 分词器工作流程首先进行 normalization切分词语,将目标文本拆分成单个单词,同时对每个单词进行 normalization时态转换单复数转换、分词器recall、搜索时召回率、增加能搜索到的结果的数量 。分词器将文本进行各种处理,最后处理好的结果才会用来建立倒排索引 。 123character filter：在一段文本进行分词之前,先进行预处理,如过滤html标签（&lt;span&gt;hello&lt;span&gt; --&gt; hello）,&amp; --&gt; and (I&amp;you --&gt; I and you)tokenizer：分词,hello you and me --&gt; hello, you, and, metoken filter：lowercase,stop word,synonymom,liked --&gt; like,Tom --&gt; tom,a/the/an --&gt; 干掉,small --&gt; little 对于默认的 standard分词器 ： standard tokenizer： 以单词边界进行切分 standard token filter：什么都不做 lowercase token filter：将所有字母转换为小写 stop token filer：默认被禁用,移除停用词,比如a the it等等1234567891011121314151617181920212223242526272829303132333435363738394041424344454647POST _analyze&#123; &quot;analyzer&quot;: &quot;standard&quot;, &quot;text&quot;: &quot;Set the shape to semi-transparent by calling set_trans(5)&quot;&#125;PUT /my_index&#123; &quot;settings&quot;: &#123; &quot;analysis&quot;: &#123; &quot;analyzer&quot;: &#123; &quot;es_std&quot;: &#123; &quot;type&quot;: &quot;standard&quot;, &quot;stopwords&quot;: &quot;_english_&quot; // 启用english停用词token filter &#125; &#125; &#125; &#125;&#125;GET /my_index/_analyze&#123; &quot;analyzer&quot;: &quot;standard&quot;, &quot;text&quot;: &quot;a dog is in the house&quot;&#125;GET /my_index/_analyze&#123; &quot;analyzer&quot;: &quot;es_std&quot;, &quot;text&quot;:&quot;a dog is in the house&quot;&#125;PUT /my_index // 定制化分词器&#123; &quot;settings&quot;: &#123; &quot;analysis&quot;: &#123; &quot;char_filter&quot;: &#123;&quot;&amp;_to_and&quot;: &#123;&quot;type&quot;: &quot;mapping&quot;,&quot;mappings&quot;: [&quot;&amp;=&gt; and&quot;]&#125;&#125;, &quot;filter&quot;: &#123;&quot;my_stopwords&quot;: &#123;&quot;type&quot;: &quot;stop&quot;,&quot;stopwords&quot;: [&quot;the&quot;,&quot;a&quot;]&#125; &#125;, &quot;analyzer&quot;: &#123; &quot;my_analyzer&quot;: &#123;&quot;type&quot;: &quot;custom&quot;,&quot;char_filter&quot;: [&quot;html_strip&quot;,&quot;&amp;_to_and&quot;],&quot;tokenizer&quot;: &quot;standard&quot;,&quot;filter&quot;: [&quot;lowercase&quot;,&quot;my_stopwords&quot;]&#125; &#125; &#125; &#125;&#125;GET /my_index/_analyze&#123; &quot;text&quot;: &quot;tom&amp;jerry are a friend in the house, &lt;a&gt;, HAHA!!&quot;, &quot;analyzer&quot;: &quot;my_analyzer&quot;&#125; IK分词器IK分词器配置文件地址为 es/plugins/ik/config,ik原生最重要的是 main.dic 和 stopword.dic 两个配置文件 IKAnalyzer.cfg.xml：用来配置自定义词库 main.dic：ik原生内置中文词库,总共有27万多条,会按照该文件中的词语去分词 quantifier.dic：单位相关的词 suffix.dic：后缀相关的词 surname.dic：中国姓氏 stopword.dic：英文停用词,停用词会在分词时被干掉,不会建立在倒排索引中 可通过在 IKAnalyzer.cfg.xml 配置文件中通过修改 &lt;entry key=&quot;ext_dict&quot;&gt;&lt;/entry&gt; 配置内容 扩展自己的词库,需重启es才能生效,还可以通过修改 &lt;entry key=&quot;ext_stopwords&quot;&gt;&lt;/entry&gt; 配置扩展停用词 。 每次在es扩展词典中,手动添加新词语,添加完都要重启es才能生效,非常麻烦,且es是分布式的,可能有数百个节点,不能每次都一个一个节点上面去修改。 IKAnalyzer.cfg.xml 配置文件中可通过 &lt;entry key=&quot;remote_ext_dict&quot;&gt;words_location&lt;/entry&gt; 和 &lt;entry key=&quot;remote_ext_stopwords&quot;&gt;words_location&lt;/entry&gt; 配置支持 远程扩展字典 。 高亮显示搜索中经常需要对搜索关键字做高亮显示,ES默认通过添加 &lt;em&gt;&lt;/em&gt;标签,在HTML中会变成红色,指定的field中若包含了搜索词,就会在那个field文本中,对搜索词进行红色高亮显示。highlight中的field必须跟 query 中field一一对齐 默认的 highlight 为 plain highlight 即 lucene highlight,在 mapping 中设置 index_options 为 offsets 使用 posting highlight 。在 mapping 中设置 term_vector 为 term_vector 使用 fast verctor highlight,对 大于1mb的field性能更高 。也可通过在查询时强制使用某种highlighter 。 一般情况下用 plain highlight 也就足够了,不需要做其他额外设置,若对高亮性能要求很高,可尝试启用 posting highlight,若 field值特别大超过了1M,则可用 fast vector highlight 。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455PUT /news_website&#123; &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123; &quot;title&quot;: &#123;&quot;type&quot;: &quot;text&quot;,&quot;analyzer&quot;: &quot;ik_max_word&quot;&#125;, &quot;content&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;index_options&quot;: &quot;offsets&quot; &#125; &#125; &#125;&#125;PUT /news_website&#123; &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123; &quot;title&quot;: &#123;&quot;type&quot;: &quot;text&quot;,&quot;analyzer&quot;: &quot;ik_max_word&quot;&#125;, &quot;content&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;term_vector&quot;: &quot;with_positions_offsets&quot; &#125; &#125; &#125;&#125;GET /news_website/_doc/_search&#123; &quot;query&quot;: &#123;&quot;match&quot;: &#123;&quot;content&quot;: &quot;文章&quot;&#125;&#125;, &quot;highlight&quot;: &#123; &quot;fields&quot;: &#123;&quot;content&quot;: &#123;&quot;type&quot;: &quot;plain&quot;&#125;&#125; &#125;&#125;GET /news_website/_doc/_search&#123; &quot;query&quot;: &#123;&quot;match&quot;: &#123;&quot;content&quot;: &quot;文章&quot;&#125;&#125;, &quot;highlight&quot;: &#123; // 设置高亮html标签,默认是&lt;em&gt;标签 &quot;pre_tags&quot;: [&quot;&lt;span color=&#x27;red&#x27;&gt;&quot;], &quot;post_tags&quot;: [&quot;&lt;/span&gt;&quot;], &quot;fields&quot;: &#123;&quot;content&quot;: &#123;&quot;type&quot;: &quot;plain&quot;&#125;&#125; &#125;&#125;GET /_search&#123; &quot;query&quot;: &#123;&quot;match&quot;: &#123;&quot;content&quot;: &quot;文章&quot;&#125;&#125;, &quot;highlight&quot;: &#123; &quot;fields&quot;: &#123; &quot;content&quot;: &#123; &quot;fragment_size&quot;: 150, // 设置要显示出来的fragment文本长度,默认100 &quot;number_of_fragments&quot;: 3 // 指定显示高亮fragment文本片段个数 &#125; &#125; &#125;&#125;用一个大家容易理解的SQL语法来解释,如：select count(*) from table group by column。那么group by column分组后的每组数据就是bucket。对每个分组执行的count(*)就是metric。 聚合搜索bucket就是一个聚合搜索时的数据分组,metric就是对一个bucket数据执行的统计分析,metric有求和,最大值,最小值,平均值等多种统计 。如 select count(*) from table group by column 其中 group by column 分组后的 每组数据就是bucket,每个分组执行的 count(*) 就是 metric 。 1234567891011121314151617181920PUT /cars&#123;&quot;mappings&quot;:&#123;&quot;properties&quot;:&#123;&quot;price&quot;:&#123;&quot;type&quot;:&quot;long&quot;&#125;,&quot;color&quot;:&#123;&quot;type&quot;:&quot;keyword&quot;&#125;,&quot;brand&quot;:&#123;&quot;type&quot;:&quot;keyword&quot;&#125;,&quot;model&quot;:&#123;&quot;type&quot;:&quot;keyword&quot;&#125;,&quot;sold_date&quot;:&#123;&quot;type&quot;:&quot;date&quot;&#125;,&quot;remark&quot;:&#123;&quot;type&quot;:&quot;text&quot;,&quot;analyzer&quot;:&quot;ik_max_word&quot;&#125;&#125;&#125;&#125;POST /cars/_bulk&#123;&quot;index&quot;:&#123;&#125;&#125;&#123;&quot;price&quot;:258000,&quot;color&quot;:&quot;金色&quot;,&quot;brand&quot;:&quot;大众&quot;,&quot;model&quot;:&quot;大众迈腾&quot;,&quot;sold_date&quot;:&quot;2021-10-28&quot;,&quot;remark&quot;:&quot;大众中档车&quot;&#125;&#123;&quot;index&quot;:&#123;&#125;&#125;&#123;&quot;price&quot;:123000,&quot;color&quot;:&quot;金色&quot;,&quot;brand&quot;:&quot;大众&quot;,&quot;model&quot;:&quot;大众速腾&quot;,&quot;sold_date&quot;:&quot;2021-11-05&quot;,&quot;remark&quot;:&quot;大众神车&quot;&#125;&#123;&quot;index&quot;:&#123;&#125;&#125;&#123;&quot;price&quot;:239800,&quot;color&quot;:&quot;白色&quot;,&quot;brand&quot;:&quot;标志&quot;,&quot;model&quot;:&quot;标志508&quot;,&quot;sold_date&quot;:&quot;2021-05-18&quot;,&quot;remark&quot;:&quot;标志品牌全球上市车型&quot;&#125;&#123;&quot;index&quot;:&#123;&#125;&#125;&#123;&quot;price&quot;:148800,&quot;color&quot;:&quot;白色&quot;,&quot;brand&quot;:&quot;标志&quot;,&quot;model&quot;:&quot;标志408&quot;,&quot;sold_date&quot;:&quot;2021-07-02&quot;,&quot;remark&quot;:&quot;比较大的紧凑型车&quot;&#125;&#123;&quot;index&quot;:&#123;&#125;&#125;&#123;&quot;price&quot;:1998000,&quot;color&quot;:&quot;黑色&quot;,&quot;brand&quot;:&quot;大众&quot;,&quot;model&quot;:&quot;大众辉腾&quot;,&quot;sold_date&quot;:&quot;2021-08-19&quot;,&quot;remark&quot;:&quot;大众最让人肝疼的车&quot;&#125;&#123;&quot;index&quot;:&#123;&#125;&#125;&#123;&quot;price&quot;:218000,&quot;color&quot;:&quot;红色&quot;,&quot;brand&quot;:&quot;奥迪&quot;,&quot;model&quot;:&quot;奥迪A4&quot;,&quot;sold_date&quot;:&quot;2021-11-05&quot;,&quot;remark&quot;:&quot;小资车型&quot;&#125;&#123;&quot;index&quot;:&#123;&#125;&#125;&#123;&quot;price&quot;:489000,&quot;color&quot;:&quot;黑色&quot;,&quot;brand&quot;:&quot;奥迪&quot;,&quot;model&quot;:&quot;奥迪A6&quot;,&quot;sold_date&quot;:&quot;2022-01-01&quot;,&quot;remark&quot;:&quot;政府专用？&quot;&#125;&#123;&quot;index&quot;:&#123;&#125;&#125;&#123;&quot;price&quot;:1899000,&quot;color&quot;:&quot;黑色&quot;,&quot;brand&quot;:&quot;奥迪&quot;,&quot;model&quot;:&quot;奥迪A 8&quot;,&quot;sold_date&quot;:&quot;2022-02-12&quot;,&quot;remark&quot;:&quot;很贵的大A6。。。&quot;&#125; 根据color 分组统计销售数量,只执行聚合分组,ES中 最基础的聚合 为 terms,相当于SQL中的count,ES中默认为分组数据做排序,使用的是 doc_count 数据执行 降序排列 。可使用 _key 元数据根据分组后的 字段数据 执行不同的排序方案,也可根据 _count 元数据,根据分组后的统计值执行不同的排序方案 。 1234567891011GET /cars/_search&#123; &quot;aggs&quot;: &#123; &quot;group_by_color&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;color&quot;, &quot;order&quot;: &#123;&quot;_count&quot;: &quot;desc&quot;&#125; &#125; &#125; &#125;&#125; 先根据color执行聚合分组,在此分组的基础上,对组内数据执行聚合统计,组内数据的聚合统计就是 metric,同样可执行排序,因为组内有聚合统计,且对统计数据给予了命名avg_by_price,所以可根据该聚合统计数据字段名执行排序逻辑。 size可设置为0,表示不返回文档只返回聚合之后的数据,提高查询速度,若需要这些文档也可按照实际情况进行设置。对聚合统计数据进行排序,若有多层 aggs 执行 下钻聚合 时也可 根据最内层聚合数据执行排序 。 1234567891011121314151617181920212223242526272829GET /cars/_search&#123; &quot;aggs&quot;: &#123; &quot;group_by_color&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;color&quot;, &quot;order&quot;: &#123;&quot;avg_by_price&quot;: &quot;asc&quot;&#125; &#125;, &quot;aggs&quot;: &#123; &quot;avg_by_price&quot;: &#123;&quot;avg&quot;: &#123;&quot;field&quot;: &quot;price&quot;&#125;&#125; &#125; &#125; &#125;&#125;GET /cars/_search&#123; &quot;size&quot;: 0, &quot;aggs&quot;: &#123; &quot;group_by_color&quot;: &#123; &quot;terms&quot;: &#123;&quot;field&quot;: &quot;color&quot;&#125;, &quot;aggs&quot;: &#123; &quot;group_by_brand&quot;: &#123; &quot;terms&quot;: &#123;&quot;field&quot;: &quot;brand&quot;,&quot;order&quot;: &#123;&quot;avg_by_price&quot;: &quot;desc&quot;&#125;&#125;, &quot;aggs&quot;: &#123;&quot;avg_by_price&quot;: &#123;&quot;avg&quot;: &#123;&quot;field&quot;: &quot;price&quot;&#125;&#125;&#125; &#125; &#125; &#125; &#125;&#125; 先根据color聚合分组,在组内根据brand再次聚合分组,这种操作可称为下钻分析,aggs若定义比较多,则会感觉语法格式混乱,aggs语法格式有一个相对固定的结构,aggs可嵌套定义也可水平定义 。嵌套定义称为下钻分析,水平定义就是平铺多个分组方式 123456789101112131415GET /index_name/type_name/_search&#123; &quot;aggs&quot;: &#123; &quot;定义分组名称&quot;: &#123; &quot;分组策略如：terms、avg、sum&quot;: &#123; &quot;field&quot;: &quot;根据哪一个字段分组&quot;, &quot;其他参数&quot;: &quot;&quot; &#125;, &quot;aggs&quot;: &#123; &quot;分组名称1&quot;: &#123;&#125;, &quot;分组名称2&quot;: &#123;&#125; &#125; &#125; &#125;&#125; 统计不同color中的最大和最小价格、总价,聚合分析最常用的种类就是统计数量,最大,最小,平均,总计等 12345678910111213141516171819202122232425262728293031GET /cars/_search&#123; &quot;aggs&quot;: &#123; &quot;group_by_color&quot;: &#123; &quot;terms&quot;: &#123;&quot;field&quot;: &quot;color&quot;&#125;, &quot;aggs&quot;: &#123; &quot;max_price&quot;: &#123;&quot;max&quot;: &#123;&quot;field&quot;: &quot;price&quot;&#125;&#125;, &quot;min_price&quot;: &#123;&quot;min&quot;: &#123;&quot;field&quot;: &quot;price&quot;&#125;&#125;, &quot;sum_price&quot;: &#123;&quot;sum&quot;: &#123;&quot;field&quot;: &quot;price&quot;&#125;&#125; &#125; &#125; &#125;&#125;GET cars/_search // 统计不同品牌汽车中价格排名最高的车型&#123; &quot;size&quot;: 0, &quot;aggs&quot;: &#123; &quot;group_by_brand&quot;: &#123; &quot;terms&quot;: &#123;&quot;field&quot;: &quot;brand&quot;&#125;, &quot;aggs&quot;: &#123; &quot;top_car&quot;: &#123; &quot;top_hits&quot;: &#123; &quot;size&quot;: 1, // 取组内多少条数据,默认为10 &quot;sort&quot;: [&#123;&quot;price&quot;: &#123;&quot;order&quot;: &quot;desc&quot;&#125;&#125;], // 组内使用什么字段什么规则排序,默认使用_doc的asc规则排序 &quot;_source&quot;: &#123;&quot;includes&quot;: [&quot;model&quot;,&quot;price&quot;]&#125; // 结果中包含document中的哪些字段,默认包含全部字段 &#125; &#125; &#125; &#125; &#125;&#125; histogram区间统计 类似 terms, 也是用于 bucket分组操作, 是根据一个field实现数据区间分组 。如以100万为一个范围,统计不同范围内车辆销售量和平均价格。使用 histogram聚合 时field指定价格字段price,区间范围是100万,此时ES会将price价格区间划分为： [0, 1000000), [1000000, 2000000), [2000000, 3000000)等依次类推。在划分区间同时 histogram 会类似 terms 进行 数据数量统计, 可通过嵌套aggs对聚合分组后的组内数据做再次聚合分析 。 123456789101112GET /cars/_search&#123; &quot;aggs&quot;: &#123; &quot;histogram_by_price&quot;: &#123; &quot;histogram&quot;: &#123; &quot;field&quot;: &quot;price&quot;, &quot;interval&quot;: 1000000 &#125;, &quot;aggs&quot;: &#123;&quot;avg_by_price&quot;: &#123;&quot;avg&quot;: &#123;&quot;field&quot;: &quot;price&quot;&#125;&#125;&#125; &#125; &#125;&#125; date_histogram区间分组可对date类型的field执行区间聚合分组,若以月为单位,统计不同月份汽车销售数量及销售总金额。此时可使用 date_histogram 实现聚合分组,其中field来指定用于聚合分组的字段,interval指定 区间范围,可选值有 year、quarter、month、week、day、hour、minute、second,format指定日期格式化,min_doc_count指定每个区间最少document,若不指定默认为0,当区间范围内没有document时,也会显示bucket分组,extended_bounds指定起始时间和结束时间,若不指定默认使用字段中日期最小值和最大值作为起始和结束时间。 123456789101112131415GET /cars/_search&#123; &quot;aggs&quot;: &#123; &quot;histogram_by_date&quot;: &#123; &quot;date_histogram&quot;: &#123; &quot;field&quot;: &quot;sold_date&quot;, &quot;interval&quot;: &quot;month&quot;, // 7.X之后使用calendar_interval,指定区间范围 &quot;format&quot;: &quot;yyyy-MM-dd&quot;, // 指定日期格式化 &quot;min_doc_count&quot;: 1, &quot;extended_bounds&quot;: &#123;&quot;min&quot;: &quot;2021-01-01&quot;,&quot;max&quot;: &quot;2022-12-31&quot;&#125; &#125;, &quot;aggs&quot;: &#123;&quot;sum_by_price&quot;: &#123;&quot;sum&quot;: &#123;&quot;field&quot;: &quot;price&quot;&#125;&#125;&#125; &#125; &#125;&#125; 聚合统计数据时,有时需要对比部分数据和总体数据,如统计某品牌车辆平均价格和所有车辆平均价格。 global 是用于定义一个全局bucket,该 bucket 会 忽略query 的条件,检索所有document进行对应的聚合统计。 123456789101112GET /cars/_search&#123; &quot;size&quot;: 0, &quot;query&quot;: &#123;&quot;match&quot;: &#123;&quot;brand&quot;: &quot;大众&quot;&#125;&#125;, &quot;aggs&quot;: &#123; &quot;volkswagen_of_avg_price&quot;: &#123;&quot;avg&quot;: &#123;&quot;field&quot;: &quot;price&quot;&#125;&#125;, // 统计某品牌车辆平均价格 &quot;all_avg_price&quot;: &#123; // 所有车辆平均价格 &quot;global&quot;: &#123;&#125;, &quot;aggs&quot;: &#123;&quot;all_of_price&quot;: &#123;&quot;avg&quot;: &#123;&quot;field&quot;: &quot;price&quot;&#125;&#125;&#125; &#125; &#125;&#125; filter也可和aggs组合使用,实现相对复杂的过滤聚合分析,filter的范围决定了其过滤的范围,将filter放在aggs内部,代表该过滤器只对query搜索得到的结果执行filter过滤 。若filter放在aggs外部,过滤器则会过滤所有数据。 12345678910111213141516171819GET /cars/_search // filter和aggs组合使用,实现相对复杂的过滤聚合分析&#123; &quot;query&quot;: &#123; &quot;constant_score&quot;: &#123; &quot;filter&quot;: &#123;&quot;range&quot;: &#123;&quot;price&quot;: &#123;&quot;gte&quot;: 100000,&quot;lte&quot;: 500000&#125;&#125;&#125; &#125; &#125;, &quot;aggs&quot;: &#123;&quot;avg_by_price&quot;: &#123;&quot;avg&quot;: &#123;&quot;field&quot;: &quot;price&quot;&#125;&#125;&#125;&#125;GET /cars/_search&#123; &quot;query&quot;: &#123;&quot;match&quot;: &#123;&quot;brand&quot;: &quot;大众&quot;&#125;&#125;, &quot;aggs&quot;: &#123; &quot;count_last_year&quot;: &#123; // 12M/M表示12个月,1y/y表示1年,d表示天 &quot;filter&quot;: &#123;&quot;range&quot;: &#123;&quot;sold_date&quot;: &#123;&quot;gte&quot;: &quot;now-12M&quot;&#125;&#125;&#125;, &quot;aggs&quot;: &#123;&quot;sum_of_price_last_year&quot;: &#123;&quot;sum&quot;: &#123;&quot;field&quot;: &quot;price&quot;&#125;&#125;&#125; &#125; &#125;&#125; 数据建模如下设计一个用户document数据类型,其中包含一个地址数据的数组,该设计方式相对复杂,但在管理数据时更加的灵活。但也有明显的缺陷,针对地址数据做数据搜索时,经常会搜索出不必要的数据 。 123456789101112131415161718192021222324252627282930313233343536373839404142434445PUT /user_index&#123; &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123; &quot;login_name&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;&#125;, &quot;age &quot;: &#123;&quot;type&quot;: &quot;short&quot;&#125;, &quot;address&quot;: &#123; &quot;properties&quot;: &#123; &quot;province&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;&#125;, &quot;city&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;&#125;, &quot;street&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;&#125; &#125; &#125; &#125; &#125;&#125;PUT /user_index/_doc/1&#123; &quot;login_name&quot;: &quot;jack&quot;, &quot;age&quot;: 25, &quot;address&quot;: [ &#123;&quot;province&quot;: &quot;北京&quot;,&quot;city&quot;: &quot;北京&quot;,&quot;street&quot;: &quot;枫林三路&quot;&#125;, &#123;&quot;province&quot;: &quot;天津&quot;,&quot;city&quot;: &quot;天津&quot;,&quot;street&quot;: &quot;华夏路&quot;&#125; ]&#125;PUT /user_index/_doc/2&#123; &quot;login_name&quot;: &quot;rose&quot;, &quot;age&quot;: 21, &quot;address&quot;: [ &#123;&quot;province&quot;: &quot;河北&quot;,&quot;city&quot;: &quot;廊坊&quot;,&quot;street&quot;: &quot;燕郊经济开发区&quot;&#125;, &#123;&quot;province&quot;: &quot;天津&quot;,&quot;city&quot;: &quot;天津&quot;,&quot;street&quot;: &quot;华夏路&quot;&#125; ]&#125;GET /user_index/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [ &#123;&quot;match&quot;: &#123;&quot;address.province&quot;: &quot;北京&quot;&#125;&#125;, &#123;&quot;match&quot;: &#123;&quot;address.city&quot;: &quot;天津&quot;&#125;&#125; ] &#125; &#125;&#125; 可使用 nested object 作为 地址数组 的集体类型可解决上述问题,且搜索时需要 使用nested对应的搜索语法 123456789101112131415161718192021222324252627282930PUT /user_index&#123; &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123; &quot;login_name&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;&#125;, &quot;age &quot;: &#123;&quot;type&quot;: &quot;short&quot;&#125;, &quot;address&quot;: &#123; &quot;type&quot;: &quot;nested&quot;, &quot;properties&quot;: &#123; &quot;province&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;&#125;, &quot;city&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;&#125;, &quot;street&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;&#125; &#125; &#125; &#125; &#125;&#125;GET /user_index/_search&#123; &quot;query&quot;: &#123;&quot;bool&quot;: &#123;&quot;must&quot;: [ &#123;&quot;nested&quot;: &#123;&quot;path&quot;: &quot;address&quot;, &quot;query&quot;: &#123; &quot;bool&quot;: &#123;&quot;must&quot;: [ &#123;&quot;match&quot;: &#123;&quot;address.province&quot;: &quot;北京&quot;&#125;&#125;, &#123;&quot;match&quot;: &#123;&quot;address.city&quot;: &quot;北京&quot;&#125;&#125; ]&#125; &#125;&#125; &#125;] &#125;&#125;&#125; 普通数组数据在ES中会被扁平化处理,nested object数据类型ES在保存时不会扁平化处理 1234567891011121314151617181920&#123; // 普通数组 &quot;login_name&quot; : &quot;jack&quot;, &quot;address.province&quot; : [ &quot;北京&quot;, &quot;天津&quot; ], &quot;address.city&quot; : [ &quot;北京&quot;, &quot;天津&quot; ] &quot;address.street&quot; : [ &quot;枫林三路&quot;, &quot;华夏路&quot; ]&#125;// nested数据&#123; &quot;login_name&quot; : &quot;jack&quot;&#125;&#123; &quot;address.province&quot; : &quot;北京&quot;, &quot;address.city&quot; : &quot;北京&quot;, &quot;address.street&quot; : &quot;枫林三路&quot;&#125;&#123; &quot;address.province&quot; : &quot;天津&quot;, &quot;address.city&quot; : &quot;天津&quot;, &quot;address.street&quot; : &quot;华夏路&quot;,&#125; nested object建模缺点是采取的是类似冗余数据的方式,将多个数据放在一起,维护成本比较高,每次更新需要重新索引整个对象,包括根对象和嵌套对象。ES提供 类似关系型数据库 中 Join 的实现,使用Join数据类型实现父子关系,从而分离两个文档对象。 更新父文档无需重新索引整个子文档,子文档被新增,更改和删除也不会影响到父文档和其他子文档,父子关系元数据映射,用于确保查询时高性能,但是有一个限制父子数据包括映射其关联关系的元数据必须存在于一个shard中,搜索父子关系数据时,不用跨分片性能高。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495PUT my_blogs&#123; &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123; &quot;blog_comments_relation&quot;: &#123; &quot;type&quot;: &quot;join&quot;, // 指明join类型 &quot;relations&quot;: &#123; // 声明父子关系 &quot;blog&quot;: &quot;comment&quot; // blog为父文档名称,comment为子文档名称 &#125; &#125;, &quot;content&quot;: &#123;&quot;type&quot;: &quot;text&quot;&#125;, &quot;title&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;&#125; &#125; &#125;&#125;PUT my_blogs/_doc/blog1 // blog1为父文档id&#123; &quot;title&quot;: &quot;Learning Elasticsearch&quot;, &quot;content&quot;: &quot;learning ELK is happy&quot;, &quot;blog_comments_relation&quot;: &#123; // 声明文档类型 &quot;name&quot;: &quot;blog&quot; &#125;&#125;PUT my_blogs/_doc/blog2 // blog2为父文档id&#123; &quot;title&quot;: &quot;Learning Hadoop&quot;, &quot;content&quot;: &quot;learning Hadoop&quot;, &quot;blog_comments_relation&quot;: &#123; // 声明文档类型 &quot;name&quot;: &quot;blog&quot; &#125;&#125;// 父文档和子文档必须存在相同的分片上, 当指定文档时候,必须指定它的父文档IDPUT my_blogs/_doc/comment1?routing=blog1 // 使用route参数来保证,分配到相同分片&#123; &quot;comment&quot;: &quot;I am learning ELK&quot;, &quot;username&quot;: &quot;Jack&quot;, &quot;blog_comments_relation&quot;: &#123; &quot;name&quot;: &quot;comment&quot;, &quot;parent&quot;: &quot;blog1&quot; &#125;&#125;PUT my_blogs/_doc/comment2?routing=blog2 // comment2为子文档id,blog2为父文档id&#123; &quot;comment&quot;: &quot;I like Hadoop!!!!!&quot;, &quot;username&quot;: &quot;Jack&quot;, &quot;blog_comments_relation&quot;: &#123; &quot;name&quot;: &quot;comment&quot;, &quot;parent&quot;: &quot;blog2&quot; &#125;&#125;PUT my_blogs/_doc/comment3?routing=blog2&#123; &quot;comment&quot;: &quot;Hello Hadoop&quot;, &quot;username&quot;: &quot;Bob&quot;, &quot;blog_comments_relation&quot;: &#123; &quot;name&quot;: &quot;comment&quot;, &quot;parent&quot;: &quot;blog2&quot; &#125;&#125;POST my_blogs/_search // 查询所有文档&#123;&#125;GET my_blogs/_doc/blog2 // 根据父文档ID查看POST my_blogs/_search // parent_id查询,返回所有相关子文档&#123; &quot;query&quot;: &#123; &quot;parent_id&quot;: &#123;&quot;type&quot;: &quot;comment&quot;,&quot;id&quot;: &quot;blog2&quot;&#125; &#125;&#125;POST my_blogs/_search // has_child查询,返回父文档&#123; &quot;query&quot;: &#123; &quot;has_child&quot;: &#123; &quot;type&quot;: &quot;comment&quot;, &quot;query&quot;: &#123;&quot;match&quot;: &#123;&quot;username&quot;: &quot;Jack&quot;&#125;&#125; &#125; &#125;&#125;POST my_blogs/_search // has_parent查询,返回相关的子文档&#123; &quot;query&quot;: &#123; &quot;has_parent&quot;: &#123; &quot;parent_type&quot;: &quot;blog&quot;, &quot;query&quot;: &#123;&quot;match&quot;: &#123;&quot;title&quot;: &quot;Learning Hadoop&quot;&#125;&#125; &#125; &#125;&#125;PUT my_blogs/_doc/comment3?routing=blog2 //更新子文档不会影响到父文档&#123; &quot;comment&quot;: &quot;Hello Hadoop??&quot;, &quot;blog_comments_relation&quot;: &#123; &quot;name&quot;: &quot;comment&quot;, &quot;parent&quot;: &quot;blog2&quot; &#125;&#125; 文件系统数据若需要使用 文件路径搜索 内容,只需要为其中的字段定义一个特殊的 path_hierarchy 分词器 123456789101112131415161718192021222324252627282930313233343536373839404142PUT /codes&#123; &quot;settings&quot;: &#123;&quot;analysis&quot;: &#123;&quot;analyzer&quot;: &#123;&quot;path_analyzer&quot;: &#123;&quot;tokenizer&quot;: &quot;path_hierarchy&quot;&#125;&#125;&#125;&#125;, &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123; &quot;fileName&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;&#125;, &quot;path&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;path_analyzer&quot;, &quot;fields&quot;: &#123;&quot;keyword&quot;: &#123;&quot;type&quot;: &quot;text&quot;,&quot;analyzer&quot;: &quot;standard&quot;&#125;&#125; &#125;, &quot;content&quot;: &#123;&quot;type&quot;: &quot;text&quot;,&quot;analyzer&quot;: &quot;standard&quot;&#125; &#125; &#125;&#125;PUT /codes/_doc/1&#123; &quot;fileName&quot;: &quot;HelloWorld.java&quot;, &quot;path&quot;: &quot;/com/eleven/first&quot;, &quot;content&quot;: &quot;package com.eleven.first; public class HelloWorld &#123; // some code... &#125;&quot;&#125;GET /codes/_search&#123; &quot;query&quot;: &#123;&quot;match&quot;: &#123;&quot;path&quot;: &quot;/com&quot;&#125;&#125;&#125;GET /codes/_analyze&#123; &quot;text&quot;: &quot;/a/b/c/d&quot;, &quot;field&quot;: &quot;path&quot;&#125;GET /codes/_search&#123; &quot;query&quot;: &#123;&quot;match&quot;: &#123;&quot;path.keyword&quot;: &quot;/com&quot;&#125;&#125;&#125;GET /codes/_search&#123; &quot;query&quot;: &#123;&quot;bool&quot;: &#123;&quot;should&quot;: [ &#123;&quot;match&quot;: &#123;&quot;path&quot;: &quot;/com&quot;&#125;&#125;, &#123;&quot;match&quot;: &#123;&quot;path.keyword&quot;: &quot;/com/eleven&quot;&#125;&#125; ]&#125;&#125;&#125; Scroll分页使用 from 和 size 方式查询1W以内的数据都OK,但若数据比较多时会出现性能问题。ES做了一个限制 不允许查询1W条以后的数据 。若要查询1W条以后的数据,可使用ES中提供的 scroll游标 来查询。 在进行大量分页时,每次分页都需要将要查询数据进行重新排序,这样非常浪费性能。使用 scroll游标 是 将要用的数据一次性排序好, 然后 分批取出 。性能要比from + size好得多,使用scroll查询后,排序后的数据会保持一定的时间, 后续分页查询都从该快照取数据。响应结果中会返回_scroll_id,第二次查询直接使用_scroll_id来查询。 1234567891011121314GET /es_db/_search?scroll=1m // 让排序的数据保持1分钟&#123; &quot;query&quot;: &#123; &quot;multi_match&quot;: &#123; &quot;query&quot;: &quot;广州长沙张三&quot;, &quot;fields&quot;: [&quot;address&quot;,&quot;name&quot;] &#125; &#125;, &quot;size&quot;: 100&#125;GET _search/scroll?scroll=1m&#123; &quot;scroll_id&quot;: &quot;FGluY2x1ZGVfY29udGV4dF91dWlkDXF1ZXJ5QW5kRmV0Y2gBFnJKUnZmX1pIVGVpM05TWDBQX0JJeXcAAAAAAAaeghZDUkdZN1FJNVIwYUJhYUxvNWVxd1Rn&quot;&#125; SQL支持ES SQL允许执行类SQL查询,REST接口、命令行或 JDBC 等都可使用 SQL 来进行 数据检索 和 数据聚合 。特点： 本地集成：ES SQL是专门为ES构建的,每个SQL查询都根据底层存储对相关节点有效执行 无额外要求：不依赖其他硬件、进程、运行时库,可直接运行在ES集群上 轻量且高效：像SQL那样简洁、高效地完成查询1234567891011121314GET /es_db/_search?scroll=1m // 让排序的数据保持1分钟&#123; &quot;query&quot;: &#123; &quot;multi_match&quot;: &#123; &quot;query&quot;: &quot;广州长沙张三&quot;, &quot;fields&quot;: [&quot;address&quot;,&quot;name&quot;] &#125; &#125;, &quot;size&quot;: 100&#125;GET _search/scroll?scroll=1m&#123; &quot;scroll_id&quot;: &quot;FGluY2x1ZGVfY29udGV4dF91dWlkDXF1ZXJ5QW5kRmV0Y2gBFnJKUnZmX1pIVGVpM05TWDBQX0JJeXcAAAAAAAaeghZDUkdZN1FJNVIwYUJhYUxvNWVxd1Rn&quot;&#125; 目前 FROM只支持单表, 不支持JOIN、不支持较复杂的子查询,format 表示 指定返回数据类型, 支持的类型有 逗号分隔csv、json、制表符分隔符tsv、txt、yaml 。 12345678910111213141516GET /_sql?format=json&#123; &quot;query&quot;: &quot;SELECT * FROM es_db limit 1&quot;&#125;GET /_sql/translate // 将SQL转换为DSL&#123; &quot;query&quot;: &quot;SELECT * FROM es_db limit 1&quot;&#125;GET /_sql?format=json // field_exp匹配字段,constant_exp匹配常量表达式,&#123; // 检索address包含广州和name中包含张三的用户 &quot;query&quot;: &quot;select * from es_db where MATCH(address, &#x27;广州&#x27;) or MATCH(name, &#x27;张三&#x27;) limit 10&quot;&#125;GET /_sql?format=txt // 统计分组&#123; &quot;query&quot;: &quot;select age, count(*) as age_cnt from es_db group by age&quot;&#125; 模板模板搜索可将一些搜索进行模板化,每次执行该搜索就直接调用模板,传入一些参数即可。 123456789101112131415161718192021222324252627282930GET /cars/_search/template // 简单定义参数并传递&#123; &quot;source&quot;: &#123; &quot;query&quot;: &#123;&quot;match&quot;: &#123;&quot;remark&quot;: &quot;&#123;&#123;kw&#125;&#125;&quot;&#125;&#125;, &quot;size&quot;: &quot;&#123;&#123;size&#125;&#125;&quot; &#125;, &quot;params&quot;: &#123;&quot;kw&quot;: &quot;大众&quot;,&quot;size&quot;: 2&#125;&#125;GET cars/_search/template // toJson方式传递参数&#123; &quot;source&quot;: &quot;&quot;&quot;&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123;&#123;#toJson&#125;&#125;parameter&#123;&#123;/toJson&#125;&#125; &#125;&#125;&quot;&quot;&quot;, &quot;params&quot;: &#123; &quot;parameter&quot;: &#123;&quot;remark&quot;: &quot;大众&quot;&#125; &#125;&#125;GET cars/_search/template // json方式传递参数&#123; &quot;source&quot;: &#123;&quot;query&quot;: &#123;&quot;match&quot;: &#123; &quot;remark&quot;: &quot;&#123;&#123;#join delimiter=&#x27; &#x27;&#125;&#125;kw&#123;&#123;/join delimiter=&#x27; &#x27;&#125;&#125;&quot; &#125;&#125;&#125;, &quot;params&quot;: &#123;&quot;kw&quot;: [&quot;大众&quot;,&quot;标致&quot;]&#125;&#125;GET cars/_search/template&#123; &quot;source&quot;: &#123;&quot;query&quot;: &#123;&quot;range&quot;: &#123;&quot;price&quot;: &#123; &quot;gte&quot;: &quot;&#123;&#123;start&#125;&#125;&quot;, &quot;lte&quot;: &quot;&#123;&#123;end&#125;&#125;&#123;&#123;^end&#125;&#125;200000&#123;&#123;/end&#125;&#125;&quot; // 默认值定义 &#125;&#125;&#125;&#125;, &quot;params&quot;: &#123;&quot;start&quot;: 100000,&quot;end&quot;: 140000&#125;&#125; 记录template实现重复调用 可使用 Mustache 语言作为 搜索请求预处理, 它提供模板 通过键值对 来替换模板中的变量。把 脚本存储在本地磁盘中, 默认位置为 elasticsearch\\config\\scripts, 通过引用脚本名称进行使用 12345678910111213POST _scripts/test // test为脚本id&#123; &quot;script&quot;: &#123; &quot;lang&quot;: &quot;mustache&quot;, // 指定mustache语言 &quot;source&quot;: &#123;&quot;query&quot;: &#123;&quot;match&quot;: &#123;&quot;remark&quot;: &quot;&#123;&#123;kw&#125;&#125;&quot;&#125;&#125;&#125; &#125;&#125;GET cars/_search/template&#123; &quot;id&quot;: &quot;test&quot;, // 指定调用脚本的id &quot;params&quot;: &#123;&quot;kw&quot;: &quot;大众&quot;&#125;&#125;DELETE _scripts/test // 删除脚本id为test的脚本 suggest searchsuggest search(completion suggest) 即 建议搜索 或 搜索建议, 也可叫做自动完成,类似百度中搜索联想提示功能。ES实现 suggest时 性能非常高, 其构建的不是倒排索引也不是正排索引,是纯粹用于前缀搜索的一种特殊数据结构,且会全部放在内存中,所以suggest search进行前缀搜索提示性能是非常高。需要使用suggest时候,必须在定义index时为其mapping指定开启suggest 。 12345678910111213141516171819202122232425262728293031323334PUT /movie&#123; &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123;&quot;title&quot;: &#123;&quot;type&quot;: &quot;text&quot;,&quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;fields&quot;: &#123;&quot;suggest&quot;: &#123;&quot;type&quot;: &quot;completion&quot;,&quot;analyzer&quot;: &quot;ik_max_word&quot;&#125;&#125; &#125;, &quot;content&quot;: &#123;&quot;type&quot;: &quot;text&quot;,&quot;analyzer&quot;: &quot;ik_max_word&quot;&#125; &#125; &#125;&#125;PUT /movie/_doc/1&#123; &quot;title&quot;: &quot;西游记电影系列&quot;, &quot;content&quot;: &quot;西游记之月光宝盒将与2021年进行......&quot;&#125;PUT /movie/_doc/2&#123; &quot;title&quot;: &quot;西游记文学系列&quot;, &quot;content&quot;: &quot;某知名网络小说作家已经完成了大话西游同名小说的出版&quot;&#125;PUT /movie/_doc/3&#123; &quot;title&quot;: &quot;西游记之大话西游手游&quot;, &quot;content&quot;: &quot;网易游戏近日出品了大话西游经典IP的手游,正在火爆内测中&quot;&#125;GET /movie/_search&#123; &quot;suggest&quot;: &#123; &quot;my-suggest&quot;: &#123; &quot;prefix&quot;: &quot;西游记&quot;, &quot;completion&quot;: &#123;&quot;field&quot;: &quot;title.suggest&quot;&#125; &#125; &#125;&#125; 地理位置搜索ES支持 地理位置搜索 和 聚合分析, 可实现 在指定区域内搜索数据、搜索指定地点附近的数据、聚合分析指定地点附近的数据 等操作。ES中若使用地理位置搜索,必须提供一个特殊的字段类型 geo_point, 用于指定地理位置坐标点。 新增一个基于 geo_point 类型数据,可使用多种方式。多种类型描述 geo_point 类型字段时,在 搜索数据时显示格式和录入格式是统一的 。 任何数据描述 的 geo_point 类型字段, 都适用地理位置搜索 。 数据范围要求 纬度范围 是-90~90之间, 经度范围 是-180~180之间,经纬度数据都是 浮点数 或 数字串, 最大精度为 小数点后7位 。 latitude ： 纬度 、 longitude ： 经度 。 123456789101112131415161718192021222324PUT /hotel_app&#123; &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123; &quot;pin&quot;: &#123;&quot;type&quot;: &quot;geo_point&quot;&#125;, &quot;name&quot;: &#123;&quot;type&quot;: &quot;text&quot;,&quot;analyzer&quot;: &quot;ik_max_word&quot;&#125; &#125; &#125;&#125;PUT /hotel_app/_doc/1&#123; &quot;name&quot;: &quot;七天连锁酒店&quot;, &quot;pin&quot;: &#123;&quot;lat&quot;: 40.12,&quot;lon&quot;: -71.34&#125;&#125;PUT /hotel_app/_doc/2&#123; &quot;name&quot;: &quot;维多利亚大酒店&quot;, &quot;pin&quot;: &quot;40.99, -70.81&quot;&#125;PUT /hotel_app/_doc/3&#123; &quot;name&quot;: &quot; 红树林宾馆&quot;, &quot;pin&quot;: [40,-73.81] // 基于数组：依次定义经度、纬度,不推荐使用&#125; 矩形范围搜索 传入 top_left 和 bottom_right 坐标点是有固定要求的, top_left 即 从西北向东南, Bottom_right 即从东南向西北, 且 top_left纬度应大于bottom_right, top_left经度应小于bottom_right 。多边形范围搜索 对传入若干点坐标顺序没有任何要求,只要传入若干地理位置坐标点,即可形成多边形。 12345678910111213141516171819202122232425GET /hotel_app/_doc/_search // 矩形搜索&#123; &quot;query&quot;: &#123; &quot;geo_bounding_box&quot;: &#123; &quot;pin&quot;: &#123; &quot;top_left&quot;: &#123;&quot;lat&quot;: 41.73,&quot;lon&quot;: -74.1&#125;, &quot;bottom_right&quot;: &#123;&quot;lat&quot;: 40.01,&quot;lon&quot;: -70.12&#125; &#125; &#125; &#125;&#125;GET /hotel_app/_doc/_search // 多边形搜索&#123; &quot;query&quot;: &#123; &quot;geo_polygon&quot;: &#123; &quot;pin&quot;: &#123; &quot;points&quot;: [ &#123;&quot;lat&quot;: 40.73,&quot;lon&quot;: -74.1&#125;, &#123;&quot;lat&quot;: 40.01,&quot;lon&quot;: -71.12&#125;, &#123;&quot;lat&quot;: 50.56,&quot;lon&quot;: -90.58&#125; ] &#125; &#125; &#125;&#125; Distance距离的单位,常用米m和千米km,建议使用 filter 来过滤 geo_point 数据,因为 geo_point 数据相关度评分计算比较耗时。使用query来搜索geo_point数据效率相对会慢一些。 12345678910111213141516171819GET /hotel_app/_doc/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;filter&quot;: &#123; &quot;geo_distance&quot;: &#123;&quot;distance&quot;: &quot;200km&quot;,&quot;pin&quot;: &#123;&quot;lat&quot;: 40,&quot;lon&quot;: -70&#125;&#125; &#125; &#125; &#125;&#125;GET hotel_app/_search&#123; &quot;query&quot;: &#123; &quot;geo_distance&quot;: &#123; &quot;distance&quot;: &quot;90km&quot;, &quot;pin&quot;: &#123;&quot;lat&quot;: 40.55,&quot;lon&quot;: -71.12&#125; &#125; &#125;&#125; 聚合统计某位置附近区域内的数据,unit是距离单位,常用单位有米m,千米km,英里mi,distance_type是统计算法：sloppy_arc默认算法、 arc最高精度 、 plane最高效率 。 12345678910111213141516171819GET /hotel_app/_doc/_search&#123; &quot;size&quot;: 0, &quot;aggs&quot;: &#123; &quot;agg_by_pin&quot;: &#123; &quot;geo_distance&quot;: &#123; &quot;distance_type&quot;: &quot;arc&quot;, &quot;field&quot;: &quot;pin&quot;, &quot;origin&quot;: &#123;&quot;lat&quot;: 40,&quot;lon&quot;: -70&#125;, &quot;unit&quot;: &quot;mi&quot;, &quot;ranges&quot;: [ // 聚合统计分别距离某位置80英里,300英里,1000英里范围内的数据数量 &#123;&quot;to&quot;: 80&#125;, &#123;&quot;from&quot;: 80,&quot;to&quot;: 300&#125;, &#123;&quot;from&quot;: 300,&quot;to&quot;: 1000&#125; ] &#125; &#125; &#125;&#125; ElasticSearch: 进一步学习Elasticsearch 官方学习文档：https://www.elastic.co/guide/en/elasticsearch/reference/current/index.htmlJava API:https://www.elastic.co/guide/en/elasticsearch/client/java-api/current/java-api.html","tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"http://example.com/tags/ElasticSearch/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"ElasticSearch","slug":"工具和中间件/搜索引擎技术/ElasticSearch","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/ElasticSearch/"}]},{"title":"ElasticSearch实战","date":"2022-01-02T03:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/ElasticSearch/ElasticSearch实战/","text":"引入pom依赖：12345&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch-rest-high-level-client&lt;/artifactId&gt; &lt;version&gt;7.6.1&lt;/version&gt;&lt;/dependency&gt; 使用Java API来操作ES集群初始化连接，基于 RestClient.builder 方法来构建 RestClientBuilder, 使用 RestHighLevelClient 去连接ES集群，用 HttpHost 来添加ES的节点。 123456789// 建立与ES的连接// 1. 使用RestHighLevelClient构建客户端连接。// 2. 基于RestClient.builder方法来构建RestClientBuilder// 3. 用HttpHost来添加ES的节点RestClientBuilder restClientBuilder = RestClient.builder( new HttpHost(&quot;192.168.21.130&quot;, 9200, &quot;http&quot;) , new HttpHost(&quot;192.168.21.131&quot;, 9200, &quot;http&quot;) , new HttpHost(&quot;192.168.21.132&quot;, 9200, &quot;http&quot;));RestHighLevelClient restHighLevelClient = new RestHighLevelClient(restClientBuilder); 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155public void add(JobDetail jobDetail) throws IOException &#123; // 构建IndexRequest对象，用来描述ES发起请求的数据 IndexRequest indexRequest = new IndexRequest(JOB_IDX); // 设置文档ID indexRequest.id(String.valueOf(jobDetail.getId())); // 使用FastJSON将实体类对象转换为JSON String json = JSONObject.toJSONString(jobDetail); // 使用IndexRequest.source方法设置文档数据，并设置请求的数据为JSON格式 indexRequest.source(json, XContentType.JSON); // 使用ES RestHighLevelClient调用index方法发起请求，将一个文档添加到索引中 restHighLevelClient.index(indexRequest, RequestOptions.DEFAULT);&#125;public JobDetail findById(long id) throws IOException &#123; GetRequest getRequest = new GetRequest(JOB_IDX, id + &quot;&quot;); // 构建GetRequest请求 // 使用RestHighLevelClient.get发送GetRequest请求，并获取到ES服务器的响应。 GetResponse getResponse = restHighLevelClient.get(getRequest, RequestOptions.DEFAULT); String json = getResponse.getSourceAsString();// 将ES响应的数据转换为JSON字符串 // 并使用FastJSON将JSON字符串转换为JobDetail类对象 JobDetail jobDetail = JSONObject.parseObject(json, JobDetail.class); jobDetail.setId(id);// 单独设置ID return jobDetail;&#125;public void update(JobDetail jobDetail) throws IOException &#123; // 判断对应ID的文档是否存在，构建GetRequest GetRequest getRequest = new GetRequest(JOB_IDX, jobDetail.getId() + &quot;&quot;); // 执行client的exists方法，发起请求，判断是否存在 boolean exists = restHighLevelClient.exists(getRequest, RequestOptions.DEFAULT); if(exists) &#123; // 构建UpdateRequest请求 UpdateRequest updateRequest = new UpdateRequest(JOB_IDX, jobDetail.getId() + &quot;&quot;); // 设置UpdateRequest的文档，并配置为JSON格式 updateRequest.doc(JSONObject.toJSONString(jobDetail), XContentType.JSON); // 执行client发起update请求 restHighLevelClient.update(updateRequest, RequestOptions.DEFAULT); &#125;&#125;public void deleteById(long id) throws IOException &#123; DeleteRequest deleteRequest = new DeleteRequest(JOB_IDX, id + &quot;&quot;);// 构建delete请求 restHighLevelClient.delete(deleteRequest, RequestOptions.DEFAULT);// 使用RestHighLevelClient执行delete请求&#125;public List&lt;JobDetail&gt; searchByKeywords(String keywords) throws IOException &#123; // 构建SearchRequest检索请求 专门用来进行全文检索、关键字检索的API SearchRequest searchRequest = new SearchRequest(JOB_IDX); // 创建一个SearchSourceBuilder专门用于构建查询条件 SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); // 使用QueryBuilders.multiMatchQuery构建一个查询条件（搜索title、jd），并配置到SearchSourceBuilder MultiMatchQueryBuilder multiMatchQueryBuilder = QueryBuilders.multiMatchQuery(keywords, &quot;title&quot;, &quot;jd&quot;); searchSourceBuilder.query(multiMatchQueryBuilder);// 将查询条件设置到查询请求构建器中 searchRequest.source(searchSourceBuilder);// 调用SearchRequest.source将查询条件设置到检索请求 // 执行RestHighLevelClient.search发起请求 SearchResponse searchResponse = restHighLevelClient.search(searchRequest, RequestOptions.DEFAULT); SearchHit[] hitArray = searchResponse.getHits().getHits(); ArrayList&lt;JobDetail&gt; jobDetailArrayList = new ArrayList&lt;&gt;(); for (SearchHit documentFields : hitArray) &#123;// 遍历结果 String json = documentFields.getSourceAsString();// 获取命中的结果 JobDetail jobDetail = JSONObject.parseObject(json, JobDetail.class);// 将JSON字符串转换为对象 jobDetail.setId(Long.parseLong(documentFields.getId()));// 使用SearchHit.getId设置文档ID jobDetailArrayList.add(jobDetail); &#125; return jobDetailArrayList;&#125;public Map&lt;String, Object&gt; searchByPage(String keywords, int pageNum, int pageSize) throws IOException &#123; // 构建SearchRequest检索请求 专门用来进行全文检索、关键字检索的API SearchRequest searchRequest = new SearchRequest(JOB_IDX); // 创建一个SearchSourceBuilder专门用于构建查询条件 SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); // 使用QueryBuilders.multiMatchQuery构建一个查询条件（搜索title、jd），并配置到SearchSourceBuilder MultiMatchQueryBuilder multiMatchQueryBuilder = QueryBuilders.multiMatchQuery(keywords, &quot;title&quot;, &quot;jd&quot;); searchSourceBuilder.query(multiMatchQueryBuilder); // 将查询条件设置到查询请求构建器中 searchSourceBuilder.size(pageSize);// 每页显示多少条 searchSourceBuilder.from((pageNum - 1) * pageSize);// 设置从第几条开始查询 searchRequest.source(searchSourceBuilder);// 调用SearchRequest.source将查询条件设置到检索请求 // 执行RestHighLevelClient.search发起请求 SearchResponse searchResponse = restHighLevelClient.search(searchRequest, RequestOptions.DEFAULT); SearchHit[] hitArray = searchResponse.getHits().getHits(); ArrayList&lt;JobDetail&gt; jobDetailArrayList = new ArrayList&lt;&gt;(); for (SearchHit documentFields : hitArray) &#123;// 遍历结果 String json = documentFields.getSourceAsString();// 获取命中的结果 JobDetail jobDetail = JSONObject.parseObject(json, JobDetail.class);// 将JSON字符串转换为对象 jobDetail.setId(Long.parseLong(documentFields.getId()));// 使用SearchHit.getId设置文档ID jobDetailArrayList.add(jobDetail); &#125; // 将结果封装到Map结构中（带有分页信息） long totalNum = searchResponse.getHits().getTotalHits().value; Map&lt;String, Object&gt; resultMap = new HashMap&lt;&gt;(); resultMap.put(&quot;total&quot;, totalNum); // total -&gt; 使用SearchHits.getTotalHits().value获取到所有的记录数 resultMap.put(&quot;content&quot;, jobDetailArrayList); content -&gt; 当前分页中的数据 return resultMap;&#125;public Map&lt;String, Object&gt; searchByScrollPage(String keywords, String scrollId, int pageSize) throws IOException &#123; SearchResponse searchResponse = null; if(scrollId == null) &#123; // 构建SearchRequest检索请求 专门用来进行全文检索、关键字检索的API SearchRequest searchRequest = new SearchRequest(JOB_IDX); // 创建一个SearchSourceBuilder专门用于构建查询条件 SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); // 使用QueryBuilders.multiMatchQuery构建一个查询条件（搜索title、jd），并配置到SearchSourceBuilder MultiMatchQueryBuilder multiMatchQueryBuilder = QueryBuilders.multiMatchQuery(keywords, &quot;title&quot;, &quot;jd&quot;); searchSourceBuilder.query(multiMatchQueryBuilder);// 将查询条件设置到查询请求构建器中 HighlightBuilder highlightBuilder = new HighlightBuilder(); // 设置高亮 highlightBuilder.field(&quot;title&quot;); highlightBuilder.field(&quot;jd&quot;); highlightBuilder.preTags(&quot;&lt;font color=&#x27;red&#x27;&gt;&quot;); highlightBuilder.postTags(&quot;&lt;/font&gt;&quot;); searchSourceBuilder.highlighter(highlightBuilder); // 给请求设置高亮 searchSourceBuilder.size(pageSize); // 每页显示多少条 searchRequest.source(searchSourceBuilder); // 调用SearchRequest.source将查询条件设置到检索请求 searchRequest.scroll(TimeValue.timeValueMinutes(5)); // 设置scroll查询 // 执行RestHighLevelClient.search发起请求 searchResponse = restHighLevelClient.search(searchRequest, RequestOptions.DEFAULT); &#125; else &#123; // 第二次查询的时候，直接通过scroll id查询数据 SearchScrollRequest searchScrollRequest = new SearchScrollRequest(scrollId); searchScrollRequest.scroll(TimeValue.timeValueMinutes(5)); // 使用RestHighLevelClient发送scroll请求 searchResponse = restHighLevelClient.scroll(searchScrollRequest, RequestOptions.DEFAULT); &#125; SearchHit[] hitArray = searchResponse.getHits().getHits(); ArrayList&lt;JobDetail&gt; jobDetailArrayList = new ArrayList&lt;&gt;(); for (SearchHit documentFields : hitArray) &#123; // 遍历结果，迭代ES响应的数据 String json = documentFields.getSourceAsString(); // 获取命中的结果 JobDetail jobDetail = JSONObject.parseObject(json, JobDetail.class); // 将JSON字符串转换为对象 jobDetail.setId(Long.parseLong(documentFields.getId())); // 使用SearchHit.getId设置文档ID jobDetailArrayList.add(jobDetail); // 设置高亮的一些文本到实体类中 封装了高亮 Map&lt;String, HighlightField&gt; highlightFieldMap = documentFields.getHighlightFields(); HighlightField titleHL = highlightFieldMap.get(&quot;title&quot;); HighlightField jdHL = highlightFieldMap.get(&quot;jd&quot;); if(titleHL != null) &#123; Text[] fragments = titleHL.getFragments(); // 获取指定字段的高亮片段 StringBuilder builder = new StringBuilder(); for(Text text : fragments) &#123; // 将这些高亮片段拼接成一个完整的高亮字段 builder.append(text); &#125; jobDetail.setTitle(builder.toString()); // 设置到实体类中 &#125; if(jdHL != null) &#123; Text[] fragments = jdHL.getFragments(); // 获取指定字段的高亮片段 StringBuilder builder = new StringBuilder(); for(Text text : fragments) &#123;// 将这些高亮片段拼接成一个完整的高亮字段 builder.append(text); &#125; jobDetail.setJd(builder.toString()); // 设置到实体类中 &#125; &#125; // 将结果封装到Map结构中，带有分页信息 long totalNum = searchResponse.getHits().getTotalHits().value; Map&lt;String, Object&gt; hashMap = new HashMap&lt;&gt;(); hashMap.put(&quot;scroll_id&quot;, searchResponse.getScrollId()); hashMap.put(&quot;content&quot;, jobDetailArrayList); // content -&gt; 当前分页中的数据 hashMap.put(&quot;total_num&quot;, totalNum); // total -&gt; 使用SearchHits.getTotalHits().value获取到所有的记录数 return hashMap;&#125;public void close() throws IOException &#123; restHighLevelClient.close();&#125; 京东商城搜索效果实现ES索引库表结构分析 1234567891011121314151617181920212223242526272829303132333435363738PUT product_db // 创建索引库&#123;&quot;mappings&quot;:&#123;&quot;properties&quot;:&#123;&quot;id&quot;:&#123;&quot;type&quot;:&quot;long&quot;&#125;,&quot;name&quot;:&#123;&quot;type&quot;:&quot;text&quot;,&quot;analyzer&quot;:&quot;ik_max_word&quot;&#125;,&quot;keywords&quot;:&#123;&quot;type&quot;:&quot;text&quot;,&quot;analyzer&quot;:&quot;ik_max_word&quot;&#125;,&quot;subTitle&quot;:&#123;&quot;type&quot;:&quot;text&quot;,&quot;analyzer&quot;:&quot;ik_max_word&quot;&#125;,&quot;salecount&quot;:&#123;&quot;type&quot;:&quot;long&quot;&#125;,&quot;putawayDate&quot;:&#123;&quot;type&quot;:&quot;date&quot;&#125;,&quot;price&quot;:&#123;&quot;type&quot;:&quot;double&quot;&#125;,&quot;promotionPrice&quot;:&#123;&quot;type&quot;:&quot;keyword&quot;&#125;,&quot;originalPrice&quot;:&#123;&quot;type&quot;:&quot;keyword&quot;&#125;,&quot;pic&quot;:&#123;&quot;type&quot;:&quot;keyword&quot;&#125;,&quot;sale&quot;:&#123;&quot;type&quot;:&quot;long&quot;&#125;,&quot;hasStock&quot;:&#123;&quot;type&quot;:&quot;boolean&quot;&#125;,&quot;brandId&quot;:&#123;&quot;type&quot;:&quot;long&quot;&#125;,&quot;brandName&quot;:&#123;&quot;type&quot;:&quot;keyword&quot;&#125;,&quot;brandImg&quot;:&#123;&quot;type&quot;:&quot;keyword&quot;&#125;,&quot;categoryId&quot;:&#123;&quot;type&quot;:&quot;long&quot;&#125;,&quot;categoryName&quot;:&#123;&quot;type&quot;:&quot;keyword&quot;&#125;,&quot;attrs&quot;:&#123;&quot;type&quot;:&quot;nested&quot;,&quot;properties&quot;:&#123;&quot;attrId&quot;:&#123;&quot;type&quot;:&quot;long&quot;&#125;,&quot;attrName&quot;:&#123;&quot;type&quot;:&quot;keyword&quot;&#125;,&quot;attrValue&quot;:&#123;&quot;type&quot;:&quot;keyword&quot;&#125;&#125;&#125;&#125;&#125;&#125;// 索引数据准备PUT /product_db/_doc/1&#123;&quot;id&quot;:&quot;26&quot;,&quot;name&quot;:&quot;小米 11 手机&quot;,&quot;keywords&quot;:&quot;小米手机&quot;,&quot;subTitle&quot;:&quot;AI智慧全面屏 6GB +64GB 亮黑色 全网通版 移动联通电信4G手机 双卡双待 双卡双待&quot;,&quot;price&quot;:&quot;3999&quot;,&quot;promotionPrice&quot;:&quot;2999&quot;,&quot;originalPrice&quot;:&quot;5999&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/xiaomi.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:999,&quot;putawayDate&quot;:&quot;2021-04-01&quot;,&quot;brandId&quot;:6,&quot;brandName&quot;:&quot;小米&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/1e34aef2a409119018a4c6258e39ecfb_222_222.png&quot;,&quot;categoryId&quot;:19,&quot;categoryName&quot;:&quot;手机通讯&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:1,&quot;attrName&quot;:&quot;cpu&quot;,&quot;attrValue&quot;:&quot;2核&quot;&#125;,&#123;&quot;attrId&quot;:2,&quot;attrName&quot;:&quot;颜色&quot;,&quot;attrValue&quot;:&quot;黑色&quot;&#125;]&#125;PUT /product_db/_doc/2&#123;&quot;id&quot;:&quot;27&quot;,&quot;name&quot;:&quot;小米 10 手机&quot;,&quot;keywords&quot;:&quot;小米手机&quot;,&quot;subTitle&quot;:&quot;AI智慧全面屏 4GB +64GB 亮白色 全网通版 移动联通电信4G手机 双卡双待 双卡双待&quot;,&quot;price&quot;:&quot;2999&quot;,&quot;promotionPrice&quot;:&quot;1999&quot;,&quot;originalPrice&quot;:&quot;3999&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/xiaomi.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:false,&quot;salecount&quot;:99,&quot;putawayDate&quot;:&quot;2021-04-02&quot;,&quot;brandId&quot;:6,&quot;brandName&quot;:&quot;小米&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/1e34aef2a409119018a4c6258e39ecfb_222_222.png&quot;,&quot;categoryId&quot;:19,&quot;categoryName&quot;:&quot;手机通讯&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:1,&quot;attrName&quot;:&quot;cpu&quot;,&quot;attrValue&quot;:&quot;4核&quot;&#125;,&#123;&quot;attrId&quot;:2,&quot;attrName&quot;:&quot;颜色&quot;,&quot;attrValue&quot;:&quot;白色&quot;&#125;]&#125;PUT /product_db/_doc/3&#123;&quot;id&quot;:&quot;28&quot;,&quot;name&quot;:&quot;小米 手机&quot;,&quot;keywords&quot;:&quot;小米手机&quot;,&quot;subTitle&quot;:&quot;AI智慧全面屏 4GB +64GB 亮蓝色 全网通版 移动联通电信4G手机 双卡双待 双卡双待&quot;,&quot;price&quot;:&quot;2999&quot;,&quot;promotionPrice&quot;:&quot;1999&quot;,&quot;originalPrice&quot;:&quot;3999&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/xiaomi.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:199,&quot;putawayDate&quot;:&quot;2021-04-03&quot;,&quot;brandId&quot;:6,&quot;brandName&quot;:&quot;小米&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/1e34aef2a409119018a4c6258e39ecfb_222_222.png&quot;,&quot;categoryId&quot;:19,&quot;categoryName&quot;:&quot;手机通讯&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:1,&quot;attrName&quot;:&quot;cpu&quot;,&quot;attrValue&quot;:&quot;2核&quot;&#125;,&#123;&quot;attrId&quot;:2,&quot;attrName&quot;:&quot;颜色&quot;,&quot;attrValue&quot;:&quot;蓝色&quot;&#125;]&#125;PUT /product_db/_doc/4&#123;&quot;id&quot;:&quot;29&quot;,&quot;name&quot;:&quot;Apple iPhone 8 Plus 64GB 金色特别版 移动联通电信4G手机&quot;,&quot;keywords&quot;:&quot;苹果手机&quot;,&quot;subTitle&quot;:&quot;苹果手机 Apple产品年中狂欢节，好物尽享，美在智慧！速来 &gt;&gt; 勾选[保障服务][原厂保2年]，获得AppleCare+全方位服务计划，原厂延保售后无忧。&quot;,&quot;price&quot;:&quot;5999&quot;,&quot;promotionPrice&quot;:&quot;4999&quot;,&quot;originalPrice&quot;:&quot;7999&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/5acc5248N6a5f81cd.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:1199,&quot;putawayDate&quot;:&quot;2021-04-04&quot;,&quot;brandId&quot;:51,&quot;brandName&quot;:&quot;苹果&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180607/timg.jpg&quot;,&quot;categoryId&quot;:19,&quot;categoryName&quot;:&quot;手机通讯&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:1,&quot;attrName&quot;:&quot;cpu&quot;,&quot;attrValue&quot;:&quot;4核&quot;&#125;,&#123;&quot;attrId&quot;:2,&quot;attrName&quot;:&quot;颜色&quot;,&quot;attrValue&quot;:&quot;金色&quot;&#125;]&#125;PUT /product_db/_doc/5&#123;&quot;id&quot;:&quot;30&quot;,&quot;name&quot;:&quot;HLA海澜之家简约动物印花短袖T恤&quot;,&quot;keywords&quot;:&quot;海澜之家衣服&quot;,&quot;subTitle&quot;:&quot;HLA海澜之家短袖T恤&quot;,&quot;price&quot;:&quot;199&quot;,&quot;promotionPrice&quot;:&quot;99&quot;,&quot;originalPrice&quot;:&quot;299&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/5ad83a4fN6ff67ecd.jpg!cc_350x449.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:19,&quot;putawayDate&quot;:&quot;2021-04-05&quot;,&quot;brandId&quot;:50,&quot;brandName&quot;:&quot;海澜之家&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/99d3279f1029d32b929343b09d3c72de_222_222.jpg&quot;,&quot;categoryId&quot;:8,&quot;categoryName&quot;:&quot;T恤&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:3,&quot;attrName&quot;:&quot;尺寸&quot;,&quot;attrValue&quot;:&quot;M&quot;&#125;,&#123;&quot;attrId&quot;:4,&quot;attrName&quot;:&quot;颜色&quot;,&quot;attrValue&quot;:&quot;黑色&quot;&#125;]&#125;PUT /product_db/_doc/6&#123;&quot;id&quot;:&quot;31&quot;,&quot;name&quot;:&quot;HLA海澜之家蓝灰花纹圆领针织布短袖T恤&quot;,&quot;keywords&quot;:&quot;海澜之家衣服&quot;,&quot;subTitle&quot;:&quot;HLA海澜之家短袖T恤&quot;,&quot;price&quot;:&quot;299&quot;,&quot;promotionPrice&quot;:&quot;199&quot;,&quot;originalPrice&quot;:&quot;299&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/5ac98b64N70acd82f.jpg!cc_350x449.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:399,&quot;putawayDate&quot;:&quot;2021-04-06&quot;,&quot;brandId&quot;:50,&quot;brandName&quot;:&quot;海澜之家&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/99d3279f1029d32b929343b09d3c72de_222_222.jpg&quot;,&quot;categoryId&quot;:8,&quot;categoryName&quot;:&quot;T恤&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:3,&quot;attrName&quot;:&quot;尺寸&quot;,&quot;attrValue&quot;:&quot;X&quot;&#125;,&#123;&quot;attrId&quot;:4,&quot;attrName&quot;:&quot;颜色&quot;,&quot;attrValue&quot;:&quot;蓝灰&quot;&#125;]&#125;PUT /product_db/_doc/7&#123;&quot;id&quot;:&quot;32&quot;,&quot;name&quot;:&quot;HLA海澜之家短袖T恤男基础款&quot;,&quot;keywords&quot;:&quot;海澜之家衣服&quot;,&quot;subTitle&quot;:&quot;HLA海澜之家短袖T恤&quot;,&quot;price&quot;:&quot;269&quot;,&quot;promotionPrice&quot;:&quot;169&quot;,&quot;originalPrice&quot;:&quot;399&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/5a51eb88Na4797877.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:399,&quot;putawayDate&quot;:&quot;2021-04-07&quot;,&quot;brandId&quot;:50,&quot;brandName&quot;:&quot;海澜之家&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/99d3279f1029d32b929343b09d3c72de_222_222.jpg&quot;,&quot;categoryId&quot;:8,&quot;categoryName&quot;:&quot;T恤&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:3,&quot;attrName&quot;:&quot;尺寸&quot;,&quot;attrValue&quot;:&quot;L&quot;&#125;,&#123;&quot;attrId&quot;:4,&quot;attrName&quot;:&quot;颜色&quot;,&quot;attrValue&quot;:&quot;蓝色&quot;&#125;]&#125;PUT /product_db/_doc/8&#123;&quot;id&quot;:&quot;33&quot;,&quot;name&quot;:&quot;小米（MI）小米电视4A &quot;,&quot;keywords&quot;:&quot;小米电视机家用电器&quot;,&quot;subTitle&quot;:&quot;小米（MI）小米电视4A 55英寸 L55M5-AZ/L55M5-AD 2GB+8GB HDR 4K超高清 人工智能网络液晶平板电视&quot;,&quot;price&quot;:&quot;2269&quot;,&quot;promotionPrice&quot;:&quot;2169&quot;,&quot;originalPrice&quot;:&quot;2399&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/5b02804dN66004d73.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:132,&quot;putawayDate&quot;:&quot;2021-04-09&quot;,&quot;brandId&quot;:6,&quot;brandName&quot;:&quot;小米&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/1e34aef2a409119018a4c6258e39ecfb_222_222.png&quot;,&quot;categoryId&quot;:35,&quot;categoryName&quot;:&quot;手机数码&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:5,&quot;attrName&quot;:&quot;屏幕尺寸&quot;,&quot;attrValue&quot;:&quot;52&quot;&#125;,&#123;&quot;attrId&quot;:6,&quot;attrName&quot;:&quot;机身颜色&quot;,&quot;attrValue&quot;:&quot;黑色&quot;&#125;]&#125;PUT /product_db/_doc/9&#123;&quot;id&quot;:&quot;34&quot;,&quot;name&quot;:&quot;小米（MI）小米电视4A 65英寸&quot;,&quot;keywords&quot;:&quot;小米电视机家用电器&quot;,&quot;subTitle&quot;:&quot;小米（MI）小米电视4A 65英寸 L55M5-AZ/L55M5-AD 2GB+8GB HDR 4K超高清 人工智能网络液晶平板电视&quot;,&quot;price&quot;:&quot;3269&quot;,&quot;promotionPrice&quot;:&quot;3169&quot;,&quot;originalPrice&quot;:&quot;3399&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/5b028530N51eee7d4.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:999,&quot;putawayDate&quot;:&quot;2021-04-10&quot;,&quot;brandId&quot;:6,&quot;brandName&quot;:&quot;小米&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/1e34aef2a409119018a4c6258e39ecfb_222_222.png&quot;,&quot;categoryId&quot;:35,&quot;categoryName&quot;:&quot;手机数码&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:5,&quot;attrName&quot;:&quot;屏幕尺寸&quot;,&quot;attrValue&quot;:&quot;65&quot;&#125;,&#123;&quot;attrId&quot;:6,&quot;attrName&quot;:&quot;机身颜色&quot;,&quot;attrValue&quot;:&quot;金色&quot;&#125;]&#125;PUT /product_db/_doc/10&#123;&quot;id&quot;:&quot;35&quot;,&quot;name&quot;:&quot;耐克NIKE 男子 休闲鞋 ROSHE RUN 运动鞋 511881-010黑色41码&quot;,&quot;keywords&quot;:&quot;耐克运动鞋 鞋子&quot;,&quot;subTitle&quot;:&quot;耐克NIKE 男子 休闲鞋 ROSHE RUN 运动鞋 511881-010黑色41码&quot;,&quot;price&quot;:&quot;569&quot;,&quot;promotionPrice&quot;:&quot;369&quot;,&quot;originalPrice&quot;:&quot;899&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/5b235bb9Nf606460b.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:399,&quot;putawayDate&quot;:&quot;2021-04-11&quot;,&quot;brandId&quot;:58,&quot;brandName&quot;:&quot;NIKE&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/timg (51).jpg&quot;,&quot;categoryId&quot;:29,&quot;categoryName&quot;:&quot;男鞋&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:7,&quot;attrName&quot;:&quot;尺码&quot;,&quot;attrValue&quot;:&quot;42&quot;&#125;,&#123;&quot;attrId&quot;:8,&quot;attrName&quot;:&quot;颜色&quot;,&quot;attrValue&quot;:&quot;黑色&quot;&#125;]&#125;PUT /product_db/_doc/11&#123;&quot;id&quot;:&quot;36&quot;,&quot;name&quot;:&quot;耐克NIKE 男子 气垫 休闲鞋 AIR MAX 90 ESSENTIAL 运动鞋 AJ1285-101白色41码&quot;,&quot;keywords&quot;:&quot;耐克运动鞋 鞋子&quot;,&quot;subTitle&quot;:&quot;AIR MAX 90 ESSENTIAL 运动鞋 AJ1285-101白色&quot;,&quot;price&quot;:&quot;769&quot;,&quot;promotionPrice&quot;:&quot;469&quot;,&quot;originalPrice&quot;:&quot;999&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/5b19403eN9f0b3cb8.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:499,&quot;putawayDate&quot;:&quot;2021-04-13&quot;,&quot;brandId&quot;:58,&quot;brandName&quot;:&quot;NIKE&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/timg (51).jpg&quot;,&quot;categoryId&quot;:29,&quot;categoryName&quot;:&quot;男鞋&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:7,&quot;attrName&quot;:&quot;尺码&quot;,&quot;attrValue&quot;:&quot;44&quot;&#125;,&#123;&quot;attrId&quot;:8,&quot;attrName&quot;:&quot;颜色&quot;,&quot;attrValue&quot;:&quot;白色&quot;&#125;]&#125;PUT /product_db/_doc/12&#123;&quot;id&quot;:&quot;37&quot;,&quot;name&quot;:&quot;(华为)HUAWEI MateBook X Pro 2019款 13.9英寸3K触控全面屏 轻薄笔记本&quot;,&quot;keywords&quot;:&quot;轻薄笔记本华为 笔记本电脑&quot;,&quot;subTitle&quot;:&quot;轻薄华为笔记本 电脑&quot;,&quot;price&quot;:&quot;4769&quot;,&quot;promotionPrice&quot;:&quot;4469&quot;,&quot;originalPrice&quot;:&quot;4999&quot;,&quot;pic&quot;:&quot;http://tuling-mall.oss-cn-shenzhen.aliyuncs.com/tulingmall/images/20200317/800_800_1555752016264mp.png&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:699,&quot;putawayDate&quot;:&quot;2021-04-14&quot;,&quot;brandId&quot;:3,&quot;brandName&quot;:&quot;华为&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/17f2dd9756d9d333bee8e60ce8c03e4c_222_222.jpg&quot;,&quot;categoryId&quot;:19,&quot;categoryName&quot;:&quot;手机通讯&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:9,&quot;attrName&quot;:&quot;容量&quot;,&quot;attrValue&quot;:&quot;16G&quot;&#125;,&#123;&quot;attrId&quot;:10,&quot;attrName&quot;:&quot;网络&quot;,&quot;attrValue&quot;:&quot;4G&quot;&#125;]&#125;PUT /product_db/_doc/13&#123;&quot;id&quot;:&quot;38&quot;,&quot;name&quot;:&quot;华为nova6se 手机 绮境森林 全网通（8G+128G)&quot;,&quot;keywords&quot;:&quot;轻薄笔记本华为 手机&quot;,&quot;subTitle&quot;:&quot;华为nova6se 手机&quot;,&quot;price&quot;:&quot;6769&quot;,&quot;promotionPrice&quot;:&quot;6469&quot;,&quot;originalPrice&quot;:&quot;6999&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180607/5ac1bf58Ndefaac16.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:899,&quot;putawayDate&quot;:&quot;2021-04-15&quot;,&quot;brandId&quot;:3,&quot;brandName&quot;:&quot;华为&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/17f2dd9756d9d333bee8e60ce8c03e4c_222_222.jpg&quot;,&quot;categoryId&quot;:19,&quot;categoryName&quot;:&quot;手机通讯&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:9,&quot;attrName&quot;:&quot;容量&quot;,&quot;attrValue&quot;:&quot;64G&quot;&#125;,&#123;&quot;attrId&quot;:10,&quot;attrName&quot;:&quot;网络&quot;,&quot;attrValue&quot;:&quot;5G&quot;&#125;]&#125;PUT /product_db/_doc/14&#123;&quot;id&quot;:&quot;39&quot;,&quot;name&quot;:&quot;iPhone7/6s/8钢化膜苹果8Plus全屏复盖抗蓝光防窥防偷看手机膜&quot;,&quot;keywords&quot;:&quot;手机膜&quot;,&quot;subTitle&quot;:&quot;iPhone7/6s/8钢化膜苹果8Plus全屏复盖抗蓝光防窥防偷看手机膜&quot;,&quot;price&quot;:&quot;29&quot;,&quot;promotionPrice&quot;:&quot;39&quot;,&quot;originalPrice&quot;:&quot;49&quot;,&quot;pic&quot;:&quot;http://tuling-mall.oss-cn-shenzhen.aliyuncs.com/tulingmall/images/20200311/6df99dab78bb2014.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:799,&quot;putawayDate&quot;:&quot;2021-04-16&quot;,&quot;brandId&quot;:51,&quot;brandName&quot;:&quot;苹果&quot;,&quot;brandImg&quot;:&quot;http://tuling-mall.oss-cn-shenzhen.aliyuncs.com/tulingmall/images/20200311/2b84746650fc122d67749a876c453619.png&quot;,&quot;categoryId&quot;:30,&quot;categoryName&quot;:&quot;手机配件&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:11,&quot;attrName&quot;:&quot;手机膜-材料&quot;,&quot;attrValue&quot;:&quot;钢化&quot;&#125;,&#123;&quot;attrId&quot;:12,&quot;attrName&quot;:&quot;手机膜-颜色&quot;,&quot;attrValue&quot;:&quot;白色&quot;&#125;]&#125;PUT /product_db/_doc/15&#123;&quot;id&quot;:&quot;40&quot;,&quot;name&quot;:&quot;七匹狼短袖T恤男纯棉舒适春夏修身运动休闲短袖三条装 圆领3条装&quot;,&quot;keywords&quot;:&quot;七匹狼服装 衣服&quot;,&quot;subTitle&quot;:&quot;七匹狼短袖T恤男纯棉舒适春夏修身运动休闲短袖三条装 圆领3条装&quot;,&quot;price&quot;:&quot;129&quot;,&quot;promotionPrice&quot;:&quot;139&quot;,&quot;originalPrice&quot;:&quot;149&quot;,&quot;pic&quot;:&quot;http://tuling-mall.oss-cn-shenzhen.aliyuncs.com/tulingmall/images/20200311/19e846e727dff337.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:199,&quot;putawayDate&quot;:&quot;2021-04-20&quot;,&quot;brandId&quot;:49,&quot;brandName&quot;:&quot;七匹狼&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/18d8bc3eb13533fab466d702a0d3fd1f40345bcd.jpg&quot;,&quot;categoryId&quot;:8,&quot;categoryName&quot;:&quot;T恤&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:3,&quot;attrName&quot;:&quot;尺寸&quot;,&quot;attrValue&quot;:&quot;M&quot;&#125;,&#123;&quot;attrId&quot;:4,&quot;attrName&quot;:&quot;颜色&quot;,&quot;attrValue&quot;:&quot;白色&quot;&#125;]&#125;PUT /product_db/_doc/16&#123;&quot;id&quot;:&quot;41&quot;,&quot;name&quot;:&quot;华为P40 Pro手机&quot;,&quot;keywords&quot;:&quot;华为手机&quot;,&quot;subTitle&quot;:&quot;华为P40 Pro手机&quot;,&quot;price&quot;:&quot;2129&quot;,&quot;promotionPrice&quot;:&quot;2139&quot;,&quot;originalPrice&quot;:&quot;2149&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180607/5ac1bf58Ndefaac16.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:199,&quot;putawayDate&quot;:&quot;2021-05-03&quot;,&quot;brandId&quot;:3,&quot;brandName&quot;:&quot;华为&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/17f2dd9756d9d333bee8e60ce8c03e4c_222_222.jpg&quot;,&quot;categoryId&quot;:19,&quot;categoryName&quot;:&quot;手机通讯&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:9,&quot;attrName&quot;:&quot;容量&quot;,&quot;attrValue&quot;:&quot;128G&quot;&#125;,&#123;&quot;attrId&quot;:10,&quot;attrName&quot;:&quot;网络&quot;,&quot;attrValue&quot;:&quot;5G&quot;&#125;]&#125;PUT /product_db/_doc/17&#123;&quot;id&quot;:&quot;42&quot;,&quot;name&quot;:&quot;朵唯智能手机 4G全网通 老人学生双卡双待手机&quot;,&quot;keywords&quot;:&quot;朵唯手机&quot;,&quot;subTitle&quot;:&quot;朵唯手机后置双摄，国产虎贲芯片！优化散热结构！浅薄机身！朵唯4月特惠！&quot;,&quot;price&quot;:&quot;3129&quot;,&quot;promotionPrice&quot;:&quot;3139&quot;,&quot;originalPrice&quot;:&quot;3249&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/xiaomi.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:1199,&quot;putawayDate&quot;:&quot;2021-06-01&quot;,&quot;brandId&quot;:59,&quot;brandName&quot;:&quot;朵唯&quot;,&quot;brandImg&quot;:&quot;http://tuling-mall.oss-cn-shenzhen.aliyuncs.com/tulingmall/images/20200311/2b84746650fc122d67749a876c453619.png&quot;,&quot;categoryId&quot;:19,&quot;categoryName&quot;:&quot;手机通讯&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:9,&quot;attrName&quot;:&quot;容量&quot;,&quot;attrValue&quot;:&quot;32G&quot;&#125;,&#123;&quot;attrId&quot;:10,&quot;attrName&quot;:&quot;网络&quot;,&quot;attrValue&quot;:&quot;4G&quot;&#125;]&#125; 检索DSL语句构建 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647POST /product_db/_doc/_search&#123; &quot;from&quot;: 0, &quot;size&quot;: 8, &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [&#123;&quot;match&quot;: &#123;&quot;name&quot;: &#123;&quot;query&quot;: &quot;手机&quot;&#125;&#125;&#125;], &quot;filter&quot;: [ &#123;&quot;term&quot;: &#123;&quot;hasStock&quot;: &#123;&quot;value&quot;: true&#125;&#125;&#125;, &#123;&quot;range&quot;: &#123;&quot;price&quot;: &#123;&quot;from&quot;: &quot;1&quot;,&quot;to&quot;: &quot;5000&quot;&#125;&#125;&#125; ] &#125; &#125;, &quot;sort&quot;: [&#123;&quot;salecount&quot;: &#123;&quot;order&quot;: &quot;asc&quot;&#125;&#125;], &quot;aggregations&quot;: &#123; &quot;brand_agg&quot;: &#123; &quot;terms&quot;: &#123;&quot;field&quot;: &quot;brandId&quot;,&quot;size&quot;: 50&#125;, &quot;aggregations&quot;: &#123; &quot;brand_name_agg&quot;: &#123;&quot;terms&quot;: &#123;&quot;field&quot;: &quot;brandName&quot;&#125;&#125;, &quot;brand_img_agg&quot;: &#123;&quot;terms&quot;: &#123;&quot;field&quot;: &quot;brandImg&quot;&#125;&#125; &#125; &#125;, &quot;category_agg&quot;: &#123; &quot;terms&quot;: &#123;&quot;field&quot;: &quot;categoryId&quot;,&quot;size&quot;: 50,&quot;min_doc_count&quot;: 1&#125;, &quot;aggregations&quot;: &#123; &quot;category_name_agg&quot;: &#123;&quot;terms&quot;: &#123;&quot;field&quot;: &quot;categoryName&quot;&#125;&#125; &#125; &#125;, &quot;attr_agg&quot;: &#123; &quot;nested&quot;: &#123;&quot;path&quot;: &quot;attrs&quot;&#125;, &quot;aggregations&quot;: &#123; &quot;attr_id_agg&quot;: &#123; &quot;terms&quot;: &#123;&quot;field&quot;: &quot;attrs.attrId&quot;&#125;, &quot;aggregations&quot;: &#123; &quot;attr_name_agg&quot;: &#123;&quot;terms&quot;: &#123;&quot;field&quot;: &quot;attrs.attrName&quot;&#125;&#125;, &quot;attr_value_agg&quot;: &#123;&quot;terms&quot;: &#123;&quot;field&quot;: &quot;attrs.attrValue&quot;&#125;&#125; &#125; &#125; &#125; &#125; &#125;, &quot;highlight&quot;: &#123; &quot;pre_tags&quot;: [&quot;&lt;b style=&#x27;color:red&#x27;&gt;&quot;], &quot;post_tags&quot;: [&quot;&lt;/b&gt;&quot;], &quot;fields&quot;: &#123;&quot;name&quot;: &#123;&#125;&#125; &#125;&#125; Java代码实现 1234567@ResponseBody@RequestMapping(value = &quot;/searchList&quot;)public CommonResult&lt;ESResponseResult&gt; listPage(ESRequestParam param, HttpServletRequest request) &#123; // 根据传递来的页面的查询参数，去es中检索商品 ESResponseResult searchResult = tulingMallSearchService.search(param); return CommonResult.success(searchResult);&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221@Overridepublic ESResponseResult search(ESRequestParam param) &#123; try &#123; // 构建检索对象-封装请求相关参数信息 SearchRequest searchRequest = startBuildRequestParam(param); // 进行检索操作 SearchResponse response = client.search(searchRequest, RequestOptions.DEFAULT); // 分析响应数据，封装成指定的格式 ESResponseResult responseResult = startBuildResponseResult(response, param); return responseResult; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null;&#125;/** * 封装请求参数信息，关键字查询、根据属性、分类、品牌、价格区间、是否有库存等进行过滤、分页、高亮、以及聚合统计品牌分类属性 */private SearchRequest startBuildRequestParam(ESRequestParam param) &#123; SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); // 关键字查询、根据属性、分类、品牌、价格区间、是否有库存等进行过滤、分页、高亮、以及聚合统计品牌分类属性 BoolQueryBuilder boolQueryBuilder = new BoolQueryBuilder(); if (!StringUtils.isEmpty(param.getKeyword())) &#123; //单字段查询 boolQueryBuilder.must(QueryBuilders.matchQuery(&quot;name&quot;, param.getKeyword())); //多字段查询 boolQueryBuilder.must(QueryBuilders.multiMatchQuery(param.getKeyword(),&quot;name&quot;,&quot;keywords&quot;,&quot;subTitle&quot;)); &#125; // 根据类目ID进行过滤 if (null != param.getCategoryId()) &#123; boolQueryBuilder.filter(QueryBuilders.termQuery(&quot;categoryId&quot;, param.getCategoryId())); &#125; // 根据品牌ID进行过滤 if (null != param.getBrandId() &amp;&amp; param.getBrandId().size() &gt; 0) &#123; boolQueryBuilder.filter(QueryBuilders.termsQuery(&quot;brandId&quot;, param.getBrandId())); &#125; // 根据属性进行相关过滤 if (param.getAttrs() != null &amp;&amp; param.getAttrs().size() &gt; 0) &#123; param.getAttrs().forEach(item -&gt; &#123; //attrs=1_白色&amp;2_4核 BoolQueryBuilder boolQuery = QueryBuilders.boolQuery(); //attrs=1_64G String[] s = item.split(&quot;_&quot;); String attrId = s[0]; String[] attrValues = s[1].split(&quot;:&quot;);//这个属性检索用的值 boolQuery.must(QueryBuilders.termQuery(&quot;attrs.attrId&quot;, attrId)); boolQuery.must(QueryBuilders.termsQuery(&quot;attrs.attrValue&quot;, attrValues)); NestedQueryBuilder nestedQueryBuilder = QueryBuilders.nestedQuery(&quot;attrs&quot;, boolQuery, ScoreMode.None); boolQueryBuilder.filter(nestedQueryBuilder); &#125;); &#125; // 是否有库存 if (null != param.getHasStock()) &#123; boolQueryBuilder.filter(QueryBuilders.termQuery(&quot;hasStock&quot;, param.getHasStock() == 1)); &#125; // 根据价格过滤 if (!StringUtils.isEmpty(param.getPrice())) &#123; // 价格的输入形式为：10-100（起始价格和最终价格）或-100（不指定起始价格）或10-（不限制最终价格） RangeQueryBuilder rangeQueryBuilder = QueryBuilders.rangeQuery(&quot;price&quot;); String[] price = param.getPrice().split(&quot;_&quot;); if (price.length == 2) &#123; rangeQueryBuilder.gte(price[0]).lte(price[1]); &#125; else if (price.length == 1) &#123; if (param.getPrice().startsWith(&quot;_&quot;)) &#123; rangeQueryBuilder.lte(price[1]); &#125; if (param.getPrice().endsWith(&quot;_&quot;)) &#123; rangeQueryBuilder.gte(price[0]); &#125; &#125; boolQueryBuilder.filter(rangeQueryBuilder); &#125; // 封装所有查询条件 searchSourceBuilder.query(boolQueryBuilder); //实现排序、高亮、分页操作，排序，页面传入的参数值形式 sort=price_asc/desc if (!StringUtils.isEmpty(param.getSort())) &#123; String sort = param.getSort(); String[] sortFileds = sort.split(&quot;_&quot;); System.out.println(&quot;sortFileds:&quot;+sortFileds.length); if(!StringUtils.isEmpty(sortFileds[0]))&#123; SortOrder sortOrder = &quot;asc&quot;.equalsIgnoreCase(sortFileds[1]) ? SortOrder.ASC : SortOrder.DESC; searchSourceBuilder.sort(sortFileds[0], sortOrder); &#125; &#125; // 分页查询 searchSourceBuilder.from((param.getPageNum() - 1) * SearchConstant.PAGE_SIZE); searchSourceBuilder.size(SearchConstant.PAGE_SIZE); // 高亮显示 if (!StringUtils.isEmpty(param.getKeyword())) &#123; HighlightBuilder highlightBuilder = new HighlightBuilder(); highlightBuilder.field(&quot;name&quot;); highlightBuilder.preTags(&quot;&lt;b style=&#x27;color:red&#x27;&gt;&quot;); highlightBuilder.postTags(&quot;&lt;/b&gt;&quot;); searchSourceBuilder.highlighter(highlightBuilder); &#125; // 对品牌、分类信息、属性信息进行聚合分析，按照品牌进行聚合 TermsAggregationBuilder brand_agg = AggregationBuilders.terms(&quot;brand_agg&quot;); brand_agg.field(&quot;brandId&quot;).size(50); // 品牌的子聚合-品牌名聚合 brand_agg.subAggregation(AggregationBuilders.terms(&quot;brand_name_agg&quot;).field(&quot;brandName&quot;).size(1)); // 品牌的子聚合-品牌图片聚合 brand_agg.subAggregation(AggregationBuilders.terms(&quot;brand_img_agg&quot;).field(&quot;brandImg&quot;).size(1)); searchSourceBuilder.aggregation(brand_agg); // 按照分类信息进行聚合 TermsAggregationBuilder category_agg = AggregationBuilders.terms(&quot;category_agg&quot;); category_agg.field(&quot;categoryId&quot;).size(50); category_agg.subAggregation(AggregationBuilders.terms(&quot;category_name_agg&quot;).field(&quot;categoryName&quot;).size(1)); searchSourceBuilder.aggregation(category_agg); // 按照属性信息进行聚合 NestedAggregationBuilder attr_agg = AggregationBuilders.nested(&quot;attr_agg&quot;, &quot;attrs&quot;); // 按照属性ID进行聚合 TermsAggregationBuilder attr_id_agg = AggregationBuilders.terms(&quot;attr_id_agg&quot;).field(&quot;attrs.attrId&quot;); attr_agg.subAggregation(attr_id_agg); // 在每个属性ID下，按照属性名进行聚合 attr_id_agg.subAggregation(AggregationBuilders.terms(&quot;attr_name_agg&quot;).field(&quot;attrs.attrName&quot;).size(1)); // 在每个属性ID下，按照属性值进行聚合 attr_id_agg.subAggregation(AggregationBuilders.terms(&quot;attr_value_agg&quot;).field(&quot;attrs.attrValue&quot;).size(50)); searchSourceBuilder.aggregation(attr_agg); System.out.println(&quot;构建的DSL语句 &#123;&#125;:&quot;+ searchSourceBuilder.toString()); SearchRequest searchRequest = new SearchRequest(new String[]&#123;SearchConstant.INDEX_NAME&#125;, searchSourceBuilder); return searchRequest;&#125;/** * 封装查询到的结果信息，关键字查询、根据属性、分类、品牌、价格区间、是否有库存等进行过滤、分页、高亮、以及聚合统计品牌分类属性 */private ESResponseResult startBuildResponseResult(SearchResponse response, ESRequestParam param) &#123; ESResponseResult result = new ESResponseResult(); // 获取查询到的商品信息 SearchHits hits = response.getHits(); List&lt;EsProduct&gt; esModels = new ArrayList&lt;&gt;(); // 遍历所有商品信息 if (hits.getHits() != null &amp;&amp; hits.getHits().length &gt; 0) &#123; for (SearchHit hit : hits.getHits()) &#123; String sourceAsString = hit.getSourceAsString(); EsProduct esModel = JSON.parseObject(sourceAsString, EsProduct.class); // 判断是否按关键字检索，若是就显示高亮，否则不显示 if (!StringUtils.isEmpty(param.getKeyword())) &#123; // 拿到高亮信息显示标题 HighlightField name = hit.getHighlightFields().get(&quot;name&quot;); // 判断name中是否含有查询的关键字(因为是多字段查询，因此可能不包含指定的关键字，假设不包含则显示原始name字段的信息) String nameValue = name!=null ? name.getFragments()[0].string() : esModel.getName(); esModel.setName(nameValue); &#125; esModels.add(esModel); &#125; &#125; result.setProducts(esModels); // 当前商品涉及到的所有品牌信息，小米手机和小米电脑都属于小米品牌，过滤重复品牌信息 Set&lt;ESResponseResult.BrandVo&gt; brandVos = new LinkedHashSet&lt;&gt;(); // 获取到品牌的聚合 ParsedLongTerms brandAgg = response.getAggregations().get(&quot;brand_agg&quot;); for (Terms.Bucket bucket : brandAgg.getBuckets()) &#123; ESResponseResult.BrandVo brandVo = new ESResponseResult.BrandVo(); // 获取品牌的id long brandId = bucket.getKeyAsNumber().longValue(); brandVo.setBrandId(brandId); // 获取品牌的名字 ParsedStringTerms brandNameAgg = bucket.getAggregations().get(&quot;brand_name_agg&quot;); String brandName = brandNameAgg.getBuckets().get(0).getKeyAsString(); brandVo.setBrandName(brandName); // 获取品牌的LOGO ParsedStringTerms brandImgAgg = bucket.getAggregations().get(&quot;brand_img_agg&quot;); String brandImg = brandImgAgg.getBuckets().get(0).getKeyAsString(); brandVo.setBrandImg(brandImg); System.out.println(&quot;brandId:&quot;+brandId+&quot;brandName:&quot;+brandName+&quot;brandImg&quot;); brandVos.add(brandVo); &#125; System.out.println(&quot;brandVos.size:&quot;+brandVos.size()); result.setBrands(brandVos); // 当前商品相关的所有类目信息，获取到分类的聚合 List&lt;ESResponseResult.categoryVo&gt; categoryVos = new ArrayList&lt;&gt;(); ParsedLongTerms categoryAgg = response.getAggregations().get(&quot;category_agg&quot;); for (Terms.Bucket bucket : categoryAgg.getBuckets()) &#123; ESResponseResult.categoryVo categoryVo = new ESResponseResult.categoryVo(); // 获取分类id String keyAsString = bucket.getKeyAsString(); categoryVo.setCategoryId(Long.parseLong(keyAsString)); // 获取分类名 ParsedStringTerms categoryNameAgg = bucket.getAggregations().get(&quot;category_name_agg&quot;); String categoryName = categoryNameAgg.getBuckets().get(0).getKeyAsString(); categoryVo.setCategoryName(categoryName); categoryVos.add(categoryVo); &#125; result.setCategorys(categoryVos); // 获取商品相关的所有属性信息 List&lt;ESResponseResult.AttrVo&gt; attrVos = new ArrayList&lt;&gt;(); // 获取属性信息的聚合 ParsedNested attrsAgg = response.getAggregations().get(&quot;attr_agg&quot;); ParsedLongTerms attrIdAgg = attrsAgg.getAggregations().get(&quot;attr_id_agg&quot;); for (Terms.Bucket bucket : attrIdAgg.getBuckets()) &#123; ESResponseResult.AttrVo attrVo = new ESResponseResult.AttrVo(); // 获取属性ID值 long attrId = bucket.getKeyAsNumber().longValue(); attrVo.setAttrId(attrId); // 获取属性的名字 ParsedStringTerms attrNameAgg = bucket.getAggregations().get(&quot;attr_name_agg&quot;); String attrName = attrNameAgg.getBuckets().get(0).getKeyAsString(); attrVo.setAttrName(attrName); // 获取属性的值 ParsedStringTerms attrValueAgg = bucket.getAggregations().get(&quot;attr_value_agg&quot;); List&lt;String&gt; attrValues = attrValueAgg.getBuckets().stream().map(item -&gt; item.getKeyAsString()).collect(Collectors.toList()); attrVo.setAttrValue(attrValues); attrVos.add(attrVo); &#125; result.setAttrs(attrVos); // 进行分页操作 result.setPageNum(param.getPageNum()); // 获取总记录数 long total = hits.getTotalHits().value; result.setTotal(total); // 计算总页码 int totalPages = (int) total % SearchConstant.PAGE_SIZE == 0 ? (int) total / SearchConstant.PAGE_SIZE : ((int) total / SearchConstant.PAGE_SIZE + 1); result.setTotalPages(totalPages); List&lt;Integer&gt; pageNavs = new ArrayList&lt;&gt;(); for (int i = 1; i &lt;= totalPages; i++) &#123; pageNavs.add(i); &#125; result.setPageNavs(pageNavs); return result;&#125;","tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"http://example.com/tags/ElasticSearch/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"ElasticSearch","slug":"工具和中间件/搜索引擎技术/ElasticSearch","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/ElasticSearch/"}]},{"title":"ElasticSearch基础","date":"2022-01-02T02:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/ElasticSearch/ElasticSearch基础/","text":"Elasticsearch是什么？ Elasticsearch 是用 Java开发 的当前 最流行 的 开源 的企业级搜索引擎,能够达到 实时搜索, 稳定, 可靠, 快速,安装使用方便。 和Solr一样的,Elasticsearch 是基于 Lucene 进行了封装, 提供了更为便利的访问和调用, Lucene可被认为是迄今为止最先进、性能最好、功能最全的搜索引擎框架。 ES与Solr对比：单纯对已有数据进行搜索时 Solr更快,当实时建立索引时Solr会产生 IO阻塞,查询性能较差,该情况下 Elasticsearch 具有明显优势。 Solr利用Zookeeper进行分布式管理,而 Elasticsearch自带分布式协调管理功能 Solr支持更多格式数据,如JSON、XML、CSV,而 Elasticsearch仅支持JSON文件格式 Solr在传统搜索应用中表现好于Elasticsearch,但在处理实时搜索应用时效率明显低于Elasticsearch Solr是传统搜索应用的有力解决方案,但Elasticsearch更适用于新兴实时搜索应用。 ES与关系型数据库: 关系型数据库 Database数据库 Table表 ROW行 Column列 Elasticsearch Index索引库 Type类型 Document文档 Field字段 ES核心概念: 索引index:一个索引就是一个拥有几分相似特征的文档集合,相当于关系型数据库中的database,一个索引由一个名字来标识, 必须全部是小写字母,且当要对对应于该索引中的文档进行索引搜索、更新和删除时,都要使用该名字。 Mapping映射:ElasticSearch中的Mapping映射用来定义一个文档,Mapping是处理数据的方式和规则方面做一些限制,如某个字段的数据类型、默认值、分词器、是否被索引等,这都是映射里面可设置的。 Field字段:相当于是数据表的字段或列。 Type字段类型：每个字段都应该有一个对应的类型,如 Text、Keyword、Byte 等。 Document文档：一个文档是一个可被索引的基础信息单元,类似一条记录, 文档以JSON格式来表示。 Cluster集群：一个集群由一个或多个节点组织在一起, 共同持有整个数据,并一起提供索引和搜索功能 Node节点：一个节点即集群中一个服务器,作为集群的一部分,它存储数据,参与集群的索引和搜索功能,一个节点可通过配置集群名称的方式来加入一个指定的集群。默认每个节点都会被安排加入到一个叫做 elasticsearch的集群中。一个集群中可拥有任意多个节点,且若当前网络中没有运行任何Elasticsearch节点,这时启动一个节点,会默认创建并加入一个叫做 elasticsearch 的集群。 分片：一个索引可存储超出单个结点硬件限制的大量数据,如一个具有10亿文档的索引占据1TB磁盘空间,而任一节点都没有这样大的磁盘空间,或者单个节点处理搜索请求,响应太慢,为了解决这个问题,Elasticsearch提供了将索引划分成多份的能力,每一份就是一个分片。当创建索引时可指定分片数量, 每个分片本身也是一个功能完善且独立的索引,该分片可被放置到集群中任何节点上, 分片允许水平分割扩展内容容量,允许在分片之上进行分布式并行操作,进而提高性能和吞吐量,每个分片怎样分布, 文档怎样聚合回搜索请求,完全由Elasticsearch管理,对于用户透明 副本：在一个网络环境中,失败随时都可能发生,在某个分片或节点处于离线状态,或由于任何原因消失,该情况下有一个故障转移机制是非常有用且强烈推荐。为此 Elasticsearch允许创建分片的一份或多份拷贝,这些拷贝叫做副本分片或直接叫副本。扩展搜索量和吞吐量,搜索可在所有的副本上并行运行, 每个索引可被分成多个分片, 一个索引有零个或者多个副本, 一旦设置了副本,每个索引就有了主分片和副本分片, 分片和副本数量可在索引创建时指定,在索引创建后, 可在任何时候动态地改变副本数量,但不能改变分片数量。 ES安装注： ES不能使用root用户来启动,必须使用普通用户来安装启动。 12345678910groupadd elasticsearch # 创建elasticsearch用户组useradd eleven # 创建eleven用户passwd eleven # 给eleven用户设置密码为elevenusermod -G elasticsearch eleven # 将用户eleven添加到elasticsearch用户组mkdir -p /usr/local/es # 创建es文件夹chown -R eleven /usr/local/es/elasticsearch-7.6.1 # 修改owner为eleven用户visudo # 使用root用户执行visudo命令然后为es用户添加权限eleven ALL=(ALL) ALL # 在root ALL=(ALL) ALL 一行下面添加eleven用户 修改elasticsearch.yml,可通过修改jvm.options配置文件调整JVM参数: 123456789101112cluster.name: eleven-es # 集群名称node.name: node1 # 节点名称path.data: /usr/local/es/elasticsearch-7.6.1/data # 数据目录path.logs: /usr/local/es/elasticsearch-7.6.1/log # 日志目录network.host: 0.0.0.0http.port: 9200discovery.seed_hosts: [&quot;IP1&quot;, &quot;IP2&quot;, &quot;IP3&quot;]cluster.initial_master_nodes: [&quot;节点1名称&quot;, &quot;节点2名称&quot;, &quot;节点3名称&quot;]bootstrap.system_call_filter: falsebootstrap.memory_lock: falsehttp.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot; ES需要大量创建索引文件,需要大量打开系统文件,所以需要解除linux系统当中打开文件最大数目限制,不然ES启动会抛错：max file descriptors [4096] for elasticsearch process likely too low, increase to at least [65536] 12345sudo vim /etc/security/limits.conf* soft nofile 65536* hard nofile 131072* soft nproc 2048* hard nproc 4096 若出现max number of threads [1024] for user [es] likely too low, increase to at least [4096] 错误信息,是由于普通用户启动线程数限制最大可创建线程数太小,无法创建本地线程问题。 安装IK分词器使用ElasticSearch来进行中文分词,需要单独给Elasticsearch安装IK分词器插件, 123mkdir -p /usr/local/es/elasticsearch-7.6.1/plugins/ikcd /usr/local/es/elasticsearch-7.6.1/plugins/ikunzip elasticsearch-analysis-ik-7.6.1.zip ES的默认分词设置是 standard单字拆分,可使用 IK分词器 的 ik_smart 和 ik_max_word 分词方式, ik_smart 会做 最粗粒度拆分, ik_max_word会将文本做最细粒度拆分。修改默认分词方法,修改 eleven_index索引的默认分词为 ik_max_word 1234567891011121314151617181920212223PUT /school_index&#123; &quot;settings&quot;: &#123; &quot;index&quot;: &#123; &quot;analysis.analyzer.default.type&quot;: &quot;ik_max_word&quot; &#125; &#125;&#125;POST _analyze&#123; &quot;analyzer&quot;: &quot;standard&quot;, &quot;text&quot;: &quot;中华人民共和国&quot;&#125;POST _analyze&#123; &quot;analyzer&quot;: &quot;ik_smart&quot;, &quot;text&quot;: &quot;中华人民共和国&quot;&#125;POST _analyze&#123; &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;text&quot;: &quot;中华人民共和国&quot;&#125; ES基础ES是面向文档Document的, 使用JSON作为文档序列化格式,这其可存储整个对象或文档Document,不仅仅是存储,还会索引index每个文档内容使之可被搜索。ES中可对文档而非成行成列的数据进行索引、搜索、排序、过滤。 条件查询：GET /索引名称/类型/_search?q=字段1:字段值,字段2:字段值,条件之间是通过逗号分隔多个条件,如分页、排序、输出指定字段等通过 &amp;符号分隔 123456789101112131415161718192021222324252627GET _cat/nodes?v // 查看集群节点状态GET _cat/health?v // 查看集群健康状态GET /es_db // 查询索引：GET /索引名称PUT /es_db // 创建索引：PUT /索引名称DELETE /es_db // 删除索引：DELETE /索引名称PUT /es_db/_doc/1 // 添加文档：PUT /索引名称/类型/id&#123; &quot;name&quot;: &quot;张三&quot;, &quot;sex&quot;: 1, &quot;age&quot;: 25, &quot;address&quot;: &quot;广州天河公园&quot;, &quot;remark&quot;: &quot;java developer&quot;&#125;GET /es_db/_doc/1 // 查询文档：GET /索引名称/类型/idDELETE /es_db/_doc/1 // 删除文档：DELETE /索引名称/类型/idGET /es_db/_doc/_search // 查询当前类型中的所有文档：GET /索引名称/类型/_searchGET /es_db/_doc/_search?q=age:28 // 条件查询：GET /索引名称/类型/_search?q=*:***GET /es_db/_doc/_search?q=age[25 TO 26] // 范围查询：GET /索引名称/类型/_search?q=***[** TO **]GET /es_db/_doc/_mget // 根据多个ID进行批量查询：GET /索引名称/类型/_mget&#123;&quot;ids&quot;:[&quot;1&quot;,&quot;2&quot;]&#125;GET /es_db/_doc/_search?q=age:&lt;=28 // 查询小于等于：GET /索引名称/类型/_search?q=age:&lt;=**GET /es_db/_doc/_search?q=age:&gt;=28 // 查询大于等于：GET /索引名称/类型/_search?q=age:&gt;=**GET /es_db/_doc/_search?q=age[25 TO 26]&amp;from=0&amp;size=1 // 分页查询：from=*&amp;size=*GET /es_db/_doc/_search?_source=name,age // 对查询结果只输出某些字段：_search?_source=字段,字段GET /es_db/_doc/_search?q=age[25 TO 26],sex:0 // 多条件查询GET /es_db/_doc/_search?sort=age:desc // 对查询结果排序sort=字段:desc/asc ES是基于Restful API和所有客户端交互都是使用JSON格式数据,其他所有程序语言都可使用RESTful API,通过9200端口的与ES进行通信,GET查询、PUT添加、POST修改、DELETE删除, POST和PUT都能起到创建&#x2F;更新的作用： PUT需要对一个具体的资源进行操作,也就是要确定id才能进行更新&#x2F;创建,而 POST可针对整个资源集合进行操作,若不写id则由ES生成一个唯一id进行创建新文档,过填了id则针对该id文档进行创建&#x2F;更新 PUT会将JSON数据都进行替换,POST只会更新相同字段的值 PUT与DELETE都是幂等性操作,不论操作多少次结果都一样 文档批量操作通过 _mget 的API来实现 批量操作多个文档,可通过 _id 批量获取 不同index和type的数据,若查询的是同一个文档可将index和type放到URL上。且可 通过_source指定查询字段。 1234567891011121314151617181920212223242526GET _mget&#123; &quot;docs&quot;: [ &#123; &quot;_index&quot;: &quot;es_db_1&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: 1, &#125;, &#123; &quot;_index&quot;: &quot;es_db&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: 2 &#125; ]&#125;GET /es_db/_doc/_mget?_source=age,name&#123; &quot;docs&quot;: [ &#123; &quot;_id&quot;: 1 &#125;, &#123; &quot;_id&quot;: 2 &#125; ]&#125; 批量 对文档进行 写操作 是通过 _bulk 的API来实现的,通过 _bulk 写操作文档,一般至少有两行参数,第一行参数为指定 操作的类型 及 操作的对象 如index、type、id,第二行参数为 操作的数据. actionName 表示 操作类型, 主要有 create、index、delete、update 。 1234567891011&#123; &quot;actionName&quot;: &#123; &quot;_index&quot;: &quot;indexName&quot;, &quot;_type&quot;: &quot;typeName&quot;, &quot;_id&quot;: &quot;id&quot; &#125;&#125;&#123; &quot;field1&quot;: &quot;value1&quot;, &quot;field2&quot;: &quot;value2&quot;&#125; 1234567891011&#123; &quot;actionName&quot;: &#123; &quot;_index&quot;: &quot;indexName&quot;, &quot;_type&quot;: &quot;typeName&quot;, &quot;_id&quot;: &quot;id&quot; &#125;&#125;&#123; &quot;field1&quot;: &quot;value1&quot;, &quot;field2&quot;: &quot;value2&quot;&#125; 乐观并发控制在数据库领域中,有悲观并发控制和乐观并发控制两种方法来确保并发更新不丢失数据, 悲观并发控制被关系型数据库广泛使用,阻塞访问资源以防止冲突；ES使用乐观并发控制,若源数据在读写当中被修改,更新将会失败。 12345678PUT /db_index/_doc/1?if_seq_no=1&amp;if_primary_term=1&#123; &quot;name&quot;: &quot;Jack&quot;, &quot;sex&quot;: 1, &quot;age&quot;: 25, &quot;book&quot;: &quot;Spring Boot 入门到精通2&quot;, &quot;remark&quot;: &quot;hello world2&quot;&#125; ES老版本是使用 version字段来乐观并发控制,新版本7.x使用if_seq_no&#x3D;文档版本号&amp;if_primary_term&#x3D;文档位置来乐观并发控制。 每当Primary Shard发生重新分配时如 重启, Primary选举 等, _primary_term会递增1, _primary_term 主要是用来 恢复数据时 处理当多个文档的 _seq_no一样 时的冲突. 如当一个shard宕机了,raplica需要用到最新的数据,就会根据_primary_term和_seq_no两个值来拿到最新的document。 文档映射ES中映射可以分为动态映射和静态映射,在关系数据库中,需要事先在数据库下创建数据表,并创建表字段、类型、长度、主键等,最后才能基于表插入数据。而Elasticsearch中不需要定义Mapping映射,在文档写入ES时,会根据文档字段自动识别类型,该机制为动态映射；也可事先定义好映射,包含文档的各字段类型、分词器等,该方式为静态映射 字符串： string类型包含text和keyword text： 该类型被用来索引长文本,创建索引前会将文本进行分词,转化为词的组合,建立索引；允许es来检索这些词, 不能用来排序和聚合 keyword： 该类型不能分词,可被用来检索过滤、排序和聚合, 不可用text进行分词模糊检索 数值型： long、integer、short、byte、double、float 日期型： date 布尔型： boolean 123456789101112131415161718192021222324252627282930313233343536GET /es_db/_mapping // 获取文档映射 PUT /es_db2 // 创建索引且设置文档映射&#123; &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123; &quot;name&quot;: &#123; &quot;type&quot;: &quot;keyword&quot;, &quot;index&quot;: true, &quot;store&quot;: true &#125;, &quot;sex&quot;: &#123; &quot;type&quot;: &quot;integer&quot;, &quot;index&quot;: true, &quot;store&quot;: true &#125;, &quot;age&quot;: &#123; &quot;type&quot;: &quot;integer&quot;, &quot;index&quot;: true, &quot;store&quot;: true &#125;, &quot;book&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;index&quot;: true, &quot;store&quot;: true, &quot;analyzer&quot;: &quot;ik_smart&quot;, // 指定text类型的ik分词器 &quot;search_analyzer&quot;: &quot;ik_smart&quot; // 指定text类型的ik分词器 &#125;, &quot;address&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;index&quot;: true, &quot;store&quot;: true &#125; &#125; &#125;&#125; 若要推倒现有的映射,得重新建立一个静态索引,然后把之前索引里的数据导入到新的索引里, 删除原创建的索引, 为新索引起个别名,为原索引名。 1234567891011POST _reindex // 把之前索引里的数据导入到新的索引里&#123; &quot;source&quot;: &#123; &quot;index&quot;: &quot;db_index&quot; &#125;, &quot;dest&quot;: &#123; &quot;index&quot;: &quot;db_index_2&quot; &#125;&#125;DELETE /db_index // 删除原创建的索引PUT /db_index_2/_alias/db_index // 为新索引起个别名, 为原索引名 若要推倒现有的映射,得重新建立一个静态索引,然后把之前索引里的数据导入到新的索引里, 删除原创建的索引, 为新索引起个别名,为原索引名。 1234567891011POST _reindex // 把之前索引里的数据导入到新的索引里&#123; &quot;source&quot;: &#123; &quot;index&quot;: &quot;db_index&quot; &#125;, &quot;dest&quot;: &#123; &quot;index&quot;: &quot;db_index_2&quot; &#125;&#125;DELETE /db_index // 删除原创建的索引PUT /db_index_2/_alias/db_index // 为新索引起个别名, 为原索引名 DSL高级查询Domain Specific Language领域专用语言,由叶子查询子句和复合查询子句两种子句组成。DSL查询语言又分为查询DSL和过滤DSL。ES中索引的数据都会存储一个 _score分值, 分值越高就代表越匹配, 查询上下文中不仅要判断查询条件与文档是否匹配,且还要关心相关度即 _score分值,需要根据分值排序；过滤器上下文中值关心查询条件与文档是否匹配,不计算 _score分值, 不关心排序问题,经常使用过滤器,ES会自动缓存过滤器内容。 12GET /es_db/_doc/_search // 无查询条件是查询所有,默认查询所有,或使用match_all表示所有&#123;&quot;query&quot;:&#123;&quot;match_all&quot;:&#123;&#125;&#125;&#125; 叶子查询模糊匹配模糊匹配主要是针对文本类型的字段,文本类型的字段会对内容进行分词, 查询时也会对搜索条件进行分词,然后通过倒排索引查找到匹配数据,模糊匹配主要通过 match 等参数来实现 match：通过match关键词模糊匹配条件内容, 需指定字段名, 会进行分词 query：指定匹配的值 operator：匹配条件类型 and：条件分词后都要匹配 or：条件分词后有一个匹配即可,默认为or minmum_should_match：指定最小匹配数量 query_string：和match类似, 可不指定字段即所有字段中搜索,范围更广泛 match_phase：会对输入做分词,但结果中也包含所有分词,且顺序一样 prefix：前缀匹配 regexp：通过正则表达式来匹配数据 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566POST /es_db/_doc/_search&#123; &quot;from&quot;: 0, &quot;size&quot;: 2, &quot;query&quot;: &#123; &quot;match&quot;: &#123; // match会根据该字段的分词器,进行分词查询 &quot;address&quot;: &quot;广州&quot; &#125; &#125;&#125;POST /es_db/_doc/_search&#123; &quot;query&quot;: &#123; &quot;multi_match&quot;: &#123; // 多字段模糊匹配查询 &quot;query&quot;: &quot;长沙&quot;, &quot;fields&quot;: [&quot;address&quot;, &quot;name&quot;] // address或name字段中匹配到“长沙” &#125; &#125;&#125;POST /es_db/_doc/_search&#123; &quot;query&quot;: &#123; &quot;query_string&quot;: &#123; // 未指定字段条件查询query_string, 含AND与OR条件 &quot;query&quot;: &quot;广州 OR 长沙&quot; // 所有的字段中只要包含“广州”或“长沙” &#125; &#125;&#125;POST /es_db/_doc/_search&#123; &quot;query&quot;: &#123; &quot;query_string&quot;: &#123; // 指定字段条件查询query_string &quot;query&quot;: &quot;admin AND 长沙&quot;, &quot;fields&quot;: [&quot;name&quot;, &quot;address&quot;] // name或address匹配admin和长沙 &#125; &#125;&#125;GET /es_db/_search&#123; &quot;query&quot;: &#123; // ES执行搜索时,默认operator为or &quot;match&quot;: &#123; // remark字段包含java或developer词组,则符合搜索条件。 &quot;remark&quot;: &quot;java developer&quot; &#125; &#125;&#125;GET /es_db/_search&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;remark&quot;: &#123; // remark字段包含java和developer词组 &quot;query&quot;: &quot;java developer&quot;, &quot;operator&quot;: &quot;and&quot; &#125; &#125; &#125;&#125;GET /es_db/_search&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;remark&quot;: &#123; // 需要remark字段中包含多个搜索词条中的一定比例 &quot;query&quot;: &quot;java architect assistant&quot;, &quot;minimum_should_match&quot;: &quot;50%&quot; // minimum_should_match可使用百分比或固定数字 &#125; &#125; &#125;&#125; match_phrase短语搜索,使用短语搜索时和match类似,首先对搜索条件进行分词,ES在做分词时除了将数据切分外,还会保留一个词在整个数据中的下标position。当ES执行match phrase短语搜索时,首先将搜索条件分词,然后在倒排索引中检索数据,若搜索条件分词数据在某个document某个field出现时,则检查匹配到的单词的position是否连续,若不连续则匹配失败。 ES对match phrase短语搜索提供了 slop参数,可实现数据在所有匹配结果中,多个单词距离越近相关度评分越高排序越靠前,若当 slop 移动次数使用完毕还没有匹配成功则无搜索结果。 12345678910111213141516171819GET _search&#123; &quot;query&quot;: &#123; &quot;match_phrase&quot;: &#123; // 短语搜索,搜索条件不分词 &quot;remark&quot;: &quot;java assistant&quot; &#125; &#125;&#125;GET /es_db/_search&#123; &quot;query&quot;: &#123; &quot;match_phrase&quot;: &#123; &quot;remark&quot;: &#123; &quot;query&quot;: &quot;java assistant&quot;, &quot;slop&quot;: 1 &#125; &#125; &#125;&#125; 前缀搜索通常针对 keyword 类型字段即不分词字段, keyword类型字段数据大小写敏感, 前缀搜索效率比较低,且不计算相关度分数, 前缀越短效率越低。若使用前缀搜索,建议使用长前缀,因为前缀搜索需要扫描完整索引内容,所以前缀越长相对效率越高。 12345678GET /test_a/_search&#123; &quot;query&quot;: &#123; &quot;prefix&quot;: &#123; &quot;f.keyword&quot;: &#123;&quot;value&quot;: &quot;Jav&quot;&#125; &#125; &#125;&#125; 通配符搜索通配符可在倒排索引中使用,也可在 keyword类型字段中使用。?问号匹配一个任意字符, *星号匹配0到n个任意字符。性能也很低,也需要扫描完整索引。 12345678GET /test_a/_search&#123; &quot;query&quot;: &#123; &quot;wildcard&quot;: &#123; &quot;f.keyword&quot;: &#123; &quot;value&quot;: &quot;?e*o*&quot; &#125; &#125; &#125;&#125; 正则搜索可在 倒排索引 或 keyword 类型字段中使用, 性能很低需要扫描完整索引。 123456GET /test_a/_search&#123; &quot;query&quot;: &#123; &quot;regexp&quot;: &#123;&quot;f.keyword&quot;: &quot;[A-z].+&quot;&#125; &#125;&#125; 搜索推荐其原理和 match phrase类似,先使用match匹配term数据即示例中的java,然后在指定 slop移动次数范围内前缀匹配示例数据sp, max_expansions是用于指定prefix最多匹配多少个term,超过该数量就不再匹配了。该语法限制只有最后一个term会执行前缀搜索。执行性能很差, 最后一个term 需要 扫描所有符合slop要求的倒排索引的term. 若必须使用一定要使用参数 max_expansions. 12345678GET /test_a/_search&#123; &quot;query&quot;: &#123; &quot;match_phrase_prefix&quot;: &#123; &quot;f&quot;: &#123;&quot;query&quot;: &quot;java sp&quot;,&quot;slop&quot;: 10,&quot;max_expansions&quot;: 10&#125; &#125; &#125;&#125; 模糊搜索搜索时可能搜索条件文本输入错误,fuzzy技术就是用于解决错误拼写的,英文中很有效但中文中几乎无效,其中 fuzziness 代表 value值word可修改多少个字母来进行拼写错误纠正,修改字母数量包含字母变更,增加或减少字母. 12345678GET /test_a/_search&#123; &quot;query&quot;: &#123; &quot;fuzzy&quot;: &#123; &quot;f&quot;: &#123;&quot;value&quot;: &quot;word&quot;,&quot;fuzziness&quot;: 2&#125; &#125; &#125;&#125; 精确匹配 term： 单个条件相等,查询字段映射类型属于为 keyword, 不会被分词 terms： 单个字段属于某个值数组内的值 range： 字段属于某个范围内的值 gte： 大于等于 lte： 小于等于 gt： 大于 lt： 小于 now： 当前时间 exists： 某个字段的值是否存在 ids： 通过ID批量查询 12345678910111213141516171819202122232425262728POST /es_db/_doc/_search&#123; &quot;query&quot;: &#123; &quot;term&quot;: &#123; // term查询不会对字段进行分词查询,会采用精确匹配 &quot;name&quot;: &quot;admin&quot; &#125; &#125;&#125;POST /es_db/_doc/_search&#123; &quot;query&quot;: &#123; &quot;range&quot;: &#123; // 范围查询 &quot;age&quot;: &#123;&quot;gte&quot;: 25,&quot;lte&quot;: 28&#125; &#125; &#125;&#125;POST /es_db/_doc/_search // 范围、分页、输出字段、综合查询&#123; &quot;query&quot;: &#123; &quot;range&quot;: &#123; // 范围查询 &quot;age&quot;: &#123;&quot;gte&quot;: 25,&quot;lte&quot;: 28&#125; &#125; &#125;, &quot;from&quot;: 0, // 分页 &quot;size&quot;: 2, &quot;_source&quot;: [&quot;name&quot;, &quot;age&quot;, &quot;book&quot;], // 指定输出字段 &quot;sort&quot;: &#123;&quot;age&quot;: &quot;desc&quot;&#125;// 排序&#125; 组合查询组合条件查询是将叶子条件查询语句进行组合而形成的一个完整的查询条件, must、filter、shoud、must_not等子条件是通过 term、terms、range、ids、exists、match等叶子条件为参数,当只有一个搜索条件时,must等对应的是一个对象,当多个条件时,对应的是一个数组。 bool： 各条件之间有 and, or 或 not 关系 must： 各个条件都必须满足,即各条件是 and 关系 should： 各个条件有一个满足即可,即各条件是 or 关系 must_not： 不满足所有条件,即各条件是 not 关系 filter： 不计算相关度评分,即不计算_score, 不对结果排序,效率更高, 查询结果可被缓存 constant_score： 不计算相关度评分 1234567891011121314151617181920212223POST /es_db/_doc/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;filter&quot;: &#123; // 对数据进行过滤 &quot;term&quot;: &#123;&quot;age&quot;: 25&#125; &#125; &#125; &#125;&#125; GET /es_db/_search&#123; &quot;query&quot;: &#123; // 使用should+bool搜索,控制搜索条件的匹配度 &quot;bool&quot;: &#123; &quot;should&quot;: [ // 必须匹配java、developer、assistant三个词条中的至少2个 &#123;&quot;match&quot;: &#123;&quot;remark&quot;: &quot;java&quot;&#125;&#125;, &#123;&quot;match&quot;: &#123;&quot;remark&quot;: &quot;developer&quot;&#125;&#125;, &#123;&quot;match&quot;: &#123;&quot;remark&quot;: &quot;assistant&quot;&#125;&#125; ], &quot;minimum_should_match&quot;: 2 // 控制搜索条件的匹配度 &#125; &#125;&#125; ES中执行 match搜索 时,ES底层通常会对搜索条件进行底层转换,来实现最终的搜索结果,若不怕麻烦, 尽量使用转换后的语法执行搜索, 效率更高。 123456789101112131415GET /es_db/_search // 转换前&#123;&quot;query&quot;:&#123;&quot;match&quot;:&#123;&quot;remark&quot;:&quot;java developer&quot;&#125;&#125;&#125;GET /es_db/_search // 转换后&#123;&quot;query&quot;:&#123;&quot;bool&quot;:&#123;&quot;should&quot;:[&#123;&quot;term&quot;:&#123;&quot;remark&quot;:&quot;java&quot;&#125;&#125;,&#123;&quot;term&quot;:&#123;&quot;remark&quot;:&#123;&quot;value&quot;:&quot;developer&quot;&#125;&#125;&#125;]&#125;&#125;&#125;GET /es_db/_search // 转换前&#123;&quot;query&quot;:&#123;&quot;match&quot;:&#123;&quot;remark&quot;:&#123;&quot;query&quot;:&quot;java developer&quot;,&quot;operator&quot;:&quot;and&quot;&#125;&#125;&#125;&#125;GET /es_db/_search // 转换后&#123;&quot;query&quot;:&#123;&quot;bool&quot;:&#123;&quot;must&quot;:[&#123;&quot;term&quot;:&#123;&quot;remark&quot;:&quot;java&quot;&#125;&#125;,&#123;&quot;term&quot;:&#123;&quot;remark&quot;:&#123;&quot;value&quot;:&quot;developer&quot;&#125;&#125;&#125;]&#125;&#125;&#125;GET /es_db/_search // 转换前&#123;&quot;query&quot;:&#123;&quot;match&quot;:&#123;&quot;remark&quot;:&#123;&quot;query&quot;:&quot;java architect assistant&quot;,&quot;minimum_should_match&quot;:&quot;68%&quot;&#125;&#125;&#125;&#125;GET /es_db/_search // 转换后&#123;&quot;query&quot;:&#123;&quot;bool&quot;:&#123;&quot;should&quot;:[&#123;&quot;term&quot;:&#123;&quot;remark&quot;:&quot;java&quot;&#125;&#125;,&#123;&quot;term&quot;:&#123;&quot;remark&quot;:&quot;architect&quot;&#125;&#125;,&#123;&quot;term&quot;:&#123;&quot;remark&quot;:&quot;assistant&quot;&#125;&#125;],&quot;minimum_should_match&quot;:2&#125;&#125;&#125; boost权重控制boost权重控制一般用于搜索时相关度排序使用,将某字段数据匹配时相关度分数增加 123456789101112GET /es_db/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [&#123;&quot;match&quot;: &#123;&quot;remark&quot;: &quot;java&quot;&#125;&#125;], &quot;should&quot;: [ &#123;&quot;match&quot;: &#123;&quot;remark&quot;: &#123;&quot;query&quot;: &quot;developer&quot;,&quot;boost&quot;: 3&#125;&#125;&#125;, &#123;&quot;match&quot;: &#123;&quot;remark&quot;: &#123;&quot;query&quot;: &quot;architect&quot;,&quot;boost&quot;: 1&#125;&#125;&#125; ] &#125; &#125;&#125; dis_maxdis_max 语法是直接 获取搜索多条件 中 单条件query相关度分数最高 的数据,以该数据做 相关度排序。基于dis_max 实现 best fields策略 进行 多字段搜索, best fields策略是搜索document中某个field, 尽可能多的匹配搜索条件。与之相反的是 most fields策略 即 尽可能多的字段匹配到搜索条件 。 best fields策略优点是精确匹配的数据可尽可能排列在最前端,且可通过 minimum_should_match 去除 长尾数据,避免长尾数据字段对排序结果的影响。缺点相对排序不均匀。 1234567891011GET /es_db/_search&#123; &quot;query&quot;: &#123; &quot;dis_max&quot;: &#123; // 找name字段中rod匹配相关度分数或remark字段中java developer匹配相关度分数,哪个高就使用哪个相关度分数进行结果排序 &quot;queries&quot;: [ &#123;&quot;match&quot;: &#123;&quot;name&quot;: &quot;rod&quot;&#125;&#125;, &#123;&quot;match&quot;: &#123;&quot;remark&quot;: &quot;java developer&quot;&#125;&#125; ] &#125; &#125;&#125; dis_max 是将 多个 搜索query条件中 相关度分数最高 的用于结果排序, 忽略其他query分数,在某些情况下 需要其他query条件中相关度介入最终结果排序,此时可 使用tie_breaker参数来优化dis_max搜索。 tie_breaker 参数表示 将其他query搜索条件相关度分数乘以参数值再参与结果排序。若不定义 tie_breaker 参数相当于 参数值为0,故其他query条件的相关度分数被忽略。 123456789101112GET /es_db/_search&#123; &quot;query&quot;: &#123; &quot;dis_max&quot;: &#123; // 找name字段中rod匹配相关度分数或remark字段中java developer匹配相关度分数,哪个高就使用哪个相关度分数进行结果排序 &quot;queries&quot;: [ &#123;&quot;match&quot;: &#123;&quot;name&quot;: &quot;rod&quot;&#125;&#125;, &#123;&quot;match&quot;: &#123;&quot;remark&quot;: &quot;java developer&quot;&#125;&#125; ], &quot;tie_breaker&quot;: 0.5 &#125; &#125;&#125; 使用multi_match简化dis_max+tie_breaker,ES中相同结果搜索也可使用不同语法语句来实现。 123456789101112131415161718192021222324252627GET /es_db/_search&#123; &quot;query&quot;: &#123; &quot;dis_max&quot;: &#123; &quot;queries&quot;: [ &#123;&quot;match&quot;: &#123;&quot;name&quot;: &quot;rod&quot;&#125;&#125;, &#123;&quot;match&quot;: &#123;&quot;remark&quot;: &#123;&quot;query&quot;: &quot;java assistant&quot;,&quot;boost&quot;: 2&#125;&#125;&#125; ], &quot;tie_breaker&quot;: 0.5 &#125; &#125;&#125;GET /es_db/_search&#123; &quot;query&quot;: &#123; &quot;multi_match&quot;: &#123; &quot;query&quot;: &quot;rod java developer&quot;, &quot;fields&quot;: [ &quot;name&quot;, &quot;remark^2&quot; // ^n代表权重,相当于&quot;boost&quot;:n ], &quot;type&quot;: &quot;best_fields&quot;, // 其中type常用的有best_fields和most_fields &quot;tie_breaker&quot;: 0.5, &quot;minimum_should_match&quot;: &quot;50%&quot; &#125; &#125;&#125; cross fields 是一个 唯一标识,且分布在 多个fields 中, 使用该唯一标识搜索数据即cross fields搜索。如人名可分为姓和名,地址可分为省、市、区县、街道等。使用人名或地址来搜索document,就称为cross fields搜索。 实现这种搜索,一般都是使用 most fields搜索策略,因为这就是 多个field 问题。 Cross fields 搜索策略是 从多个字段中搜索条件数据, 默认和most fields搜索逻辑一致 但 计算相关度分数和best fields策略一致。一般若使用cross fields搜索策略,都会携带 operator 额外参数,用来标记搜索条件如何在多个字段中匹配。 1234567891011GET /es_db/_search&#123; &quot;query&quot;: &#123; &quot;multi_match&quot;: &#123; // 搜索条件中java必须在name或remark字段中匹配,developer也必须在name或remark字段中匹配 &quot;query&quot;: &quot;java developer&quot;, &quot;fields&quot;: [&quot;name&quot;, &quot;remark&quot;], &quot;type&quot;: &quot;cross_fields&quot;, &quot;operator&quot;: &quot;and&quot; &#125; &#125;&#125; most fields策略 是尽可能匹配更多字段,会导致 精确搜索结果排序问题 ,又因为cross fields搜索,不能使用 minimum_should_match 来去除长尾数据。故在使用 most fields 和 cross fields 策略搜索数据时,都有不同缺陷,商业项目开发中都 推荐使用best fields策略 实现搜索。 可通过 copy_to 解决 cross fields搜索问题, copy_to 就是将 多个字段复制到一个字段 中实现一个 多字段组合,在商业项目中,也用于 解决搜索条件默认字段问题。若需要使用copy_to语法,则需要在定义 index 时手工指定 mapping映射策略。 123456789PUT /es_db/_mapping&#123; &quot;properties&quot;: &#123; &quot;provice&quot;: &#123;&quot;type&quot;: &quot;text&quot;,&quot;analyzer&quot;: &quot;standard&quot;,&quot;copy_to&quot;: &quot;address&quot;&#125;, &quot;city&quot;: &#123;&quot;type&quot;: &quot;text&quot;,&quot;copy_to&quot;: &quot;address&quot;&#125;, &quot;street&quot;: &#123;&quot;type&quot;: &quot;text&quot;,&quot;analyzer&quot;: &quot;standard&quot;,&quot;copy_to&quot;: &quot;address&quot;&#125;, &quot;address&quot;: &#123;&quot;type&quot;: &quot;text&quot;,&quot;analyzer&quot;: &quot;standard&quot;&#125; &#125;&#125; 在mapping定义中新增provice、city、street、address等字段,其中provice、city、street三个字段值会自动复制到address字段中,实现一个字段组合。在搜索地址时可在address字段中做条件匹配,从而避免most fields策略导致的问题。在维护数据时不需对address字段特殊维护,ES会自动维护组合字段。在存储时物理上不一定存在但逻辑上存在,因为address由3个物理存在属性province、city、street组成。 使用 match 和 proximity search 实现 召回率 和 精准度平衡 ,若搜索时只使用match phrase语法,会导致 召回率低下,若只使用match语法,会导致 精准度低下,因为搜索结果排序是根据相关度分数算法计算得到。若需要在结果中 兼顾召回率 和 精准度,就需要将 match 和 proximity search 混合使用。 召回率：搜索结果比率,如索引A中有100个document,搜索时返回多少个document 精准度：搜索结果准确率,如搜索条件为hello java,搜索结果中尽可能让短语匹配和hello java离的近的结果排序靠前1234567891011121314151617181920POST /test_a/_doc/3&#123;&quot;f&quot;:&quot;hello, java is very good, spark is also very good&quot;&#125;POST /test_a/_doc/4&#123;&quot;f&quot;:&quot;java and spark, development language &quot;&#125;POST /test_a/_doc/5&#123;&quot;f&quot;:&quot;Java Spark is a fast and general-purpose cluster computing system. It provides high-level APIs in Java, Scala, Python and R, and an optimized engine that supports general execution graphs.&quot;&#125;POST /test_a/_doc/6&#123;&quot;f&quot;:&quot;java spark and, development language &quot;&#125;GET /test_a/_search&#123;&quot;query&quot;:&#123;&quot;match&quot;:&#123;&quot;f&quot;:&quot;java spark&quot;&#125;&#125;&#125;GET /test_a/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [&#123;&quot;match&quot;: &#123;&quot;f&quot;: &quot;java spark&quot;&#125;&#125;], &quot;should&quot;: [&#123;&quot;match_phrase&quot;: &#123;&quot;f&quot;: &#123;&quot;query&quot;: &quot;java spark&quot;,&quot;slop&quot;: 50&#125;&#125;&#125;] &#125; &#125;&#125; 连接查询 父子 文档查询： parent/child 嵌套 文档查询： nested ES架构原理在ES中主要分成 Master 和 DataNode 两类节点,ES启动时会选举出一个Master节点,当某个节点启动后,使用 Zen Discovery机制 找到集群中的其他节点并 建立连接,并 从候选主节点中选举出一个主节点。一个ES集群中只有一个Master节点,但会有 N个DataNode 节点,在生产环境中内存可相对小一点但机器要稳定。 Master：管理索引即创建、删除索引, 分配分片, 维护元数据, 管理集群节点状态, 不负责数据写入和查询,比较轻量级 DataNode：数据写入, 数据检索,大部分ES压力都在DataNode节点上 分片ShardES是一个分布式搜索引擎,索引数据也分成若干部分,分布在不同服务器节点中,分布在不同服务器节点中的索引数据,就是Shard分片。Elasticsearch会自动管理分片,若发现分片分布不均衡,会自动迁移一个索引index由多个shard分片组成, 分片是分布在不同的服务器上。 副本为了对ES分片进行容错,假设某个节点不可用,会导致整个索引库都将不可用。故需要对分片进行副本容错, 每个分片都会有对应的副本。默认创建索引为1个分片、每个分片有 1个主分片 和 1个副本分片。 每个分片都会有一个Primary Shard主分片,也会有若干个Replica Shard副本分片, Primary Shard和Replica Shard不在同一个节点上。 12345678910111213141516PUT /job_idx_shard_temp // 创建指定分片数量、副本数量的索引&#123; &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123; &quot;id&quot;: &#123;&quot;type&quot;: &quot;long&quot;,&quot;store&quot;: true&#125;, &quot;area&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;,&quot;store&quot;: true&#125;, &quot;edu&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;,&quot;store&quot;: true&#125; &#125; &#125;, &quot;settings&quot;: &#123; &quot;number_of_shards&quot;: 3, // 指定分片数量 &quot;number_of_replicas&quot;: 2 // 指定副本数量 &#125;&#125;GET /_cat/indices?v // 查看分片、主分片、副本分片 文档写入原理 选择 任意一个DataNode发送请求 如node2,此时node2就成为一个 coordinating node协调节点,通过协调节点 计算得到文档要写入的分片shard = hash(routing) % number_of_primary_shards,其中 routing 是一个 可变值, 默认为文档_id,然后 协调节点会进行路由,将请求 转发给对应 primary shard主分片所在的 DataNode,假设primary shard主分片在node1、replica shard副分片在node2,node1节点上的Primary Shard处理请求,写入数据到索引库中,并将数据同步到Replica shard副分片,Primary Shard和Replica Shard都保存好了文档则返回Client。 检索原理 Client发起查询请求某个 DataNode 接收到请求后,该 DataNode 就成为 Coordinating Node协调节点, 协调节点将查询请求广播到每一个数据节点,这些 数据节点 的 分片 会处理该查询请求, 每个分片进行数据查询,将符合条件的数据放在一个 优先队列 中,并将这些数据的 文档ID 、 节点信息 、 分片信息 返回给 协调节点 , 协调节点将所有结果进行汇总并全局排序,协调节点向包含这些 文档ID 的 分片 发送 get请求,对应的分片将文档数据返回给协调节点,最后协调节点将数据返回给客户端。 准实时索引 当数据写入到ES分片时会 首先写入到内存中,然后通过 内存buffer 生成一个 Segment,并刷到 文件系统缓存 中而 不是直接刷到磁盘,数据可被检索,ES中 默认1秒refresh一次。数据在 写入内存的同时,也会 记录Translog日志,若 在refresh期间出现异常,会 根据Translog 来进行 数据恢复,等到 文件系统缓存 中的 Segment 数据 都刷到磁盘中,则 清空Translog文件,ES 默认每隔30分钟 会将 文件系统缓存 的数据 刷入到磁盘. Segment太多 时ES 定期 会将多个 Segment合并 成为大的Segment, 减少索引查询时IO开销,此阶段ES会真正的 物理删除 之前 执行过delete的数据。","tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"http://example.com/tags/ElasticSearch/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"ElasticSearch","slug":"工具和中间件/搜索引擎技术/ElasticSearch","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/ElasticSearch/"}]},{"title":"SpringCloud系列14-总结","date":"2021-10-07T04:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列14-总结/","text":"多个微服务:12345678910&lt;modules&gt; &lt;module&gt;eureka-server&lt;/module&gt; &lt;module&gt;product-data-service&lt;/module&gt; &lt;module&gt;product-view-service-ribbon&lt;/module&gt; &lt;module&gt;product-view-service-feign&lt;/module&gt; &lt;module&gt;config-server&lt;/module&gt; &lt;module&gt;hystrix-dashboard&lt;/module&gt; &lt;module&gt;turbine&lt;/module&gt; &lt;module&gt;productServiceZuul&lt;/module&gt;&lt;/modules&gt; 端口号总结:微服务： eureka-server: 8761 product-data-service: 8001,8002,8003 product-view-service-ribbon: 8010 product-view-service-feign: 8012, 8013, 8014 hystrix-dashboard: 8020 turbine: 8021 config-server: 8030 zuul: 8040 第三方: zipkin:9411 rabbitMQ: 5672","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"SpringCloud系列13-网关Zuul","date":"2021-10-07T03:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列13-网关Zuul/","text":"问题：为何要用网关? 我们现在有两种微服务，分别是数据微服务和视图微服务。它们有可能放在不同的 ip 地址上，有可能是不同的端口。 为了访问他们，就需要记录这些地址和端口。 而地址和端口都可能会变化，这就增加了访问者的负担。这个时候，我们就可以用网关来解决这个问题。 如图所示，我们只需要记住网关的地址和端口号就行了： 如果要访问数据服务，访问地址 http://ip:port/api-data/products 即可。 如果要访问视图服务，访问地址 http://ip:port/api-view/products 即可 创建子项目： zuulpom.xml：12345678910111213141516171819202122232425262728293031&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;spring-cloud-parent&lt;/artifactId&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-parent/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;productServiceZuul&lt;/artifactId&gt; &lt;name&gt;productServiceZuul&lt;/name&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; ProductServiceZuulApplication.java:12345678910111213141516171819202122232425package cn.peach;import cn.hutool.core.util.NetUtil;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.boot.builder.SpringApplicationBuilder;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.cloud.netflix.eureka.EnableEurekaClient;import org.springframework.cloud.netflix.zuul.EnableZuulProxy;@SpringBootApplication@EnableZuulProxy@EnableEurekaClient@EnableDiscoveryClientpublic class ProductServiceZuulApplication&#123; public static void main( String[] args ) &#123; int port = 8040; if(!NetUtil.isUsableLocalPort(port)) &#123; System.err.printf(&quot;端口%d被占用了，无法启动%n&quot;, port ); System.exit(1); &#125; new SpringApplicationBuilder(ProductServiceZuulApplication.class).properties(&quot;server.port=&quot; + port).run(args); &#125;&#125; application.yml:配置文件，进行了路由映射 12345678zuul: routes: api-a: path: /api-data/** serviceId: PRODUCT-DATA-SERVICE api-b: path: /api-view/** serviceId: PRODUCT-VIEW-SERVICE-FEIGN 完整代码： 123456789101112131415eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/spring: application: name: product-service-zuulzuul: routes: api-a: path: /api-data/** serviceId: PRODUCT-DATA-SERVICE api-b: path: /api-view/** serviceId: PRODUCT-VIEW-SERVICE-FEIGN 启动： 首先挨个运行 EurekaServerApplication, ConfigServerApplication, ProductDataServiceApplication， ProductViewServiceFeignApplication。 然后启动 ProductServiceZuulApplication 接着访问地址: http://localhost:8040/api-data/products http://localhost:8040/api-view/products 这样就可以访问数据微服务和视微服务集群了，并且无需去记住那么多ip地址和端口号了。","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"SpringCloud系列12-断路器聚合监控","date":"2021-10-07T02:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列12-断路器聚合监控/","text":"需求:前面是针对一个微服务的断路器监控，但是微服务通常会是多个实例组成的一个集群。 倘若集群里的实例比较多，难道要挨个挨个去监控这些实例吗？ 何况有时候，根据集群的需要，会动态增加或者减少实例，监控起来就更麻烦了。 为了方便监控集群里的多个实例，springCloud 提供了一个 turbine 项目，它的作用是把一个集群里的多个实例汇聚在一个 turbine里，这个然后再在 断路器监控里查看这个 turbine, 这样就能够在集群层面进行监控了。 创建子项目： turbinepom.xml:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;spring-cloud-parent&lt;/artifactId&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-parent/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;turbine&lt;/artifactId&gt; &lt;name&gt;turbine&lt;/name&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-turbine&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; ProductServiceTurbineApplication.java1234567891011121314151617181920package cn.peach;import cn.hutool.core.util.NetUtil;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.boot.builder.SpringApplicationBuilder;import org.springframework.cloud.netflix.turbine.EnableTurbine;@SpringBootApplication@EnableTurbinepublic class ProductServiceTurbineApplication &#123; public static void main(String[] args) &#123; int port = 8021; if(!NetUtil.isUsableLocalPort(port)) &#123; System.err.printf(&quot;端口%d被占用了，无法启动%n&quot;, port ); System.exit(1); &#125; new SpringApplicationBuilder(ProductServiceTurbineApplication.class).properties(&quot;server.port=&quot; + port).run(args); &#125;&#125; application.yml配置信息，主要是：appConfig: product-view-service-feign, 这就表示它会把所有微服务名称是product-view-service-feign 的实例信息都收集起来。 1234567891011121314spring: application.name: turbineturbine: aggregator: clusterConfig: default # 指定聚合哪些集群，多个使用&quot;,&quot;分割，默认为default。可使用http://.../turbine.stream?cluster=&#123;clusterConfig之一&#125;访问 appConfig: product-view-service-feign ### 配置Eureka中的serviceId列表，表明监控哪些服务 clusterNameExpression: new String(&quot;default&quot;) # 1. clusterNameExpression指定集群名称，默认表达式appName；此时：turbine.aggregator.clusterConfig需要配置想要监控的应用名称 # 2. 当clusterNameExpression:default时，turbine.aggregator.clusterConfig可以不写，因为默认就是default # 3. 当clusterNameExpression:metadata[&#x27;cluster&#x27;]时，假设想要监控的应用配置了eureka.instance.metadata-map.cluster: ABC，则需要配置，同时turbine.aggregator.clusterConfig: ABCeureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"SpringCloud系列11-断路器监控","date":"2021-10-06T13:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列11-断路器监控/","text":"需求:断路器，是当数据服务不可用的时候， 断路器就会发挥作用。那么数据服务什么时候可用，什么时候不可用，如何监控这个事情呢？ 我们就要用到 断路器监控 来可视化掌控这个情况了。 创建子项目：hystrix-dashboardpom.xml文件1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;spring-cloud-parent&lt;/artifactId&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-parent/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;hystrix-dashboard&lt;/artifactId&gt; &lt;name&gt;hystrix-dashboard&lt;/name&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; ProductServiceHystrixDashboardApplication.java断路器监控启动类，主要就是@EnableHystrixDashboard 1234567891011121314151617181920package cn.peach;import cn.hutool.core.util.NetUtil;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.boot.builder.SpringApplicationBuilder;import org.springframework.cloud.netflix.hystrix.dashboard.EnableHystrixDashboard;@SpringBootApplication@EnableHystrixDashboardpublic class ProductServiceHystrixDashboardApplication&#123; public static void main(String[] args) &#123; int port = 8020; if(!NetUtil.isUsableLocalPort(port)) &#123; System.err.printf(&quot;端口%d被占用了，无法启动%n&quot;, port ); System.exit(1); &#125; new SpringApplicationBuilder(ProductServiceHystrixDashboardApplication.class).properties(&quot;server.port=&quot; + port).run(args); &#125;&#125; application.yml:123spring: application: name: hystrix-dashboard ProductViewServiceFeignApplication.java 修改视图微服务项目，以使得它可以把信息共享给监控中心。 修改ProductViewServiceFeignApplication， 增加 @EnableCircuitBreaker 1234567891011121314151617181920212223242526272829303132333435package cn.peach;import brave.sampler.Sampler;import cn.hutool.core.util.NetUtil;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.circuitbreaker.EnableCircuitBreaker;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.cloud.netflix.eureka.EnableEurekaClient;import org.springframework.cloud.openfeign.EnableFeignClients;import org.springframework.context.annotation.Bean;@SpringBootApplication@EnableEurekaClient@EnableDiscoveryClient@EnableFeignClients@EnableCircuitBreaker //把信息共享给监控中心public class ProductViewServiceFeignApplication &#123; public static void main(String[] args) &#123; // 判断 rabiitMQ 是否启动 int rabbitMQPort = 5672; if(NetUtil.isUsableLocalPort(rabbitMQPort)) &#123; System.err.printf(&quot;未在端口%d 发现 rabbitMQ服务，请检查rabbitMQ 是否启动&quot;, rabbitMQPort ); System.exit(1); &#125; // 推荐 8012 、 8013 或者 8014 SpringApplication.run(ProductViewServiceFeignApplication.class, args); &#125; @Bean public Sampler defaultSampler() &#123; return Sampler.ALWAYS_SAMPLE; &#125;&#125; AccessViewService.java:准备一个不停访问服务的类： AccessViewService。 这样可以不断地访问服务，才便于在监控那里观察现象。 1234567891011121314151617181920212223242526package cn.peach.util;import cn.hutool.core.thread.ThreadUtil;import cn.hutool.http.HttpUtil;public class AccessViewService &#123; public static void main(String[] args) &#123; while(true) &#123; ThreadUtil.sleep(1000); access(8012); access(8013); &#125; &#125; public static void access(int port) &#123; try &#123; String html= HttpUtil.get(String.format(&quot;http://127.0.0.1:%d/products&quot;,port)); System.out.printf(&quot;%d 地址的视图服务访问成功，返回大小是 %d%n&quot; ,port, html.length()); &#125; catch(Exception e) &#123; System.err.printf(&quot;%d 地址的视图服务无法访问%n&quot;,port); &#125; &#125;&#125; 启动： 首先挨个运行 EurekaServerApplication, ConfigServerApplication, ProductDataServiceApplication， ProductViewServiceFeignApplication，ProductServiceHystrixDashboardApplication; 运行视图微服务里的 AccessViewService 来周期性地访问 http://127.0.0.1:8012/products 。 因为只有访问了，监控里才能看到数据; 打开监控地址 http://localhost:8020/hystrix; 如图所示，在最上面输入http://localhost:8012/actuator/hystrix.stream : 点击 Monitor Stream 就可以看到监控信息了。","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"SpringCloud系列10-断路器Hystrix","date":"2021-10-06T12:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列10-断路器Hystrix/","text":"问题:视图微服务是依赖于数据微服务的。那么当数据微服务不可用的时候，会怎么样呢？我们主动把 ProductDataServiceApplication 关闭，然后再访问：http://localhost:8012/products 就会抛出异常。客户也看不懂这个是什么。为了解决这个问题，我们就会引入断路器的概念。 断路器:断路器: 就是当被访问的微服务无法使用的时候，当前服务能够感知这个现象，并且提供一个备用的方案出来。 改造:pom.xml:增加 jar spring-cloud-starter-netflix-hystrix 以支持断路器。 12345&lt;!--增加 jar spring-cloud-starter-netflix-hystrix 以支持断路器--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;&lt;/dependency&gt; ProductClientFeign.java注解由原来的 @FeignClient(value = &quot;PRODUCT-DATA-SERVICE&quot;)修改为 @FeignClient(value = &quot;PRODUCT-DATA-SERVICE&quot;,fallback = ProductClientFeignHystrix.class)。 123456789101112131415package cn.peach.client;import cn.peach.pojo.Product;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;import java.util.List;@FeignClient(value = &quot;PRODUCT-DATA-SERVICE&quot;,fallback = ProductClientFeignHystrix.class)public interface ProductClientFeign &#123; @GetMapping(&quot;/products&quot;) public List&lt;Product&gt; listProdcuts();&#125; ProductClientFeignHystrix.javaProductClientFeignHystrix 实现了 ProductClientFeign 接口，并提供了 listProdcuts() 方法。这个方法就会固定返回包含一条信息的集合。 1234567891011121314151617181920package cn.peach.client;/* * Create By Tao on 2022/4/24. * * */import cn.peach.pojo.Product;import org.springframework.stereotype.Component;import java.util.ArrayList;import java.util.List;@Componentpublic class ProductClientFeignHystrix implements ProductClientFeign&#123; public List&lt;Product&gt; listProdcuts()&#123; List&lt;Product&gt; result = new ArrayList&lt;&gt;(); result.add(new Product(0,&quot;产品数据微服务现在不可用&quot;,0)); return result; &#125;&#125; application.yml在配置文件里开启断路器: 1feign.hystrix.enabled: true 启动:挨个启动： EurekaServerApplication, ConfigServerApplication, ProductViewServiceFeignApplication。注意: 数据服务是没有启动的。然后访问地址：http://127.0.0.1:8012/products会发现，依然可以打开，并且得到提示信息： 产品数据微服务不可用。","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"SpringCloud系列9-消息总线Bus","date":"2021-10-06T11:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列9-消息总线Bus/","text":"问题：虽然配置了config-server, 也把视图服务改造成了配置客户端，但是当需要刷新配置信息的时候，不得不既重启 config-server, 又重启微服务。 这样的体验当然是不太好的。 我们当然是希望一旦 git 上的配置信息修改之后，就可以自动地刷新到微服务里，而不是需要手动重启才可以。 RabbitMQ： springCloud 通过 rabbitMQ 来进行消息广播，以达到有配置信息发生改变的时候，广播给多个微服务的效果。 需要先安装 rabbitMQ 服务器。 改造:pom.xml:product-view-service-feign: 新增spring-boot-starter-actuator 用于访问路径：&#x2F;actuator&#x2F;bus-refresh 新增spring-cloud-starter-bus-amqp 用于支持 rabbitmq 12345678910&lt;!--多了spring-boot-starter-actuator 用于访问路径：/actuator/bus-refresh--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--多了spring-cloud-starter-bus-amqp 用于支持 rabbitmq--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt;&lt;/dependency&gt; bootstrap.yml:新增 but总线配置: 123456spring: cloud: bus: enabled: true trace: enabled: true 新增 rabbitMQ 配置: 12345rabbitmq: host: localhost port: 5672 username: guest password: guest 完整代码： 123456789101112131415161718192021spring: cloud: config: label: develop profile: dev discovery: enabled: true serviceId: config-server bus: enabled: true trace: enabled: true client: serviceUrl: defaultZone: http://localhost:8761/eureka/rabbitmq: host: localhost port: 5672 username: guest password: guest application.yml:新增路径访问允许,这样才能访问 &#x2F;actuator&#x2F;bus-refresh: 12345678management: endpoints: web: exposure: include: &quot;*&quot; cors: allowed-origins: &quot;*&quot; allowed-methods: &quot;*&quot; FreshConfigUtil.java使用 post 的方式访问 http://localhost:8012/actuator/bus-refresh 地址，之所以要专门做一个 FreshConfigUtil 类，就是为了可以使用 post 访问，因为它不支持 get 方式访问，直接把这个地址放在浏览器里，是会抛出 405错误的。 12345678910111213141516171819202122package cn.peach.util;/* * Create By Tao on 2022/4/24. * * */import cn.hutool.http.HttpUtil;import java.util.HashMap;public class FreshConfigUtil &#123; public static void main(String[] args) &#123; HashMap&lt;String,String&gt; headers =new HashMap&lt;&gt;(); headers.put(&quot;Content-Type&quot;, &quot;application/json; charset=utf-8&quot;); System.out.println(&quot;因为要去git获取，还要刷新config-server, 会比较卡，所以一般会要好几秒才能完成，请耐心等待&quot;); String result = HttpUtil.createPost(&quot;http://localhost:8012/actuator/bus-refresh&quot;).addHeaders(headers).execute().body(); System.out.println(&quot;result:&quot;+result); System.out.println(&quot;refresh 完成&quot;); &#125;&#125; 对服务链路追踪的影响因为视图服务进行了改造，支持了 rabbitMQ, 那么在默认情况下，它的信息就不会进入 Zipkin了。 在Zipkin 里看不到视图服务的资料了。为了解决这个问题，在启动 Zipkin 的时候 带一个参数就好了：–zipkin.collector.rabbitmq.addresses&#x3D;localhost即改成了： 1java -jar zipkin-server-2.10.1-exec.jar --zipkin.collector.rabbitmq.addresses=localhost 注： 重启 zipkin 后，要再访问业务地址才可以看到依赖关系。","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"SpringCloud系列8-配置客户端","date":"2021-10-06T10:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列8-配置客户端/","text":"配置客户端把现成的 视图微服务-Feign 改造成配置客户端，使得其可以从配置服务器上获取版本信息。 pom.xml增加一个 spring-cloud-starter-config 用于访问配置服务器。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;&lt;/dependency&gt; bootstrap.yml 作为配置客户端，它需要在 bootstrap.yml 里配置 config-server 的信息，而不是像以前那样在 application.yml 里进行配置。 bootstrap.yml 和 application.yml 的区别，简单说就是前者先启动，并且一些系统方面的配置需要在 bootstrap.yml 里进行配置。 在 bootstrap.yml 里配置提供了 serviceId: config-server, 这个是配置服务器在 eureka server 里的服务名称，这样就可以定位 config-server了。123456789101112131415spring: cloud: config: label: develop profile: dev discovery: enabled: true serviceId: config-server bus: enabled: true trace: enabled: true client: serviceUrl: defaultZone: http://localhost:8761/eureka/ application.yml把 eureka 地址信息移动到了 bootstrap.yml 里。 123456789101112spring: application: name: product-view-service-feign thymeleaf: cache: false prefix: classpath:/templates/ suffix: .html encoding: UTF-8 content-type: text/html mode: HTML5 zipkin: base-url: http://localhost:9411 ProductController.java增加这个属性，就可以从 config-server 去获取 version 信息了。 12@Value(&quot;$&#123;version&#125;&quot;)String version; 然后把这个信息放在 Model里 1m.addAttribute(&quot;version&quot;, version); 完整代码： 12345678910111213141516@Controller@RefreshScopepublic class ProductController &#123; @Autowired ProductService productService; @Value(&quot;$&#123;version&#125;&quot;) String version; @RequestMapping(&quot;/products&quot;) public Object products(Model m) &#123; List&lt;Product&gt; ps = productService.listProducts(); m.addAttribute(&quot;version&quot;, version); m.addAttribute(&quot;ps&quot;, ps); return &quot;products&quot;; &#125;&#125; products.html:12345&lt;tr&gt; &lt;td align=&quot;center&quot; colspan=&quot;3&quot;&gt; &lt;p th:text=&quot;$&#123;version&#125;&quot; &gt;how2j springcloud version unknown&lt;/p&gt; &lt;/td&gt;&lt;/tr&gt; 启动:挨个启动 EurekaServerApplication, ConfigServerApplication, ProductDataServiceApplication, ProductViewServiceFeignApplication, 然后访问如下地址：http://localhost:8012/products","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"SpringCloud系列7-配置服务器","date":"2021-10-06T09:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列7-配置服务器/","text":"配置服务的需要:有时候，微服务要做集群，这就意味着，会有多个微服务实例。 在业务上有时候需要修改一些配置信息，比如说 版本信息吧~ 倘若没有配置服务， 那么就需要挨个修改微服务，挨个重新部署微服务，这样就比较麻烦。为了偷懒， 这些配置信息就会放在一个公共的地方，比如git, 然后通过配置服务器把它获取下来，然后微服务再从配置服务器上取下来。这样只要修改git上的信息，那么同一个集群里的所有微服务都立即获取相应信息了，这样就大大节约了开发，上线和重新部署的时间了。 如图所示，我们先在 git 里保存 version 信息， 然后通过 ConfigServer 去获取 version 信息， 接着不同的视图微服务实例再去 ConfigServer 里获取 version. git首先要准备git。如下是已经准备好的 git:https://github.com/taoliu-hub/spring-cloud-angular11/blob/develop/respo/product-view-service-feign-dev.properties这里就准备了版本信息： version &#x3D; Version 1.1 创建子项目: config-serverpom.xml主要是 spring-cloud-config-server 这个 jar 包 1234567891011121314151617181920212223242526272829303132&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;spring-cloud-parent&lt;/artifactId&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-parent/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;artifactId&gt;config-server&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;config-server&lt;/name&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 启动类：ConfigServerApplication123456789101112131415161718package cn.peach;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.cloud.config.server.EnableConfigServer;import org.springframework.cloud.netflix.eureka.EnableEurekaClient;@SpringBootApplication@EnableConfigServer@EnableDiscoveryClient@EnableEurekaClientpublic class ConfigServerApplication &#123; public static void main(String[] args) &#123; // 推荐 8030 SpringApplication.run(ConfigServerApplication.class, args); &#125;&#125; application.yml12345678910111213141516171819spring: application: name: config-server cloud: config: label: develop name: product-view-service-feign profile: dev server: git: uri: https://github.com/taoliu-hub/spring-cloud-angular11.git searchPaths: respo default-label: main timeout: 500000eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/ 启动先启动 EurekaServerApplication， 再启动 ConfigServerApplication， 然后访问http://localhost:8030/version/dev","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"SpringCloud系列6-服务链路追踪","date":"2021-10-06T08:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列6-服务链路追踪/","text":"什么是服务链路我们有两个微服务，分别是数据服务和视图服务，随着业务的增加，就会有越来越多的微服务存在，他们之间也会有更加复杂的调用关系。这个调用关系，仅仅通过观察代码，会越来越难以识别，所以就需要通过 zipkin 服务链路追踪服务器 这个东西来用图片进行识别了 改造 eureka-server 不需要做改造; product-data-service和product-view-service 需要进行改造以使其可以被追踪到。 pom.xml都加上以下依赖：12345&lt;!--服务链路追踪--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt;&lt;/dependency&gt; application.yml都加上以下配置信息：123spring: zipkin: base-url: http://localhost:9411 启动类都加上以下配置信息：ProductDataServiceApplication.java 和 ProductViewServiceFeignApplication.java： 1234@Beanpublic Sampler defaultSampler() &#123; return Sampler.ALWAYS_SAMPLE;&#125; 启动测试： 需要启动链路追踪服务器：zipkin-server-2.10.1-exec.jar, 命令启动:1java -jar zipkin-server-2.10.1-exec.jar 启动 eureka-server, 改造后的 product-data-service 和 product-view-service-feign; 访问一次 http://127.0.0.1:8012/products 通过 视图微服务去访问数据微服务，这样链路追踪服务器才知道有这事儿发生 然后打开链路追踪服务器 http://localhost:9411/zipkin/dependency/ 就可以看到如图所示的 视图微服务调用数据微服务 的图形了","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"SpringCloud系列5-视图微服务-Feign","date":"2021-10-06T07:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列5-视图微服务-Feign/","text":"Feign 概念:是对Ribbon的封装，调用起来更简单。 代码片段的区别 Ribbon方式：123456@AutowiredRestTemplate restTemplate;public List&lt;Product&gt; listProdcuts() &#123; return restTemplate.getForObject(&quot;http://PRODUCT-DATA-SERVICE/products&quot;,List.class);&#125; Feign方式：123456@FeignClient(value = &quot;PRODUCT-DATA-SERVICE&quot;)public interface ProductClientFeign &#123; @GetMapping(&quot;/products&quot;) public List&lt;Product&gt; listProdcuts();&#125; 创建子项目 product-view-service-feignpom.xml:123456789101112131415161718192021222324252627282930313233&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;spring-cloud-parent&lt;/artifactId&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-parent/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;product-view-service-feign&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; Feign 客户端:Feign 客户端， 通过 注解方式 访问 访问PRODUCT-DATA-SERVICE服务的 products路径， product-data-service 既不是域名也不是ip地址，而是 数据服务在 eureka 注册中心的名称。 注意: 这里只是指定了要访问的 微服务名称，但是并没有指定端口号到底是 8001, 还是 8002. Feign方式：1234567891011121314package cn.peach.client;import cn.peach.pojo.Product;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;import java.util.List;@FeignClient(value = &quot;PRODUCT-DATA-SERVICE&quot;)public interface ProductClientFeign &#123; @GetMapping(&quot;/products&quot;) public List&lt;Product&gt; listProdcuts();&#125; Java code: 注意：这里忽略controller、 service、 repository, html层的代码，只列出重要部分代码，如需了解详情可参阅以下地址获取代码：https://github.com/taoliu-hub/spring-cloud-angular11/tree/main/spring-cloud. 服务类: ProductServiceImpl 123456789101112131415161718192021package cn.peach.service.impl;import cn.peach.client.ProductClientFeign;import cn.peach.pojo.Product;import cn.peach.service.ProductService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import java.util.List;@Servicepublic class ProductServiceImpl implements ProductService &#123; @Autowired ProductClientFeign productClientFeign; @Override public List&lt;Product&gt; listProducts() &#123; return productClientFeign.listProdcuts(); &#125;&#125; 启动类，注解多了个 @EnableFeignClients， 表示用于使用 Feign 方式。 1234567891011121314151617181920package cn.peach;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.EnableEurekaClient;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.cloud.openfeign.EnableFeignClients;@SpringBootApplication@EnableEurekaClient@EnableDiscoveryClient@EnableFeignClientspublic class ProductViewServiceFeignApplication &#123; public static void main(String[] args) &#123; // 推荐 8012 、 8013 或者 8014 SpringApplication.run(ProductViewServiceFeignApplication.class, args); &#125;&#125; 配置application.yml配置类，指定了 eureka server 的地址，以及自己的名称。 另外是一些 thymeleaf 的默认配置。 1234567891011121314eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/spring: application: name: product-view-service-feign thymeleaf: cache: false prefix: classpath:/templates/ suffix: .html encoding: UTF-8 content-type: text/html mode: HTML5 启动并访问注册中心Eureka:刷新访问：http://127.0.0.1:8761/。 启动并访问视图微服务product-view-service-feign:刷新访问：http://127.0.0.1:8012/products。 调用图：如图所示： 首先数据微服务和视图微服务都被 eureka 管理起来了。 数据服务是由两个实例的集群组成的，端口分别是 8001 ， 8002 视图微服务通过 注册中心调用微服务， 然后负载均衡到 8001 或者 8002 端口的应用上。","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"SpringCloud系列4-视图微服务-RIBBON","date":"2021-10-06T06:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列4-视图微服务-RIBBON/","text":"Ribbon 概念访问前面注册好的数据微服务, springcloud 提供了两种方式: Ribbon: 是使用 restTemplate 进行调用，并进行客户端负载均衡。 Feign: 是对 Ribbon的封装，调用起来更简单。 什么是客户端负载均衡:在前面注册数据微服务里，注册了8001和8002两个微服务， Ribbon会从注册中心获知这个信息，然后由 Ribbon 这个客户端自己决定是调用哪个，这个就叫做客户端负载均衡。 创建子项目: product-view-service-ribbonpom.xml包含以下jar: spring-cloud-starter-netflix-eureka-client: eureka 客户端 spring-boot-starter-web： springmvc spring-boot-starter-thymeleaf： thymeleaf 做服务端渲染，(前后端分离项目不用配置)。 12345678910111213141516171819202122232425262728293031&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;spring-cloud-parent&lt;/artifactId&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-parent/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;product-view-service-ribbon&lt;/artifactId&gt; &lt;name&gt;product-view-service-ribbon&lt;/name&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; Ribbon 客户端Ribbon客户端: 通过restTemplate 访问 http://PRODUCT-DATA-SERVICE/products,而 product-data-service既不是域名也不是ip地址，而是数据服务在eureka 注册中心的名称. 注意: 这里只是指定了要访问的 微服务名称，但是并没有指定端口号到底是8001, 还是8002. 12345678910111213141516171819package cn.peach.client;import cn.peach.pojo.Product;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Component;import org.springframework.web.client.RestTemplate;import java.util.List;@Componentpublic class ProductClientRibbon &#123; @Autowired RestTemplate restTemplate; public List&lt;Product&gt; listProdcuts() &#123; return restTemplate.getForObject(&quot;http://PRODUCT-DATA-SERVICE/products&quot;,List.class); &#125;&#125; Java code: 注意：这里忽略controller、 service、 repository, html层的代码，只列出重要部分代码，如需了解详情可参阅以下地址获取代码：https://github.com/taoliu-hub/spring-cloud-angular11/tree/main/spring-cloud. 服务类: ProductServiceImpl 12345678910111213141516171819202122package cn.peach.service.impl;import cn.peach.client.ProductClientRibbon;import cn.peach.pojo.Product;import cn.peach.service.ProductService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import java.util.List;@Servicepublic class ProductServiceImpl implements ProductService &#123; @Autowired ProductClientRibbon productClientRibbon; @Override public List&lt;Product&gt; listProducts() &#123; return productClientRibbon.listProdcuts(); &#125;&#125; 启动类，注解多了个 @EnableDiscoveryClient，表示用于发现eureka 注册中心的微服务, 启动类，多了个 RestTemplate，就表示用 restTemplate 这个工具来做负载均衡, 考虑到要做集群。 自己输入端口，推荐 80010，8002，8003. 1234567891011121314151617181920212223import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.EnableEurekaClient;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.context.annotation.Bean;import org.springframework.cloud.client.loadbalancer.LoadBalanced;import org.springframework.web.client.RestTemplate;@SpringBootApplication@EnableEurekaClient@EnableDiscoveryClientpublic class ProductViewServiceRibbonApplication &#123; public static void main( String[] args ) &#123; SpringApplication.run(ProductDataServiceApplication.class, args); &#125; @Bean @LoadBalanced RestTemplate restTemplate() &#123; return new RestTemplate(); &#125;&#125; 配置application.yml配置类，指定了 eureka server 的地址，以及自己的名称。 另外是一些 thymeleaf 的默认配置。 1234567891011121314eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/spring: application: name: product-view-service-ribbon thymeleaf: cache: false prefix: classpath:/templates/ suffix: .html encoding: UTF-8 content-type: text/html mode: HTML5 启动并访问注册中心Eureka:刷新访问：http://127.0.0.1:8761/。 启动并访问视图微服务product-view-service-ribbon:刷新访问：http://127.0.0.1:8010/products。 调用图：如图所示： 首先数据微服务和视图微服务都被 eureka 管理起来了。 数据服务是由两个实例的集群组成的，端口分别是 8001 ， 8002 视图微服务通过 注册中心调用微服务， 然后负载均衡到 8001 或者 8002 端口的应用上。","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"SpringCloud系列3-注册数据微服务","date":"2021-10-06T05:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列3-注册数据微服务/","text":"创建子项目: product-data-service注意：若前面父子(聚合)项目创建了数据微服务，可直接更新此微服务。修改 pom.xml 为如下： spring-cloud-starter-netflix-eureka-client 表示这是个 eureka 客户端。 spring-boot-starter-web: 表示这是个web服务，会提供控制层1234567891011121314151617181920212223242526&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;spring-cloud-parent&lt;/artifactId&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-parent/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;product-data-service&lt;/artifactId&gt; &lt;name&gt;product-data-service&lt;/name&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 启动类ProductDataServiceApplication 启动类， 考虑到要做集群。 自己输入端口，推荐 8001，8002，8003. 注意：这里忽略controller、 service、 repository, html层的代码，只列出重要部分代码，如需了解详情可参阅以下地址获取代码：https://github.com/taoliu-hub/spring-cloud-angular11/tree/main/spring-cloud. 123456789101112131415package cn.peach;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.EnableEurekaClient;@SpringBootApplication@EnableEurekaClientpublic class ProductDataServiceApplication&#123; public static void main( String[] args ) &#123; SpringApplication.run(ProductDataServiceApplication.class, args); &#125;&#125; 配置application.yml 设置微服务的名称： product-data-service 设置注册中心的地址： http://localhost:8761/eureka/, 与eureka-server中的配置 application.yml一致。 12345678910# server:# port: 因为会启动多个 product-data-service, 所以端口号由用户自动设置，推荐 8001,8002,8003 spring: application: name: product-data-serviceeureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/ 启动并访问注册中心Eureka:刷新访问：http://127.0.0.1:8761/。 补充(上图红色信息)： EMERGENCY! EUREKA MAY BE INCORRECTLY CLAIMING INSTANCES ARE UP WHEN THEY’RE NOT. RENEWALS ARE LESSER THAN THRESHOLD AND HENCE THE INSTANCES ARE NOT BEING EXPIRED JUST TO BE SAFE. 上面这句话意思是，Eureka可能会声明已经不存在的实例。刷新数小于阈值时，为了安全起见不会剔除过期实例。 Eureka的默认阈值为：85% 比如目前有10个微服务，只有8个有心跳反应时，（8&#x2F;10&#x3D;80%&lt;85%）Eureka就会开启保护机制，过期的实例不会立马剔除。并且出这个紧急警告，在搭建Eureka Server时，比如我们搭建了2个Eureka Server，并且禁止自注册，Eureka Server自身算一个服务，那么其中任意一个Eureka，只能获得一个心跳，1&#x2F;2&#x3D;50%。那么也会出现这个警告。 当不想有这个红色警告是，本机自测可以关闭Eureka保护配置。生产环境下不要关。在application.yml文件中配置：12server: enable-self-preservation: false","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"SpringCloud系列2-服务注册中心","date":"2021-10-06T04:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列2-服务注册中心/","text":"创建子项目: eureka-serverpom.xml ，增加 spring-cloud-starter-netflix-eureka-server jar 包 12345678910111213141516171819202122&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;spring-cloud-parent&lt;/artifactId&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-parent/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;eureka-server&lt;/artifactId&gt; &lt;name&gt;eureka-server&lt;/name&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 启动类: EurekaServerApplication EurekaServer，它扮演的角色是注册中心，用于注册各种微服务，以便于其他微服务找到和访问。 EurekaServer 本身就是个 Springboot 微服务, 所以它有 @SpringBootApplication 注解。 @EnableEurekaServer 表示这是个 EurekaServer 。完整代码：123456789101112131415161718192021package cn.peach;import cn.hutool.core.util.NetUtil;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.boot.builder.SpringApplicationBuilder;import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;@SpringBootApplication@EnableEurekaServerpublic class EurekaServerApplication&#123; public static void main(String[] args) &#123; //8761 这个端口是默认的，就不要修改了，后面的子项目，都会访问这个端口。 int port = 8761; if(!NetUtil.isUsableLocalPort(port)) &#123; System.err.printf(&quot;端口%d被占用了，无法启动%n&quot;, port ); System.exit(1); &#125; new SpringApplicationBuilder(EurekaServerApplication.class).properties(&quot;server.port=&quot; + port).run(args); &#125;&#125; 配置application.yml 设置微服务的名称： eureka-server hostname: localhost 表示主机名称。 registerWithEureka：false. 表示是否注册到服务器。 因为它本身就是服务器，所以就无需把自己注册到服务器了。 fetchRegistry: false. 表示是否获取服务器的注册信息，和上面同理，这里也设置为 false。 defaultZone： http:&#x2F;&#x2F;${eureka.instance.hostname}:${server.port}&#x2F;eureka&#x2F; 自己作为服务器，公布出来的地址。 比如后续某个微服务要把自己注册到 eureka server, 那么就要使用这个地址： http://localhost:8761/eureka/ 123456789101112eureka: instance: hostname: localhost client: registerWithEureka: false fetchRegistry: false serviceUrl: defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ spring: application: name: eureka-server 启动并访问注册中心Eureka:运行 EurekaServerApplication，并访问：http://127.0.0.1:8761/，默认端口号为：8761。","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"SpringCloud系列1-父子(聚合)项目","date":"2021-10-06T03:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列1-父子(聚合)项目/","text":"SpringCloud代码结构 创建父项目: spring-cloud-parent修改pom： 1&lt;packaging&gt;pom&lt;/packaging&gt; 注意： 父项目只有pom.xml文件， packaging值为pom. 完整代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.6.RELEASE&lt;/version&gt; &lt;!-- 踩坑:版本不对会导致Feign连接不上，亲测其它版本, 2.3.3.RELEASE version. --&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-parent&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;spring-cloud-parent&lt;/name&gt; &lt;description&gt;spring-cloud-parent project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Finchley.SR2&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt;&lt;/project&gt; 创建子项目: product-data-service修改pom： 123456789&lt;parent&gt; &lt;artifactId&gt;spring-cloud-parent&lt;/artifactId&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-parent/pom.xml&lt;/relativePath&gt;&lt;/parent&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;artifactId&gt;product-data-service&lt;/artifactId&gt;&lt;name&gt;product-data-service&lt;/name&gt;","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"JAVA数据结构和算法","date":"2021-10-06T02:08:20.000Z","path":"blog/数据结构和算法/JAVA数据结构和算法/","text":"JAVA数据结构和算法： 数据结构分类：线性结构和非线性结构： 问题一：什么是线性和非线性； 个人的理解是：数据结构中线性结构指的是数据元素之间存在着“一对一”的线性关系的数据结构；线性结构包括：数组，链表，队列，栈；非线性结构包括：树，图，表； 详解：一.线性结构 1.数组特点：我们都知道数组中的元素在内存中连续存储的，可以根据是下标快速访问元素，因此，查询速度很快，然而插入和删除时，需要对元素移动空间，比较慢。数组使用场景：频繁查询，很少增加和删除的情况。 2.链表特点：元素可以不连续内存中，是以索引将数据联系起来的，当查询元素的时候需要从头开始查询，所以效率比较低，然而添加和删除的只需要修改索引就可以了链表使用场景：少查询，需要频繁的插入或删除情况 3.队列特点：先进先出，队列使用场景：多线程阻塞队列管理非常有用 4.栈特点：先进后出，就像一个箱子，栈使用场景：实现递归以及表示式 5.数组与链表的区别数组连续，链表不连续（从数据存储形式来说）数组内存静态分配，链表动态分配数组查询复杂度O(1)，链表查询复杂度O(n)数组添加或删除，复杂度O(n),链表添加删除，复杂度O(1)数组从栈中分配内存。链表从堆中分配内存。 补充：时间复杂度O(1), O(n), O(logn), O(nlogn)指什么 描述算法复杂度时,常用o(1), o(n), o(logn), o(nlogn)表示对应算法的时间复杂度，是算法的时空复杂度的表示。不仅仅用于表示时间复杂度，也用于表示空间复杂度。O后面的括号中有一个函数，指明某个算法的耗时&#x2F;耗空间与数据增长量之间的关系。其中的n代表输入数据的量。 O(1)： 是最低的时空复杂度了，代表耗时&#x2F;耗空间与输入数据大小无关，无论输入数据增大多少倍，耗时&#x2F;耗空间都不变。 哈希算法就是典型的O(1)时间复杂度，无论数据规模多大，都可以在一次计算后找到目标（不考虑冲突的话） O(n)： 代表数据量增大几倍，耗时也增大几倍。比如常见的遍历算法。 O(n^2)： 代表数据量增大n倍时，耗时增大n的平方倍，这是比线性更高的时间复杂度。比如冒泡排序，就是典型的O(n^2)的算法，对n个数排序，需要扫描n×n次。 O(logn)： 代表当数据增大n倍时，耗时增大logn倍（这里的log是以2为底的，比如，当数据增大256倍时，耗时只增大8倍，是比线性还要低的时间复杂度）。二分查找就是O(logn)的算法，每找一次排除一半的可能，256个数据中查找只要找8次就可以找到目标。 O(nlogn)： 代表n乘以logn，当数据增大256倍时，耗时增大256*8&#x3D;2048倍。这个复杂度高于线性低于平方。归并排序就是O(nlogn)的时间复杂度。 问题二：c1）插入排序（直接插入排序、希尔排序） 2）交换排序（冒泡排序、快速排序）3）选择排序（直接选择排序、堆排序）4）归并排序5）分配排序（基数排序）特点:所需辅助空间最多：归并排序所需辅助空间最少：堆排序平均速度最快：快速排序不稳定：快速排序，希尔排序，堆排序 直接插入排序 基本思想：在要排序的一组数中，假设前面(n-1)[n&gt;&#x3D;2] 个数已经是排好顺序的，现在要把第n 个数插到前面的有序数中，使得这 n个数也是排好顺序的。如此反复循环，直到全部排好顺序 12345678910111213141516/** * 插入排序法 * * @param datas */ public static int[] sortInsert(int[] datas) &#123; for (int i = 1; i &lt; datas.length; i++) &#123; int j = i - 1; AlgorithmUtil.temp = datas[i]; for (; j &gt;= 0 &amp;&amp; AlgorithmUtil.temp &lt; datas[j]; j--) &#123; datas[j + 1] = datas[j]; &#125; datas[j + 1] = AlgorithmUtil.temp; &#125; return datas; &#125; 简单选择排序 基本思想：在要排序的一组数中，选出最小的一个数与第一个位置的数交换；然后在剩下的数当中再找最小的与第二个位置的数交换，如此循环到倒数第二个数和最后一个数比较为止。 1234567891011121314151617/** * 选择排序 * * @return */ public static int[] sortSelect(int[] datas) &#123; for (int i = 0; i &lt; datas.length; i++) &#123; int index = i; for (int j = i + 1; j &lt; datas.length; j++) &#123; if (datas[j] &lt; datas[index]) index = j; &#125; if (i != index) AlgorithmUtil.swap(datas, i, index); &#125; return datas; &#125; 冒泡排序 基本思想：在要排序的一组数中，对当前还未排好序的范围内的全部数，自上而下对相邻的两个数依次进行比较和调整，让较大的数往下沉，较小的往上冒。即：每当两相邻的数比较后发现它们的排序与排序要求相反时，就将它们互换。 1234567891011121314/** * 冒泡排序 * * @return */ public static int[] sortBubble(int[] datas) &#123; for (int i = 0; i &lt; datas.length - 1; i++) &#123; for (int j = 0; j &lt; datas.length - 1 - i; j++) &#123; if (datas[j] &gt; datas[j + 1]) AlgorithmUtil.swap(datas, j, j + 1); &#125; &#125; return datas; &#125; 快速排序 基本思想：选择一个基准元素,通常选择第一个元素或者最后一个元素,通过一趟扫描，将待排序列分成两部分,一部分比基准元素小,一部分大于等于基准元素,此时基准元素在其排好序后的正确位置,然后再用同样的方法递归地排序划分的两部分。 1234567891011121314151617181920212223242526272829303132/** * 快速排序；分割数组 * * @param datas */ public static int QuickPartition(int[] datas, int left, int right) &#123; int pivot = datas[left]; while (left &lt; right) &#123; while (left &lt; right &amp;&amp; datas[right] &gt;= pivot) --right; datas[left] = datas[right]; // 将比枢轴小的元素移到低端，此时right位相当于空，等待低位比pivotkey大的数补上 while (left &lt; right &amp;&amp; datas[left] &lt;= pivot) ++left; datas[right] = datas[left]; // 将比枢轴大的元素移到高端，此时left位相当于空，等待高位比pivotkey小的数补上 &#125; datas[left] = pivot; // 当left == right，完成一趟快速排序，此时left位相当于空，等待pivotkey补上 return left; &#125; /** * 快速排序；递归返回数组 * * @param datas */ public static int[] sortQuick(int[] datas, int left, int right) &#123; if (left &lt; right) &#123; int data = QuickPartition(datas, left, right); sortQuick(datas, left, data - 1); sortQuick(datas, data + 1, right); &#125; return datas; &#125; 1.冒泡算法，2.选择算法，3.快速算法。4.插入算法，5.希尔算法，6.堆算法 基本思想：在要排序的一组数中，选出最小的一个数与第一个位置的数交换；然后在剩下的数当中再找最小的与第二个位置的数交换，如此循环到倒数第二个数和最后一个数比较为止。 123456789101112131415161718192021222324252627282930313233343536public class AlgorithmUtil &#123; public static int temp,index = 0; /** * 临时值交换 * * @param datas * 数组 * @param i * @param j */ public static void swap(int[] datas, int i, int j) &#123; temp = datas[i]; datas[i] = datas[j]; datas[j] = temp; &#125; /** * 扩充数组长度 * * @param datas * @param value * @return */ public static int[] expandArray(int[] datas, int value) &#123; if (datas.length &lt;= index) &#123; int[] arrays = new int[datas.length * 2]; System.arraycopy(datas, 0, arrays, 0, datas.length); datas = arrays; &#125; datas[index] = value; index++; return datas; &#125; &#125;","tags":[{"name":"JAVA数据结构和算法","slug":"JAVA数据结构和算法","permalink":"http://example.com/tags/JAVA%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/"}],"categories":[{"name":"数据结构和算法","slug":"数据结构和算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/"}]},{"title":"SpringCloud介绍","date":"2021-10-06T02:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud/","text":"基础知识介绍：单体架构系统：单体架构就是所有功能，都放在一个应用里。 好处：便于开发，测试，部署也很方便，直接打成一个 jar 或者 war, 就什么都好了。 弊端：要体现在高访问，高并发的上限是固定的。 比如一个单体架构，能够承受 1000次访问&#x2F;秒。 但是访问量达到 2000次&#x2F;秒的时候，就会非常卡顿，严重影响业务，并且仅仅依靠单体架构本身，很难突破这个瓶颈了。 集群和分布式：既然单体架构会有性能上的瓶颈，那么总要解决呀。 解决办法通常就是采用集群和分布式来做。 集群：指一组相互独立的计算机，通过高速的网络组成一个计算机系统。服务器集群就是指将很多服务器集中起来一起进行同一种服务，在客户端看来就像是只有一个服务器。 集群的特点和优势: 高性能 性价比 可伸缩性集群的分类 负载均衡集群（Load balancing clusters）简称LBC 高可用性集群（High-availability clusters）简称HAC 高性能计算集群（High-perfomance clusters）简称HPC 分布式：指将不同的业务分布在不同的地方，而集群指的是将几台服务器集中在一起，实现同一业务。分布式中的每一个节点，都可以做集群，而集群并不一定就是分布式的。 分布式一致性：分布式系统中，一个问题是负载均衡，另外一个问题就是数据的一致性。 在分布式集群中，很难保障数据的一致性。在以往的单节点服务中，通常使用锁来实现，当发生并发冲突时 通过对锁的持有获得对象的操作权，从而保证数据在同一时刻只允许被一个请求操作。但是在集群中，若同样采用锁的机制，那么需要一台节点用来管理分配锁，当其他节点进行请求前，首先去获取锁从而获得执行权。但是这样会产生单节点问题，即若管理锁的节点down掉，那么整个集群将无法工作。同时，由于锁的机制会使整个集群变成串行化单节点的形式，失去了集群的意义。 分布式和集群的关系： 根据分布式的介绍看出，其主要的功能是用了将我们的系统模块化，将系统进行解耦的，方便我们的维护和开发的，但是其并不能解决我们的并发问题，也无法保证我们的系统在服务器宕机后的正常运转。 集群就恰好弥补了分布式的缺陷，集群就是多个服务器处理相同的业务，这在一方面可以解决或者说改善我们系统的并发问题，一方面可以解决我们服务器如果出现一定数量的宕机后，系统仍然可以正常运转。 SpringCloud介绍：SpringCloud 就是一套工具。 Spring Cloud 并不是一个项目，而是一组项目的集合。包含了很多的子项目，每一个子项目都是一种微服务开发过程中遇到的问题的一种解决方案。它利用 Spring Boot的开发便利性巧妙地简化了分布式系统基础设施的开发，如服务发现注册、配置中心、消息总线、负载均衡、断路器、数据监控等，都可以用 Spring Boot的开发风格做到一键启动和部署。Spring Cloud并没有重复制造轮子，它只是将目前各家公司开发的比较成熟、经得起实际考验的服务框架组合起来，通过Spring Boot风格进行再封装屏蔽掉了复杂的配置和实现原理，最终给开发者留出了一套简单易懂、易部署和易维护的分布式系统开发工具包。 子项目介绍: Spring Cloud Config：集中配置管理工具，分布式系统中统一的外部配置管理，可以支持客户端配置的刷新及加密、解密操作, 可以让你把配置放到远程服务器，目前支持本地存储、Git 以及 Subversion。 Spring Cloud Netflix：针对多种 Netflix 组件提供的开发工具包，其中包括 Eureka、Hystrix、Ribbon、Feign、Zuul、Archaius 等组件, 如下: Eureka：服务治理组件，包括服务端的注册中心和客户端的服务发现机制； Hystrix：服务容错组件，实现了断路器模式，为依赖服务的出错和延迟提供了容错能力； Ribbon：负载均衡的服务调用组件，具有多种负载均衡调用策略； Feign：基于Ribbon和Hystrix的声明式服务调用组件； Zuul：API网关组件，对请求提供路由及过滤功能； Archaius：基于java的配置管理类库，主要用于多配置存储的动态获取。 Spring Cloud Bus：事件、消息总线，用于在集群（例如，配置变化事件）中传播状态变化，可与 Spring Cloud Config 联合实现热部署。 Spring Cloud Consul：封装了 Consul 操作，consul 是一个服务发现与配置工具，与 Docker 容器可以无缝集成。 Spring Cloud Security ：安全工具包，对Zuul代理中的负载均衡OAuth2客户端及登录认证进行支持。 Spring Cloud Sleuth：日志收集工具包，封装了 Dapper，Zipkin 和 HTrace 操作. Spring Cloud 应用的分布式跟踪实现。 Spring Cloud Stream：数据流操作开发包，封装了与 Redis，Rabbit、Kafka 等发送接收消息，实现的消息微服务。 Spring Cloud Task：用于快速构建短暂、有限数据处理任务的微服务框架，用于向应用中添加功能性和非功能性的特性。 Spring Cloud Zookeeper：基于 ZooKeeper 的服务发现与配置管理组件。 Spring Cloud Gateway：API网关组件，对请求提供路由及过滤功能, Spring Cloud 网关相关的整合实现。 Spring Cloud Aws：用于简化整合 Amazon Web Service 的组件。 Spring Cloud Cli：基于 Spring Boot CLI，可以让你以命令行方式快速建立云组件。 Spring Cloud Commons：服务发现、负载均衡、熔断机制这种模式为 Spring Cloud 客户端提供了一个通用的抽象层。 Spring Cloud Contract：Spring Cloud Contract是一个总体项目，其中包含帮助用户成功实施消费者驱动合同方法的解决方案(契约测试)。 Spring Cloud Cloudfoundry：通过 Oauth2 协议绑定服务到 CloudFoundry，CloudFoundry 是 VMware 推出的开源 PaaS 云平台。 Spring Cloud OpenFeign：基于Ribbon和Hystrix的声明式服务调用组件，可以动态创建基于Spring MVC注解的接口实现用于服务调用，在Spring Cloud 2.0中已经取代Feign成为了一等公民。","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"消息队列","date":"2021-03-23T02:00:20.000Z","path":"blog/工具和中间件/消息队列/消息队列/","text":"什么是消息中间件呢？以公众号为例，如果某用户订阅（关注）了这个公众号，每当管理员发布新文章的时候，都可以在这个公众号得到通知，这就是一种广播订阅模式。 公众号如何实现这一点呢？ 可以通过 消息中间件 来轻松实现。 管理员把最新的教程信息 发给 消息中间件服务器， 用户手机上的微信里的 消息中间件客户端，就会自动去把消息获取出来显示，这样管理员就达到了文章广播的效果了。 消息队列的作用： 应用耦合：多应用间通过消息队列对同一消息进行处理，避免调用接口失败导致整个过程失败； 异步处理：多应用对消息队列中同一消息进行处理，应用间并发处理消息，相比串行处理，减少处理时间； 限流削峰：广泛应用于秒杀或抢购活动中，避免流量过大导致应用系统挂掉的情况； 消息驱动的系统：系统分为消息队列、消息生产者、消息消费者，生产者负责产生消息，消费者(可能有多个)负责对消息进行处理； 选择消息队列要满足以下几个条件： 开源 流行 兼容性强 消息队列需要： 消息的可靠传递：确保不丢消息； 性能：具备足够好的性能，能满足绝大多数场景的性能要求。 Cluster：支持集群，确保不会因为某个节点宕机导致服务不可用，当然也不能丢消息； 实现选择：消息中间件有很多种，如 Activemq, Rabbitmq, RocketMQ, Kafka 等等 几种常见MQ的对比:","tags":[],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"}]},{"title":"AOP创建代理与调用","date":"2020-10-16T11:08:20.000Z","path":"blog/Spring/AOP创建代理与调用/","text":"创建代理给Bean创建代理的地方有两个，存在循环依赖的Bean会调用实现了**SmartInstantiationAwareBeanPostProcessor接口的getEarlyBeanReference方法，即Bean的生命周期中第四次调用后置处理器的地方，给有AOP代理的且产生循环依赖且先被加载的对象创建AOP代理。若在该处已经设置了动态代理会将beanName加入到earlyProxyReferences集合中，防止第八次调用后置处理器时重复添加动态代理**。 1234567public abstract class AbstractAutoProxyCreator extends ProxyProcessorSupport implements SmartInstantiationAwareBeanPostProcessor, BeanFactoryAware &#123; public Object getEarlyBeanReference(Object bean, String beanName) throws BeansException &#123; Object cacheKey = getCacheKey(bean.getClass(), beanName); this.earlyProxyReferences.put(cacheKey, bean); return wrapIfNecessary(bean, beanName, cacheKey); &#125;&#125; 若Bean有AOP代理，但不存在循环依赖或存在循环依赖但后被加载，则AOP代理是在第八次调用后置处理器时，给该Bean创建动态代理的。 1234567891011public abstract class AbstractAutoProxyCreator extends ProxyProcessorSupport implements SmartInstantiationAwareBeanPostProcessor, BeanFactoryAware &#123; public Object postProcessAfterInitialization(@Nullable Object bean, String beanName) throws BeansException &#123; if (bean != null) &#123; Object cacheKey = getCacheKey(bean.getClass(), beanName);// 获取缓存key if (this.earlyProxyReferences.remove(cacheKey) != bean) &#123;// 若之前循环依赖已创建的动态代理则不再创建且移除 return wrapIfNecessary(bean, beanName, cacheKey);// 若存在动态代理将返回创建动态代理后实例 &#125; &#125; return bean; &#125;&#125; 这两个地方其实都是调用的**wrapIfNecessary方法为加载的Bean创建动态代理的，advisedBeans中对于AOP基础类或被标记跳过的类会直接返回原始对象。shouldSkip在切面解析时就已经对所有切面类进行了解析，这里会走缓存。接着找到当前Bean的所有匹配切点规则的advisor，然后对当前Bean创建代理对象，不管是否创建代理对象都将其缓存到advisedBeans**中。","tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://example.com/tags/SpringBoot/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}]},{"title":"AOP切面类解析","date":"2020-10-16T03:08:20.000Z","path":"blog/Spring/AOP切面类解析/","text":"Spring AOP是通过给一个类加上 @Aspect注解来定义一个切面类，定义一个 Pointcut 方法，最后定义一系列的增强方法，这样就完成一个对象的切面操作。 通过 @EnableAspectJAutoProxy注解开启AOP切面，该注解类上 @Import(AspectJAutoProxyRegistrar.class) 注解中 AspectJAutoProxyRegistrar 实现了 ImportBeanDefinitionRegistrar ，其会通过 registerBeanDefinitions 方法为容器导入为Bean创建代理 beanName 为 internalAutoProxyCreator 的关键 beanDefinition 。type为 AnnotationAwareAspectJAutoProxyCreator 。 @Import 中 ImportBeanDefinitionRegistrar 接口 registerBeanDefinitions 方法调用时机是在 invokeBeanFactoryPostProcessors 的 invokeBeanFactoryPostProcessors 中解析完配置类后调用 ConfigurationClassBeanDefinitionReader 的 loadBeanDefinitions 方法，即在Bean实例化之前。 123456789101112131415161718class AspectJAutoProxyRegistrar implements ImportBeanDefinitionRegistrar &#123; @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; // 注册名字internalAutoProxyCreator的AnnotationAwareAspectJAutoProxyCreator AopConfigUtils.registerAspectJAnnotationAutoProxyCreatorIfNecessary(registry); // 获得注解的属性 AnnotationAttributes enableAspectJAutoProxy = AnnotationConfigUtils.attributesFor(importingClassMetadata, EnableAspectJAutoProxy.class); // 根据其中的proxyTargetClass/exposeProxy设置beanDefinition属性 if (enableAspectJAutoProxy != null) &#123; if (enableAspectJAutoProxy.getBoolean(&quot;proxyTargetClass&quot;)) &#123; AopConfigUtils.forceAutoProxyCreatorToUseClassProxying(registry); &#125; if (enableAspectJAutoProxy.getBoolean(&quot;exposeProxy&quot;)) &#123; AopConfigUtils.forceAutoProxyCreatorToExposeProxy(registry); &#125; &#125; &#125;&#125; 12345678910111213141516171819202122232425262728public abstract class AopConfigUtils &#123; public static BeanDefinition registerAspectJAnnotationAutoProxyCreatorIfNecessary(BeanDefinitionRegistry registry) &#123; return registerAspectJAnnotationAutoProxyCreatorIfNecessary(registry, null); &#125; public static BeanDefinition registerAspectJAnnotationAutoProxyCreatorIfNecessary(BeanDefinitionRegistry registry, @Nullable Object source) &#123; return registerOrEscalateApcAsRequired(AnnotationAwareAspectJAutoProxyCreator.class, registry, source); &#125; private static BeanDefinition registerOrEscalateApcAsRequired(Class&lt;?&gt; cls, BeanDefinitionRegistry registry, @Nullable Object source) &#123; Assert.notNull(registry, &quot;BeanDefinitionRegistry must not be null&quot;); if (registry.containsBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME)) &#123; BeanDefinition apcDefinition = registry.getBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME); if (!cls.getName().equals(apcDefinition.getBeanClassName())) &#123; int currentPriority = findPriorityForClass(apcDefinition.getBeanClassName()); int requiredPriority = findPriorityForClass(cls); if (currentPriority &lt; requiredPriority) &#123; apcDefinition.setBeanClassName(cls.getName()); &#125; &#125; return null; &#125; RootBeanDefinition beanDefinition = new RootBeanDefinition(cls); beanDefinition.setSource(source); beanDefinition.getPropertyValues().add(&quot;order&quot;, Ordered.HIGHEST_PRECEDENCE); beanDefinition.setRole(BeanDefinition.ROLE_INFRASTRUCTURE); registry.registerBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME, beanDefinition); return beanDefinition; &#125;&#125; 在 finishBeanFactoryInitialization第一个Bean创建时通过 resolveBeforeInstantiation第一次调用后置处理器时，调用 AnnotationAwareAspectJAutoProxyCreator 超类 AbstractAutoProxyCreator 中的 postProcessBeforeInstantiation 方法时，对所有的AOP切面类进行解析并将解析后的 Advisors列表缓存。 12345678910111213141516171819202122232425262728public abstract class AbstractAutoProxyCreator extends ProxyProcessorSupport implements SmartInstantiationAwareBeanPostProcessor, BeanFactoryAware &#123; public Object postProcessBeforeInstantiation(Class&lt;?&gt; beanClass, String beanName) throws BeansException &#123; Object cacheKey = getCacheKey(beanClass, beanName); // 构建缓存key // 没有beanName或没有包含在targetSourcedBeans中，一般都不会包含，因为targetSource需要手动设置，一般情况不会设置 if (!StringUtils.hasLength(beanName) || !this.targetSourcedBeans.contains(beanName)) &#123; if (this.advisedBeans.containsKey(cacheKey)) &#123; // 被解析过 直接返回 return null; &#125; // 判断是不是基础的bean即是不是切面类、通知、切点等，判断是不是应该跳过 默认false，切面解析也在其中 if (isInfrastructureClass(beanClass) || shouldSkip(beanClass, beanName)) &#123; this.advisedBeans.put(cacheKey, Boolean.FALSE); return null; &#125; &#125; // TargetSource代理逻辑的实现，在创建代理时默认是SingletonTargetSource，故若指定了TargetSource说明有自己的代理逻辑实现，在这就直接创建代理 TargetSource targetSource = getCustomTargetSource(beanClass, beanName); if (targetSource != null) &#123; if (StringUtils.hasLength(beanName)) &#123; this.targetSourcedBeans.add(beanName); &#125; Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(beanClass, beanName, targetSource); Object proxy = createProxy(beanClass, beanName, specificInterceptors, targetSource); this.proxyTypes.put(cacheKey, proxy.getClass()); return proxy; &#125; return null; &#125;&#125; 通过 isInfrastructureClass 判断该类是否是切面类、通知、切点等，判断逻辑就是判断当前正在创建的类是否为 Advice 、 Pointcut 、 Advisor 、 AopInfrastructureBean 的子类，若是则直接跳过解析。或若该类上有 @Aspect注解且不是一个被 AspectJ编译过的类也跳过解析。 123456789101112131415161718192021222324252627public class AnnotationAwareAspectJAutoProxyCreator extends AspectJAwareAdvisorAutoProxyCreator &#123; protected boolean isInfrastructureClass(Class&lt;?&gt; beanClass) &#123; return (super.isInfrastructureClass(beanClass) || (this.aspectJAdvisorFactory != null &amp;&amp; this.aspectJAdvisorFactory.isAspect(beanClass))); &#125;&#125;public abstract class AbstractAutoProxyCreator extends ProxyProcessorSupport implements SmartInstantiationAwareBeanPostProcessor, BeanFactoryAware &#123; private static final String AJC_MAGIC = &quot;ajc$&quot;; protected boolean isInfrastructureClass(Class&lt;?&gt; beanClass) &#123; // 若当前正在创建的Bean的class是Advice PointCut Advisor AopInfrastructureBean，直接跳过不需要解析 boolean retVal = Advice.class.isAssignableFrom(beanClass) || Pointcut.class.isAssignableFrom(beanClass) || Advisor.class.isAssignableFrom(beanClass) || AopInfrastructureBean.class.isAssignableFrom(beanClass); return retVal; &#125; public boolean isAspect(Class&lt;?&gt; clazz) &#123; // 有没有切面注解 &amp;&amp; 没有被AspectJ编译过 return (hasAspectAnnotation(clazz) &amp;&amp; !compiledByAjc(clazz)); &#125; private boolean hasAspectAnnotation(Class&lt;?&gt; clazz) &#123; return (AnnotationUtils.findAnnotation(clazz, Aspect.class) != null); &#125; private boolean compiledByAjc(Class&lt;?&gt; clazz) &#123; for (Field field : clazz.getDeclaredFields()) &#123; if (field.getName().startsWith(AJC_MAGIC)) &#123; return true; // 至少一个属性前缀为&quot;ajc$&quot; &#125; &#125; return false; &#125;&#125; shouldSkip 中的 findCandidateAdvisors() 会解析出所有的 Advisor ，这里的 AspectJPointcutAdvisor 是 xml 中advisor解析的对象，若aspect是当前beanName就说明当前bean是切面类则跳过。 123456789101112public class AspectJAwareAdvisorAutoProxyCreator extends AbstractAdvisorAutoProxyCreator &#123; protected boolean shouldSkip(Class&lt;?&gt; beanClass, String beanName) &#123; List&lt;Advisor&gt; candidateAdvisors = findCandidateAdvisors(); // 找到所有定义的候选Advisors for (Advisor advisor : candidateAdvisors) &#123; // AspectJPointcutAdvisor是xml&lt;aop:advisor解析的对象，若&lt;aop:aspect ref=&quot;beanName&quot;&gt;是当前beanName就说明当前bean是切面类则跳过。 if (advisor instanceof AspectJPointcutAdvisor &amp;&amp; ((AspectJPointcutAdvisor) advisor).getAspectName().equals(beanName)) &#123; return true; &#125; &#125; return super.shouldSkip(beanClass, beanName); &#125;&#125; 通过 buildAspectJAdvisors 去容器中获取所有切面信息保存到缓存中。 12345678910public class AnnotationAwareAspectJAutoProxyCreator extends AspectJAwareAdvisorAutoProxyCreator &#123; protected List&lt;Advisor&gt; findCandidateAdvisors() &#123; // 找出xml配置的Advisor、原生接口的AOP的Advisor、事务相关的advisor List&lt;Advisor&gt; advisors = super.findCandidateAdvisors(); if (this.aspectJAdvisorsBuilder != null) &#123; // 找出Aspect相关的信息之后封装为一个advisor advisors.addAll(this.aspectJAdvisorsBuilder.buildAspectJAdvisors()); &#125; return advisors; // 返回所有的通知 &#125;&#125; 关于 advisorRetrievalHelper 的初始化， AbstractAdvisorAutoProxyCreator 的父类 AbstractAutoProxyCreator 实现了 BeanFactoryAware 接口，而 AbstractAutoProxyCreator 是事务和 AOP 导入进来的后置处理器的顶级父类，在实例化AOP 和事务导入组件时会调用setBeanFactory的方法来注入Bean工厂，调用setBeanFactory会触发 initBeanFactory 的调用来实例化通知查找探测器。 1234567891011121314151617public abstract class AbstractAdvisorAutoProxyCreator extends AbstractAutoProxyCreator &#123; private BeanFactoryAdvisorRetrievalHelper advisorRetrievalHelper; protected List&lt;Advisor&gt; findCandidateAdvisors() &#123; // 通过通知者探测器帮助找到通知 Assert.state(this.advisorRetrievalHelper != null, &quot;No BeanFactoryAdvisorRetrievalHelper available&quot;); return this.advisorRetrievalHelper.findAdvisorBeans(); &#125; public void setBeanFactory(BeanFactory beanFactory) &#123; super.setBeanFactory(beanFactory); if (!(beanFactory instanceof ConfigurableListableBeanFactory)) &#123; throw new IllegalArgumentException(&quot;AdvisorAutoProxyCreator requires a ConfigurableListableBeanFactory: &quot; + beanFactory); &#125; initBeanFactory((ConfigurableListableBeanFactory) beanFactory); &#125; protected void initBeanFactory(ConfigurableListableBeanFactory beanFactory) &#123; this.advisorRetrievalHelper = new BeanFactoryAdvisorRetrievalHelperAdapter(beanFactory); &#125;&#125; 探测器字段 cachedAdvisorBeanNames 是用来缓存Advisor全类名，在第一个单实例bean实例化过程中把所有的advisor名称解析出来，若 cachedAdvisorBeanNames 为空则先获取容器中所有实现了Advisor接口的实现类，典型为事务注解@EnableTransactionManagement 导入 ProxyTransactionManagementConfiguration 配置类。 1234567891011121314151617181920212223242526272829303132333435public class BeanFactoryAdvisorRetrievalHelper &#123; public List&lt;Advisor&gt; findAdvisorBeans() &#123; // 探测器字段cachedAdvisorBeanNames是用来缓存Advisor全类名，在第一个单实例bean实例化过程中把该advisor名称解析出来 String[] advisorNames = this.cachedAdvisorBeanNames; if (advisorNames == null) &#123; advisorNames = BeanFactoryUtils.beanNamesForTypeIncludingAncestors(this.beanFactory, Advisor.class, true, false); this.cachedAdvisorBeanNames = advisorNames; &#125; if (advisorNames.length == 0) &#123; // 若在容器中没有找到，直接返回一个空的集合 return new ArrayList&lt;&gt;(); &#125; List&lt;Advisor&gt; advisors = new ArrayList&lt;&gt;(); for (String name : advisorNames) &#123; // 容器中找到了配置的BeanFactoryTransactionAttributeSourceAdvisor if (isEligibleBean(name)) &#123; // 判断其是不是一个合适的 if (this.beanFactory.isCurrentlyInCreation(name)) &#123; // BeanFactoryTransactionAttributeSourceAdvisor是不是正在创建的bean &#125; else &#123; // 不是的话 try &#123; //显示的调用getBean方法方法创建BeanFactoryTransactionAttributeSourceAdvisor返回去 advisors.add(this.beanFactory.getBean(name, Advisor.class)); &#125; catch (BeanCreationException ex) &#123; Throwable rootCause = ex.getMostSpecificCause(); if (rootCause instanceof BeanCurrentlyInCreationException) &#123; BeanCreationException bce = (BeanCreationException) rootCause; String bceBeanName = bce.getBeanName(); if (bceBeanName != null &amp;&amp; this.beanFactory.isCurrentlyInCreation(bceBeanName)) &#123; continue; &#125; &#125; throw ex; &#125; &#125; &#125; &#125; return advisors; &#125;&#125; 缓存字段 aspectNames 没有值，会在 AnnotationAwareAspectJAutoProxyCreator 注册之后，第一个单例执行后置处理器时触发解析切面的操作。这里获取的是Object类型的Bean的名称即获取所有的Bean。遍历解析Advisor的过程十分耗性能，解析后会加入了保存切面信息的缓存，事务模块的功能是直接去容器中获取Advisor类型的，选择范围小，且不消耗性能，故事务模块中没有加入缓存来保存事务相关的advisor。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public List&lt;Advisor&gt; buildAspectJAdvisors() &#123; // 用于保存切面的名称，该aspectNames是类级别的缓存，缓存已解析出的切面信息 List&lt;String&gt; aspectNames = this.aspectBeanNames; if (aspectNames == null) &#123; synchronized (this) &#123; // 加上同步锁， 防止多线程同时加载Aspect aspectNames = this.aspectBeanNames; if (aspectNames == null) &#123; // 双重检查加锁 List&lt;Advisor&gt; advisors = new ArrayList&lt;&gt;(); // 保存所有通知的集合 aspectNames = new ArrayList&lt;&gt;(); // 保存切面的名称的集合 // 从容器中获取所有Bean，再遍历，该过程十分耗性能，解析后会加入了保存切面信息的缓存 String[] beanNames = BeanFactoryUtils.beanNamesForTypeIncludingAncestors(this.beanFactory, Object.class, true, false); for (String beanName : beanNames) &#123; // 遍历从IOC容器中获取的所有bean的名称 if (!isEligibleBean(beanName)) continue; Class&lt;?&gt; beanType = this.beanFactory.getType(beanName); // 通过beanName去容器中获取到对应class对象 if (beanType == null) continue; if (this.advisorFactory.isAspect(beanType)) &#123; // 根据class对象判断是不是切面 aspectNames.add(beanName); // 是切面类，加入到缓存中 // 把beanName和class对象构建成为一个AspectMetadata AspectMetadata amd = new AspectMetadata(beanType, beanName); if (amd.getAjType().getPerClause().getKind() == PerClauseKind.SINGLETON) &#123; //构建切面注解的实例工厂 MetadataAwareAspectInstanceFactory factory = new BeanFactoryAspectInstanceFactory(this.beanFactory, beanName); // 真正的去获取通知对象 List&lt;Advisor&gt; classAdvisors = this.advisorFactory.getAdvisors(factory); if (this.beanFactory.isSingleton(beanName)) &#123; // 加入到缓存中 this.advisorsCache.put(beanName, classAdvisors); &#125; else &#123; this.aspectFactoryCache.put(beanName, factory); &#125; advisors.addAll(classAdvisors); &#125; else &#123; if (this.beanFactory.isSingleton(beanName)) &#123; throw new IllegalArgumentException(&quot;Bean with name &#x27;&quot; + beanName + &quot;&#x27; is a singleton, but aspect instantiation model is not singleton&quot;); &#125; MetadataAwareAspectInstanceFactory factory = new PrototypeAspectInstanceFactory(this.beanFactory, beanName); this.aspectFactoryCache.put(beanName, factory); advisors.addAll(this.advisorFactory.getAdvisors(factory)); &#125; &#125; &#125; this.aspectBeanNames = aspectNames; return advisors; &#125; &#125; &#125; if (aspectNames.isEmpty()) &#123; return Collections.emptyList(); &#125; // 真正的创建切面的时候，我们不需要去解析了而是直接去缓存中获取处 List&lt;Advisor&gt; advisors = new ArrayList&lt;&gt;(); for (String aspectName : aspectNames) &#123; List&lt;Advisor&gt; cachedAdvisors = this.advisorsCache.get(aspectName); if (cachedAdvisors != null) &#123; advisors.addAll(cachedAdvisors); &#125; else &#123; MetadataAwareAspectInstanceFactory factory = this.aspectFactoryCache.get(aspectName); advisors.addAll(this.advisorFactory.getAdvisors(factory)); &#125; &#125; return advisors;&#125; 遍历切面类中的所有除了被 @Pointcut 注解标注的方法，并将满足条件的每个方法都封装成一个Advisor 。这里 getAdvisorMethods 方法中对所有获取到的切面方法按照 Around 、 Before 、 After 、 AfterReturning 、 AfterThrowing 的顺序进行了排序。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public class ReflectiveAspectJAdvisorFactory extends AbstractAspectJAdvisorFactory implements Serializable &#123; public List&lt;Advisor&gt; getAdvisors(MetadataAwareAspectInstanceFactory aspectInstanceFactory) &#123; Class&lt;?&gt; aspectClass = aspectInstanceFactory.getAspectMetadata().getAspectClass(); // 获取标记为Aspect的类 String aspectName = aspectInstanceFactory.getAspectMetadata().getAspectName(); // 获取切面类的名称 validate(aspectClass); // 校验切面类 // 使用包装模式来包装MetadataAwareAspectInstanceFactory构建为MetadataAwareAspectInstanceFactory MetadataAwareAspectInstanceFactory lazySingletonAspectInstanceFactory = new LazySingletonAspectInstanceFactoryDecorator(aspectInstanceFactory); List&lt;Advisor&gt; advisors = new ArrayList&lt;&gt;(); // 获取到切面类中的所有方法，但是该方法不会解析标注了@PointCut注解的方法 for (Method method : getAdvisorMethods(aspectClass)) &#123; // 挨个去解析切面中的方法 Advisor advisor = getAdvisor(method, lazySingletonAspectInstanceFactory, advisors.size(), aspectName); if (advisor != null) &#123; advisors.add(advisor); &#125; &#125; if (!advisors.isEmpty() &amp;&amp; lazySingletonAspectInstanceFactory.getAspectMetadata().isLazilyInstantiated()) &#123; Advisor instantiationAdvisor = new SyntheticInstantiationAdvisor(lazySingletonAspectInstanceFactory); advisors.add(0, instantiationAdvisor); &#125; for (Field field : aspectClass.getDeclaredFields()) &#123; Advisor advisor = getDeclareParentsAdvisor(field); if (advisor != null) &#123; advisors.add(advisor); &#125; &#125; return advisors; &#125; public Advisor getAdvisor(Method candidateAdviceMethod, MetadataAwareAspectInstanceFactory aspectInstanceFactory, int declarationOrderInAspect, String aspectName) &#123; validate(aspectInstanceFactory.getAspectMetadata().getAspectClass()); // 获得当前通知的切点表达式 AspectJExpressionPointcut expressionPointcut = getPointcut(candidateAdviceMethod, aspectInstanceFactory.getAspectMetadata().getAspectClass()); if (expressionPointcut == null) &#123; return null; &#125; // 将切点表达式和通知封装到InstantiationModelAwarePointcutAdvisorImpl对象中 return new InstantiationModelAwarePointcutAdvisorImpl(expressionPointcut, candidateAdviceMethod, this, aspectInstanceFactory, declarationOrderInAspect, aspectName); &#125; private AspectJExpressionPointcut getPointcut(Method candidateAdviceMethod, Class&lt;?&gt; candidateAspectClass) &#123; // 找到aspectJ的注解：@Pointcut、@Around、@Before、@After、@AfterReturning、@AfterThrowing AspectJAnnotation&lt;?&gt; aspectJAnnotation = AbstractAspectJAdvisorFactory.findAspectJAnnotationOnMethod(candidateAdviceMethod); if (aspectJAnnotation == null) &#123; // 没有注解直接忽略 return null; &#125; AspectJExpressionPointcut ajexp = new AspectJExpressionPointcut(candidateAspectClass, new String[0], new Class&lt;?&gt;[0]); ajexp.setExpression(aspectJAnnotation.getPointcutExpression()); if (this.beanFactory != null) &#123; ajexp.setBeanFactory(this.beanFactory); &#125; return ajexp; &#125; private List&lt;Method&gt; getAdvisorMethods(Class&lt;?&gt; aspectClass) &#123; final List&lt;Method&gt; methods = new ArrayList&lt;&gt;(); ReflectionUtils.doWithMethods(aspectClass, method -&gt; &#123; if (AnnotationUtils.getAnnotation(method, Pointcut.class) == null) &#123; methods.add(method); &#125; &#125;); methods.sort(METHOD_COMPARATOR); return methods; &#125; private static final Comparator&lt;Method&gt; METHOD_COMPARATOR; static &#123; Comparator&lt;Method&gt; adviceKindComparator = new ConvertingComparator&lt;&gt;( new InstanceComparator&lt;&gt;(Around.class, Before.class, After.class, AfterReturning.class, AfterThrowing.class), (Converter&lt;Method, Annotation&gt;) method -&gt; &#123; AspectJAnnotation&lt;?&gt; annotation = AbstractAspectJAdvisorFactory.findAspectJAnnotationOnMethod(method); return (annotation != null ? annotation.getAnnotation() : null); &#125;); Comparator&lt;Method&gt; methodNameComparator = new ConvertingComparator&lt;&gt;(Method::getName); METHOD_COMPARATOR = adviceKindComparator.thenComparing(methodNameComparator); &#125;&#125; 找到方法上是否有 @Pointcut 、 @Around 、 @Before 、 @After 、 @AfterReturning 、 @AfterThrowing 等注解，并获取到注解上切面表达式。 123456789101112public abstract class AbstractAspectJAdvisorFactory implements AspectJAdvisorFactory &#123; private static final Class&lt;?&gt;[] ASPECTJ_ANNOTATION_CLASSES = new Class&lt;?&gt;[] &#123;Pointcut.class, Around.class, Before.class, After.class, AfterReturning.class, AfterThrowing.class&#125;; protected static AspectJAnnotation&lt;?&gt; findAspectJAnnotationOnMethod(Method method) &#123; for (Class&lt;?&gt; clazz : ASPECTJ_ANNOTATION_CLASSES) &#123; AspectJAnnotation&lt;?&gt; foundAnnotation = findAnnotation(method, (Class&lt;Annotation&gt;) clazz); if (foundAnnotation != null) &#123; return foundAnnotation; &#125; &#125; return null; &#125;&#125; 通过 InstantiationModelAwarePointcutAdvisorImpl 的 instantiateAdvice 方法将不同类型的注解方法解析成对应的Advice。 12345678910111213141516171819202122232425262728class InstantiationModelAwarePointcutAdvisorImpl implements InstantiationModelAwarePointcutAdvisor, AspectJPrecedenceInformation, Serializable &#123; public InstantiationModelAwarePointcutAdvisorImpl(AspectJExpressionPointcut declaredPointcut, Method aspectJAdviceMethod, AspectJAdvisorFactory aspectJAdvisorFactory, MetadataAwareAspectInstanceFactory aspectInstanceFactory, int declarationOrder, String aspectName) &#123; this.declaredPointcut = declaredPointcut;// 当前的切点 this.declaringClass = aspectJAdviceMethod.getDeclaringClass();// 切面的class对象 this.methodName = aspectJAdviceMethod.getName();// 切面方法的名称 this.parameterTypes = aspectJAdviceMethod.getParameterTypes();// 切面方法的参数类型 this.aspectJAdviceMethod = aspectJAdviceMethod;// 切面方法对象 this.aspectJAdvisorFactory = aspectJAdvisorFactory;// aspectj的通知工厂 this.aspectInstanceFactory = aspectInstanceFactory;// aspect的实例工厂 this.declarationOrder = declarationOrder;// 切面的顺序 this.aspectName = aspectName;// 切面的名称 // 判断当前的切面对象是否需要延时加载 if (aspectInstanceFactory.getAspectMetadata().isLazilyInstantiated()) &#123; Pointcut preInstantiationPointcut = Pointcuts.union(aspectInstanceFactory.getAspectMetadata().getPerClausePointcut(), this.declaredPointcut); this.pointcut = new PerTargetInstantiationModelPointcut(this.declaredPointcut, preInstantiationPointcut, aspectInstanceFactory); this.lazy = true; &#125; else &#123; this.pointcut = this.declaredPointcut; this.lazy = false; // 把切面中的通知构造为一个一个的advice通知对象 this.instantiatedAdvice = instantiateAdvice(this.declaredPointcut); &#125; &#125; private Advice instantiateAdvice(AspectJExpressionPointcut pointcut) &#123; Advice advice = this.aspectJAdvisorFactory.getAdvice(this.aspectJAdviceMethod, pointcut, this.aspectInstanceFactory, this.declarationOrder, this.aspectName); return (advice != null ? advice : EMPTY_ADVICE); &#125;&#125; 在 instantiateAdvice 方法中调用 getAdvice 方法根据不同类型的注解生成对应的 Advice 。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class ReflectiveAspectJAdvisorFactory extends AbstractAspectJAdvisorFactory implements Serializable &#123; public Advice getAdvice(Method candidateAdviceMethod, AspectJExpressionPointcut expressionPointcut, MetadataAwareAspectInstanceFactory aspectInstanceFactory, int declarationOrder, String aspectName) &#123; // 获取切面类的class对象 Class&lt;?&gt; candidateAspectClass = aspectInstanceFactory.getAspectMetadata().getAspectClass(); validate(candidateAspectClass); // 获取切面方法上的注解 AspectJAnnotation&lt;?&gt; aspectJAnnotation = AbstractAspectJAdvisorFactory.findAspectJAnnotationOnMethod(candidateAdviceMethod); if (aspectJAnnotation == null) &#123; // 解析出来的注解信息是否为null return null; &#125; if (!isAspect(candidateAspectClass)) &#123; // 判断这里的class对象是不是切面信息对象 throw new AopConfigException(&quot;Advice must be declared inside an aspect type: Offending method &#x27;&quot; + candidateAdviceMethod + &quot;&#x27; in class [&quot; + candidateAspectClass.getName() + &quot;]&quot;); &#125; AbstractAspectJAdvice springAdvice; switch (aspectJAnnotation.getAnnotationType()) &#123; // 判断标注在方法上的注解类型 case AtPointcut: // 是PointCut注解则抛出异常，在外面传递进来的方法已经排除了pointcut的方法 return null; case AtAround: //环绕通知 构建AspectJAroundAdvice springAdvice = new AspectJAroundAdvice(candidateAdviceMethod, expressionPointcut, aspectInstanceFactory); break; case AtBefore: //前置通知 构建AspectJMethodBeforeAdvice springAdvice = new AspectJMethodBeforeAdvice(candidateAdviceMethod, expressionPointcut, aspectInstanceFactory); break; case AtAfter: //后置通知 AspectJAfterAdvice springAdvice = new AspectJAfterAdvice(candidateAdviceMethod, expressionPointcut, aspectInstanceFactory); break; case AtAfterReturning: //返回通知 AspectJAfterReturningAdvice springAdvice = new AspectJAfterReturningAdvice(candidateAdviceMethod, expressionPointcut, aspectInstanceFactory); AfterReturning afterReturningAnnotation = (AfterReturning) aspectJAnnotation.getAnnotation(); if (StringUtils.hasText(afterReturningAnnotation.returning())) &#123; springAdvice.setReturningName(afterReturningAnnotation.returning()); &#125; break; case AtAfterThrowing: //异常通知 AspectJAfterThrowingAdvice springAdvice = new AspectJAfterThrowingAdvice(candidateAdviceMethod, expressionPointcut, aspectInstanceFactory); AfterThrowing afterThrowingAnnotation = (AfterThrowing) aspectJAnnotation.getAnnotation(); if (StringUtils.hasText(afterThrowingAnnotation.throwing())) &#123; springAdvice.setThrowingName(afterThrowingAnnotation.throwing()); &#125; break; default: throw new UnsupportedOperationException(&quot;Unsupported advice type on method: &quot; + candidateAdviceMethod); &#125; springAdvice.setAspectName(aspectName); // 配置构建出来的通知对象 springAdvice.setDeclarationOrder(declarationOrder); String[] argNames = this.parameterNameDiscoverer.getParameterNames(candidateAdviceMethod); if (argNames != null) &#123; springAdvice.setArgumentNamesFromStringArray(argNames); &#125; springAdvice.calculateArgumentBindings(); return springAdvice; &#125;&#125;","tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://example.com/tags/SpringBoot/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}]},{"title":"SpringBoot启动原理","date":"2020-10-15T07:08:20.000Z","path":"blog/Spring/SpringBoot/SpringBoot启动原理/","text":"SpringBoot的启动是 SpringApplication.run(ElevenApplication.class, args) 来完成的，首先在实例化SpringApplication时会去加载项目中所有的 spring.factories 配置文件数据到缓存中，并将所有的 ApplicationContextInitializer 和 ApplicationListener 筛选出来并实例化，其作用是对外扩张，以及对内的解耦，全局配置文件以及热部署插件就是通过这两个Initializer和Listener来完成的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public class SpringApplication &#123; private List&lt;ApplicationContextInitializer&lt;?&gt;&gt; initializers; private List&lt;ApplicationListener&lt;?&gt;&gt; listeners; public SpringApplication(Class&lt;?&gt;... primarySources) &#123; this(null, primarySources); &#125; public SpringApplication(ResourceLoader resourceLoader, Class&lt;?&gt;... primarySources) &#123; this.resourceLoader = resourceLoader; Assert.notNull(primarySources, &quot;PrimarySources must not be null&quot;); this.primarySources = new LinkedHashSet&lt;&gt;(Arrays.asList(primarySources));/ 将启动类放入primarySources this.webApplicationType = WebApplicationType.deduceFromClasspath(); // 根据classpath下的类确定Web类型NONE、SERVLET、REACTIVE this.bootstrapRegistryInitializers = getBootstrapRegistryInitializersFromSpringFactories(); // 去spring.factories中去获取所有key:org.springframework.context.ApplicationContextInitializer setInitializers((Collection) getSpringFactoriesInstances(ApplicationContextInitializer.class)); // 去spring.factories中去获取所有key: org.springframework.context.ApplicationListener setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); this.mainApplicationClass = deduceMainApplicationClass(); // 根据main方法推算出mainApplicationClass &#125; private &lt;T&gt; Collection&lt;T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type) &#123; return getSpringFactoriesInstances(type, new Class&lt;?&gt;[] &#123;&#125;); &#125; private &lt;T&gt; Collection&lt;T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type, Class&lt;?&gt;[] parameterTypes, Object... args) &#123; ClassLoader classLoader = getClassLoader(); // 根据类型筛选出spring.factories中配置的满足条件的类名列表 Set&lt;String&gt; names = new LinkedHashSet&lt;&gt;(SpringFactoriesLoader.loadFactoryNames(type, classLoader)); // 将满足条件的类实例化 List&lt;T&gt; instances = createSpringFactoriesInstances(type, parameterTypes, classLoader, args, names); AnnotationAwareOrderComparator.sort(instances); return instances; &#125;&#125;public final class SpringFactoriesLoader &#123; // 加载Jar包中所有的spring.factories文件中配置的数据到缓存中 public static final String FACTORIES_RESOURCE_LOCATION = &quot;META-INF/spring.factories&quot;; public static List&lt;String&gt; loadFactoryNames(Class&lt;?&gt; factoryType, @Nullable ClassLoader classLoader) &#123; ClassLoader classLoaderToUse = classLoader; if (classLoaderToUse == null) &#123; classLoaderToUse = SpringFactoriesLoader.class.getClassLoader(); &#125; String factoryTypeName = factoryType.getName(); return loadSpringFactories(classLoaderToUse).getOrDefault(factoryTypeName, Collections.emptyList()); &#125; private static Map&lt;String, List&lt;String&gt;&gt; loadSpringFactories(ClassLoader classLoader) &#123; Map&lt;String, List&lt;String&gt;&gt; result = cache.get(classLoader); if (result != null) &#123; // 若已加载过直接跳过 return result; &#125; result = new HashMap&lt;&gt;(); try &#123; Enumeration&lt;URL&gt; urls = classLoader.getResources(FACTORIES_RESOURCE_LOCATION); while (urls.hasMoreElements()) &#123; URL url = urls.nextElement(); UrlResource resource = new UrlResource(url); Properties properties = PropertiesLoaderUtils.loadProperties(resource); for (Map.Entry&lt;?, ?&gt; entry : properties.entrySet()) &#123; String factoryTypeName = ((String) entry.getKey()).trim(); String[] factoryImplementationNames = StringUtils.commaDelimitedListToStringArray((String) entry.getValue()); for (String factoryImplementationName : factoryImplementationNames) &#123; result.computeIfAbsent(factoryTypeName, key -&gt; new ArrayList&lt;&gt;()).add(factoryImplementationName.trim()); &#125; &#125; &#125; result.replaceAll((factoryType, implementations) -&gt; implementations.stream().distinct().collect(Collectors.collectingAndThen(Collectors.toList(), Collections::unmodifiableList))); cache.put(classLoader, result); &#125; catch (IOException ex) &#123; throw new IllegalArgumentException(&quot;Unable to load factories from location [&quot; + FACTORIES_RESOURCE_LOCATION + &quot;]&quot;, ex); &#125; return result; &#125;&#125; 通过run方法完成SpringBoot的启动 123456789101112131415161718192021222324252627282930313233343536373839public ConfigurableApplicationContext run(String... args) &#123; StopWatch stopWatch = new StopWatch(); // 用来记录当前springboot启动耗时 stopWatch.start(); // 记录启动开始时间 DefaultBootstrapContext bootstrapContext = createBootstrapContext(); ConfigurableApplicationContext context = null; // // 它是任何spring上下文的接口，可接收任何ApplicationContext实现 configureHeadlessProperty(); // 开启了Headless模式 SpringApplicationRunListeners listeners = getRunListeners(args); // 去spring.factroies中读取SpringApplicationRunListener组件，用来发布事件或者运行监听器 listeners.starting(bootstrapContext, this.mainApplicationClass); // ApplicationStartingEvent事件，在运行开始时发送 try &#123; // 根据命令行参数实例化一个ApplicationArguments ApplicationArguments applicationArguments = new DefaultApplicationArguments(args); // 基于监听器预初始化环境：读取环境变量，读取配置文件信息 ConfigurableEnvironment environment = prepareEnvironment(listeners, bootstrapContext, applicationArguments); configureIgnoreBeanInfo(environment); // 忽略beaninfo的bean Banner printedBanner = printBanner(environment); // 打印Banner横幅 context = createApplicationContext(); context.setApplicationStartup(this.applicationStartup); // 预初始化spring上下文 prepareContext(bootstrapContext, context, environment, listeners, applicationArguments, printedBanner); refreshContext(context); // 加载spring ioc容器 afterRefresh(context, applicationArguments); stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass).logStarted(getApplicationLog(), stopWatch); &#125; listeners.started(context); callRunners(context, applicationArguments); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, listeners); throw new IllegalStateException(ex); &#125; try &#123; listeners.running(context); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, null); throw new IllegalStateException(ex); &#125; return context;&#125; 预初始化环境是基于监听器来读取环境变量和读取配置文件信息，首先根据 webApplicationType 创建 Environment ，创建就会读取Java环境变量和系统环境变量。然后将命令行参数读取环境变量中，通过发布 ApplicationEnvironmentPreparedEvent 监听器读取全局配置文件。 12345678910111213141516171819private ConfigurableEnvironment prepareEnvironment(SpringApplicationRunListeners listeners, DefaultBootstrapContext bootstrapContext, ApplicationArguments applicationArguments) &#123; // 根据webApplicationType创建Environment，创建就会读取：java环境变量和系统环境变量 ConfigurableEnvironment environment = getOrCreateEnvironment(); // 将命令行参数读取环境变量中 configureEnvironment(environment, applicationArguments.getSourceArgs()); // 将@PropertieSource的配置信息放在第一位，读取配置文件@PropertieSource优先级是最低的 ConfigurationPropertySources.attach(environment); // 发布了ApplicationEnvironmentPreparedEvent的监听器读取全局配置文件 listeners.environmentPrepared(bootstrapContext, environment); // 将所有spring.main开头的配置信息绑定SpringApplication DefaultPropertiesPropertySource.moveToEnd(environment); Assert.state(!environment.containsProperty(&quot;spring.main.environment-prefix&quot;), &quot;Environment prefix cannot be set via properties.&quot;); bindToSpringApplication(environment); if (!this.isCustomEnvironment) &#123; environment = new EnvironmentConverter(getClassLoader()).convertEnvironmentIfNecessary(environment, deduceEnvironmentClass()); &#125; ConfigurationPropertySources.attach(environment); // 更新PropertySources return environment;&#125; 根据应用类型创建Spring IOC上下文 1234567891011121314151617181920protected ConfigurableApplicationContext createApplicationContext() &#123; return this.applicationContextFactory.create(this.webApplicationType);&#125;public interface ApplicationContextFactory &#123; ApplicationContextFactory DEFAULT = (webApplicationType) -&gt; &#123; try &#123; switch (webApplicationType) &#123; case SERVLET: return new AnnotationConfigServletWebServerApplicationContext(); case REACTIVE: return new AnnotationConfigReactiveWebServerApplicationContext(); default: return new AnnotationConfigApplicationContext(); &#125; &#125; catch (Exception ex) &#123; throw new IllegalStateException(&quot;Unable create a default ApplicationContext instance, &quot; + &quot;you may need a custom ApplicationContextFactory&quot;, ex); &#125; &#125;; ConfigurableApplicationContext create(WebApplicationType webApplicationType);&#125; 预初始化上下文，这里会发布 ApplicationContextInitializedEvent 事件，且设置重名的Bean不允许覆盖直接抛出异常，设置当前Spring容器是否要将所有bean设置为懒加载，然后通过 AnnotatedBeanDefinitionReader 的 register 方法将 SpringApplication#run 中传入的类注册到IoC容器中，读取完配置类后发布 ApplicationPreparedEvent 事件。 12345678910111213141516171819202122232425262728293031private void prepareContext(DefaultBootstrapContext bootstrapContext, ConfigurableApplicationContext context, ConfigurableEnvironment environment, SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments, Banner printedBanner) &#123; context.setEnvironment(environment); postProcessApplicationContext(context); applyInitializers(context); // 拿到之前读取到所有ApplicationContextInitializer的组件， 循环调用initialize方法 listeners.contextPrepared(context); // 发布了ApplicationContextInitializedEvent bootstrapContext.close(context); if (this.logStartupInfo) &#123; logStartupInfo(context.getParent() == null); logStartupProfileInfo(context); &#125; // 获取当前spring上下文beanFactory，负责创建bean ConfigurableListableBeanFactory beanFactory = context.getBeanFactory(); beanFactory.registerSingleton(&quot;springApplicationArguments&quot;, applicationArguments); if (printedBanner != null) &#123; beanFactory.registerSingleton(&quot;springBootBanner&quot;, printedBanner); &#125; // 若Spring下出现2个重名的bean, 则后读取到的会覆盖前面，SpringBoot在这里设置了不允许覆盖，当出现2个重名的bean会抛出异常 if (beanFactory instanceof DefaultListableBeanFactory) &#123; ((DefaultListableBeanFactory) beanFactory).setAllowBeanDefinitionOverriding(this.allowBeanDefinitionOverriding); &#125; // 设置当前spring容器是不是要将所有的bean设置为懒加载 if (this.lazyInitialization) &#123; context.addBeanFactoryPostProcessor(new LazyInitializationBeanFactoryPostProcessor()); &#125; // 即传入的ElevenApplication Set&lt;Object&gt; sources = getAllSources(); Assert.notEmpty(sources, &quot;Sources must not be empty&quot;); // 读取主启动类将它注册为BD、就和以前register启动类一个意思，因为后续要根据配置类解析配置的所有bean load(context, sources.toArray(new Object[0])); listeners.contextLoaded(context); // 读取完配置类后发送ApplicationPreparedEvent&#125; 最后调用容器启动最重要的 refresh() 方法来完成Bean的扫描注册和实例化等工作。 123456789private void refreshContext(ConfigurableApplicationContext context) &#123; if (this.registerShutdownHook) &#123; shutdownHook.registerApplicationContext(context); &#125; refresh(context);&#125;protected void refresh(ConfigurableApplicationContext applicationContext) &#123; applicationContext.refresh();&#125; 内嵌Web容器启动内嵌Web容器的启动是在 refresh() 中的 onRefresh() 中完成的，最终调用子容器 ServletWebServerApplicationContext 的 onRefresh() 方法，从而调用 createWebServer() 创建Web容器。 12345678910111213141516171819202122232425262728293031public class ServletWebServerApplicationContext extends GenericWebApplicationContext implements ConfigurableWebServerApplicationContext &#123; protected void onRefresh() &#123; super.onRefresh(); try &#123; createWebServer(); &#125; catch (Throwable ex) &#123; throw new ApplicationContextException(&quot;Unable to start web server&quot;, ex); &#125; &#125; private void createWebServer() &#123; WebServer webServer = this.webServer; ServletContext servletContext = getServletContext(); if (webServer == null &amp;&amp; servletContext == null) &#123; StartupStep createWebServer = this.getApplicationStartup().start(&quot;spring.boot.webserver.create&quot;); ServletWebServerFactory factory = getWebServerFactory(); createWebServer.tag(&quot;factory&quot;, factory.getClass().toString()); this.webServer = factory.getWebServer(getSelfInitializer()); createWebServer.end(); getBeanFactory().registerSingleton(&quot;webServerGracefulShutdown&quot;, new WebServerGracefulShutdownLifecycle(this.webServer)); getBeanFactory().registerSingleton(&quot;webServerStartStop&quot;, new WebServerStartStopLifecycle(this, this.webServer)); &#125; else if (servletContext != null) &#123; try &#123; getSelfInitializer().onStartup(servletContext); &#125; catch (ServletException ex) &#123; throw new ApplicationContextException(&quot;Cannot initialize servlet context&quot;, ex); &#125; &#125; initPropertySources(); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public class TomcatServletWebServerFactory extends AbstractServletWebServerFactory implements ConfigurableTomcatWebServerFactory, ResourceLoaderAware &#123; public WebServer getWebServer(ServletContextInitializer... initializers) &#123; if (this.disableMBeanRegistry) &#123; Registry.disableRegistry(); &#125; Tomcat tomcat = new Tomcat(); File baseDir = (this.baseDirectory != null) ? this.baseDirectory : createTempDir(&quot;tomcat&quot;); tomcat.setBaseDir(baseDir.getAbsolutePath()); Connector connector = new Connector(this.protocol); connector.setThrowOnFailure(true); tomcat.getService().addConnector(connector); customizeConnector(connector); tomcat.setConnector(connector); tomcat.getHost().setAutoDeploy(false); configureEngine(tomcat.getEngine()); for (Connector additionalConnector : this.additionalTomcatConnectors) &#123; tomcat.getService().addConnector(additionalConnector); &#125; prepareContext(tomcat.getHost(), initializers); return getTomcatWebServer(tomcat); &#125; protected TomcatWebServer getTomcatWebServer(Tomcat tomcat) &#123; return new TomcatWebServer(tomcat, getPort() &gt;= 0, getShutdown()); &#125;&#125;public class TomcatWebServer implements WebServer &#123; public TomcatWebServer(Tomcat tomcat, boolean autoStart, Shutdown shutdown) &#123; Assert.notNull(tomcat, &quot;Tomcat Server must not be null&quot;); this.tomcat = tomcat; this.autoStart = autoStart; this.gracefulShutdown = (shutdown == Shutdown.GRACEFUL) ? new GracefulShutdown(tomcat) : null; initialize(); &#125; private void initialize() throws WebServerException &#123; synchronized (this.monitor) &#123; try &#123; addInstanceIdToEngineName(); Context context = findContext(); context.addLifecycleListener((event) -&gt; &#123; if (context.equals(event.getSource()) &amp;&amp; Lifecycle.START_EVENT.equals(event.getType())) &#123; removeServiceConnectors(); &#125; &#125;); this.tomcat.start(); rethrowDeferredStartupExceptions(); try &#123; ContextBindings.bindClassLoader(context, context.getNamingToken(), getClass().getClassLoader()); &#125; catch (NamingException ex) &#123; &#125; startDaemonAwaitThread(); &#125; catch (Exception ex) &#123; stopSilently(); destroySilently(); throw new WebServerException(&quot;Unable to start embedded Tomcat&quot;, ex); &#125; &#125; &#125; private void startDaemonAwaitThread() &#123; Thread awaitThread = new Thread(&quot;container-&quot; + (containerCounter.get())) &#123; @Override public void run() &#123; TomcatWebServer.this.tomcat.getServer().await(); &#125; &#125;; awaitThread.setContextClassLoader(getClass().getClassLoader()); awaitThread.setDaemon(false); awaitThread.start(); &#125;&#125; 外部Servlet容器启动外部Servlet容器启动是通过war包以及 SPI机制来完成的， SPI是一种服务发现机制，它通过在ClassPath路径下的 META-INF/services 文件夹查找文件，自动加载文件里所定义的类。需要将打包方式改成war包，然后将POM中Tomcat的依赖设置为不参与打包。 12345&lt;dependency&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 当 Servlet 启动时回去 META-INF/services 文件夹中找到 javax.servlet.ServletContainerInitializer ，当Servlet容器启动时会去找到ServletContainerInitializer的实现类，从而创建它的实例调用 onStartup 方法。在Spring中ServletContainerInitializer 的实现类为 SpringServletContainerInitializer ，且通过 @HandlesTypes(WebApplicationInitializer.class)注解将 ServletContainerInitializer 感兴趣的类 WebApplicationInitializer 传入到 onStartup 方法的参数中。 123456789101112131415161718192021222324252627282930313233343536public abstract class SpringBootServletInitializer implements WebApplicationInitializer &#123; protected WebApplicationContext createRootApplicationContext(ServletContext servletContext) &#123; SpringApplicationBuilder builder = createSpringApplicationBuilder(); builder.main(getClass()); ApplicationContext parent = getExistingRootWebApplicationContext(servletContext); if (parent != null) &#123; servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, null); builder.initializers(new ParentContextApplicationContextInitializer(parent)); &#125; builder.initializers(new ServletContextApplicationContextInitializer(servletContext)); builder.contextFactory((webApplicationType) -&gt; new AnnotationConfigServletWebServerApplicationContext()); builder = configure(builder); builder.listeners(new WebEnvironmentPropertySourceInitializer(servletContext)); SpringApplication application = builder.build(); if (application.getAllSources().isEmpty() &amp;&amp; MergedAnnotations.from(getClass(), SearchStrategy.TYPE_HIERARCHY).isPresent(Configuration.class)) &#123; application.addPrimarySources(Collections.singleton(getClass())); &#125; Assert.state(!application.getAllSources().isEmpty(), &quot;No SpringApplication sources have been defined. Either override the &quot; + &quot;configure method or add an @Configuration annotation&quot;); if (this.registerErrorPageFilter) &#123; application.addPrimarySources(Collections.singleton(ErrorPageFilterConfiguration.class)); &#125; application.setRegisterShutdownHook(false); return run(application); &#125; protected SpringApplicationBuilder createSpringApplicationBuilder() &#123; return new SpringApplicationBuilder(); &#125;&#125;public class SpringApplicationBuilder &#123; public SpringApplicationBuilder(Class&lt;?&gt;... sources) &#123; this.application = createSpringApplication(sources); &#125; protected SpringApplication createSpringApplication(Class&lt;?&gt;... sources) &#123; return new SpringApplication(sources); &#125;&#125; 由代码可以明显看到Tomcat不会主动去启动SpringBoot应用，而默认创建SpringApplication时什么都没有传入，故需要通过继承 SpringBootServletInitializer 重写 configure 来指定SpringBoot启动类。 123456public class TomcatStartSpringBoot extends SpringBootServletInitializer &#123; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder builder) &#123; return builder.sources(ElevenSpringbootApplication.class); &#125;&#125;","tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://example.com/tags/SpringBoot/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"},{"name":"SpringBoot","slug":"Spring/SpringBoot","permalink":"http://example.com/categories/Spring/SpringBoot/"}]},{"title":"SpringBoot自动装配原理","date":"2020-10-15T06:08:20.000Z","path":"blog/Spring/SpringBoot/SpringBoot自动装配原理/","text":"SpringBoot容器启动时最终会调用 refresh() 方法来扫描项目中的Bean注册为BeanDefinition然后将其加载到容器中。扫描注册过程还是在 invokeBeanFactoryPostProcessors 中来完成的。首先通过启动类上 @SpringBootApplication 中的 @ComponentScan 来确定扫描的包来扫描包下所有的类，然后通过条件筛选出符合的Bean。 12345678910111213141516171819202122@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan(excludeFilters = &#123; @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) &#125;)public @interface SpringBootApplication &#123; @AliasFor(annotation = EnableAutoConfiguration.class) Class&lt;?&gt;[] exclude() default &#123;&#125;; @AliasFor(annotation = EnableAutoConfiguration.class) String[] excludeName() default &#123;&#125;; @AliasFor(annotation = ComponentScan.class, attribute = &quot;basePackages&quot;) String[] scanBasePackages() default &#123;&#125;; @AliasFor(annotation = ComponentScan.class, attribute = &quot;basePackageClasses&quot;) Class&lt;?&gt;[] scanBasePackageClasses() default &#123;&#125;; @AliasFor(annotation = ComponentScan.class, attribute = &quot;nameGenerator&quot;) Class&lt;? extends BeanNameGenerator&gt; nameGenerator() default BeanNameGenerator.class; @AliasFor(annotation = Configuration.class) boolean proxyBeanMethods() default true;&#125; 在 @ComponentScan 中配置了一个两个 excludeFilters ，TypeExcludeFilter适用于提供的扩展点，AutoConfigurationExcludeFilter的作用是排除被 @Configuration 注解标注的且在所有 META-INF/spring.factories 文件中的KEY为 org.springframework.boot.autoconfigure.EnableAutoConfiguration 的自动配置类。 1234567891011121314151617181920public class AutoConfigurationExcludeFilter implements TypeFilter, BeanClassLoaderAware &#123; public boolean match(MetadataReader metadataReader, MetadataReaderFactory metadataReaderFactory) throws IOException &#123; return isConfiguration(metadataReader) &amp;&amp; isAutoConfiguration(metadataReader); &#125; private boolean isConfiguration(MetadataReader metadataReader) &#123; return metadataReader.getAnnotationMetadata().isAnnotated(Configuration.class.getName()); &#125; private boolean isAutoConfiguration(MetadataReader metadataReader) &#123; return getAutoConfigurations().contains(metadataReader.getClassMetadata().getClassName()); &#125; protected List&lt;String&gt; getAutoConfigurations() &#123; if (this.autoConfigurations == null) &#123; this.autoConfigurations = SpringFactoriesLoader.loadFactoryNames(EnableAutoConfiguration.class, this.beanClassLoader); &#125; return this.autoConfigurations; &#125;&#125; 若 @ComponentScan 未指定 basePackages 和 basePackageClasses ，则默认使用当前配置类所在的包。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162class ComponentScanAnnotationParser &#123; public Set&lt;BeanDefinitionHolder&gt; parse(AnnotationAttributes componentScan, final String declaringClass) &#123; ClassPathBeanDefinitionScanner scanner = new ClassPathBeanDefinitionScanner(this.registry, componentScan.getBoolean(&quot;useDefaultFilters&quot;), this.environment, this.resourceLoader); // 为扫描器设置beanName的生成器对象 Class&lt;? extends BeanNameGenerator&gt; generatorClass = componentScan.getClass(&quot;nameGenerator&quot;); boolean useInheritedGenerator = (BeanNameGenerator.class == generatorClass); scanner.setBeanNameGenerator(useInheritedGenerator ? this.beanNameGenerator : BeanUtils.instantiateClass(generatorClass)); // 解析@Scope的ProxyMode属性，该属性可以将Bean创建为jdk代理或cglib代理 ScopedProxyMode scopedProxyMode = componentScan.getEnum(&quot;scopedProxy&quot;); if (scopedProxyMode != ScopedProxyMode.DEFAULT) &#123; scanner.setScopedProxyMode(scopedProxyMode); &#125; else &#123; Class&lt;? extends ScopeMetadataResolver&gt; resolverClass = componentScan.getClass(&quot;scopeResolver&quot;); scanner.setScopeMetadataResolver(BeanUtils.instantiateClass(resolverClass)); &#125; scanner.setResourcePattern(componentScan.getString(&quot;resourcePattern&quot;)); // 设置CompentScan对象的includeFilters 包含的属性 for (AnnotationAttributes filter : componentScan.getAnnotationArray(&quot;includeFilters&quot;)) &#123; for (TypeFilter typeFilter : typeFiltersFor(filter)) &#123; scanner.addIncludeFilter(typeFilter); &#125; &#125; // 设置CompentScan对象的excludeFilters 包含的属性 for (AnnotationAttributes filter : componentScan.getAnnotationArray(&quot;excludeFilters&quot;)) &#123; for (TypeFilter typeFilter : typeFiltersFor(filter)) &#123; scanner.addExcludeFilter(typeFilter); &#125; &#125; // 是否懒加载，此懒加载为componentScan延迟加载所有类 boolean lazyInit = componentScan.getBoolean(&quot;lazyInit&quot;); if (lazyInit) &#123; scanner.getBeanDefinitionDefaults().setLazyInit(true); &#125; // 包路径配置类中componentScan设置的路径 Set&lt;String&gt; basePackages = new LinkedHashSet&lt;&gt;(); String[] basePackagesArray = componentScan.getStringArray(&quot;basePackages&quot;); for (String pkg : basePackagesArray) &#123; String[] tokenized = StringUtils.tokenizeToStringArray(this.environment.resolvePlaceholders(pkg), ConfigurableApplicationContext.CONFIG_LOCATION_DELIMITERS); Collections.addAll(basePackages, tokenized); &#125; for (Class&lt;?&gt; clazz : componentScan.getClassArray(&quot;basePackageClasses&quot;)) &#123; basePackages.add(ClassUtils.getPackageName(clazz)); &#125; if (basePackages.isEmpty()) &#123; // 若未指定则使用当前配置所在的包 basePackages.add(ClassUtils.getPackageName(declaringClass)); &#125; scanner.addExcludeFilter(new AbstractTypeHierarchyTraversingFilter(false, false) &#123; @Override protected boolean matchClassName(String className) &#123; return declaringClass.equals(className); &#125; &#125;); return scanner.doScan(StringUtils.toStringArray(basePackages)); // 真正的进行扫描解析 &#125;&#125;public static String getPackageName(String fqClassName) &#123; // 截取出当前类所在的文件夹 Assert.notNull(fqClassName, &quot;Class name must not be null&quot;); int lastDotIndex = fqClassName.lastIndexOf(PACKAGE_SEPARATOR); return (lastDotIndex != -1 ? fqClassName.substring(0, lastDotIndex) : &quot;&quot;);&#125; 将所有的@Component注解标注的类扫描出来，将其注册到容器中，对于 @Import注解导入的类，总的来说分为三种，第一种是普通的类，第二种是实现了 ImportSelector 接口，这里面有两种类型，若是一个延时的 DeferredImportSelector 则只将该类添加到 deferredImportSelectors 后续解析后统一处理。否则调用 selectImports 递归调用 processImports ，第三中是实现了 ImportBeanDefinitionRegistrar 接口，这种会将其添加到当前 ConfigurationClass 的 importBeanDefinitionRegistrars 列表中后续统一处理。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950private void processImports(ConfigurationClass configClass, SourceClass currentSourceClass, Collection&lt;SourceClass&gt; importCandidates, boolean checkForCircularImports) &#123; if (importCandidates.isEmpty()) &#123; return; &#125; if (checkForCircularImports &amp;&amp; isChainedImportOnStack(configClass)) &#123; this.problemReporter.error(new CircularImportProblem(configClass, this.importStack)); &#125; else &#123; this.importStack.push(configClass); try &#123; for (SourceClass candidate : importCandidates) &#123; // 获取我们Import导入进来的所有组件 if (candidate.isAssignable(ImportSelector.class)) &#123; // 判断该组件是不是实现了ImportSelector // Candidate class is an ImportSelector -&gt; delegate to it to determine imports Class&lt;?&gt; candidateClass = candidate.loadClass(); // 实例化我们的SelectImport组件 ImportSelector selector = BeanUtils.instantiateClass(candidateClass, ImportSelector.class); // 调用相关的aware方法 ParserStrategyUtils.invokeAwareMethods(selector, this.environment, this.resourceLoader, this.registry); // 判断是不是延时的DeferredImportSelectors，是这个类型不进行处理 if (this.deferredImportSelectors != null &amp;&amp; selector instanceof DeferredImportSelector) &#123; this.deferredImportSelectors.add(new DeferredImportSelectorHolder(configClass, (DeferredImportSelector) selector)); &#125; else &#123; // 不是延时的， 调用selector的selectImports String[] importClassNames = selector.selectImports(currentSourceClass.getMetadata()); // 所以递归解析-- 直到成普通组件 Collection&lt;SourceClass&gt; importSourceClasses = asSourceClasses(importClassNames); processImports(configClass, currentSourceClass, importSourceClasses, false); &#125; &#125; // 判断导入的组件是不是ImportBeanDefinitionRegistrar，这里不直接调用，只是解析 else if (candidate.isAssignable(ImportBeanDefinitionRegistrar.class)) &#123; Class&lt;?&gt; candidateClass = candidate.loadClass(); // 实例化ImportBeanDefinitionRegistrar对象 ImportBeanDefinitionRegistrar registrar = BeanUtils.instantiateClass(candidateClass, ImportBeanDefinitionRegistrar.class); ParserStrategyUtils.invokeAwareMethods(registrar, this.environment, this.resourceLoader, this.registry); // 保存ImportBeanDefinitionRegistrar对象currentSourceClass=所在配置类 configClass.addImportBeanDefinitionRegistrar(registrar, currentSourceClass.getMetadata()); &#125; else &#123; // 当做配置类再解析，注意这里会标记：importedBy，表示这是Import的配置的类，再执行之前的processConfigurationClass()方法 ， this.importStack.registerImport(currentSourceClass.getMetadata(), candidate.getMetadata().getClassName()); processConfigurationClass(candidate.asConfigClass(configClass)); &#125; &#125; &#125; catch (BeanDefinitionStoreException ex) &#123; throw ex; &#125; catch (Throwable ex) &#123; throw new BeanDefinitionStoreException(&quot;Failed to process import candidates for configuration class [&quot; + configClass.getMetadata().getClassName() + &quot;]&quot;, ex); &#125; finally &#123; this.importStack.pop(); &#125; &#125;&#125; 对于 DeferredImportSelector 的处理在 processImports 中会通过handle方法将其添加到 ConfigurationClassParser 的 deferredImportSelectors 列表中。在parse解析完所有Bean后调用 process 方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849class ConfigurationClassParser &#123; public void parse(Set&lt;BeanDefinitionHolder&gt; configCandidates) &#123; for (BeanDefinitionHolder holder : configCandidates) &#123; BeanDefinition bd = holder.getBeanDefinition(); try &#123; if (bd instanceof AnnotatedBeanDefinition) &#123; parse(((AnnotatedBeanDefinition) bd).getMetadata(), holder.getBeanName()); &#125; else if (bd instanceof AbstractBeanDefinition &amp;&amp; ((AbstractBeanDefinition) bd).hasBeanClass()) &#123; parse(((AbstractBeanDefinition) bd).getBeanClass(), holder.getBeanName()); &#125; else &#123; parse(bd.getBeanClassName(), holder.getBeanName()); &#125; &#125; catch (BeanDefinitionStoreException ex) &#123; throw ex; &#125; catch (Throwable ex) &#123; throw new BeanDefinitionStoreException(&quot;Failed to parse configuration class [&quot; + bd.getBeanClassName() + &quot;]&quot;, ex); &#125; &#125; this.deferredImportSelectorHandler.process(); &#125;&#125;private class DeferredImportSelectorHandler &#123; private List&lt;DeferredImportSelectorHolder&gt; deferredImportSelectors = new ArrayList&lt;&gt;(); public void handle(ConfigurationClass configClass, DeferredImportSelector importSelector) &#123; DeferredImportSelectorHolder holder = new DeferredImportSelectorHolder(configClass, importSelector); if (this.deferredImportSelectors == null) &#123; DeferredImportSelectorGroupingHandler handler = new DeferredImportSelectorGroupingHandler(); handler.register(holder); handler.processGroupImports(); &#125; else &#123; this.deferredImportSelectors.add(holder); &#125; &#125; public void process() &#123; List&lt;DeferredImportSelectorHolder&gt; deferredImports = this.deferredImportSelectors; this.deferredImportSelectors = null; try &#123; if (deferredImports != null) &#123; DeferredImportSelectorGroupingHandler handler = new DeferredImportSelectorGroupingHandler(); deferredImports.sort(DEFERRED_IMPORT_COMPARATOR); deferredImports.forEach(handler::register); handler.processGroupImports(); &#125; &#125; finally &#123; this.deferredImportSelectors = new ArrayList&lt;&gt;(); &#125; &#125;&#125; 通过 DeferredImportSelectorGroupingHandler 的 register 方法遍历，首先调用其 getImportGroup 获取Group，然后再将其封装添加到 grouping ，最后通过 processGroupImports 遍历 getImports() 再遍历每个导入的类执行 processImports 。 123456789101112131415161718192021222324252627282930313233private class DeferredImportSelectorGroupingHandler &#123; private final Map&lt;Object, DeferredImportSelectorGrouping&gt; groupings = new LinkedHashMap&lt;&gt;(); private final Map&lt;AnnotationMetadata, ConfigurationClass&gt; configurationClasses = new HashMap&lt;&gt;(); public void register(DeferredImportSelectorHolder deferredImport) &#123; Class&lt;? extends Group&gt; group = deferredImport.getImportSelector().getImportGroup(); DeferredImportSelectorGrouping grouping = this.groupings.computeIfAbsent( (group != null ? group : deferredImport), key -&gt; new DeferredImportSelectorGrouping(createGroup(group))); grouping.add(deferredImport); this.configurationClasses.put(deferredImport.getConfigurationClass().getMetadata(), deferredImport.getConfigurationClass()); &#125; public void processGroupImports() &#123; for (DeferredImportSelectorGrouping grouping : this.groupings.values()) &#123; Predicate&lt;String&gt; exclusionFilter = grouping.getCandidateFilter(); grouping.getImports().forEach(entry -&gt; &#123; ConfigurationClass configurationClass = this.configurationClasses.get(entry.getMetadata()); try &#123; processImports(configurationClass, asSourceClass(configurationClass, exclusionFilter), Collections.singleton(asSourceClass(entry.getImportClassName(), exclusionFilter)), exclusionFilter, false); &#125; catch (BeanDefinitionStoreException ex) &#123; throw ex; &#125; catch (Throwable ex) &#123; throw new BeanDefinitionStoreException(&quot;Failed to process import candidates for configuration class [&quot; + configurationClass.getMetadata().getClassName() + &quot;]&quot;, ex); &#125; &#125;); &#125; &#125; private Group createGroup(@Nullable Class&lt;? extends Group&gt; type) &#123; Class&lt;? extends Group&gt; effectiveType = (type != null ? type : DefaultDeferredImportSelectorGroup.class); return ParserStrategyUtils.instantiateClass(effectiveType, Group.class, ConfigurationClassParser.this.environment, ConfigurationClassParser.this.resourceLoader, ConfigurationClassParser.this.registry); &#125;&#125; 当处理完所有的Bean后通过调用 ConfigurationClassBeanDefinitionReader 的 loadBeanDefinitions 方法，按照解析Bean的顺序再次解析Bean中用@Bean注解标注的方法，以及对 @Import 中导入的实现了 ImportBeanDefinitionRegistrar 接口的类。 123456789101112131415161718private void loadBeanDefinitionsForConfigurationClass(ConfigurationClass configClass, TrackedConditionEvaluator trackedConditionEvaluator) &#123; if (trackedConditionEvaluator.shouldSkip(configClass)) &#123; String beanName = configClass.getBeanName(); if (StringUtils.hasLength(beanName) &amp;&amp; this.registry.containsBeanDefinition(beanName)) &#123; this.registry.removeBeanDefinition(beanName); &#125; this.importRegistry.removeImportingClass(configClass.getMetadata().getClassName()); return; &#125; if (configClass.isImported()) &#123; registerBeanDefinitionForImportedConfigurationClass(configClass); &#125; for (BeanMethod beanMethod : configClass.getBeanMethods()) &#123; loadBeanDefinitionsForBeanMethod(beanMethod); &#125; loadBeanDefinitionsFromImportedResources(configClass.getImportedResources()); loadBeanDefinitionsFromRegistrars(configClass.getImportBeanDefinitionRegistrars());&#125; SpringBoot的自动装配主要体现在 @EnableAutoConfiguration 中。在该注解上导入了 AutoConfigurationImportSelector ，该类实现了延时的 DeferredImportSelector ，从而延时加载自动配置的类，达到自动配置的效果。 1234567891011@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@AutoConfigurationPackage@Import(AutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration &#123; String ENABLED_OVERRIDE_PROPERTY = &quot;spring.boot.enableautoconfiguration&quot;; Class&lt;?&gt;[] exclude() default &#123;&#125;; String[] excludeName() default &#123;&#125;;&#125; 对于 @AutoConfigurationPackages 注解的作用是保存当前配置类所在的包路径作为扫描路径，提供给 spring-data-jpa 需要扫描 @Entity 。 123456789101112131415161718192021222324252627282930public abstract class AutoConfigurationPackages &#123; static class Registrar implements ImportBeanDefinitionRegistrar, DeterminableImports &#123; @Override public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry) &#123; register(registry, new PackageImports(metadata).getPackageNames().toArray(new String[0])); &#125; @Override public Set&lt;Object&gt; determineImports(AnnotationMetadata metadata) &#123; return Collections.singleton(new PackageImports(metadata)); &#125; &#125;&#125;private static final class PackageImports &#123; private final List&lt;String&gt; packageNames; PackageImports(AnnotationMetadata metadata) &#123; AnnotationAttributes attributes = AnnotationAttributes.fromMap(metadata.getAnnotationAttributes(AutoConfigurationPackage.class.getName(), false)); List&lt;String&gt; packageNames = new ArrayList&lt;&gt;(Arrays.asList(attributes.getStringArray(&quot;basePackages&quot;))); for (Class&lt;?&gt; basePackageClass : attributes.getClassArray(&quot;basePackageClasses&quot;)) &#123; packageNames.add(basePackageClass.getPackage().getName()); &#125; if (packageNames.isEmpty()) &#123; packageNames.add(ClassUtils.getPackageName(metadata.getClassName())); &#125; this.packageNames = Collections.unmodifiableList(packageNames); &#125; List&lt;String&gt; getPackageNames() &#123; return this.packageNames; &#125;&#125; 通过调用 AutoConfigurationImportSelector 的 getImportGroup() 获取到 AutoConfigurationGroup ，在解析完成所有Bean后调用 AutoConfigurationGroup 的process方法，最终调用 getAutoConfigurationEntry 去加载系统中所有 META-INF/spring.factories 文件中的KEY为 org.springframework.boot.autoconfigure.EnableAutoConfiguration 的自动配置类列表。 加载自动配置类的过程中会排除掉 @EnableAutoConfiguration注解中 exclude 和 excludeName 配置的类，以及 spring.autoconfigure.exclude 配置的类过滤掉，还会根据配置类上的 @Conditional派生注解进行配置类的过滤；在加载Bean方法时通过 ConditionEvaluator 的 shouldSkip 根据Bean上的 @Conditional派生注解来判断是否加载该Bean。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public class AutoConfigurationImportSelector implements DeferredImportSelector, BeanClassLoaderAware, ResourceLoaderAware, BeanFactoryAware, EnvironmentAware, Ordered &#123; public Class&lt;? extends Group&gt; getImportGroup() &#123; return AutoConfigurationGroup.class; &#125; protected AutoConfigurationEntry getAutoConfigurationEntry(AnnotationMetadata annotationMetadata) &#123; if (!isEnabled(annotationMetadata)) &#123; return EMPTY_ENTRY; &#125; AnnotationAttributes attributes = getAttributes(annotationMetadata); // 从META-INF/spring.factories中获得候选的自动配置类 List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata, attributes); configurations = removeDuplicates(configurations);// 排重 //根据EnableAutoConfiguration注解中属性，获取不需要自动装配的类名单 Set&lt;String&gt; exclusions = getExclusions(annotationMetadata, attributes); // 根据:@EnableAutoConfiguration.exclude，@EnableAutoConfiguration.excludeName，spring.autoconfigure.exclude进行排除 checkExcludedClasses(configurations, exclusions); configurations.removeAll(exclusions); // exclusions 也排除 // 通过读取spring.factories中的OnBeanCondition\\OnClassCondition\\OnWebApplicationCondition进行配置类的过滤 configurations = getConfigurationClassFilter().filter(configurations); fireAutoConfigurationImportEvents(configurations, exclusions); return new AutoConfigurationEntry(configurations, exclusions); &#125; protected boolean isEnabled(AnnotationMetadata metadata) &#123; if (getClass() == AutoConfigurationImportSelector.class) &#123; return getEnvironment().getProperty(EnableAutoConfiguration.ENABLED_OVERRIDE_PROPERTY, Boolean.class, true); &#125; return true; &#125; protected Class&lt;?&gt; getAnnotationClass() &#123; return EnableAutoConfiguration.class; &#125; protected List&lt;String&gt; getCandidateConfigurations(AnnotationMetadata metadata, AnnotationAttributes attributes) &#123; List&lt;String&gt; configurations = SpringFactoriesLoader.loadFactoryNames(getSpringFactoriesLoaderFactoryClass(), getBeanClassLoader()); Assert.notEmpty(configurations, &quot;No auto configuration classes found in META-INF/spring.factories. If you &quot; + &quot;are using a custom packaging, make sure that file is correct.&quot;); return configurations; &#125; protected Class&lt;?&gt; getSpringFactoriesLoaderFactoryClass() &#123; return EnableAutoConfiguration.class; &#125;&#125;private static class AutoConfigurationGroup implements DeferredImportSelector.Group, BeanClassLoaderAware, BeanFactoryAware, ResourceLoaderAware &#123; public void process(AnnotationMetadata annotationMetadata, DeferredImportSelector deferredImportSelector) &#123; Assert.state(deferredImportSelector instanceof AutoConfigurationImportSelector, () -&gt; String.format(&quot;Only %s implementations are supported, got %s&quot;, AutoConfigurationImportSelector.class.getSimpleName(), deferredImportSelector.getClass().getName())); AutoConfigurationEntry autoConfigurationEntry = ((AutoConfigurationImportSelector) deferredImportSelector).getAutoConfigurationEntry(annotationMetadata); this.autoConfigurationEntries.add(autoConfigurationEntry); for (String importClassName : autoConfigurationEntry.getConfigurations()) &#123; this.entries.putIfAbsent(importClassName, annotationMetadata); &#125; &#125; @Override public Iterable&lt;Entry&gt; selectImports() &#123; if (this.autoConfigurationEntries.isEmpty()) &#123; return Collections.emptyList(); &#125; Set&lt;String&gt; allExclusions = this.autoConfigurationEntries.stream() .map(AutoConfigurationEntry::getExclusions).flatMap(Collection::stream).collect(Collectors.toSet()); Set&lt;String&gt; processedConfigurations = this.autoConfigurationEntries.stream() .map(AutoConfigurationEntry::getConfigurations).flatMap(Collection::stream) .collect(Collectors.toCollection(LinkedHashSet::new)); processedConfigurations.removeAll(allExclusions); return sortAutoConfigurations(processedConfigurations, getAutoConfigurationMetadata()).stream() .map((importClassName) -&gt; new Entry(this.entries.get(importClassName), importClassName)) .collect(Collectors.toList()); &#125;&#125; @Conditional有很多扩展注解，最终这些扩展注解是通过 @Conditional中指定的类来处理具体的逻辑的。最终都是通过 SpringBootCondition 的 matches 方法。 @Conditional扩展注解 判断件 具体处理类 @ConditionalOnJava 系统的java版本是否符合要求 OnJavaCondition @ConditionalOnBean 容器中存在指定Bean OnBeanCondition @ConditionalOnMissingBean 容器中不存在指定Bean OnBeanCondition @ConditionalOnExpression 满足SpEL表达式指定 OnExpressionCondition @ConditionalOnClass 系统中有指定的类 OnClassCondition @ConditionalOnMissingClass 系统中没有指定的类 OnClassCondition @ConditionalOnSingleCandidate 容器中只有一个指定的Bean或者该Bean是首选Bean OnBeanCondition @ConditionalOnProperty 系统中指定的属性是否有指定的值 OnPropertyCondition @ConditionalOnResource 类路径下是否存在指定资源文件 OnResourceCondition @ConditionalOnNotWebApplication 不是Web应用 OnWebApplicationCondition @ConditionalOnWebApplication 是Web应用 OnWebApplicationCondition getMatchOutcome 方法是提供给具体的处理类去实现的。 12345678910111213141516171819202122232425262728293031323334353637383940414243public abstract class SpringBootCondition implements Condition &#123; public final boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) &#123; String classOrMethodName = getClassOrMethodName(metadata); try &#123; ConditionOutcome outcome = getMatchOutcome(context, metadata); logOutcome(classOrMethodName, outcome); recordEvaluation(context, classOrMethodName, outcome); return outcome.isMatch(); &#125; catch (NoClassDefFoundError ex) &#123; throw new IllegalStateException(ex.getMessage(), ex); &#125; catch (RuntimeException ex) &#123; throw new IllegalStateException(&quot;Error processing condition on &quot; + getName(metadata), ex); &#125; &#125; public abstract ConditionOutcome getMatchOutcome(ConditionContext context, AnnotatedTypeMetadata metadata);&#125;class OnClassCondition extends FilteringSpringBootCondition &#123; public ConditionOutcome getMatchOutcome(ConditionContext context, AnnotatedTypeMetadata metadata) &#123; ClassLoader classLoader = context.getClassLoader(); ConditionMessage matchMessage = ConditionMessage.empty(); List&lt;String&gt; onClasses = getCandidates(metadata, ConditionalOnClass.class); if (onClasses != null) &#123; List&lt;String&gt; missing = filter(onClasses, ClassNameFilter.MISSING, classLoader); if (!missing.isEmpty()) &#123; return ConditionOutcome.noMatch(ConditionMessage.forCondition(ConditionalOnClass.class) .didNotFind(&quot;required class&quot;, &quot;required classes&quot;).items(Style.QUOTE, missing)); &#125; matchMessage = matchMessage.andCondition(ConditionalOnClass.class) .found(&quot;required class&quot;, &quot;required classes&quot;) .items(Style.QUOTE, filter(onClasses, ClassNameFilter.PRESENT, classLoader)); &#125; List&lt;String&gt; onMissingClasses = getCandidates(metadata, ConditionalOnMissingClass.class); if (onMissingClasses != null) &#123; List&lt;String&gt; present = filter(onMissingClasses, ClassNameFilter.PRESENT, classLoader); if (!present.isEmpty()) &#123; return ConditionOutcome.noMatch(ConditionMessage.forCondition(ConditionalOnMissingClass.class).found(&quot;unwanted class&quot;, &quot;unwanted classes&quot;).items(Style.QUOTE, present)); &#125; matchMessage = matchMessage.andCondition(ConditionalOnMissingClass.class) .didNotFind(&quot;unwanted class&quot;, &quot;unwanted classes&quot;) .items(Style.QUOTE, filter(onMissingClasses, ClassNameFilter.MISSING, classLoader)); &#125; return ConditionOutcome.match(matchMessage); &#125;&#125;","tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://example.com/tags/SpringBoot/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"},{"name":"SpringBoot","slug":"Spring/SpringBoot","permalink":"http://example.com/categories/Spring/SpringBoot/"}]},{"title":"SpringBoot资源加载","date":"2020-10-15T05:08:20.000Z","path":"blog/Spring/SpringBoot/SpringBoot资源加载/","text":"@ConfigurationProperties被 @ConfigurationProperties 注解修饰的类的属性注入，可通过 @ConfigurationPropertiesScan 和 @EnableConfigurationProperties 注解将 @ConfigurationProperties 修饰的类注册到Spring容器中，且注册处理属性注入的 BeanPostProcessor 后置处理器及相关的类。 @EnableConfigurationProperties 注解通过 @Import 注解导入 EnableConfigurationPropertiesRegistrar 。能讲该注解 value属性中配置的加了 @ConfigurationProperties 注解的类注册到Spring容器中。 12345678@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(EnableConfigurationPropertiesRegistrar.class)public @interface EnableConfigurationProperties &#123; String VALIDATOR_BEAN_NAME = &quot;configurationPropertiesValidator&quot;; Class&lt;?&gt;[] value() default &#123;&#125;;&#125; EnableConfigurationPropertiesRegistrar 实现了 ImportBeanDefinitionRegistrar 接口，在扫描 BeanDefinition 时被调用 registerBeanDefinitions 方法，从而完成 ConfigurationPropertiesBindingPostProcessor 、 BoundConfigurationProperties 、 ConfigurationPropertiesBinder 等处理属性注入的Bean的注册。 通过 getTypes 方法获取 @EnableConfigurationProperties 注解中 value属性配置的类，遍历这些类通过 ConfigurationPropertiesBeanRegistrar#register 将这些类注册到Spring容器中。 1234567891011121314151617class EnableConfigurationPropertiesRegistrar implements ImportBeanDefinitionRegistrar &#123; public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry) &#123; registerInfrastructureBeans(registry); ConfigurationPropertiesBeanRegistrar beanRegistrar = new ConfigurationPropertiesBeanRegistrar(registry); getTypes(metadata).forEach(beanRegistrar::register); &#125; static void registerInfrastructureBeans(BeanDefinitionRegistry registry) &#123; ConfigurationPropertiesBindingPostProcessor.register(registry); BoundConfigurationProperties.register(registry); ConfigurationBeanFactoryMetadata.register(registry); &#125; private Set&lt;Class&lt;?&gt;&gt; getTypes(AnnotationMetadata metadata) &#123; return metadata.getAnnotations().stream(EnableConfigurationProperties.class) .flatMap((annotation) -&gt; Arrays.stream(annotation.getClassArray(MergedAnnotation.VALUE))) .filter((type) -&gt; void.class != type).collect(Collectors.toSet()); &#125;&#125; 再通过 ConfigurationPropertiesBeanRegistrar 将其注册到Spring容器前会检查该类上是否存在 @ConfigurationProperties 注解，且通过该方式生成Bean的名称和通过 @Component 等注解生成Bean不一样。这里会将 @ConfigurationProperties 注解 prefix 属性配置的值加上 - 再加上类的全限定名。 12345678910111213141516171819202122232425262728final class ConfigurationPropertiesBeanRegistrar &#123; void register(Class&lt;?&gt; type) &#123; MergedAnnotation&lt;ConfigurationProperties&gt; annotation = MergedAnnotations .from(type, SearchStrategy.TYPE_HIERARCHY).get(ConfigurationProperties.class); register(type, annotation); &#125; void register(Class&lt;?&gt; type, MergedAnnotation&lt;ConfigurationProperties&gt; annotation) &#123; String name = getName(type, annotation); // 特殊化Bean的名称 if (!containsBeanDefinition(name)) &#123;// 判断该Bean是否注册到容器中 registerBeanDefinition(name, type, annotation); // 注册BeanDefinition到容器中 &#125; &#125; private String getName(Class&lt;?&gt; type, MergedAnnotation&lt;ConfigurationProperties&gt; annotation) &#123; String prefix = annotation.isPresent() ? annotation.getString(&quot;prefix&quot;) : &quot;&quot;; return (StringUtils.hasText(prefix) ? prefix + &quot;-&quot; + type.getName() : type.getName()); &#125; private void registerBeanDefinition(String beanName, Class&lt;?&gt; type, MergedAnnotation&lt;ConfigurationProperties&gt; annotation) &#123; this.registry.registerBeanDefinition(beanName, createBeanDefinition(beanName, type)); &#125; private BeanDefinition createBeanDefinition(String beanName, Class&lt;?&gt; type) &#123; if (BindMethod.forType(type) == BindMethod.VALUE_OBJECT) &#123; // 根据该类是否有构造函数，且构造函数上是否有ConstructorBinding注解 return new ConfigurationPropertiesValueObjectBeanDefinition(this.beanFactory, beanName, type); &#125; GenericBeanDefinition definition = new GenericBeanDefinition(); definition.setBeanClass(type); return definition; &#125;&#125; ConfigurationPropertiesBindingPostProcessor 实现了 BeanPostProcessor 后置处理器，在Bean创建过程中会调用该Bean的后置处理器的 postProcessBeforeInitialization 最终通过 ConfigurationPropertiesBinder 完成属性的注入。 12345678910111213141516171819202122232425262728293031public class ConfigurationPropertiesBindingPostProcessor implements BeanPostProcessor, PriorityOrdered, ApplicationContextAware, InitializingBean &#123; public static void register(BeanDefinitionRegistry registry) &#123; Assert.notNull(registry, &quot;Registry must not be null&quot;); if (!registry.containsBeanDefinition(BEAN_NAME)) &#123; GenericBeanDefinition definition = new GenericBeanDefinition(); definition.setBeanClass(ConfigurationPropertiesBindingPostProcessor.class); definition.setRole(BeanDefinition.ROLE_INFRASTRUCTURE); registry.registerBeanDefinition(BEAN_NAME, definition); &#125; ConfigurationPropertiesBinder.register(registry); &#125; public void afterPropertiesSet() throws Exception &#123; this.registry = (BeanDefinitionRegistry) this.applicationContext.getAutowireCapableBeanFactory(); this.binder = ConfigurationPropertiesBinder.get(this.applicationContext); &#125; public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; bind(ConfigurationPropertiesBean.get(this.applicationContext, bean, beanName)); return bean; &#125; private void bind(ConfigurationPropertiesBean bean) &#123; if (bean == null || hasBoundValueObject(bean.getName())) &#123; return; &#125; Assert.state(bean.getBindMethod() == BindMethod.JAVA_BEAN, &quot;Cannot bind @ConfigurationProperties for bean &#x27;&quot; + bean.getName() + &quot;&#x27;. Ensure that @ConstructorBinding has not been applied to regular bean&quot;); try &#123; this.binder.bind(bean); &#125; catch (Exception ex) &#123; throw new ConfigurationPropertiesBindException(bean, ex); &#125; &#125;&#125; 最终通过层层调用将从 PropertySources 匹配到的属性值通过set方法将属性赋值。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102class ConfigurationPropertiesBinder &#123; BindResult&lt;?&gt; bind(ConfigurationPropertiesBean propertiesBean) &#123; Bindable&lt;?&gt; target = propertiesBean.asBindTarget(); ConfigurationProperties annotation = propertiesBean.getAnnotation(); BindHandler bindHandler = getBindHandler(target, annotation); return getBinder().bind(annotation.prefix(), target, bindHandler); &#125; private Binder getBinder() &#123; if (this.binder == null) &#123; this.binder = new Binder(getConfigurationPropertySources(), getPropertySourcesPlaceholdersResolver(), getConversionService(), getPropertyEditorInitializer(), null, ConfigurationPropertiesBindConstructorProvider.INSTANCE); &#125; return this.binder; &#125;&#125;public class Binder &#123; public &lt;T&gt; BindResult&lt;T&gt; bind(ConfigurationPropertyName name, Bindable&lt;T&gt; target, BindHandler handler) &#123; T bound = bind(name, target, handler, false); return BindResult.of(bound); &#125; private &lt;T&gt; T bind(ConfigurationPropertyName name, Bindable&lt;T&gt; target, BindHandler handler, Context context, boolean allowRecursiveBinding, boolean create) &#123; try &#123; Bindable&lt;T&gt; replacementTarget = handler.onStart(name, target, context); if (replacementTarget == null) &#123; return handleBindResult(name, target, handler, context, null, create); &#125; target = replacementTarget; Object bound = bindObject(name, target, handler, context, allowRecursiveBinding); return handleBindResult(name, target, handler, context, bound, create); &#125; catch (Exception ex) &#123; return handleBindError(name, target, handler, context, ex); &#125; &#125; private Object bindDataObject(ConfigurationPropertyName name, Bindable&lt;?&gt; target, BindHandler handler, Context context, boolean allowRecursiveBinding) &#123; if (isUnbindableBean(name, target, context)) &#123; return null; &#125; Class&lt;?&gt; type = target.getType().resolve(Object.class); if (!allowRecursiveBinding &amp;&amp; context.isBindingDataObject(type)) &#123; return null; &#125; DataObjectPropertyBinder propertyBinder = (propertyName, propertyTarget) -&gt; bind(name.append(propertyName), propertyTarget, handler, context, false, false); return context.withDataObject(type, () -&gt; &#123; for (DataObjectBinder dataObjectBinder : this.dataObjectBinders) &#123; Object instance = dataObjectBinder.bind(name, target, context, propertyBinder); if (instance != null) &#123; return instance; &#125; &#125; return null; &#125;); &#125;&#125;class JavaBeanBinder implements DataObjectBinder &#123; public &lt;T&gt; T bind(ConfigurationPropertyName name, Bindable&lt;T&gt; target, Context context, DataObjectPropertyBinder propertyBinder) &#123; boolean hasKnownBindableProperties = target.getValue() != null &amp;&amp; hasKnownBindableProperties(name, context); Bean&lt;T&gt; bean = Bean.get(target, hasKnownBindableProperties); if (bean == null) &#123; return null; &#125; BeanSupplier&lt;T&gt; beanSupplier = bean.getSupplier(target); boolean bound = bind(propertyBinder, bean, beanSupplier, context); return (bound ? beanSupplier.get() : null); &#125; private &lt;T&gt; boolean bind(DataObjectPropertyBinder propertyBinder, Bean&lt;T&gt; bean, BeanSupplier&lt;T&gt; beanSupplier, Context context) &#123; boolean bound = false; for (BeanProperty beanProperty : bean.getProperties().values()) &#123; bound |= bind(beanSupplier, propertyBinder, beanProperty); context.clearConfigurationProperty(); &#125; return bound; &#125; private &lt;T&gt; boolean bind(BeanSupplier&lt;T&gt; beanSupplier, DataObjectPropertyBinder propertyBinder, BeanProperty property) &#123; String propertyName = property.getName(); ResolvableType type = property.getType(); Supplier&lt;Object&gt; value = property.getValue(beanSupplier); Annotation[] annotations = property.getAnnotations(); Object bound = propertyBinder.bindProperty(propertyName, Bindable.of(type).withSuppliedValue(value).withAnnotations(annotations)); if (bound == null) &#123; return false; &#125; if (property.isSettable()) &#123; property.setValue(beanSupplier, bound); &#125; else if (value == null || !bound.equals(value.get())) &#123; throw new IllegalStateException(&quot;No setter found for property: &quot; + property.getName()); &#125; return true; &#125;&#125;static class BeanProperty &#123; private Method getter; private Method setter; private Field field; void setValue(Supplier&lt;?&gt; instance, Object value) &#123; try &#123; this.setter.setAccessible(true); this.setter.invoke(instance.get(), value); &#125; catch (Exception ex) &#123; throw new IllegalStateException(&quot;Unable to set value for property &quot; + this.name, ex); &#125; &#125;&#125; @ConfigurationPropertiesScan 注解的作用是扫描所有带有 @ConfigurationProperties 注解的类将其注册到Spring容器中。且该注解上被 @EnableConfigurationProperties 注解标记。 123456789101112@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(ConfigurationPropertiesScanRegistrar.class)@EnableConfigurationPropertiespublic @interface ConfigurationPropertiesScan &#123; @AliasFor(&quot;basePackages&quot;) String[] value() default &#123;&#125;; @AliasFor(&quot;value&quot;) String[] basePackages() default &#123;&#125;; Class&lt;?&gt;[] basePackageClasses() default &#123;&#125;;&#125; ConfigurationPropertiesScanRegistrar 同样实现了 ImportBeanDefinitionRegistrar 接口，首先获取需要扫描的包，若未指定则以当前注解所在类所在的包作为扫描包，通过 ClassPathScanningCandidateComponentProvider 遍历扫描所有的包，扫描出包中被 @ConfigurationProperties 注解标注，但是未被 @Component 注解及其派生注解标注的类，注册到Spring容器中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253class ConfigurationPropertiesScanRegistrar implements ImportBeanDefinitionRegistrar &#123; public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; Set&lt;String&gt; packagesToScan = getPackagesToScan(importingClassMetadata); // 获取扫描的包 scan(registry, packagesToScan); // 扫描出包中所有带有@ConfigurationProperties注解的类，注册到Spring容器中 &#125; private Set&lt;String&gt; getPackagesToScan(AnnotationMetadata metadata) &#123; AnnotationAttributes attributes = AnnotationAttributes.fromMap(metadata.getAnnotationAttributes(ConfigurationPropertiesScan.class.getName())); String[] basePackages = attributes.getStringArray(&quot;basePackages&quot;); Class&lt;?&gt;[] basePackageClasses = attributes.getClassArray(&quot;basePackageClasses&quot;); Set&lt;String&gt; packagesToScan = new LinkedHashSet&lt;&gt;(Arrays.asList(basePackages)); for (Class&lt;?&gt; basePackageClass : basePackageClasses) &#123; packagesToScan.add(ClassUtils.getPackageName(basePackageClass)); &#125; if (packagesToScan.isEmpty()) &#123; // 若未指定则以当前注解所在类所在的包作为扫描包 packagesToScan.add(ClassUtils.getPackageName(metadata.getClassName())); &#125; packagesToScan.removeIf((candidate) -&gt; !StringUtils.hasText(candidate)); return packagesToScan; &#125; private void scan(BeanDefinitionRegistry registry, Set&lt;String&gt; packages) &#123; ConfigurationPropertiesBeanRegistrar registrar = new ConfigurationPropertiesBeanRegistrar(registry); ClassPathScanningCandidateComponentProvider scanner = getScanner(registry); for (String basePackage : packages) &#123; for (BeanDefinition candidate : scanner.findCandidateComponents(basePackage)) &#123; register(registrar, candidate.getBeanClassName()); &#125; &#125; &#125; private ClassPathScanningCandidateComponentProvider getScanner(BeanDefinitionRegistry registry) &#123; ClassPathScanningCandidateComponentProvider scanner = new ClassPathScanningCandidateComponentProvider(false); scanner.setEnvironment(this.environment); scanner.setResourceLoader(this.resourceLoader); scanner.addIncludeFilter(new AnnotationTypeFilter(ConfigurationProperties.class)); // 添加过滤器，过滤出带有@ConfigurationProperties注解的类 TypeExcludeFilter typeExcludeFilter = new TypeExcludeFilter(); typeExcludeFilter.setBeanFactory((BeanFactory) registry); scanner.addExcludeFilter(typeExcludeFilter); return scanner; &#125; private void register(ConfigurationPropertiesBeanRegistrar registrar, String className) throws LinkageError &#123; try &#123; register(registrar, ClassUtils.forName(className, null)); &#125; catch (ClassNotFoundException ex) &#123; &#125; &#125; private void register(ConfigurationPropertiesBeanRegistrar registrar, Class&lt;?&gt; type) &#123; if (!isComponent(type)) &#123; // 该类没有被@Component注解修饰 registrar.register(type); // 注册过程和上面一样 &#125; &#125; private boolean isComponent(Class&lt;?&gt; type) &#123; return MergedAnnotations.from(type, SearchStrategy.TYPE_HIERARCHY).isPresent(Component.class); &#125;&#125; Enviroment Enviroment 是Spring为运行环境提供的高度抽象接口，项目运行中的所有相关配置都基于此接口，在 SpringApplication 的 prepareEnvironment 方法中完成了配置文件的加载。通过发布环境准备就绪事件 ApplicationEnvironmentPreparedEvent ，从而加载项目中的配置文件。 123456789101112131415private ConfigurableEnvironment prepareEnvironment(SpringApplicationRunListeners listeners, DefaultBootstrapContext bootstrapContext, ApplicationArguments applicationArguments) &#123; // Create and configure the environment ConfigurableEnvironment environment = getOrCreateEnvironment(); // 获取或创建ConfigurableEnvironment，会调用超类AbstractEnvironment的无参构造方法 configureEnvironment(environment, applicationArguments.getSourceArgs()); // 加载默认配置 ConfigurationPropertySources.attach(environment); listeners.environmentPrepared(bootstrapContext, environment); // 发布环境准备就绪事件ApplicationEnvironmentPreparedEvent，从而加载项目中的配置文件 DefaultPropertiesPropertySource.moveToEnd(environment); // 将defaultProperties移到列表最后，即将其优先级降到最低 Assert.state(!environment.containsProperty(&quot;spring.main.environment-prefix&quot;), &quot;Environment prefix cannot be set via properties.&quot;); bindToSpringApplication(environment); if (!this.isCustomEnvironment) &#123; environment = new EnvironmentConverter(getClassLoader()).convertEnvironmentIfNecessary(environment, deduceEnvironmentClass()); &#125; ConfigurationPropertySources.attach(environment); return environment;&#125; 在 getOrCreateEnvironment 方法中对 Environment 初始化，以 ApplicationServletEnvironment 为例，其初始化时会调用超类 AbstractEnvironment 的无参构造函数，然后调用子类 StandardServletEnvironment 实现的 customizePropertySources 方法，添加类型为 StubPropertySource 的 servletConfigInitParams 和 servletContextInitParams ，然后再调用其父类 StandardEnvironment 的 customizePropertySources 方法，将 systemProperties 和 systemEnvironment 加载到 Environment 中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class SpringApplication &#123; private ConfigurableEnvironment getOrCreateEnvironment() &#123; if (this.environment != null) &#123; return this.environment; &#125; switch (this.webApplicationType) &#123; case SERVLET: return new ApplicationServletEnvironment(); case REACTIVE: return new ApplicationReactiveWebEnvironment(); default: return new ApplicationEnvironment(); &#125; &#125;&#125;class ApplicationServletEnvironment extends StandardServletEnvironment &#123; protected ConfigurablePropertyResolver createPropertyResolver(MutablePropertySources propertySources) &#123; return ConfigurationPropertySources.createPropertyResolver(propertySources); &#125;&#125;public class StandardServletEnvironment extends StandardEnvironment implements ConfigurableWebEnvironment &#123; public static final String SERVLET_CONTEXT_PROPERTY_SOURCE_NAME = &quot;servletContextInitParams&quot;; public static final String SERVLET_CONFIG_PROPERTY_SOURCE_NAME = &quot;servletConfigInitParams&quot;; public static final String JNDI_PROPERTY_SOURCE_NAME = &quot;jndiProperties&quot;; protected void customizePropertySources(MutablePropertySources propertySources) &#123; propertySources.addLast(new StubPropertySource(SERVLET_CONFIG_PROPERTY_SOURCE_NAME)); propertySources.addLast(new StubPropertySource(SERVLET_CONTEXT_PROPERTY_SOURCE_NAME)); if (JndiLocatorDelegate.isDefaultJndiEnvironmentAvailable()) &#123; propertySources.addLast(new JndiPropertySource(JNDI_PROPERTY_SOURCE_NAME)); &#125; super.customizePropertySources(propertySources); &#125;&#125;public class StandardEnvironment extends AbstractEnvironment &#123; public static final String SYSTEM_ENVIRONMENT_PROPERTY_SOURCE_NAME = &quot;systemEnvironment&quot;; public static final String SYSTEM_PROPERTIES_PROPERTY_SOURCE_NAME = &quot;systemProperties&quot;; protected void customizePropertySources(MutablePropertySources propertySources) &#123; propertySources.addLast(new PropertiesPropertySource(SYSTEM_PROPERTIES_PROPERTY_SOURCE_NAME, getSystemProperties())); propertySources.addLast(new SystemEnvironmentPropertySource(SYSTEM_ENVIRONMENT_PROPERTY_SOURCE_NAME, getSystemEnvironment())); &#125;&#125;public abstract class AbstractEnvironment implements ConfigurableEnvironment &#123; public AbstractEnvironment() &#123; this(new MutablePropertySources()); &#125; protected AbstractEnvironment(MutablePropertySources propertySources) &#123; this.propertySources = propertySources; this.propertyResolver = createPropertyResolver(propertySources); customizePropertySources(propertySources); &#125; protected void customizePropertySources(MutablePropertySources propertySources) &#123; &#125;&#125; 发布环境准备就绪事件 ApplicationEnvironmentPreparedEvent 是通过 getRunListeners 中从 spring.factories 配置文件加载的 EventPublishingRunListener 来完成的。 123# Run Listenersorg.springframework.boot.SpringApplicationRunListener=\\org.springframework.boot.context.event.EventPublishingRunListener 123456public class SpringApplication &#123; private SpringApplicationRunListeners getRunListeners(String[] args) &#123; Class&lt;?&gt;[] types = new Class&lt;?&gt;[] &#123; SpringApplication.class, String[].class &#125;; return new SpringApplicationRunListeners(logger, getSpringFactoriesInstances(SpringApplicationRunListener.class, types, this, args)); &#125;&#125; 故最终会调用 EventPublishingRunListener 的 environmentPrepared 方法来发布 ApplicationEnvironmentPreparedEvent 事件。 12345678910class SpringApplicationRunListeners &#123; void environmentPrepared(ConfigurableBootstrapContext bootstrapContext, ConfigurableEnvironment environment) &#123; doWithListeners(&quot;spring.boot.application.environment-prepared&quot;, (listener) -&gt; listener.environmentPrepared(bootstrapContext, environment)); &#125;&#125;public class EventPublishingRunListener implements SpringApplicationRunListener, Ordered &#123; public void environmentPrepared(ConfigurableBootstrapContext bootstrapContext, ConfigurableEnvironment environment) &#123; this.initialMulticaster.multicastEvent(new ApplicationEnvironmentPreparedEvent(bootstrapContext, this.application, this.args, environment)); &#125;&#125; 监听了 ApplicationEnvironmentPreparedEvent 事件的类很多个，旧版本中是通过 ConfigFileApplicationListener 来加载配置文件，该监听器的加载是通过 SpringApplication构造方法中通过 getSpringFactoriesInstances 方法从 spring.factories 配置文件中加载 ApplicationListener 时加载的。新版本是通过 ConfigDataEnvironmentPostProcessor 来加载的配置文件，其是通过加载 ApplicationListener 时加载的 EnvironmentPostProcessorApplicationListener 监听器时该类的构造方法中又加载了一系列 EnvironmentPostProcessor 后置处理器中的一个。这里 DEFAULT_SEARCH_LOCATIONS 体现了配置文件加载顺序。 1234567891011121314151617181920212223242526272829303132public class ConfigFileApplicationListener implements EnvironmentPostProcessor, SmartApplicationListener, Ordered &#123; private static final String DEFAULT_SEARCH_LOCATIONS = &quot;classpath:/,classpath:/config/,file:./,file:./config/*/,file:./config/&quot;; private static final String DEFAULT_PROPERTIES = &quot;defaultProperties&quot;; private static final String DEFAULT_NAMES = &quot;application&quot;; public void onApplicationEvent(ApplicationEvent event) &#123; if (event instanceof ApplicationEnvironmentPreparedEvent) &#123; onApplicationEnvironmentPreparedEvent((ApplicationEnvironmentPreparedEvent) event); &#125; if (event instanceof ApplicationPreparedEvent) &#123; onApplicationPreparedEvent(event); &#125; &#125; private void onApplicationEnvironmentPreparedEvent(ApplicationEnvironmentPreparedEvent event) &#123; List&lt;EnvironmentPostProcessor&gt; postProcessors = loadPostProcessors(); postProcessors.add(this); AnnotationAwareOrderComparator.sort(postProcessors); for (EnvironmentPostProcessor postProcessor : postProcessors) &#123; postProcessor.postProcessEnvironment(event.getEnvironment(), event.getSpringApplication()); &#125; &#125; List&lt;EnvironmentPostProcessor&gt; loadPostProcessors() &#123; // 加载spring.factories配置文件中以EnvironmentPostProcessor为key配置的类 return SpringFactoriesLoader.loadFactories(EnvironmentPostProcessor.class, getClass().getClassLoader()); &#125; public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application) &#123; addPropertySources(environment, application.getResourceLoader()); &#125; protected void addPropertySources(ConfigurableEnvironment environment, ResourceLoader resourceLoader) &#123; RandomValuePropertySource.addToEnvironment(environment); new Loader(environment, resourceLoader).load(); // 最终通过该处去加载配置文件 &#125;&#125; ConfigFileApplicationListener 也实现了 EnvironmentPostProcessor 故最终会执行其 postProcessEnvironment 方法最终通过 Loader 类来加载配置文件。构造方法中会加载 PropertySourceLoader ，主要是 PropertiesPropertySourceLoader 和 YamlPropertySourceLoader 12345678private class Loader &#123; Loader(ConfigurableEnvironment environment, ResourceLoader resourceLoader) &#123; this.environment = environment; this.placeholdersResolver = new PropertySourcesPlaceholdersResolver(this.environment); this.resourceLoader = (resourceLoader != null) ? resourceLoader : new DefaultResourceLoader(null); this.propertySourceLoaders = SpringFactoriesLoader.loadFactories(PropertySourceLoader.class, getClass().getClassLoader()); &#125;&#125; 1234# PropertySource Loadersorg.springframework.boot.env.PropertySourceLoader=\\org.springframework.boot.env.PropertiesPropertySourceLoader,\\org.springframework.boot.env.YamlPropertySourceLoader 最终调用load方法来加载配置文件，首先获取需要遍历的目录，其实就是将 DEFAULT_SEARCH_LOCATIONS 中的目录拆分成数组，并进行反序，若为Cloud项目会在 BootstrapApplicationListener 中添加 MapPropertySource 配置，从而会获取 spring.config.name 设置的值，默认是 bootstrap ，故默认会先加载各个目录下的 bootstrap 配置文件。然后再加载 application 配置文件。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061void load() &#123; FilteredPropertySource.apply(this.environment, DEFAULT_PROPERTIES, LOAD_FILTERED_PROPERTY, (defaultProperties) -&gt; &#123; this.profiles = new LinkedList&lt;&gt;(); this.processedProfiles = new LinkedList&lt;&gt;(); this.activatedProfiles = false; this.loaded = new LinkedHashMap&lt;&gt;(); initializeProfiles(); while (!this.profiles.isEmpty()) &#123; Profile profile = this.profiles.poll(); if (isDefaultProfile(profile)) &#123; addProfileToEnvironment(profile.getName()); &#125; load(profile, this::getPositiveProfileFilter, addToLoaded(MutablePropertySources::addLast, false)); this.processedProfiles.add(profile); &#125; load(null, this::getNegativeProfileFilter, addToLoaded(MutablePropertySources::addFirst, true)); addLoadedPropertySources(); applyActiveProfiles(defaultProperties); &#125;);&#125;class FilteredPropertySource extends PropertySource&lt;PropertySource&lt;?&gt;&gt; &#123; static void apply(ConfigurableEnvironment environment, String propertySourceName, Set&lt;String&gt; filteredProperties, Consumer&lt;PropertySource&lt;?&gt;&gt; operation) &#123; MutablePropertySources propertySources = environment.getPropertySources(); PropertySource&lt;?&gt; original = propertySources.get(propertySourceName); if (original == null) &#123; operation.accept(null); return; &#125; propertySources.replace(propertySourceName, new FilteredPropertySource(original, filteredProperties)); try &#123; operation.accept(original); &#125; finally &#123; propertySources.replace(propertySourceName, original); &#125; &#125;&#125;private void load(Profile profile, DocumentFilterFactory filterFactory, DocumentConsumer consumer) &#123; getSearchLocations().forEach((location) -&gt; &#123; boolean isDirectory = location.endsWith(&quot;/&quot;); Set&lt;String&gt; names = isDirectory ? getSearchNames() : NO_SEARCH_NAMES; names.forEach((name) -&gt; load(location, name, profile, filterFactory, consumer)); &#125;);&#125;private Set&lt;String&gt; getSearchLocations() &#123; Set&lt;String&gt; locations = getSearchLocations(CONFIG_ADDITIONAL_LOCATION_PROPERTY); if (this.environment.containsProperty(CONFIG_LOCATION_PROPERTY)) &#123; locations.addAll(getSearchLocations(CONFIG_LOCATION_PROPERTY)); &#125; else &#123; // 将DEFAULT_SEARCH_LOCATIONS中的目录拆分成数组，并进行反序 locations.addAll(asResolvedSet(ConfigFileApplicationListener.this.searchLocations, DEFAULT_SEARCH_LOCATIONS)); &#125; return locations;&#125;private Set&lt;String&gt; getSearchNames() &#123; if (this.environment.containsProperty(CONFIG_NAME_PROPERTY)) &#123; String property = this.environment.getProperty(CONFIG_NAME_PROPERTY); Set&lt;String&gt; names = asResolvedSet(property, null); names.forEach(this::assertValidConfigName); return names; &#125; return asResolvedSet(ConfigFileApplicationListener.this.names, DEFAULT_NAMES);&#125; 遍历 propertySourceLoaders 依次通过 PropertiesPropertySourceLoader 和 YamlPropertySourceLoader 去加载解析配置文件。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879private void load(String location, String name, Profile profile, DocumentFilterFactory filterFactory, DocumentConsumer consumer) &#123; if (!StringUtils.hasText(name)) &#123; for (PropertySourceLoader loader : this.propertySourceLoaders) &#123; if (canLoadFileExtension(loader, location)) &#123; load(loader, location, profile, filterFactory.getDocumentFilter(profile), consumer); return; &#125; &#125; throw new IllegalStateException(&quot;File extension of config file location &#x27;&quot; + location + &quot;&#x27; is not known to any PropertySourceLoader. If the location is meant to reference &quot; + &quot;a directory, it must end in &#x27;/&#x27;&quot;); &#125; Set&lt;String&gt; processed = new HashSet&lt;&gt;(); for (PropertySourceLoader loader : this.propertySourceLoaders) &#123; for (String fileExtension : loader.getFileExtensions()) &#123; if (processed.add(fileExtension)) &#123; loadForFileExtension(loader, location + name, &quot;.&quot; + fileExtension, profile, filterFactory, consumer); &#125; &#125; &#125;&#125;private void loadForFileExtension(PropertySourceLoader loader, String prefix, String fileExtension, Profile profile, DocumentFilterFactory filterFactory, DocumentConsumer consumer) &#123; DocumentFilter defaultFilter = filterFactory.getDocumentFilter(null); DocumentFilter profileFilter = filterFactory.getDocumentFilter(profile); if (profile != null) &#123; // 若设置了环境则加载对应环境的配置文件 String profileSpecificFile = prefix + &quot;-&quot; + profile + fileExtension; load(loader, profileSpecificFile, profile, defaultFilter, consumer); load(loader, profileSpecificFile, profile, profileFilter, consumer); for (Profile processedProfile : this.processedProfiles) &#123; if (processedProfile != null) &#123; String previouslyLoaded = prefix + &quot;-&quot; + processedProfile + fileExtension; load(loader, previouslyLoaded, profile, profileFilter, consumer); &#125; &#125; &#125; load(loader, prefix + fileExtension, profile, profileFilter, consumer);&#125;private void load(PropertySourceLoader loader, String location, Profile profile, DocumentFilter filter, DocumentConsumer consumer) &#123; Resource[] resources = getResources(location); for (Resource resource : resources) &#123; try &#123; if (resource == null || !resource.exists()) &#123; continue; &#125; if (!StringUtils.hasText(StringUtils.getFilenameExtension(resource.getFilename()))) &#123; continue; &#125; String name = &quot;applicationConfig: [&quot; + getLocationName(location, resource) + &quot;]&quot;; List&lt;Document&gt; documents = loadDocuments(loader, name, resource); if (CollectionUtils.isEmpty(documents)) &#123; continue; &#125; List&lt;Document&gt; loaded = new ArrayList&lt;&gt;(); for (Document document : documents) &#123; if (filter.match(document)) &#123; addActiveProfiles(document.getActiveProfiles()); addIncludedProfiles(document.getIncludeProfiles()); loaded.add(document); &#125; &#125; Collections.reverse(loaded); if (!loaded.isEmpty()) &#123; loaded.forEach((document) -&gt; consumer.accept(profile, document)); &#125; &#125; catch (Exception ex) &#123; StringBuilder description = getDescription(&quot;Failed to load property source from &quot;, location, resource, profile); throw new IllegalStateException(description.toString(), ex); &#125; &#125;&#125;private List&lt;Document&gt; loadDocuments(PropertySourceLoader loader, String name, Resource resource) throws IOException &#123; DocumentsCacheKey cacheKey = new DocumentsCacheKey(loader, resource); List&lt;Document&gt; documents = this.loadDocumentsCache.get(cacheKey); if (documents == null) &#123; // 调用具体的PropertySourceLoader去加载解析配置文件 List&lt;PropertySource&lt;?&gt;&gt; loaded = loader.load(name, resource); documents = asDocuments(loaded); this.loadDocumentsCache.put(cacheKey, documents); &#125; return documents;&#125; 若是在 Spring Cloud 项目中会通过ApplicationListener加载 BootstrapApplicationListener ，在该监听器中的 bootstrapServiceContext 方法中添加了 MapPropertySource 配置，将 spring.config.name 值设置为 configName ， configName 默认值为 bootstrap 。 1234org.springframework.context.ApplicationListener=\\org.springframework.cloud.bootstrap.BootstrapApplicationListener,\\org.springframework.cloud.bootstrap.LoggingSystemShutdownListener,\\org.springframework.cloud.context.restart.RestartListener 12345678910111213141516171819202122232425public class BootstrapApplicationListener implements ApplicationListener&lt;ApplicationEnvironmentPreparedEvent&gt;, Ordered &#123; public static final String BOOTSTRAP_PROPERTY_SOURCE_NAME = &quot;bootstrap&quot;; public void onApplicationEvent(ApplicationEnvironmentPreparedEvent event) &#123; ConfigurableEnvironment environment = event.getEnvironment(); if (!environment.getProperty(&quot;spring.cloud.bootstrap.enabled&quot;, Boolean.class, true)) &#123; return; &#125; if (environment.getPropertySources().contains(BOOTSTRAP_PROPERTY_SOURCE_NAME)) &#123; return; &#125; ConfigurableApplicationContext context = null; // 很明显configName默认值为bootstrap String configName = environment.resolvePlaceholders(&quot;$&#123;spring.cloud.bootstrap.name:bootstrap&#125;&quot;); for (ApplicationContextInitializer&lt;?&gt; initializer : event.getSpringApplication().getInitializers()) &#123; if (initializer instanceof ParentContextApplicationContextInitializer) &#123; context = findBootstrapContext((ParentContextApplicationContextInitializer) initializer, configName); &#125; &#125; if (context == null) &#123; context = bootstrapServiceContext(environment, event.getSpringApplication(), configName); event.getSpringApplication().addListeners(new CloseContextOnFailureApplicationListener(context)); &#125; apply(context, event.getSpringApplication(), environment); &#125;&#125;","tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://example.com/tags/SpringBoot/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"},{"name":"SpringBoot","slug":"Spring/SpringBoot","permalink":"http://example.com/categories/Spring/SpringBoot/"}]},{"title":"SpringBoot Jar包启动原理","date":"2020-10-15T03:08:20.000Z","path":"blog/Spring/SpringBoot/SpringBoot Jar包启动原理/","text":"在执行 java -jar 命令时会在Jar包中找到 META-INF/MANIFEST.MF 文件，在该文件中通过 Main-Class 指定了应用的 启动类 ，在SpringBoot的Jar包中 Main-Class 指定的是 JarLauncher 而非是正在的启动类，因为在Java中 没有 提供任何 标准方式 来 加载jar文件中的jar文件 ，故SpringBoot通过 JarLauncher 来执行启动类，同时加载jar包中依赖的jar文件。 123456789101112Manifest-Version: 1.0Spring-Boot-Classpath-Index: BOOT-INF/classpath.idxImplementation-Title: eleven-springbootImplementation-Version: 0.0.1-SNAPSHOTSpring-Boot-Layers-Index: BOOT-INF/layers.idxStart-Class: com.icode.eleven.elevenspringboot.ElevenSpringbootApplicationSpring-Boot-Classes: BOOT-INF/classes/Spring-Boot-Lib: BOOT-INF/lib/Build-Jdk-Spec: 1.8Spring-Boot-Version: 2.5.5Created-By: Maven Jar Plugin 3.2.0Main-Class: org.springframework.boot.loader.JarLauncher Spring-Boot-Classes 指定的 BOOT-INF/classes/ 中是应用程序类， Spring-Boot-Lib 指定的 BOOT-INF/lib/ 是第三方依赖jar路径。在Jar包中的 org/springframework/boot/loader 是SpringBoot的启动程序， JarLauncher 就在该目录下。JarLauncher可以加载内部 /BOOT-INF/lib 下的jar及 /BOOT-INF/classes 下的应用 class 。 1234567891011public class JarLauncher extends ExecutableArchiveLauncher &#123; static final EntryFilter NESTED_ARCHIVE_ENTRY_FILTER = (entry) -&gt; &#123; if (entry.isDirectory()) &#123; return entry.getName().equals(&quot;BOOT-INF/classes/&quot;); &#125; return entry.getName().startsWith(&quot;BOOT-INF/lib/&quot;); &#125;; public static void main(String[] args) throws Exception &#123; new JarLauncher().launch(args); &#125;&#125; 实例化 JarLauncher 时会先调用父类 ExecutableArchiveLauncher 的构造方法，最终调用超类Launcher中的 createArchive() 创建一个 归档文件Archive 。通过获取当前执行类所在的的磁盘路径，然后通过该路径打开一个文件，判断文件是否为目录来决定创建 ExplodedArchive 还是 JarFileArchive 。若是Jar文件这里的 classPathIndex 为 null 。 123456789101112131415161718192021222324252627282930public abstract class ExecutableArchiveLauncher extends Launcher &#123; private static final String START_CLASS_ATTRIBUTE = &quot;Start-Class&quot;; private final Archive archive; private final ClassPathIndexFile classPathIndex; public ExecutableArchiveLauncher() &#123; try &#123; this.archive = createArchive(); this.classPathIndex = getClassPathIndex(this.archive); &#125; catch (Exception ex) &#123; throw new IllegalStateException(ex); &#125; &#125;&#125;public abstract class Launcher &#123; protected final Archive createArchive() throws Exception &#123; ProtectionDomain protectionDomain = getClass().getProtectionDomain(); CodeSource codeSource = protectionDomain.getCodeSource(); URI location = (codeSource != null) ? codeSource.getLocation().toURI() : null; String path = (location != null) ? location.getSchemeSpecificPart() : null; if (path == null) &#123; throw new IllegalStateException(&quot;Unable to determine code source archive&quot;); &#125; File root = new File(path); if (!root.exists()) &#123; throw new IllegalStateException(&quot;Unable to determine code source archive from &quot; + root); &#125; return (root.isDirectory() ? new ExplodedArchive(root) : new JarFileArchive(root)); &#125;&#125; Archive有处理文件目录资源的 ExplodedArchive 和处理Jar包资源的 JarFileArchive 两个实现类。对Jar包的封装每个 JarFileArchive 都会对应一个 JarFile ， JarFile被构造时会解析内部结构去获取jar包里的各个文件或文件夹 ，这些文件或文件夹会被封装到Entry中，也存储在JarFileArchive中。若Entry是个jar会解析成JarFileArchive。 1234567public interface Archive extends Iterable&lt;Archive.Entry&gt;, AutoCloseable &#123; URL getUrl() throws MalformedURLException; // 获取该归档的url // 获取jar!/META-INF/MANIFEST.MF或[ArchiveDir]/META-INF/MANIFEST.MF Manifest getManifest() throws IOException; // 获取jar!/BOOT-INF/lib/*.jar或[ArchiveDir]/BOOT-INF/lib/*.jar List&lt;Archive&gt; getNestedArchives(EntryFilter filter) throws IOException;&#125; 执行launch方法最终调用超类Launcher中的launch方法。createClassLoader方法会遍历出满足条件的jar包，并通过其创建一个 LaunchedURLClassLoader 。 12345678910111213141516171819202122232425262728public abstract class Launcher &#123; protected void launch(String[] args) throws Exception &#123; if (!isExploded()) &#123; JarFile.registerUrlProtocolHandler(); &#125; ClassLoader classLoader = createClassLoader(getClassPathArchivesIterator()); String jarMode = System.getProperty(&quot;jarmode&quot;); String launchClass = (jarMode != null &amp;&amp; !jarMode.isEmpty()) ? JAR_MODE_LAUNCHER : getMainClass(); launch(args, launchClass, classLoader); &#125;&#125;public abstract class ExecutableArchiveLauncher extends Launcher &#123; protected ClassLoader createClassLoader(Iterator&lt;Archive&gt; archives) throws Exception &#123; List&lt;URL&gt; urls = new ArrayList&lt;&gt;(guessClassPathSize()); while (archives.hasNext()) &#123; urls.add(archives.next().getUrl()); &#125; if (this.classPathIndex != null) &#123; urls.addAll(this.classPathIndex.getUrls()); &#125; return createClassLoader(urls.toArray(new URL[0])); &#125;&#125;public abstract class Launcher &#123; protected ClassLoader createClassLoader(URL[] urls) throws Exception &#123; return new LaunchedURLClassLoader(isExploded(), getArchive(), urls, getClass().getClassLoader()); &#125;&#125; 会将 BOOT-INF/lib/ 目录下的所有文件过滤出来。 12345678910111213141516171819202122232425262728293031323334353637public abstract class ExecutableArchiveLauncher extends Launcher &#123; protected Iterator&lt;Archive&gt; getClassPathArchivesIterator() throws Exception &#123; Archive.EntryFilter searchFilter = this::isSearchCandidate; Iterator&lt;Archive&gt; archives = this.archive.getNestedArchives(searchFilter, (entry) -&gt; isNestedArchive(entry) &amp;&amp; !isEntryIndexed(entry)); if (isPostProcessingClassPathArchives()) &#123; archives = applyClassPathArchivePostProcessing(archives); &#125; return archives; &#125; protected ClassLoader createClassLoader(Iterator&lt;Archive&gt; archives) throws Exception &#123; List&lt;URL&gt; urls = new ArrayList&lt;&gt;(guessClassPathSize()); while (archives.hasNext()) &#123; urls.add(archives.next().getUrl()); &#125; if (this.classPathIndex != null) &#123; urls.addAll(this.classPathIndex.getUrls()); &#125; return createClassLoader(urls.toArray(new URL[0])); &#125;&#125;public class JarLauncher extends ExecutableArchiveLauncher &#123; static final EntryFilter NESTED_ARCHIVE_ENTRY_FILTER = (entry) -&gt; &#123; if (entry.isDirectory()) &#123; return entry.getName().equals(&quot;BOOT-INF/classes/&quot;); &#125; return entry.getName().startsWith(&quot;BOOT-INF/lib/&quot;); &#125;; protected boolean isSearchCandidate(Archive.Entry entry) &#123; return entry.getName().startsWith(&quot;BOOT-INF/&quot;); &#125; protected boolean isNestedArchive(Archive.Entry entry) &#123; return NESTED_ARCHIVE_ENTRY_FILTER.matches(entry); &#125; protected boolean isPostProcessingClassPathArchives() &#123; return false; &#125;&#125; 创建一个 NestedArchiveIterator 迭代器，迭代时调用超类AbstractIterator的next方法会回调 adapt 方法，最终调用 getNestedArchive 对于comment为 UNPACK: 开头的文件，会进行解压。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class JarFileArchive implements Archive &#123; private static final String UNPACK_MARKER = &quot;UNPACK:&quot;; public Iterator&lt;Archive&gt; getNestedArchives(EntryFilter searchFilter, EntryFilter includeFilter) throws IOException &#123; return new NestedArchiveIterator(this.jarFile.iterator(), searchFilter, includeFilter); &#125; protected Archive getNestedArchive(Entry entry) throws IOException &#123; JarEntry jarEntry = ((JarFileEntry) entry).getJarEntry(); if (jarEntry.getComment().startsWith(UNPACK_MARKER)) &#123; return getUnpackedNestedArchive(jarEntry); &#125; try &#123; JarFile jarFile = this.jarFile.getNestedJarFile(jarEntry); return new JarFileArchive(jarFile); &#125; catch (Exception ex) &#123; throw new IllegalStateException(&quot;Failed to get nested archive for entry &quot; + entry.getName(), ex); &#125; &#125; private Archive getUnpackedNestedArchive(JarEntry jarEntry) throws IOException &#123; String name = jarEntry.getName(); if (name.lastIndexOf(&#x27;/&#x27;) != -1) &#123; name = name.substring(name.lastIndexOf(&#x27;/&#x27;) + 1); &#125; Path path = getTempUnpackDirectory().resolve(name); if (!Files.exists(path) || Files.size(path) != jarEntry.getSize()) &#123; unpack(jarEntry, path); &#125; return new JarFileArchive(path.toFile(), path.toUri().toURL()); &#125;&#125;private class NestedArchiveIterator extends AbstractIterator&lt;Archive&gt; &#123; NestedArchiveIterator(Iterator&lt;JarEntry&gt; iterator, EntryFilter searchFilter, EntryFilter includeFilter) &#123; super(iterator, searchFilter, includeFilter); &#125; @Override protected Archive adapt(Entry entry) &#123; try &#123; return getNestedArchive(entry); &#125; catch (IOException ex) &#123; throw new IllegalStateException(ex); &#125; &#125;&#125;private abstract static class AbstractIterator&lt;T&gt; implements Iterator&lt;T&gt; &#123; public T next() &#123; T result = adapt(this.current); this.current = poll(); return result; &#125;&#125; 然后调用 ExecutableArchiveLauncher 的 getMainClass 或者正在的 启动类 ，即 META-INF/MANIFEST.MF 文件中配置的- Start-Class 。Manifest就是用来接收解析 META-INF/MANIFEST.MF 出来的数据。 1234567891011121314public abstract class ExecutableArchiveLauncher extends Launcher &#123; private static final String START_CLASS_ATTRIBUTE = &quot;Start-Class&quot;; protected String getMainClass() throws Exception &#123; Manifest manifest = this.archive.getManifest(); String mainClass = null; if (manifest != null) &#123; mainClass = manifest.getMainAttributes().getValue(START_CLASS_ATTRIBUTE); &#125; if (mainClass == null) &#123; throw new IllegalStateException(&quot;No &#x27;Start-Class&#x27; manifest entry specified in &quot; + this); &#125; return mainClass; &#125;&#125; 获取到启动类后通过反射调用启动类的main方法，即最终调用ElevenSpringbootApplication的main方法，从而去完成SpringBoot的启动。 1234567891011121314151617181920212223public abstract class Launcher &#123; protected void launch(String[] args, String launchClass, ClassLoader classLoader) throws Exception &#123; Thread.currentThread().setContextClassLoader(classLoader); createMainMethodRunner(launchClass, args, classLoader).run(); &#125; protected MainMethodRunner createMainMethodRunner(String mainClass, String[] args, ClassLoader classLoader) &#123; return new MainMethodRunner(mainClass, args); &#125;&#125;public class MainMethodRunner &#123; private final String mainClassName; private final String[] args; public MainMethodRunner(String mainClass, String[] args) &#123; this.mainClassName = mainClass; this.args = (args != null) ? args.clone() : null; &#125; public void run() throws Exception &#123; Class&lt;?&gt; mainClass = Class.forName(this.mainClassName, false, Thread.currentThread().getContextClassLoader()); Method mainMethod = mainClass.getDeclaredMethod(&quot;main&quot;, String[].class); mainMethod.setAccessible(true); mainMethod.invoke(null, new Object[] &#123; this.args &#125;); &#125;&#125;","tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://example.com/tags/SpringBoot/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"},{"name":"SpringBoot","slug":"Spring/SpringBoot","permalink":"http://example.com/categories/Spring/SpringBoot/"}]},{"title":"LoadRunner日常总结","date":"2019-10-06T03:50:20.000Z","path":"blog/Test/LoadRunner日常总结/","text":"HTTPS请求LoadRunner对HTTPS接口进行测试时，最好加上web_set_sockets_option(&quot;SSL_VERSION&quot;,&quot;TLS&quot;)。 LoadRunner在对HTTPS接口进行请求时，可能出现Error -27778: SSL protocol error when attempting to connect with host &quot;XXX&quot; [MsgId: MERR-27778]错误。 设置Vuser -&gt; Run-time Setting找到Internet Protocol -&gt; Preferences -&gt; Advanced勾选winlnet replay instead of sockets(windows only)选项。 日志中文打印通常在请求时想看到请求参数、返回结果等数据，可以在 Vuser -&gt; run-time setting -&gt; general -&gt; log 勾选 extended log 且勾选其下的三个选项。但是这种方式不能解决中文乱码问题。 可以将中文数据通过 web_reg_save_param 单独提取出来 lr_convert_string_encoding 转码后通过 lr_output_message 或 lr_log_message 打印： 1234web_reg_save_param(&quot;result&quot;, &quot;LB=message\\&quot;:\\&quot;&quot;, &quot;RB=\\&quot;&quot;, LAST);// web_custom_request请求lr_convert_string_encoding(lr_eval_string(&quot;&#123;result&#125;&quot;), &quot;utf-8&quot;, NULL, &quot;msg&quot;);lr_output_message(&quot;message--------%s&quot;,lr_eval_string(&quot;&#123;msg&#125;&quot;)); 中文参数乱码通常在通过 LoadRunner 请求接口时，若 请求参数中存在中文参数 ，虽然在 Replay Log 中打印的内容可能并没有乱码，但是请求到服务器可能就乱码了，从而导致接口请求失败。 为了解决中文参数导致的中文乱码，可以将中文参数提取出来通过 lr_convert_string_encoding 进行 转码 后使用。首先通过通过 lr_save_string 将中文参数参数化，也可以到 Parameter List 进行设置。然后将参数转成 UTF-8 ，最后将参数转成 URL编码 。 123456lr_save_string(&quot;奚姝&quot;,&quot;name&quot;);lr_convert_string_encoding(lr_eval_string(&quot;&#123;name&#125;&quot;), LR_ENC_SYSTEM_LOCALE, LR_ENC_UTF8, &quot;encode_name&quot;);lr_save_string(lr_eval_string(&quot;&#123;encode_name&#125;&quot;),&quot;name&quot;);web_convert_param(&quot;name&quot;, &quot;SourceEncoding=PLAIN&quot;, &quot;TargetEncoding=URL&quot;, LAST);lr_log_message(&quot;参数化结果name：%s&quot;, lr_eval_string(&quot;&#123;name&#125;&quot;)); Web请求LR可以通过 web_custom_request 函数发送 POST 或者 GET 请求。对于普通POST请求，未将请求参数放到 RequestBody 中的，可以将参数在 Body 中通过 &amp; 符号进行拼接。 12345web_custom_request(&quot;web_custom_request&quot;,&quot;URL=&#123;url&#125;&quot;,&quot;Method=POST&quot;, &quot;Resource=0&quot;,&quot;RecContentType=Application/json&quot;,&quot;Referer=&quot;,&quot;Mode=HTML&quot;, &quot;EncType=application/x-www-form-urlencoded;charset=UTF-8&quot;, //&quot;EncType=application/json;charset=UTF-8&quot;, &quot;Body=name=&#123;name&#125;&amp;phone=&#123;phone&#125;&quot;,LAST); 对于请求参数放到 RequestBody 中的，可以直接将请求参数转成字符串放到 Body 中。或者放到 RAW_BODY_START 和 RAW_BODY_END 之间，其中 200 指代参数长度。 123456789web_custom_request(&quot;web_custom_request&quot;,&quot;URL=&#123;url&#125;&quot;,&quot;Method=POST&quot;,&quot;Resource=0&quot;, &quot;RecContentType=application/json&quot;,&quot;Referer=&quot;,&quot;Mode=HTTP&quot;, &quot;EncType=application/json;charset=UTF-8&quot;, //RAW_BODY_START, //&quot;&#123;\\&quot;id\\&quot;:\\&quot;&#123;id&#125;\\&quot;,\\&quot;name\\&quot;:\\&quot;&#123;name&#125;\\&quot;,\\&quot;mobile\\&quot;:\\&quot;&#123;mobile&#125;\\&quot;&#125;&quot;, //200, //RAW_BODY_END, &quot;Body=&#123;\\&quot;id\\&quot;:\\&quot;&#123;id&#125;\\&quot;,\\&quot;name\\&quot;:\\&quot;&#123;name&#125;\\&quot;,\\&quot;mobile\\&quot;:\\&quot;&#123;mobile&#125;\\&quot;&#125;&quot;, LAST); 对于响应结果的提取通过 web_reg_save_param(&quot;code&quot;,&quot;LB=response_code\\&quot;:\\&quot;&quot;,&quot;RB=\\&quot;&quot;,LAST); 提取出来，用来进行事务成功与否判断。 12345678910111213lr_start_transaction (&quot;接口A&quot;);web_reg_save_param(&quot;code&quot;,&quot;LB=response_code\\&quot;:\\&quot;&quot;,&quot;RB=\\&quot;,\\&quot;&quot;,LAST);web_custom_request(&quot;web_custom_request&quot;,&quot;URL=&#123;url&#125;&quot;,&quot;Method=POST&quot;,&quot;Resource=0&quot;, &quot;RecContentType=application/json&quot;,&quot;Referer=&quot;,&quot;Mode=HTTP&quot;, &quot;EncType=application/json;charset=UTF-8&quot;, &quot;Body=&#123;\\&quot;id\\&quot;:\\&quot;&#123;id&#125;\\&quot;,\\&quot;name\\&quot;:\\&quot;&#123;name&#125;\\&quot;&#125;&quot;,LAST);if (strcmp(lr_eval_string(&quot;&#123;coke&#125;&quot;), &quot;00&quot;) == 0)&#123; lr_end_transaction(&quot;接口A&quot;, LR_PASS);&#125;else&#123; lr_end_transaction(&quot;接口A&quot;, LR_FAIL);&#125;","tags":[{"name":"Test","slug":"Test","permalink":"http://example.com/tags/Test/"}],"categories":[{"name":"Test","slug":"Test","permalink":"http://example.com/categories/Test/"}]},{"title":"JMeter日常总结","date":"2019-10-06T03:28:20.000Z","path":"blog/Test/JMeter日常总结/","text":"断言在对接口进行测试时，通常需要对接口调用结果进行断言，以确定接口调用是否达到预期，同时也可以在结果数中看到接口是否调用成功。响应断言 和 jp@gc - JSON Path Assertion 是比较简单和常用的两个断言器。 在HTTP请求下添加 断言 -&gt; 响应断言 ，可以通过不同的模式匹配规则进行匹配断言。 在HTTP请求下添加 断言 -&gt; jp@gc - JSON Path Assertion 。目前看来该断言器只能断言其中一个字段。 一般来说以上两种断言器已经基本够用了，如果遇到比较复杂的可以使用 BeanShell断言 来通过脚本进行断言。 变量提取使用通常在测试时接口需要进行鉴权，这是通过调用登录接口获取到token_id然后在调用具体接口时将token_id作为参数或者放在header中传入。这里就需要将 token_id 从鉴权接口的响应中提取出来，然后再使用时传入。 对于鉴权接口在 JMeter 中可以通过在测试计划中添加 setUp Thread Group ，并将 线程数 和 循环次数 设置成 1 ，并在该线程组中添加鉴权接口的HTTP请求。可以添加常规的 断言 和 察看结果树 。也可以在线程组中添加 逻辑控制器 -&gt; 仅一次控制器 将鉴权接口相关类容添加至该逻辑控制器下。 目前我用到的变量提取有 JSON Extractor 和 正则表达式提取器 两种。当然还有其他的提取器，目前这两种提取器基本够用了。 JSON Extractor 其实是通过 XPath 从JSON串中取出目标值。 正则表达式提取器 当然是通过正则表达式的方式从字符串中提取目标值。 虽然将变量从响应结果中提取出来了，但是并不能直接使用。可以通过 BeanShell PostProcessor 将参数设置为全局变量，也可以将其存储到本地文件中使用时通过 CSV Data Set Config 来读取并使用。 设置成全局变量 相对简单，只需要在 BeanShell PostProcessor 中配置 $&#123;__setProperty(token_id, $&#123;token_id&#125;,)&#125; 脚本即可。这里的print会将提取到的变量打印到 cmd 窗口中。在使用变量时通过 $&#123;__property(token_id)&#125; 进行获取。 将变量存储到本地文件中，也是通过 BeanShell PostProcessor 脚本实现的，只是相对于设置全局变量复杂得多。 1234567891011121314151617181920212223242526272829import java.util.regex.Matcher; import java.util.regex.Pattern; //JMeter的内置API：prev.getResponseData()获取请求的响应内容 byte[] responseData = prev.getResponseData();//定义正则表达式需要匹配的模式提取相关变量Pattern pattern = Pattern.compile(&quot;\\&quot;token_id\\&quot;:\\&quot;(.+?)\\&quot;&quot;); Matcher result = pattern.matcher(new String(responseData)); //boolean java.util.regex.Matcher.find()只要找到符合条件的就返回trueif(result.find())&#123; String tokenId += result.group(1)+&quot;\\r\\n&quot;; //导出的csv存放位置 String filePath = &quot;D:/test/token.txt&quot;; BufferedOutputStream bos = null; FileOutputStream fos = null; try &#123; File file = new File(filePath); fos = new FileOutputStream(file); bos = new BufferedOutputStream(fos); bos.write(tokenId.getBytes()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; if (bos != null) &#123; bos.close(); &#125; if (fos != null) &#123; fos.close(); &#125; &#125;&#125; 使用时通过 CSV Data Set Config 来读取到配置中。 JMeter压测的坑在JMeter中通过线程组的方式进行并发压测，但是实际测试中发现，JMeter其实实际上是一个同步的方式去发送请求的，当我们同时压测几个接口时，通过聚合报告很明显的看出JMeter会等到前一个接口结束后才会请求下一个接口。 在单个接口做并发测试时，当我们的并发设置为150时，JMeter的并发请求数确实是150，但是JMeter会等到其中某个请求结束然后再补充一个请求，通俗的将若你的接口延时1分钟，JMeter在这1分钟内只会发150个请求，当其中有请求结束再往里面补充一致维持150个请求。并不能完全模拟真实场景下的高并发。 通过MBean监控Tomcat的collectionCount参数也可以明显的看出这一点： JMeter BindExecption：Address already in use：connect在Windows10环境下，通过JMeter对接口进行压测时，在100的并发下聚合报告中会出现百分之三点几的错误率，在150的并发下出现了百分之三十几的错误率，当然在不同的环境和接口响应速率下这个错误率可能会不一样。 具体原因是由于端口被占用，Windows提供给TCP&#x2F;IP连接的端口为1024-5000，并且要四分钟来循环回收他们。就导致我们在短时间内跑大量的请求时将端口占满了。解决方案： cmd中，用regedit打开注册表 在 HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\Tcpip\\Parameters下: 右击parameters，添加一个新的DWORD，名字为MaxUserPort 然后双击MaxUserPort，输入数值数据为65534，基数选择十进制。 然后重启电脑！重启电脑！重启电脑！ Gzip压缩请求对于Gzip压缩请求，通常做法是添加JSR223 PreProcessor预处理程序，将请求内容进行压缩。 123456789101112import org.apache.commons.io.IOUtils;import java.util.zip.GZIPOutputStream;String bodyString = sampler.getArguments().getArgument(0).getValue();byte [] requestBody = bodyString.getBytes(&quot;utf-8&quot;);ByteArrayOutputStream out = new ByteArrayOutputStream(requestBody.length);GZIPOutputStream gzip = new GZIPOutputStream(out);gzip.write(requestBody);gzip.close();sampler.getArguments().getArgument(0).setValue(out.toString(0)); 在上述代码中的 getBytes(&quot;utf-8&quot;) 最好加上 utf-8 的编码格式，否则日志可能乱码。 值得注意的是，在 HTTP Request 中的 Content encoding 中的编码方式一定不要填，否则很有可能导致乱码，从而导致请求失败。","tags":[{"name":"Test","slug":"Test","permalink":"http://example.com/tags/Test/"}],"categories":[{"name":"Test","slug":"Test","permalink":"http://example.com/categories/Test/"}]},{"title":"UT测试总结","date":"2019-10-06T02:28:20.000Z","path":"blog/Test/UT测试总结/","text":"UT测试主要测试单元内部的数据结构、逻辑控制、异常处理等。单元测试实现容易、运行速度快、能完全控制被测试的单元不包含外部依赖、测试用例相互独立无依赖关系。能够帮助发现代码缺陷、修改或者重构代码时确保没有影响现有功能。 对于一些对 Bean 没有依赖的类的测试（例如一些工具类），仅使用 JUnit 即可完成单元测试。 对于一些依赖 Bean 的类进行测试，若其复杂度低，在上层一两个IT测试即可覆盖掉，可以使用IT测试；若其复杂度比较高，可以使用 JUnit 加 Mockito 来完成单元测试，通过使用 Mock 技术测试可以 无视代码依赖关系 去测试代码的有效性，mock技术的目的和作用就是 模拟一些在应用中不容易构造或者比较复杂的对象，从而把测试与测试边界以外的对象隔离开，对于依赖的Bean进行Mock处理，模拟构造各种 Bean的输出 来以及 待测试方法的输入 来覆盖当前方法的所有分支。 Mockito基础必须使用 @RunWith(MockitoJUnitRunner.class) 注解，否则Mock的依赖Bean将为空。 @Mock 将创建一个Mock， @InjectMocks 创建一个实例且自动实例化， mockito 会自动注入 mock 或 spy 成员。 UserBaseServiceImpl 中通过 @Autowired 注解或者构造方法等方式注入了 IUserBaseDao ，就可以通过如下方式使用。 12345678@RunWith(MockitoJUnitRunner.class)public class UserBaseServiceTest &#123; @Mock private IUserBaseDao userBaseDao; @InjectMocks private UserBaseServiceImpl userBaseService;&#125; @Mock与@Spy的区别使用 @Mock 生成的类，所有方法都不是真实的方法，而且返回值都是NULL。通常在设置测试桩时通过如下方式设置，对于多次调用返回不同值，可以通过多次设置 thenReturn ： 123456LinkedList mockedList = mock(LinkedList.class);mockedList.add(11);assertEquals(null, mockedList.get(0));when(mockedList.get(0)).thenReturn(&quot;first&quot;).thenReturn(&quot;second&quot;);assertEquals(&quot;first&quot;, mockedList.get(0)); 使用 @Spy 生成的类，所有方法都是真实方法，返回值都是和真实方法一样的。测试桩设置与 @Mock 方式有所区别： 123456LinkedList mockedList = spy(LinkedList.class);mockedList.add(11);assertEquals(11, mockedList.get(0));doReturn(&quot;foo&quot;).when(spy).get(0);assertEquals(&quot;foo&quot;, mockedList.get(0)); Redis测试有时在进行Mock测试时会遇到 redisTemplate ，通常在应用中会使用 redisTemplate.boundValueOps 或者 redisTemplate.boundHashOps 生成一个 BoundValueOperations 或者 BoundHashOperations 对象，再来继续调用具体的处理方法。在设置测试桩时，需要进行两次设置。 12when(redisTemplate.boundValueOps(redisKey)).thenReturn(mock(BoundValueOperations.class));when(redisTemplate.boundValueOps(redisKey).increment(anyLong())).thenReturn(10L); 参数捕捉有时会出现一大串复杂的逻辑处理后生成一个或几个参数，用于调用其他的依赖Bean，这时可以通过参数捕捉来验证逻辑中各种情况下生产的参数是否满足预期。若简单参数也可以通过 verify 直接验证。 123456789BoundHashOperations boundHashOperations = mock(BoundHashOperations.class);when(redisTemplate.boundHashOps(anyString())).thenReturn(boundHashOperations);ArgumentCaptor&lt;Map&gt; argument = ArgumentCaptor.forClass(Map.class); verify(boundHashOperations, times(2)).putAll(argument.capture());Map&lt;String, CaseFlow&gt; map = new HashMap&lt;&gt;();assertEquals(map, argument.getValue()); 方法调用次数验证当验证的方法中存在循环、或者复杂度比较高等，导致方法在不同条件下可能存在多次调用的情况，最好验证一下方法的调用次数。或者是用于验证某个逻辑没有被执行或方法没有别调用。 12345verify(mock, times(1)).someMethod();// 至少调用2次verify(mock, atLeast(2)).someMethod();// 至多调用5次verify(mock, atMost(5)).someMethod(); 异常处理在进行一些会抛出异常的测试时，可以通过捕获异常在进行后续校验，可以使用 @Test(expected = Exception.class) ，若有多个地方抛出相同异常但异常信息不同时，该测试方法就不适用了，可以通过如下方式进行异常捕获后进行相关的验证。 1234567891011doThrow(new RuntimeException()).when(mockedList).clear();when(redisTemplate.boundValueOps(any())).thenThrow(new RuntimeException());Exception error = null;try &#123; baselineModelHandler.output(segment, modelData);&#125; catch (Exception e) &#123; error = e;&#125;assertNotNull(error);assertEquals(&quot;&quot;, error.getMessage()); 验证调用顺序12345678910111213List firstMock = mock(List.class);List secondMock = mock(List.class);firstMock.add(&quot;was called first&quot;);secondMock.add(&quot;was called second&quot;);//创建多个mock对象的inOrderInOrder inOrder = inOrder(firstMock, secondMock);//验证firstMock先于secondMock调用inOrder.verify(firstMock).add(&quot;was called first&quot;);inOrder.verify(secondMock).add(&quot;was called second&quot;); 实现ApplicationContextAware接口的类测试1234Map&lt;String, Object&gt; map = new HashMap&lt;&gt;();map.put(&quot;outputServiceImpl&quot;, new OutputServiceImpl(requestService, updateCache, mock(ICache.class)));when(applicationContext.getBeansWithAnnotation(InvokeListener.class)).thenReturn(map);dataInvokeService.setApplicationContext(applicationContext);","tags":[{"name":"Test","slug":"Test","permalink":"http://example.com/tags/Test/"}],"categories":[{"name":"Test","slug":"Test","permalink":"http://example.com/categories/Test/"}]},{"title":"IT测试总结","date":"2019-10-06T02:08:20.000Z","path":"blog/Test/IT测试总结/","text":"IT测试主要测试模块之间的接口和接口数据传递关系，以及模块组合后的整体功能。 在做集成测试时，若涉及到数据库的数据变更的，最好在测试过后将数据还原，可以先构建一条新的数据测试完成后删除，防止印象到数据库中原有的数据。 Controller层测试对于 SpringBoot 项目，Controller层的IT测试可以通过在类上加 @AutoConfigureMockMvc 注解并直接注入 MockMvc 的方式进行测试。 若对于一些特殊的测试，需要使用不同的配置的, 可使用 @TestPropertySource(locations=&quot;classpath:test.application.properties&quot;) 注解指定特定的配置文件。 123456789101112131415161718@RunWith(SpringRunner.class)@SpringBootTest@AutoConfigureMockMvcpublic class DashboardControllerTest &#123; @Autowired private MockMvc mockMvc; @Test public void get_method_test() throws Exception &#123; this.mockMvc.perform(get(&quot;/test//v1&quot;) .param(&quot;param1&quot;, &quot;value1&quot;) .param(&quot;param2&quot;, &quot;value2&quot;) .header(&quot;uid&quot;, &quot;123456&quot;)) .andExpect(status().isOk()) .andExpect(content().string(containsString(&quot;&#123;\\&quot;response_code\\&quot;:\\&quot;00\\&quot;&quot;))); &#125;&#125; 对于 MockMvc 的使用还可以通过如下方式，这样可以不用在类上添加 @AutoConfigureMockMvc 注解： 12345678910@Autowiredprivate WebApplicationContext context;private MockMvc mvc;@Beforepublic void setUp() throws Exception &#123; mvc = MockMvcBuilders.webAppContextSetup(context) .addFilter(new BaseParamCheckFilter()).build();&#125; mockMvc.perform 需要传入的是一个 RequestBuilder ，可以将其封装好了再传入，需要放入 RequestBody 中的参数可以通过 content 进行参数构造： 12345678910HttpHeaders httpHeaders = new HttpHeaders();httpHeaders.add(&quot;uuid&quot;, &quot;68A&quot;);httpHeaders.add(&quot;Content-Type&quot;, &quot;application/json&quot;);RequestBuilder request = post(&quot;/test/v1&quot;) .headers(httpHeaders) .content(&quot;&#123;\\&quot;uuid\\&quot;: \\&quot;68A\\&quot;,\\&quot;param1\\&quot;:\\&quot;aa\\&quot;&#125;&quot;) .accept(MediaType.APPLICATION_JSON);mockMvc.perform(request).andExpect(status().isOk()).andDo(print()).andExpect( content().string(containsString(&quot;&#123;\\&quot;response_code\\&quot;:\\&quot;02\\&quot;,\\&quot;message\\&quot;:\\&quot;请求参数缺失\\&quot;&quot;))); 对于返回结果的严重可以使用上面的示例通过 MockMvcResultMatchers 结合 Matchers 中的方法进行验证，也可以通过以下方式获取到具体结果后进行验证。 123String responseString = mvc.perform(request) .andExpect(status().isOk()) .andReturn().getResponse().getContentAsString(); perform ：执行一个 RequestBuilder 请求，会自动执行 SpringMVC 的流程并映射到相应的控制器执行处理； andExpect ：添加 ResultMatcher 验证规则，验证控制器执行完成后结果是否正确； andDo ：添加 ResultHandler 结果处理器，比如调试时打印结果到控制台； andReturn ：最后返回相应的 MvcResult ；然后进行自定义验证&#x2F;进行下一步的异步处理； 测试文件上传对于文件大小限制的测试可以直接构建一个指定大小的byte数组。 1234567MockMultipartFile xmlFile = new MockMultipartFile(&quot;xmlFile&quot;, &quot;emptyModel.xml&quot;, &quot;text/plain&quot;, new byte[1024 * 1024 * 200 + 1]);this.mockMvc.perform(MockMvcRequestBuilders.fileUpload(&quot;/test/config/add&quot;) .file(xmlFile).param(&quot;mid&quot;, mid).param(&quot;status&quot;, &quot;1&quot;)) .andExpect(status().isOk()) .andExpect(content().string(containsString(&quot;&#123;\\&quot;message\\&quot;:\\&quot;上传文件异常\\&quot;&quot;))); 如果对于真实的文件上传测试可以读取真实的文件传输： 12345678910111213141516171819URL url = this.getClass().getClassLoader().getResource(&quot;test/errorFileType.txt&quot;);File file = new File(url.getPath());MockMultipartFile xmlFile = new MockMultipartFile(&quot;xmlFile&quot;, &quot;errorFileType.txt&quot;, &quot;text/plain&quot;, getByte(file));private byte[] getByte(File file) throws IOException &#123; FileInputStream fis = new FileInputStream(file); ByteArrayOutputStream bos = new ByteArrayOutputStream(); byte[] b = new byte[1000]; int n; while ((n = fis.read(b)) != -1) &#123; bos.write(b, 0, n); &#125; fis.close(); bos.close(); return bos.toByteArray(); &#125;&#125; 使用TestRestTemplate 对象测试12345678910@Autowiredprivate TestRestTemplate template;@Testpublic void testController()&#123; // template.getForObject() 会得到 controller 返回的 json 值 String content = template.getForObject(&quot;/show/100&quot;, String.class); // 使用断言测试，使用正确的断言 Assert.assertEquals(&quot;show100&quot;, content);&#125; 非Controller层测试对于非Controller测试一般更简单一些，只需要注入相关的类构造入参进行具体的方法调用测试，输出结果进行验证即可。 123456789101112131415161718192021@RunWith(SpringRunner.class)@SpringBootTest(webEnvironment = NONE)public class ITConfigServiceTest &#123; @Autowired private TestBusiConfigMapper testBuisConfigMapper; @Autowired private otherConfigService otherConfigService; @Test public void getConfigTest() &#123; List&lt;Config&gt; configList = testBuisConfigMapper.getAllConfigs(); assertNotNull(configList); assertEquals(true, configList.size() &gt; 0); for (Config config : configList) &#123; Config config = otherConfigService.getConfig(config.getId()); assertNotNull(config); &#125; &#125;&#125;","tags":[{"name":"Test","slug":"Test","permalink":"http://example.com/tags/Test/"}],"categories":[{"name":"Test","slug":"Test","permalink":"http://example.com/categories/Test/"}]},{"title":"RocketMQ-Spring集成","date":"2019-05-01T02:08:20.000Z","path":"blog/工具和中间件/消息队列/RocketMQ/RocketMQ-Spring集成/","text":"SpringBoot集成SpringBoot集成RocketMQ的starter依赖是由Spring社区提供的,目前正在快速迭代的过程当中,不同版本之间的差距非常大,故需特别注意版本.通过内置的 RocketMQTemplate 来与RocketMQ交互. 123456789101112131415161718192021222324&lt;dependency&gt; &lt;groupId&gt;org.apache.rocketmq&lt;/groupId&gt; &lt;artifactId&gt;rocketmq-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.1.1&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;version&gt;2.1.6.RELEASE&lt;/version&gt;&lt;/dependency&gt; 1234# NameServer地址rocketmq.name-server=localhost:9876# 默认的消息生产者组rocketmq.producer.group=springBootGroup SpringBoot集成RocketMQ,消费者部分核心功能都集成到 @RocketMQMessageListener 注解.消息过滤可以由里面的 selectorType 属性和 selectorExpression 来定制,由 consumeMode 来有序消费还是并发消费等； 1234567891011121314151617181920@Componentpublic class SpringProducer &#123; @Resource private RocketMQTemplate rocketMQTemplate; public void sendMessage(String topic, String msg) &#123; String[] tags = new String[]&#123;&quot;TagA&quot;, &quot;TagB&quot;, &quot;TagC&quot;, &quot;TagD&quot;, &quot;TagE&quot;&#125;; for (String tag : tags) &#123; String destination = topic + &quot;:&quot; + tag; this.rocketMQTemplate.convertAndSend(destination, msg); &#125; &#125;&#125;@Component@RocketMQMessageListener(consumerGroup = &quot;MyConsumerGroup&quot;, messageModel = MessageModel.CLUSTERING, topic = &quot;TestTopic&quot;, consumeMode = ConsumeMode.CONCURRENTLY, selectorExpression = &quot;TagA&quot;)public class SpringConsumer implements RocketMQListener&lt;String&gt; &#123; @Override public void onMessage(String message) &#123; System.out.println(&quot;Received message1 : &quot; + message); &#125;&#125; 对于事务消息需要添加一个 事务消息监听器 ,对于消息TAG的使用,需要通过将TAG拼接到Topic后面.SpringBoot依赖中的 Message 对象和RocketMQ中的 Message 对象是两个不同的对象,SpringBoot中的Message中就没有TAG属性,Tag属性被移到了发送目标中,以 Topic:Tag 的方式指定. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465@ExtRocketMQTemplateConfigurationpublic class ExtRocketMQTemplate extends RocketMQTemplate &#123;&#125;@RocketMQTransactionListener(rocketMQTemplateBeanName = &quot;extRocketMQTemplate&quot;)public class MyTransactionImpl implements RocketMQLocalTransactionListener &#123; private ConcurrentHashMap&lt;Object, Message&gt; localTrans = new ConcurrentHashMap&lt;&gt;(); @Override public RocketMQLocalTransactionState executeLocalTransaction(Message msg, Object arg) &#123; Object transId = msg.getHeaders().get(RocketMQHeaders.PREFIX + RocketMQHeaders.TRANSACTION_ID); String destination = arg.toString(); localTrans.put(transId, msg); //这个msg的实现类是GenericMessage,里面实现了toString方法 //在Header中自定义的RocketMQHeaders.TAGS属性,到这里就没了.但是RocketMQHeaders.TRANSACTION_ID这个属性就还在. //而message的Header里面会默认保存RocketMQHeaders里的属性,但是都会加上一个RocketMQHeaders.PREFIX前缀 System.out.println(&quot;executeLocalTransaction msg = &quot; + msg); //转成RocketMQ的Message对象 org.apache.rocketmq.common.message.Message message = RocketMQUtil.convertToRocketMessage(new StringMessageConverter(), &quot;UTF-8&quot;, destination, msg); String tags = message.getTags(); if (StringUtils.contains(tags, &quot;TagA&quot;)) &#123; return RocketMQLocalTransactionState.COMMIT; &#125; else if (StringUtils.contains(tags, &quot;TagB&quot;)) &#123; return RocketMQLocalTransactionState.ROLLBACK; &#125; else &#123; return RocketMQLocalTransactionState.UNKNOWN; &#125; &#125; @Override public RocketMQLocalTransactionState checkLocalTransaction(Message msg) &#123; String transId = msg.getHeaders().get(RocketMQHeaders.PREFIX + RocketMQHeaders.TRANSACTION_ID).toString(); Message originalMessage = localTrans.get(transId); // 这里能够获取到自定义的transaction_id属性 System.out.println(&quot;checkLocalTransaction msg = &quot; + originalMessage); // 获取标签时,自定义的RocketMQHeaders.TAGS拿不到,但是框架会封装成一个带RocketMQHeaders.PREFIX的属性 String tags = msg.getHeaders().get(RocketMQHeaders.PREFIX + RocketMQHeaders.TAGS).toString(); if (StringUtils.contains(tags, &quot;TagC&quot;)) &#123; return RocketMQLocalTransactionState.COMMIT; &#125; else if (StringUtils.contains(tags, &quot;TagD&quot;)) &#123; return RocketMQLocalTransactionState.ROLLBACK; &#125; else &#123; return RocketMQLocalTransactionState.UNKNOWN; &#125; &#125;&#125;@Componentpublic class SpringProducer &#123; @Resource private RocketMQTemplate extRocketMQTemplate; public void sendMessageInTransaction(String topic, String msg) throws InterruptedException &#123; String[] tags = new String[]&#123;&quot;TagA&quot;, &quot;TagB&quot;, &quot;TagC&quot;, &quot;TagD&quot;, &quot;TagE&quot;&#125;; for (int i = 0; i &lt; 10; i++) &#123; //尝试在Header中加入一些自定义的属性. Message&lt;String&gt; message = MessageBuilder.withPayload(msg) .setHeader(RocketMQHeaders.TRANSACTION_ID, &quot;TransID_&quot; + i) //发到事务监听器里后,这个自己设定的TAGS属性会丢失.但是上面那个属性不会丢失. .setHeader(RocketMQHeaders.TAGS, tags[i % tags.length]) //MyProp在事务监听器里也能拿到,为什么就单单这个RocketMQHeaders.TAGS拿不到？这只能去调源码了. .setHeader(&quot;MyProp&quot;, &quot;MyProp_&quot; + i) .build(); String destination = topic + &quot;:&quot; + tags[i % tags.length]; //这里发送事务消息时,还是会转换成RocketMQ的Message对象,再调用RocketMQ的API完成事务消息机制. SendResult sendResult = extRocketMQTemplate.sendMessageInTransaction(destination, message, destination); System.out.printf(&quot;%s%n&quot;, sendResult); Thread.sleep(10); &#125; &#125;&#125;","tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"http://example.com/tags/RocketMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RocketMQ","slug":"工具和中间件/消息队列/RocketMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RocketMQ/"}]},{"title":"RocketMQ-高级特性","date":"2019-04-24T02:08:20.000Z","path":"blog/工具和中间件/消息队列/RocketMQ/RocketMQ-高级特性/","text":"消息模型RocketMQ主要由 Producer 、 Broker 、 Consumer 三部分组成, Producer负责生产消息, Consumer负责消费消息, Broker负责存储消息. Broker在实际部署过程中对应一台服务器, 每个Broker可存储多个Topic消息, 每个Topic消息也可分片存储于不同的Broker. MessageQueue用于存储消息的物理地址, 每个Topic中的消息地址存储于多个MessageQueue中. ConsumerGroup由多个Consumer 实例构成. 每个Broker下都会生成对应的Topic的文件夹, 每个Topic文件夹下会为每个队列生成一个以队列id作为文件名的文件夹, 在文件夹内才是对应的MessageQueue文件. 消息生产者RocketMQ提供多种发送方式, 同步发送、异步发送、顺序发送、单向发送. 同步和异步方式均需要Broker返回确认信息, 单向发送不需要； 生产者中会把同一类Producer组成一个集合, 叫做生产者组, 这类Producer发送同一类消息且发送逻辑一致. 若发送的是事务消息且原始生产者在发送之后崩溃, 则Broker服务器会联系同一生产者组的其他生产者实例以提交或回溯消费. 消息消费者一个消息消费者会从 Broker 服务器拉取消息, 从用户应用的角度而言提供了两种消费形式：拉取式消费、推动式消费. 拉取式消费的应用通常主动调用Consumer的拉消息方法从Broker服务器拉消息、主动权由应用控制. 一旦获取了批量消息, 应用就会启动消费过程. 推动式消费模式下Broker收到数据后会主动推送给消费端, 该消费模式一般实时性较高, 底层也是通过拉取模式来实现的, 与Broker建立长连接达到消息实时接收的效果. 消费者同样会把同一类Consumer组成一个集合, 叫做消费者组, 这类Consumer通常消费同一类消息且消费逻辑一致. 消费者组使得在消息消费方面, 实现负载均衡和容错的目标变得非常容易. 消费者组的消费者实例必须订阅完全相同的Topic . RocketMQ支持两种消息模式：集群消费Clustering 和广播消费Broadcasting . 集群消费模式：相同Consumer Group的每个Consumer实例平均分摊消息. 不同的Consumer Group全量接收消息. 广播消费模式：相同Consumer Group的每个Consumer实例都接收全量的消息. Topic Topic 表示一类消息的集合, 每个Topic包含若干条消息, 每条消息只能属于一个主题, 是RocketMQ进行消息订阅的基本单位. 同一个Topic下的数据, 会分片保存到不同的Broker上, 而每一个分片单位为 MessageQueue . MessageQueue 是生产者发送消息与消费者消费消息的最小单位. Broker Server消息中转角色, 负责存储消息、转发消息. 代理服务器在RocketMQ系统中负责接收从生产者发送来的消息并存储、同时为消费者的拉取请求作准备. 代理服务器也存储消息相关元数据, 包括消费者组、消费进度偏移和主题和队列消息等. Broker Server要保证高可用需要搭建主从集群架构. RocketMQ中有普通集群和Dledger高可用集群两种Broker架构模式. 普通集群该集群模式下会给每个节点分配一个固定角色, Master 负责响应客户端的请求并存储消息. Slave 则只负责对 Master 的消息进行同步保存, 并响应部分客户端的读请求, 消息同步方式分为同步同步和异步同步. 该集群模式下各节点角色无法进行切换, 即Master节点挂了, 则这一组Broker就不可用了, Slave 不会顶上去成为Master. Dledger高可用集群Dledger是 RocketMQ 4.5 引入的实现高可用集群的一项技术. 该模式下集群会随机选出一个节点作为Master, 当Master节点挂了后, 会从Slave中自动选出一个节点升级成为Master. Dledger会从集群中选举出Master节点, 完成Master节点往Slave节点的消息同步, 且接管Broker的 CommitLog消息存储. Dledger是使用 Raft算法来进行节点选举的. 每个节点有 Leader 、 Follower 、 Candidate 三个状态, 正常运行情况下, 集群中会有一个leader, 其他都是Follower且只响应Leader和Candidate的请求, 而客户端的请求全部由Leader处理, 即使有客户端请求到了一个Follower也会将请求转发到Leader . 集群刚启动时每个节点都是Follower状态, 之后集群内部会发送一个timeout信号, 所有Follower转成Candidate去拉取选票, 获得大多数选票的节点选为Leader, 其他候选人转为Follower. 若一个timeout信号发出时, 没有选出Leader, 将会重新开始一次新的选举. Leader节点会往其他节点发送心跳信号, 确认其Leader状态. 然后启动定时器, 若指定时间内未收到Leader心跳, 则转为Candidate状态, 然后向其他成员发起投票请求, 若收到半数以上成员的投票, 则Candidate会晋升为Leader, 然后Leader也有可能会退化成Follower. 在Raft协议中会将时间分为一些任意时间长度的时间片段叫做 term . term会使用一个全局唯一, 连续递增的编号作为标识, 起到一个逻辑时钟的作用. 在每个term时间片里都会进行新的选举, 每个 Candidate 都会努力争取成为Leader. Leader节点在一个term时间片里会保持Leader状态, 同一时间段内, 集群中只会有一个Leader. 某些情况下形成不了多数派, 那该term可能直到结束都没有leader, 直到下一个term再重新发起选举, 也就没有了Zookeeper中的脑裂问题. 而在每次重新选举的过程中, Leader也有可能会退化成为Follower. 在该集群中Leader节点会不断变化. 每次选举的过程中, 每个节点都会存储当前term编号, 并在节点之间进行交流时带上自己的term编号. 若一个节点发现他的编号比另外一个小, 则会将自己的编号更新为较大的那一个. 若Leader或Candidate发现自己的编号不是最新的, 则会自动转成Follower . 若接收到的请求term编号小于自己的编号term将会拒绝执行. 在选举过程中, Raft协议会通过心跳机制发起Leader选举. 节点都是从Follower状态开始, 若收到了来自Leader或Candidate的心跳RPC请求, 则会保持Follower状态, 避免争抢成为Candidate. 而Leader会往其他节点发送心跳信号, 来确认自己的地位. 若 Follower两个timeout信号内没有收到Leader的心跳信号, 则会认为Leader挂了, 发起新一轮选举. 选举开始后, 每个Follower会增加自己当前的term, 并将自己转为Candidate. 然后向其他节点发起投票请求, 请求时默认投自己一票. 之后Candidate状态可能会发生以下三种变化： 赢得选举成为Leader ：若在一个term内收到了大多数的选票, 将会在接下的剩余term时间内称为Leader, 然后就可通过发送心跳确立自己的地位. 每一个Server在一个term内只能投一张选票, 并且按先到先得的原则投出 其他节点成为Leader：在等待投票时, 可能会收到其他Server发出心跳信号, 说明Leader已产生. 这时通过比较自己的term编号和RPC过来的term编号, 若比对方大说明Leader的term过期, 则拒绝该RPC并继续保持候选人身份, 若对方编号不比自己小则承认对方的地位,转为follower. 选票被瓜分选举失败：若无Candidate获取大多数选票, 则无Leader产生, Candidate们等待超时后发起另一轮选举, 为防止下一次选票还被瓜分, Raft采用随机Election Timeout即随机休眠时间机制防止选票被持续瓜分. 通过将timeout随机设为一段区间上的某个值, 因此很大概率会有某个Candidate率先超时然后赢得大部分选票. 以三个节点的集群为例, 集群启动时三个节点都是Follower, 发起投票后三个节点都会给自己投票, 一轮投票下来三个节点的term都是1, 选举不出Leader；三个节点会进入随机休眠, 然后开始新一轮投票； Dledger还会采用Raft协议进行多副本消息同步, 数据同步会通过 uncommitted阶段和 commited阶段两个阶段来完成. Leader Broker上的Dledger收到一条数据后, 会标记为 uncommitted状态, 然后他通过自己的DledgerServer组件把该uncommitted数据发给Follower Broker的 DledgerServer 组件. Follower Broker的 DledgerServer 收到uncommitted消息后, 必须返回一个Ack 给Leader Broker的Dledger. 若Leader Broker收到超过半数的Follower Broker返回的 Ack 之后, 就会把消息标记为committed状态. Leader Broker上的 DledgerServer 就会发送committed消息给Follower Broker上的DledgerServer, 让他们把消息也标记为committed状态. 消息存储分布式队列因为有高可靠性的要求, 所以数据要进行持久化存储. RocketMQ采用的是类似于Kafka的文件存储机制, 即直接用磁盘文件来保存消息, 而不需要借助MySQL这一类索引工具. MQ收到一条消息后, 需要向生产者返回一个ACK响应, 并将消息存储起来. MQ Push一条消息给消费者后, 等待消费者的ACK响应, 需要将消息标记为已消费. 若没有标记为消费, MQ会不断尝试往消费者推送这条消息. MQ需要定期删除一些过期的消息, 这样才能保证服务一直可用. 目前的高性能磁盘, 顺序写速度可以达到 600MB/s , 超过一般网卡传输速度. 但是磁盘随机写速度只有大概 100KB/s , RocketMQ的消息用顺序写保证了消息存储的速度. Linux操作系统分为用户态和内核态, 文件操作、网络操作需要涉及这两种形态的切换, 免不了进行数据复制. 一台服务器把本机磁盘文件的内容发送到客户端, 一般分为读取本地文件内容、将读取的内容通过网络发送出去两个步骤. 看似简单的操作, 实际进行了 4 次数据复制： 从磁盘复制数据到内核态内存 从内核态内存复制到用户态内存 然后从用户态内存复制到网络驱动的内核态内存 最后从网络驱动的内核态内存复制到网卡中进行传输 通过使用 mmap 方式, 可省去向用户态内存复制, 提高速度. 这种机制在Java中是通过 NIO 包中的 MappedByteBuffer 实现的. RocketMQ充分利用该特性, 也就是所谓的零拷贝技术, 提高消息存盘和网络发送速度. 采用 MappedByteBuffer 这种内存映射的方式有几个限制：一次只能映射1.5~2G的文件至用户态的虚拟内存, 这也是为何RocketMQ默认设置单个CommitLog日志数据文件为1G的原因. 零拷贝在Java NIO中提供了 mmap 和 sendfile 两种实现方式, mmap适合比较小的文件, sendfile适合传递比较大的文件. RocketMQ消息的存储分为三个部分： CommitLog ：存储消息的元数据, 所有消息都会顺序存入到 CommitLog 文件当中. CommitLog 由多个文件组成, 每个文件固定大小1G , 以第一条消息的偏移量为文件名. ConsumerQueue ：存储消息在CommitLog的索引, 一个 MessageQueue 一个文件, 记录当前 MessageQueue 被哪些消费者组消费到了哪一条 CommitLog . 每个Broker下都会生成对应的Topic的文件夹, 每个Topic文件夹下会为每个队列生成一个以队列id作为文件名的文件夹, 在文件夹内才是对应的MessageQueue文件. IndexFile ：为了消息查询提供了一种通过key或时间区间来查询消息的方法, 这种通过 IndexFile 来查找消息的方法不影响发送与消费消息的主流程 abort ：该文件是RocketMQ用来判断程序是否正常关闭的一个标识文件. 正常情况下在启动时创建关闭服务时删除. 若遇到服务器宕机或 kill -9 等一些非正常关闭服务的情况, 该abort文件不会删除, RocketMQ就可判断上一次服务是非正常关闭, 做一些数据恢复的操作. checkpoint ：数据存盘检查点. config/*.json ：将 Topic配置、消费者组配置、消费者组消息偏移量Offset等关键配置信息进行存盘保存. 刷盘机制RocketMQ需要将消息存储到磁盘上才能保证断电后消息不丢失, 才可以让存储的消息量超出内存的限制. 为了提高性能, 会尽量保证磁盘的顺序写. 消息在写入磁盘时有 SYNC_FLUSH同步刷盘和 ASYNC_FLUSH异步刷盘两种写磁盘的方式. 通过Broker配置文件中 flushDiskType 参数设置. 同步刷盘：返回写成功状态时, 消息已经被写入磁盘. 消息写入内存的 PAGECACHE 后, 立刻通知刷盘线程刷盘, 等待刷盘完成, 刷盘线程执行完成后唤醒等待的线程, 返回消息写成功的状态. 异步刷盘：返回写成功状态时, 消息可能只是被写入了内存的PAGECACHE , 写操作的返回快吞吐量大；当内存里的消息量积累到一定程度时, 统一触发写磁盘动作快速写入. 主从复制若Broker以集群方式部署, 会有一个Master节点和多个Slave节点, 消息需要从Master复制到Slave上. 而消息复制的方式分为同步复制和异步复制. 通过Broker配置文件里的 brokerRole 参数进行设置, 该参数可以被设置成 ASYNC_MASTER 、 SYNC_MASTER 、 SLAVE 三个值中的一个. 同步复制：等Master和Slave都写入消息成功后才反馈给客户端写入成功的状态. 若Master故障Slave上有全部数据备份, 很容易恢复数据. 同步复制会增大数据写入延迟降低系统的吞吐量. 异步复制：Master写入消息成功就反馈给客户端写入成功的状态, 再异步将消息复制给Slave节点. 系统拥有较低延迟和较高吞吐量. 但若Master故障而有些数据没有完成复制就会造成数据丢失 负载均衡Producer负载均衡Producer发送消息时, 默认会轮询目标Topic下的所有MessageQueue , 并采用递增取模方式往不同的 MessageQueue 上发送消息, 让消息平均落在不同的Queue上. 由于 MessageQueue 是分布在不同的Broker上, 故消息也会发送到不同的Broker上. 生产者在发送消息时, 可指定一个 MessageQueueSelector , 通过该对象来将消息发送到指定的MessageQueue上, 可通过该方式保证消息局部有序. Consumer负载均衡Consumer也是以 MessageQueue 为单位来进行负载均衡, 分为集群模式和广播模式.广播模式下每条消息都会投递给订阅了Topic的所有消费者实例, 在Consumer分配Queue时, 所有Consumer都分到所有的Queue. 集群消费模式每条消息只需要投递到订阅该Topic的Consumer Group下的一个实例, RocketMQ采用主动拉取方式拉取并消费消息, 在拉取时需明确指定拉取哪一条MessageQueue . 每当实例的数量有变更, 都会触发一次所有实例的负载均衡, 这时会按照 Queue的数量和实例的数量平均分配Queue给每个实例. 每次分配时都会将 MessageQueue 和消费者ID进行排序, 再用不同的分配算法进行分配. 内置的分配的算法共有六种, 分别对应 AllocateMessageQueueStrategy下的六种实现类, 可在Consumer中直接指定. 默认情况下使用的是最简单的平均分配策略. AllocateMachineRoomNearby ：将同机房的Consumer和Broker优先分配在一起. 该策略可通过一个 machineRoomResolver 对象来定制Consumer和Broker的机房解析规则. 还需要引入另外一个分配策略来对同机房的Broker和Consumer进行分配. 一般用平均分配策略或轮询分配策略. AllocateMessageQueueAveragely ：平均分配, 将所有MessageQueue平均分给每一个消费者 AllocateMessageQueueAveragelyByCircle ： 轮询分配, 轮流的给一个消费者分配一个MessageQueue. AllocateMessageQueueByConfig ： 直接指定一个messageQueue列表, 类似于广播模式, 直接指定所有队列. AllocateMessageQueueByMachineRoom ：按逻辑机房的概念进行分配. 对BrokerName和ConsumerIdc有定制化的配置. AllocateMessageQueueConsistentHash ：一致性哈希策略只需要指定一个虚拟节点数, 用一个哈希环算法, 虚拟节点是为了让Hash数据在环上分布更为均匀. 消息重试广播模式的消息是不存在消息重试机制, 消息消费失败后不会再重新进行发送, 继续消费新的消息. 对于普通消息, 当消费者消费消息失败后, 可通过设置返回状态达到消息重试的结果. 集群消费方式下, 消息消费失败后期望消息重试, 需要在消息监听器接口的实现中明确进行配置, 有返回Action.ReconsumeLater 、返回NULL 、抛出异常三种配置方式. 重试消息会进入一个 %RETRY%+ConsumeGroup 队列中, 默认允许每条消息最多重试16次, 重试时间跟延迟消息的延迟级别是对应的, 不过取的是延迟级别的后16级别. 若消息重试16次后仍然失败, 消息将不再投递转为进入死信队列, 可通过 consumer.setMaxReconsumeTimes(20) 自定义重试次数, 当定制的重试次数超过16次后, 消息重试时间间隔均为2小时. 消息最大重试次数的设置对相同GroupID下的所有Consumer实例有效. 且最后启动的Consumer会覆盖之前启动的Consumer的配置. 死信队列当一条消息消费失败会自动进行消息重试, 若消息超过最大重试次数, RocketMQ认为该消息有问题, 但不会立刻将该消息丢弃, 而是将其发送到这个消费者组对应的一种特殊队列死信队列. 死信队列名称 %DLQ%+ConsumGroup . 一个死信队列对应一个ConsumGroup , 而不是对应某个消费者实例. 若一个 ConsumeGroup没有产生死信队列, RocketMQ就不会为其创建相应的死信队列. 一个死信队列包含了该ConsumeGroup里的所有死信消息, 而不区分该消息Topic . 死信队列中的消息不会再被消费者正常消费. 死信队列的有效期跟正常消息相同, 默认3天, 对应broker.conf中的 fileReservedTime 属性. 超过该最长时间的消息都会被删除, 而不管消息是否消费过. 通常一条消息进入了死信队列, 意味着消息在消费处理的过程中出现了比较严重的错误, 且无法自行恢复. 此时, 一般需要人工去查看死信队列中的消息, 对错误原因进行排查. 然后对死信消息进行处理, 比如转发到正常的Topic重新进行消费或者丢弃. 消息幂等 发送时消息重复：当一条消息已被成功发送到服务端并完成持久化, 此时出现了网络闪断或者客户端宕机, 导致服务端对客户端应答失败. 若此时生产者意识到消息发送失败并尝试再次发送消息, 消费者后续会收到两条内容相同且 MessageID也相同的消息. 投递时消息重复：消息已投递到消费者并完成业务处理, 当客户端给服务端反馈应答的时候网络闪断. 为了保证消息至少被消费一次, RocketMQ服务端将在网络恢复后再次尝试投递之前已被处理过的消息, 消费者后续会收到两条内容相同并且 MessageID也相同的消息. 负载均衡时消息重复：包括但不限于网络抖动、Broker重启以及订阅方应用重启, 当RocketMQ的Broker或客户端重启、扩容或缩容时, 会触发Rebalance , 此时消费者可能会收到重复消息. 在RocketMQ中, 无法保证每个消息只被投递一次, 所以要在业务上自行来保证消息消费的幂等性. RocketMQ的每条消息都有一个唯一的MessageId , 该参数在多次投递的过程中是不会改变, 业务上可用MessageId来作为判断幂等的关键依据. MessageId无法保证全局唯一, 也会有冲突的情况. 所以在一些对幂等性要求严格的场景, 最好是使用业务上唯一的一个标识如订单ID. 而该业务标识可使用 Message的Key来进行传递. 消息零丢失 生产者使用事务消息机制. Broker配置同步刷盘+Dledger主从架构 消费者不要使用异步消费. 整个MQ挂了之后准备降级方案 消息积压处理若Topic下的MessageQueue配置得是足够多的, 每个Consumer实际上会分配多个MessageQueue来进行消费. 可通过增加Consumer服务节点数量来加快消息的消费, 等积压消息消费完了, 再恢复成正常情况. 最极限的情况是把Consumer的节点个数设置成跟MessageQueue的个数相同. 此时再继续增加Consumer的服务节点就没有用了. 若Topic下的MessageQueue配置不够多, 就不能用上面这种增加Consumer节点个数的方法. 若要快速处理积压的消息, 可创建一个新的Topic , 配置足够多的MessageQueue , 把所有消费者节点的目标Topic转向新的Topic, 并紧急上线一组新的消费者, 只负责消费旧Topic中的消息, 并转储到新的Topic中, 在新的Topic上就可以通过增加消费者个数来提高消费速度了. 若RocketMQ原本是采用的普通方式搭建主从架构, 而现在想要中途改为使用Dledger高可用集群, 这时若不想历史消息丢失, 就需要先将消息进行对齐, 也就是要消费者把所有的消息都消费完, 再来切换主从架构. 因为Dledger集群会接管RocketMQ原有的CommitLog日志, 切换主从架构时, 若有消息没有消费完, 这些消息是存在旧的CommitLog中的, 就无法再进行消费了. 该场景下也是需要尽快的处理掉积压的消息.","tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"http://example.com/tags/RocketMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RocketMQ","slug":"工具和中间件/消息队列/RocketMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RocketMQ/"}]},{"title":"RocketMQ-消息存储源码","date":"2019-04-23T05:08:20.000Z","path":"blog/工具和中间件/消息队列/RocketMQ/RocketMQ-消息存储源码/","text":"RocketMQ的存储文件包括消息文件Commitlog 、消息消费队列文件ConsumerQueue 、Hash索引文件IndexFile 、监测点文件checkPoint 、 abort关闭异常文件. 单个消息存储文件、消息消费队列文件、Hash索引文件长度固定以便使用内存映射机制进行文件的读写操作. RocketMQ组织文件以文件起始偏移量来命令文件, 根据偏移量能快速定位到真实物理文件. 基于内存映射文件机制提供了同步刷盘和异步刷盘两种机制, 异步刷盘是指在消息存储时先追加到内存映射文件, 然后启动专门的刷盘线程定时将内存中的文件数据刷写到磁盘. 为了保证消息发送的高吞吐量, 采用单一文件存储所有主题消息, 保证消息存储是完全的顺序写, 但这样给文件读取带来了不便, 为了方便消息消费构建了消息消费队列文件, 基于主题与队列进行组织, 同时为消息实现了Hash索引, 可以为消息设置索引键, 故能快速从 CommitLog 文件中检索消息. 当消息达到 CommitLog 后, 会通过 ReputMessageService 线程接近实时地将消息转发给消息消费队列文件与索引文件. 为了安全起见引入 abort文件, 记录Broker停机是否是正常关闭, 在重启Broker时为了保证CommitLog文件、消息消费队列文件与Hash索引文件的正确性, 分别采用不同策略来恢复文件. RocketMQ不会永久存储消息文件、消息消费队列文件, 而是启动文件过期机制并在磁盘空间不足或默认4点删除过期文件, 文件保存72小时并且在删除文件时并不会判断该消息文件上的消息是否被消费. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class DefaultMessageStore implements MessageStore &#123; public void start() throws Exception &#123; lock = lockFile.getChannel().tryLock(0, 1, false); if (lock == null || lock.isShared() || !lock.isValid()) &#123; throw new RuntimeException(&quot;Lock failed,MQ already started&quot;); &#125; lockFile.getChannel().write(ByteBuffer.wrap(&quot;lock&quot;.getBytes())); lockFile.getChannel().force(true); &#123; long maxPhysicalPosInLogicQueue = commitLog.getMinOffset(); for (ConcurrentMap&lt;Integer, ConsumeQueue&gt; maps : this.consumeQueueTable.values()) &#123; for (ConsumeQueue logic : maps.values()) &#123; if (logic.getMaxPhysicOffset() &gt; maxPhysicalPosInLogicQueue) &#123; maxPhysicalPosInLogicQueue = logic.getMaxPhysicOffset(); &#125; &#125; &#125; if (maxPhysicalPosInLogicQueue &lt; 0) &#123; maxPhysicalPosInLogicQueue = 0; &#125; if (maxPhysicalPosInLogicQueue &lt; this.commitLog.getMinOffset()) &#123; maxPhysicalPosInLogicQueue = this.commitLog.getMinOffset(); &#125; // Broker启动时会启动一个线程来更新ConsumerQueue索引文件. this.reputMessageService.setReputFromOffset(maxPhysicalPosInLogicQueue); this.reputMessageService.start(); while (true) &#123; if (dispatchBehindBytes() &lt;= 0) &#123; break; &#125; Thread.sleep(1000); &#125; this.recoverTopicQueueTable(); &#125; if (!messageStoreConfig.isEnableDLegerCommitLog()) &#123; this.haService.start(); this.handleScheduleMessageService(messageStoreConfig.getBrokerRole()); &#125; this.flushConsumeQueueService.start(); this.commitLog.start(); this.storeStatsService.start(); this.createTempFile(); this.addScheduleTask(); // Broker启动删除过期文件的定时任务 this.shutdown = false; &#125;&#125; 消息存储对于消息的存储是通过 DefaultMessageStore 的 putMessage 方法最终调用 CommitLog 的 putMessage 方法从而使用 mmap零拷贝来完成数据的存储. 对于延迟消息会将实际的Topic替换为SCHEDULE_TOPIC_XXXX , 通过异步任务当到达时间点时再从该队列中取出再放入原来实际的Topic中. 对于 CommitLog 文件的写同一时间只能有一个线程, 首先会获取当前要写的 MappedFile , 若该文件已满或不存在则创建一个 MappedFile , 通过 MappedFile 的 appendMessage 方法将数据写入缓存中. 然后执行 handleDiskFlush 方法将缓存中的数据刷到磁盘中, 以及通过 handleHA 方法进行主从同步. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113public interface MessageStore &#123; default CompletableFuture&lt;PutMessageResult&gt; asyncPutMessage(final MessageExtBrokerInner msg) &#123; return CompletableFuture.completedFuture(putMessage(msg)); &#125;&#125;public class DefaultMessageStore implements MessageStore &#123; public PutMessageResult putMessage(MessageExtBrokerInner msg) &#123; PutMessageStatus checkStoreStatus = this.checkStoreStatus(); if (checkStoreStatus != PutMessageStatus.PUT_OK) &#123; return new PutMessageResult(checkStoreStatus, null); &#125; PutMessageStatus msgCheckStatus = this.checkMessage(msg); if (msgCheckStatus == PutMessageStatus.MESSAGE_ILLEGAL) &#123; return new PutMessageResult(msgCheckStatus, null); &#125; long beginTime = this.getSystemClock().now(); //我们跟踪下这个最典型的消息写入commitlog的方法 PutMessageResult result = this.commitLog.putMessage(msg); long elapsedTime = this.getSystemClock().now() - beginTime; this.storeStatsService.setPutMessageEntireTimeMax(elapsedTime); if (null == result || !result.isOk()) &#123; this.storeStatsService.getPutMessageFailedTimes().incrementAndGet(); &#125; return result; &#125;&#125;public class CommitLog &#123; public PutMessageResult putMessage(final MessageExtBrokerInner msg) &#123; msg.setStoreTimestamp(System.currentTimeMillis()); // Set the storage time msg.setBodyCRC(UtilAll.crc32(msg.getBody())); AppendMessageResult result = null; StoreStatsService storeStatsService = this.defaultMessageStore.getStoreStatsService(); String topic = msg.getTopic(); int queueId = msg.getQueueId(); final int tranType = MessageSysFlag.getTransactionValue(msg.getSysFlag()); if (tranType == MessageSysFlag.TRANSACTION_NOT_TYPE || tranType == MessageSysFlag.TRANSACTION_COMMIT_TYPE) &#123; if (msg.getDelayTimeLevel() &gt; 0) &#123; // Delay Delivery if (msg.getDelayTimeLevel() &gt; this.defaultMessageStore.getScheduleMessageService().getMaxDelayLevel()) &#123; msg.setDelayTimeLevel(this.defaultMessageStore.getScheduleMessageService().getMaxDelayLevel()); &#125; topic = TopicValidator.RMQ_SYS_SCHEDULE_TOPIC; // 将消息的Topic替换为SCHEDULE_TOPIC_XXXX queueId = ScheduleMessageService.delayLevel2QueueId(msg.getDelayTimeLevel()); MessageAccessor.putProperty(msg, MessageConst.PROPERTY_REAL_TOPIC, msg.getTopic()); MessageAccessor.putProperty(msg, MessageConst.PROPERTY_REAL_QUEUE_ID, String.valueOf(msg.getQueueId())); msg.setPropertiesString(MessageDecoder.messageProperties2String(msg.getProperties())); msg.setTopic(topic); msg.setQueueId(queueId); &#125; &#125; InetSocketAddress bornSocketAddress = (InetSocketAddress) msg.getBornHost(); if (bornSocketAddress.getAddress() instanceof Inet6Address) &#123; msg.setBornHostV6Flag(); &#125; InetSocketAddress storeSocketAddress = (InetSocketAddress) msg.getStoreHost(); if (storeSocketAddress.getAddress() instanceof Inet6Address) &#123; msg.setStoreHostAddressV6Flag(); &#125; long elapsedTimeInLock = 0; MappedFile unlockMappedFile = null; MappedFile mappedFile = this.mappedFileQueue.getLastMappedFile(); //mappedFile 零拷贝实现 putMessageLock.lock(); // 线程锁 注意使用锁的这种方式 try &#123; long beginLockTimestamp = this.defaultMessageStore.getSystemClock().now(); this.beginTimeInLock = beginLockTimestamp; msg.setStoreTimestamp(beginLockTimestamp); if (null == mappedFile || mappedFile.isFull()) &#123; mappedFile = this.mappedFileQueue.getLastMappedFile(0); // Mark: NewFile may be cause noise &#125; if (null == mappedFile) &#123; beginTimeInLock = 0; return new PutMessageResult(PutMessageStatus.CREATE_MAPEDFILE_FAILED, null); &#125; // 直接以Append的方式写入文件 result = mappedFile.appendMessage(msg, this.appendMessageCallback); switch (result.getStatus()) &#123; // 文件写入的结果 case PUT_OK: break; case END_OF_FILE: //文件写满了, 就创建一个新文件, 重写消息 unlockMappedFile = mappedFile; mappedFile = this.mappedFileQueue.getLastMappedFile(0); if (null == mappedFile) &#123; beginTimeInLock = 0; return new PutMessageResult(PutMessageStatus.CREATE_MAPEDFILE_FAILED, result); &#125; result = mappedFile.appendMessage(msg, this.appendMessageCallback); break; case MESSAGE_SIZE_EXCEEDED: case PROPERTIES_SIZE_EXCEEDED: beginTimeInLock = 0; return new PutMessageResult(PutMessageStatus.MESSAGE_ILLEGAL, result); case UNKNOWN_ERROR: beginTimeInLock = 0; return new PutMessageResult(PutMessageStatus.UNKNOWN_ERROR, result); default: beginTimeInLock = 0; return new PutMessageResult(PutMessageStatus.UNKNOWN_ERROR, result); &#125; elapsedTimeInLock = this.defaultMessageStore.getSystemClock().now() - beginLockTimestamp; beginTimeInLock = 0; &#125; finally &#123; putMessageLock.unlock(); &#125; if (null != unlockMappedFile &amp;&amp; this.defaultMessageStore.getMessageStoreConfig().isWarmMapedFileEnable()) &#123; this.defaultMessageStore.unlockMappedFile(unlockMappedFile); &#125; PutMessageResult putMessageResult = new PutMessageResult(PutMessageStatus.PUT_OK, result); storeStatsService.getSinglePutMessageTopicTimesTotal(msg.getTopic()).incrementAndGet(); storeStatsService.getSinglePutMessageTopicSizeTotal(topic).addAndGet(result.getWroteBytes()); handleDiskFlush(result, putMessageResult, msg); //文件刷盘 handleHA(result, putMessageResult, msg); //主从同步 return putMessageResult; &#125;&#125; MappedFileQueue 对应 CommitLog 目录下的文件, 文件名称为第一个数据的偏移量加个上文件的固定大小, 最终会通过 AllocateMappedFileService 的 putRequestAndReturnMappedFile 方法创建一个 MappedFile 对象. 123456789101112131415161718192021222324252627282930313233343536public class MappedFileQueue &#123; // MappedFileQueue对应CommitLog目录下的文件 public MappedFile getLastMappedFile(final long startOffset) &#123; return getLastMappedFile(startOffset, true); &#125; public MappedFile getLastMappedFile(final long startOffset, boolean needCreate) &#123; long createOffset = -1; MappedFile mappedFileLast = getLastMappedFile(); if (mappedFileLast == null) &#123; createOffset = startOffset - (startOffset % this.mappedFileSize); &#125; if (mappedFileLast != null &amp;&amp; mappedFileLast.isFull()) &#123; createOffset = mappedFileLast.getFileFromOffset() + this.mappedFileSize; &#125; if (createOffset != -1 &amp;&amp; needCreate) &#123; String nextFilePath = this.storePath + File.separator + UtilAll.offset2FileName(createOffset); String nextNextFilePath = this.storePath + File.separator + UtilAll.offset2FileName(createOffset + this.mappedFileSize); MappedFile mappedFile = null; if (this.allocateMappedFileService != null) &#123; mappedFile = this.allocateMappedFileService.putRequestAndReturnMappedFile(nextFilePath, nextNextFilePath, this.mappedFileSize); &#125; else &#123; try &#123; mappedFile = new MappedFile(nextFilePath, this.mappedFileSize); &#125; catch (IOException e) &#123; &#125; &#125; if (mappedFile != null) &#123; if (this.mappedFiles.isEmpty()) &#123; mappedFile.setFirstCreateInQueue(true); &#125; this.mappedFiles.add(mappedFile); &#125; return mappedFile; &#125; return mappedFileLast; &#125;&#125; AllocateMappedFileService 是一个线程类, putRequestAndReturnMappedFile 中会把任务放入队列中, 然后在run方法中取处理任务, 该线程是在 DefaultMessageStore 的构造方法中创建启动. 这里会将写满的文件刷到磁盘中. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131public class AllocateMappedFileService extends ServiceThread &#123; private ConcurrentMap&lt;String, AllocateRequest&gt; requestTable = new ConcurrentHashMap&lt;String, AllocateRequest&gt;(); private PriorityBlockingQueue&lt;AllocateRequest&gt; requestQueue = new PriorityBlockingQueue&lt;AllocateRequest&gt;(); public MappedFile putRequestAndReturnMappedFile(String nextFilePath, String nextNextFilePath, int fileSize) &#123; int canSubmitRequests = 2; if (this.messageStore.getMessageStoreConfig().isTransientStorePoolEnable()) &#123; if (this.messageStore.getMessageStoreConfig().isFastFailIfNoBufferInStorePool() &amp;&amp; BrokerRole.SLAVE != this.messageStore.getMessageStoreConfig().getBrokerRole()) &#123; //if broker is slave, don&#x27;t fast fail even no buffer in pool canSubmitRequests = this.messageStore.getTransientStorePool().availableBufferNums() - this.requestQueue.size(); &#125; &#125; AllocateRequest nextReq = new AllocateRequest(nextFilePath, fileSize); boolean nextPutOK = this.requestTable.putIfAbsent(nextFilePath, nextReq) == null; if (nextPutOK) &#123; if (canSubmitRequests &lt;= 0) &#123; this.requestTable.remove(nextFilePath); return null; &#125; boolean offerOK = this.requestQueue.offer(nextReq); canSubmitRequests--; &#125; AllocateRequest nextNextReq = new AllocateRequest(nextNextFilePath, fileSize); boolean nextNextPutOK = this.requestTable.putIfAbsent(nextNextFilePath, nextNextReq) == null; if (nextNextPutOK) &#123; if (canSubmitRequests &lt;= 0) &#123; this.requestTable.remove(nextNextFilePath); &#125; else &#123; boolean offerOK = this.requestQueue.offer(nextNextReq); &#125; &#125; if (hasException) &#123; return null; &#125; AllocateRequest result = this.requestTable.get(nextFilePath); try &#123; if (result != null) &#123; boolean waitOK = result.getCountDownLatch().await(waitTimeOut, TimeUnit.MILLISECONDS); if (!waitOK) &#123; return null; &#125; else &#123; this.requestTable.remove(nextFilePath); return result.getMappedFile(); &#125; &#125; &#125; return null; &#125; public void run() &#123; while (!this.isStopped() &amp;&amp; this.mmapOperation()) &#123; &#125; &#125; private boolean mmapOperation() &#123; boolean isSuccess = false; AllocateRequest req = null; try &#123; req = this.requestQueue.take(); AllocateRequest expectedRequest = this.requestTable.get(req.getFilePath()); if (null == expectedRequest) &#123; return true; &#125; if (expectedRequest != req) &#123; return true; &#125; if (req.getMappedFile() == null) &#123; long beginTime = System.currentTimeMillis(); MappedFile mappedFile; if (messageStore.getMessageStoreConfig().isTransientStorePoolEnable()) &#123; try &#123; mappedFile = ServiceLoader.load(MappedFile.class).iterator().next(); mappedFile.init(req.getFilePath(), req.getFileSize(), messageStore.getTransientStorePool()); &#125; catch (RuntimeException e) &#123; mappedFile = new MappedFile(req.getFilePath(), req.getFileSize(), messageStore.getTransientStorePool()); &#125; &#125; else &#123; mappedFile = new MappedFile(req.getFilePath(), req.getFileSize()); &#125; long elapsedTime = UtilAll.computeElapsedTimeMilliseconds(beginTime); if (elapsedTime &gt; 10) &#123; int queueSize = this.requestQueue.size(); &#125; if (mappedFile.getFileSize() &gt;= this.messageStore.getMessageStoreConfig().getMappedFileSizeCommitLog() &amp;&amp; this.messageStore.getMessageStoreConfig().isWarmMapedFileEnable()) &#123; mappedFile.warmMappedFile(this.messageStore.getMessageStoreConfig().getFlushDiskType(), this.messageStore.getMessageStoreConfig().getFlushLeastPagesWhenWarmMapedFile()); &#125; req.setMappedFile(mappedFile); this.hasException = false; isSuccess = true; &#125; &#125; catch (InterruptedException e) &#123; this.hasException = true; return false; &#125; catch (IOException e) &#123; this.hasException = true; if (null != req) &#123; requestQueue.offer(req); try &#123; Thread.sleep(1); &#125; catch (InterruptedException ignored) &#123; &#125; &#125; &#125; finally &#123; if (req != null &amp;&amp; isSuccess) req.getCountDownLatch().countDown(); &#125; return true; &#125;&#125;public class MappedFile extends ReferenceResource &#123; public void warmMappedFile(FlushDiskType type, int pages) &#123; long beginTime = System.currentTimeMillis(); ByteBuffer byteBuffer = this.mappedByteBuffer.slice(); int flush = 0; long time = System.currentTimeMillis(); for (int i = 0, j = 0; i &lt; this.fileSize; i += MappedFile.OS_PAGE_SIZE, j++) &#123; byteBuffer.put(i, (byte) 0); if (type == FlushDiskType.SYNC_FLUSH) &#123; if ((i / OS_PAGE_SIZE) - (flush / OS_PAGE_SIZE) &gt;= pages) &#123; flush = i; mappedByteBuffer.force(); // force flush when flush disk type is sync &#125; &#125; if (j % 1000 == 0) &#123; // prevent gc try &#123; Thread.sleep(0); &#125; &#125; &#125; if (type == FlushDiskType.SYNC_FLUSH) &#123; mappedByteBuffer.force(); // force flush when prepare load finished &#125; this.mlock(); &#125;&#125; 消息是通过 MappedFile 的 appendMessage 方法以Append的方式写入文件缓存中. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899public class MappedFile extends ReferenceResource &#123; public AppendMessageResult appendMessage(final MessageExtBrokerInner msg, final AppendMessageCallback cb) &#123; return appendMessagesInner(msg, cb); &#125; public AppendMessageResult appendMessagesInner(final MessageExt messageExt, final AppendMessageCallback cb) &#123; assert messageExt != null; assert cb != null; int currentPos = this.wrotePosition.get(); if (currentPos &lt; this.fileSize) &#123; ByteBuffer byteBuffer = writeBuffer != null ? writeBuffer.slice() : this.mappedByteBuffer.slice(); byteBuffer.position(currentPos); AppendMessageResult result; if (messageExt instanceof MessageExtBrokerInner) &#123; result = cb.doAppend(this.getFileFromOffset(), byteBuffer, this.fileSize - currentPos, (MessageExtBrokerInner) messageExt); &#125; else if (messageExt instanceof MessageExtBatch) &#123; result = cb.doAppend(this.getFileFromOffset(), byteBuffer, this.fileSize - currentPos, (MessageExtBatch) messageExt); &#125; else &#123; return new AppendMessageResult(AppendMessageStatus.UNKNOWN_ERROR); &#125; this.wrotePosition.addAndGet(result.getWroteBytes()); this.storeTimestamp = result.getStoreTimestamp(); return result; &#125; return new AppendMessageResult(AppendMessageStatus.UNKNOWN_ERROR); &#125;&#125;public class CommitLog &#123; public AppendMessageResult doAppend(final long fileFromOffset, final ByteBuffer byteBuffer, final int maxBlank, final MessageExtBatch messageExtBatch) &#123; byteBuffer.mark(); long wroteOffset = fileFromOffset + byteBuffer.position(); //physical offset keyBuilder.setLength(0); // Record ConsumeQueue information keyBuilder.append(messageExtBatch.getTopic()); keyBuilder.append(&#x27;-&#x27;); keyBuilder.append(messageExtBatch.getQueueId()); String key = keyBuilder.toString(); Long queueOffset = CommitLog.this.topicQueueTable.get(key); if (null == queueOffset) &#123; queueOffset = 0L; CommitLog.this.topicQueueTable.put(key, queueOffset); &#125; long beginQueueOffset = queueOffset; int totalMsgLen = 0; int msgNum = 0; msgIdBuilder.setLength(0); final long beginTimeMills = CommitLog.this.defaultMessageStore.now(); ByteBuffer messagesByteBuff = messageExtBatch.getEncodedBuff(); int sysFlag = messageExtBatch.getSysFlag(); int storeHostLength = (sysFlag &amp; MessageSysFlag.STOREHOSTADDRESS_V6_FLAG) == 0 ? 4 + 4 : 16 + 4; ByteBuffer storeHostHolder = ByteBuffer.allocate(storeHostLength); this.resetByteBuffer(storeHostHolder, storeHostLength); ByteBuffer storeHostBytes = messageExtBatch.getStoreHostBytes(storeHostHolder); messagesByteBuff.mark(); while (messagesByteBuff.hasRemaining()) &#123; final int msgPos = messagesByteBuff.position(); // 1 TOTALSIZE final int msgLen = messagesByteBuff.getInt(); final int bodyLen = msgLen - 40; //only for log, just estimate it if (msgLen &gt; this.maxMessageSize) &#123; // Exceeds the maximum message CommitLog.log.warn(&quot;message size exceeded, msg total size: &quot; + msgLen + &quot;, msg body size: &quot; + bodyLen + &quot;, maxMessageSize: &quot; + this.maxMessageSize); return new AppendMessageResult(AppendMessageStatus.MESSAGE_SIZE_EXCEEDED); &#125; totalMsgLen += msgLen; if ((totalMsgLen + END_FILE_MIN_BLANK_LENGTH) &gt; maxBlank) &#123; // Determines whether there is sufficient free space this.resetByteBuffer(this.msgStoreItemMemory, 8); this.msgStoreItemMemory.putInt(maxBlank); // 1 TOTALSIZE this.msgStoreItemMemory.putInt(CommitLog.BLANK_MAGIC_CODE); // 2 MAGICCODE messagesByteBuff.reset(); // 3 The remaining space may be any value ignore previous read byteBuffer.reset(); //Here the length of the specially set maxBlank ignore the previous appended messages byteBuffer.put(this.msgStoreItemMemory.array(), 0, 8); return new AppendMessageResult(AppendMessageStatus.END_OF_FILE, wroteOffset, maxBlank, msgIdBuilder.toString(), messageExtBatch.getStoreTimestamp(), beginQueueOffset, CommitLog.this.defaultMessageStore.now() - beginTimeMills); &#125; messagesByteBuff.position(msgPos + 20); //move to add queue offset and commitlog offset messagesByteBuff.putLong(queueOffset); messagesByteBuff.putLong(wroteOffset + totalMsgLen - msgLen); storeHostBytes.rewind(); String msgId; if ((sysFlag &amp; MessageSysFlag.STOREHOSTADDRESS_V6_FLAG) == 0) &#123; msgId = MessageDecoder.createMessageId(this.msgIdMemory, storeHostBytes, wroteOffset + totalMsgLen - msgLen); &#125; else &#123; msgId = MessageDecoder.createMessageId(this.msgIdV6Memory, storeHostBytes, wroteOffset + totalMsgLen - msgLen); &#125; if (msgIdBuilder.length() &gt; 0) &#123; msgIdBuilder.append(&#x27;,&#x27;).append(msgId); &#125; else &#123; msgIdBuilder.append(msgId); &#125; queueOffset++; msgNum++; messagesByteBuff.position(msgPos + msgLen); &#125; messagesByteBuff.position(0); messagesByteBuff.limit(totalMsgLen); byteBuffer.put(messagesByteBuff); messageExtBatch.setEncodedBuff(null); AppendMessageResult result = new AppendMessageResult(AppendMessageStatus.PUT_OK, wroteOffset, totalMsgLen, msgIdBuilder.toString(), messageExtBatch.getStoreTimestamp(), beginQueueOffset, CommitLog.this.defaultMessageStore.now() - beginTimeMills); result.setMsgNum(msgNum); CommitLog.this.topicQueueTable.put(key, queueOffset); return result; &#125;&#125; 同步数据刷盘是通过 CommitLog 的 handleDiskFlush 方法来完成的, 最终将耍盘任务通过 putRequest 方法提交到 GroupCommitService 中, 异步消息刷盘任务也是调用的 putRequest 方法, GroupCommitService 是一个线程在 CommitLog 的start方法中被启动, 从run方法中可知该刷盘任务每10ms执行一次. 最终调用 MappedFileQueue 的 flush 方法强迫把写入内存的数据刷入到磁盘文件中. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133public class CommitLog &#123; public CompletableFuture&lt;PutMessageStatus&gt; submitFlushRequest(AppendMessageResult result, PutMessageResult putMessageResult, MessageExt messageExt) &#123; if (FlushDiskType.SYNC_FLUSH == this.defaultMessageStore.getMessageStoreConfig().getFlushDiskType()) &#123; final GroupCommitService service = (GroupCommitService) this.flushCommitLogService; if (messageExt.isWaitStoreMsgOK()) &#123; GroupCommitRequest request = new GroupCommitRequest(result.getWroteOffset() + result.getWroteBytes(), this.defaultMessageStore.getMessageStoreConfig().getSyncFlushTimeout()); service.putRequest(request); return request.future(); // 直接返回future不会同步等待 &#125; else &#123; service.wakeup(); return CompletableFuture.completedFuture(PutMessageStatus.PUT_OK); &#125; &#125; else &#123; // 若打开了对外内存, 就需要先将对外内存写入到文件映射中, 再存盘 if (!this.defaultMessageStore.getMessageStoreConfig().isTransientStorePoolEnable()) &#123; flushCommitLogService.wakeup(); &#125; else &#123; commitLogService.wakeup(); &#125; return CompletableFuture.completedFuture(PutMessageStatus.PUT_OK); &#125; &#125; public void handleDiskFlush(AppendMessageResult result, PutMessageResult putMessageResult, MessageExt messageExt) &#123; if (FlushDiskType.SYNC_FLUSH == this.defaultMessageStore.getMessageStoreConfig().getFlushDiskType()) &#123; // Synchronization flush 同步刷盘 final GroupCommitService service = (GroupCommitService) this.flushCommitLogService; if (messageExt.isWaitStoreMsgOK()) &#123;//构建一个GroupCommitRequest, 交给GroupCommitService处理. GroupCommitRequest request = new GroupCommitRequest(result.getWroteOffset() + result.getWroteBytes()); service.putRequest(request); CompletableFuture&lt;PutMessageStatus&gt; flushOkFuture = request.future(); PutMessageStatus flushStatus = null; try &#123; //同步等待文件刷新 flushStatus = flushOkFuture.get(this.defaultMessageStore.getMessageStoreConfig().getSyncFlushTimeout(), TimeUnit.MILLISECONDS); &#125; catch (InterruptedException | ExecutionException | TimeoutException e) &#123; &#125; if (flushStatus != PutMessageStatus.PUT_OK) &#123; putMessageResult.setPutMessageStatus(PutMessageStatus.FLUSH_DISK_TIMEOUT); &#125; &#125; else &#123; service.wakeup(); &#125; &#125; else &#123; // Asynchronous flush 异步刷盘, 异步刷盘是把消息映射到MappedFile后, 单独唤醒一个服务来进行刷盘 if (!this.defaultMessageStore.getMessageStoreConfig().isTransientStorePoolEnable()) &#123; flushCommitLogService.wakeup(); &#125; else &#123; commitLogService.wakeup(); &#125; &#125; &#125;&#125;class GroupCommitService extends FlushCommitLogService &#123; private volatile List&lt;GroupCommitRequest&gt; requestsWrite = new ArrayList&lt;GroupCommitRequest&gt;(); private volatile List&lt;GroupCommitRequest&gt; requestsRead = new ArrayList&lt;GroupCommitRequest&gt;(); public synchronized void putRequest(final GroupCommitRequest request) &#123; synchronized (this.requestsWrite) &#123; this.requestsWrite.add(request); &#125; this.wakeup(); &#125; public void run() &#123; while (!this.isStopped()) &#123; try &#123; this.waitForRunning(10); this.doCommit(); &#125; &#125; try &#123;// Under normal circumstances shutdown, wait for the arrival of the request, and then flush Thread.sleep(10); &#125; synchronized (this) &#123; this.swapRequests(); &#125; this.doCommit(); &#125; private void doCommit() &#123; synchronized (this.requestsRead) &#123; if (!this.requestsRead.isEmpty()) &#123; for (GroupCommitRequest req : this.requestsRead) &#123; // 消息刷盘 // There may be a message in the next file, so a maximum of two times the flush boolean flushOK = false; for (int i = 0; i &lt; 2 &amp;&amp; !flushOK; i++) &#123; flushOK = CommitLog.this.mappedFileQueue.getFlushedWhere() &gt;= req.getNextOffset(); if (!flushOK) &#123; // 当前索引位置小于请求数据的位置执行刷盘 CommitLog.this.mappedFileQueue.flush(0); &#125; &#125; req.wakeupCustomer(flushOK ? PutMessageStatus.PUT_OK : PutMessageStatus.FLUSH_DISK_TIMEOUT); &#125; long storeTimestamp = CommitLog.this.mappedFileQueue.getStoreTimestamp(); if (storeTimestamp &gt; 0) &#123; CommitLog.this.defaultMessageStore.getStoreCheckpoint().setPhysicMsgTimestamp(storeTimestamp); &#125; this.requestsRead.clear(); &#125; else &#123; // Because of individual messages is set to not sync flush, it will come to this process CommitLog.this.mappedFileQueue.flush(0); &#125; &#125; &#125;&#125;public class MappedFileQueue &#123; public boolean flush(final int flushLeastPages) &#123; boolean result = true; MappedFile mappedFile = this.findMappedFileByOffset(this.flushedWhere, this.flushedWhere == 0); if (mappedFile != null) &#123; long tmpTimeStamp = mappedFile.getStoreTimestamp(); int offset = mappedFile.flush(flushLeastPages); long where = mappedFile.getFileFromOffset() + offset; result = where == this.flushedWhere; this.flushedWhere = where; if (0 == flushLeastPages) &#123; this.storeTimestamp = tmpTimeStamp; &#125; &#125; return result; &#125;&#125;public int flush(final int flushLeastPages) &#123; if (this.isAbleToFlush(flushLeastPages)) &#123; if (this.hold()) &#123; int value = getReadPosition(); try &#123; // force方法就是强迫把写入内存的数据刷入到磁盘文件里去 if (writeBuffer != null || this.fileChannel.position() != 0) &#123; this.fileChannel.force(false); &#125; else &#123; this.mappedByteBuffer.force(); &#125; &#125; this.flushedPosition.set(value); this.release(); &#125; else &#123; this.flushedPosition.set(getReadPosition()); &#125; &#125; return this.getFlushedPosition();&#125; 消息分发当 CommitLog 写入一条消息后, 会有一个后台线程 ReputMessageService 每隔1ms 就会去拉取 CommitLog 中最新更新的一批消息, 然后分别转发到 ComsumeQueue 和 IndexFile 中. 若服务异常宕机, 会造成 CommitLog 和 ConsumeQueue 、 IndexFile 文件不一致, 有消息写入CommitLog后, 没有分发到索引文件, 这样消息就丢失了. DefaultMappedStore 的 load 方法提供了恢复索引文件的方法. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970class ReputMessageService extends ServiceThread &#123; public void run() &#123; while (!this.isStopped()) &#123; try &#123; // 每隔1毫秒, 往ConsumeQueue和IndexFile中转发一次CommitLog写入的消息 Thread.sleep(1); this.doReput(); &#125; catch (Exception e) &#123; &#125; &#125; &#125; private void doReput() &#123; if (this.reputFromOffset &lt; DefaultMessageStore.this.commitLog.getMinOffset()) &#123; this.reputFromOffset = DefaultMessageStore.this.commitLog.getMinOffset(); &#125; for (boolean doNext = true; this.isCommitLogAvailable() &amp;&amp; doNext; ) &#123; if (DefaultMessageStore.this.getMessageStoreConfig().isDuplicationEnable() &amp;&amp; this.reputFromOffset &gt;= DefaultMessageStore.this.getConfirmOffset()) &#123; break; &#125; SelectMappedBufferResult result = DefaultMessageStore.this.commitLog.getData(reputFromOffset); // 获取CommitLog中的消息 if (result != null) &#123; try &#123; this.reputFromOffset = result.getStartOffset(); for (int readSize = 0; readSize &lt; result.getSize() &amp;&amp; doNext; ) &#123; //从CommitLog中获取一个DispatchRequest,拿到一份需要进行转发的消息, 也就是从commitlog中读取的. DispatchRequest dispatchRequest = DefaultMessageStore.this.commitLog.checkMessageAndReturnSize(result.getByteBuffer(), false, false); int size = dispatchRequest.getBufferSize() == -1 ? dispatchRequest.getMsgSize() : dispatchRequest.getBufferSize(); if (dispatchRequest.isSuccess()) &#123; if (size &gt; 0) &#123; DefaultMessageStore.this.doDispatch(dispatchRequest); //分发CommitLog写入消息 // 长轮询： 如果有消息到了主节点, 并且开启了长轮询. if (BrokerRole.SLAVE != DefaultMessageStore.this.getMessageStoreConfig().getBrokerRole() &amp;&amp; DefaultMessageStore.this.brokerConfig.isLongPollingEnable()) &#123; //唤醒NotifyMessageArrivingListener的arriving方法, 进行一次请求线程的检查 DefaultMessageStore.this.messageArrivingListener.arriving(dispatchRequest.getTopic(), dispatchRequest.getQueueId(), dispatchRequest.getConsumeQueueOffset() + 1, dispatchRequest.getTagsCode(), dispatchRequest.getStoreTimestamp(), dispatchRequest.getBitMap(), dispatchRequest.getPropertiesMap()); &#125; this.reputFromOffset += size; readSize += size; if (DefaultMessageStore.this.getMessageStoreConfig().getBrokerRole() == BrokerRole.SLAVE) &#123; DefaultMessageStore.this.storeStatsService.getSinglePutMessageTopicTimesTotal(dispatchRequest.getTopic()).incrementAndGet(); DefaultMessageStore.this.storeStatsService.getSinglePutMessageTopicSizeTotal(dispatchRequest.getTopic()).addAndGet(dispatchRequest.getMsgSize()); &#125; &#125; else if (size == 0) &#123; this.reputFromOffset = DefaultMessageStore.this.commitLog.rollNextFile(this.reputFromOffset); readSize = result.getSize(); &#125; &#125; else if (!dispatchRequest.isSuccess()) &#123; if (size &gt; 0) &#123; this.reputFromOffset += size; &#125; else &#123; doNext = false; if (DefaultMessageStore.this.getMessageStoreConfig().isEnableDLegerCommitLog() || DefaultMessageStore.this.brokerConfig.getBrokerId() == MixAll.MASTER_ID) &#123; this.reputFromOffset += result.getSize() - readSize; &#125; &#125; &#125; &#125; &#125; finally &#123; result.release(); &#125; &#125; else &#123; doNext = false; &#125; &#125; &#125; public void doDispatch(DispatchRequest req) &#123; for (CommitLogDispatcher dispatcher : this.dispatcherList) &#123; dispatcher.dispatch(req); // 将commitLog写入的事件转发到ComsumeQueue和IndexFile &#125; &#125;&#125; 对于 ConsumeQueue 文件的写入是通过调用 CommitLogDispatcherBuildConsumeQueue 的 dispatch 方法, 在分发时首先通过 DefaultMessageStore 的 findConsumeQueue 方法按消息 Topic 和 queueId 找到对应的消息队列, 然后调用 ConsumeQueue 的 putMessagePositionInfoWrapper 正则去完成写入到对应的缓存以及刷盘工作. 最终调用的 MappedFile 的 appendMessage 来完成数据的持久化. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108class CommitLogDispatcherBuildConsumeQueue implements CommitLogDispatcher &#123; @Override public void dispatch(DispatchRequest request) &#123; // Consumequeue文件分发的构建器 final int tranType = MessageSysFlag.getTransactionValue(request.getSysFlag()); switch (tranType) &#123; case MessageSysFlag.TRANSACTION_NOT_TYPE: case MessageSysFlag.TRANSACTION_COMMIT_TYPE: DefaultMessageStore.this.putMessagePositionInfo(request); break; case MessageSysFlag.TRANSACTION_PREPARED_TYPE: case MessageSysFlag.TRANSACTION_ROLLBACK_TYPE: break; &#125; &#125;&#125;public class DefaultMessageStore implements MessageStore &#123; private final ConcurrentMap&lt;String, ConcurrentMap&lt;Integer, ConsumeQueue&gt;&gt; consumeQueueTable; public void putMessagePositionInfo(DispatchRequest dispatchRequest) &#123; ConsumeQueue cq = this.findConsumeQueue(dispatchRequest.getTopic(), dispatchRequest.getQueueId()); cq.putMessagePositionInfoWrapper(dispatchRequest); &#125; public ConsumeQueue findConsumeQueue(String topic, int queueId) &#123; // 获取具体的队列 ConcurrentMap&lt;Integer, ConsumeQueue&gt; map = consumeQueueTable.get(topic); if (null == map) &#123; ConcurrentMap&lt;Integer, ConsumeQueue&gt; newMap = new ConcurrentHashMap&lt;Integer, ConsumeQueue&gt;(128); ConcurrentMap&lt;Integer, ConsumeQueue&gt; oldMap = consumeQueueTable.putIfAbsent(topic, newMap); if (oldMap != null) &#123; map = oldMap; &#125; else &#123; map = newMap; &#125; &#125; ConsumeQueue logic = map.get(queueId); if (null == logic) &#123; ConsumeQueue newLogic = new ConsumeQueue(topic, queueId, StorePathConfigHelper.getStorePathConsumeQueue(this.messageStoreConfig.getStorePathRootDir()), this.getMessageStoreConfig().getMappedFileSizeConsumeQueue(), this); ConsumeQueue oldLogic = map.putIfAbsent(queueId, newLogic); if (oldLogic != null) &#123; logic = oldLogic; &#125; else &#123; logic = newLogic; &#125; &#125; return logic; &#125;&#125;public class ConsumeQueue &#123; public void putMessagePositionInfoWrapper(DispatchRequest request) &#123; final int maxRetries = 30; boolean canWrite = this.defaultMessageStore.getRunningFlags().isCQWriteable(); for (int i = 0; i &lt; maxRetries &amp;&amp; canWrite; i++) &#123; long tagsCode = request.getTagsCode(); if (isExtWriteEnable()) &#123; ConsumeQueueExt.CqExtUnit cqExtUnit = new ConsumeQueueExt.CqExtUnit(); cqExtUnit.setFilterBitMap(request.getBitMap()); cqExtUnit.setMsgStoreTime(request.getStoreTimestamp()); cqExtUnit.setTagsCode(request.getTagsCode()); long extAddr = this.consumeQueueExt.put(cqExtUnit); if (isExtAddr(extAddr)) &#123; tagsCode = extAddr; &#125; &#125; // ConsumeQueue数据分发 boolean result = this.putMessagePositionInfo(request.getCommitLogOffset(), request.getMsgSize(), tagsCode, request.getConsumeQueueOffset()); if (result) &#123; if (this.defaultMessageStore.getMessageStoreConfig().getBrokerRole() == BrokerRole.SLAVE || this.defaultMessageStore.getMessageStoreConfig().isEnableDLegerCommitLog()) &#123; this.defaultMessageStore.getStoreCheckpoint().setPhysicMsgTimestamp(request.getStoreTimestamp()); &#125; this.defaultMessageStore.getStoreCheckpoint().setLogicsMsgTimestamp(request.getStoreTimestamp()); return; &#125; else &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; &#125; &#125; &#125; this.defaultMessageStore.getRunningFlags().makeLogicsQueueError(); &#125; private boolean putMessagePositionInfo(final long offset, final int size, final long tagsCode, final long cqOffset) &#123; if (offset + size &lt;= this.maxPhysicOffset) &#123; return true; &#125; this.byteBufferIndex.flip(); this.byteBufferIndex.limit(CQ_STORE_UNIT_SIZE); this.byteBufferIndex.putLong(offset); this.byteBufferIndex.putInt(size); this.byteBufferIndex.putLong(tagsCode); final long expectLogicOffset = cqOffset * CQ_STORE_UNIT_SIZE; MappedFile mappedFile = this.mappedFileQueue.getLastMappedFile(expectLogicOffset); if (mappedFile != null) &#123; if (mappedFile.isFirstCreateInQueue() &amp;&amp; cqOffset != 0 &amp;&amp; mappedFile.getWrotePosition() == 0) &#123; this.minLogicOffset = expectLogicOffset; this.mappedFileQueue.setFlushedWhere(expectLogicOffset); this.mappedFileQueue.setCommittedWhere(expectLogicOffset); this.fillPreBlank(mappedFile, expectLogicOffset); &#125; if (cqOffset != 0) &#123; long currentLogicOffset = mappedFile.getWrotePosition() + mappedFile.getFileFromOffset(); if (expectLogicOffset &lt; currentLogicOffset) &#123; return true; &#125; &#125; this.maxPhysicOffset = offset + size; return mappedFile.appendMessage(this.byteBufferIndex.array()); &#125; return false; &#125;&#125; 对于Index文件的分发是通过 CommitLogDispatcherBuildIndex 中最终调用 IndexService 的 buildIndex 方法完成的, 首先先通过 retryGetAndCreateIndexFile 获取 IndexFile , 若不存在则创建, 让后通过 IndexFile 的 putKey 方法将数据写入磁盘. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169class CommitLogDispatcherBuildIndex implements CommitLogDispatcher &#123; @Override public void dispatch(DispatchRequest request) &#123; if (DefaultMessageStore.this.messageStoreConfig.isMessageIndexEnable()) &#123; DefaultMessageStore.this.indexService.buildIndex(request); &#125; &#125;&#125;public class IndexService &#123; public void buildIndex(DispatchRequest req) &#123; IndexFile indexFile = retryGetAndCreateIndexFile(); if (indexFile != null) &#123; long endPhyOffset = indexFile.getEndPhyOffset(); DispatchRequest msg = req; String topic = msg.getTopic(); String keys = msg.getKeys(); if (msg.getCommitLogOffset() &lt; endPhyOffset) &#123; //重复消息直接返回 return; &#125; final int tranType = MessageSysFlag.getTransactionValue(msg.getSysFlag()); switch (tranType) &#123; case MessageSysFlag.TRANSACTION_NOT_TYPE: case MessageSysFlag.TRANSACTION_PREPARED_TYPE: case MessageSysFlag.TRANSACTION_COMMIT_TYPE: break; case MessageSysFlag.TRANSACTION_ROLLBACK_TYPE: return; // 回退消息直接返回 &#125; // indexFile索引文件构建的核心步骤 if (req.getUniqKey() != null) &#123; // 若存在唯一键 indexFile = putKey(indexFile, msg, buildKey(topic, req.getUniqKey())); if (indexFile == null) &#123; return; &#125; &#125; if (keys != null &amp;&amp; keys.length() &gt; 0) &#123; // 若存在过滤的keys String[] keyset = keys.split(MessageConst.KEY_SEPARATOR); for (int i = 0; i &lt; keyset.length; i++) &#123; String key = keyset[i]; if (key.length() &gt; 0) &#123; indexFile = putKey(indexFile, msg, buildKey(topic, key)); if (indexFile == null) &#123; return; &#125; &#125; &#125; &#125; &#125; &#125; public IndexFile retryGetAndCreateIndexFile() &#123; IndexFile indexFile = null; for (int times = 0; null == indexFile &amp;&amp; times &lt; MAX_TRY_IDX_CREATE; times++) &#123; indexFile = this.getAndCreateLastIndexFile(); if (null != indexFile) break; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; &#125; &#125; if (null == indexFile) &#123; this.defaultMessageStore.getAccessRights().makeIndexFileError(); &#125; return indexFile; &#125; public IndexFile getAndCreateLastIndexFile() &#123; IndexFile indexFile = null; IndexFile prevIndexFile = null; long lastUpdateEndPhyOffset = 0; long lastUpdateIndexTimestamp = 0; &#123; this.readWriteLock.readLock().lock(); if (!this.indexFileList.isEmpty()) &#123; IndexFile tmp = this.indexFileList.get(this.indexFileList.size() - 1); if (!tmp.isWriteFull()) &#123; indexFile = tmp; &#125; else &#123; lastUpdateEndPhyOffset = tmp.getEndPhyOffset(); lastUpdateIndexTimestamp = tmp.getEndTimestamp(); prevIndexFile = tmp; &#125; &#125; this.readWriteLock.readLock().unlock(); &#125; if (indexFile == null) &#123; try &#123; // 按照时间生成Index文件名称 String fileName = this.storePath + File.separator + UtilAll.timeMillisToHumanString(System.currentTimeMillis()); indexFile = new IndexFile(fileName, this.hashSlotNum, this.indexNum, lastUpdateEndPhyOffset, lastUpdateIndexTimestamp); this.readWriteLock.writeLock().lock(); this.indexFileList.add(indexFile); &#125; catch (Exception e) &#123; &#125; finally &#123; this.readWriteLock.writeLock().unlock(); &#125; if (indexFile != null) &#123; // 开启线程将之前的IndexFile缓存中的数据刷到磁盘中 final IndexFile flushThisFile = prevIndexFile; Thread flushThread = new Thread(new Runnable() &#123; @Override public void run() &#123; IndexService.this.flush(flushThisFile); &#125; &#125;, &quot;FlushIndexFileThread&quot;); flushThread.setDaemon(true); flushThread.start(); &#125; &#125; return indexFile; &#125; private IndexFile putKey(IndexFile indexFile, DispatchRequest msg, String idxKey) &#123; for (boolean ok = indexFile.putKey(idxKey, msg.getCommitLogOffset(), msg.getStoreTimestamp()); !ok; ) &#123; indexFile = retryGetAndCreateIndexFile(); if (null == indexFile) &#123; return null; &#125; ok = indexFile.putKey(idxKey, msg.getCommitLogOffset(), msg.getStoreTimestamp()); &#125; return indexFile; &#125;&#125;public class IndexFile &#123; public boolean putKey(final String key, final long phyOffset, final long storeTimestamp) &#123; if (this.indexHeader.getIndexCount() &lt; this.indexNum) &#123; int keyHash = indexKeyHashMethod(key); int slotPos = keyHash % this.hashSlotNum; int absSlotPos = IndexHeader.INDEX_HEADER_SIZE + slotPos * hashSlotSize; FileLock fileLock = null; try &#123;// fileLock = this.fileChannel.lock(absSlotPos, hashSlotSize, false); int slotValue = this.mappedByteBuffer.getInt(absSlotPos); if (slotValue &lt;= invalidIndex || slotValue &gt; this.indexHeader.getIndexCount()) &#123; slotValue = invalidIndex; &#125; long timeDiff = storeTimestamp - this.indexHeader.getBeginTimestamp(); timeDiff = timeDiff / 1000; if (this.indexHeader.getBeginTimestamp() &lt;= 0) &#123; timeDiff = 0; &#125; else if (timeDiff &gt; Integer.MAX_VALUE) &#123; timeDiff = Integer.MAX_VALUE; &#125; else if (timeDiff &lt; 0) &#123; timeDiff = 0; &#125; int absIndexPos = IndexHeader.INDEX_HEADER_SIZE + this.hashSlotNum * hashSlotSize + this.indexHeader.getIndexCount() * indexSize; this.mappedByteBuffer.putInt(absIndexPos, keyHash); this.mappedByteBuffer.putLong(absIndexPos + 4, phyOffset); this.mappedByteBuffer.putInt(absIndexPos + 4 + 8, (int) timeDiff); this.mappedByteBuffer.putInt(absIndexPos + 4 + 8 + 4, slotValue); this.mappedByteBuffer.putInt(absSlotPos, this.indexHeader.getIndexCount()); if (this.indexHeader.getIndexCount() &lt;= 1) &#123; this.indexHeader.setBeginPhyOffset(phyOffset); this.indexHeader.setBeginTimestamp(storeTimestamp); &#125; if (invalidIndex == slotValue) &#123; this.indexHeader.incHashSlotCount(); &#125; this.indexHeader.incIndexCount(); this.indexHeader.setEndPhyOffset(phyOffset); this.indexHeader.setEndTimestamp(storeTimestamp); return true; &#125; catch (Exception e) &#123; &#125; finally &#123; if (fileLock != null) &#123; try &#123; fileLock.release(); &#125; &#125; &#125; &#125; return false; &#125;&#125;","tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"http://example.com/tags/RocketMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RocketMQ","slug":"工具和中间件/消息队列/RocketMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RocketMQ/"}]},{"title":"RocketMQ-消费者源码","date":"2019-04-23T04:08:20.000Z","path":"blog/工具和中间件/消息队列/RocketMQ/RocketMQ-消费者源码/","text":"消费者以消费者组的模式开展.消费者组之间有集群模式和广播模式两种消费模式.消费模式有推模式和拉模式.推模式是由拉模式封装组成. 集群模式下,一个消费队列同一时间只能被一个消费者消费,而一个消费者可以同时消费多个队列.RocketMQ只支持一个队列上的局部消息顺序,不保证全局消息顺序. 在 DefaultMQPushConsumer 中的 start 方法中,通过调用 MQClientManager 的 getOrCreateMQClientInstance 方法实例化关键类 MQClientInstance ,在 MQClientInstance 中实例化了 PullMessageService 和 RebalanceService 两个线程类. MQClientInstance 的start方法中会启动 PullMessageService 和 RebalanceService 线程. RebalanceService 线程默认每 20s 执行一次,调用 MQClientInstance 的 doRebalance 方法遍历当前客户端所有消费者组的所有消费者,再通过 RebalanceImpl 的 doRebalance 方法遍历消费者对应的所有Topic,然后通过 rebalanceByTopic 对集群模式和广播模式进行处理,然后通过 updateProcessQueueTableInRebalance 方法遍历Topic下所有的队列将未消费的消息封装成 PullRequest列表最终通过 PullMessageService 的 executePullRequestImmediately 方法将 PullRequest 任务添加阻塞队列中. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149public class RebalanceService extends ServiceThread &#123; public void run() &#123; log.info(this.getServiceName() + &quot; service started&quot;); while (!this.isStopped()) &#123; this.waitForRunning(waitInterval); this.mqClientFactory.doRebalance(); &#125; log.info(this.getServiceName() + &quot; service end&quot;); &#125;&#125;public class MQClientInstance &#123; public void doRebalance() &#123; // 客户端负载均衡 针对当前消费者所属的每一个消费者组 for (Map.Entry&lt;String, MQConsumerInner&gt; entry : this.consumerTable.entrySet()) &#123; MQConsumerInner impl = entry.getValue(); if (impl != null) &#123; try &#123; impl.doRebalance(); &#125; &#125; &#125; &#125;&#125;public abstract class RebalanceImpl &#123; public void doRebalance(final boolean isOrder) &#123; Map&lt;String, SubscriptionData&gt; subTable = this.getSubscriptionInner(); if (subTable != null) &#123; for (final Map.Entry&lt;String, SubscriptionData&gt; entry : subTable.entrySet()) &#123; final String topic = entry.getKey(); try &#123; // 客户端负载：真正进行负载都是根据主题来进行的. this.rebalanceByTopic(topic, isOrder); &#125; catch (Throwable e) &#123; &#125; &#125; &#125; this.truncateMessageQueueNotMyTopic(); &#125; private void rebalanceByTopic(final String topic, final boolean isOrder) &#123; switch (messageModel) &#123; case BROADCASTING: &#123; //广播模式,不需要进行负载.每个消费者都要消费.只需要更新负载信息. Set&lt;MessageQueue&gt; mqSet = this.topicSubscribeInfoTable.get(topic); if (mqSet != null) &#123; boolean changed = this.updateProcessQueueTableInRebalance(topic, mqSet, isOrder); // 关键代码 if (changed) &#123; this.messageQueueChanged(topic, mqSet, mqSet); &#125; &#125; break; &#125; case CLUSTERING: &#123; // 客户端负载：集群模式负载方法 Set&lt;MessageQueue&gt; mqSet = this.topicSubscribeInfoTable.get(topic); //订阅的主题 List&lt;String&gt; cidAll = this.mQClientFactory.findConsumerIdList(topic, consumerGroup); //客户端ID if (mqSet != null &amp;&amp; cidAll != null) &#123; List&lt;MessageQueue&gt; mqAll = new ArrayList&lt;MessageQueue&gt;(); mqAll.addAll(mqSet); Collections.sort(mqAll); //排序后才能保证消费者负载策略相对稳定. Collections.sort(cidAll); AllocateMessageQueueStrategy strategy = this.allocateMessageQueueStrategy; //MessageQueue的负载策略,有五种实现类 List&lt;MessageQueue&gt; allocateResult = null; try &#123;//按负载策略进行分配,返回当前消费者实际订阅的MessageQueue集合. allocateResult = strategy.allocate(this.consumerGroup, this.mQClientFactory.getClientId(), mqAll, cidAll); &#125; catch (Throwable e) &#123; return; &#125; Set&lt;MessageQueue&gt; allocateResultSet = new HashSet&lt;MessageQueue&gt;(); if (allocateResult != null) &#123; allocateResultSet.addAll(allocateResult); &#125; boolean changed = this.updateProcessQueueTableInRebalance(topic, allocateResultSet, isOrder); // 关键代码 if (changed) &#123; this.messageQueueChanged(topic, mqSet, allocateResultSet); &#125; &#125; break; &#125; default: break; &#125; &#125; private boolean updateProcessQueueTableInRebalance(final String topic, final Set&lt;MessageQueue&gt; mqSet, final boolean isOrder) &#123; boolean changed = false; Iterator&lt;Entry&lt;MessageQueue, ProcessQueue&gt;&gt; it = this.processQueueTable.entrySet().iterator(); while (it.hasNext()) &#123; Entry&lt;MessageQueue, ProcessQueue&gt; next = it.next(); MessageQueue mq = next.getKey(); ProcessQueue pq = next.getValue(); if (mq.getTopic().equals(topic)) &#123; if (!mqSet.contains(mq)) &#123; pq.setDropped(true); if (this.removeUnnecessaryMessageQueue(mq, pq)) &#123; it.remove(); changed = true; &#125; &#125; else if (pq.isPullExpired()) &#123; switch (this.consumeType()) &#123; case CONSUME_ACTIVELY: break; case CONSUME_PASSIVELY: pq.setDropped(true); if (this.removeUnnecessaryMessageQueue(mq, pq)) &#123; it.remove(); changed = true; &#125; break; default: break; &#125; &#125; &#125; &#125; List&lt;PullRequest&gt; pullRequestList = new ArrayList&lt;PullRequest&gt;(); for (MessageQueue mq : mqSet) &#123; if (!this.processQueueTable.containsKey(mq)) &#123; if (isOrder &amp;&amp; !this.lock(mq)) &#123; continue; &#125; this.removeDirtyOffset(mq); ProcessQueue pq = new ProcessQueue(); long nextOffset = this.computePullFromWhere(mq); if (nextOffset &gt;= 0) &#123; ProcessQueue pre = this.processQueueTable.putIfAbsent(mq, pq); if (pre != null) &#123; &#125; else &#123; PullRequest pullRequest = new PullRequest(); pullRequest.setConsumerGroup(consumerGroup); pullRequest.setNextOffset(nextOffset); pullRequest.setMessageQueue(mq); pullRequest.setProcessQueue(pq); pullRequestList.add(pullRequest); changed = true; &#125; &#125; &#125; &#125; this.dispatchPullRequest(pullRequestList); return changed; &#125;&#125;public class RebalancePushImpl extends RebalanceImpl &#123; public void dispatchPullRequest(List&lt;PullRequest&gt; pullRequestList) &#123; for (PullRequest pullRequest : pullRequestList) &#123; this.defaultMQPushConsumerImpl.executePullRequestImmediately(pullRequest); &#125; &#125;&#125;public class DefaultMQPushConsumerImpl implements MQConsumerInner &#123; public void executePullRequestImmediately(final PullRequest pullRequest) &#123; this.mQClientFactory.getPullMessageService().executePullRequestImmediately(pullRequest); &#125;&#125; PullMessageService 线程的 run 方法中消费 PullRequest 请求,最终调用 DefaultMQPushConsumerImpl 的 pullMessage 方法,首先会对消息进行流量和消息大小限流,若不满足限流条线丢到线程池中延迟处理,定义了一个拉取消息的回调函数PullCallback ,若拉取消息失败则调用 onException 将其丢到线程池中延迟处理下次继续重试处理,若成功则调用 onSuccess 方法,在该方法中若拉取到数据后会调用 executePullRequestLater 或 executePullRequestImmediately 方法再次将拉取请求放入任务队列中,若有数据则会一直拉取直到数据被消费完则 PullStatus 会变为非 FOUND 状态.不论获取消息成功还是失败都会将请求再次放回队列,便于长轮训的方式拉取消息. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157public class PullMessageService extends ServiceThread &#123; public void run() &#123; while (!this.isStopped()) &#123; try &#123; //拉取消息的请求队列 PullRequest pullRequest = this.pullRequestQueue.take(); this.pullMessage(pullRequest); //处理请求 &#125; &#125; &#125; private void pullMessage(final PullRequest pullRequest) &#123; final MQConsumerInner consumer = this.mQClientFactory.selectConsumer(pullRequest.getConsumerGroup()); if (consumer != null) &#123; DefaultMQPushConsumerImpl impl = (DefaultMQPushConsumerImpl) consumer; impl.pullMessage(pullRequest); // 推模式的消费者最终还是会使用拉消息的方式 &#125; &#125;&#125;public class DefaultMQPushConsumerImpl implements MQConsumerInner &#123; public void pullMessage(final PullRequest pullRequest) &#123; // 拉取消息的核心流程 final ProcessQueue processQueue = pullRequest.getProcessQueue(); //获取要处理的消息：ProcessQueue if (processQueue.isDropped()) &#123; //如果队列被抛弃,直接返回 return; &#125; pullRequest.getProcessQueue().setLastPullTimestamp(System.currentTimeMillis()); //先更新时间戳 try &#123; this.makeSureStateOK(); &#125; catch (MQClientException e) &#123; this.executePullRequestLater(pullRequest, pullTimeDelayMillsWhenException); return; &#125; if (this.isPause()) &#123; //如果处理队列被挂起,延迟1S后再执行. this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_SUSPEND); return; &#125; long cachedMessageCount = processQueue.getMsgCount().get(); //获得最大待处理消息数量 long cachedMessageSizeInMiB = processQueue.getMsgSize().get() / (1024 * 1024); //获得最大待处理消息大小 if (cachedMessageCount &gt; this.defaultMQPushConsumer.getPullThresholdForQueue()) &#123; //从数量进行流控 this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL); return; &#125; if (cachedMessageSizeInMiB &gt; this.defaultMQPushConsumer.getPullThresholdSizeForQueue()) &#123; //从消息大小进行流控 this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL); return; &#125; if (!this.consumeOrderly) &#123; // 若是有序消息 if (processQueue.getMaxSpan() &gt; this.defaultMQPushConsumer.getConsumeConcurrentlyMaxSpan()) &#123; this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL); return; &#125; &#125; else &#123; if (processQueue.isLocked()) &#123; if (!pullRequest.isLockedFirst()) &#123; final long offset = this.rebalanceImpl.computePullFromWhere(pullRequest.getMessageQueue()); boolean brokerBusy = offset &lt; pullRequest.getNextOffset(); pullRequest.setLockedFirst(true); pullRequest.setNextOffset(offset); &#125; &#125; else &#123; this.executePullRequestLater(pullRequest, pullTimeDelayMillsWhenException); return; &#125; &#125; // 获取订阅信息 final SubscriptionData subscriptionData = this.rebalanceImpl.getSubscriptionInner().get(pullRequest.getMessageQueue().getTopic()); if (null == subscriptionData) &#123; this.executePullRequestLater(pullRequest, pullTimeDelayMillsWhenException); return; &#125; final long beginTimestamp = System.currentTimeMillis(); PullCallback pullCallback = new PullCallback() &#123; // 客户端默认的拉取的回调函数,在拉取到消息后会进入这个方法处理. @Override public void onSuccess(PullResult pullResult) &#123; if (pullResult != null) &#123; pullResult = DefaultMQPushConsumerImpl.this.pullAPIWrapper.processPullResult(pullRequest.getMessageQueue(), pullResult, subscriptionData); switch (pullResult.getPullStatus()) &#123; case FOUND: long prevRequestOffset = pullRequest.getNextOffset(); pullRequest.setNextOffset(pullResult.getNextBeginOffset()); long pullRT = System.currentTimeMillis() - beginTimestamp; DefaultMQPushConsumerImpl.this.getConsumerStatsManager().incPullRT(pullRequest.getConsumerGroup(), pullRequest.getMessageQueue().getTopic(), pullRT); long firstMsgOffset = Long.MAX_VALUE; if (pullResult.getMsgFoundList() == null || pullResult.getMsgFoundList().isEmpty()) &#123; DefaultMQPushConsumerImpl.this.executePullRequestImmediately(pullRequest); &#125; else &#123; firstMsgOffset = pullResult.getMsgFoundList().get(0).getQueueOffset(); DefaultMQPushConsumerImpl.this.getConsumerStatsManager().incPullTPS(pullRequest.getConsumerGroup(), pullRequest.getMessageQueue().getTopic(), pullResult.getMsgFoundList().size()); boolean dispatchToConsume = processQueue.putMessage(pullResult.getMsgFoundList()); // 消费者消息服务处理消费到的消息 DefaultMQPushConsumerImpl.this.consumeMessageService.submitConsumeRequest(pullResult.getMsgFoundList(), processQueue, pullRequest.getMessageQueue(), dispatchToConsume); if (DefaultMQPushConsumerImpl.this.defaultMQPushConsumer.getPullInterval() &gt; 0) &#123; // 退模式下任务间隔时间 DefaultMQPushConsumerImpl.this.executePullRequestLater(pullRequest, DefaultMQPushConsumerImpl.this.defaultMQPushConsumer.getPullInterval()); &#125; else &#123; DefaultMQPushConsumerImpl.this.executePullRequestImmediately(pullRequest); &#125; &#125; break; case NO_NEW_MSG: pullRequest.setNextOffset(pullResult.getNextBeginOffset()); DefaultMQPushConsumerImpl.this.correctTagsOffset(pullRequest); DefaultMQPushConsumerImpl.this.executePullRequestImmediately(pullRequest); break; case NO_MATCHED_MSG: pullRequest.setNextOffset(pullResult.getNextBeginOffset()); DefaultMQPushConsumerImpl.this.correctTagsOffset(pullRequest); DefaultMQPushConsumerImpl.this.executePullRequestImmediately(pullRequest); break; case OFFSET_ILLEGAL: pullRequest.setNextOffset(pullResult.getNextBeginOffset()); pullRequest.getProcessQueue().setDropped(true); DefaultMQPushConsumerImpl.this.executeTaskLater(new Runnable() &#123; @Override public void run() &#123; try &#123; DefaultMQPushConsumerImpl.this.offsetStore.updateOffset(pullRequest.getMessageQueue(), pullRequest.getNextOffset(), false); DefaultMQPushConsumerImpl.this.offsetStore.persist(pullRequest.getMessageQueue()); DefaultMQPushConsumerImpl.this.rebalanceImpl.removeProcessQueue(pullRequest.getMessageQueue()); &#125; &#125; &#125;, 10000); break; default: break; &#125; &#125; &#125; @Override public void onException(Throwable e) &#123; DefaultMQPushConsumerImpl.this.executePullRequestLater(pullRequest, pullTimeDelayMillsWhenException); &#125; &#125;; boolean commitOffsetEnable = false; long commitOffsetValue = 0L; if (MessageModel.CLUSTERING == this.defaultMQPushConsumer.getMessageModel()) &#123; commitOffsetValue = this.offsetStore.readOffset(pullRequest.getMessageQueue(), ReadOffsetType.READ_FROM_MEMORY); if (commitOffsetValue &gt; 0) &#123; commitOffsetEnable = true; &#125; &#125; String subExpression = null; boolean classFilter = false; SubscriptionData sd = this.rebalanceImpl.getSubscriptionInner().get(pullRequest.getMessageQueue().getTopic()); if (sd != null) &#123; if (this.defaultMQPushConsumer.isPostSubscriptionWhenPull() &amp;&amp; !sd.isClassFilterMode()) &#123; subExpression = sd.getSubString(); &#125; classFilter = sd.isClassFilterMode(); &#125; int sysFlag = PullSysFlag.buildSysFlag(commitOffsetEnable, true, subExpression != null, classFilter); try &#123;// 客户端实际与服务器交互,拉取消息的地方,拉取成功后回调PullCallback this.pullAPIWrapper.pullKernelImpl(pullRequest.getMessageQueue(), subExpression, subscriptionData.getExpressionType(), subscriptionData.getSubVersion(), pullRequest.getNextOffset(), this.defaultMQPushConsumer.getPullBatchSize(), sysFlag, commitOffsetValue, BROKER_SUSPEND_MAX_TIME_MILLIS, CONSUMER_TIMEOUT_MILLIS_WHEN_SUSPEND, CommunicationMode.ASYNC, pullCallback); &#125; catch (Exception e) &#123; this.executePullRequestLater(pullRequest, pullTimeDelayMillsWhenException); &#125; &#125;&#125; 在拉取消息成功 PullCallback回调方法中,普通消息和顺序消息分别调用 ConsumeMessageConcurrentlyService 和 ConsumeMessageOrderlyService 的 submitConsumeRequest 方法.最终通过 ConsumeRequest 线程来处理,在该线程中具体消费者的 consumeMessage 方法. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135public class ConsumeMessageConcurrentlyService implements ConsumeMessageService &#123; public void submitConsumeRequest(final List&lt;MessageExt&gt; msgs, final ProcessQueue processQueue, final MessageQueue messageQueue, final boolean dispatchToConsume) &#123; final int consumeBatchSize = this.defaultMQPushConsumer.getConsumeMessageBatchMaxSize(); if (msgs.size() &lt;= consumeBatchSize) &#123; //一次只拉取32条数据,不足32直接处理 ConsumeRequest consumeRequest = new ConsumeRequest(msgs, processQueue, messageQueue); try &#123; this.consumeExecutor.submit(consumeRequest); &#125; catch (RejectedExecutionException e) &#123; this.submitConsumeRequestLater(consumeRequest); &#125; &#125; else &#123;//超过32条,就进行分页处理. for (int total = 0; total &lt; msgs.size(); ) &#123; List&lt;MessageExt&gt; msgThis = new ArrayList&lt;MessageExt&gt;(consumeBatchSize); for (int i = 0; i &lt; consumeBatchSize; i++, total++) &#123; if (total &lt; msgs.size()) &#123; msgThis.add(msgs.get(total)); &#125; else &#123; break; &#125; &#125; ConsumeRequest consumeRequest = new ConsumeRequest(msgThis, processQueue, messageQueue); //消费请求处理线程 try &#123; this.consumeExecutor.submit(consumeRequest); &#125; catch (RejectedExecutionException e) &#123; for (; total &lt; msgs.size(); total++) &#123; msgThis.add(msgs.get(total)); &#125; this.submitConsumeRequestLater(consumeRequest); &#125; &#125; &#125; &#125;&#125;public class ConsumeMessageOrderlyService implements ConsumeMessageService &#123; public void submitConsumeRequest(final List&lt;MessageExt&gt; msgs, final ProcessQueue processQueue, final MessageQueue messageQueue, final boolean dispathToConsume) &#123; if (dispathToConsume) &#123; ConsumeRequest consumeRequest = new ConsumeRequest(processQueue, messageQueue); this.consumeExecutor.submit(consumeRequest); &#125; &#125;&#125;class ConsumeRequest implements Runnable &#123; public void run() &#123; if (this.processQueue.isDropped()) &#123; return; &#125; final Object objLock = messageQueueLock.fetchLockObject(this.messageQueue); synchronized (objLock) &#123;//通过加锁,将并发的消息顺序进行消费.消息处理的方式没什么特别. if (MessageModel.BROADCASTING.equals(ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.messageModel()) || (this.processQueue.isLocked() &amp;&amp; !this.processQueue.isLockExpired())) &#123; final long beginTime = System.currentTimeMillis(); for (boolean continueConsume = true; continueConsume; ) &#123; if (this.processQueue.isDropped()) &#123; break; &#125; if (MessageModel.CLUSTERING.equals(ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.messageModel()) &amp;&amp; !this.processQueue.isLocked()) &#123; ConsumeMessageOrderlyService.this.tryLockLaterAndReconsume(this.messageQueue, this.processQueue, 10); break; &#125; if (MessageModel.CLUSTERING.equals(ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.messageModel()) &amp;&amp; this.processQueue.isLockExpired()) &#123; ConsumeMessageOrderlyService.this.tryLockLaterAndReconsume(this.messageQueue, this.processQueue, 10); break; &#125; long interval = System.currentTimeMillis() - beginTime; if (interval &gt; MAX_TIME_CONSUME_CONTINUOUSLY) &#123; ConsumeMessageOrderlyService.this.submitConsumeRequestLater(processQueue, messageQueue, 10); break; &#125; final int consumeBatchSize = ConsumeMessageOrderlyService.this.defaultMQPushConsumer.getConsumeMessageBatchMaxSize(); List&lt;MessageExt&gt; msgs = this.processQueue.takeMessages(consumeBatchSize); defaultMQPushConsumerImpl.resetRetryAndNamespace(msgs, defaultMQPushConsumer.getConsumerGroup()); if (!msgs.isEmpty()) &#123; final ConsumeOrderlyContext context = new ConsumeOrderlyContext(this.messageQueue); ConsumeOrderlyStatus status = null; ConsumeMessageContext consumeMessageContext = null; if (ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.hasHook()) &#123; consumeMessageContext = new ConsumeMessageContext(); consumeMessageContext.setConsumerGroup(ConsumeMessageOrderlyService.this.defaultMQPushConsumer.getConsumerGroup()); consumeMessageContext.setNamespace(defaultMQPushConsumer.getNamespace()); consumeMessageContext.setMq(messageQueue); consumeMessageContext.setMsgList(msgs); consumeMessageContext.setSuccess(false); consumeMessageContext.setProps(new HashMap&lt;String, String&gt;()); // init the consume context type ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.executeHookBefore(consumeMessageContext); &#125; long beginTimestamp = System.currentTimeMillis(); ConsumeReturnType returnType = ConsumeReturnType.SUCCESS; boolean hasException = false; try &#123; this.processQueue.getLockConsume().lock(); status = messageListener.consumeMessage(Collections.unmodifiableList(msgs), context); // 调用消费者具体的消费方法 &#125; catch (Throwable e) &#123; hasException = true; &#125; finally &#123; this.processQueue.getLockConsume().unlock(); &#125; long consumeRT = System.currentTimeMillis() - beginTimestamp; if (null == status) &#123; if (hasException) &#123; returnType = ConsumeReturnType.EXCEPTION; &#125; else &#123; returnType = ConsumeReturnType.RETURNNULL; &#125; &#125; else if (consumeRT &gt;= defaultMQPushConsumer.getConsumeTimeout() * 60 * 1000) &#123; returnType = ConsumeReturnType.TIME_OUT; &#125; else if (ConsumeOrderlyStatus.SUSPEND_CURRENT_QUEUE_A_MOMENT == status) &#123; returnType = ConsumeReturnType.FAILED; &#125; else if (ConsumeOrderlyStatus.SUCCESS == status) &#123; returnType = ConsumeReturnType.SUCCESS; &#125; if (ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.hasHook()) &#123; consumeMessageContext.getProps().put(MixAll.CONSUME_CONTEXT_TYPE, returnType.name()); &#125; if (null == status) &#123; status = ConsumeOrderlyStatus.SUSPEND_CURRENT_QUEUE_A_MOMENT; &#125; if (ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.hasHook()) &#123; consumeMessageContext.setStatus(status.toString()); consumeMessageContext.setSuccess(ConsumeOrderlyStatus.SUCCESS == status || ConsumeOrderlyStatus.COMMIT == status); ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.executeHookAfter(consumeMessageContext); &#125; ConsumeMessageOrderlyService.this.getConsumerStatsManager().incConsumeRT(ConsumeMessageOrderlyService.this.consumerGroup, messageQueue.getTopic(), consumeRT); continueConsume = ConsumeMessageOrderlyService.this.processConsumeResult(msgs, status, context, this); &#125; else &#123; continueConsume = false; &#125; &#125; &#125; else &#123; if (this.processQueue.isDropped()) &#123; return; &#125; ConsumeMessageOrderlyService.this.tryLockLaterAndReconsume(this.messageQueue, this.processQueue, 100); &#125; &#125; &#125;&#125; 消息的拉取最终调用的是 PullAPIWrapper 的 pullKernelImpl 方法,拉取模式固定为 ASYNC ,最终调用 MQClientAPIImpl 的 pullMessageAsync 方法想 Broker 发送 RequestCode.PULL_MESSAGE 命令拉取消息,在 operationComplete 方法中完成 PullCallback回调. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788public class PullAPIWrapper &#123; public PullResult pullKernelImpl(final MessageQueue mq, final String subExpression, final String expressionType, final long subVersion, final long offset, final int maxNums, final int sysFlag, final long commitOffset, final long brokerSuspendMaxTimeMillis, final long timeoutMillis, final CommunicationMode communicationMode, final PullCallback pullCallback) throws MQClientException, RemotingException, MQBrokerException, InterruptedException &#123; //找到Broker FindBrokerResult findBrokerResult = this.mQClientFactory.findBrokerAddressInSubscribe(mq.getBrokerName(), this.recalculatePullFromWhichNode(mq), false); if (null == findBrokerResult) &#123; this.mQClientFactory.updateTopicRouteInfoFromNameServer(mq.getTopic()); findBrokerResult = this.mQClientFactory.findBrokerAddressInSubscribe(mq.getBrokerName(), this.recalculatePullFromWhichNode(mq), false); &#125; if (findBrokerResult != null) &#123; &#123;// check version 版本检查 if (!ExpressionType.isTagType(expressionType) &amp;&amp; findBrokerResult.getBrokerVersion() &lt; MQVersion.Version.V4_1_0_SNAPSHOT.ordinal()) &#123; throw new MQClientException(&quot;The broker[&quot; + mq.getBrokerName() + &quot;, &quot; + findBrokerResult.getBrokerVersion() + &quot;] does not upgrade to support for filter message by &quot; + expressionType, null); &#125; &#125; int sysFlagInner = sysFlag; if (findBrokerResult.isSlave()) &#123; sysFlagInner = PullSysFlag.clearCommitOffsetFlag(sysFlagInner); &#125; //构建请求 PullMessageRequestHeader requestHeader = new PullMessageRequestHeader(); requestHeader.setConsumerGroup(this.consumerGroup); requestHeader.setTopic(mq.getTopic()); requestHeader.setQueueId(mq.getQueueId()); requestHeader.setQueueOffset(offset); requestHeader.setMaxMsgNums(maxNums); requestHeader.setSysFlag(sysFlagInner); requestHeader.setCommitOffset(commitOffset); requestHeader.setSuspendTimeoutMillis(brokerSuspendMaxTimeMillis); requestHeader.setSubscription(subExpression); requestHeader.setSubVersion(subVersion); requestHeader.setExpressionType(expressionType); String brokerAddr = findBrokerResult.getBrokerAddr(); if (PullSysFlag.hasClassFilterFlag(sysFlagInner)) &#123; brokerAddr = computPullFromWhichFilterServer(mq.getTopic(), brokerAddr); &#125; //拉取消息 PullResult pullResult = this.mQClientFactory.getMQClientAPIImpl().pullMessage(brokerAddr, requestHeader, timeoutMillis, communicationMode, pullCallback); return pullResult; &#125; throw new MQClientException(&quot;The broker[&quot; + mq.getBrokerName() + &quot;] not exist&quot;, null); &#125;&#125;public class MQClientAPIImpl &#123; public PullResult pullMessage(final String addr, final PullMessageRequestHeader requestHeader, final long timeoutMillis, final CommunicationMode communicationMode, final PullCallback pullCallback) throws RemotingException, MQBrokerException, InterruptedException &#123; RemotingCommand request = RemotingCommand.createRequestCommand(RequestCode.PULL_MESSAGE, requestHeader); //几种拉取方式 switch (communicationMode) &#123; case ONEWAY: assert false; return null; case ASYNC: this.pullMessageAsync(addr, request, timeoutMillis, pullCallback); return null; case SYNC: return this.pullMessageSync(addr, request, timeoutMillis); default: assert false; break; &#125; return null; &#125; private void pullMessageAsync(final String addr, final RemotingCommand request, final long timeoutMillis, final PullCallback pullCallback) throws RemotingException, InterruptedException &#123; this.remotingClient.invokeAsync(addr, request, timeoutMillis, new InvokeCallback() &#123; //异步拉取 @Override public void operationComplete(ResponseFuture responseFuture) &#123; RemotingCommand response = responseFuture.getResponseCommand(); //处理拉取消息的结果 if (response != null) &#123; //有响应 try &#123; PullResult pullResult = MQClientAPIImpl.this.processPullResponse(response); assert pullResult != null; pullCallback.onSuccess(pullResult); &#125; catch (Exception e) &#123; pullCallback.onException(e); &#125; &#125; else &#123;//没响应 if (!responseFuture.isSendRequestOK()) &#123; pullCallback.onException(new MQClientException(&quot;send request failed to &quot; + addr + &quot;. Request: &quot; + request, responseFuture.getCause())); &#125; else if (responseFuture.isTimeout()) &#123; pullCallback.onException(new MQClientException(&quot;wait response from &quot; + addr + &quot; timeout :&quot; + responseFuture.getTimeoutMillis() + &quot;ms&quot; + &quot;. Request: &quot; + request, responseFuture.getCause())); &#125; else &#123; pullCallback.onException(new MQClientException(&quot;unknown reason. addr: &quot; + addr + &quot;, timeoutMillis: &quot; + timeoutMillis + &quot;. Request: &quot; + request, responseFuture.getCause())); &#125; &#125; &#125; &#125;); &#125;&#125; 在Broker通过 PullMessageProcessor 方法的 processRequest 方法处理 RequestCode.PULL_MESSAGE 请求.首先端构建消息过滤器,然后在 DefaultMessageStore 的 getMessage 查询消息中调用 MessageFilter 的 isMatchedByConsumeQueue 方法.若 ResponseCode.PULL_NOT_FOUND 未拉取到数据,则再创建一个拉取请求且通过 PullRequestHoldService 的 suspendPullRequest 将该请求放入 ManyPullRequest 请求拉取队列,从而实现长连接. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109private RemotingCommand processRequest(final Channel channel, RemotingCommand request, boolean brokerAllowSuspend) throws RemotingCommandException &#123; RemotingCommand response = RemotingCommand.createResponseCommand(PullMessageResponseHeader.class); final PullMessageResponseHeader responseHeader = (PullMessageResponseHeader) response.readCustomHeader(); final PullMessageRequestHeader requestHeader = (PullMessageRequestHeader) request.decodeCommandCustomHeader(PullMessageRequestHeader.class); response.setOpaque(request.getOpaque()); SubscriptionGroupConfig subscriptionGroupConfig = this.brokerController.getSubscriptionGroupManager().findSubscriptionGroupConfig(requestHeader.getConsumerGroup()); final boolean hasSuspendFlag = PullSysFlag.hasSuspendFlag(requestHeader.getSysFlag()); final boolean hasCommitOffsetFlag = PullSysFlag.hasCommitOffsetFlag(requestHeader.getSysFlag()); final boolean hasSubscriptionFlag = PullSysFlag.hasSubscriptionFlag(requestHeader.getSysFlag()); final long suspendTimeoutMillisLong = hasSuspendFlag ? requestHeader.getSuspendTimeoutMillis() : 0; TopicConfig topicConfig = this.brokerController.getTopicConfigManager().selectTopicConfig(requestHeader.getTopic()); SubscriptionData subscriptionData = null; ConsumerFilterData consumerFilterData = null; if (hasSubscriptionFlag) &#123; try &#123; subscriptionData = FilterAPI.build(requestHeader.getTopic(), requestHeader.getSubscription(), requestHeader.getExpressionType()); if (!ExpressionType.isTagType(subscriptionData.getExpressionType())) &#123; consumerFilterData = ConsumerFilterManager.build(requestHeader.getTopic(), requestHeader.getConsumerGroup(), requestHeader.getSubscription(), requestHeader.getExpressionType(), requestHeader.getSubVersion()); assert consumerFilterData != null; &#125; &#125; &#125; else &#123; ConsumerGroupInfo consumerGroupInfo = this.brokerController.getConsumerManager().getConsumerGroupInfo(requestHeader.getConsumerGroup()); subscriptionData = consumerGroupInfo.findSubscriptionData(requestHeader.getTopic()); if (!ExpressionType.isTagType(subscriptionData.getExpressionType())) &#123; consumerFilterData = this.brokerController.getConsumerFilterManager().get(requestHeader.getTopic(), requestHeader.getConsumerGroup()); &#125; &#125; //在Broker端构建消息过滤器 MessageFilter messageFilter; if (this.brokerController.getBrokerConfig().isFilterSupportRetry()) &#123; messageFilter = new ExpressionForRetryMessageFilter(subscriptionData, consumerFilterData, this.brokerController.getConsumerFilterManager()); &#125; else &#123; messageFilter = new ExpressionMessageFilter(subscriptionData, consumerFilterData, this.brokerController.getConsumerFilterManager()); &#125; // 获取消息 final GetMessageResult getMessageResult = this.brokerController.getMessageStore().getMessage(requestHeader.getConsumerGroup(), requestHeader.getTopic(), requestHeader.getQueueId(), requestHeader.getQueueOffset(), requestHeader.getMaxMsgNums(), messageFilter); if (getMessageResult != null) &#123; response.setRemark(getMessageResult.getStatus().name()); responseHeader.setNextBeginOffset(getMessageResult.getNextBeginOffset()); responseHeader.setMinOffset(getMessageResult.getMinOffset()); responseHeader.setMaxOffset(getMessageResult.getMaxOffset()); if (getMessageResult.isSuggestPullingFromSlave()) &#123; responseHeader.setSuggestWhichBrokerId(subscriptionGroupConfig.getWhichBrokerWhenConsumeSlowly()); &#125; else &#123; responseHeader.setSuggestWhichBrokerId(MixAll.MASTER_ID); &#125; //消息拉取结果 switch (getMessageResult.getStatus()) &#123; case FOUND: response.setCode(ResponseCode.SUCCESS); break; case MESSAGE_WAS_REMOVING: response.setCode(ResponseCode.PULL_RETRY_IMMEDIATELY); break; case NO_MATCHED_LOGIC_QUEUE: case NO_MESSAGE_IN_QUEUE: break; case NO_MATCHED_MESSAGE: response.setCode(ResponseCode.PULL_RETRY_IMMEDIATELY); break; case OFFSET_FOUND_NULL: response.setCode(ResponseCode.PULL_NOT_FOUND); break; case OFFSET_OVERFLOW_BADLY: response.setCode(ResponseCode.PULL_OFFSET_MOVED); break; case OFFSET_OVERFLOW_ONE: response.setCode(ResponseCode.PULL_NOT_FOUND); break; case OFFSET_TOO_SMALL: response.setCode(ResponseCode.PULL_OFFSET_MOVED); break; default: assert false; break; &#125; switch (response.getCode()) &#123; case ResponseCode.SUCCESS: this.brokerController.getBrokerStatsManager().incGroupGetNums(requestHeader.getConsumerGroup(), requestHeader.getTopic(), getMessageResult.getMessageCount()); this.brokerController.getBrokerStatsManager().incGroupGetSize(requestHeader.getConsumerGroup(), requestHeader.getTopic(), getMessageResult.getBufferTotalSize()); this.brokerController.getBrokerStatsManager().incBrokerGetNums(getMessageResult.getMessageCount()); break; case ResponseCode.PULL_NOT_FOUND: if (brokerAllowSuspend &amp;&amp; hasSuspendFlag) &#123; long pollingTimeMills = suspendTimeoutMillisLong; if (!this.brokerController.getBrokerConfig().isLongPollingEnable()) &#123;// 消息长轮询 pollingTimeMills = this.brokerController.getBrokerConfig().getShortPollingTimeMills(); &#125; String topic = requestHeader.getTopic(); long offset = requestHeader.getQueueOffset(); int queueId = requestHeader.getQueueId(); //没有拉取到消息,就再创建一个拉取请求 PullRequest pullRequest = new PullRequest(request, channel, pollingTimeMills, this.brokerController.getMessageStore().now(), offset, subscriptionData, messageFilter); //将请求放入ManyRequestPull请求队列,为了配合长连接处理 this.brokerController.getPullRequestHoldService().suspendPullRequest(topic, queueId, pullRequest); response = null; break; &#125; &#125; &#125; boolean storeOffsetEnable = brokerAllowSuspend; storeOffsetEnable = storeOffsetEnable &amp;&amp; hasCommitOffsetFlag; storeOffsetEnable = storeOffsetEnable &amp;&amp; this.brokerController.getMessageStoreConfig().getBrokerRole() != BrokerRole.SLAVE; if (storeOffsetEnable) &#123; this.brokerController.getConsumerOffsetManager().commitOffset(RemotingHelper.parseChannelRemoteAddr(channel), requestHeader.getConsumerGroup(), requestHeader.getTopic(), requestHeader.getQueueId(), requestHeader.getCommitOffset()); &#125; return response;&#125; 长轮询对于消息的发送基本能达到实时的效果,是通过 PullRequestHoldService 类中长轮训来实现的,该类是一个线程类,在 Broker 中的 BrokerController 中被实例化和启动.客户端拉取数时未拉取到数据就会将请求通过 suspendPullRequest 方法放入 pullRequestTable 中.在run方法中一直循环若没有消息就 waitForRunning 方法等待 5s ,若有数据则会被提前唤醒.然后通过 checkHoldRequest 方法检查请求对象,若有数据则将数据返回给客户端. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117public class PullRequestHoldService extends ServiceThread &#123; private ConcurrentMap&lt;String, ManyPullRequest&gt; pullRequestTable = new ConcurrentHashMap&lt;String, ManyPullRequest&gt;(1024); public void suspendPullRequest(final String topic, final int queueId, final PullRequest pullRequest) &#123; String key = this.buildKey(topic, queueId); ManyPullRequest mpr = this.pullRequestTable.get(key); if (null == mpr) &#123; mpr = new ManyPullRequest(); ManyPullRequest prev = this.pullRequestTable.putIfAbsent(key, mpr); if (prev != null) &#123; mpr = prev; &#125; &#125; mpr.addPullRequest(pullRequest); &#125; public void run() &#123; // 处理ManyPullRequest线程 while (!this.isStopped()) &#123; try &#123;// 如果开启了长轮询,等待5秒后再去查 if (this.brokerController.getBrokerConfig().isLongPollingEnable()) &#123; this.waitForRunning(5 * 1000); &#125; else &#123;//没有开启长轮询,等待1秒后再去查. this.waitForRunning(this.brokerController.getBrokerConfig().getShortPollingTimeMills()); &#125; long beginLockTimestamp = this.systemClock.now(); this.checkHoldRequest(); //检查请求对象 long costTime = this.systemClock.now() - beginLockTimestamp; &#125; catch (Throwable e) &#123; &#125; &#125; &#125; private void checkHoldRequest() &#123; for (String key : this.pullRequestTable.keySet()) &#123; String[] kArray = key.split(TOPIC_QUEUEID_SEPARATOR); if (2 == kArray.length) &#123; String topic = kArray[0]; int queueId = Integer.parseInt(kArray[1]); //从CommitLog中检查是否有新的消息. final long offset = this.brokerController.getMessageStore().getMaxOffsetInQueue(topic, queueId); try &#123;//通知消息到达 this.notifyMessageArriving(topic, queueId, offset); &#125; catch (Throwable e) &#123; &#125; &#125; &#125; &#125; public void notifyMessageArriving(final String topic, final int queueId, final long maxOffset) &#123; notifyMessageArriving(topic, queueId, maxOffset, null, 0, null, null); &#125; public void notifyMessageArriving(final String topic, final int queueId, final long maxOffset, final Long tagsCode, long msgStoreTime, byte[] filterBitMap, Map&lt;String, String&gt; properties) &#123; String key = this.buildKey(topic, queueId); //CommitLog消息到达通知 ManyPullRequest mpr = this.pullRequestTable.get(key); if (mpr != null) &#123; List&lt;PullRequest&gt; requestList = mpr.cloneListAndClear(); if (requestList != null) &#123; List&lt;PullRequest&gt; replayList = new ArrayList&lt;PullRequest&gt;(); for (PullRequest request : requestList) &#123; long newestOffset = maxOffset; if (newestOffset &lt;= request.getPullFromThisOffset()) &#123; newestOffset = this.brokerController.getMessageStore().getMaxOffsetInQueue(topic, queueId); &#125; if (newestOffset &gt; request.getPullFromThisOffset()) &#123; //判断是否有新的消息 //检查新的消息是否是ConsumeQueue感兴趣的消息 boolean match = request.getMessageFilter().isMatchedByConsumeQueue(tagsCode, new ConsumeQueueExt.CqExtUnit(tagsCode, msgStoreTime, filterBitMap)); if (match &amp;&amp; properties != null) &#123; match = request.getMessageFilter().isMatchedByCommitLog(null, properties); &#125; if (match) &#123; //如果是感兴趣的消息,就等待线程唤醒后执行消息推送. try &#123; this.brokerController.getPullMessageProcessor().executeRequestWhenWakeup(request.getClientChannel(), request.getRequestCommand()); &#125; catch (Throwable e) &#123; &#125; continue; &#125; &#125; if (System.currentTimeMillis() &gt;= (request.getSuspendTimestamp() + request.getTimeoutMillis())) &#123; try &#123; //请求超时后也给客户端响应. this.brokerController.getPullMessageProcessor().executeRequestWhenWakeup(request.getClientChannel(), request.getRequestCommand()); &#125; catch (Throwable e) &#123; &#125; continue; &#125; replayList.add(request); &#125; if (!replayList.isEmpty()) &#123; mpr.addPullRequest(replayList); &#125; &#125; &#125; &#125;&#125;public class PullMessageProcessor extends AsyncNettyRequestProcessor implements NettyRequestProcessor &#123; public void executeRequestWhenWakeup(final Channel channel, final RemotingCommand request) throws RemotingCommandException &#123; Runnable run = new Runnable() &#123; @Override public void run() &#123; try &#123; final RemotingCommand response = PullMessageProcessor.this.processRequest(channel, request, false); if (response != null) &#123; response.setOpaque(request.getOpaque()); response.markResponseType(); try &#123; channel.writeAndFlush(response).addListener(new ChannelFutureListener() &#123; @Override public void operationComplete(ChannelFuture future) throws Exception &#123; if (!future.isSuccess()) &#123; &#125; &#125; &#125;); &#125; catch (Throwable e) &#123; &#125; &#125; &#125; catch (RemotingCommandException e1) &#123; &#125; &#125; &#125;; this.brokerController.getPullMessageExecutor().submit(new RequestTask(run, channel, request)); &#125;&#125; 还有一种方式在 DefaultMessageStore 的 ReputMessageService 线程类的 run 方法中执行分发请求时,执行完分发请求后通过调用 NotifyMessageArrivingListener 的 arriving 方法从而调用 PullRequestHoldService 的 notifyMessageArriving 方法进行一起请求线程的检查从而通知到客户端. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667class ReputMessageService extends ServiceThread &#123; @Override public void run() &#123; while (!this.isStopped()) &#123; try &#123; // 每隔1毫秒,往ConsumeQueue和IndexFile中转发一次CommitLog写入的消息 Thread.sleep(1); this.doReput(); &#125; catch (Exception e) &#123; &#125; &#125; &#125; private void doReput() &#123; if (this.reputFromOffset &lt; DefaultMessageStore.this.commitLog.getMinOffset()) &#123; log.warn(&quot;The reputFromOffset=&#123;&#125; is smaller than minPyOffset=&#123;&#125;, this usually indicate that the dispatch behind too much and the commitlog has expired.&quot;, this.reputFromOffset, DefaultMessageStore.this.commitLog.getMinOffset()); this.reputFromOffset = DefaultMessageStore.this.commitLog.getMinOffset(); &#125; for (boolean doNext = true; this.isCommitLogAvailable() &amp;&amp; doNext; ) &#123; if (DefaultMessageStore.this.getMessageStoreConfig().isDuplicationEnable() &amp;&amp; this.reputFromOffset &gt;= DefaultMessageStore.this.getConfirmOffset()) &#123; break; &#125; SelectMappedBufferResult result = DefaultMessageStore.this.commitLog.getData(reputFromOffset); // 获取CommitLog中的消息 if (result != null) &#123; try &#123; this.reputFromOffset = result.getStartOffset(); for (int readSize = 0; readSize &lt; result.getSize() &amp;&amp; doNext; ) &#123; //从CommitLog中获取一个DispatchRequest,拿到一份需要进行转发的消息,也就是从commitlog中读取的. DispatchRequest dispatchRequest = DefaultMessageStore.this.commitLog.checkMessageAndReturnSize(result.getByteBuffer(), false, false); int size = dispatchRequest.getBufferSize() == -1 ? dispatchRequest.getMsgSize() : dispatchRequest.getBufferSize(); if (dispatchRequest.isSuccess()) &#123; if (size &gt; 0) &#123; DefaultMessageStore.this.doDispatch(dispatchRequest); //分发CommitLog写入消息 // 长轮询： 如果有消息到了主节点,并且开启了长轮询. if (BrokerRole.SLAVE != DefaultMessageStore.this.getMessageStoreConfig().getBrokerRole() &amp;&amp; DefaultMessageStore.this.brokerConfig.isLongPollingEnable()) &#123; //唤醒NotifyMessageArrivingListener的arriving方法,进行一次请求线程的检查 DefaultMessageStore.this.messageArrivingListener.arriving(dispatchRequest.getTopic(), dispatchRequest.getQueueId(), dispatchRequest.getConsumeQueueOffset() + 1, dispatchRequest.getTagsCode(), dispatchRequest.getStoreTimestamp(), dispatchRequest.getBitMap(), dispatchRequest.getPropertiesMap()); &#125; this.reputFromOffset += size; readSize += size; if (DefaultMessageStore.this.getMessageStoreConfig().getBrokerRole() == BrokerRole.SLAVE) &#123; // 从节点 DefaultMessageStore.this.storeStatsService.getSinglePutMessageTopicTimesTotal(dispatchRequest.getTopic()).incrementAndGet(); DefaultMessageStore.this.storeStatsService.getSinglePutMessageTopicSizeTotal(dispatchRequest.getTopic()).addAndGet(dispatchRequest.getMsgSize()); &#125; &#125; else if (size == 0) &#123; this.reputFromOffset = DefaultMessageStore.this.commitLog.rollNextFile(this.reputFromOffset); readSize = result.getSize(); &#125; &#125; else if (!dispatchRequest.isSuccess()) &#123; if (size &gt; 0) &#123; this.reputFromOffset += size; &#125; else &#123; doNext = false; if (DefaultMessageStore.this.getMessageStoreConfig().isEnableDLegerCommitLog() || DefaultMessageStore.this.brokerConfig.getBrokerId() == MixAll.MASTER_ID) &#123; this.reputFromOffset += result.getSize() - readSize; &#125; &#125; &#125; &#125; &#125; finally &#123; result.release(); &#125; &#125; else &#123; doNext = false; &#125; &#125; &#125;&#125; 集群模式下消费者策略Consumer也是以 MessageQueue 为单位来进行负载均衡,分为集群模式和广播模式.广播模式下每条消息都会投递给订阅了Topic的所有消费者实例,在Consumer分配Queue时,所有Consumer都分到所有的Queue.集群消费模式每条消息只需要投递到订阅该Topic的Consumer Group下的一个实例,RocketMQ采用主动拉取方式拉取并消费消息,在拉取时需明确指定拉取哪一条MessageQueue . 每当实例的数量有变更,都会触发一次所有实例的负载均衡,这时会按照 Queue的数量和实例的数量平均分配Queue给每个实例.每次分配时都会将 MessageQueue 和消费者ID进行排序,再用不同的分配算法进行分配.内置的分配的算法共有六种,分别对应 AllocateMessageQueueStrategy下的六种实现类,可在Consumer中直接指定.默认情况下使用的是最简单的平均分配策略. AllocateMachineRoomNearby ：将同机房的Consumer和Broker优先分配在一起.该策略可通过一个 machineRoomResolver 对象来定制Consumer和Broker的机房解析规则.还需要引入另外一个分配策略来对同机房的Broker和Consumer进行分配.一般用平均分配策略或轮询分配策略. AllocateMessageQueueAveragely ：平均分配,将所有MessageQueue平均分给每一个消费者 AllocateMessageQueueAveragelyByCircle ： 轮询分配,轮流的给一个消费者分配一个MessageQueue. AllocateMessageQueueByConfig ： 直接指定一个messageQueue列表,类似于广播模式,直接指定所有队列. AllocateMessageQueueByMachineRoom ：按逻辑机房的概念进行分配.对BrokerName和ConsumerIdc有定制化的配置. AllocateMessageQueueConsistentHash ：一致性哈希策略只需要指定一个虚拟节点数,用一个哈希环算法,虚拟节点是为了让Hash数据在环上分布更为均匀. 对于消费者策略可以通过 DefaultMQPushConsumer 构造方法设置,默认是使用 AllocateMessageQueueAveragely平均分配策略.且该负载均衡策略在 RebalanceImpl 的 rebalanceByTopic 方法中被调用. 123456789101112131415161718192021222324252627public class AllocateMessageQueueAveragely implements AllocateMessageQueueStrategy &#123; public List&lt;MessageQueue&gt; allocate(String consumerGroup, String currentCID, List&lt;MessageQueue&gt; mqAll, List&lt;String&gt; cidAll) &#123; if (currentCID == null || currentCID.length() &lt; 1) &#123; throw new IllegalArgumentException(&quot;currentCID is empty&quot;); &#125; if (mqAll == null || mqAll.isEmpty()) &#123; throw new IllegalArgumentException(&quot;mqAll is null or mqAll empty&quot;); &#125; if (cidAll == null || cidAll.isEmpty()) &#123; throw new IllegalArgumentException(&quot;cidAll is null or cidAll empty&quot;); &#125; List&lt;MessageQueue&gt; result = new ArrayList&lt;MessageQueue&gt;(); if (!cidAll.contains(currentCID)) &#123; log.info(&quot;[BUG] ConsumerGroup: &#123;&#125; The consumerId: &#123;&#125; not in cidAll: &#123;&#125;&quot;, consumerGroup, currentCID, cidAll); return result; &#125; int index = cidAll.indexOf(currentCID); int mod = mqAll.size() % cidAll.size(); int averageSize = mqAll.size() &lt;= cidAll.size() ? 1 : (mod &gt; 0 &amp;&amp; index &lt; mod ? mqAll.size() / cidAll.size() + 1 : mqAll.size() / cidAll.size()); int startIndex = (mod &gt; 0 &amp;&amp; index &lt; mod) ? index * averageSize : index * averageSize + mod; int range = Math.min(averageSize, mqAll.size() - startIndex); for (int i = 0; i &lt; range; i++) &#123; result.add(mqAll.get((startIndex + i) % mqAll.size())); &#125; return result; &#125;&#125; 顺序消息12345678910111213141516171819DefaultMQProducer producer = new DefaultMQProducer(&quot;please_rename_unique_group_name&quot;);producer.setNamesrvAddr(&quot;localhost:9876&quot;);producer.start();for (int i = 0; i &lt; 10; i++) &#123; int orderId = i; for (int j = 0; j &lt;= 5; j++) &#123; Message msg = new Message(&quot;OrderTopicTest&quot;, &quot;order_&quot; + orderId, &quot;KEY&quot; + orderId, (&quot;order_&quot; + orderId + &quot; step &quot; + j).getBytes(RemotingHelper.DEFAULT_CHARSET)); SendResult sendResult = producer.send(msg, new MessageQueueSelector() &#123; @Override public MessageQueue select(List&lt;MessageQueue&gt; mqs, Message msg, Object arg) &#123; Integer id = (Integer) arg; // 实际就是传入的orderId int index = id % mqs.size(); return mqs.get(index); &#125; &#125;, orderId); System.out.printf(&quot;%s%n&quot;, sendResult); &#125;&#125;producer.shutdown(); 顺序消息,对于生产者发送消息需要将消息发送到同一个 MessageQueue 中,可通过 MessageQueueSelector ,对于需要保持顺序的消息传入同一个业务参数orderId,通过orderId对消息队列的取模得到一个固定的 MessageQueue ,在发送消息时就能将数据发送到同一个消息队列中了.但不能100%保证消息的顺序,若发生宕机可能导致发送到不同的 MessageQueue 中. 12345678910111213141516171819202122232425262728293031323334353637public class DefaultMQProducer extends ClientConfig implements MQProducer &#123; public SendResult send(Message msg, MessageQueueSelector selector, Object arg) throws MQClientException, RemotingException, MQBrokerException, InterruptedException &#123; msg.setTopic(withNamespace(msg.getTopic())); return this.defaultMQProducerImpl.send(msg, selector, arg); &#125; private SendResult sendSelectImpl(Message msg, MessageQueueSelector selector, Object arg, final CommunicationMode communicationMode, final SendCallback sendCallback, final long timeout) throws MQClientException, RemotingException, MQBrokerException, InterruptedException &#123; long beginStartTime = System.currentTimeMillis(); this.makeSureStateOK(); Validators.checkMessage(msg, this.defaultMQProducer); TopicPublishInfo topicPublishInfo = this.tryToFindTopicPublishInfo(msg.getTopic()); if (topicPublishInfo != null &amp;&amp; topicPublishInfo.ok()) &#123; MessageQueue mq = null; try &#123; List&lt;MessageQueue&gt; messageQueueList = mQClientFactory.getMQAdminImpl().parsePublishMessageQueues(topicPublishInfo.getMessageQueueList()); Message userMessage = MessageAccessor.cloneMessage(msg); String userTopic = NamespaceUtil.withoutNamespace(userMessage.getTopic(), mQClientFactory.getClientConfig().getNamespace()); userMessage.setTopic(userTopic); // 这里回调上面示例中MessageQueueSelector的select方法,这里的arg就是传入的orderId mq = mQClientFactory.getClientConfig().queueWithNamespace(selector.select(messageQueueList, userMessage, arg)); &#125; catch (Throwable e) &#123; throw new MQClientException(&quot;select message queue throwed exception.&quot;, e); &#125; long costTime = System.currentTimeMillis() - beginStartTime; if (timeout &lt; costTime) &#123; throw new RemotingTooMuchRequestException(&quot;sendSelectImpl call timeout&quot;); &#125; if (mq != null) &#123; return this.sendKernelImpl(msg, mq, communicationMode, sendCallback, null, timeout - costTime); &#125; else &#123; throw new MQClientException(&quot;select message queue return null.&quot;, null); &#125; &#125; validateNameServerSetting(); throw new MQClientException(&quot;No route info for this topic, &quot; + msg.getTopic(), null); &#125;&#125; 对于每个消费端在创建 DefaultMQPushConsumer 时指定 consumerGroup ,在 DefaultMQPushConsumer 的start方法中调用 DefaultMQPushConsumerImpl 的 start 方法从而将 consumerGroup 设置到 RebalancePushImpl 中.且通过 registerMessageListener 方法设置的 MessageListenerOrderly 会被赋值给 DefaultMQPushConsumerImpl 的 messageListenerInner ,在DefaultMQPushConsumerImpl的start方法中判断messageListenerInner类型最终调用 ConsumeMessageOrderlyService 的 start 方法启动异步线程. 1234567891011121314DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;please_rename_unique_group_name_3&quot;);consumer.setNamesrvAddr(&quot;localhost:9876&quot;);consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_LAST_OFFSET);consumer.subscribe(&quot;OrderTopicTest&quot;, &quot;*&quot;);consumer.registerMessageListener(new MessageListenerOrderly() &#123; @Override public ConsumeOrderlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeOrderlyContext context) &#123; context.setAutoCommit(true); for (MessageExt msg : msgs) &#123; System.out.println(&quot;收到消息内容 &quot; + new String(msg.getBody())); &#125; return ConsumeOrderlyStatus.SUCCESS; &#125;&#125;); 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100public class DefaultMQPushConsumer extends ClientConfig implements MQPushConsumer &#123; private String consumerGroup; public DefaultMQPushConsumer(final String consumerGroup) &#123; this(null, consumerGroup, null, new AllocateMessageQueueAveragely()); &#125; public DefaultMQPushConsumer(final String namespace, final String consumerGroup, RPCHook rpcHook, AllocateMessageQueueStrategy allocateMessageQueueStrategy) &#123; this.consumerGroup = consumerGroup; this.namespace = namespace; this.allocateMessageQueueStrategy = allocateMessageQueueStrategy; defaultMQPushConsumerImpl = new DefaultMQPushConsumerImpl(this, rpcHook); &#125; public void registerMessageListener(MessageListenerOrderly messageListener) &#123; this.messageListener = messageListener; this.defaultMQPushConsumerImpl.registerMessageListener(messageListener); &#125; public void start() throws MQClientException &#123; setConsumerGroup(NamespaceUtil.wrapNamespace(this.getNamespace(), this.consumerGroup)); this.defaultMQPushConsumerImpl.start(); if (null != traceDispatcher) &#123; try &#123; traceDispatcher.start(this.getNamesrvAddr(), this.getAccessChannel()); &#125; catch (MQClientException e) &#123; &#125; &#125; &#125;&#125;public class DefaultMQPushConsumerImpl implements MQConsumerInner &#123; public void registerMessageListener(MessageListener messageListener) &#123; this.messageListenerInner = messageListener; &#125; public MessageListener getMessageListenerInner() &#123; return messageListenerInner; &#125; public synchronized void start() throws MQClientException &#123; switch (this.serviceState) &#123; case CREATE_JUST: this.serviceState = ServiceState.START_FAILED; this.checkConfig(); // 检查配置 this.copySubscription(); if (this.defaultMQPushConsumer.getMessageModel() == MessageModel.CLUSTERING) &#123; this.defaultMQPushConsumer.changeInstanceNameToPID(); &#125; //K2 客户端创建工厂,这个是核心对象 this.mQClientFactory = MQClientManager.getInstance().getOrCreateMQClientInstance(this.defaultMQPushConsumer, this.rpcHook); this.rebalanceImpl.setConsumerGroup(this.defaultMQPushConsumer.getConsumerGroup()); this.rebalanceImpl.setMessageModel(this.defaultMQPushConsumer.getMessageModel()); // 集群模式下消费者策略 this.rebalanceImpl.setAllocateMessageQueueStrategy(this.defaultMQPushConsumer.getAllocateMessageQueueStrategy()); this.rebalanceImpl.setmQClientFactory(this.mQClientFactory); this.pullAPIWrapper = new PullAPIWrapper(mQClientFactory, this.defaultMQPushConsumer.getConsumerGroup(), isUnitMode()); this.pullAPIWrapper.registerFilterMessageHook(filterMessageHookList); if (this.defaultMQPushConsumer.getOffsetStore() != null) &#123; this.offsetStore = this.defaultMQPushConsumer.getOffsetStore(); &#125; else &#123; switch (this.defaultMQPushConsumer.getMessageModel()) &#123; case BROADCASTING: this.offsetStore = new LocalFileOffsetStore(this.mQClientFactory, this.defaultMQPushConsumer.getConsumerGroup()); break; case CLUSTERING: this.offsetStore = new RemoteBrokerOffsetStore(this.mQClientFactory, this.defaultMQPushConsumer.getConsumerGroup()); break; default: break; &#125; this.defaultMQPushConsumer.setOffsetStore(this.offsetStore); &#125; this.offsetStore.load(); //根据客户端配置实例化不同的consumeMessageService if (this.getMessageListenerInner() instanceof MessageListenerOrderly) &#123; // 顺序消息 this.consumeOrderly = true; this.consumeMessageService = new ConsumeMessageOrderlyService(this, (MessageListenerOrderly) this.getMessageListenerInner()); &#125; else if (this.getMessageListenerInner() instanceof MessageListenerConcurrently) &#123; // 非顺序消息 this.consumeOrderly = false; this.consumeMessageService = new ConsumeMessageConcurrentlyService(this, (MessageListenerConcurrently) this.getMessageListenerInner()); &#125; this.consumeMessageService.start(); //注册本地的消费者组缓存. boolean registerOK = mQClientFactory.registerConsumer(this.defaultMQPushConsumer.getConsumerGroup(), this); if (!registerOK) &#123; this.serviceState = ServiceState.CREATE_JUST; this.consumeMessageService.shutdown(defaultMQPushConsumer.getAwaitTerminationMillisWhenShutdown()); throw new MQClientException(&quot;The consumer group[&quot; + this.defaultMQPushConsumer.getConsumerGroup() + &quot;] has been created before, specify another name please.&quot; + FAQUrl.suggestTodo(FAQUrl.GROUP_NAME_DUPLICATE_URL), null); &#125; mQClientFactory.start(); this.serviceState = ServiceState.RUNNING; break; case RUNNING: case START_FAILED: case SHUTDOWN_ALREADY: throw new MQClientException(&quot;The PushConsumer service state not OK, maybe started once, &quot; + this.serviceState + FAQUrl.suggestTodo(FAQUrl.CLIENT_SERVICE_NOT_OK), null); default: break; &#125; this.updateTopicSubscribeInfoWhenSubscriptionChanged(); this.mQClientFactory.checkClientInBroker(); this.mQClientFactory.sendHeartbeatToAllBrokerWithLock(); this.mQClientFactory.rebalanceImmediately(); &#125;&#125; ConsumeMessageOrderlyService 线程会每隔 20s 执行一次,最终调用 RebalancePushImpl 超类 RebalanceImpl 的 lock 方法,通过 LockBatchRequestBody 设置前面设置到 RebalancePushImpl 中的 consumerGroup ,向Broker获取队列锁,且将锁定的队列缓存到 processQueueTable 中. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203public class ConsumeMessageOrderlyService implements ConsumeMessageService &#123; public void start() &#123; if (MessageModel.CLUSTERING.equals(ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.messageModel())) &#123; this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() &#123; @Override public void run() &#123; // 每20s执行一次 ConsumeMessageOrderlyService.this.lockMQPeriodically(); &#125; &#125;, 1000 * 1, ProcessQueue.REBALANCE_LOCK_INTERVAL, TimeUnit.MILLISECONDS); &#125; &#125; public synchronized void lockMQPeriodically() &#123; if (!this.stopped) &#123; this.defaultMQPushConsumerImpl.getRebalanceImpl().lockAll(); &#125; &#125;&#125;public abstract class RebalanceImpl &#123; private boolean updateProcessQueueTableInRebalance(final String topic, final Set&lt;MessageQueue&gt; mqSet, final boolean isOrder) &#123; boolean changed = false; Iterator&lt;Entry&lt;MessageQueue, ProcessQueue&gt;&gt; it = this.processQueueTable.entrySet().iterator(); while (it.hasNext()) &#123; Entry&lt;MessageQueue, ProcessQueue&gt; next = it.next(); MessageQueue mq = next.getKey(); ProcessQueue pq = next.getValue(); if (mq.getTopic().equals(topic)) &#123; if (!mqSet.contains(mq)) &#123; pq.setDropped(true); if (this.removeUnnecessaryMessageQueue(mq, pq)) &#123; it.remove(); changed = true; &#125; &#125; else if (pq.isPullExpired()) &#123; switch (this.consumeType()) &#123; case CONSUME_ACTIVELY: break; case CONSUME_PASSIVELY: pq.setDropped(true); if (this.removeUnnecessaryMessageQueue(mq, pq)) &#123; it.remove(); changed = true; &#125; break; default: break; &#125; &#125; &#125; &#125; List&lt;PullRequest&gt; pullRequestList = new ArrayList&lt;PullRequest&gt;(); for (MessageQueue mq : mqSet) &#123; if (!this.processQueueTable.containsKey(mq)) &#123; if (isOrder &amp;&amp; !this.lock(mq)) &#123; continue; &#125; this.removeDirtyOffset(mq); ProcessQueue pq = new ProcessQueue(); long nextOffset = this.computePullFromWhere(mq); if (nextOffset &gt;= 0) &#123; ProcessQueue pre = this.processQueueTable.putIfAbsent(mq, pq); if (pre != null) &#123; &#125; else &#123; PullRequest pullRequest = new PullRequest(); pullRequest.setConsumerGroup(consumerGroup); pullRequest.setNextOffset(nextOffset); pullRequest.setMessageQueue(mq); pullRequest.setProcessQueue(pq); pullRequestList.add(pullRequest); changed = true; &#125; &#125; &#125; &#125; this.dispatchPullRequest(pullRequestList); return changed; &#125; public boolean lock(final MessageQueue mq) &#123; FindBrokerResult findBrokerResult = this.mQClientFactory.findBrokerAddressInSubscribe(mq.getBrokerName(), MixAll.MASTER_ID, true); if (findBrokerResult != null) &#123; LockBatchRequestBody requestBody = new LockBatchRequestBody(); requestBody.setConsumerGroup(this.consumerGroup); requestBody.setClientId(this.mQClientFactory.getClientId()); requestBody.getMqSet().add(mq); try &#123; Set&lt;MessageQueue&gt; lockedMq = this.mQClientFactory.getMQClientAPIImpl().lockBatchMQ(findBrokerResult.getBrokerAddr(), requestBody, 1000); for (MessageQueue mmqq : lockedMq) &#123; ProcessQueue processQueue = this.processQueueTable.get(mmqq); if (processQueue != null) &#123; processQueue.setLocked(true); processQueue.setLastLockTimestamp(System.currentTimeMillis()); &#125; &#125; boolean lockOK = lockedMq.contains(mq); return lockOK; &#125; catch (Exception e) &#123; &#125; &#125; return false; &#125;&#125;public class ConsumeMessageOrderlyService implements ConsumeMessageService &#123; class ConsumeRequest implements Runnable &#123; private final ProcessQueue processQueue; private final MessageQueue messageQueue; @Override public void run() &#123; // 每一个ConsumeRequest消费任务不是以消费消息条数来计算,而是根据消费时间,默认当消费时长大于MAX_TIME_CONSUME_CONTINUOUSLY,默认60s后,本次消费任务结束,由消费组内其他线程继续消费 if (this.processQueue.isDropped()) &#123; return; &#125; final Object objLock = messageQueueLock.fetchLockObject(this.messageQueue); synchronized (objLock) &#123; // 通过加锁,将并发的消息顺序进行消费.消息处理的方式没什么特别. // 广播模式直接进入消费,无需锁定处理对列因为相互直接无竞争,集群模式proceessQueue被锁定并且锁未超时 if (MessageModel.BROADCASTING.equals(ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.messageModel()) || (this.processQueue.isLocked() &amp;&amp; !this.processQueue.isLockExpired())) &#123; final long beginTime = System.currentTimeMillis(); for (boolean continueConsume = true; continueConsume; ) &#123; if (this.processQueue.isDropped()) &#123; break; &#125; if (MessageModel.CLUSTERING.equals(ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.messageModel()) &amp;&amp; !this.processQueue.isLocked()) &#123; ConsumeMessageOrderlyService.this.tryLockLaterAndReconsume(this.messageQueue, this.processQueue, 10); break; &#125; if (MessageModel.CLUSTERING.equals(ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.messageModel()) &amp;&amp; this.processQueue.isLockExpired()) &#123; ConsumeMessageOrderlyService.this.tryLockLaterAndReconsume(this.messageQueue, this.processQueue, 10); break; &#125; long interval = System.currentTimeMillis() - beginTime; if (interval &gt; MAX_TIME_CONSUME_CONTINUOUSLY) &#123; ConsumeMessageOrderlyService.this.submitConsumeRequestLater(processQueue, messageQueue, 10); break; &#125; final int consumeBatchSize = ConsumeMessageOrderlyService.this.defaultMQPushConsumer.getConsumeMessageBatchMaxSize(); List&lt;MessageExt&gt; msgs = this.processQueue.takeMessages(consumeBatchSize); defaultMQPushConsumerImpl.resetRetryAndNamespace(msgs, defaultMQPushConsumer.getConsumerGroup()); if (!msgs.isEmpty()) &#123; final ConsumeOrderlyContext context = new ConsumeOrderlyContext(this.messageQueue); ConsumeOrderlyStatus status = null; ConsumeMessageContext consumeMessageContext = null; if (ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.hasHook()) &#123; consumeMessageContext = new ConsumeMessageContext(); consumeMessageContext.setConsumerGroup(ConsumeMessageOrderlyService.this.defaultMQPushConsumer.getConsumerGroup()); consumeMessageContext.setNamespace(defaultMQPushConsumer.getNamespace()); consumeMessageContext.setMq(messageQueue); consumeMessageContext.setMsgList(msgs); consumeMessageContext.setSuccess(false); consumeMessageContext.setProps(new HashMap&lt;String, String&gt;()); // init the consume context type ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.executeHookBefore(consumeMessageContext); &#125; long beginTimestamp = System.currentTimeMillis(); ConsumeReturnType returnType = ConsumeReturnType.SUCCESS; boolean hasException = false; try &#123; this.processQueue.getLockConsume().lock(); if (this.processQueue.isDropped()) &#123; break; &#125; status = messageListener.consumeMessage(Collections.unmodifiableList(msgs), context); // 调用消费者具体的消费方法 &#125; catch (Throwable e) &#123; hasException = true; &#125; finally &#123; this.processQueue.getLockConsume().unlock(); &#125; long consumeRT = System.currentTimeMillis() - beginTimestamp; if (null == status) &#123; if (hasException) &#123; returnType = ConsumeReturnType.EXCEPTION; &#125; else &#123; returnType = ConsumeReturnType.RETURNNULL; &#125; &#125; else if (consumeRT &gt;= defaultMQPushConsumer.getConsumeTimeout() * 60 * 1000) &#123; returnType = ConsumeReturnType.TIME_OUT; &#125; else if (ConsumeOrderlyStatus.SUSPEND_CURRENT_QUEUE_A_MOMENT == status) &#123; returnType = ConsumeReturnType.FAILED; &#125; else if (ConsumeOrderlyStatus.SUCCESS == status) &#123; returnType = ConsumeReturnType.SUCCESS; &#125; if (ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.hasHook()) &#123; consumeMessageContext.getProps().put(MixAll.CONSUME_CONTEXT_TYPE, returnType.name()); &#125; if (null == status) &#123; status = ConsumeOrderlyStatus.SUSPEND_CURRENT_QUEUE_A_MOMENT; &#125; if (ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.hasHook()) &#123; consumeMessageContext.setStatus(status.toString()); consumeMessageContext.setSuccess(ConsumeOrderlyStatus.SUCCESS == status || ConsumeOrderlyStatus.COMMIT == status); ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.executeHookAfter(consumeMessageContext); &#125; ConsumeMessageOrderlyService.this.getConsumerStatsManager().incConsumeRT(ConsumeMessageOrderlyService.this.consumerGroup, messageQueue.getTopic(), consumeRT); continueConsume = ConsumeMessageOrderlyService.this.processConsumeResult(msgs, status, context, this); &#125; else &#123; continueConsume = false; &#125; &#125; &#125; else &#123; if (this.processQueue.isDropped()) &#123; return; &#125; ConsumeMessageOrderlyService.this.tryLockLaterAndReconsume(this.messageQueue, this.processQueue, 100); &#125; &#125; &#125; &#125;&#125;","tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"http://example.com/tags/RocketMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RocketMQ","slug":"工具和中间件/消息队列/RocketMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RocketMQ/"}]},{"title":"RocketMQ-生产者源码","date":"2019-04-23T03:08:20.000Z","path":"blog/工具和中间件/消息队列/RocketMQ/RocketMQ-生产者源码/","text":"普通消息不论同步请求还是异步请求最终都是调用 DefaultMQProducerImpl 的 sendDefaultImpl 方法,首先通过 tryToFindTopicPublishInfo 方法获取Topic信息,先从本地缓存找,若本地缓存没有则调用 MQClientAPIImpl 的 getTopicRouteInfoFromNameServer 方法通过 RequestCode.GET_ROUTEINFO_BY_TOPIC 关联调用NameServer的 DefaultRequestProcessor 的 getRouteInfoByTopic 方法获取Topic信息； Topic 信息在 Producter 启动时就注册到 NameServer 了,且每 30s 发送心跳也会发送 Topic 相关的信息. 然后通过 MQFaultStrategy 的 selectOneMessageQueue 获取具体的具体要将消息发送到哪一个队列中,Producer选择 MessageQueue 方法是消息数自增对队列数取模,可通过 sendLatencyFaultEnable 参数开启Broker故障延迟机制,发送消息失败后一定时间内不在往同一个Queue重复发送的机制,在 LatencyFaultToleranceImpl 中维护了曾经发送失败的Broker列表到faultItemTable 中. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189public class DefaultMQProducer extends ClientConfig implements MQProducer &#123; public SendResult send(Message msg) throws MQClientException, RemotingException, MQBrokerException, InterruptedException &#123; Validators.checkMessage(msg, this); msg.setTopic(withNamespace(msg.getTopic())); return this.defaultMQProducerImpl.send(msg); &#125; public void send(Message msg, SendCallback sendCallback) throws MQClientException, RemotingException, InterruptedException &#123; msg.setTopic(withNamespace(msg.getTopic())); this.defaultMQProducerImpl.send(msg, sendCallback); &#125;&#125;public class DefaultMQProducerImpl implements MQProducerInner &#123; public void send(final Message msg, final SendCallback sendCallback, final long timeout) throws MQClientException, RemotingException, InterruptedException &#123; final long beginStartTime = System.currentTimeMillis(); ExecutorService executor = this.getAsyncSenderExecutor(); try &#123; executor.submit(new Runnable() &#123; @Override public void run() &#123; long costTime = System.currentTimeMillis() - beginStartTime; if (timeout &gt; costTime) &#123; try &#123; sendDefaultImpl(msg, CommunicationMode.ASYNC, sendCallback, timeout - costTime); &#125; catch (Exception e) &#123; sendCallback.onException(e); // 调用回调方法 &#125; &#125; else &#123; // 调用回调方法 sendCallback.onException(new RemotingTooMuchRequestException(&quot;DEFAULT ASYNC send call timeout&quot;)); &#125; &#125; &#125;); &#125; catch (RejectedExecutionException e) &#123; throw new MQClientException(&quot;executor rejected &quot;, e); &#125; &#125; private SendResult sendDefaultImpl(Message msg, final CommunicationMode communicationMode, final SendCallback sendCallback, final long timeout) throws MQClientException, RemotingException, MQBrokerException, InterruptedException &#123; this.makeSureStateOK(); Validators.checkMessage(msg, this.defaultMQProducer); final long invokeID = random.nextLong(); long beginTimestampFirst = System.currentTimeMillis(); long beginTimestampPrev = beginTimestampFirst; long endTimestamp = beginTimestampFirst; // 生产者获取Topic的公开信息 TopicPublishInfo topicPublishInfo = this.tryToFindTopicPublishInfo(msg.getTopic()); if (topicPublishInfo != null &amp;&amp; topicPublishInfo.ok()) &#123; boolean callTimeout = false; MessageQueue mq = null; Exception exception = null; SendResult sendResult = null; int timesTotal = communicationMode == CommunicationMode.SYNC ? 1 + this.defaultMQProducer.getRetryTimesWhenSendFailed() : 1; int times = 0; String[] brokersSent = new String[timesTotal]; for (; times &lt; timesTotal; times++) &#123; // 重试次数,异步默认重试2次共3次,同步不重试共1次 String lastBrokerName = null == mq ? null : mq.getBrokerName(); // Producer计算把消息发到哪个MessageQueue中,自增然后取模 MessageQueue mqSelected = this.selectOneMessageQueue(topicPublishInfo, lastBrokerName); if (mqSelected != null) &#123; mq = mqSelected; brokersSent[times] = mq.getBrokerName(); // 根据MessageQueue去获取目标节点的信息. try &#123; beginTimestampPrev = System.currentTimeMillis(); if (times &gt; 0) &#123; // 重新发送期间使用命名空间重置主题 msg.setTopic(this.defaultMQProducer.withNamespace(msg.getTopic())); &#125; long costTime = beginTimestampPrev - beginTimestampFirst; if (timeout &lt; costTime) &#123; // 判断是否超时,默认3s callTimeout = true; break; // 若超时 &#125; // 实际发送消息的方法 sendResult = this.sendKernelImpl(msg, mq, communicationMode, sendCallback, topicPublishInfo, timeout - costTime); endTimestamp = System.currentTimeMillis(); this.updateFaultItem(mq.getBrokerName(), endTimestamp - beginTimestampPrev, false); switch (communicationMode) &#123; case ASYNC: return null; // 异步发送返回null case ONEWAY: return null; // 单向发送返回null case SYNC: if (sendResult.getSendStatus() != SendStatus.SEND_OK) &#123; if (this.defaultMQProducer.isRetryAnotherBrokerWhenNotStoreOK()) &#123; continue; // 若重试则继续,否则直接返回结果 &#125; &#125; return sendResult; default: break; &#125; &#125; &#125; else &#123; break; &#125; &#125; if (sendResult != null) &#123; return sendResult; &#125; info += FAQUrl.suggestTodo(FAQUrl.SEND_MSG_FAILED); MQClientException mqClientException = new MQClientException(info, exception); if (callTimeout) &#123; throw new RemotingTooMuchRequestException(&quot;sendDefaultImpl call timeout&quot;); &#125; throw mqClientException; &#125; validateNameServerSetting(); throw new MQClientException(&quot;No route info of this topic: &quot; + msg.getTopic() + FAQUrl.suggestTodo(FAQUrl.NO_TOPIC_ROUTE_INFO), null).setResponseCode(ClientErrorCode.NOT_FOUND_TOPIC_EXCEPTION); &#125; public MessageQueue selectOneMessageQueue(final TopicPublishInfo tpInfo, final String lastBrokerName) &#123; return this.mqFaultStrategy.selectOneMessageQueue(tpInfo, lastBrokerName); &#125; // 找路由表的过程都是先从本地缓存找,本地缓存没有,就去NameServer上申请. private TopicPublishInfo tryToFindTopicPublishInfo(final String topic) &#123; TopicPublishInfo topicPublishInfo = this.topicPublishInfoTable.get(topic); if (null == topicPublishInfo || !topicPublishInfo.ok()) &#123; this.topicPublishInfoTable.putIfAbsent(topic, new TopicPublishInfo()); // Producer向NameServer获取更新Topic的路由信息. this.mQClientFactory.updateTopicRouteInfoFromNameServer(topic); // 还是从本地缓存中寻找Topic路由信息. topicPublishInfo = this.topicPublishInfoTable.get(topic); &#125; if (topicPublishInfo.isHaveTopicRouterInfo() || topicPublishInfo.ok()) &#123; return topicPublishInfo; &#125; else &#123; this.mQClientFactory.updateTopicRouteInfoFromNameServer(topic, true, this.defaultMQProducer); topicPublishInfo = this.topicPublishInfoTable.get(topic); return topicPublishInfo; &#125; &#125;&#125;public class MQFaultStrategy &#123; public MessageQueue selectOneMessageQueue(final TopicPublishInfo tpInfo, final String lastBrokerName) &#123; // sendLatencyFaultEnable默认关闭,Broker故障延迟机制,表示一种发送消息失败后一定时间内不在往同一个Queue重复发送的机制 if (this.sendLatencyFaultEnable) &#123; try &#123; // Producer选择MessageQueue的方法是自增然后取模. int index = tpInfo.getSendWhichQueue().getAndIncrement(); for (int i = 0; i &lt; tpInfo.getMessageQueueList().size(); i++) &#123; int pos = Math.abs(index++) % tpInfo.getMessageQueueList().size(); if (pos &lt; 0) pos = 0; MessageQueue mq = tpInfo.getMessageQueueList().get(pos); // Broker轮询,尽量将请求平均分配给不同的Broker if (latencyFaultTolerance.isAvailable(mq.getBrokerName())) &#123; if (null == lastBrokerName || mq.getBrokerName().equals(lastBrokerName)) return mq; &#125; &#125; final String notBestBroker = latencyFaultTolerance.pickOneAtLeast(); int writeQueueNums = tpInfo.getQueueIdByBroker(notBestBroker); if (writeQueueNums &gt; 0) &#123; final MessageQueue mq = tpInfo.selectOneMessageQueue();// 自增取模计算 if (notBestBroker != null) &#123; mq.setBrokerName(notBestBroker); mq.setQueueId(tpInfo.getSendWhichQueue().getAndIncrement() % writeQueueNums); &#125; return mq; &#125; else &#123; latencyFaultTolerance.remove(notBestBroker); &#125; &#125; return tpInfo.selectOneMessageQueue(); // 自增取模计算 &#125; return tpInfo.selectOneMessageQueue(lastBrokerName); // 自增取模计算 &#125;&#125;public class TopicPublishInfo &#123; //选择MessageQueue的方式：递增取模 public MessageQueue selectOneMessageQueue() &#123; int index = this.sendWhichQueue.getAndIncrement(); int pos = Math.abs(index) % this.messageQueueList.size(); if (pos &lt; 0) pos = 0; return this.messageQueueList.get(pos); &#125; public MessageQueue selectOneMessageQueue(final String lastBrokerName) &#123; if (lastBrokerName == null) &#123; return selectOneMessageQueue(); &#125; else &#123; int index = this.sendWhichQueue.getAndIncrement(); for (int i = 0; i &lt; this.messageQueueList.size(); i++) &#123; int pos = Math.abs(index++) % this.messageQueueList.size(); if (pos &lt; 0) pos = 0; MessageQueue mq = this.messageQueueList.get(pos); if (!mq.getBrokerName().equals(lastBrokerName)) &#123; return mq; &#125; &#125; return selectOneMessageQueue(); &#125; &#125;&#125; 不论是同步还是异步或是单向消息最终都会调用 MQClientAPIImpl 的 sendMessage 方法,不同的是同步方法没有 SendCallback 回调. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152public class DefaultMQProducerImpl implements MQProducerInner &#123; private SendResult sendKernelImpl(final Message msg, final MessageQueue mq, final CommunicationMode communicationMode, final SendCallback sendCallback, final TopicPublishInfo topicPublishInfo, final long timeout) throws MQClientException, RemotingException, MQBrokerException, InterruptedException &#123; long beginStartTime = System.currentTimeMillis(); String brokerAddr = this.mQClientFactory.findBrokerAddressInPublish(mq.getBrokerName()); // 找到Master节点地址 if (null == brokerAddr) &#123;// 通过Broker名称获取Broker地址,若获取不到则去NameServer上获取. tryToFindTopicPublishInfo(mq.getTopic()); brokerAddr = this.mQClientFactory.findBrokerAddressInPublish(mq.getBrokerName()); &#125; SendMessageContext context = null; if (brokerAddr != null) &#123; brokerAddr = MixAll.brokerVIPChannel(this.defaultMQProducer.isSendMessageWithVIPChannel(), brokerAddr); byte[] prevBody = msg.getBody(); try &#123; if (!(msg instanceof MessageBatch)) &#123; //for MessageBatch,ID has been set in the generating process MessageClientIDSetter.setUniqID(msg); // 批量消息 &#125; boolean topicWithNamespace = false; if (null != this.mQClientFactory.getClientConfig().getNamespace()) &#123; msg.setInstanceId(this.mQClientFactory.getClientConfig().getNamespace()); topicWithNamespace = true; &#125; int sysFlag = 0; boolean msgBodyCompressed = false; if (this.tryToCompressMessage(msg)) &#123; // 消息体大于4K将默认压缩 sysFlag |= MessageSysFlag.COMPRESSED_FLAG; msgBodyCompressed = true; &#125; final String tranMsg = msg.getProperty(MessageConst.PROPERTY_TRANSACTION_PREPARED); if (tranMsg != null &amp;&amp; Boolean.parseBoolean(tranMsg)) &#123; sysFlag |= MessageSysFlag.TRANSACTION_PREPARED_TYPE; &#125; SendMessageRequestHeader requestHeader = new SendMessageRequestHeader(); requestHeader.setProducerGroup(this.defaultMQProducer.getProducerGroup()); requestHeader.setTopic(msg.getTopic()); requestHeader.setDefaultTopic(this.defaultMQProducer.getCreateTopicKey()); requestHeader.setDefaultTopicQueueNums(this.defaultMQProducer.getDefaultTopicQueueNums()); requestHeader.setQueueId(mq.getQueueId()); requestHeader.setSysFlag(sysFlag); requestHeader.setBornTimestamp(System.currentTimeMillis()); requestHeader.setFlag(msg.getFlag()); requestHeader.setProperties(MessageDecoder.messageProperties2String(msg.getProperties())); requestHeader.setReconsumeTimes(0); requestHeader.setUnitMode(this.isUnitMode()); requestHeader.setBatch(msg instanceof MessageBatch); if (requestHeader.getTopic().startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)) &#123; // 重试消息 String reconsumeTimes = MessageAccessor.getReconsumeTime(msg); if (reconsumeTimes != null) &#123; requestHeader.setReconsumeTimes(Integer.valueOf(reconsumeTimes)); MessageAccessor.clearProperty(msg, MessageConst.PROPERTY_RECONSUME_TIME); &#125; String maxReconsumeTimes = MessageAccessor.getMaxReconsumeTimes(msg); if (maxReconsumeTimes != null) &#123; requestHeader.setMaxReconsumeTimes(Integer.valueOf(maxReconsumeTimes)); MessageAccessor.clearProperty(msg, MessageConst.PROPERTY_MAX_RECONSUME_TIMES); &#125; &#125; SendResult sendResult = null; switch (communicationMode) &#123; case ASYNC: Message tmpMessage = msg; boolean messageCloned = false; if (msgBodyCompressed) &#123; tmpMessage = MessageAccessor.cloneMessage(msg); messageCloned = true; msg.setBody(prevBody); &#125; if (topicWithNamespace) &#123; if (!messageCloned) &#123; tmpMessage = MessageAccessor.cloneMessage(msg); messageCloned = true; &#125; msg.setTopic(NamespaceUtil.withoutNamespace(msg.getTopic(), this.defaultMQProducer.getNamespace())); &#125; long costTimeAsync = System.currentTimeMillis() - beginStartTime; if (timeout &lt; costTimeAsync) &#123; throw new RemotingTooMuchRequestException(&quot;sendKernelImpl call timeout&quot;); &#125; // 真正向Broker发送消息,异步要传入回调函数 sendResult = this.mQClientFactory.getMQClientAPIImpl().sendMessage(brokerAddr, mq.getBrokerName(), tmpMessage, requestHeader, timeout - costTimeAsync, communicationMode, sendCallback, topicPublishInfo, this.mQClientFactory, this.defaultMQProducer.getRetryTimesWhenSendAsyncFailed(), context, this); break; case ONEWAY: case SYNC: long costTimeSync = System.currentTimeMillis() - beginStartTime; if (timeout &lt; costTimeSync) &#123; throw new RemotingTooMuchRequestException(&quot;sendKernelImpl call timeout&quot;); &#125; // 真正向Broker发送消息,同步不需要传入回调函数 sendResult = this.mQClientFactory.getMQClientAPIImpl().sendMessage(brokerAddr, mq.getBrokerName(), msg, requestHeader, timeout - costTimeSync, communicationMode, context, this); break; default: assert false; break; &#125; if (this.hasSendMessageHook()) &#123;//消息发送完成后执行钩子程序. context.setSendResult(sendResult); this.executeSendMessageHookAfter(context); &#125; return sendResult; &#125; &#125; throw new MQClientException(&quot;The broker[&quot; + mq.getBrokerName() + &quot;] not exist&quot;, null); &#125;&#125;public class MQClientAPIImpl &#123; // 不论同步还是异步最终都会调用该方法 public SendResult sendMessage(final String addr, final String brokerName, final Message msg, final SendMessageRequestHeader requestHeader, final long timeoutMillis, final CommunicationMode communicationMode, final SendCallback sendCallback, final TopicPublishInfo topicPublishInfo, final MQClientInstance instance, final int retryTimesWhenSendFailed, final SendMessageContext context, final DefaultMQProducerImpl producer) throws RemotingException, MQBrokerException, InterruptedException &#123; long beginStartTime = System.currentTimeMillis(); RemotingCommand request = null; String msgType = msg.getProperty(MessageConst.PROPERTY_MESSAGE_TYPE); boolean isReply = msgType != null &amp;&amp; msgType.equals(MixAll.REPLY_MESSAGE_FLAG); if (isReply) &#123; if (sendSmartMsg) &#123; SendMessageRequestHeaderV2 requestHeaderV2 = SendMessageRequestHeaderV2.createSendMessageRequestHeaderV2(requestHeader); request = RemotingCommand.createRequestCommand(RequestCode.SEND_REPLY_MESSAGE_V2, requestHeaderV2); &#125; else &#123; request = RemotingCommand.createRequestCommand(RequestCode.SEND_REPLY_MESSAGE, requestHeader); &#125; &#125; else &#123; if (sendSmartMsg || msg instanceof MessageBatch) &#123; SendMessageRequestHeaderV2 requestHeaderV2 = SendMessageRequestHeaderV2.createSendMessageRequestHeaderV2(requestHeader); request = RemotingCommand.createRequestCommand(msg instanceof MessageBatch ? RequestCode.SEND_BATCH_MESSAGE : RequestCode.SEND_MESSAGE_V2, requestHeaderV2); &#125; else &#123; request = RemotingCommand.createRequestCommand(RequestCode.SEND_MESSAGE, requestHeader); &#125; &#125; request.setBody(msg.getBody()); switch (communicationMode) &#123; case ONEWAY: this.remotingClient.invokeOneway(addr, request, timeoutMillis); return null; case ASYNC: final AtomicInteger times = new AtomicInteger(); long costTimeAsync = System.currentTimeMillis() - beginStartTime; if (timeoutMillis &lt; costTimeAsync) &#123; throw new RemotingTooMuchRequestException(&quot;sendMessage call timeout&quot;); &#125; this.sendMessageAsync(addr, brokerName, msg, timeoutMillis - costTimeAsync, request, sendCallback, topicPublishInfo, instance, retryTimesWhenSendFailed, times, context, producer); return null; case SYNC: long costTimeSync = System.currentTimeMillis() - beginStartTime; if (timeoutMillis &lt; costTimeSync) &#123; throw new RemotingTooMuchRequestException(&quot;sendMessage call timeout&quot;); &#125; return this.sendMessageSync(addr, brokerName, msg, timeoutMillis - costTimeSync, request); default: assert false; break; &#125; return null; &#125; &#125; 对于同步消息最终用通过 RequestCode.SEND_MESSAGE 编号最终在 Broker 中执行 SendMessageProcessor 的 processRequest 方法,异步消息最终调用的是 SendMessageProcessor 的 asyncProcessRequest 方法,最终都是调用的 asyncProcessRequest 方法,不同点在于同步消息的 processRequest 中获取到异步 CompletableFuture 直接调用get方法等待结果,不论是同步还是异步方法最终都是在 handlePutMessageResultFuture 方法中调用 CompletableFuture 的 thenApply 方法,在响应后最终在 handlePutMessageResult 中调用 doResponse 方法将结果写回给客户端. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109public class MQClientAPIImpl &#123; private SendResult sendMessageSync(final String addr, final String brokerName, final Message msg, final long timeoutMillis, final RemotingCommand request) throws RemotingException, MQBrokerException, InterruptedException &#123; RemotingCommand response = this.remotingClient.invokeSync(addr, request, timeoutMillis); assert response != null; return this.processSendResponse(brokerName, msg, response); &#125;&#125;public class NettyRemotingClient extends NettyRemotingAbstract implements RemotingClient &#123; public RemotingCommand invokeSync(String addr, final RemotingCommand request, long timeoutMillis) throws InterruptedException, RemotingConnectException, RemotingSendRequestException, RemotingTimeoutException &#123; long beginStartTime = System.currentTimeMillis(); // channel是和Nameserver之间建立的一个连接. final Channel channel = this.getAndCreateChannel(addr); if (channel != null &amp;&amp; channel.isActive()) &#123; // 网络连接ok则发送请求 try &#123; doBeforeRpcHooks(addr, request); //计算时间 long costTime = System.currentTimeMillis() - beginStartTime; if (timeoutMillis &lt; costTime) &#123; throw new RemotingTimeoutException(&quot;invokeSync call timeout&quot;); &#125; RemotingCommand response = this.invokeSyncImpl(channel, request, timeoutMillis - costTime); // 真正发网络请求的地方 doAfterRpcHooks(RemotingHelper.parseChannelRemoteAddr(channel), request, response); return response; &#125; catch (RemotingSendRequestException e) &#123; this.closeChannel(addr, channel); throw e; &#125; catch (RemotingTimeoutException e) &#123; if (nettyClientConfig.isClientCloseSocketIfTimeout()) &#123; this.closeChannel(addr, channel); &#125; throw e; &#125; &#125; else &#123; this.closeChannel(addr, channel); throw new RemotingConnectException(addr); &#125; &#125;&#125;public class SendMessageProcessor extends AbstractSendMessageProcessor implements NettyRequestProcessor &#123; public RemotingCommand processRequest(ChannelHandlerContext ctx, RemotingCommand request) throws RemotingCommandException &#123; RemotingCommand response = null; try &#123; response = asyncProcessRequest(ctx, request).get(); &#125; return response; &#125; public CompletableFuture&lt;RemotingCommand&gt; asyncProcessRequest(ChannelHandlerContext ctx, RemotingCommand request) throws RemotingCommandException &#123; final SendMessageContext mqtraceContext; switch (request.getCode()) &#123; case RequestCode.CONSUMER_SEND_MSG_BACK: return this.asyncConsumerSendMsgBack(ctx, request); default: SendMessageRequestHeader requestHeader = parseRequestHeader(request); if (requestHeader == null) &#123; return CompletableFuture.completedFuture(null); &#125; mqtraceContext = buildMsgContext(ctx, requestHeader); this.executeSendMessageHookBefore(ctx, request, mqtraceContext); if (requestHeader.isBatch()) &#123; return this.asyncSendBatchMessage(ctx, request, mqtraceContext, requestHeader); &#125; else &#123; return this.asyncSendMessage(ctx, request, mqtraceContext, requestHeader); &#125; &#125; &#125; private CompletableFuture&lt;RemotingCommand&gt; asyncSendMessage(ChannelHandlerContext ctx, RemotingCommand request, SendMessageContext mqtraceContext, SendMessageRequestHeader requestHeader) &#123; final RemotingCommand response = preSend(ctx, request, requestHeader); final SendMessageResponseHeader responseHeader = (SendMessageResponseHeader)response.readCustomHeader(); if (response.getCode() != -1) &#123; return CompletableFuture.completedFuture(response); &#125; final byte[] body = request.getBody(); int queueIdInt = requestHeader.getQueueId(); TopicConfig topicConfig = this.brokerController.getTopicConfigManager().selectTopicConfig(requestHeader.getTopic()); if (queueIdInt &lt; 0) &#123; queueIdInt = randomQueueId(topicConfig.getWriteQueueNums()); &#125; MessageExtBrokerInner msgInner = new MessageExtBrokerInner(); msgInner.setTopic(requestHeader.getTopic()); msgInner.setQueueId(queueIdInt); if (!handleRetryAndDLQ(requestHeader, response, request, msgInner, topicConfig)) &#123; return CompletableFuture.completedFuture(response); &#125; msgInner.setBody(body); msgInner.setFlag(requestHeader.getFlag()); MessageAccessor.setProperties(msgInner, MessageDecoder.string2messageProperties(requestHeader.getProperties())); msgInner.setPropertiesString(requestHeader.getProperties()); msgInner.setBornTimestamp(requestHeader.getBornTimestamp()); msgInner.setBornHost(ctx.channel().remoteAddress()); msgInner.setStoreHost(this.getStoreHost()); msgInner.setReconsumeTimes(requestHeader.getReconsumeTimes() == null ? 0 : requestHeader.getReconsumeTimes()); String clusterName = this.brokerController.getBrokerConfig().getBrokerClusterName(); MessageAccessor.putProperty(msgInner, MessageConst.PROPERTY_CLUSTER, clusterName); msgInner.setPropertiesString(MessageDecoder.messageProperties2String(msgInner.getProperties())); CompletableFuture&lt;PutMessageResult&gt; putMessageResult = null; Map&lt;String, String&gt; origProps = MessageDecoder.string2messageProperties(requestHeader.getProperties()); String transFlag = origProps.get(MessageConst.PROPERTY_TRANSACTION_PREPARED); if (transFlag != null &amp;&amp; Boolean.parseBoolean(transFlag)) &#123; if (this.brokerController.getBrokerConfig().isRejectTransactionMessage()) &#123; response.setCode(ResponseCode.NO_PERMISSION); response.setRemark(&quot;the broker[&quot; + this.brokerController.getBrokerConfig().getBrokerIP1() + &quot;] sending transaction message is forbidden&quot;); return CompletableFuture.completedFuture(response); &#125; putMessageResult = this.brokerController.getTransactionalMessageService().asyncPrepareMessage(msgInner); // 事务消息持久化 &#125; else &#123; putMessageResult = this.brokerController.getMessageStore().asyncPutMessage(msgInner); // 普通消息持久化 &#125; return handlePutMessageResultFuture(putMessageResult, response, request, msgInner, responseHeader, mqtraceContext, ctx, queueIdInt); &#125;&#125; 对于异步方法当获取到响应后会回调 InvokeCallback 中的 operationComplete 方法,在该方法中若成功则回调用 SendCallback 的 onSuccess 方法.若失败则走重试逻辑若中还是失败则回调用 SendCallback 的 onException 方法. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class MQClientAPIImpl &#123; private void sendMessageAsync(final String addr, final String brokerName, final Message msg, final long timeoutMillis, final RemotingCommand request, final SendCallback sendCallback, final TopicPublishInfo topicPublishInfo, final MQClientInstance instance, final int retryTimesWhenSendFailed, final AtomicInteger times, final SendMessageContext context, final DefaultMQProducerImpl producer) throws InterruptedException, RemotingException &#123; final long beginStartTime = System.currentTimeMillis(); this.remotingClient.invokeAsync(addr, request, timeoutMillis, new InvokeCallback() &#123; @Override public void operationComplete(ResponseFuture responseFuture) &#123; long cost = System.currentTimeMillis() - beginStartTime; RemotingCommand response = responseFuture.getResponseCommand(); if (null == sendCallback &amp;&amp; response != null) &#123; try &#123; SendResult sendResult = MQClientAPIImpl.this.processSendResponse(brokerName, msg, response); if (context != null &amp;&amp; sendResult != null) &#123; context.setSendResult(sendResult); context.getProducer().executeSendMessageHookAfter(context); &#125; &#125; catch (Throwable e) &#123; &#125; producer.updateFaultItem(brokerName, System.currentTimeMillis() - responseFuture.getBeginTimestamp(), false); return; &#125; if (response != null) &#123; try &#123; SendResult sendResult = MQClientAPIImpl.this.processSendResponse(brokerName, msg, response); assert sendResult != null; if (context != null) &#123; context.setSendResult(sendResult); context.getProducer().executeSendMessageHookAfter(context); &#125; try &#123; sendCallback.onSuccess(sendResult); // 回调用SendCallback的onSuccess方法 &#125; catch (Throwable e) &#123; &#125; producer.updateFaultItem(brokerName, System.currentTimeMillis() - responseFuture.getBeginTimestamp(), false); &#125; catch (Exception e) &#123; producer.updateFaultItem(brokerName, System.currentTimeMillis() - responseFuture.getBeginTimestamp(), true); onExceptionImpl(brokerName, msg, timeoutMillis - cost, request, sendCallback, topicPublishInfo, instance, retryTimesWhenSendFailed, times, e, context, false, producer); &#125; &#125; else &#123; producer.updateFaultItem(brokerName, System.currentTimeMillis() - responseFuture.getBeginTimestamp(), true); if (!responseFuture.isSendRequestOK()) &#123; MQClientException ex = new MQClientException(&quot;send request failed&quot;, responseFuture.getCause()); onExceptionImpl(brokerName, msg, timeoutMillis - cost, request, sendCallback, topicPublishInfo, instance, retryTimesWhenSendFailed, times, ex, context, true, producer); &#125; else if (responseFuture.isTimeout()) &#123; MQClientException ex = new MQClientException(&quot;wait response timeout &quot; + responseFuture.getTimeoutMillis() + &quot;ms&quot;, responseFuture.getCause()); onExceptionImpl(brokerName, msg, timeoutMillis - cost, request, sendCallback, topicPublishInfo, instance, retryTimesWhenSendFailed, times, ex, context, true, producer); &#125; else &#123; MQClientException ex = new MQClientException(&quot;unknow reseaon&quot;, responseFuture.getCause()); onExceptionImpl(brokerName, msg, timeoutMillis - cost, request, sendCallback, topicPublishInfo, instance, retryTimesWhenSendFailed, times, ex, context, true, producer); &#125; &#125; &#125; &#125;); &#125;&#125; 事务消息对于事务消息的发送是通过 TransactionMQProducer 类的 sendMessageInTransaction 方法来完成的,若事务消息设置了延迟参数则将会被清除,会设置 TRAN_MSG 属性为 true ,然后调用send方法发送消费到 Broker ,send方法中和普通的发送消息调用的一个方法,但普通消息是走的 DefaultMessageStore 的 asyncPutMessage 方法,事务消息是走的 TransactionalMessageServiceImpl 的 asyncPrepareMessage 方法.若发送成功则调用设置的 TransactionListener 的 executeLocalTransaction 方法,然后调用 MQClientAPIImpl 的 endTransactionOneway 方法. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111public class TransactionMQProducer extends DefaultMQProducer &#123; public TransactionSendResult sendMessageInTransaction(final Message msg, final Object arg) throws MQClientException &#123; if (null == this.transactionListener) &#123; throw new MQClientException(&quot;TransactionListener is null&quot;, null); &#125; msg.setTopic(NamespaceUtil.wrapNamespace(this.getNamespace(), msg.getTopic())); return this.defaultMQProducerImpl.sendMessageInTransaction(msg, null, arg); &#125;&#125;public class DefaultMQProducerImpl implements MQProducerInner &#123; public TransactionSendResult sendMessageInTransaction(final Message msg, final LocalTransactionExecuter localTransactionExecuter, final Object arg) throws MQClientException &#123; TransactionListener transactionListener = getCheckListener(); if (null == localTransactionExecuter &amp;&amp; null == transactionListener) &#123; throw new MQClientException(&quot;tranExecutor is null&quot;, null); &#125; if (msg.getDelayTimeLevel() != 0) &#123; // 不支持延迟消息 MessageAccessor.clearProperty(msg, MessageConst.PROPERTY_DELAY_TIME_LEVEL); &#125; Validators.checkMessage(msg, this.defaultMQProducer); SendResult sendResult = null; MessageAccessor.putProperty(msg, MessageConst.PROPERTY_TRANSACTION_PREPARED, &quot;true&quot;); MessageAccessor.putProperty(msg, MessageConst.PROPERTY_PRODUCER_GROUP, this.defaultMQProducer.getProducerGroup()); try &#123; sendResult = this.send(msg); &#125; catch (Exception e) &#123; throw new MQClientException(&quot;send message Exception&quot;, e); &#125; LocalTransactionState localTransactionState = LocalTransactionState.UNKNOW; // 默认本地事务状态为UNKNOW Throwable localException = null; switch (sendResult.getSendStatus()) &#123; case SEND_OK: &#123; try &#123; if (sendResult.getTransactionId() != null) &#123; msg.putUserProperty(&quot;__transactionId__&quot;, sendResult.getTransactionId()); &#125; String transactionId = msg.getProperty(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX); if (null != transactionId &amp;&amp; !&quot;&quot;.equals(transactionId)) &#123; msg.setTransactionId(transactionId); &#125; if (null != localTransactionExecuter) &#123; // 默认localTransactionExecuter为null localTransactionState = localTransactionExecuter.executeLocalTransactionBranch(msg, arg); &#125; else if (transactionListener != null) &#123; // transactionListener是调用时设置的 localTransactionState = transactionListener.executeLocalTransaction(msg, arg); &#125; if (null == localTransactionState) &#123; localTransactionState = LocalTransactionState.UNKNOW; &#125; &#125; catch (Throwable e) &#123; localException = e; &#125; &#125; break; case FLUSH_DISK_TIMEOUT: case FLUSH_SLAVE_TIMEOUT: case SLAVE_NOT_AVAILABLE: localTransactionState = LocalTransactionState.ROLLBACK_MESSAGE; break; default: break; &#125; try &#123; this.endTransaction(sendResult, localTransactionState, localException); &#125; TransactionSendResult transactionSendResult = new TransactionSendResult(); transactionSendResult.setSendStatus(sendResult.getSendStatus()); transactionSendResult.setMessageQueue(sendResult.getMessageQueue()); transactionSendResult.setMsgId(sendResult.getMsgId()); transactionSendResult.setQueueOffset(sendResult.getQueueOffset()); transactionSendResult.setTransactionId(sendResult.getTransactionId()); transactionSendResult.setLocalTransactionState(localTransactionState); return transactionSendResult; &#125; public void endTransaction(final SendResult sendResult, final LocalTransactionState localTransactionState, final Throwable localException) throws RemotingException, MQBrokerException, InterruptedException, UnknownHostException &#123; final MessageId id; if (sendResult.getOffsetMsgId() != null) &#123; id = MessageDecoder.decodeMessageId(sendResult.getOffsetMsgId()); &#125; else &#123; id = MessageDecoder.decodeMessageId(sendResult.getMsgId()); &#125; String transactionId = sendResult.getTransactionId(); final String brokerAddr = this.mQClientFactory.findBrokerAddressInPublish(sendResult.getMessageQueue().getBrokerName()); EndTransactionRequestHeader requestHeader = new EndTransactionRequestHeader(); requestHeader.setTransactionId(transactionId); requestHeader.setCommitLogOffset(id.getOffset()); switch (localTransactionState) &#123; case COMMIT_MESSAGE: requestHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_COMMIT_TYPE); break; case ROLLBACK_MESSAGE: requestHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_ROLLBACK_TYPE); break; case UNKNOW: requestHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_NOT_TYPE); break; default: break; &#125; requestHeader.setProducerGroup(this.defaultMQProducer.getProducerGroup()); requestHeader.setTranStateTableOffset(sendResult.getQueueOffset()); requestHeader.setMsgId(sendResult.getMsgId()); String remark = localException != null ? (&quot;executeLocalTransactionBranch exception: &quot; + localException.toString()) : null; this.mQClientFactory.getMQClientAPIImpl().endTransactionOneway(brokerAddr, requestHeader, remark, this.defaultMQProducer.getSendMsgTimeout()); &#125;&#125;public class MQClientAPIImpl &#123; public void endTransactionOneway(final String addr, final EndTransactionRequestHeader requestHeader, final String remark, final long timeoutMillis) throws RemotingException, MQBrokerException, InterruptedException &#123; RemotingCommand request = RemotingCommand.createRequestCommand(RequestCode.END_TRANSACTION, requestHeader); request.setRemark(remark); this.remotingClient.invokeOneway(addr, request, timeoutMillis); &#125;&#125; 首先会将将真正的事务 Topic 存储到 REAL_TOPIC 属性中,然后将 Topic 换成 RMQ_SYS_TRANS_HALF_TOPIC ,然后将替换了Topic的事务消息通过 DefaultMessageStore 的 asyncPutMessage 方法最终存储到 CommitLog 中. 1234567891011121314151617public class TransactionalMessageServiceImpl implements TransactionalMessageService &#123; public CompletableFuture&lt;PutMessageResult&gt; asyncPrepareMessage(MessageExtBrokerInner messageInner) &#123; return transactionalMessageBridge.asyncPutHalfMessage(messageInner); &#125; public CompletableFuture&lt;PutMessageResult&gt; asyncPutHalfMessage(MessageExtBrokerInner messageInner) &#123; return store.asyncPutMessage(parseHalfMessageInner(messageInner)); &#125; private MessageExtBrokerInner parseHalfMessageInner(MessageExtBrokerInner msgInner) &#123; MessageAccessor.putProperty(msgInner, MessageConst.PROPERTY_REAL_TOPIC, msgInner.getTopic()); // 将真正的事务Topic存储到REAL_TOPIC属性中 MessageAccessor.putProperty(msgInner, MessageConst.PROPERTY_REAL_QUEUE_ID, String.valueOf(msgInner.getQueueId())); msgInner.setSysFlag(MessageSysFlag.resetTransactionValue(msgInner.getSysFlag(), MessageSysFlag.TRANSACTION_NOT_TYPE)); msgInner.setTopic(TransactionalMessageUtil.buildHalfTopic()); // Topic换成RMQ_SYS_TRANS_HALF_TOPIC msgInner.setQueueId(0); msgInner.setPropertiesString(MessageDecoder.messageProperties2String(msgInner.getProperties())); return msgInner; &#125;&#125; 最终通过 RequestCode.END_TRANSACTION 编码关联调用 EndTransactionProcessor 的 processRequest 方法,不论是是 COMMIT 还是 ROLLBACK 都将消息从 RMQ_SYS_TRANS_HALF_TOPIC 队列中查询出,若是 COMMIT 则将从 RMQ_SYS_TRANS_HALF_TOPIC 队列中查询的消息真正存储到其真实的Topic队列中,然后成功则再在 RMQ_SYS_TRANS_OP_HALF_TOPIC 队列中添加一条对应的消息标识该Half消息被删除.若为 ROLLBACK 则直接在 RMQ_SYS_TRANS_OP_HALF_TOPIC 队列中添加一条对应的消标识事务结束.开源版本进行了阉割,不会走回查逻辑. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class EndTransactionProcessor extends AsyncNettyRequestProcessor implements NettyRequestProcessor &#123; public RemotingCommand processRequest(ChannelHandlerContext ctx, RemotingCommand request) throws RemotingCommandException &#123; final RemotingCommand response = RemotingCommand.createResponseCommand(null); final EndTransactionRequestHeader requestHeader = (EndTransactionRequestHeader)request.decodeCommandCustomHeader(EndTransactionRequestHeader.class); if (BrokerRole.SLAVE == brokerController.getMessageStoreConfig().getBrokerRole()) &#123; response.setCode(ResponseCode.SLAVE_NOT_AVAILABLE); return response; // 若当前节点是从节点 &#125; OperationResult result = new OperationResult(); if (MessageSysFlag.TRANSACTION_COMMIT_TYPE == requestHeader.getCommitOrRollback()) &#123; result = this.brokerController.getTransactionalMessageService().commitMessage(requestHeader); if (result.getResponseCode() == ResponseCode.SUCCESS) &#123; RemotingCommand res = checkPrepareMessage(result.getPrepareMessage(), requestHeader); if (res.getCode() == ResponseCode.SUCCESS) &#123; MessageExtBrokerInner msgInner = endMessageTransaction(result.getPrepareMessage()); msgInner.setSysFlag(MessageSysFlag.resetTransactionValue(msgInner.getSysFlag(), requestHeader.getCommitOrRollback())); msgInner.setQueueOffset(requestHeader.getTranStateTableOffset()); msgInner.setPreparedTransactionOffset(requestHeader.getCommitLogOffset()); msgInner.setStoreTimestamp(result.getPrepareMessage().getStoreTimestamp()); MessageAccessor.clearProperty(msgInner, MessageConst.PROPERTY_TRANSACTION_PREPARED); // 将事务消息TRAN_MSG标记移除 RemotingCommand sendResult = sendFinalMessage(msgInner);// 将从RMQ_SYS_TRANS_HALF_TOPIC队列中查询的消息真正存储到其真实的Topic队列中 if (sendResult.getCode() == ResponseCode.SUCCESS) &#123;// 存储成功则在RMQ_SYS_TRANS_OP_HALF_TOPIC队列中添加对应的消息 this.brokerController.getTransactionalMessageService().deletePrepareMessage(result.getPrepareMessage()); &#125; return sendResult; &#125; return res; &#125; &#125; else if (MessageSysFlag.TRANSACTION_ROLLBACK_TYPE == requestHeader.getCommitOrRollback()) &#123; result = this.brokerController.getTransactionalMessageService().rollbackMessage(requestHeader); if (result.getResponseCode() == ResponseCode.SUCCESS) &#123; RemotingCommand res = checkPrepareMessage(result.getPrepareMessage(), requestHeader); if (res.getCode() == ResponseCode.SUCCESS) &#123;// 成功则在RMQ_SYS_TRANS_OP_HALF_TOPIC队列中添加对应的消息 this.brokerController.getTransactionalMessageService().deletePrepareMessage(result.getPrepareMessage()); &#125; return res; &#125; &#125; response.setCode(result.getResponseCode()); response.setRemark(result.getResponseRemark()); return response; &#125;&#125;public class TransactionalMessageServiceImpl implements TransactionalMessageService &#123; public OperationResult commitMessage(EndTransactionRequestHeader requestHeader) &#123; return getHalfMessageByOffset(requestHeader.getCommitLogOffset()); &#125; public OperationResult rollbackMessage(EndTransactionRequestHeader requestHeader) &#123; return getHalfMessageByOffset(requestHeader.getCommitLogOffset()); &#125; private OperationResult getHalfMessageByOffset(long commitLogOffset) &#123; OperationResult response = new OperationResult(); MessageExt messageExt = this.transactionalMessageBridge.lookMessageByOffset(commitLogOffset); if (messageExt != null) &#123; response.setPrepareMessage(messageExt); response.setResponseCode(ResponseCode.SUCCESS); &#125; else &#123; response.setResponseCode(ResponseCode.SYSTEM_ERROR); response.setResponseRemark(&quot;Find prepared transaction message failed&quot;); &#125; return response; &#125;&#125; 在 BrokerController 的 initialTransaction() 方法中会初始化事务消息检查类TransactionalMessageCheckService ,该类是一个线程类,在 BrokerController 的 start 方法中通过 startProcessorByHa 方法开启事务消息检查线程.若已经超过最大回查次数,则将消息添加到 TRANS_CHECK_MAXTIME_TOPIC 队列中,若需要检查则将消息写回 RMQ_SYS_TRANS_HALF_TOPIC 队列中防止再次失败,然后调用 AbstractTransactionalMessageCheckListener 的 resolveHalfMsg 方法检查消息. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130public class TransactionalMessageCheckService extends ServiceThread &#123; public void run() &#123; // 默认60s long checkInterval = brokerController.getBrokerConfig().getTransactionCheckInterval(); while (!this.isStopped()) &#123; this.waitForRunning(checkInterval); &#125; &#125; protected void waitForRunning(long interval) &#123; if (hasNotified.compareAndSet(true, false)) &#123; this.onWaitEnd(); return; &#125; waitPoint.reset(); try &#123; waitPoint.await(interval, TimeUnit.MILLISECONDS); &#125; catch (InterruptedException e) &#123; &#125; finally &#123; hasNotified.set(false); this.onWaitEnd(); &#125; &#125; protected void onWaitEnd() &#123; long timeout = brokerController.getBrokerConfig().getTransactionTimeOut(); // 获取超时时间6s int checkMax = brokerController.getBrokerConfig().getTransactionCheckMax(); // 获取最大回查次数15 long begin = System.currentTimeMillis(); this.brokerController.getTransactionalMessageService().check(timeout, checkMax, this.brokerController.getTransactionalMessageCheckListener()); &#125;&#125;public class TransactionalMessageServiceImpl implements TransactionalMessageService &#123; public void check(long transactionTimeout, int transactionCheckMax, AbstractTransactionalMessageCheckListener listener) &#123; try &#123; String topic = TopicValidator.RMQ_SYS_TRANS_HALF_TOPIC; // RMQ_SYS_TRANS_HALF_TOPIC Set&lt;MessageQueue&gt; msgQueues = transactionalMessageBridge.fetchMessageQueues(topic); if (msgQueues == null || msgQueues.size() == 0) &#123; return; &#125; for (MessageQueue messageQueue : msgQueues) &#123; long startTime = System.currentTimeMillis(); MessageQueue opQueue = getOpQueue(messageQueue); long halfOffset = transactionalMessageBridge.fetchConsumeOffset(messageQueue); long opOffset = transactionalMessageBridge.fetchConsumeOffset(opQueue); if (halfOffset &lt; 0 || opOffset &lt; 0) &#123; continue; &#125; List&lt;Long&gt; doneOpOffset = new ArrayList&lt;&gt;(); HashMap&lt;Long, Long&gt; removeMap = new HashMap&lt;&gt;(); PullResult pullResult = fillOpRemoveMap(removeMap, opQueue, opOffset, halfOffset, doneOpOffset); if (null == pullResult) &#123; continue; &#125; int getMessageNullCount = 1; long newOffset = halfOffset; long i = halfOffset; while (true) &#123; if (System.currentTimeMillis() - startTime &gt; MAX_PROCESS_TIME_LIMIT) &#123; break; &#125; if (removeMap.containsKey(i)) &#123; Long removedOpOffset = removeMap.remove(i); doneOpOffset.add(removedOpOffset); &#125; else &#123; GetResult getResult = getHalfMsg(messageQueue, i); // 消费RMQ_SYS_TRANS_HALF_TOPIC队列中的事务消息 MessageExt msgExt = getResult.getMsg(); if (msgExt == null) &#123; if (getMessageNullCount++ &gt; MAX_RETRY_COUNT_WHEN_HALF_NULL) &#123; break; &#125; if (getResult.getPullResult().getPullStatus() == PullStatus.NO_NEW_MSG) &#123; break; &#125; else &#123; i = getResult.getPullResult().getNextBeginOffset(); newOffset = i; continue; &#125; &#125; if (needDiscard(msgExt, transactionCheckMax) || needSkip(msgExt)) &#123;// 若已经超过最大回查次数了 listener.resolveDiscardMsg(msgExt); // 将消息添加到TRANS_CHECK_MAXTIME_TOPIC队列中 newOffset = i + 1; i++; continue; &#125; if (msgExt.getStoreTimestamp() &gt;= startTime) &#123; break; &#125; long valueOfCurrentMinusBorn = System.currentTimeMillis() - msgExt.getBornTimestamp(); long checkImmunityTime = transactionTimeout; String checkImmunityTimeStr = msgExt.getUserProperty(MessageConst.PROPERTY_CHECK_IMMUNITY_TIME_IN_SECONDS); if (null != checkImmunityTimeStr) &#123; checkImmunityTime = getImmunityTime(checkImmunityTimeStr, transactionTimeout); if (valueOfCurrentMinusBorn &lt; checkImmunityTime) &#123; if (checkPrepareQueueOffset(removeMap, doneOpOffset, msgExt)) &#123; newOffset = i + 1; i++; continue; &#125; &#125; &#125; else &#123; if ((0 &lt;= valueOfCurrentMinusBorn) &amp;&amp; (valueOfCurrentMinusBorn &lt; checkImmunityTime)) &#123; break; &#125; &#125; List&lt;MessageExt&gt; opMsg = pullResult.getMsgFoundList(); boolean isNeedCheck = (opMsg == null &amp;&amp; valueOfCurrentMinusBorn &gt; checkImmunityTime) || (opMsg != null &amp;&amp; (opMsg.get(opMsg.size() - 1).getBornTimestamp() - startTime &gt; transactionTimeout)) || (valueOfCurrentMinusBorn &lt;= -1); if (isNeedCheck) &#123; if (!putBackHalfMsgQueue(msgExt, i)) &#123; // 写回RMQ_SYS_TRANS_HALF_TOPIC队列中 continue; &#125; listener.resolveHalfMsg(msgExt); // 真正检查消息的地方,回调客户端checkLocalTransaction方法 &#125; else &#123; pullResult = fillOpRemoveMap(removeMap, opQueue, pullResult.getNextBeginOffset(), halfOffset, doneOpOffset); continue; &#125; &#125; newOffset = i + 1; i++; &#125; if (newOffset != halfOffset) &#123; transactionalMessageBridge.updateConsumeOffset(messageQueue, newOffset); &#125; long newOpOffset = calculateOpOffset(doneOpOffset, opOffset); if (newOpOffset != opOffset) &#123; transactionalMessageBridge.updateConsumeOffset(opQueue, newOpOffset); &#125; &#125; &#125; &#125;&#125; 检查消息是异步执行的,首先还原当前消息真正的Topic,然后通过 Broker2Client 的 checkProducerTransactionState 方法中通过 RequestCode.CHECK_TRANSACTION_STATE 关联调用 ClientRemotingProcessor 的 ClientRemotingProcessor 方法. 123456789101112131415161718192021222324252627282930313233343536373839public abstract class AbstractTransactionalMessageCheckListener &#123; public void resolveHalfMsg(final MessageExt msgExt) &#123; executorService.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; sendCheckMessage(msgExt); &#125; catch (Exception e) &#123; &#125; &#125; &#125;); &#125; public void sendCheckMessage(MessageExt msgExt) throws Exception &#123; CheckTransactionStateRequestHeader checkTransactionStateRequestHeader = new CheckTransactionStateRequestHeader(); checkTransactionStateRequestHeader.setCommitLogOffset(msgExt.getCommitLogOffset()); checkTransactionStateRequestHeader.setOffsetMsgId(msgExt.getMsgId()); checkTransactionStateRequestHeader.setMsgId(msgExt.getUserProperty(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX)); checkTransactionStateRequestHeader.setTransactionId(checkTransactionStateRequestHeader.getMsgId()); checkTransactionStateRequestHeader.setTranStateTableOffset(msgExt.getQueueOffset()); msgExt.setTopic(msgExt.getUserProperty(MessageConst.PROPERTY_REAL_TOPIC)); // 真正的Topic msgExt.setQueueId(Integer.parseInt(msgExt.getUserProperty(MessageConst.PROPERTY_REAL_QUEUE_ID))); msgExt.setStoreSize(0); String groupId = msgExt.getProperty(MessageConst.PROPERTY_PRODUCER_GROUP); Channel channel = brokerController.getProducerManager().getAvaliableChannel(groupId); if (channel != null) &#123; brokerController.getBroker2Client().checkProducerTransactionState(groupId, channel, checkTransactionStateRequestHeader, msgExt); &#125; &#125;&#125;public class Broker2Client &#123; public void checkProducerTransactionState(final String group, final Channel channel, final CheckTransactionStateRequestHeader requestHeader, final MessageExt messageExt) throws Exception &#123; RemotingCommand request = RemotingCommand.createRequestCommand(RequestCode.CHECK_TRANSACTION_STATE, requestHeader); request.setBody(MessageDecoder.encode(messageExt, false)); try &#123; this.brokerController.getRemotingServer().invokeOneway(channel, request, 10); &#125; catch (Exception e) &#123; &#125; &#125;&#125; 首先调用自定义 TransactionListener 的 checkLocalTransaction 方法,然后调用 MQClientAPIImpl 的 endTransactionOneway 方法.最终又调用 EndTransactionProcessor 的 processRequest 方法. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596public class ClientRemotingProcessor extends AsyncNettyRequestProcessor implements NettyRequestProcessor &#123; public class ClientRemotingProcessor extends AsyncNettyRequestProcessor implements NettyRequestProcessor &#123; public RemotingCommand checkTransactionState(ChannelHandlerContext ctx, RemotingCommand request) throws RemotingCommandException &#123; final CheckTransactionStateRequestHeader requestHeader = (CheckTransactionStateRequestHeader) request.decodeCommandCustomHeader(CheckTransactionStateRequestHeader.class); final ByteBuffer byteBuffer = ByteBuffer.wrap(request.getBody()); final MessageExt messageExt = MessageDecoder.decode(byteBuffer); if (messageExt != null) &#123; if (StringUtils.isNotEmpty(this.mqClientFactory.getClientConfig().getNamespace())) &#123; messageExt.setTopic(NamespaceUtil.withoutNamespace(messageExt.getTopic(), this.mqClientFactory.getClientConfig().getNamespace())); &#125; String transactionId = messageExt.getProperty(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX); if (null != transactionId &amp;&amp; !&quot;&quot;.equals(transactionId)) &#123; messageExt.setTransactionId(transactionId); &#125; final String group = messageExt.getProperty(MessageConst.PROPERTY_PRODUCER_GROUP); if (group != null) &#123; MQProducerInner producer = this.mqClientFactory.selectProducer(group); if (producer != null) &#123; final String addr = RemotingHelper.parseChannelRemoteAddr(ctx.channel()); producer.checkTransactionState(addr, messageExt, requestHeader); &#125; &#125; &#125; return null; &#125; &#125;&#125;public class DefaultMQProducerImpl implements MQProducerInner &#123; public void checkTransactionState(final String addr, final MessageExt msg, final CheckTransactionStateRequestHeader header) &#123; Runnable request = new Runnable() &#123; private final String brokerAddr = addr; private final MessageExt message = msg; private final CheckTransactionStateRequestHeader checkRequestHeader = header; private final String group = DefaultMQProducerImpl.this.defaultMQProducer.getProducerGroup(); @Override public void run() &#123; TransactionCheckListener transactionCheckListener = DefaultMQProducerImpl.this.checkListener(); TransactionListener transactionListener = getCheckListener(); if (transactionCheckListener != null || transactionListener != null) &#123; LocalTransactionState localTransactionState = LocalTransactionState.UNKNOW; Throwable exception = null; try &#123; if (transactionCheckListener != null) &#123; localTransactionState = transactionCheckListener.checkLocalTransactionState(message); &#125; else if (transactionListener != null) &#123; localTransactionState = transactionListener.checkLocalTransaction(message); &#125; &#125; catch (Throwable e) &#123; exception = e; &#125; this.processTransactionState(localTransactionState, group, exception); &#125; &#125; private void processTransactionState(final LocalTransactionState localTransactionState, final String producerGroup, final Throwable exception) &#123; final EndTransactionRequestHeader thisHeader = new EndTransactionRequestHeader(); thisHeader.setCommitLogOffset(checkRequestHeader.getCommitLogOffset()); thisHeader.setProducerGroup(producerGroup); thisHeader.setTranStateTableOffset(checkRequestHeader.getTranStateTableOffset()); thisHeader.setFromTransactionCheck(true); String uniqueKey = message.getProperties().get(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX); if (uniqueKey == null) &#123; uniqueKey = message.getMsgId(); &#125; thisHeader.setMsgId(uniqueKey); thisHeader.setTransactionId(checkRequestHeader.getTransactionId()); switch (localTransactionState) &#123; case COMMIT_MESSAGE: thisHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_COMMIT_TYPE); break; case ROLLBACK_MESSAGE: thisHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_ROLLBACK_TYPE); break; case UNKNOW: thisHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_NOT_TYPE); break; default: break; &#125; String remark = null; if (exception != null) &#123; remark = &quot;checkLocalTransactionState Exception: &quot; + RemotingHelper.exceptionSimpleDesc(exception); &#125; try &#123; DefaultMQProducerImpl.this.mQClientFactory.getMQClientAPIImpl().endTransactionOneway(brokerAddr, thisHeader, remark, 3000); &#125; catch (Exception e) &#123; &#125; &#125; &#125;; this.checkExecutor.submit(request); &#125;&#125;public void endTransactionOneway(final String addr, final EndTransactionRequestHeader requestHeader, final String remark, final long timeoutMillis) throws RemotingException, MQBrokerException, InterruptedException &#123; RemotingCommand request = RemotingCommand.createRequestCommand(RequestCode.END_TRANSACTION, requestHeader); request.setRemark(remark); this.remotingClient.invokeOneway(addr, request, timeoutMillis);&#125; 延迟消息 延迟消息写入时会将延迟消息转为写入到SCHEDULE_TOPIC_XXXX的Topic中,系统内置的该Topic有 18 个队列,对应18个延迟级别. ScheduleMessageService 会每隔1s 执行一次 DeliverDelayedMessageTimerTask.executeOnTimeup 任务,将消息从延迟队列中写入正常Topic中. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107public class ScheduleMessageService extends ConfigManager &#123; private static final long FIRST_DELAY_TIME = 1000L; private static final long DELAY_FOR_A_WHILE = 100L; private static final long DELAY_FOR_A_PERIOD = 10000L; public void start() &#123; // 延迟消息服务的启动方法 if (started.compareAndSet(false, true)) &#123; this.timer = new Timer(&quot;ScheduleMessageTimerThread&quot;, true); for (Map.Entry&lt;Integer, Long&gt; entry : this.delayLevelTable.entrySet()) &#123; Integer level = entry.getKey(); Long timeDelay = entry.getValue(); Long offset = this.offsetTable.get(level); if (null == offset) &#123; offset = 0L; &#125; if (timeDelay != null) &#123;//定时执行延迟消息处理任务 this.timer.schedule(new DeliverDelayedMessageTimerTask(level, offset), FIRST_DELAY_TIME); &#125; &#125; this.timer.scheduleAtFixedRate(new TimerTask() &#123; //每隔10秒,将延迟消息持久化到硬盘中. @Override public void run() &#123; try &#123; if (started.get()) ScheduleMessageService.this.persist(); &#125; catch (Throwable e) &#123; &#125; &#125; &#125;, 10000, this.defaultMessageStore.getMessageStoreConfig().getFlushDelayOffsetInterval()); &#125; &#125;&#125;class DeliverDelayedMessageTimerTask extends TimerTask &#123; public void run() &#123; try &#123; if (isStarted()) &#123; this.executeOnTimeup(); &#125; &#125; catch (Exception e) &#123; ScheduleMessageService.this.timer.schedule(new DeliverDelayedMessageTimerTask(this.delayLevel, this.offset), DELAY_FOR_A_PERIOD); &#125; &#125; public void executeOnTimeup() &#123; // 拿到延迟级别对应的队列 ConsumeQueue cq = ScheduleMessageService.this.defaultMessageStore.findConsumeQueue(TopicValidator.RMQ_SYS_SCHEDULE_TOPIC, delayLevel2QueueId(delayLevel)); long failScheduleOffset = offset; if (cq != null) &#123; SelectMappedBufferResult bufferCQ = cq.getIndexBuffer(this.offset); if (bufferCQ != null) &#123; try &#123; long nextOffset = offset; int i = 0; ConsumeQueueExt.CqExtUnit cqExtUnit = new ConsumeQueueExt.CqExtUnit(); // 遍历每个延迟队列的消息 for (; i &lt; bufferCQ.getSize(); i += ConsumeQueue.CQ_STORE_UNIT_SIZE) &#123; long offsetPy = bufferCQ.getByteBuffer().getLong(); int sizePy = bufferCQ.getByteBuffer().getInt(); long tagsCode = bufferCQ.getByteBuffer().getLong(); if (cq.isExtAddr(tagsCode)) &#123; if (cq.getExt(tagsCode, cqExtUnit)) &#123; tagsCode = cqExtUnit.getTagsCode(); &#125; &#125; long now = System.currentTimeMillis(); long deliverTimestamp = this.correctDeliverTimestamp(now, tagsCode); nextOffset = offset + (i / ConsumeQueue.CQ_STORE_UNIT_SIZE); long countdown = deliverTimestamp - now; if (countdown &lt;= 0) &#123; //把每个延迟消息封装成一个MessageExt MessageExt msgExt = ScheduleMessageService.this.defaultMessageStore.lookMessageByOffset(offsetPy, sizePy); if (msgExt != null) &#123; try &#123; MessageExtBrokerInner msgInner = this.messageTimeup(msgExt); if (TopicValidator.RMQ_SYS_TRANS_HALF_TOPIC.equals(msgInner.getTopic())) &#123; continue; &#125; //将延迟消息写入正常消息队列,这样就能被消费者正常消费了. PutMessageResult putMessageResult = ScheduleMessageService.this.writeMessageStore.putMessage(msgInner); if (putMessageResult != null &amp;&amp; putMessageResult.getPutMessageStatus() == PutMessageStatus.PUT_OK) &#123; continue; &#125; else &#123; ScheduleMessageService.this.timer.schedule(new DeliverDelayedMessageTimerTask(this.delayLevel, nextOffset), DELAY_FOR_A_PERIOD); ScheduleMessageService.this.updateOffset(this.delayLevel, nextOffset); return; &#125; &#125; catch (Exception e) &#123; &#125; &#125; &#125; else &#123; ScheduleMessageService.this.timer.schedule(new DeliverDelayedMessageTimerTask(this.delayLevel, nextOffset), countdown); ScheduleMessageService.this.updateOffset(this.delayLevel, nextOffset); return; &#125; &#125; // end of for nextOffset = offset + (i / ConsumeQueue.CQ_STORE_UNIT_SIZE); ScheduleMessageService.this.timer.schedule(new DeliverDelayedMessageTimerTask(this.delayLevel, nextOffset), DELAY_FOR_A_WHILE); ScheduleMessageService.this.updateOffset(this.delayLevel, nextOffset); return; &#125; finally &#123; bufferCQ.release(); &#125; &#125; else &#123; // end of if (bufferCQ != null) long cqMinOffset = cq.getMinOffsetInQueue(); if (offset &lt; cqMinOffset) &#123; failScheduleOffset = cqMinOffset; &#125; &#125; &#125; // end of if (cq != null) ScheduleMessageService.this.timer.schedule(new DeliverDelayedMessageTimerTask(this.delayLevel, failScheduleOffset), DELAY_FOR_A_WHILE); &#125;&#125;","tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"http://example.com/tags/RocketMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RocketMQ","slug":"工具和中间件/消息队列/RocketMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RocketMQ/"}]},{"title":"RocketMQ-基础","date":"2019-04-23T02:08:20.000Z","path":"blog/工具和中间件/消息队列/RocketMQ/RocketMQ-基础/","text":"介绍Apache RocketMQ作为阿里开源的一款高性能、高吞吐量的分布式消息中间件. RocketMQ架构 生产者-Producer消息发布的角色,支持分布式集群方式部署.Producer 通过MQ的负载均衡模块 选择相应的 Broker集群队列 进行消息投递,投递的过程支持 快速失败 并且 低延迟. Producer启动后会 随机选择 NameServer集群中 其中一个节点建立长连接,定期从NameServer获取 Topic路由信息,并判断 当前订阅Topic存在哪些Broker上, 轮询从队列列表中选择一个队列,并向 提供Topic服务的队列所在的Master建立长连接,且 定时向Master发送心跳. Producer 完全无状态,可集群部署. 消费者-Consumer消息消费的角色,支持分布式集群方式部署.支持以 Push推,Pull拉两种模式对消息进行消费.同时支持集群方式和广播方式消费,提供实时消息订阅机制. Consumer启动后会随机选择NameServer集群中其中一个节点建立长连接,定期从NameServer获取 Topic路由信息,并判断当前订阅Topic存在哪些Broker上,并向提供Topic服务的Master、Slave建立长连接,且定时向Master、Slave发送心跳.Consumer既可从Master订阅消息,也可从Slave订阅消息,消费者在向Master拉取消息时,Master服务器会根据拉取偏移量与最大偏移量的距离,判断是否读老消息产生读I&#x2F;O,以及从服务器是否可读等因素建议下一次是从Master还是Slave拉取. NameServerNameServer一个非常简单的 Topic路由注册中心,支持Broker动态注册与发现.通常也是集群方式部署,各实例间不信息通讯. Broker 向每台NameServer注册自己的路由信息,故每个NameServer实例上都保存一份完整的路由信息.若当某个NameServer因某种原因下线,Broker仍可向其它NameServer同步其路由信息,Producer和Consumer仍可动态感知Broker路由信息. NameServer 主要包括 Broker管理和路由信息管理两个功能： Broker管理： NameServer 接受Broker集群的注册信息且保存作为路由信息基本数据.提供心跳检测机制,检查Broker是否存活； 路由信息管理,每个 NameServer 将保存关于Broker集群的整个路由信息和用于客户端查询的队列信息.然后 Producer 和 Conumser 通过 NameServer 可知道整个Broker集群的路由信息,从而进行消息的投递和消费. NameServer是一个几乎无状态节点,可集群部署,节点之间无任何信息同步.NameServer启动后监听端口,等待Broker、Producer、Consumer连接,相当于一个路由控制中心. BrokerServerBroker主要负责消息的存储、投递和查询以及服务高可用保证,为了实现这些功能,Broker包含了以下几个重要子模块. Remoting Module ：整个Broker的实体,负责处理来自clients端的请求. Client Manager ：负责管理Producer和Consumer客户端和维护Consumer的Topic订阅信息 Store Service ：提供方便简单的API接口处理消息存储到物理硬盘和查询功能. HA Service ：高可用服务,提供 Master Broker 和 Slave Broker 之间的数据同步功能. Index Service ：根据特定Message key对投递到Broker的消息进行索引服务,以提供消息的快速查询. Broker分为Master与Slave ,一个Master可对应多个Slave,一个Slave只能对应一个Master,Master与Slave对应关系通过指定相同的BrokerName不同BrokerId 来定义, BrokerId为0表示Master ,非0表示Slave .Master可部署多个.每个Broker 与NameServer集群中的所有节点建立长连接,定时注册Topic信息到所有NameServer. 虽然支持一Master多Slave,但只有 BrokerId=1 的从服务器才会参与消息读负载.Broker启动后跟所有的NameServer保持长连接,定时发送心跳包.心跳包中包含当前Broker如IP、端口等信息,以及存储所有Topic信息.注册成功后NameServer集群中就有 Topic与Broker映射关系. RocketMQ使用基本样例生产者发送消息有同步发送、异步发送和单向发送三种方式:单向发送使用 sendOneway 方法来发送消息,该方法无返回值无回调. 12345678DefaultMQProducer producer = new DefaultMQProducer(&quot;ProducerGroupName&quot;);producer.setNamesrvAddr(&quot;localhost:9876&quot;);producer.start();for (int i = 0; i &lt; 20; i++) &#123; Message msg = new Message(&quot;TopicTest&quot;, &quot;TagA&quot;, &quot;OrderID188&quot;, &quot;Hello world&quot;.getBytes(RemotingHelper.DEFAULT_CHARSET)); producer.sendOneway(msg);&#125;producer.shutdown(); 同步发送使用 send 方法同步传递消息,消息会发给集群中的一个Broker节点 123456789DefaultMQProducer producer = new DefaultMQProducer(&quot;ProducerGroupName&quot;);producer.setNamesrvAddr(&quot;localhost:9876&quot;);producer.start();for (int i = 0; i &lt; 20; i++) &#123; Message msg = new Message(&quot;TopicTest&quot;, &quot;TagA&quot;, &quot;OrderID188&quot;, &quot;Hello world&quot;.getBytes(RemotingHelper.DEFAULT_CHARSET)); SendResult sendResult = producer.send(msg); System.out.printf(&quot;%s%n&quot;, sendResult);&#125;producer.shutdown(); 由于是异步发送,这里引入了CountDownLatch,保证所有Producer发送消息的回调方法都执行完了再停止Producer服务. 12345678910111213141516171819202122232425DefaultMQProducer producer = new DefaultMQProducer(&quot;Jodie_Daily_test&quot;);producer.setNamesrvAddr(&quot;localhost:9876&quot;);producer.start();producer.setRetryTimesWhenSendAsyncFailed(0);int messageCount = 100;final CountDownLatch countDownLatch = new CountDownLatch(messageCount);for (int i = 0; i &lt; messageCount; i++) &#123; final int index = i; Message msg = new Message(&quot;TopicTest&quot;, &quot;TagA&quot;, &quot;OrderID188&quot;, &quot;Hello world&quot;.getBytes(RemotingHelper.DEFAULT_CHARSET)); producer.send(msg, new SendCallback() &#123; @Override public void onSuccess(SendResult sendResult) &#123; countDownLatch.countDown(); System.out.printf(&quot;%-10d OK %s %n&quot;, index, sendResult.getMsgId()); &#125; @Override public void onException(Throwable e) &#123; countDownLatch.countDown(); System.out.printf(&quot;%-10d Exception %s %n&quot;, index, e); e.printStackTrace(); &#125; &#125;);&#125;countDownLatch.await(5, TimeUnit.SECONDS);producer.shutdown(); 消费者消费消息有两种模式：消费者主动去Broker上拉取消息的拉模式；消费者等待Broker把消息推送过来的推模式. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394public class PullConsumer &#123; private static final Map&lt;MessageQueue, Long&gt; OFFSE_TABLE = new HashMap&lt;MessageQueue, Long&gt;(); public static void main(String[] args) throws MQClientException &#123; DefaultMQPullConsumer consumer = new DefaultMQPullConsumer(&quot;please_rename_unique_group_name_5&quot;); consumer.setNamesrvAddr(&quot;localhost:9876&quot;); consumer.start(); Set&lt;MessageQueue&gt; mqs = consumer.fetchSubscribeMessageQueues(&quot;TopicTest&quot;); for (MessageQueue mq : mqs) &#123; System.out.printf(&quot;Consume from the queue: %s%n&quot;, mq); SINGLE_MQ: while (true) &#123; try &#123; PullResult pullResult = consumer.pullBlockIfNotFound(mq, null, getMessageQueueOffset(mq), 32); System.out.printf(&quot;%s%n&quot;, pullResult); putMessageQueueOffset(mq, pullResult.getNextBeginOffset()); if (pullResult.getMsgFoundList() != null) &#123; for (MessageExt messageExt : pullResult.getMsgFoundList()) &#123; System.out.println(&quot;messageExt：&quot; + messageExt); &#125; &#125; switch (pullResult.getPullStatus()) &#123; case FOUND: break; case NO_MATCHED_MSG: break; case NO_NEW_MSG: break SINGLE_MQ; case OFFSET_ILLEGAL: break; default: break; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; consumer.shutdown(); &#125; private static long getMessageQueueOffset(MessageQueue mq) &#123; Long offset = OFFSE_TABLE.get(mq); if (offset != null) &#123; return offset; &#125; return 0; &#125; private static void putMessageQueueOffset(MessageQueue mq, long offset) &#123; OFFSE_TABLE.put(mq, offset); &#125;&#125;public class LitePullConsumerAssign &#123; public static volatile boolean running = true; public static void main(String[] args) throws Exception &#123; DefaultLitePullConsumer litePullConsumer = new DefaultLitePullConsumer(&quot;please_rename_unique_group_name&quot;); litePullConsumer.setNamesrvAddr(&quot;localhost:9876&quot;); litePullConsumer.setAutoCommit(false); litePullConsumer.start(); Collection&lt;MessageQueue&gt; mqSet = litePullConsumer.fetchMessageQueues(&quot;TopicTest&quot;); List&lt;MessageQueue&gt; list = new ArrayList&lt;&gt;(mqSet); List&lt;MessageQueue&gt; assignList = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; list.size(); i++) &#123; assignList.add(list.get(i)); &#125; litePullConsumer.assign(assignList); litePullConsumer.seek(assignList.get(0), 10); try &#123; while (running) &#123; List&lt;MessageExt&gt; messageExts = litePullConsumer.poll(); System.out.printf(&quot;%s %n&quot;, messageExts); litePullConsumer.commitSync(); &#125; &#125; finally &#123; litePullConsumer.shutdown(); &#125; &#125;&#125;public class LitePullConsumerSubscribe &#123; public static volatile boolean running = true; public static void main(String[] args) throws Exception &#123; DefaultLitePullConsumer litePullConsumer = new DefaultLitePullConsumer(&quot;lite_pull_consumer_test&quot;); litePullConsumer.setNamesrvAddr(&quot;localhost:9876&quot;); litePullConsumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET); litePullConsumer.subscribe(&quot;TopicTest&quot;, &quot;*&quot;); litePullConsumer.start(); try &#123; while (running) &#123; List&lt;MessageExt&gt; messageExts = litePullConsumer.poll(); System.out.printf(&quot;%s%n&quot;, messageExts); &#125; &#125; finally &#123; litePullConsumer.shutdown(); &#125; &#125;&#125; 消费者推模式 123456789101112DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;CID_JODIE_1&quot;);consumer.setNamesrvAddr(&quot;localhost:9876&quot;);consumer.subscribe(&quot;TopicTest&quot;, &quot;*&quot;);consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; System.out.printf(&quot;%s Receive New Messages: %s %n&quot;, Thread.currentThread().getName(), msgs); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125;&#125;);consumer.start(); 顺序消息发送者端默认情况下,消息发送者会采取 Round Robin轮询方式把消息发送到不同MessageQueue分区队列,消费者消费时也从多个MessageQueue上拉取消息,该情况下消息是不能保证顺序的.仅当一组有序的消息发送到同一个MessageQueue时,才能利用MessageQueue先进先出的特性保证这一组消息有序.而Broker中一个队列内的消息是可以保证有序的. 消费者端消费者会从多个消息队列取消息.虽然每个消息队列消息是有序的,但多个队列之间消息仍是乱序的.消费者端要保证消息有序,就需要按队列一个一个来取消息,即取完一个队列的消息后,再去取下一个队列的消息.而给Consumer注入的 MessageListenerOrderly 对象,在RocketMQ内部就会通过锁队列的方式保证消息是一个一个队列来取的. MessageListenerConcurrently 消息监听器则不会锁队列,每次都是从多个Message中取一批数据,默认不超过32条,因此也无法保证消息有序. 发送者端: 12345678910111213141516171819DefaultMQProducer producer = new DefaultMQProducer(&quot;please_rename_unique_group_name&quot;);producer.setNamesrvAddr(&quot;localhost:9876&quot;);producer.start();for (int i = 0; i &lt; 10; i++) &#123; int orderId = i; for (int j = 0; j &lt;= 5; j++) &#123; Message msg = new Message(&quot;OrderTopicTest&quot;, &quot;order_&quot; + orderId, &quot;KEY&quot; + orderId, (&quot;order_&quot; + orderId + &quot; step &quot; + j).getBytes(RemotingHelper.DEFAULT_CHARSET)); SendResult sendResult = producer.send(msg, new MessageQueueSelector() &#123; @Override public MessageQueue select(List&lt;MessageQueue&gt; mqs, Message msg, Object arg) &#123; Integer id = (Integer) arg; int index = id % mqs.size(); return mqs.get(index); &#125; &#125;, orderId); System.out.printf(&quot;%s%n&quot;, sendResult); &#125;&#125;producer.shutdown(); 消费者端: 123456789101112131415DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;please_rename_unique_group_name_3&quot;);consumer.setNamesrvAddr(&quot;localhost:9876&quot;);consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_LAST_OFFSET);consumer.subscribe(&quot;OrderTopicTest&quot;, &quot;*&quot;);consumer.registerMessageListener(new MessageListenerOrderly() &#123; @Override public ConsumeOrderlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeOrderlyContext context) &#123; context.setAutoCommit(true); for (MessageExt msg : msgs) &#123; System.out.println(&quot;收到消息内容 &quot; + new String(msg.getBody())); &#125; return ConsumeOrderlyStatus.SUCCESS; &#125;&#125;);consumer.start(); 广播消息在集群状态MessageModel.CLUSTERING 下,每条消息只会被同一个消费者组中的一个实例消费到.而广播模式则是把消息模式设置为 MessageModel.BROADCASTING ,将给所有订阅对应主题的消费者发送消息,而不管消费者是不是同一个消费者组. 12345678910111213DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;please_rename_unique_group_name_1&quot;);consumer.setNamesrvAddr(&quot;localhost:9876&quot;);consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_LAST_OFFSET);consumer.setMessageModel(MessageModel.BROADCASTING); // 将消息模式设置为BROADCASTINGconsumer.subscribe(&quot;TopicTest&quot;, &quot;*&quot;);consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; System.out.printf(&quot;%s Receive New Messages: %s %n&quot;, Thread.currentThread().getName(), msgs); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125;&#125;);consumer.start(); 延迟消息延迟时间的设置是在Message消息对象上设置一个延迟级别 setDelayTimeLevel(3) ,开源版RocketMQ中,对延迟消息并不支持任意时间的延迟设定,而是只支持18个固定的延迟级别,1到18分别对应 messageDelayLevel=1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h .这18个延迟级别也支持自行定义,不过一般情况下最好不要自定义修改. 12345678910DefaultMQProducer producer = new DefaultMQProducer(&quot;please_rename_unique_group_name&quot;); // 分组名称producer.setNamesrvAddr(&quot;localhost:9876&quot;);producer.start();for (int i = 0; i &lt; 2; i++) &#123; Message msg = new Message(&quot;TopicTest&quot;, &quot;TagA&quot;, (&quot;Hello RocketMQ &quot; + i).getBytes(RemotingHelper.DEFAULT_CHARSET)); // messageDelayLevel=1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h msg.setDelayTimeLevel(3); // 延时队列 SendResult sendResult = producer.send(msg);&#125;producer.shutdown(); 批量消息将多条消息合并成一个批量消息,一次发送出去,可减少网络IO,提升吞吐量.批量消息的使用有一定限制,这些消息 Topic和waitStoreMsgOK必须相同,且不能是延迟消息、事务消息等. 12345678910DefaultMQProducer producer = new DefaultMQProducer(&quot;BatchProducerGroupName&quot;);producer.setNamesrvAddr(&quot;localhost:9876&quot;);producer.start();String topic = &quot;BatchTest&quot;;List&lt;Message&gt; messages = new ArrayList&lt;&gt;();messages.add(new Message(topic, &quot;Tag&quot;, &quot;OrderID001&quot;, &quot;Hello world 0&quot;.getBytes()));messages.add(new Message(topic, &quot;Tag&quot;, &quot;OrderID002&quot;, &quot;Hello world 1&quot;.getBytes()));messages.add(new Message(topic, &quot;Tag&quot;, &quot;OrderID003&quot;, &quot;Hello world 2&quot;.getBytes()));producer.send(messages);producer.shutdown(); 若批量消息大于1MB 就不要用一个批次发送,而要拆分成多个批次消息发送.实际最大的限制是4194304字节约 4MB ； 123456789101112131415DefaultMQProducer producer = new DefaultMQProducer(&quot;BatchProducerGroupName&quot;);producer.setNamesrvAddr(&quot;localhost:9876&quot;);producer.start();String topic = &quot;BatchTest&quot;;List&lt;Message&gt; messages = new ArrayList&lt;&gt;(100 * 1000);for (int i = 0; i &lt; 100 * 1000; i++) &#123; messages.add(new Message(topic, &quot;Tag&quot;, &quot;OrderID&quot; + i, (&quot;Hello world &quot; + i).getBytes()));&#125;producer.send(messages);ListSplitter splitter = new ListSplitter(messages);while (splitter.hasNext()) &#123; List&lt;Message&gt; listItem = splitter.next(); producer.send(listItem);&#125;producer.shutdown(); 12345678910111213141516171819202122232425262728293031323334353637383940class ListSplitter implements Iterator&lt;List&lt;Message&gt;&gt; &#123; private final List&lt;Message&gt; messages; private int sizeLimit = 1000 * 1000; private int currIndex; public ListSplitter(List&lt;Message&gt; messages) &#123; this.messages = messages; &#125; @Override public boolean hasNext() &#123; return currIndex &lt; messages.size(); &#125; @Override public List&lt;Message&gt; next() &#123; int nextIndex = currIndex; int totalSize = 0; for (; nextIndex &lt; messages.size(); nextIndex++) &#123; Message message = messages.get(nextIndex); int tmpSize = message.getTopic().length() + message.getBody().length; Map&lt;String, String&gt; properties = message.getProperties(); for (Map.Entry&lt;String, String&gt; entry : properties.entrySet()) &#123; tmpSize += entry.getKey().length() + entry.getValue().length(); &#125; tmpSize = tmpSize + 20; //for log overhead if (tmpSize &gt; sizeLimit) &#123; if (nextIndex - currIndex == 0) &#123; nextIndex++; &#125; break; &#125; if (tmpSize + totalSize &gt; sizeLimit) &#123; break; &#125; else &#123; totalSize += tmpSize; &#125; &#125; List&lt;Message&gt; subList = messages.subList(currIndex, nextIndex); currIndex = nextIndex; return subList; &#125;&#125; 过滤消息可使用Message的 Tag属性来简单快速的过滤信息,TAG是RocketMQ中特有的一个消息属性,一个应用可以就用一个Topic,而应用中的不同业务就用TAG来区分. 1234567891011DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;please_rename_unique_group_name&quot;);consumer.setNamesrvAddr(&quot;localhost:9876&quot;);consumer.subscribe(&quot;TagFilterTest&quot;, &quot;TagA || TagC&quot;);consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; System.out.printf(&quot;%s Receive New Messages: %s %n&quot;, Thread.currentThread().getName(), msgs); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125;&#125;);consumer.start(); 一个消息只能有一个TAG ,不能满足一些比较复杂的场景. 可使用 SQL表达式来对消息进行过滤,但只有推模式的消费者可使用SQL过滤.拉模式是用不了的.RocketMQ只定义了一些基本语法来支持这个特性.也可很容易地扩展它. 数值比较： &gt;、&gt;=、&lt;、&lt;=、BETWEEN、= 字符比较： =、&lt;&gt;、IN、IS NULL、IS NOT NULL 逻辑符号： AND、OR、NOT 数值：123,3.1415；字符： &#39;abc&#39; ；必须用单引号包裹起来 特殊常量：NULL,布尔值TRUE或FALSE12345678910111213141516171819202122DefaultMQProducer producer = new DefaultMQProducer(&quot;please_rename_unique_group_name&quot;);producer.start();String[] tags = new String[]&#123;&quot;TagA&quot;, &quot;TagB&quot;, &quot;TagC&quot;&#125;;for (int i = 0; i &lt; 15; i++) &#123; Message msg = new Message(&quot;SqlFilterTest&quot;, tags[i % tags.length], (&quot;Hello RocketMQ &quot; + i).getBytes(RemotingHelper.DEFAULT_CHARSET)); msg.putUserProperty(&quot;a&quot;, String.valueOf(i)); // 自定义字段 SendResult sendResult = producer.send(msg); System.out.printf(&quot;%s%n&quot;, sendResult);&#125;producer.shutdown();// 消费者示例DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;please_rename_unique_group_name&quot;);consumer.setNamesrvAddr(&quot;localhost:9876&quot;);consumer.subscribe(&quot;SqlFilterTest&quot;, MessageSelector.bySql(&quot;(TAGS is not null and TAGS in (&#x27;TagA&#x27;, &#x27;TagB&#x27;))and (a is not null and a between 0 and 3)&quot;));consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; System.out.printf(&quot;%s Receive New Messages: %s %n&quot;, Thread.currentThread().getName(), msgs); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125;&#125;);consumer.start(); 事务消息事务消息是在分布式系统中保证最终一致性的两阶段提交的消息实现,可保证本地事务执行与消息发送两个操作的原子性,事务消息只涉及到消息发送者,对消息消费者来说没有什么特别,即只保证了分布式事务的一半.事务消息的关键是在 TransactionMQProducer 中指定了一个 TransactionListener事务监听器,该事务监听器就是事务消息的关键控制器； 123456789101112131415161718192021222324TransactionListener transactionListener = new TransactionListenerImpl();TransactionMQProducer producer = new TransactionMQProducer(&quot;please_rename_unique_group_name&quot;);producer.setNamesrvAddr(&quot;127.0.0.1:9876&quot;);ExecutorService executorService = new ThreadPoolExecutor(2, 5, 100, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(2000), new ThreadFactory() &#123; @Override public Thread newThread(Runnable r) &#123; Thread thread = new Thread(r); thread.setName(&quot;client-transaction-msg-check-thread&quot;); return thread; &#125;&#125;);producer.setExecutorService(executorService);producer.setTransactionListener(transactionListener);producer.start();String[] tags = new String[]&#123;&quot;TagA&quot;, &quot;TagB&quot;, &quot;TagC&quot;, &quot;TagD&quot;, &quot;TagE&quot;&#125;;for (int i = 0; i &lt; 10; i++) &#123; Message msg = new Message(&quot;TopicTest&quot;, tags[i % tags.length], &quot;KEY&quot; + i, (&quot;Hello RocketMQ &quot; + i).getBytes(RemotingHelper.DEFAULT_CHARSET)); msg.putUserProperty(MessageConst.PROPERTY_TRANSACTION_CHECK_TIMES, &quot;15&quot;); // 回查次数 msg.putUserProperty(MessageConst.PROPERTY_CHECK_IMMUNITY_TIME_IN_SECONDS, &quot;10000&quot;); // 回查时间 SendResult sendResult = producer.sendMessageInTransaction(msg, null); System.out.printf(&quot;%s%n&quot;, sendResult); Thread.sleep(10);&#125;producer.shutdown(); 123456789101112131415161718192021222324public class TransactionListenerImpl implements TransactionListener &#123; @Override public LocalTransactionState executeLocalTransaction(Message msg, Object arg) &#123; String tags = msg.getTags(); if (StringUtils.contains(tags, &quot;TagA&quot;)) &#123; return LocalTransactionState.COMMIT_MESSAGE; &#125; else if (StringUtils.contains(tags, &quot;TagB&quot;)) &#123; return LocalTransactionState.ROLLBACK_MESSAGE; &#125; else &#123; return LocalTransactionState.UNKNOW; &#125; &#125; @Override public LocalTransactionState checkLocalTransaction(MessageExt msg) &#123; String tags = msg.getTags(); if (StringUtils.contains(tags, &quot;TagC&quot;)) &#123; return LocalTransactionState.COMMIT_MESSAGE; &#125; else if (StringUtils.contains(tags, &quot;TagD&quot;)) &#123; return LocalTransactionState.ROLLBACK_MESSAGE; &#125; else &#123; return LocalTransactionState.UNKNOW; &#125; &#125;&#125; 事务消息不支持延迟消息和批量消息,为了避免单个消息被检查太多次而导致队列消息累积,回查次数由BrokerConfig.transactionCheckMax参数来配置,默认15次,可在 broker.conf 中覆盖,实际检查次数会在message中保存一个用户属性 MessageConst.PROPERTY_TRANSACTION_CHECK_TIMES .该属性值大于transactionCheckMax 则丢弃,默认情况下同时打印错误日志,可通过重写 AbstractTransactionCheckListener 类来修改该行为. 该用户属性值按回查次数递增,也可在Producer中自行覆盖该属性. 回查时间间隔由 BrokerConfig.transactionTimeOut 参数来配置,默认6秒,可在broker.conf中修改,也可给消息配置一个 MessageConst.PROPERTY_CHECK_IMMUNITY_TIME_IN_SECONDS 属性来给消息指定一个特定的消息回查时间. 事务性消息可能不止一次被检查或消费；提交给用户的目标主题消息可能会失败,目前以日志的记录而定.其高可用性通过RocketMQ本身的高可用性机制来保证,若希望确保事务消息不丢失、且事务完整性得到保证,建议使用同步双重写入机制. 事务消息的生产者ID不能与其他类型消息的生产者ID共享.与其他类型的消息不同,事务消息允许反向查询,MQ服务器能通过事务消息的生产者ID查询到消费者. 事务消息机制在发送消息时,会将消息转为一个 half半消息,并存入RocketMQ内部的一个 RMQ_SYS_TRANS_HALF_TOPIC ,该Topic对消费者不可见,然后执行本地事务执行commit提交,则Broker会将投递到 RMQ_SYS_TRANS_HALF_TOPIC 中的消息投递到用户指定真正Topic中,然后再投递一个表示删除的消息到 RMQ_SYS_TRANS_OP_HALF_TOPIC 中,表示当前事务已完成,若本地事务rollback 回滚,则没有投递到真实Topic的过程,只需要投递表示删除的消息到 RMQ_SYS_TRANS_OP_HALF_TOPIC ,若Commit提交或Rollback回滚失败,Broker默认每6s中回查调用 checkLocalTransaction 一次,在该回查方法中再次回滚会提交事务,默认最多15次. ACL权限控制 ACL权限控制主要为RocketMQ提供 Topic资源级别的用户访问控制,可在Client客户端通过 RPCHook 注入 AccessKey 和 SecretKey 签名；将对应的权限控制属性,包括 Topic访问权限、 IP白名单和 AccessKey 和 SecretKey 签名等,设置在 $ROCKETMQ_HOME/conf/plain_acl.yml 配置文件中.Broker端对AccessKey所拥有的权限进行校验,校验不过抛出异常. 1234567891011121314151617181920212223242526272829303132333435private static final String ACL_ACCESS_KEY = &quot;RocketMQ&quot;;private static final String ACL_SECRET_KEY = &quot;1234567&quot;;public static void producer() throws MQClientException &#123; DefaultMQProducer producer = new DefaultMQProducer(&quot;ProducerGroupName&quot;, getAclRPCHook()); producer.setNamesrvAddr(&quot;127.0.0.1:9876&quot;); producer.start(); for (int i = 0; i &lt; 128; i++) &#123; try &#123; Message msg = new Message(&quot;TopicTest&quot;, &quot;TagA&quot;, &quot;OrderID188&quot;, &quot;Hello world&quot;.getBytes(RemotingHelper.DEFAULT_CHARSET)); SendResult sendResult = producer.send(msg); System.out.printf(&quot;%s%n&quot;, sendResult); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; producer.shutdown();&#125;public static void pushConsumer() throws MQClientException &#123; DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;please_rename_unique_group_name_5&quot;, getAclRPCHook(), new AllocateMessageQueueAveragely()); consumer.setNamesrvAddr(&quot;127.0.0.1:9876&quot;); consumer.subscribe(&quot;TopicTest&quot;, &quot;*&quot;); consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET); consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; System.out.printf(&quot;%s Receive New Messages: %s %n&quot;, Thread.currentThread().getName(), msgs); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; &#125;); consumer.start();&#125;static RPCHook getAclRPCHook() &#123; return new AclClientRPCHook(new SessionCredentials(ACL_ACCESS_KEY, ACL_SECRET_KEY));&#125; Broker端具体配置信息可参见源码包下 docs/cn/acl/user_guide.md ,在 broker.conf 中通过 aclEnable=true 打开acl的标志.然后就可以用 plain_acl.yml 来进行权限配置了.且该配置文件是热加载的,修改后不用重启Broker服务. 1234567891011121314151617181920212223242526globalWhiteRemoteAddresses: # 全局白名单,不受ACL控制,通常需要将主从架构中所有节点加进来- 10.10.103.*- 192.168.0.*accounts:- accessKey: RocketMQ secretKey: 12345678 whiteRemoteAddress: admin: false defaultTopicPerm: DENY # 默认Topic访问策略是拒绝 defaultGroupPerm: SUB # 默认Group访问策略是只允许订阅 topicPerms: - topicA=DENY # topicA拒绝 - topicB=PUB|SUB # topicB允许发布和订阅消息 - topicC=SUB # topicC只允许订阅 groupPerms: # the group should convert to retry topic - groupA=DENY - groupB=PUB|SUB - groupC=SUB# 第二个账户,只要是来自192.168.1.*的IP,就可以访问所有资源- accessKey: rocketmq2 secretKey: 12345678 whiteRemoteAddress: 192.168.1.* # if it is admin, it could access all resources admin: true","tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"http://example.com/tags/RocketMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RocketMQ","slug":"工具和中间件/消息队列/RocketMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RocketMQ/"}]},{"title":"RabbitMQ-Spring集成","date":"2019-03-25T09:08:20.000Z","path":"blog/工具和中间件/消息队列/RabbitMQ/RabbitMQ-Spring集成/","text":"Spring集成12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:rabbit=&quot;http://www.springframework.org/schema/rabbit&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/rabbit http://www.springframework.org/schema/rabbit/spring-rabbit.xsd&quot;&gt; &lt;!--加载配置文件--&gt; &lt;context:property-placeholder location=&quot;classpath:rabbitmq.properties&quot;/&gt; &lt;!-- 定义rabbitmq connectionFactory --&gt; &lt;rabbit:connection-factory id=&quot;connectionFactory&quot; host=&quot;$&#123;rabbitmq.host&#125;&quot; port=&quot;$&#123;rabbitmq.port&#125;&quot; username=&quot;$&#123;rabbitmq.username&#125;&quot; password=&quot;$&#123;rabbitmq.password&#125;&quot; virtual-host=&quot;$&#123;rabbitmq.virtual-host&#125;&quot;/&gt; &lt;!-- 定义管理交换机、队列 --&gt; &lt;rabbit:admin connection-factory=&quot;connectionFactory&quot;/&gt; &lt;!-- 定义持久化队列，不存在则自动创建；不绑定到交换机则绑定到默认交换机，默认交换机类型为direct，名字为：&quot;&quot;，路由键为队列的名称 --&gt; &lt;!-- id：bean的名称，name：queue的名称，auto-declare：自动创建，durable：是否持久化，auto-delete：自动删除。最后一个消费者和该队列断开连接后，自动删除队列 --&gt; &lt;rabbit:queue id=&quot;spring_queue&quot; name=&quot;spring_queue&quot; auto-declare=&quot;true&quot; durable=&quot;false&quot;/&gt; &lt;!-- 广播；所有队列都能收到消息 --&gt; &lt;!--定义广播交换机中的持久化队列，不存在则自动创建--&gt; &lt;rabbit:queue id=&quot;spring_fanout_queue_1&quot; name=&quot;spring_fanout_queue_1&quot; auto-declare=&quot;true&quot;/&gt; &lt;!--定义广播交换机中的持久化队列，不存在则自动创建--&gt; &lt;rabbit:queue id=&quot;spring_fanout_queue_2&quot; name=&quot;spring_fanout_queue_2&quot; auto-declare=&quot;true&quot;/&gt; &lt;!--定义广播类型交换机；并绑定上述两个队列--&gt; &lt;rabbit:fanout-exchange id=&quot;spring_fanout_exchange&quot; name=&quot;spring_fanout_exchange&quot; auto-declare=&quot;true&quot;&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding queue=&quot;spring_fanout_queue_1&quot;/&gt; &lt;rabbit:binding queue=&quot;spring_fanout_queue_2&quot;/&gt; &lt;/rabbit:bindings&gt; &lt;/rabbit:fanout-exchange&gt; &lt;!-- 路由；所有队列都能收到消息 --&gt; &lt;rabbit:queue id=&quot;spring_direct_queue&quot; name=&quot;spring_direct_queue&quot; auto-declare=&quot;true&quot;/&gt; &lt;rabbit:direct-exchange id=&quot;spring_direct_exchange&quot; name=&quot;spring_direct_exchange&quot;&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding queue=&quot;spring_direct_queue&quot;/&gt; &lt;/rabbit:bindings&gt; &lt;/rabbit:direct-exchange&gt; &lt;!-- 通配符；*匹配一个单词，#匹配多个单词 --&gt; &lt;rabbit:queue id=&quot;spring_topic_queue_star&quot; name=&quot;spring_topic_queue_star&quot; auto-declare=&quot;true&quot;/&gt; &lt;rabbit:queue id=&quot;spring_topic_queue_well&quot; name=&quot;spring_topic_queue_well&quot; auto-declare=&quot;true&quot;/&gt; &lt;rabbit:queue id=&quot;spring_topic_queue_well2&quot; name=&quot;spring_topic_queue_well2&quot; auto-declare=&quot;true&quot;/&gt; &lt;!-- 声明 topic 类型的交换机 --&gt; &lt;rabbit:topic-exchange name=&quot;spring_topic_exchange&quot; id=&quot;spring_topic_exchange&quot; auto-declare=&quot;true&quot;&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding pattern=&quot;eleven.*&quot; queue=&quot;spring_topic_queue_star&quot;/&gt; &lt;rabbit:binding pattern=&quot;eleven.#&quot; queue=&quot;spring_topic_queue_well&quot;/&gt; &lt;rabbit:binding pattern=&quot;itcast.*&quot; queue=&quot;spring_topic_queue_well2&quot;/&gt; &lt;/rabbit:bindings&gt; &lt;/rabbit:topic-exchange&gt; &lt;!--定义rabbitTemplate对象操作可以在代码中方便发送消息--&gt; &lt;rabbit:template id=&quot;rabbitTemplate&quot; connection-factory=&quot;connectionFactory&quot;/&gt;&lt;/beans&gt; 12345678910111213141516171819202122@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = &quot;classpath:spring-rabbitmq-producer-basic.xml&quot;)public class ProducerBasicTest &#123; @Autowired private RabbitTemplate rabbitTemplate; @Test public void testHelloWorld() &#123; rabbitTemplate.convertAndSend(&quot;spring_queue&quot;, &quot;hello world spring...&quot;); &#125; @Test public void testFanout() &#123; rabbitTemplate.convertAndSend(&quot;spring_fanout_exchange&quot;, &quot;&quot;, &quot;spring fanout...&quot;); &#125; @Test public void testDirect() &#123; rabbitTemplate.convertAndSend(&quot;spring_direct_exchange&quot;, &quot;info&quot;, &quot;spring_direct...&quot;); &#125; @Test public void testTopic() &#123; rabbitTemplate.convertAndSend(&quot;spring_topic_exchange&quot;, &quot;eleven.hehe.haha&quot;, &quot;spring topic...&quot;); &#125;&#125; 1234567891011121314151617181920212223242526272829303132&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:rabbit=&quot;http://www.springframework.org/schema/rabbit&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/rabbit http://www.springframework.org/schema/rabbit/spring-rabbit.xsd&quot;&gt; &lt;!--加载配置文件--&gt; &lt;context:property-placeholder location=&quot;classpath:rabbitmq.properties&quot;/&gt; &lt;!-- 定义rabbitmq connectionFactory --&gt; &lt;rabbit:connection-factory id=&quot;connectionFactory&quot; host=&quot;$&#123;rabbitmq.host&#125;&quot; port=&quot;$&#123;rabbitmq.port&#125;&quot; username=&quot;$&#123;rabbitmq.username&#125;&quot; password=&quot;$&#123;rabbitmq.password&#125;&quot; virtual-host=&quot;$&#123;rabbitmq.virtual-host&#125;&quot;/&gt; &lt;bean id=&quot;springQueueListener&quot; class=&quot;com.eleven.icode.rabbitmq.SpringQueueListener&quot;/&gt; &lt;bean id=&quot;fanoutListener&quot; class=&quot;com.eleven.icode.rabbitmq.SpringQueueListener&quot;/&gt; &lt;bean id=&quot;fanoutListener2&quot; class=&quot;com.eleven.icode.rabbitmq.SpringQueueListener&quot;/&gt; &lt;bean id=&quot;topicListenerStar&quot; class=&quot;com.eleven.icode.rabbitmq.SpringQueueListener&quot;/&gt; &lt;bean id=&quot;topicListenerWell&quot; class=&quot;com.eleven.icode.rabbitmq.SpringQueueListener&quot;/&gt; &lt;bean id=&quot;topicListenerWell2&quot; class=&quot;com.eleven.icode.rabbitmq.SpringQueueListener&quot;/&gt; &lt;rabbit:listener-container connection-factory=&quot;connectionFactory&quot; auto-declare=&quot;true&quot;&gt; &lt;rabbit:listener ref=&quot;springQueueListener&quot; queue-names=&quot;spring_queue&quot;/&gt; &lt;rabbit:listener ref=&quot;fanoutListener&quot; queue-names=&quot;spring_fanout_queue_1&quot;/&gt; &lt;rabbit:listener ref=&quot;fanoutListener2&quot; queue-names=&quot;spring_fanout_queue_2&quot;/&gt; &lt;rabbit:listener ref=&quot;topicListenerStar&quot; queue-names=&quot;spring_topic_queue_star&quot;/&gt; &lt;rabbit:listener ref=&quot;topicListenerWell&quot; queue-names=&quot;spring_topic_queue_well&quot;/&gt; &lt;rabbit:listener ref=&quot;topicListenerWell2&quot; queue-names=&quot;spring_topic_queue_well2&quot;/&gt; &lt;/rabbit:listener-container&gt;&lt;/beans&gt; 123456public class SpringQueueListener implements MessageListener &#123; @Override public void onMessage(Message message) &#123; System.out.println(new String(message.getBody())); &#125;&#125; SpringBoot集成1234567spring: rabbitmq: host: localhost #主机ip port: 5672 #端口 username: eleven password: eleven virtual-host: eleven 12345678910111213141516171819202122232425262728@Configurationpublic class TopicConfig &#123; @Bean public Queue topicQ1() &#123; // 声明队列 return new Queue(&quot;topic_sb_mq_q1&quot;); &#125; @Bean public Queue topicQ2() &#123; // 声明队列 return new Queue(&quot;topic_sb_mq_q2&quot;); &#125; @Bean public TopicExchange setTopicExchange() &#123; // 声明exchange return new TopicExchange(&quot;topicExchange&quot;); &#125; @Bean public Binding bindTopicHebei1() &#123; // 声明binding，需要声明一个roytingKey return BindingBuilder.bind(topicQ1()).to(setTopicExchange()).with(&quot;changsha.*&quot;); &#125; @Bean public Binding bindTopicHebei2() &#123; return BindingBuilder.bind(topicQ2()).to(setTopicExchange()).with(&quot;#.beijing&quot;); &#125;&#125;@RabbitListener(queues = &quot;topic_sb_mq_q2&quot;)public void topicReceiveq2(String message) &#123; System.out.println(&quot;Topic模式 topic_sb_mq_q2 received message : &quot; + message);&#125;","tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://example.com/tags/RabbitMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RabbitMQ","slug":"工具和中间件/消息队列/RabbitMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/"}]},{"title":"RabbitMQ-高级特性","date":"2019-03-25T07:08:20.000Z","path":"blog/工具和中间件/消息队列/RabbitMQ/RabbitMQ-高级特性/","text":"消息可靠性投递持久化: Exchange持久化、 Queue持久化、 Message持久化; 生产方确认Confirm; 消费方确认Ack; Broker高可用; 生成端确认使用RabbitMQ时,作为消息发送方希望杜绝任何消息丢失或投递失败场景.RabbitMQ提供了 Confirm确认模式 和 Return退回模式 两种方式用来控制消息的投递可靠性. RabbitMQ整个消息投递的路径为:Producer到Rabbitmq Broker到Exchange到Queue到Consumer;消息从Producer到Exchange 则会返回一个 ConfirmCallback.消息从Exchange到Queue投递失败 则会返回一个 ReturnCallback.可利用这两个Callback控制消息的可靠性投递; 设置 ConnectionFactory 的 publisher-confirms=&quot;true&quot;开启确认模式.使用 RabbitTemplate 的 setConfirmCallback 设置回调函数.当消息发送到Exchange后回调confirm方法.在方法中判断ack,若为true则发送成功,若为false则发送失败需要处理. 设置 ConnectionFactory 的 publisher-returns=&quot;true&quot;开启退回模式.使用 RabbitTemplate 的 setReturnCallback 设置退回函数,当消息从Exchange路由到Queue失败后,若设置了 rabbitTemplate.setMandatory(true) 参数,则会将消息退回给Producer并 执行回调函数returnedMessage. 消费端确认ack指 Acknowledge 确认,表示 消费端收到消息后的确认方式,有三种确认方式: 自动确认:acknowledge=&quot;none&quot; 手动确认:acknowledge=&quot;manual&quot; 根据异常情况确认:acknowledge=&quot;auto&quot; 自动确认是指当消息一旦被Consumer接收到,则自动确认收到,并将相应message从RabbitMQ消息缓存中移除.但在实际业务处理中,很可能消息接收到,业务处理出现异常,则该消息会丢失.若设置了手动确认方式,则需要在业务处理成功后,调用 channel.basicAck()手动签收,若出现异常则调用 channel.basicNack() 方法,让其自动重新发送消息. 123456789101112131415&lt;!--加载配置文件--&gt;&lt;context:property-placeholder location=&quot;classpath:rabbitmq.properties&quot;/&gt;&lt;!-- 定义rabbitmq connectionFactory --&gt;&lt;rabbit:connection-factory id=&quot;connectionFactory&quot; host=&quot;$&#123;rabbitmq.host&#125;&quot; port=&quot;$&#123;rabbitmq.port&#125;&quot; username=&quot;$&#123;rabbitmq.username&#125;&quot; password=&quot;$&#123;rabbitmq.password&#125;&quot; virtual-host=&quot;$&#123;rabbitmq.virtual-host&#125;&quot; publisher-confirms=&quot;true&quot; publisher-returns=&quot;true&quot;/&gt;&lt;!--定义管理交换机、队列--&gt;&lt;rabbit:admin connection-factory=&quot;connectionFactory&quot;/&gt;&lt;!--定义rabbitTemplate对象操作可以在代码中方便发送消息--&gt;&lt;rabbit:template id=&quot;rabbitTemplate&quot; connection-factory=&quot;connectionFactory&quot;/&gt;&lt;!--消息可靠性投递（生产端）--&gt;&lt;rabbit:queue id=&quot;test_queue_confirm&quot; name=&quot;test_queue_confirm&quot;/&gt;&lt;rabbit:direct-exchange name=&quot;test_exchange_confirm&quot;&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding queue=&quot;test_queue_confirm&quot; key=&quot;confirm&quot;/&gt; &lt;/rabbit:bindings&gt;&lt;/rabbit:direct-exchange&gt; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = &quot;classpath:spring-rabbitmq-producer.xml&quot;)public class ProducerTest &#123; @Autowired private RabbitTemplate rabbitTemplate; @Test public void testConfirm() &#123; //测试Confirm模式 //定义回调 rabbitTemplate.setConfirmCallback(new RabbitTemplate.ConfirmCallback() &#123; /** * @param correlationData 相关配置信息 * @param ack exchange交换机 是否成功收到了消息.true 成功,false代表失败 * @param cause 失败原因 */ @Override public void confirm(CorrelationData correlationData, boolean ack, String cause) &#123; System.out.println(&quot;confirm方法被执行了....&quot; + correlationData.getId()); // ack为true表示消息已经到达交换机 if (ack) &#123; // 接收成功 System.out.println(&quot;接收成功消息&quot; + cause); &#125; else &#123; // 接收失败 System.out.println(&quot;接收失败消息&quot; + cause); // 做一些处理,让消息再次发送. &#125; &#125; &#125;); // 进行消息发送 for (int i = 0; i &lt; 5; i++) &#123; rabbitTemplate.convertAndSend(&quot;test_exchange_confirm&quot;, &quot;confirm&quot;, &quot;message Confirm...&quot;); &#125; &#125; @Test public void testReturn() &#123; // 测试return模式 // 设置交换机处理失败消息的模式,为true时消息到达不了队列时,会将消息重新返回给生产者 rabbitTemplate.setMandatory(true); // 定义回调 rabbitTemplate.setReturnCallback(new RabbitTemplate.ReturnCallback() &#123; /** * @param message 消息对象 * @param replyCode 错误码 * @param replyText 错误信息 * @param exchange 交换机 * @param routingKey 路由键 */ @Override public void returnedMessage(Message message, int replyCode, String replyText, String exchange, String routingKey) &#123; System.out.println(&quot;return 执行了....&quot;); System.out.println(&quot;message:&quot; + message); System.out.println(&quot;replyCode:&quot; + replyCode); System.out.println(&quot;replyText:&quot; + replyText); System.out.println(&quot;exchange:&quot; + exchange); System.out.println(&quot;routingKey:&quot; + routingKey); &#125; &#125;); // 进行消息发送 rabbitTemplate.convertAndSend(&quot;test_exchange_confirm&quot;, &quot;confirm&quot;, &quot;message return...&quot;); &#125;&#125; 12345&lt;!--定义监听器容器 acknowledge=&quot;manual&quot;:手动签收 prefetch=&quot;1&quot;:每次抓取多少条消息 --&gt;&lt;!--定义监听器容器 acknowledge=&quot;manual&quot; prefetch=&quot;1&quot; --&gt;&lt;rabbit:listener-container connection-factory=&quot;connectionFactory&quot; acknowledge=&quot;manual&quot; prefetch=&quot;1&quot;&gt; &lt;rabbit:listener ref=&quot;ackListener&quot; queue-names=&quot;test_queue_confirm&quot;&gt;&lt;/rabbit:listener&gt;&lt;/rabbit:listener&gt;&lt;/rabbit:listener-container&gt; 12345678910111213141516171819202122@Componentpublic class AckListener implements ChannelAwareMessageListener &#123; @Override public void onMessage(Message message, Channel channel) throws Exception &#123; //1、获取消息的id long deliveryTag = message.getMessageProperties().getDeliveryTag(); try &#123; //2、获取消息 System.out.println(&quot;message:&quot; + new String(message.getBody())); //3、进行业务处理 System.out.println(&quot;=====进行业务处理====&quot;); //模拟出现异常 int i = 5/0; //4、进行消息签收 channel.basicAck(deliveryTag, false); System.out.println(&quot;收到了消息:&quot; + deliveryTag); &#125; catch (Exception e) &#123; //拒绝签收,第三个参数：requeue：重回队列.如果设置为true,则消息重新回到queue,broker会重新发送该消息给消费端 channel.basicNack(deliveryTag, false, true); &#125; &#125;&#125; 消费端限流在 &lt;rabbit:listener-container&gt; 中配置 prefetch 属性设置 消费端一次拉取多少消息 ,消费端的确认模式一定为手动确认 acknowledge=&quot;manual&quot; . TTL当消息达到存活时间后,还未被消费会被自动清除,RabbitMQ可 对消息设置过期时间,也可 对整个队列设置过期时间. 设置队列过期时间使用参数 x-message-ttl 单位 ms毫秒,会对整个队列消息统一过期.设置消息过期时间使用参数 expiration 单位 ms毫秒,当该消息在 队列头部 时,会单独判断这一消息是否过期.若 两者都进行了设置以时间短的为准. 123456789101112&lt;rabbit:queue name=&quot;test_queue_ttl&quot; id=&quot;test_queue_ttl&quot;&gt; &lt;!--设置queue的参数--&gt; &lt;rabbit:queue-arguments&gt; &lt;!--x-message-ttl指队列的过期时间--&gt; &lt;entry key=&quot;x-message-ttl&quot; value=&quot;10000&quot; value-type=&quot;java.lang.Integer&quot;/&gt; &lt;/rabbit:queue-arguments&gt;&lt;/rabbit:queue&gt;&lt;rabbit:topic-exchange name=&quot;test_exchange_ttl&quot;&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding pattern=&quot;ttl.#&quot; queue=&quot;test_queue_ttl&quot;/&gt; &lt;/rabbit:bindings&gt;&lt;/rabbit:topic-exchange&gt; 死信队列死信队列DXL.Dead Letter Exchange死信交换机,当消息成为Dead Message后,可被 重新发送到另一个交换机,这个交换机就是 DLX.消息成为死信的 三种情况： 队列消息长度到达限制; 消费者拒接消费消息,basicNack/basicReject且不把消息重新放入原目标队列,requeue=false; 原队列存在消息过期设置,消息到达超时时间未被消费; 死信交换机和死信队列和普通的没有区别，当消息成为死信后，若该队列绑定了死信交换机，则消息会被死信交换机重新路由到死信队列。可通过给队列设置 x-dead-letter-exchange 和 x-dead-letter-routing-key 参数来绑定死信交换机; 12345678910111213141516171819202122232425262728293031323334&lt;!-- 1. 声明正常的队列(test_queue_dlx)和交换机(test_exchange_dlx) 2. 声明死信队列(queue_dlx)和死信交换机(exchange_dlx) 3. 正常队列绑定死信交换机 设置两个参数： * x-dead-letter-exchange：死信交换机名称 * x-dead-letter-routing-key：发送给死信交换机的routingkey--&gt;&lt;!-- 1. 声明正常的队列(test_queue_dlx)和交换机(test_exchange_dlx) --&gt;&lt;rabbit:queue name=&quot;test_queue_dlx&quot; id=&quot;test_queue_dlx&quot;&gt; &lt;!--3. 正常队列绑定死信交换机--&gt; &lt;rabbit:queue-arguments&gt; &lt;!--3.1 x-dead-letter-exchange：死信交换机名称--&gt; &lt;entry key=&quot;x-dead-letter-exchange&quot; value=&quot;exchange_dlx&quot;/&gt; &lt;!--3.2 x-dead-letter-routing-key：发送给死信交换机的routingkey--&gt; &lt;entry key=&quot;x-dead-letter-routing-key&quot; value=&quot;dlx.hehe&quot;/&gt; &lt;!--4.1 设置队列的过期时间 ttl--&gt; &lt;entry key=&quot;x-message-ttl&quot; value=&quot;10000&quot; value-type=&quot;java.lang.Integer&quot;/&gt; &lt;!--4.2 设置队列的长度限制 max-length--&gt; &lt;entry key=&quot;x-max-length&quot; value=&quot;10&quot; value-type=&quot;java.lang.Integer&quot;/&gt; &lt;/rabbit:queue-arguments&gt;&lt;/rabbit:queue&gt;&lt;rabbit:topic-exchange name=&quot;test_exchange_dlx&quot;&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding pattern=&quot;test.dlx.#&quot; queue=&quot;test_queue_dlx&quot;/&gt; &lt;/rabbit:bindings&gt;&lt;/rabbit:topic-exchange&gt;&lt;!-- 2. 声明死信队列(queue_dlx)和死信交换机(exchange_dlx) --&gt;&lt;rabbit:queue name=&quot;queue_dlx&quot; id=&quot;queue_dlx&quot;/&gt;&lt;rabbit:topic-exchange name=&quot;exchange_dlx&quot;&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding pattern=&quot;dlx.#&quot; queue=&quot;queue_dlx&quot;/&gt; &lt;/rabbit:bindings&gt;&lt;/rabbit:topic-exchange&gt; 1234&lt;rabbit:listener-container connection-factory=&quot;connectionFactory&quot; acknowledge=&quot;manual&quot; prefetch=&quot;1&quot;&gt; &lt;!--定义监听器，监听正常队列--&gt; &lt;rabbit:listener ref=&quot;dlxListener&quot; queue-names=&quot;test_queue_dlx&quot;&gt;&lt;/rabbit:listener&gt;&lt;/rabbit:listener&gt;&lt;/rabbit:listener-container&gt; 123456789101112131415161718192021@Componentpublic class DlxListener implements ChannelAwareMessageListener &#123; @Override public void onMessage(Message message, Channel channel) throws Exception &#123; long deliveryTag = message.getMessageProperties().getDeliveryTag(); try &#123; //1.接收转换消息 System.out.println(new String(message.getBody())); //2. 处理业务逻辑 System.out.println(&quot;处理业务逻辑...&quot;); //int i = 3/0;//出现错误 //3. 手动签收 channel.basicAck(deliveryTag, true); &#125; catch (Exception e) &#123; //e.printStackTrace(); System.out.println(&quot;出现异常，拒绝接受&quot;); //4.拒绝签收，不重回队列 requeue=false channel.basicNack(deliveryTag, true, false); &#125; &#125;&#125; 延迟队列延迟队列即消息进入队列后不会立即被消费，只有到达指定时间后才会被消费，在RabbitMQ中并未提供延迟队列功能。但是可使用 TTL+死信队列 组合实现延迟队列的效果 123456789101112131415161718192021222324252627&lt;!-- 延迟队列： 1. 定义正常交换机（order_exchange）和队列(order_queue) 2. 定义死信交换机（order_exchange_dlx）和队列(order_queue_dlx) 3. 绑定，设置正常队列过期时间为30分钟--&gt;&lt;!-- 1. 定义正常交换机（order_exchange）和队列(order_queue)--&gt;&lt;rabbit:queue id=&quot;order_queue&quot; name=&quot;order_queue&quot;&gt; &lt;!--3. 绑定，设置正常队列过期时间为30分钟--&gt; &lt;rabbit:queue-arguments&gt; &lt;entry key=&quot;x-dead-letter-exchange&quot; value=&quot;order_exchange_dlx&quot;/&gt; &lt;entry key=&quot;x-dead-letter-routing-key&quot; value=&quot;dlx.order.cancel&quot;/&gt; &lt;entry key=&quot;x-message-ttl&quot; value=&quot;10000&quot; value-type=&quot;java.lang.Integer&quot;/&gt; &lt;/rabbit:queue-arguments&gt;&lt;/rabbit:queue&gt;&lt;rabbit:topic-exchange name=&quot;order_exchange&quot;&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding pattern=&quot;order.#&quot; queue=&quot;order_queue&quot;/&gt; &lt;/rabbit:bindings&gt;&lt;/rabbit:topic-exchange&gt;&lt;!--2. 定义死信交换机（order_exchange_dlx）和队列(order_queue_dlx)--&gt;&lt;rabbit:queue id=&quot;order_queue_dlx&quot; name=&quot;order_queue_dlx&quot;/&gt;&lt;rabbit:topic-exchange name=&quot;order_exchange_dlx&quot;&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding pattern=&quot;dlx.order.#&quot; queue=&quot;order_queue_dlx&quot;/&gt; &lt;/rabbit:bindings&gt;&lt;/rabbit:topic-exchange&gt; 1234&lt;rabbit:listener-container connection-factory=&quot;connectionFactory&quot; acknowledge=&quot;manual&quot; prefetch=&quot;1&quot;&gt; &lt;!--延迟队列效果实现：一定要监听的是死信队列！！！--&gt; &lt;rabbit:listener ref=&quot;orderListener&quot; queue-names=&quot;order_queue_dlx&quot;&gt;&lt;/rabbit:listener&gt;&lt;/rabbit:listener-container&gt; 消息幂等性保障可通过版本号实现乐观锁的方式优化; 消息积压消费者宕机积压、消费者消费能力不足积压、生产者者流量太大等都可能导致消息积压;可通过上线更多的消费者，进行正常消费上线专门的队列消费服务，将消息先批量取出来记录数据库再慢慢处理;","tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://example.com/tags/RabbitMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RabbitMQ","slug":"工具和中间件/消息队列/RabbitMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/"}]},{"title":"RabbitMQ-topic模式","date":"2019-03-25T03:08:20.000Z","path":"blog/工具和中间件/消息队列/RabbitMQ/RabbitMQ-topic模式/","text":"pom.xml123456789101112131415161718192021&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;artifactId&gt;rabbitmq&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;rabbitmq&lt;/name&gt; &lt;description&gt;rabbitmq&lt;/description&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt; &lt;artifactId&gt;amqp-client&lt;/artifactId&gt; &lt;version&gt;3.6.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;4.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; TestProducer.java分别在 四个路由：”usa.news”, “usa.weather”, “europe.news”, “europe.weather” 上发布 “美国新闻”, “美国天气”, “欧洲新闻”, “欧洲天气”. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package cn.peach;import java.io.IOException;import java.util.concurrent.TimeoutException; import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory; /** * 消息生成者 */public class TestProducer &#123; public final static String EXCHANGE_NAME=&quot;topics_exchange&quot;; public static void main(String[] args) throws IOException, TimeoutException &#123; RabbitMQUtil.checkServer(); //创建连接工厂 ConnectionFactory factory = new ConnectionFactory(); //设置RabbitMQ相关信息 factory.setHost(&quot;localhost&quot;); //创建一个新的连接 Connection connection = factory.newConnection(); //创建一个通道 Channel channel = connection.createChannel(); channel.exchangeDeclare(EXCHANGE_NAME, &quot;topic&quot;); String[] routing_keys = new String[] &#123; &quot;usa.news&quot;, &quot;usa.weather&quot;, &quot;europe.news&quot;, &quot;europe.weather&quot; &#125;; String[] messages = new String[] &#123; &quot;美国新闻&quot;, &quot;美国天气&quot;, &quot;欧洲新闻&quot;, &quot;欧洲天气&quot; &#125;; for (int i = 0; i &lt; routing_keys.length; i++) &#123; String routingKey = routing_keys[i]; String message = messages[i]; channel.basicPublish(EXCHANGE_NAME, routingKey, null, message .getBytes()); System.out.printf(&quot;发送消息到路由：%s, 内容是: %s%n &quot;, routingKey,message); &#125; //关闭通道和连接 channel.close(); connection.close(); &#125;&#125; TestCustomer4USA.java专门用于接受 usa.* 消息 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package cn.peach;import java.io.IOException;import java.util.concurrent.TimeoutException; import com.rabbitmq.client.AMQP;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import com.rabbitmq.client.Consumer;import com.rabbitmq.client.DefaultConsumer;import com.rabbitmq.client.Envelope; import cn.hutool.core.util.RandomUtil; public class TestCustomer4USA &#123; public final static String EXCHANGE_NAME=&quot;topics_exchange&quot;; public static void main(String[] args) throws IOException, TimeoutException &#123; //为当前消费者取名称 String name = &quot;consumer-usa&quot;; // 创建连接工厂 ConnectionFactory factory = new ConnectionFactory(); //设置RabbitMQ地址 factory.setHost(&quot;localhost&quot;); //创建一个新的连接 Connection connection = factory.newConnection(); //创建一个通道 Channel channel = connection.createChannel(); //交换机声明（参数为：交换机名称；交换机类型） channel.exchangeDeclare(EXCHANGE_NAME,&quot;topic&quot;); //获取一个临时队列 String queueName = channel.queueDeclare().getQueue(); //接受 USA 信息 channel.queueBind(queueName, EXCHANGE_NAME, &quot;usa.*&quot;); System.out.println(name +&quot; 等待接受消息&quot;); //DefaultConsumer类实现了Consumer接口，通过传入一个频道， // 告诉服务器我们需要那个频道的消息，如果频道中有消息，就会执行回调函数handleDelivery Consumer consumer = new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; String message = new String(body, &quot;UTF-8&quot;); System.out.println(name + &quot; 接收到消息 &#x27;&quot; + message + &quot;&#x27;&quot;); &#125; &#125;; //自动回复队列应答 -- RabbitMQ中的消息确认机制 channel.basicConsume(queueName, true, consumer); &#125;&#125; TestCustomer4News.java专门用于接受 *.news 消息 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package cn.peach;import java.io.IOException;import java.util.concurrent.TimeoutException; import com.rabbitmq.client.AMQP;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import com.rabbitmq.client.Consumer;import com.rabbitmq.client.DefaultConsumer;import com.rabbitmq.client.Envelope; import cn.hutool.core.util.RandomUtil; public class TestCustomer4News &#123; public final static String EXCHANGE_NAME=&quot;topics_exchange&quot;; public static void main(String[] args) throws IOException, TimeoutException &#123; //为当前消费者取名称 String name = &quot;consumer-news&quot;; // 创建连接工厂 ConnectionFactory factory = new ConnectionFactory(); //设置RabbitMQ地址 factory.setHost(&quot;localhost&quot;); //创建一个新的连接 Connection connection = factory.newConnection(); //创建一个通道 Channel channel = connection.createChannel(); //交换机声明（参数为：交换机名称；交换机类型） channel.exchangeDeclare(EXCHANGE_NAME,&quot;topic&quot;); //获取一个临时队列 String queueName = channel.queueDeclare().getQueue(); //接受 USA 信息 channel.queueBind(queueName, EXCHANGE_NAME, &quot;*.news&quot;); System.out.println(name +&quot; 等待接受消息&quot;); //DefaultConsumer类实现了Consumer接口，通过传入一个频道， // 告诉服务器我们需要那个频道的消息，如果频道中有消息，就会执行回调函数handleDelivery Consumer consumer = new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; String message = new String(body, &quot;UTF-8&quot;); System.out.println(name + &quot; 接收到消息 &#x27;&quot; + message + &quot;&#x27;&quot;); &#125; &#125;; //自动回复队列应答 -- RabbitMQ中的消息确认机制 channel.basicConsume(queueName, true, consumer); &#125;&#125; 运行效果先运行 TestCustomer4USA 专门用于接受美国专题消息再运行 TestCustomer4News 专门用于接受新闻专题消息最后运行 TestProducer ，分别在 四个路由：”usa.news”, “usa.weather”, “europe.news”, “europe.weather” 上发布 “美国新闻”, “美国天气”, “欧洲新闻”, “欧洲天气”.于是就能在消费者端看到 不同的主题收到对应的消息了。","tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://example.com/tags/RabbitMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RabbitMQ","slug":"工具和中间件/消息队列/RabbitMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/"}]},{"title":"ActiveMQ-Spring集成","date":"2019-03-24T09:09:03.000Z","path":"blog/工具和中间件/消息队列/Activemq/ActiveMQ-Spring集成/","text":"spring 模式前面的是 jms 模式，下面采用 spring 模式使用 activeMQ。 JMS即Java消息服务(Java Message Service)应用程序接口,是一个Java平台中关于面向消息中间件(MOM)的API,用于在两个应用程序之间,或分布式系统中发送消息,进行异步通信。 点到点（point to point）。基于消息队列，消息产生者将消息发送到队列中。消息消费者可以将自身与队列连接，以倾听消息。当消息到达队列时，客户可以从队列中取走，并给出响应。消息只能发送到一个队列，只能由一个消费者使用。消费者可以过滤消息，以便获得希望获得的消息。 出版和订阅（publish&#x2F;subscribe）。消息生产者将消息发送到一个话题（topic），注册到此话题的消费者都能接收到这些消息。这种情况下，许多消费者都能接收到同样的消息。 pom.xml引入 activemq, spring , junit ,hutool 1234567891011121314151617181920212223242526272829303132333435&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;artifactId&gt;activemq&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;activemq&lt;/name&gt; &lt;description&gt;activemq&lt;/description&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-client&lt;/artifactId&gt; &lt;version&gt;5.13.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jms&lt;/artifactId&gt; &lt;version&gt;4.3.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;4.2.4.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.9&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;4.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; spring_jms.xml在 resources下创建 spring_jms.xml 文件，这里其实就是对 activemq 的相关配置。 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:dubbo=&quot;http://code.alibabatech.com/schema/dubbo&quot; xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;context:component-scan base-package=&quot;cn.peach&quot;&gt;&lt;/context:component-scan&gt; &lt;!-- 真正可以产生Connection的ConnectionFactory，由对应的 JMS服务厂商提供--&gt; &lt;bean id=&quot;targetConnectionFactory&quot; class=&quot;org.apache.activemq.ActiveMQConnectionFactory&quot;&gt; &lt;property name=&quot;brokerURL&quot; value=&quot;tcp://127.0.0.1:61616&quot;/&gt; &lt;/bean&gt; &lt;!-- Spring用于管理真正的ConnectionFactory的ConnectionFactory --&gt; &lt;bean id=&quot;connectionFactory&quot; class=&quot;org.springframework.jms.connection.SingleConnectionFactory&quot;&gt; &lt;!-- 目标ConnectionFactory对应真实的可以产生JMS Connection的ConnectionFactory --&gt; &lt;property name=&quot;targetConnectionFactory&quot; ref=&quot;targetConnectionFactory&quot;/&gt; &lt;/bean&gt; &lt;!-- Spring提供的JMS工具类，它可以进行消息发送、接收等 --&gt; &lt;bean id=&quot;jmsTemplate&quot; class=&quot;org.springframework.jms.core.JmsTemplate&quot;&gt; &lt;!-- 这个connectionFactory对应的是我们定义的Spring提供的那个ConnectionFactory对象 --&gt; &lt;property name=&quot;connectionFactory&quot; ref=&quot;connectionFactory&quot;/&gt; &lt;/bean&gt; &lt;!--这个是队列目的地, ActiveMQQueue 就表示队列模式。 如果要用主题模式就改成 ActiveMQTopic就行了 --&gt; &lt;bean id=&quot;textDestination&quot; class=&quot;org.apache.activemq.command.ActiveMQQueue&quot;&gt; &lt;constructor-arg value=&quot;queue_style&quot;/&gt; &lt;/bean&gt; &lt;!-- 我的监听类 --&gt; &lt;bean id=&quot;myMessageListener&quot; class=&quot;cn.peach.MyMessageListener&quot;&gt;&lt;/bean&gt; &lt;!-- 消息监听容器，会伴随spring的启动 --&gt; &lt;bean class=&quot;org.springframework.jms.listener.DefaultMessageListenerContainer&quot;&gt; &lt;property name=&quot;connectionFactory&quot; ref=&quot;connectionFactory&quot; /&gt; &lt;property name=&quot;destination&quot; ref=&quot;textDestination&quot; /&gt; &lt;property name=&quot;messageListener&quot; ref=&quot;myMessageListener&quot; /&gt; &lt;/bean&gt;&lt;/beans&gt; Producer.java - 生产者类12345678910111213141516171819202122232425262728293031package cn.peach; import javax.jms.Destination;import javax.jms.JMSException;import javax.jms.Message;import javax.jms.Session; import org.springframework.beans.factory.annotation.Autowired;import org.springframework.jms.core.JmsTemplate;import org.springframework.jms.core.MessageCreator;import org.springframework.stereotype.Component; @Componentpublic class Producer &#123; @Autowired private JmsTemplate jmsTemplate; @Autowired private Destination textDestination; public void sendTextMessage(final String text)&#123; jmsTemplate.send(textDestination, new MessageCreator() &#123; public Message createMessage(Session session) throws JMSException &#123; return session.createTextMessage(text); &#125; &#125;); &#125; &#125; TestProducer.java测试生产者，发送100条消息 123456789101112131415161718192021222324252627package cn.peach;import org.junit.Before;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.test.context.ContextConfiguration;import org.springframework.test.context.junit4.SpringJUnit4ClassRunner; @RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations=&quot;classpath:spring_jms.xml&quot;)public class TestProducer &#123; @Autowired private Producer producer; @Before public void checkServer() &#123; // check ActiveMQ 服务器是否启动 &#125; @Test public void testSend()&#123; for (int i = 0; i &lt; 100; i++) &#123; producer.sendTextMessage(&quot;消息 &quot; + i); &#125; &#125;&#125; MyMessageListener.java - 监听类监听类，用于获取新的消息 12345678910111213141516171819202122232425package cn.peach; import javax.jms.JMSException;import javax.jms.Message;import javax.jms.MessageListener;import javax.jms.TextMessage; import cn.hutool.core.util.RandomUtil; public class MyMessageListener implements MessageListener &#123; String name = &quot;consumer-&quot;+ RandomUtil.randomString(5); public MyMessageListener() &#123; System.out.println(name + &quot; started&quot;); &#125; public void onMessage(Message message) &#123; TextMessage textMessage=(TextMessage)message; try &#123; System.out.println(name+&quot; 接收到消息：&quot;+textMessage.getText()); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125;&#125; TestConsumer.java - 消费者测试类消费者测试类，他其实什么都没做。 虽然它什么都没做，但是因为他是运行在 spring框架下的测试，所以一旦启动，就会导致一个 新的 DefaultMessageListenerContainer 被启动，间接地导致 一个 新的 MyMessageListener 被启动。 于是也就充当了消费者的角色了。其中的 1System.in.read(); 是为了这个测试类不退出，可以一直监听用。 与这个类似的， TestProducer 类的启动，也会导致一个 MyMessageListener 被启动，所以 TestProducer 本身既是一个 生产者，也是一个 消费者。 12345678910111213141516171819202122232425262728package cn.peach; import java.io.IOException; import org.junit.Before;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.test.context.ContextConfiguration;import org.springframework.test.context.junit4.SpringJUnit4ClassRunner; @RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations=&quot;classpath:spring_jms.xml&quot;)public class TestConsumer &#123; @Before public void checkServer() &#123; // check ActiveMQ 服务器是否启动.checkServer(); &#125; @Test public void test()&#123; try &#123; //写这个是为了不让当前测试退出。 因为 spring的配置， MyMessageListener 会自动启动 System.in.read(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; 启动测试先运行 1次 TestConsumer, 然后运行 1次 TestProducer。可以看到如图所示的，有两个消费者在瓜分 消息。 明明只启动了一次TestConsumer ，为什么会有两个消费者呢？因为采用 spring 模式， 会用到一个叫做 消息监听容器的类： DefaultMessageListenerContainer， 它会伴随 spring的启动而自动启动。 所以无论是 TestConsumer，还是 TestProducer 里面都会有它了。 模式切换当前例子是队列模式，那么要做主题模式怎么办呢?修改 spring_jms 就可以了，对了 queue_style 最好也修改成 topic_style","tags":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"http://example.com/tags/ActiveMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"Activemq","slug":"工具和中间件/消息队列/Activemq","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Activemq/"}]},{"title":"ActiveMQ-主题模式","date":"2019-03-23T04:08:20.000Z","path":"blog/工具和中间件/消息队列/Activemq/ActiveMQ-主题模式/","text":"主题模式主题模式就是每个订阅了的消费者，都可以获取所有的消息，而不像队列模式那样要争抢。 pom.xml导入两个包，一个是 activemq ，另一个是 hutool jar包 123456789101112131415161718192021&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;artifactId&gt;activemq&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;activemq&lt;/name&gt; &lt;description&gt;activemq&lt;/description&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-all&lt;/artifactId&gt; &lt;version&gt;5.15.9&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;4.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; TestProducer.java和队列模式的 TestProducer几乎一模一样，只有一个地方有区别:Destination destination=session.createTopic(topicName);这里是 createTopic 而 队列模式是 createQueue 12345678910111213141516171819202122232425262728293031323334353637383940414243package cn.peach; import javax.jms.Connection;import javax.jms.ConnectionFactory;import javax.jms.Destination;import javax.jms.JMSException;import javax.jms.MessageProducer;import javax.jms.Session;import javax.jms.TextMessage; import org.apache.activemq.ActiveMQConnectionFactory; public class TestProducer &#123; //服务地址，端口默认61616 private static final String url=&quot;tcp://127.0.0.1:61616&quot;; //这次发送的消息名称 private static final String topicName=&quot;topic_style&quot;; public static void main(String[] args) throws JMSException &#123; //1.创建ConnectiongFactory,绑定地址 ConnectionFactory factory=new ActiveMQConnectionFactory(url); //2.创建Connection Connection connection= factory.createConnection(); //3.启动连接 connection.start(); //4.创建会话 Session session=connection.createSession(false, Session.AUTO_ACKNOWLEDGE); //5.创建一个目标 (主题类型) Destination destination=session.createTopic(topicName); //6.创建一个生产者 MessageProducer producer=session.createProducer(destination); for (int i = 0; i &lt; 100; i++) &#123; //7.创建消息 TextMessage textMessage=session.createTextMessage(&quot;主题消息-&quot;+i); //8.发送消息 producer.send(textMessage); System.out.println(&quot;发送：&quot;+textMessage.getText()); &#125; //7. 关闭连接 connection.close(); &#125;&#125; TestConsumer.java和队列模式的 TestProducer几乎一模一样，只有一个地方有区别：Destination destination=session.createTopic(topicName);这里是 createTopic 而 队列模式是 createQueue 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package cn.peach.topic; import javax.jms.Connection;import javax.jms.ConnectionFactory;import javax.jms.Destination;import javax.jms.JMSException;import javax.jms.Message;import javax.jms.MessageConsumer;import javax.jms.MessageListener;import javax.jms.Session;import javax.jms.TextMessage; import org.apache.activemq.ActiveMQConnectionFactory;import cn.hutool.core.util.RandomUtil;/** * 订阅者 * @author root * */public class TestConsumer &#123; //服务地址，端口默认61616 private static final String url=&quot;tcp://127.0.0.1:61616&quot;; //这次消费的消息名称 private static final String topicName=&quot;topic_style&quot;; //消费者有可能是多个，为了区分不同的消费者，为其创建随机名称 private static final String consumerName=&quot;consumer-&quot; + RandomUtil.randomString(5); public static void main(String[] args) throws JMSException &#123; //1.创建ConnectiongFactory,绑定地址 ConnectionFactory factory=new ActiveMQConnectionFactory(url); //2.创建Connection Connection connection= factory.createConnection(); //3.启动连接 connection.start(); //4.创建会话 Session session=connection.createSession(false, Session.AUTO_ACKNOWLEDGE); //5.创建一个目标 （主题类型） Destination destination=session.createTopic(topicName); //6.创建一个消费者 MessageConsumer consumer=session.createConsumer(destination); //7.创建一个监听器 consumer.setMessageListener(new MessageListener() &#123; public void onMessage(Message arg0) &#123; // TODO Auto-generated method stub TextMessage textMessage=(TextMessage)arg0; try &#123; System.out.println(consumerName +&quot; 接收消息：&quot;+textMessage.getText()); &#125; catch (JMSException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; &#125;); //8. 因为不知道什么时候有，所以没法主动关闭，就不关闭了，一直处于监听状态 //connection.close(); &#125;&#125; 消费者要先启动需要注意的一点是，对于主题模式而言， 消费者要先启动。 如果在生产者生产完成之后，再启动，是看不到消息的。就如同现在才关注某个公众号，那么以前公众号发的信息，现在是看不到的。 只有以后发的，才看得到了。 运行效果 管理界面","tags":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"http://example.com/tags/ActiveMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"Activemq","slug":"工具和中间件/消息队列/Activemq","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Activemq/"}]},{"title":"Kafka-Spring集成","date":"2019-03-23T04:08:20.000Z","path":"blog/工具和中间件/消息队列/Kafka/Kafka-Spring集成/","text":"Spring集成1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt; &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt;&lt;/dependency&gt; 123456789101112131415161718192021222324252627282930313233spring: kafka: bootstrap-servers: localhost:9092, localhost:9093, localhost:9094 producer: # 生产者 retries: 3 # 设置大于0的值，则客户端会将发送失败的记录重新发送 batch-size: 16384 buffer-memory: 33554432 acks: 1 # 指定消息key和消息体的编解码方式 key-serializer: org.apache.kafka.common.serialization.StringSerializer value-serializer: org.apache.kafka.common.serialization.StringSerializer consumer: group-id: default-group enable-auto-commit: false auto-offset-reset: earliest key-deserializer: org.apache.kafka.common.serialization.StringDeserializer value-deserializer: org.apache.kafka.common.serialization.StringDeserializer listener: # 当每一条记录被消费者监听器（ListenerConsumer）处理之后提交 # RECORD # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后提交 # BATCH # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后，距离上次提交时间大于TIME时提交 # TIME # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后，被处理record数量大于等于COUNT时提交 # COUNT # TIME | COUNT 有一个条件满足时提交 # COUNT_TIME # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后, 手动调用Acknowledgment.acknowledge()后提交 # MANUAL # 手动调用Acknowledgment.acknowledge()后立即提交，一般使用这种 # MANUAL_IMMEDIATE ack_mode: manual_immediate 123456private final static String TOPIC_NAME = &quot;my-replicated-topic&quot;;@Autowiredprivate KafkaTemplate&lt;String, String&gt; kafkaTemplate;public void send() &#123; kafkaTemplate.send(TOPIC_NAME, 0, &quot;key&quot;, &quot;this is a msg&quot;);&#125; 123456789101112131415161718192021222324/** * @KafkaListener(groupId = &quot;testGroup&quot;, topicPartitions = &#123; * @TopicPartition(topic = &quot;topic1&quot;, partitions = &#123;&quot;0&quot;, &quot;1&quot;&#125;), * @TopicPartition(topic = &quot;topic2&quot;, partitions = &quot;0&quot;, * partitionOffsets = @PartitionOffset(partition = &quot;1&quot;, initialOffset = &quot;100&quot;)) * &#125;, concurrency = &quot;6&quot;) * concurrency就是同组下的消费者个数，就是并发消费数，必须小于等于分区总数 */@KafkaListener(topics = &quot;my-replicated-topic&quot;, groupId = &quot;testGroup&quot;)public void listenTestGroup(ConsumerRecord&lt;String, String&gt; record, Acknowledgment ack) &#123; String value = record.value(); System.out.println(value); System.out.println(record); //手动提交offset //ack.acknowledge();&#125;// 配置多个消费组@KafkaListener(topics = &quot;my-replicated-topic&quot;, groupId = &quot;elevenGroup&quot;)public void listenElevenGroup(ConsumerRecord&lt;String, String&gt; record, Acknowledgment ack) &#123; String value = record.value(); System.out.println(value); System.out.println(record); ack.acknowledge();&#125; 设计原理 总控制器ControllerKafka集群中会有一个或多个Broker ，其中有一个Broker会被选举为Kafka Controller控制器，其负责管理整个集群中所有分区和副本的状态. 当某个分区的 Leader副本出现故障时，由控制器负责为该分区选举新的Leader副本. 当检测到某个分区的 ISR集合发生变化时，由控制器负责通知所有Broker更新其元数据信息. 当使用 kafka-topics.sh 脚本为某个 Topic增加分区数量时，同样还是由控制器负责让新分区被其他节点感知到. Kafka集群启动时自动选举一台Broker作为Controller来管理整个集群，选举过程是集群中每个Broker都会尝试在Zookeeper上创建一个 /controller临时节点，Zookeeper会保证有且仅有一个Broker能创建成功，创建成功的Broker则成为集群的总控器Controller. Controller选举机制当Controller角色的Broker宕机时Zookeeper临时节点会消失，集群里其他Broker会一直监听/controller临时节点，发现临时节点消失则竞争再次创建/controller临时节点，这就是 Controller的选举机制. 具备控制器身份的Broker需要比其他普通Broker多一份职责： 监听Broker相关的变化，为Zookeeper中的 /brokers/ids 节点添加 BrokerChangeListener ，用来处理Broker增减变化. 监听Topic相关的变化，为Zookeeper中的 /brokers/topics 节点添加 TopicChangeListener ，用来处理Topic增减的变化；为Zookeeper中的 /admin/delete_topics 节点添加 TopicDeletionListener ，用来处理删除Topic动作. 从Zookeeper中读取当前所有与Topic、 Partition以及Broker有关信息并进行相应的管理. 对所有Topic所对应的Zookeeper中的 /brokers/topics/[topic] 节点添加 PartitionModificationsListener ，用来监听Topic中分区分配变化. 更新集群元数据信息，同步到其他普通Broker节点中. Partition副本选举Leader机制Controller会监听 /brokers/ids 节点可感知Broker是否存活，当Controller感知到分区Leader所在Broker挂了，参数 unclean.leader.election.enable=false 的前提下，Controller会从 ISR列表里挑第一个Broker作为Leader，因为第一个Broker最先放进ISR列表可能是同步数据最多的副本，若参数 unclean.leader.election.enable=true 代表在 ISR列表里所有副本都挂了时可在ISR列表以外的副本中选Leader，该设置可提高可用性，但选出的新Leader可能数据少很多. 副本进入ISR列表有两个条件：副本节点不能产生分区，必须能与Zookeeper保持会话以及跟Leader副本网络连通；副本能复制Leader上的所有写操作，且不能落后太多，超过 replica.lag.time.max.ms 时间都没跟Leader同步过一次的副本会被移出 ISR 列表； offset记录机制每个Consumer会定期将自己消费分区的offset 提交给Kafka内部名称为 __consumer_offsets 的Topic，提交过去时key为consumerGroupId+topic+分区号，value就是当前offset的值，Kafka会定期清理该Topic里的消息保留最新的那条数据，因为 __consumer_offsets可能会接收高并发的请求，Kafka默认给其分配50个分区，可通过 offsets.topic.num.partitions 设置，这样可通过加机器的方式抗大并发. 通过公式 hash(consumerGroupId) % __consumer_offsets主题的分区数可选出Consumer消费的offset 要提交到 __consumer_offsets的哪个分区. 消费者Rebalance机制 Rebalance机制：若消费组中消费者数量变化或消费分区数变化，Kafka会重新分配消费者消费分区的关系. 如Consumer Group中某个消费者挂了，此时会自动把分配给它的分区交给其它消费者，若其恢复则又会把一些分区重新交还给它. Rebalance只针对Subscribe这种不指定分区消费的情况，若通过 assign 消费方式指定了分区Kafka不会进行Rebanlance . 当消费组中Consumer增加或减少、 动态给Topic增加分区、 消费组订阅了更多的Topic 等情况可能触发消费者Rebalance. Rebalance过程中消费者无法从Kafka消费消息，对Kafka的TPS会有影响，若Kafka集群内节点较多， Rebalance重平衡可能会耗时极多，应尽量避免在系统高峰期Rebalance重平衡. 消费者Rebalance分区分配策略消费者Rebalance分区分配策略主要有 range 、 round-robin 、 sticky 三种 Rebalance策略，默认为 range分配策略. Kafka提供消费者客户端参数 partition.assignment.strategy 来设置消费者与订阅主题之间的分区分配策略. range策略：按分区序号排序，假设 n＝分区数／消费者数量， m＝分区数%消费者数量，则前m个消费者每个分配n+1个分区，消费者数量 - m个消费者每个分配n个分区. round-robin策略：轮询分配 sticky策略：初始时分配策略与round-robin类似，但在Rebalance时需要保证分区分配尽可能均匀、 分区分配尽可能与上次分配保持相同两个原则. 当两者发生冲突时，第一个目标优先于第二个目标 . 这样可以最大程度维持原来的分区分配的策略. Rebalance过程当有消费者加入消费组时，消费者、 消费组及组协调器之间会依次经历选择组协调器、 加入消费组、 SYNC GROUP 三个阶段； 选择组协调器：每个Consumer Group都会选择一个Broker作为自己的组协调器GroupCoordinator ，负责监控该消费组中所有消费者心跳，以及判断是否宕机，然后开启消费者Rebalance. Consumer Group中每个Consumer启动时会向Kafka集群中某个节点发送 FindCoordinatorRequest 请求来查找对应的组协调器GroupCoordinator ，并跟其建立网络连接. Consumer消费的offset要提交到 __consumer_offsets 的哪个分区，该分区Leader对应的Broker就是该Consumer Group的GroupCoordinator. 加入消费组：消费者会向 GroupCoordinator 发送 JoinGroupRequest 请求并处理响应. 然后GroupCoordinator从一个Consumer Group中选择第一个加入Group的Consumer作为Leader消费组协调器，把Consumer Group情况发送给该Leader，接着该 Consumer Leader 会负责制定分区方案. SYNC GROUP ： Consumer Leader 通过给GroupCoordinator发送SyncGroupRequest ，接着 GroupCoordinator把分区方案下发给各个Consumer ，具体的 Consumer 根据指定分区的Leader Broker进行网络连接以及消息消费. Producer发布消息机制Producer采用 push模式将消息发布到Broker，每条消息都被append到顺序写磁盘到 Patition 中，Producer发送消息到Broker时，会根据分区算法选择将其存储到哪一个Partition，路由机制为： 指定了Patition，则直接使用； 未指定Patition但指定了key ，通过对key的value进行hash选出一个Patition Patition和key都未指定，使用轮询选出一个Patition. Producer先从Zookeeper的 /brokers/.../state 节点找到该Partition的Leader，然后将消息发送给该Leader，Leader将消息写入本地commit log，Followers从Leader Pull消息，写入本地commit log后向Leader发送ACK，Leader收到所有ISR中的Replica的ACK后，增加最后 commit 的offset即 high watermark高水位简称 HW 并向Producer发送ACK. HW和LEO High Watermark 俗称高水位，取一个 Partition 对应的 ISR中最小的log-end-offset即LEO作为HW ，Consumer最多只能消费到HW所在的位置. 每个 Replica 都有 HW ， Leader 和 Follower 各自负责更新自己的HW状态. 对于 Leader新写入的消息Consumer不能立刻消费，Leader会等待该消息被所有ISR中的Replicas同步后更新HW ，此时消息才能被Consumer消费. 这样保证了若Leader所在Broker失效，该消息仍然可从新选举的Leader中获取. 对于来自内部Broker的读取请求没有HW的限制. ISR以及HW和LEO的流转过程： Kafka复制机制既不是完全的同步复制，也不是单纯的异步复制. 同步复制要求所有能工作的Follower都复制完，这条消息才会被commit极大影响了吞吐率. 异步复制方式下Follower异步从Leader复制数据，数据只要被Leader写入log就被认为已经commit，这种情况下若Follower还未复制完落后于Leader时，若Leader宕机则会丢失数据. Kafka使用 ISR 方式则很好均衡了确保数据不丢失以及吞吐率. acks=1 的情况: 日志分段存储Kafka一个分区的消息数据对应存储在一个文件夹下，以Topic名称+分区号命名，消息在分区内是分段存储，每个段的消息都存储在不一样的log文件里，这种特性方便过期分段文件快速被删除，Kafka规定一个段位的 log文件最大为 1G . Kafka每次往分区发 4K 消息就会记录一条当前消息的 offset 到 index文件以及记录一条当前消息的发送时间戳与对应的 offset 到 timeindex文件，若要定位消息的 offset 会先在index文件里快速定位，若需要按照时间来定位消息的offset ，会先在timeindex文件里查找，再去log文件里找具体消息，相当于一个稀疏索引； 123456# 部分消息的offset索引文件，Kafka每次往分区发4K(可配置)消息就会记录一条当前消息的offset到index文件，若要定位消息的offset会先在该文件里快速定位，再去log文件里找具体消息，相当于一个稀疏索引00000000000000000000.index# 消息存储文件，主要存offset和消息体00000000000000000000.log# 消息的发送时间索引文件，kafka每次往分区发4K(可配置)消息就会记录一条当前消息的发送时间戳与对应的offset到timeindex文件，若需要按照时间来定位消息的offset，会先在这个文件里查找00000000000000000000.timeindex 一个日志段文件满了，会自动开一个新的日志段文件来写入，避免单个文件过大，影响文件的读写性能，该过程叫做 log rolling ，正在被写入的日志段文件叫做 active log segment 实际问题:消息丢失消息发送端 acks=0 ： 表示Producer不需要等待任何Broker确认收到消息的回复，就可继续发送下一条消息. 性能最高，但是最容易丢消息. 大数据统计报表场景，对性能要求很高，对数据丢失不敏感的情况可用这种. acks=1 ： 至少要等待Leader已经成功将数据写入本地log，但不需要等待所有Follower是否成功写入. 就可继续发送下一条消息. 该情况下若Follower没有成功备份数据，而此时Leader挂掉则消息会丢失. acks=-1或all ： Leader需等待所有备份即 min.insync.replicas 配置的备份个数都成功写入日志，该策略会保证只要有一个备份存活就不会丢失数据 消息消费端若消费这边配置的是自动提交，万一消费到数据还没处理完，就自动提交offset了，但此时Consumer直接宕机了，未处理完的数据丢失了，下次也消费不到了. 消息重复消费消息发送端：发送消息若配置了重试机制，如网络抖动时间过长导致发送端发送超时，实际broker可能已经接收到消息，但发送方会重新发送消息 消息消费端：若消费这边配置的是自动提交，刚拉取了一批数据处理了一部分，但还没来得及提交，服务挂了，下次重启又会拉取相同的一批数据重复处理，一般消费端都是要做消费幂等处理. 消息乱序若发送端配置了重试机制，Kafka不会等之前那条消息完全发送成功才去发送下一条消息，可能会出现发送了1，2，3条消息，第一条超时了，后面两条发送成功，再重试发送第1条消息，这时消息在broker端的顺序就是2，3，1了，是否一定要配置重试要根据业务情况而定. 也可用同步发送的模式去发消息，当然acks不能设置为0，这样也能保证消息发送的有序. kafka保证全链路消息顺序消费，需要从发送端开始，将所有有序消息发送到同一个分区，然后用一个消费者去消费，但性能比较低，可在消费者端接收到消息后将需要保证顺序消费的几条消费发到内存队列，一个内存队列开启一个线程顺序处理消息. 消息积压线上有时因为发送方发送消息速度过快，或者消费方处理消息过慢，可能会导致Broker积压大量未消费消息. 若积压了上百万未消费消息需要紧急处理，可修改消费端程序，让其将收到的消息快速转发到其他Topic ，可设置很多分区，然后再启动多个消费者同时消费新主题的不同分区. 由于消息数据格式变动或消费者程序有bug，导致消费者一直消费不成功，也可能导致broker积压大量未消费消息. 此种情况可将这些消费不成功的消息转发到其它队列里去，类似死信队列，后面再慢慢分析死信队列里的消息处理问题. 延时队列延时队列存储的对象是延时消息. 指消息被发送以后，并不想让消费者立刻获取，而是等待特定的时间后，消费者才能获取该消息进行消费，但Kafka不支持延时队列. 实现思路：发送延时消息时先把消息按照不同的延迟时间段发送到指定的队列中如topic_1s，topic_5s，topic_10s，…topic_2h，一般不能支持任意时间段的延时，然后通过定时器进行轮训消费这些Topic，查看消息是否到期，若到期则把该消息发送到具体业务处理的Topic中，队列中消息越靠前的到期时间越早，具体来说就是定时器在一次消费过程中，对消息的发送时间做判断，看下是否延迟到对应时间了，若到了就转发，如果还没到这一次定时任务就可以提前结束了. 消息回溯若某段时间对已消费消息计算的结果觉得有问题，可能是由于程序bug导致的计算错误，当程序bug修复后，这时可能需要对之前已消费的消息重新消费，可以指定从多久之前的消息回溯消费，这种可以用Consumer的offsetsForTimes、 seek等方法指定从某个offset偏移的消息开始消费. 消息传递保障kafka生产者的幂等性，因发送端重试导致的消息重复发送问题，Kafka幂等性可保证重复发送的消息只接收一次，只需在生产者加上参数 props.put(&quot;enable.idempotence&quot;, true) 即可，默认是false不开启，Kafka每次发送消息会生成 PID 和 Sequence Number 并将这两个属性一起发送给Broker，Broker将PID和Sequence Number跟消息绑定一起存起来，若生产者重发相同消息，Broker会检查PID和Sequence Number，若相同不会再接收. 每个新的Producer在初始化时会被分配一个唯一的PID，PID对用户完全是透明的，生产者若重启则会生成新的PID，每个PID该Producer发送到每个Partition的数据都有对应的序列号即 Sequence Number ，这些序列号是从0开始单调递增的. Kafka的事务Kafka事务不同于Rocketmq，Rocketmq是保障本地事务与MQ消息发送的事务一致性，Kafka的事务主要是保障一次发送多条消息的事务一致性，一般在Kafka流式计算场景用得多一点，如kafka需要对一个Topic中的消息做不同的流式计算处理，处理完分别发到不同的Topic里，这些Topic分别被不同的下游系统消费如hbase，redis，es等，这种肯定希望系统发送到多个topic的数据保持事务一致性. 12345678910111213141516171819202122Properties props = new Properties();props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);props.put(&quot;transactional.id&quot;, &quot;my-transactional-id&quot;);Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props, new StringSerializer(), new StringSerializer());producer.initTransactions(); //初始化事务try &#123; producer.beginTransaction(); //开启事务 for (int i = 0; i &lt; 100; i++) &#123;//发到不同的主题的不同分区 producer.send(new ProducerRecord&lt;&gt;(&quot;hdfs-topic&quot;, Integer.toString(i), Integer.toString(i))); producer.send(new ProducerRecord&lt;&gt;(&quot;es-topic&quot;, Integer.toString(i), Integer.toString(i))); producer.send(new ProducerRecord&lt;&gt;(&quot;redis-topic&quot;, Integer.toString(i), Integer.toString(i))); &#125; producer.commitTransaction(); //提交事务&#125; catch (ProducerFencedException | OutOfOrderSequenceException | AuthorizationException e) &#123; producer.close();&#125; catch (KafkaException e) &#123; producer.abortTransaction(); //回滚事务&#125;producer.close();","tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://example.com/tags/Kafka/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"Kafka","slug":"工具和中间件/消息队列/Kafka","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Kafka/"}]},{"title":"RabbitMQ-direct模式","date":"2019-03-23T04:08:20.000Z","path":"blog/工具和中间件/消息队列/RabbitMQ/RabbitMQ-direct模式/","text":"pom.xml123456789101112131415161718192021&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;artifactId&gt;rabbitmq&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;rabbitmq&lt;/name&gt; &lt;description&gt;rabbitmq&lt;/description&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt; &lt;artifactId&gt;amqp-client&lt;/artifactId&gt; &lt;version&gt;3.6.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;4.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; TestDriectProducer.java1234567891011121314151617181920212223242526272829303132333435363738package cn.peach;import java.io.IOException;import java.util.concurrent.TimeoutException; import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory; /** * 消息生成者 */public class TestDriectProducer &#123; public final static String QUEUE_NAME=&quot;direct_queue&quot;; public static void main(String[] args) throws IOException, TimeoutException &#123; RabbitMQUtil.checkServer(); //创建连接工厂 ConnectionFactory factory = new ConnectionFactory(); //设置RabbitMQ相关信息 factory.setHost(&quot;localhost&quot;); //创建一个新的连接 Connection connection = factory.newConnection(); //创建一个通道 Channel channel = connection.createChannel(); for (int i = 0; i &lt; 100; i++) &#123; String message = &quot;direct 消息 &quot; +i; //发送消息到队列中 channel.basicPublish(&quot;&quot;, QUEUE_NAME, null, message.getBytes(&quot;UTF-8&quot;)); System.out.println(&quot;发送消息： &quot; + message); &#125; //关闭通道和连接 channel.close(); connection.close(); &#125;&#125; TestDriectCustomer.java12345678910111213141516171819202122232425262728293031323334353637383940414243444546package cn.peach;import java.io.IOException;import java.util.concurrent.TimeoutException; import com.rabbitmq.client.AMQP;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import com.rabbitmq.client.Consumer;import com.rabbitmq.client.DefaultConsumer;import com.rabbitmq.client.Envelope; import cn.hutool.core.util.RandomUtil; public class TestDriectCustomer &#123; private final static String QUEUE_NAME = &quot;direct_queue&quot;; public static void main(String[] args) throws IOException, TimeoutException &#123; //为当前消费者取随机名 String name = &quot;consumer-&quot;+ RandomUtil.randomString(5); // 创建连接工厂 ConnectionFactory factory = new ConnectionFactory(); //设置RabbitMQ地址 factory.setHost(&quot;localhost&quot;); //创建一个新的连接 Connection connection = factory.newConnection(); //创建一个通道 Channel channel = connection.createChannel(); //声明要关注的队列 channel.queueDeclare(QUEUE_NAME, false, false, true, null); System.out.println(name +&quot; 等待接受消息&quot;); //DefaultConsumer类实现了Consumer接口，通过传入一个频道， // 告诉服务器我们需要那个频道的消息，如果频道中有消息，就会执行回调函数handleDelivery Consumer consumer = new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; String message = new String(body, &quot;UTF-8&quot;); System.out.println(name + &quot; 接收到消息 &#x27;&quot; + message + &quot;&#x27;&quot;); &#125; &#125;; //自动回复队列应答 -- RabbitMQ中的消息确认机制 channel.basicConsume(QUEUE_NAME, true, consumer); &#125;&#125; 运行效果先运行两次 TestDriectCustomer，启动两个消费者。然后运行一次 TestDriectProducer， 启动生产者，生产100条信息。此时就可以看到如图所示两个消费者分食 这100条信息。","tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://example.com/tags/RabbitMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RabbitMQ","slug":"工具和中间件/消息队列/RabbitMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/"}]},{"title":"ActiveMQ-队列模式","date":"2019-03-23T03:08:20.000Z","path":"blog/工具和中间件/消息队列/Activemq/ActiveMQ-队列模式/","text":"pom.xml导入activemq jar包 12345678910111213141516&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;artifactId&gt;activemq&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;activemq&lt;/name&gt; &lt;description&gt;activemq&lt;/description&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-all&lt;/artifactId&gt; &lt;version&gt;5.15.9&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; TestProducer.java生产100条消息。注： activemq 服务器应先启动。 12345678910111213141516171819202122232425262728293031323334353637383940414243package cn.peach.queue; import javax.jms.Connection;import javax.jms.ConnectionFactory;import javax.jms.Destination;import javax.jms.JMSException;import javax.jms.MessageProducer;import javax.jms.Session;import javax.jms.TextMessage; import org.apache.activemq.ActiveMQConnectionFactory; public class TestProducer &#123; //服务地址，端口默认61616 private static final String url=&quot;tcp://127.0.0.1:61616&quot;; //这次发送的消息名称 private static final String topicName=&quot;queue_style&quot;; public static void main(String[] args) throws JMSException &#123; //1.创建ConnectionFactory,绑定地址 ConnectionFactory factory=new ActiveMQConnectionFactory(url); //2.创建Connection Connection connection= factory.createConnection(); //3.启动连接 connection.start(); //4.创建会话 Session session=connection.createSession(false, Session.AUTO_ACKNOWLEDGE); //5.创建一个目标 (队列类型) Destination destination=session.createQueue(topicName); //6.创建一个生产者 MessageProducer producer=session.createProducer(destination); for (int i = 0; i &lt; 100; i++) &#123; //7.创建消息 TextMessage textMessage=session.createTextMessage(&quot;队列消息-&quot;+i); //8.发送消息 producer.send(textMessage); System.out.println(&quot;发送：&quot;+textMessage.getText()); &#125; //7. 关闭连接 connection.close(); &#125;&#125; TestConsumer.java消费者，消费服务器上的消息。注： activemq 服务器应先启动。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package cn.peach.queue; import javax.jms.Connection;import javax.jms.ConnectionFactory;import javax.jms.Destination;import javax.jms.JMSException;import javax.jms.Message;import javax.jms.MessageConsumer;import javax.jms.MessageListener;import javax.jms.Session;import javax.jms.TextMessage; import org.apache.activemq.ActiveMQConnectionFactory; import cn.peach.util.ActiveMQUtil;import cn.hutool.core.util.RandomUtil;/** * 订阅者 * @author root * */public class TestConsumer &#123; //服务地址，端口默认61616 private static final String url=&quot;tcp://127.0.0.1:61616&quot;; //这次消费的消息名称 private static final String topicName=&quot;queue_style&quot;; //消费者有可能是多个，为了区分不同的消费者，为其创建随机名称 private static final String consumerName=&quot;consumer-&quot; + RandomUtil.randomString(5); public static void main(String[] args) throws JMSException &#123; //1.创建ConnectiongFactory,绑定地址 ConnectionFactory factory=new ActiveMQConnectionFactory(url); //2.创建Connection Connection connection= factory.createConnection(); //3.启动连接 connection.start(); //4.创建会话 Session session=connection.createSession(false, Session.AUTO_ACKNOWLEDGE); //5.创建一个目标 （队列类型） Destination destination=session.createQueue(topicName); //6.创建一个消费者 MessageConsumer consumer=session.createConsumer(destination); //7.创建一个监听器 consumer.setMessageListener(new MessageListener() &#123; public void onMessage(Message arg0) &#123; // TODO Auto-generated method stub TextMessage textMessage=(TextMessage)arg0; try &#123; System.out.println(consumerName +&quot; 接收消息：&quot;+textMessage.getText()); &#125; catch (JMSException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; &#125;); //8. 因为不知道什么时候有，所以没法主动关闭，就不关闭了，一直处于监听状态 //connection.close(); &#125;&#125; 管理界面访问地址： http://127.0.0.1:8161/admin/queues.jsp 就可以看到 刚才的消息处理情况。 queue_style 是在代码中定义的消息名称。 number Of Consumers 表示有2个消费者。 Messages Enqueued：表示收到了 100 个消息。 Messages Dequeued：表示消费了 100 个消息。","tags":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"http://example.com/tags/ActiveMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"Activemq","slug":"工具和中间件/消息队列/Activemq","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Activemq/"}]},{"title":"RabbitMQ-fanout模式","date":"2019-03-23T03:08:20.000Z","path":"blog/工具和中间件/消息队列/RabbitMQ/RabbitMQ-fanout模式/","text":"pom.xml提供 rabbitmq和hutool的jar 1234567891011121314151617181920&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;artifactId&gt;rabbitmq&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;rabbitmq&lt;/name&gt; &lt;description&gt;rabbitmq&lt;/description&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt; &lt;artifactId&gt;amqp-client&lt;/artifactId&gt; &lt;version&gt;3.6.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;4.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; TestProducer.java12345678910111213141516171819202122232425262728293031323334353637383940package cn.peach;import java.io.IOException;import java.util.concurrent.TimeoutException; import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory; /** * 消息生成者 */public class TestProducer &#123; public final static String EXCHANGE_NAME=&quot;fanout_exchange&quot;; public static void main(String[] args) throws IOException, TimeoutException &#123; RabbitMQUtil.checkServer(); //创建连接工厂 ConnectionFactory factory = new ConnectionFactory(); //设置RabbitMQ相关信息 factory.setHost(&quot;localhost&quot;); //创建一个新的连接 Connection connection = factory.newConnection(); //创建一个通道 Channel channel = connection.createChannel(); channel.exchangeDeclare(EXCHANGE_NAME, &quot;fanout&quot;); for (int i = 0; i &lt; 100; i++) &#123; String message = &quot;direct 消息 &quot; +i; //发送消息到队列中 channel.basicPublish(EXCHANGE_NAME, &quot;&quot;, null, message.getBytes(&quot;UTF-8&quot;)); System.out.println(&quot;发送消息： &quot; + message); &#125; //关闭通道和连接 channel.close(); connection.close(); &#125;&#125; TestDriectCustomer.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package cn.peach;import java.io.IOException;import java.util.concurrent.TimeoutException; import com.rabbitmq.client.AMQP;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import com.rabbitmq.client.Consumer;import com.rabbitmq.client.DefaultConsumer;import com.rabbitmq.client.Envelope; import cn.hutool.core.util.RandomUtil; public class TestCustomer &#123; public final static String EXCHANGE_NAME=&quot;fanout_exchange&quot;; public static void main(String[] args) throws IOException, TimeoutException &#123; //为当前消费者取随机名 String name = &quot;consumer-&quot;+ RandomUtil.randomString(5); //判断服务器是否启动 RabbitMQUtil.checkServer(); // 创建连接工厂 ConnectionFactory factory = new ConnectionFactory(); //设置RabbitMQ地址 factory.setHost(&quot;localhost&quot;); //创建一个新的连接 Connection connection = factory.newConnection(); //创建一个通道 Channel channel = connection.createChannel(); //交换机声明（参数为：交换机名称；交换机类型） channel.exchangeDeclare(EXCHANGE_NAME,&quot;fanout&quot;); //获取一个临时队列 String queueName = channel.queueDeclare().getQueue(); //队列与交换机绑定（参数为：队列名称；交换机名称；routingKey忽略） channel.queueBind(queueName,EXCHANGE_NAME,&quot;&quot;); System.out.println(name +&quot; 等待接受消息&quot;); //DefaultConsumer类实现了Consumer接口，通过传入一个频道， // 告诉服务器我们需要那个频道的消息，如果频道中有消息，就会执行回调函数handleDelivery Consumer consumer = new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; String message = new String(body, &quot;UTF-8&quot;); System.out.println(name + &quot; 接收到消息 &#x27;&quot; + message + &quot;&#x27;&quot;); &#125; &#125;; //自动回复队列应答 -- RabbitMQ中的消息确认机制 channel.basicConsume(queueName, true, consumer); &#125;&#125; 运行效果先运行两次 TestCustomer，启动两个消费者。然后运行一次 TestProducer， 启动生产者，生产100条信息。此时就可以看到如图所示两个消费者都能收到 这100条信息","tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://example.com/tags/RabbitMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RabbitMQ","slug":"工具和中间件/消息队列/RabbitMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/"}]},{"title":"ActiveMQ-基础","date":"2019-03-23T02:08:20.000Z","path":"blog/工具和中间件/消息队列/Activemq/ActiveMQ-基础/","text":"ActiveMQ：ActiveMQ 是用 Java 语言开发的消息中间件，简单易用。只需要操作系统支持Java虚拟机，ActiveMQ便可执行。 下载并启动：apache-activemq-5.15.8-bin.rar, 解压并运行32或者64位操作系统对应的 activemq.bat 就启动 启动成功界面 访问地址启动好之后， 访问地址 http://127.0.0.1:8161/ 就可以看到如图所示的界面。这就是服务器的管理界面，在里面就可以看到都有哪些消息被创建了，哪些被消费了 管理界面点击 manage activeMQ broker, 或者直接访问地址：http://127.0.0.1:8161/admin/会弹出登录对话框，输入默认的账号和密码，都是： admin就来到了管理界面了。 观察数据这里可以观察到 队列数据和主题数据等信息，不过还没有客户端发消息来，所以也没有数据，就先不管。 模式activeMQ 有两种模式，分别是 队列模式 和 主题模式。 队列模式，其实就是分食模式。 比如生产方发了 10条消息到 activeMQ 服务器， 而此时有多个 消费方，那么这些消费方就会瓜分这些10条消息，一条消息只会被一个消费方得到。 主题模式，就是订阅模式。 比如生产方发了10条消息，而此时有多个消费方，那么多个消费方都能得到这 10条消息，就如同订阅公众号那样。","tags":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"http://example.com/tags/ActiveMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"Activemq","slug":"工具和中间件/消息队列/Activemq","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Activemq/"}]},{"title":"Kafka-基础","date":"2019-03-23T02:08:20.000Z","path":"blog/工具和中间件/消息队列/Kafka/Kafka-基础/","text":"Kafka是什么? Kafka 是 scala 语言编写的 支持partition分区、 replica多副本, 基于Zookeeper协调 的 分布式消息系统, 可 实时处理大量数据 以满足各种需求场景, 如基于hadoop批处理系统、 低延迟实时系统、 Storm&#x2F;Spark流式处理引擎, web&#x2F;nginx日志、 访问日志, 消息服务等. 名称 解释 Broker 消息中间件处理节点, 一个Kafka节点就是一个Broker, 一个或者多个Broker组成Kafka集群 Topic Kafka根据Topic对消息进行归类, 发布到Kafka集群的每条消息都需指定一个Topic Producer 消息生产者, 向Broker发送消息的客户端, 通过TCP协议来完成通信 Consumer 消息消费者, 从Broker读取消息的客户端, 通过TCP协议来完成通信 Consumer Group 每个Consumer属于一个特定Consumer Group, 一条消息可被多个不同Consumer Group消费, 但一个Consumer Group中只能有一个Consumer能消费该消息 Partition 物理上的概念, 一个Topic可分为多个Partition, 每个Partition内部消息是有序的 使用场景 日志收集：可用Kafka收集各种服务日志, 通过kafka以统一接口服务方式开放给各种Consumer, 如Hhadoop、 Hbase、 Solr等. 消息系统：解耦生产者和消费者、 缓存消息等. 用户活动跟踪：Kafka经常被用来记录Web用户或App用户的各种活动, 如浏览网页、 搜索、 点击等活动, 被各个服务器发布到kafka的Topic中, 然后订阅者通过订阅这些Topic来做实时监控分析, 或装载到Hadoop、 数据仓库中做离线分析和挖掘. 运营指标：Kafka也经常用来记录运营监控数据. 包括收集各种分布式应用数据, 生产各种操作的集中反馈, 如报警和报告. Kafka核心配置Kafka核心配置在 config/server.properties 配置文件中. 1234broker.id=0 # broker.id属性在kafka集群中必须要是唯一listeners=PLAINTEXT://localhost:9092 # kafka部署的机器ip和提供服务的端口号log.dir=/usr/local/data/kafka-logs # kafka的消息存储文件zookeeper.connect=192.168.65.60:2181 # kafka连接zookeeper的地址, 若是集群则用逗号分割 Property Default Description broker.id 0 每个Broker都可用一个唯一非负整数id进行标识 log.dirs /tmp/kafka-logs 存放数据的路径, 该路径并不唯一, 可设置多个路径之间用逗号分隔, 创建新partition时选择包含最少partitions路径下创建 listeners PLAINTEXT://192.168.65.60:9092 Server接受客户端连接的端口, ip配置kafka本机ip即可 zookeeper.connect localhost:2181 Kafka连接Zookeeper的地址, 若是集群用逗号分隔 log.retention.hours 168 每个日志文件的保存时间. 默认数据保存时间对所有topic都一样 num.partitions 1 创建Topic默认分区数 default.replication.factor 1 自动创建Topic默认副本数量, 建议设置为大于等于2 min.insync.replicas 1 写数据到repica数量达到设定值才表示Producer发送消息成功, 若Producer设置acks为-1, 则每个repica写数据都必须成功 delete.topic.enable false 是否允许删除主题 12345678910111213141516171819202122232425262728bin/kafka-server-start.sh config/server.properties # 启动kafkabin/kafka-server-stop.sh # 停止kafka# 创建名字为test的Topic, 该topic只有一个partition, 且备份因子为1bin/kafka-topics.sh --zookeeper localhost:2181 --create --replication-factor 1 --partitions 1 --topic test# 查看kafka中目前存在的topicbin/kafka-topics.sh --zookeeper localhost:2181 --list# 删除topicbin/kafka-topics.sh --zookeeper localhost:2181 --delete --topic test# 发送消息到kafka, 若是集群--broker-list参数用逗号隔开bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test# 消费kafka集群最新消息, 若是集群--bootstrap-server参数用逗号隔开bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test# 多主题消费kafka集群消息bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --whitelist &quot;test|test-2&quot;# 通过--from-beginning从开始读取kafka集群消息bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --from-beginning --topic test# 单播消费, 一条消息只能被某一个消费者消费, 让所有消费者在同一个消费组里即可bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --consumer-property group.id=testGroup --topic test# 多播消费, 同一条消息只能被同一个消费组下的某一个消费者消费的特性bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --consumer-property group.id=testGroup-2 --topic test# 查看消费组名bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list# 查看消费组的消费偏移量, current-offset当前消费组的已消费偏移量, log-end-offset主题对应分区消息结束偏移量, lag当前消费组未消费消息数bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group testGroup# 查看下topic情况bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic test# 增加topic的分区数量, 目前kafka不支持减少分区bin/kafka-topics.sh --zookeeper localhost:2181 --alter --partitions 3 --topic test 同类消息发送到同一个Topic下面, 每个Topic下面可有多个分区Partition日志文件, Partition 是一个有序的message序列, 这些message按顺序添加到 commit log文件 中. 每个Partition中消息都有一个唯一编号 offset , 用来唯一标识某个分区中的message. 每个Partition都对应一个commit log文件, 同一个Partition 中的 message 的offset都是 唯一 的, 但 不同Partition 中 message 的 offset 可能相同. 每个Partition分区中都有一个Leader副本节点和一个或多个Replicas副本以及一个 Isr 集合， Partition的Leader副本节点负责给定Partition的所有读写请求，Replicas表示某个Partition在哪几个Broker上存在备份，不管该节点是不是Leader，甚至该节点挂了也会列出. Isr 集合是Replicas的一个子集，只列出存活的备份节点，且已同步备份了该Partition的节点. Kafka一般不会删除消息，不管是否被消费. 只会根据配置的日志保留时间log.retention.hours 确认消息多久被删除，默认保留最近一周的消息. Kafka性能与保留消息数据量大小没有关系. 每个Consumer是基于commit log中消费进度即offset 来进行工作的，消费offset由Consumer来维护，一般按照顺序逐条消费commit log中的消息，可通过指定offset来重复消费某些消息或跳过某些消息. 意味Consumer对集群影响非常小，添加或减少Consumer对于集群或其他Consumer没有影响，因为每个Consumer维护各自的消费offset . 一个Topic代表逻辑上的一个业务数据集，对于大型网站来说，后端数据都是海量的，消息可能非常巨量，若把这么多数据都放在一台机器上可能会有容量限制问题，可在 Topic内部划分多个Partition 来分片存储数据，不同Partition可位于不同机器上，每台机器上都运行一个Kafka的Broker进程. 分片存储的好处，提高并行度，且 commit log 文件会受到所在机器的文件系统大小的限制，分区后可将不同分区放在不同机器上，相当于对数据做分布式存储，理论上一个Topic可处理任意数量数据. Kafka集群Kafka将很多集群关键信息记录在 Zookeeper 中，保证自己的无状态，从而在水平扩容时非常方便. commit log 的 Partitions 分布在Kafka集群中不同Broker上，每个Broker上该Partition分区的副本可请求备份其他Broker上Partition上副本的数据，Kafka集群支持配置一个Partition备份数量. 每个Partition都有一个Broker上的副本起到Leader的作用， 0个或多个其他的Broker副本作为 Follwers 作用. 作为 Leader的副本处理所有针对该Partition的读写请求，作为Followers的副本被动复制作为Leader的副本的结果，不提供读写，主要是为了保证多副本数据与消费的一致性. 若一个Partition分区中 Leader副本失效其中一个 Follower副本将自动变成新的 Leader副本. 生产者将消息发送到Topic中去，同时负责选择将message发送到 Topic的哪个Partition中. 通过 round-robin 做简单的负载均衡. 也可根据消息中某个关键字来进行区分，通常第二种方式使用更多. 对于消费者，传统的消息传递模式有队列模式和发布订阅模式，且基于这2种模式提供了一种Consumer的抽象概念 Consumer Group . Queue模式：多个Consumer从服务器中读取数据，消息只会到达一个Consumer ，所有Consumer都位于同一Consumer Group下 Publish-Subscribe模式：消息会被广播给所有Consumer，所有Consumer都有唯一的Consumer Group . 通常一个Topic会有几个Consumer Group，每个Consumer Group都是一个逻辑上的订阅者，每个Consumer Group由多个Consumer 实例组成，从而达到可扩展和容灾的功能. 一个Partition同一时刻在一个Consumer Group中只能有一个Consumer在消费， Partition分区类似于RocketMQ中的队列，从而保证消费顺序. Consumer Group中的Consumer数不能比一个Topic中Partition的数量多，否则多出来的Consumer消费不到消息. Kafka只在Partition范围内保证消息消费的局部顺序性，不能在同一个Topic中多个Partition中保证总的消费顺序性. 若有在总体上保证消费顺序的需求，则可通过将Topic的Partition数量设置为1 ，将Consumer Group中的Consumer数量也设置为1 ，但会影响性能，故Kafka顺序消费很少用. 客户端调用12345&lt;dependency&gt; &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt; &lt;version&gt;2.4.1&lt;/version&gt;&lt;/dependency&gt; 生产者包含一些关键的参数，包括发送消息持久化机制参数ProducerConfig.ACKS_CONFIG ，发送失败会重试次数 ProducerConfig.RETRIES_CONFIG ，重试时间间隔 ProducerConfig.RETRY_BACKOFF_MS_CONFIG ，以及发送时可指定Partition分区，同步发送异步发送等. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152Properties props = new Properties();props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:9092&quot;);/* 发出消息持久化机制参数（1）acks=0：表示producer不需要等待任何broker确认收到消息的回复，就可以继续发送下一条消息. 性能最高，但是最容易丢消息. （2）acks=1：至少等待leader成功将数据写入本地log，但不用等待所有followe都成功写入. 就可继续发送下一条消息. 该情况下若follower没有成功备份数据，而此时leader又挂掉，则消息会丢失. （3）acks=-1或all：需等待min.insync.replicas，默认为1，推荐配置大于等于2，该参数配置的副本个数都成功写入日志，这种策略会保证 只要有一个备份存活就不会丢失数据. 这是最强的数据保证. 一般除非是金融级别，或跟钱打交道的场景才会使用这种配置. */props.put(ProducerConfig.ACKS_CONFIG, &quot;1&quot;);// 发送失败会重试，默认重试间隔100ms，重试能保证消息发送的可靠性，但也可能造成消息重复发送，如网络抖动，故需在接收者处做好消息接收的幂等性处理props.put(ProducerConfig.RETRIES_CONFIG, 3);// 重试时间间隔设置props.put(ProducerConfig.RETRY_BACKOFF_MS_CONFIG, 300);// 设置发送消息的本地缓冲区，如果设置了该缓冲区，消息会先发送到本地缓冲区，可以提高消息发送性能，默认值是33554432，即32MBprops.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 33554432);// kafka本地线程会从缓冲区取数据，批量发送到broker，设置批量发送消息的大小，默认值是16384，即16kb，就是说一个batch满了16kb就发送出去props.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384);// 默认值是0，消息必须立即被发送，但这样会影响性能，一般设置10毫秒左右，该消息发送完后会进入本地的一个batch，// 若10毫秒内该batch满了16kb就随batch一起被发送出去，若10毫秒内batch没满，则也必须把消息发送出去，不能让消息的发送延迟时间太长props.put(ProducerConfig.LINGER_MS_CONFIG, 10);// 把发送的key从字符串序列化为字节数组props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());// 把发送消息value从字符串序列化为字节数组props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());Producer&lt;String, String&gt; producer = new KafkaProducer&lt;String, String&gt;(props);int msgNum = 5;final CountDownLatch countDownLatch = new CountDownLatch(msgNum);for (int i = 1; i &lt;= msgNum; i++) &#123; // 指定发送分区 // ProducerRecord&lt;String, String&gt; producerRecord = new ProducerRecord&lt;String, String&gt;(TOPIC_NAME , 0, order.getOrderId().toString(), JSON.toJSONString(order)); // 未指定发送分区，具体发送的分区计算公式：hash(key)%partitionNum ProducerRecord&lt;String, String&gt; producerRecord = new ProducerRecord&lt;String, String&gt;(TOPIC_NAME, String.valueOf(i), &quot;order &quot; + i); // 等待消息发送成功的同步阻塞方法 // RecordMetadata metadata = producer.send(producerRecord).get(); // System.out.println(&quot;同步方式发送消息结果：&quot; + &quot;topic-&quot; + metadata.topic() + &quot;|partition-&quot; + metadata.partition() + &quot;|offset-&quot; + metadata.offset()); //异步回调方式发送消息 producer.send(producerRecord, new Callback() &#123; @Override public void onCompletion(RecordMetadata metadata, Exception exception) &#123; if (exception != null) &#123; System.err.println(&quot;发送消息失败：&quot; + exception.getStackTrace()); &#125; if (metadata != null) &#123; System.out.println(&quot;异步方式发送消息结果：&quot; + &quot;topic-&quot; + metadata.topic() + &quot;|partition-&quot; + metadata.partition() + &quot;|offset-&quot; + metadata.offset()); &#125; countDownLatch.countDown(); &#125; &#125;);&#125;countDownLatch.await(5, TimeUnit.SECONDS);producer.close(); 消费者同样可指定消费的分区，指定消费者组名称，是否自动提交，自动提交时间间隔，心跳时间间隔等. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980String TOPIC_NAME = &quot;my-replicated-topic&quot;;String CONSUMER_GROUP_NAME = &quot;testGroup&quot;;Properties props = new Properties();props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:9092&quot;);// 消费分组名props.put(ConsumerConfig.GROUP_ID_CONFIG, CONSUMER_GROUP_NAME);// 是否自动提交offset，默认就是trueprops.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, &quot;true&quot;);// 自动提交offset的间隔时间props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, &quot;1000&quot;);//props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, &quot;false&quot;);/*当消费主题的是一个新的消费组，或指定offset的消费方式，offset不存在，则可通过以下两种方式消费消息- latest(默认) ：只消费自己启动之后发送到主题的消息- earliest：第一次从头开始消费，以后按照消费offset记录继续消费，这个需要区别于consumer.seekToBeginning(每次都从头开始消费)*///props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, &quot;earliest&quot;);// consumer给broker发送心跳的间隔时间，broker接收到心跳若此时有rebalance发生会通过心跳响应将rebalance方案下发给consumer，该时间可以稍微短一点props.put(ConsumerConfig.HEARTBEAT_INTERVAL_MS_CONFIG, 1000);// 服务端broker多久感知不到一个consumer心跳就认为他故障了，会将其踢出消费组，对应的Partition也会被重新分配给其他consumer，默认是10秒props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, 10 * 1000);// 一次poll最大拉取消息的条数，若消费者处理速度很快，可以设置大点，若处理速度一般，可以设置小点props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, 500);// 若两次poll操作间隔超过该时间，则broker认为该consumer处理能力太弱，会将其踢出消费组，将分区分配给别的consumer消费props.put(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG, 30 * 1000);props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;String, String&gt;(props);consumer.subscribe(Arrays.asList(TOPIC_NAME));// 消费指定分区//consumer.assign(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));// 消息回溯消费//consumer.seekToBeginning(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));// 指定offset消费//consumer.seek(new TopicPartition(TOPIC_NAME, 0), 10);// 从指定时间点开始消费/*List&lt;PartitionInfo&gt; topicPartitions = consumer.partitionsFor(TOPIC_NAME);//从1小时前开始消费long fetchDataTime = new Date().getTime() - 1000 * 60 * 60;Map&lt;TopicPartition, Long&gt; map = new HashMap&lt;&gt;();for (PartitionInfo par : topicPartitions) &#123; map.put(new TopicPartition(topicName, par.partition()), fetchDataTime);&#125;Map&lt;TopicPartition, OffsetAndTimestamp&gt; parMap = consumer.offsetsForTimes(map);for (Map.Entry&lt;TopicPartition, OffsetAndTimestamp&gt; entry : parMap.entrySet()) &#123; TopicPartition key = entry.getKey(); OffsetAndTimestamp value = entry.getValue(); if (key == null || value == null) continue; Long offset = value.offset(); System.out.println(&quot;partition-&quot; + key.partition() + &quot;|offset-&quot; + offset); System.out.println(); //根据消费里的timestamp确定offset if (value != null) &#123; consumer.assign(Arrays.asList(key)); consumer.seek(key, offset); &#125;&#125;*/while (true) &#123; // poll() API 是拉取消息的长轮询 ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofMillis(1000)); for (ConsumerRecord&lt;String, String&gt; record : records) &#123; System.out.printf(&quot;收到消息：partition = %d, offset = %d, key = %s, value = %s%n&quot;, record.partition(), record.offset(), record.key(), record.value()); &#125; /*if (records.count() &gt; 0) &#123; // 手动同步提交offset，当前线程会阻塞直到offset提交成功一般使用同步提交，因为提交之后一般也没有什么逻辑代码了 consumer.commitSync(); // 手动异步提交offset，当前线程提交offset不会阻塞，可以继续处理后面的程序逻辑 consumer.commitAsync(new OffsetCommitCallback() &#123; @Override public void onComplete(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets, Exception exception) &#123; if (exception != null) &#123; System.err.println(&quot;Commit failed for &quot; + offsets); System.err.println(&quot;Commit failed exception: &quot; + exception.getStackTrace()); &#125; &#125; &#125;); &#125;*/&#125;","tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://example.com/tags/Kafka/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"Kafka","slug":"工具和中间件/消息队列/Kafka","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Kafka/"}]},{"title":"RabbitMQ-基础","date":"2019-03-23T02:08:20.000Z","path":"blog/工具和中间件/消息队列/RabbitMQ/RabbitMQ-基础/","text":"介绍RabbitMQ 也是一种 消息中间件的实现。与ActiveMQ的区别在： rabbitmq 更专业，更灵活，大企业，大型高要求的应用，普遍会采用 rabbitmq 来支持。 erlangrabbitMQ 是基于 erlang 语言开发的，就如同 activemq 需要安装 java 环境一样， 为了使用 rabbitMQ 需要安装 erlang环境。 erlang 环境使用快捷键 win+r, 然后输入 cmd, 接着运行 erl。 出现如图所示的界面，就表示安装成功了。 安装 rabbitMQ官网下载rar包, 运行里面的 rabbitmq-server-3.6.5.exe，使用默认设置，下一步下一步即可。 配置插件运行如下命令 enable rabbitmq_management，可以做到对 rabbitmq的插件配置。 1C:\\Program Files\\RabbitMQ Server\\rabbitmq_server-3.6.5\\sbin\\rabbitmq-plugins.bat&quot; enable rabbitmq_management 重启 rabbitmq管理员身份运行以下命令以重启 rabbitmq： 1net stop RabbitMQ &amp;&amp; net start RabbitMQ 访问管理界面管理界面： http://127.0.0.1:15672 输入账号： guest密码： guest就可以登陆进去了。 管理界面 RabbitMQ - 模式AMQP AMQP 是 dvanced Message Queuing Protocol 的缩写。 与activemq不一样， rabbitmq 使用的是一种叫做 AMQP 的协议来通信。简单地说，通过这种协议，可以处理更为复杂的业务需求。 基于 AMQP 这种协议，可以实现的各种模式 消息路由过程与 ActiveMQ 拿到消息就直接放在队列等待消费者拿走不同， Rabbit 拿到消息之后，会先交给 交换机 （Exchange）, 然后交换机再根据预先设定的不同绑定( Bindings )策略，来确定要发给哪个队列。如图所示，比起 ActiveMQ 多了 Exchange 和 Bindings。由于有了 Exchange 和 Bindings， RabbitMQ 就可以灵活地支撑各种模式。 模式RabbitMQ提供了 四种Exchange模式： fanout, direct, topic, header。 1. fanout 模式fanout 模式就是广播模式, 消息来了，会发给所有的队列。 2. Direct 模式Direct 模式就是指定队列模式， 消息来了，只发给指定的 Queue, 其他Queue 都收不到。 3. Topic 模式主题模式，注意这里的主题模式，和 ActivityMQ 里的不一样。 ActivityMQ 里的主题，更像是广播模式。那么这里的主题模式是什么意思呢？ 如图所示消息来源有： 美国新闻，美国天气，欧洲新闻，欧洲天气。如果你想看 美国主题： 那么就会收到 美国新闻，美国天气。如果你想看 新闻主题： 那么就会收到 美国新闻，欧洲新闻。如果你想看 天气主题： 那么就会收到 美国天气，欧洲天气。如果你想看 欧洲主题： 那么就会收到 欧洲新闻，欧洲天气。 4. headers交换机 模式。headers交换机是一种比较复杂且少见的交换机，不同于direct和topic，它不关心路由key是否匹配，而只关心header中的key-value对是否匹配(这里的匹配为精确匹配，包含键和值都必须匹配)， 有点类似于http中的请求头。headers头路由模型中，消息是根据prop即请求头中key-value来匹配的。消费方指定的headers中必须包含一个”x-match”的键。 键”x-match”的值有2个：all和any。all：表示消费方指定的所有key-value都必须在消息header中出现并匹配。any：表示消费方指定的key-value至少有一个在消息header中出现并匹配即可。 headers 匹配规则：any 、allany: 只要在发布消息时携带的有一对键值对headers满足队列定义的多个参数的其中一个就能匹配上，注意这里是键值对的完全匹配，只匹配到键了，值却不一样是不行的；all：在发布消息时携带的所有Entry必须和绑定在队列上的所有Entry完全匹配。缺点：Headers 类型的交换器性能会很差","tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://example.com/tags/RabbitMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RabbitMQ","slug":"工具和中间件/消息队列/RabbitMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/"}]},{"title":"Solr更新和删除索引","date":"2018-12-01T08:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/Solr/Solr更新和删除索引/","text":"SolrUtil.javaSolrUtil提供一个对象的增加或者更新(都是同一个方法） 1234567public static &lt;T&gt; boolean saveOrUpdate(T entity) throws SolrServerException, IOException &#123; DocumentObjectBinder binder = new DocumentObjectBinder(); SolrInputDocument doc = binder.toSolrInputDocument(entity); client.add(doc); client.commit(); return true;&#125; 根据id删除这个索引 12345678910public static boolean deleteById(String id) &#123; try &#123; client.deleteById(id); client.commit(); &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; return true;&#125; 完整代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102package cn.peach;import java.io.IOException;import java.util.List;import org.apache.solr.client.solrj.SolrClient;import org.apache.solr.client.solrj.SolrQuery;import org.apache.solr.client.solrj.SolrServerException;import org.apache.solr.client.solrj.beans.DocumentObjectBinder;import org.apache.solr.client.solrj.impl.HttpSolrClient;import org.apache.solr.client.solrj.response.QueryResponse;import org.apache.solr.common.SolrDocument;import org.apache.solr.common.SolrDocumentList;import org.apache.solr.common.SolrInputDocument;import org.apache.solr.common.util.NamedList;public class SolrUtil &#123; public static SolrClient client; private static String url; static &#123; url = &quot;http://localhost:8983/solr/howToSolr&quot;; client = new HttpSolrClient.Builder(url).build(); &#125; public static void queryHighlight(String keywords) throws SolrServerException, IOException &#123; SolrQuery q = new SolrQuery(); //开始页数 q.setStart(0); //每页显示条数 q.setRows(10); // 设置查询关键字 q.setQuery(keywords); // 开启高亮 q.setHighlight(true); // 高亮字段 q.addHighlightField(&quot;name&quot;); // 高亮单词的前缀 q.setHighlightSimplePre(&quot;&lt;span style=&#x27;color:red&#x27;&gt;&quot;); // 高亮单词的后缀 q.setHighlightSimplePost(&quot;&lt;/span&gt;&quot;); //摘要最长100个字符 q.setHighlightFragsize(100); //查询 QueryResponse query = client.query(q); //获取高亮字段name相应结果 NamedList&lt;Object&gt; response = query.getResponse(); NamedList&lt;?&gt; highlighting = (NamedList&lt;?&gt;) response.get(&quot;highlighting&quot;); for (int i = 0; i &lt; highlighting.size(); i++) &#123; System.out.println(highlighting.getName(i) + &quot;：&quot; + highlighting.getVal(i)); &#125; //获取查询结果 SolrDocumentList results = query.getResults(); for (SolrDocument result : results) &#123; System.out.println(result.toString()); &#125; &#125; public static &lt;T&gt; boolean batchSaveOrUpdate(List&lt;T&gt; entities) throws SolrServerException, IOException &#123; DocumentObjectBinder binder = new DocumentObjectBinder(); int total = entities.size(); int count=0; for (T t : entities) &#123; SolrInputDocument doc = binder.toSolrInputDocument(t); client.add(doc); System.out.printf(&quot;添加数据到索引中，总共要添加 %d 条记录，当前添加第%d条 %n&quot;,total,++count); &#125; client.commit(); return true; &#125; public static QueryResponse query(String keywords,int startOfPage, int numberOfPage) throws SolrServerException, IOException &#123; SolrQuery query = new SolrQuery(); query.setStart(startOfPage); query.setRows(numberOfPage); query.setQuery(keywords); QueryResponse rsp = client.query(query); return rsp; &#125; public static &lt;T&gt; boolean saveOrUpdate(T entity) throws SolrServerException, IOException &#123; DocumentObjectBinder binder = new DocumentObjectBinder(); SolrInputDocument doc = binder.toSolrInputDocument(entity); client.add(doc); client.commit(); return true; &#125; public static boolean deleteById(String id) &#123; try &#123; client.deleteById(id); client.commit(); &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; return true; &#125; &#125; TestSolr4j.java 修改之前查询一次 修改之后查询一次 删除之后查询一次 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package cn.peach;import java.io.IOException;import java.util.Collection;import java.util.List;import org.apache.solr.client.solrj.SolrServerException;import org.apache.solr.client.solrj.response.QueryResponse;import org.apache.solr.common.SolrDocument;import org.apache.solr.common.SolrDocumentList;public class TestSolr4j &#123; public static void main(String[] args) throws SolrServerException, IOException &#123; String keyword = &quot;name:鞭&quot;; System.out.println(&quot;修改之前&quot;); query(keyword); Product p = new Product(); p.setId(51173); p.setName(&quot;修改后的神鞭&quot;); SolrUtil.saveOrUpdate(p); System.out.println(&quot;修改之后&quot;); query(keyword); SolrUtil.deleteById(&quot;51173&quot;); System.out.println(&quot;删除之后&quot;); query(keyword); &#125; private static void query(String keyword) throws SolrServerException, IOException &#123; QueryResponse queryResponse = SolrUtil.query(keyword,0,10); SolrDocumentList documents= queryResponse.getResults(); System.out.println(&quot;累计找到的条数：&quot;+documents.getNumFound()); if(!documents.isEmpty())&#123; Collection&lt;String&gt; fieldNames = documents.get(0).getFieldNames(); for (String fieldName : fieldNames) &#123; System.out.print(fieldName+&quot;\\t&quot;); &#125; System.out.println(); &#125; for (SolrDocument solrDocument : documents) &#123; Collection&lt;String&gt; fieldNames= solrDocument.getFieldNames(); for (String fieldName : fieldNames) &#123; System.out.print(solrDocument.get(fieldName)+&quot;\\t&quot;); &#125; System.out.println(); &#125; &#125;&#125; 观察修改和删除的效果: Solr - 进一步学习:Solr官网展开学习：https://lucene.apache.org/solr/","tags":[{"name":"Solr","slug":"Solr","permalink":"http://example.com/tags/Solr/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"Solr","slug":"工具和中间件/搜索引擎技术/Solr","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/Solr/"}]},{"title":"Solr高亮显示","date":"2018-12-01T07:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/Solr/Solr高亮显示/","text":"SolrUtil.java增加queryHighlight 方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283package cn.peach;import java.io.IOException;import java.util.List; import org.apache.solr.client.solrj.SolrClient;import org.apache.solr.client.solrj.SolrQuery;import org.apache.solr.client.solrj.SolrServerException;import org.apache.solr.client.solrj.beans.DocumentObjectBinder;import org.apache.solr.client.solrj.impl.HttpSolrClient;import org.apache.solr.client.solrj.response.QueryResponse;import org.apache.solr.common.SolrDocument;import org.apache.solr.common.SolrDocumentList;import org.apache.solr.common.SolrInputDocument;import org.apache.solr.common.util.NamedList; public class SolrUtil &#123; public static SolrClient client; private static String url; static &#123; url = &quot;http://localhost:8983/solr/howToSolr&quot;; client = new HttpSolrClient.Builder(url).build(); &#125; public static void queryHighlight(String keywords) throws SolrServerException, IOException &#123; SolrQuery q = new SolrQuery(); //开始页数 q.setStart(0); //每页显示条数 q.setRows(10); // 设置查询关键字 q.setQuery(keywords); // 开启高亮 q.setHighlight(true); // 高亮字段 q.addHighlightField(&quot;name&quot;); // 高亮单词的前缀 q.setHighlightSimplePre(&quot;&lt;span style=&#x27;color:red&#x27;&gt;&quot;); // 高亮单词的后缀 q.setHighlightSimplePost(&quot;&lt;/span&gt;&quot;); //摘要最长100个字符 q.setHighlightFragsize(100); //查询 QueryResponse query = client.query(q); //获取高亮字段name相应结果 NamedList&lt;Object&gt; response = query.getResponse(); NamedList&lt;?&gt; highlighting = (NamedList&lt;?&gt;) response.get(&quot;highlighting&quot;); for (int i = 0; i &lt; highlighting.size(); i++) &#123; System.out.println(highlighting.getName(i) + &quot;：&quot; + highlighting.getVal(i)); &#125; //获取查询结果 SolrDocumentList results = query.getResults(); for (SolrDocument result : results) &#123; System.out.println(result.toString()); &#125; &#125; public static &lt;T&gt; boolean batchSaveOrUpdate(List&lt;T&gt; entities) throws SolrServerException, IOException &#123; DocumentObjectBinder binder = new DocumentObjectBinder(); int total = entities.size(); int count=0; for (T t : entities) &#123; SolrInputDocument doc = binder.toSolrInputDocument(t); client.add(doc); System.out.printf(&quot;添加数据到索引中，总共要添加 %d 条记录，当前添加第%d条 %n&quot;,total,++count); &#125; client.commit(); return true; &#125; public static QueryResponse query(String keywords,int startOfPage, int numberOfPage) throws SolrServerException, IOException &#123; SolrQuery query = new SolrQuery(); query.setStart(startOfPage); query.setRows(numberOfPage); query.setQuery(keywords); QueryResponse rsp = client.query(query); return rsp; &#125; &#125; TestSolr4j.java调用queryHighlight 方法 123456789101112131415package cn.peach; import java.io.IOException; import org.apache.solr.client.solrj.SolrServerException; public class TestSolr4j &#123; public static void main(String[] args) throws SolrServerException, IOException &#123; //高亮查询查询 SolrUtil.queryHighlight(&quot;name:手机&quot;); &#125; &#125;","tags":[{"name":"Solr","slug":"Solr","permalink":"http://example.com/tags/Solr/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"Solr","slug":"工具和中间件/搜索引擎技术/Solr","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/Solr/"}]},{"title":"Solr分页查询-Solrj","date":"2018-12-01T06:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/Solr/Solr分页查询-Solrj/","text":"SolrUtil.javaSolrUtil 增加分页查询的方法: 123456789public static QueryResponse query(String keywords,int startOfPage, int numberOfPage) throws SolrServerException, IOException &#123; SolrQuery query = new SolrQuery(); query.setStart(startOfPage); query.setRows(numberOfPage); query.setQuery(keywords); QueryResponse rsp = client.query(query); return rsp;&#125; 完整代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package cn.peach;import java.io.IOException;import java.util.List; import org.apache.solr.client.solrj.SolrClient;import org.apache.solr.client.solrj.SolrQuery;import org.apache.solr.client.solrj.SolrServerException;import org.apache.solr.client.solrj.beans.DocumentObjectBinder;import org.apache.solr.client.solrj.impl.HttpSolrClient;import org.apache.solr.client.solrj.response.QueryResponse;import org.apache.solr.common.SolrDocument;import org.apache.solr.common.SolrDocumentList;import org.apache.solr.common.SolrInputDocument;import org.apache.solr.common.util.NamedList; public class SolrUtil &#123; public static SolrClient client; private static String url; static &#123; url = &quot;http://localhost:8983/solr/howToSolr&quot;; client = new HttpSolrClient.Builder(url).build(); &#125; public static &lt;T&gt; boolean batchSaveOrUpdate(List&lt;T&gt; entities) throws SolrServerException, IOException &#123; DocumentObjectBinder binder = new DocumentObjectBinder(); int total = entities.size(); int count=0; for (T t : entities) &#123; SolrInputDocument doc = binder.toSolrInputDocument(t); client.add(doc); System.out.printf(&quot;添加数据到索引中，总共要添加 %d 条记录，当前添加第%d条 %n&quot;,total,++count); &#125; client.commit(); return true; &#125; public static QueryResponse query(String keywords,int startOfPage, int numberOfPage) throws SolrServerException, IOException &#123; SolrQuery query = new SolrQuery(); query.setStart(startOfPage); query.setRows(numberOfPage); query.setQuery(keywords); QueryResponse rsp = client.query(query); return rsp; &#125; &#125; TestSolr4j.java拿到分页查询的结果，遍历出来 12345678910111213141516171819202122232425262728293031323334353637383940package cn.peach; import java.io.IOException;import java.util.Collection; import org.apache.solr.client.solrj.SolrServerException;import org.apache.solr.client.solrj.response.QueryResponse;import org.apache.solr.common.SolrDocument;import org.apache.solr.common.SolrDocumentList; public class TestSolr4j &#123; public static void main(String[] args) throws SolrServerException, IOException &#123; //查询 QueryResponse queryResponse = SolrUtil.query(&quot;name:手机&quot;,0,10); SolrDocumentList documents= queryResponse.getResults(); System.out.println(&quot;累计找到的条数：&quot;+documents.getNumFound()); if(!documents.isEmpty())&#123; Collection&lt;String&gt; fieldNames = documents.get(0).getFieldNames(); for (String fieldName : fieldNames) &#123; System.out.print(fieldName+&quot;\\t&quot;); &#125; System.out.println(); &#125; for (SolrDocument solrDocument : documents) &#123; Collection&lt;String&gt; fieldNames= solrDocument.getFieldNames(); for (String fieldName : fieldNames) &#123; System.out.print(solrDocument.get(fieldName)+&quot;\\t&quot;); &#125; System.out.println(); &#125; &#125; &#125;","tags":[{"name":"Solr","slug":"Solr","permalink":"http://example.com/tags/Solr/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"Solr","slug":"工具和中间件/搜索引擎技术/Solr","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/Solr/"}]},{"title":"Solr创建索引","date":"2018-12-01T05:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/Solr/Solr创建索引/","text":"如何创建索引：solr 提供了一种方式向其中增加索引的界面，但是不太方便，也和实际工作环境不相符合。以下配置通过程序把数据加入到Solr 索引里。 Product.java准备实体类来存放产品信息注： 每个字段上都有@Field 注解，用来告诉Solr 这些和 howToSolr core里的字段对应 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package cn.peach; import org.apache.solr.client.solrj.beans.Field; public class Product &#123; @Field int id; @Field String name; @Field String category; @Field float price; @Field String place; @Field String code; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getCategory() &#123; return category; &#125; public void setCategory(String category) &#123; this.category = category; &#125; public float getPrice() &#123; return price; &#125; public void setPrice(float price) &#123; this.price = price; &#125; public String getPlace() &#123; return place; &#125; public void setPlace(String place) &#123; this.place = place; &#125; public String getCode() &#123; return code; &#125; public void setCode(String code) &#123; this.code = code; &#125; @Override public String toString() &#123; return &quot;Product [id=&quot; + id + &quot;, name=&quot; + name + &quot;, category=&quot; + category + &quot;, price=&quot; + price + &quot;, place=&quot; + place + &quot;, code=&quot; + code + &quot;]&quot;; &#125; &#125; ProductUtil.java工具类，把 140k_products.txt 文本文件，转换为泛型是Product的集合, 参考Lucene分页查询工具类。 SolrUtil.java工具类，用来把产品集合批量增加到Solr. 这里就用到了SolrJ第三方包里的api了。 123456789101112131415161718192021222324252627282930313233package cn.peach;import java.io.IOException;import java.util.List; import org.apache.solr.client.solrj.SolrClient;import org.apache.solr.client.solrj.SolrServerException;import org.apache.solr.client.solrj.beans.DocumentObjectBinder;import org.apache.solr.client.solrj.impl.HttpSolrClient;import org.apache.solr.common.SolrInputDocument; public class SolrUtil &#123; public static SolrClient client; private static String url; static &#123; url = &quot;http://localhost:8983/solr/howToSolr&quot;; client = new HttpSolrClient.Builder(url).build(); &#125; public static &lt;T&gt; boolean batchSaveOrUpdate(List&lt;T&gt; entities) throws SolrServerException, IOException &#123; DocumentObjectBinder binder = new DocumentObjectBinder(); int total = entities.size(); int count=0; for (T t : entities) &#123; SolrInputDocument doc = binder.toSolrInputDocument(t); client.add(doc); System.out.printf(&quot;添加数据到索引中，总共要添加 %d 条记录，当前添加第%d条 %n&quot;,total,++count); &#125; client.commit(); return true; &#125; &#125; TestSolr4j:得到14万个产品对象，然后通过SolrUtil 工具类提交到Solr 服务器。 123456789101112package cn.peach;import java.io.IOException;import java.util.List;import org.apache.solr.client.solrj.SolrServerException; public class TestSolr4j &#123; public static void main(String[] args) throws SolrServerException, IOException &#123; List&lt;Product&gt; products = ProductUtil.file2list(&quot;140k_products.txt&quot;); SolrUtil.batchSaveOrUpdate(products); &#125;&#125; 验证提交效果:","tags":[{"name":"Solr","slug":"Solr","permalink":"http://example.com/tags/Solr/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"Solr","slug":"工具和中间件/搜索引擎技术/Solr","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/Solr/"}]},{"title":"Solr设置字段","date":"2018-12-01T04:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/Solr/Solr设置字段/","text":"字段概念:创建Core 中的Core就相当于表，那么接下来就要为这个表设置字段，用于存放数据。 创建字段： 创建name字段：左边选中 howToSolr -&gt; Schema -&gt; Add Field 输入name: name， field type: text_ik, 这里一定要使用中文分词 中新创建的 text_ik类型，否则后续查询中文会失败。然后点击 Add Field按钮进行添加： 创建其他字段：按照创建name字段 的方式，继续创建如下字段： category text_ik, price pfloat, place text_ik, code text_ik注： price的类型是pfloat 关于id字段:id字段是默认就有的，无需自己创建 查看创建的字段:","tags":[{"name":"Solr","slug":"Solr","permalink":"http://example.com/tags/Solr/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"Solr","slug":"工具和中间件/搜索引擎技术/Solr","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/Solr/"}]},{"title":"Solr中文分词器IKAnalyzer","date":"2018-12-01T03:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/Solr/Solr中文分词器IKAnalyzer/","text":"中文分词默认情况下是没有中文分词的，如图所示，通过点击左边的howToSolr-&gt;Analysis 然后输入 四川省成都市动物园，得到是按照每个字的分词效果 配置中文分词下载 IKAnalyzer6.5.0.jar复制到如下目录：D:\\software\\solr-7.2.1\\server\\solr-webapp\\webapp\\WEB-INF\\lib 增加新的字段类型修改配置文件 managed-schema： 1D:\\software\\solr-7.2.1\\server\\solr\\howToSolr\\conf\\managed-schema 在line41 位置处 &lt;schema…&gt; 标签下增加如下代码: 12345&lt;schema name=&quot;default-config&quot; version=&quot;1.6&quot;&gt; &lt;fieldType name=&quot;text_ik&quot; class=&quot;solr.TextField&quot;&gt; &lt;analyzer class=&quot;org.wltea.analyzer.lucene.IKAnalyzer&quot;/&gt; &lt;/fieldType&gt; &lt;field name=&quot;text_ik&quot; type=&quot;text_ik&quot; indexed=&quot;true&quot; stored=&quot;true&quot; multiValued=&quot;false&quot; /&gt; 重启 Solr使用如下命令重启 123cd d:\\software\\solr-7.2.1\\binsolr.cmd stop -allsolr.cmd start 重新测试分词如图所示，使用中文分词后，就可以看到分词的效果了。注： FieldType 记得选增加新的字段类型 中的 text_ik","tags":[{"name":"Solr","slug":"Solr","permalink":"http://example.com/tags/Solr/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"Solr","slug":"工具和中间件/搜索引擎技术/Solr","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/Solr/"}]},{"title":"Solr基础","date":"2018-12-01T02:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/Solr/Solr基础/","text":"Solr概念：以连接数据库为类比：Lucene 就相当于JDBC，是基本的用法。Solr 就相当 Mybatis， 方便开发人员配置，访问和调用。而且Solr 被做成了 webapp形式，以tomcat的应用的方式启动，提供了可视化的配置界面 启动服务器官网(https://lucene.apache.org/solr/)下载solr并解压(我下载的是solr-7.2.1.rar), 我的解压目录在 D:\\software\\solr-7.2.1 12cd d:\\software\\solr-7.2.1\\binsolr.cmd start 如此就启动了服务器，会占用端口8983。 倘若端口被占用，会启动失败. 访问服务器:浏览器输入：http://127.0.0.1:8983/solr/#/ Core 概念：如果说Solr相当于一个数据库的话，那么Core就相当于一张表 不要通过图形界面创建Core如图所示，通过图形界面创建Core会失败，应该使用 命令行方式创建Core: 命令行方式创建Core12cd d:\\software\\solr-7.2.1\\binsolr.cmd create -c howToSolr 删除 new_core如果点击了步骤 不要通过图形界面创建Core 里的图形界面里的 Add Core,那么就会一直有错误提醒，那么按照如下方式删除 new_core 就不会再有错误提醒了 12cd d:\\software\\solr-7.2.1\\binsolr.cmd delete -c new_core","tags":[{"name":"Solr","slug":"Solr","permalink":"http://example.com/tags/Solr/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"Solr","slug":"工具和中间件/搜索引擎技术/Solr","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/Solr/"}]},{"title":"Lucene索引删除和更新","date":"2018-10-02T05:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/Lucene/Lucene索引删除和更新/","text":"索引删除和更新索引建立好了之后，还是需要维护的，比如新增，删除和维护。 新增就是建立索引的过程。索引里的数据，其实就是一个一个的Document 对象，那么本文就是介绍如何删除和更新这些Documen对象。 删除索引123456//删除id=51173的数据IndexWriterConfig config = new IndexWriterConfig(analyzer);IndexWriter indexWriter = new IndexWriter(index, config);indexWriter.deleteDocuments(new Term(&quot;id&quot;, &quot;51173&quot;));indexWriter.commit();indexWriter.close(); 更多删除还可以按照如下方法来删除索引: DeleteDocuments(Query query):根据Query条件来删除单个或多个Document DeleteDocuments(Query[] queries):根据Query条件来删除单个或多个Document DeleteDocuments(Term term):根据Term来删除单个或多个Document DeleteDocuments(Term[] terms):根据Term来删除单个或多个Document DeleteAll():删除所有的Document 更新索引12345678910111213// 更新索引IndexWriterConfig config = new IndexWriterConfig(analyzer);IndexWriter indexWriter = new IndexWriter(index, config);Document doc = new Document();doc.add(new TextField(&quot;id&quot;, &quot;51173&quot;, Field.Store.YES));doc.add(new TextField(&quot;name&quot;, &quot;神鞭，鞭没了，神还在&quot;, Field.Store.YES));doc.add(new TextField(&quot;category&quot;, &quot;道具&quot;, Field.Store.YES));doc.add(new TextField(&quot;price&quot;, &quot;998&quot;, Field.Store.YES));doc.add(new TextField(&quot;place&quot;, &quot;南海群岛&quot;, Field.Store.YES));doc.add(new TextField(&quot;code&quot;, &quot;888888&quot;, Field.Store.YES));indexWriter.updateDocument(new Term(&quot;id&quot;, &quot;51173&quot;), doc );indexWriter.commit();indexWriter.close(); LUCENE - 进一步学习:Lucene官网展开学习：https://lucene.apache.org/","tags":[{"name":"Lucene","slug":"Lucene","permalink":"http://example.com/tags/Lucene/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"Lucene","slug":"工具和中间件/搜索引擎技术/Lucene","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/Lucene/"}]},{"title":"Lucene分页查询","date":"2018-10-02T04:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/Lucene/Lucene分页查询/","text":"分页查询-两种方式:Lucene 分页通常来讲有两种方式： 第一种是把100条数据查出来，然后取最后10条。 优点是快，缺点是对内存消耗大。 第二种是把第90条查询出来，然后基于这一条，通过searchAfter方法查询10条数据。 优点是内存消耗小，缺点是比第一种更慢 准备实体类来存放产品信息12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package cn.peach;public class Product &#123; int id; String name; String category; float price; String place; String code; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getCategory() &#123; return category; &#125; public void setCategory(String category) &#123; this.category = category; &#125; public float getPrice() &#123; return price; &#125; public void setPrice(float price) &#123; this.price = price; &#125; public String getPlace() &#123; return place; &#125; public void setPlace(String place) &#123; this.place = place; &#125; public String getCode() &#123; return code; &#125; public void setCode(String code) &#123; this.code = code; &#125; @Override public String toString() &#123; return &quot;Product [id=&quot; + id + &quot;, name=&quot; + name + &quot;, category=&quot; + category + &quot;, price=&quot; + price + &quot;, place=&quot; + place + &quot;, code=&quot; + code + &quot;]&quot;; &#125;&#125; 准备工具类读取14万条数据把140k_products.txt 文本文件，转换为泛型是Product的集合 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package cn.peach;import java.awt.AWTException;import java.io.File;import java.io.IOException;import java.util.ArrayList;import java.util.HashSet;import java.util.List;import java.util.Set;import org.apache.commons.io.FileUtils; public class ProductUtil &#123; public static void main(String[] args) throws IOException, InterruptedException, AWTException &#123; String fileName = &quot;140k_products.txt&quot;; List&lt;Product&gt; products = file2list(fileName); System.out.println(products.size()); &#125; public static List&lt;Product&gt; file2list(String fileName) throws IOException &#123; File f = new File(fileName); List&lt;String&gt; lines = FileUtils.readLines(f,&quot;UTF-8&quot;); List&lt;Product&gt; products = new ArrayList&lt;&gt;(); for (String line : lines) &#123; Product p = line2product(line); products.add(p); &#125; return products; &#125; private static Product line2product(String line) &#123; Product p = new Product(); String[] fields = line.split(&quot;,&quot;); p.setId(Integer.parseInt(fields[0])); p.setName(fields[1]); p.setCategory(fields[2]); p.setPrice(Float.parseFloat(fields[3])); p.setPlace(fields[4]); p.setCode(fields[5]); return p; &#125;&#125; 第一种:一共查出 pageNow*pageSize条，然后取最后pageSize条： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142package cn.peach;import java.io.IOException;import java.io.StringReader;import java.util.ArrayList;import java.util.List;import org.apache.lucene.analysis.TokenStream;import org.apache.lucene.document.Document;import org.apache.lucene.document.Field;import org.apache.lucene.document.TextField;import org.apache.lucene.index.DirectoryReader;import org.apache.lucene.index.IndexReader;import org.apache.lucene.index.IndexWriter;import org.apache.lucene.index.IndexWriterConfig;import org.apache.lucene.index.IndexableField;import org.apache.lucene.queryparser.classic.QueryParser;import org.apache.lucene.search.IndexSearcher;import org.apache.lucene.search.Query;import org.apache.lucene.search.ScoreDoc;import org.apache.lucene.search.TopDocs;import org.apache.lucene.search.highlight.Highlighter;import org.apache.lucene.search.highlight.QueryScorer;import org.apache.lucene.search.highlight.SimpleHTMLFormatter;import org.apache.lucene.store.Directory;import org.apache.lucene.store.RAMDirectory;import org.wltea.analyzer.lucene.IKAnalyzer;public class TestLucene &#123; public static void main(String[] args) throws Exception &#123; // 1. 准备中文分词器 IKAnalyzer analyzer = new IKAnalyzer(); // 2. 索引 Directory index = createIndex(analyzer); // 3. 查询器 String keyword = &quot;手机&quot;; System.out.println(&quot;当前关键字是：&quot;+keyword); Query query = new QueryParser( &quot;name&quot;, analyzer).parse(keyword); // 4. 搜索 IndexReader reader = DirectoryReader.open(index); IndexSearcher searcher=new IndexSearcher(reader); int pageNow = 1; int pageSize = 10; ScoreDoc[] hits = pageSearch1(query, searcher, pageNow, pageSize); // 5. 显示查询结果 showSearchResults(searcher, hits,query,analyzer); // 6. 关闭查询 reader.close(); &#125; private static ScoreDoc[] pageSearch1(Query query, IndexSearcher searcher, int pageNow, int pageSize) throws IOException &#123; TopDocs topDocs = searcher.search(query, pageNow*pageSize); System.out.println(&quot;查询到的总条数\\t&quot;+topDocs.totalHits); ScoreDoc [] alllScores = topDocs.scoreDocs; List&lt;ScoreDoc&gt; hitScores = new ArrayList&lt;&gt;(); int start = (pageNow -1)*pageSize ; int end = pageSize*pageNow; for(int i=start;i&lt;end;i++) hitScores.add(alllScores[i]); ScoreDoc[] hits = hitScores.toArray(new ScoreDoc[]&#123;&#125;); return hits; &#125; private static void showSearchResults(IndexSearcher searcher, ScoreDoc[] hits, Query query, IKAnalyzer analyzer) throws Exception &#123; System.out.println(&quot;找到 &quot; + hits.length + &quot; 个命中.&quot;); SimpleHTMLFormatter simpleHTMLFormatter = new SimpleHTMLFormatter(&quot;&lt;span style=&#x27;color:red&#x27;&gt;&quot;, &quot;&lt;/span&gt;&quot;); Highlighter highlighter = new Highlighter(simpleHTMLFormatter, new QueryScorer(query)); System.out.println(&quot;找到 &quot; + hits.length + &quot; 个命中.&quot;); System.out.println(&quot;序号\\t匹配度得分\\t结果&quot;); for (int i = 0; i &lt; hits.length; ++i) &#123; ScoreDoc scoreDoc= hits[i]; int docId = scoreDoc.doc; Document d = searcher.doc(docId); List&lt;IndexableField&gt; fields= d.getFields(); System.out.print((i + 1) ); System.out.print(&quot;\\t&quot; + scoreDoc.score); for (IndexableField f : fields) &#123; if(&quot;name&quot;.equals(f.name()))&#123; TokenStream tokenStream = analyzer.tokenStream(f.name(), new StringReader(d.get(f.name()))); String fieldContent = highlighter.getBestFragment(tokenStream, d.get(f.name())); System.out.print(&quot;\\t&quot;+fieldContent); &#125; else&#123; System.out.print(&quot;\\t&quot;+d.get(f.name())); &#125; &#125; System.out.println(&quot;&lt;br&gt;&quot;); &#125; &#125; private static Directory createIndex(IKAnalyzer analyzer) throws IOException &#123; Directory index = new RAMDirectory(); IndexWriterConfig config = new IndexWriterConfig(analyzer); IndexWriter writer = new IndexWriter(index, config); String fileName = &quot;140k_products.txt&quot;; List&lt;Product&gt; products = ProductUtil.file2list(fileName); int total = products.size(); int count = 0; int per = 0; int oldPer =0; for (Product p : products) &#123; addDoc(writer, p); count++; per = count*100/total; if(per!=oldPer)&#123; oldPer = per; System.out.printf(&quot;索引中，总共要添加 %d 条记录，当前添加进度是： %d%% %n&quot;,total,per); &#125; if(per&gt;10) break; &#125; writer.close(); return index; &#125; private static void addDoc(IndexWriter w, Product p) throws IOException &#123; Document doc = new Document(); doc.add(new TextField(&quot;id&quot;, String.valueOf(p.getId()), Field.Store.YES)); doc.add(new TextField(&quot;name&quot;, p.getName(), Field.Store.YES)); doc.add(new TextField(&quot;category&quot;, p.getCategory(), Field.Store.YES)); doc.add(new TextField(&quot;price&quot;, String.valueOf(p.getPrice()), Field.Store.YES)); doc.add(new TextField(&quot;place&quot;, p.getPlace(), Field.Store.YES)); doc.add(new TextField(&quot;code&quot;, p.getCode(), Field.Store.YES)); w.addDocument(doc); &#125;&#125; 第二种首先是边界条件，如果是第一页，就直接查询了。如果不是第一页，那么就取start-1那一条，然后再根据它通过searchAfter 来查询： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162package cn.peach;import java.io.IOException;import java.io.StringReader;import java.util.ArrayList;import java.util.List;import org.apache.lucene.analysis.TokenStream;import org.apache.lucene.document.Document;import org.apache.lucene.document.Field;import org.apache.lucene.document.TextField;import org.apache.lucene.index.DirectoryReader;import org.apache.lucene.index.IndexReader;import org.apache.lucene.index.IndexWriter;import org.apache.lucene.index.IndexWriterConfig;import org.apache.lucene.index.IndexableField;import org.apache.lucene.queryparser.classic.QueryParser;import org.apache.lucene.search.IndexSearcher;import org.apache.lucene.search.Query;import org.apache.lucene.search.ScoreDoc;import org.apache.lucene.search.TopDocs;import org.apache.lucene.search.highlight.Highlighter;import org.apache.lucene.search.highlight.QueryScorer;import org.apache.lucene.search.highlight.SimpleHTMLFormatter;import org.apache.lucene.store.Directory;import org.apache.lucene.store.RAMDirectory;import org.wltea.analyzer.lucene.IKAnalyzer;public class TestLucene &#123; public static void main(String[] args) throws Exception &#123; // 1. 准备中文分词器 IKAnalyzer analyzer = new IKAnalyzer(); // 2. 索引 Directory index = createIndex(analyzer); // 3. 查询器 String keyword = &quot;手机&quot;; System.out.println(&quot;当前关键字是：&quot;+keyword); Query query = new QueryParser( &quot;name&quot;, analyzer).parse(keyword); // 4. 搜索 IndexReader reader = DirectoryReader.open(index); IndexSearcher searcher=new IndexSearcher(reader); int pageNow = 1; int pageSize = 10; ScoreDoc[] hits = pageSearch2(query, searcher, pageNow, pageSize); // 5. 显示查询结果 showSearchResults(searcher, hits,query,analyzer); // 6. 关闭查询 reader.close(); &#125; private static ScoreDoc[] pageSearch1(Query query, IndexSearcher searcher, int pageNow, int pageSize) throws IOException &#123; TopDocs topDocs = searcher.search(query, pageNow*pageSize); System.out.println(&quot;查询到的总条数\\t&quot;+topDocs.totalHits); ScoreDoc [] alllScores = topDocs.scoreDocs; List&lt;ScoreDoc&gt; hitScores = new ArrayList&lt;&gt;(); int start = (pageNow -1)*pageSize ; int end = pageSize*pageNow; for(int i=start;i&lt;end;i++) hitScores.add(alllScores[i]); ScoreDoc[] hits = hitScores.toArray(new ScoreDoc[]&#123;&#125;); return hits; &#125; private static ScoreDoc[] pageSearch2(Query query, IndexSearcher searcher, int pageNow, int pageSize) throws IOException &#123; int start = (pageNow - 1) * pageSize; if(0==start)&#123; TopDocs topDocs = searcher.search(query, pageNow*pageSize); return topDocs.scoreDocs; &#125; // 查询数据， 结束页面自前的数据都会查询到，但是只取本页的数据 TopDocs topDocs = searcher.search(query, start); //获取到上一页最后一条 ScoreDoc preScore= topDocs.scoreDocs[start-1]; //查询最后一条后的数据的一页数据 topDocs = searcher.searchAfter(preScore, query, pageSize); return topDocs.scoreDocs; &#125; private static void showSearchResults(IndexSearcher searcher, ScoreDoc[] hits, Query query, IKAnalyzer analyzer) throws Exception &#123; System.out.println(&quot;找到 &quot; + hits.length + &quot; 个命中.&quot;); SimpleHTMLFormatter simpleHTMLFormatter = new SimpleHTMLFormatter(&quot;&lt;span style=&#x27;color:red&#x27;&gt;&quot;, &quot;&lt;/span&gt;&quot;); Highlighter highlighter = new Highlighter(simpleHTMLFormatter, new QueryScorer(query)); System.out.println(&quot;找到 &quot; + hits.length + &quot; 个命中.&quot;); System.out.println(&quot;序号\\t匹配度得分\\t结果&quot;); for (int i = 0; i &lt; hits.length; ++i) &#123; ScoreDoc scoreDoc= hits[i]; int docId = scoreDoc.doc; Document d = searcher.doc(docId); List&lt;IndexableField&gt; fields= d.getFields(); System.out.print((i + 1) ); System.out.print(&quot;\\t&quot; + scoreDoc.score); for (IndexableField f : fields) &#123; if(&quot;name&quot;.equals(f.name()))&#123; TokenStream tokenStream = analyzer.tokenStream(f.name(), new StringReader(d.get(f.name()))); String fieldContent = highlighter.getBestFragment(tokenStream, d.get(f.name())); System.out.print(&quot;\\t&quot;+fieldContent); &#125; else&#123; System.out.print(&quot;\\t&quot;+d.get(f.name())); &#125; &#125; System.out.println(&quot;&lt;br&gt;&quot;); &#125; &#125; private static Directory createIndex(IKAnalyzer analyzer) throws IOException &#123; Directory index = new RAMDirectory(); IndexWriterConfig config = new IndexWriterConfig(analyzer); IndexWriter writer = new IndexWriter(index, config); String fileName = &quot;140k_products.txt&quot;; List&lt;Product&gt; products = ProductUtil.file2list(fileName); int total = products.size(); int count = 0; int per = 0; int oldPer =0; for (Product p : products) &#123; addDoc(writer, p); count++; per = count*100/total; if(per!=oldPer)&#123; oldPer = per; System.out.printf(&quot;索引中，总共要添加 %d 条记录，当前添加进度是： %d%% %n&quot;,total,per); &#125; if(per&gt;10) break; &#125; writer.close(); return index; &#125; private static void addDoc(IndexWriter w, Product p) throws IOException &#123; Document doc = new Document(); doc.add(new TextField(&quot;id&quot;, String.valueOf(p.getId()), Field.Store.YES)); doc.add(new TextField(&quot;name&quot;, p.getName(), Field.Store.YES)); doc.add(new TextField(&quot;category&quot;, p.getCategory(), Field.Store.YES)); doc.add(new TextField(&quot;price&quot;, String.valueOf(p.getPrice()), Field.Store.YES)); doc.add(new TextField(&quot;place&quot;, p.getPlace(), Field.Store.YES)); doc.add(new TextField(&quot;code&quot;, p.getCode(), Field.Store.YES)); w.addDocument(doc); &#125;&#125;","tags":[{"name":"Lucene","slug":"Lucene","permalink":"http://example.com/tags/Lucene/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"Lucene","slug":"工具和中间件/搜索引擎技术/Lucene","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/Lucene/"}]},{"title":"Lucene分词器","date":"2018-10-02T03:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/Lucene/Lucene分词器/","text":"分词器概念：分词器指的是搜索引擎如何使用关键字进行匹配，如 基础 中的关键字：护眼带光源。 如果使用like,那么%护眼带光源%，匹配出来的结果就是要么全匹配，要不都不匹配。而使用分词器，就会把这个关键字分为 护眼，带，光源 3个关键字，这样就可以找到不同相关程度的结果了。 IKAnalyzer6.5.0.jarIKAnalyzer 这个分词器很久都没有维护了，也不支持Lucene7。 代码演示 TestAnalyzer12345678910111213141516171819package cn.peach; import java.io.IOException; import org.apache.lucene.analysis.TokenStream;import org.wltea.analyzer.lucene.IKAnalyzer; public class TestAnalyzer &#123; public static void main(String[] args) throws IOException &#123; IKAnalyzer analyzer = new IKAnalyzer(); TokenStream ts= analyzer.tokenStream(&quot;name&quot;, &quot;护眼带光源&quot;); ts.reset(); while(ts.incrementToken())&#123; System.out.println(ts.reflectAsString(false)); &#125; &#125;&#125; 高亮显示:70,71行 81,82行 增加高亮显示123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106package cn.peach;import java.io.IOException;import java.io.StringReader;import java.util.ArrayList;import java.util.List;import org.apache.lucene.analysis.TokenStream;import org.apache.lucene.document.Document;import org.apache.lucene.document.Field;import org.apache.lucene.document.TextField;import org.apache.lucene.index.DirectoryReader;import org.apache.lucene.index.IndexReader;import org.apache.lucene.index.IndexWriter;import org.apache.lucene.index.IndexWriterConfig;import org.apache.lucene.index.IndexableField;import org.apache.lucene.queryparser.classic.QueryParser;import org.apache.lucene.search.IndexSearcher;import org.apache.lucene.search.Query;import org.apache.lucene.search.ScoreDoc;import org.apache.lucene.search.highlight.Highlighter;import org.apache.lucene.search.highlight.QueryScorer;import org.apache.lucene.search.highlight.SimpleHTMLFormatter;import org.apache.lucene.store.Directory;import org.apache.lucene.store.RAMDirectory;import org.wltea.analyzer.lucene.IKAnalyzer;public class TestLucene &#123; public static void main(String[] args) throws Exception &#123; // 1. 准备中文分词器 IKAnalyzer analyzer = new IKAnalyzer(); // 2. 索引 List&lt;String&gt; productNames = new ArrayList&lt;&gt;(); productNames.add(&quot;飞利浦led灯泡e27螺口暖白球泡灯家用照明超亮节能灯泡转色温灯泡&quot;); productNames.add(&quot;飞利浦led灯泡e14螺口蜡烛灯泡3W尖泡拉尾节能灯泡暖黄光源Lamp&quot;); productNames.add(&quot;雷士照明 LED灯泡 e27大螺口节能灯3W球泡灯 Lamp led节能灯泡&quot;); productNames.add(&quot;飞利浦 led灯泡 e27螺口家用3w暖白球泡灯节能灯5W灯泡LED单灯7w&quot;); productNames.add(&quot;飞利浦led小球泡e14螺口4.5w透明款led节能灯泡照明光源lamp单灯&quot;); productNames.add(&quot;飞利浦蒲公英护眼台灯工作学习阅读节能灯具30508带光源&quot;); productNames.add(&quot;欧普照明led灯泡蜡烛节能灯泡e14螺口球泡灯超亮照明单灯光源&quot;); productNames.add(&quot;欧普照明led灯泡节能灯泡超亮光源e14e27螺旋螺口小球泡暖黄家用&quot;); productNames.add(&quot;聚欧普照明led灯泡节能灯泡e27螺口球泡家用led照明单灯超亮光源&quot;); Directory index = createIndex(analyzer, productNames); // 3. 查询器 String keyword = &quot;护眼带光源&quot;; Query query = new QueryParser(&quot;name&quot;, analyzer).parse(keyword); // 4. 搜索 IndexReader reader = DirectoryReader.open(index); IndexSearcher searcher = new IndexSearcher(reader); int numberPerPage = 1000; System.out.printf(&quot;当前一共有%d条数据%n&quot;,productNames.size()); System.out.printf(&quot;查询关键字是：\\&quot;%s\\&quot;%n&quot;,keyword); ScoreDoc[] hits = searcher.search(query, numberPerPage).scoreDocs; // 5. 显示查询结果 showSearchResults(searcher, hits, query, analyzer); // 6. 关闭查询 reader.close(); &#125; private static void showSearchResults(IndexSearcher searcher, ScoreDoc[] hits, Query query, IKAnalyzer analyzer) throws Exception &#123; System.out.println(&quot;找到 &quot; + hits.length + &quot; 个命中.&quot;); System.out.println(&quot;序号\\t匹配度得分\\t结果&quot;); SimpleHTMLFormatter simpleHTMLFormatter = new SimpleHTMLFormatter(&quot;&lt;span style=&#x27;color:red&#x27;&gt;&quot;, &quot;&lt;/span&gt;&quot;); Highlighter highlighter = new Highlighter(simpleHTMLFormatter, new QueryScorer(query)); for (int i = 0; i &lt; hits.length; ++i) &#123; ScoreDoc scoreDoc= hits[i]; int docId = scoreDoc.doc; Document d = searcher.doc(docId); List&lt;IndexableField&gt; fields = d.getFields(); System.out.print((i + 1)); System.out.print(&quot;\\t&quot; + scoreDoc.score); for (IndexableField f : fields) &#123; TokenStream tokenStream = analyzer.tokenStream(f.name(), new StringReader(d.get(f.name()))); String fieldContent = highlighter.getBestFragment(tokenStream, d.get(f.name())); System.out.print(&quot;\\t&quot; + fieldContent); &#125; System.out.println(&quot;&lt;br&gt;&quot;); &#125; &#125; private static Directory createIndex(IKAnalyzer analyzer, List&lt;String&gt; products) throws IOException &#123; Directory index = new RAMDirectory(); IndexWriterConfig config = new IndexWriterConfig(analyzer); IndexWriter writer = new IndexWriter(index, config); for (String name : products) &#123; addDoc(writer, name); &#125; writer.close(); return index; &#125; private static void addDoc(IndexWriter w, String name) throws IOException &#123; Document doc = new Document(); doc.add(new TextField(&quot;name&quot;, name, Field.Store.YES)); w.addDocument(doc); &#125;&#125; 运行结果运行结果是html代码，为了正常显示，复制到一个html文件里，打开就可以看到效果了.","tags":[{"name":"Lucene","slug":"Lucene","permalink":"http://example.com/tags/Lucene/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"Lucene","slug":"工具和中间件/搜索引擎技术/Lucene","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/Lucene/"}]},{"title":"Lucene基础","date":"2018-10-02T02:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/Lucene/Lucene基础/","text":"Lucene 概念:Lucene 这个开源项目，使得 Java开发人员可以很方便地得到像搜索引擎google baidu那样的搜索效果。 Lucene是一个全文检索框架，通过程序扫描文本中每个单词，针对单词建立索引，并保存该单词在文本中的位置、以及出现次数。用户查询时通过之前建立好的索引来查询，将索引中单词对应文本位置、出现次数返给用户，有了具体文本位置，则可将具体内容读取出来。 Lucene基于倒排索引，对于使用的数据库主键索引是通过主键定位到某条数据，而倒排索引刚好相反，是通过数据对应到主键。 分词器：准备中文分词器， 12// 1. 准备中文分词器IKAnalyzer analyzer = new IKAnalyzer(); 创建索引:首先准备10条数据这10条数据都是字符串，相当于产品表里的数据 123456789101112// 索引List&lt;String&gt; productNames = new ArrayList&lt;&gt;();productNames.add(&quot;飞利浦led灯泡e27螺口暖白球泡灯家用照明超亮节能灯泡转色温灯泡&quot;);productNames.add(&quot;飞利浦led灯泡e14螺口蜡烛灯泡3W尖泡拉尾节能灯泡暖黄光源Lamp&quot;);productNames.add(&quot;雷士照明 LED灯泡 e27大螺口节能灯3W球泡灯 Lamp led节能灯泡&quot;);productNames.add(&quot;飞利浦 led灯泡 e27螺口家用3w暖白球泡灯节能灯5W灯泡LED单灯7w&quot;);productNames.add(&quot;飞利浦led小球泡e14螺口4.5w透明款led节能灯泡照明光源lamp单灯&quot;);productNames.add(&quot;飞利浦蒲公英护眼台灯工作学习阅读节能灯具30508带光源&quot;);productNames.add(&quot;欧普照明led灯泡蜡烛节能灯泡e14螺口球泡灯超亮照明单灯光源&quot;);productNames.add(&quot;欧普照明led灯泡节能灯泡超亮光源e14e27螺旋螺口小球泡暖黄家用&quot;);productNames.add(&quot;聚欧普照明led灯泡节能灯泡e27螺口球泡家用led照明单灯超亮光源&quot;); Directory index = createIndex(analyzer, productNames); 通过 createIndex 方法，把它加入到索引当中: 问题： 创建内存索引，为什么Lucene会比数据库快? 因为它是从内存里查，自然就比数据库里快多了.1234567891011121314private static Directory createIndex(IKAnalyzer analyzer, List&lt;String&gt; products) throws IOException &#123; &lt;!-- 创建内存索引 --&gt; Directory index = new RAMDirectory(); &lt;!-- 根据中文分词器创建配置对象 --&gt; IndexWriterConfig config = new IndexWriterConfig(analyzer); &lt;!-- 创建索引 writer --&gt; IndexWriter writer = new IndexWriter(index, config); &lt;!-- 遍历那10条数据，把他们挨个放进索引里 --&gt; for (String name : products) &#123; addDoc(writer, name); &#125; writer.close(); return index;&#125; 每条数据创建一个Document，并把这个Document放进索引里。 这个Document有一个字段，叫做”name”。 TestLucene.java 第49行创建查询器，就会指定查询这个字段. 12345private static void addDoc(IndexWriter w, String name) throws IOException &#123; Document doc = new Document(); doc.add(new TextField(&quot;name&quot;, name, Field.Store.YES)); w.addDocument(doc);&#125; 创建查询器根据关键字 护眼带光源，基于 “name” 字段进行查询。 这个 “name” 字段就是在创建索引步骤里每个Document的 “name” 字段，相当于表的字段名. 12String keyword = &quot;护眼带光源&quot;;Query query = new QueryParser(&quot;name&quot;, analyzer).parse(keyword); 执行搜索12345678910&lt;!-- 创建索引 reader: --&gt;IndexReader reader = DirectoryReader.open(index);&lt;!-- 基于 reader 创建搜索器： --&gt;IndexSearcher searcher = new IndexSearcher(reader);&lt;!-- 指定每页要显示多少条数据： --&gt;int numberPerPage = 1000;System.out.printf(&quot;当前一共有%d条数据%n&quot;,productNames.size());System.out.printf(&quot;查询关键字是：\\&quot;%s\\&quot;%n&quot;,keyword);&lt;!-- 执行搜索 --&gt;ScoreDoc[] hits = searcher.search(query, numberPerPage).scoreDocs; 显示查询结果12345678910111213141516171819202122private static void showSearchResults(IndexSearcher searcher, ScoreDoc[] hits, Query query, IKAnalyzer analyzer) throws Exception &#123; System.out.println(&quot;找到 &quot; + hits.length + &quot; 个命中.&quot;); System.out.println(&quot;序号\\t匹配度得分\\t结果&quot;); &lt;!-- 每一个ScoreDoc[] hits 就是一个搜索结果，首先把他遍历出来 --&gt; for (int i = 0; i &lt; hits.length; ++i) &#123; ScoreDoc scoreDoc= hits[i]; &lt;!-- 然后获取当前结果的docid, 这个docid相当于就是这个数据在索引中的主键 --&gt; int docId = scoreDoc.doc; &lt;!-- 再根据主键docid，通过搜索器从索引里把对应的Document取出来 --&gt; Document d = searcher.doc(docId); &lt;!-- 接着就打印出这个Document里面的数据。 虽然当前Document只有name一个字段，但是代码还是通过遍历所有字段的形式，打印出里面的值，这样当Docment有多个字段的时候，代码就不用修改了，兼容性更好点。scoreDoc.score 表示当前命中的匹配度得分，越高表示匹配程度越高 --&gt; List&lt;IndexableField&gt; fields = d.getFields(); System.out.print((i + 1)); System.out.print(&quot;\\t&quot; + scoreDoc.score); for (IndexableField f : fields) &#123; System.out.print(&quot;\\t&quot; + d.get(f.name())); &#125; System.out.println(); &#125;&#125; 运行结果:如图所示，一共是10条数据，通过关键字查询出来6条命中结果，不同的命中结果有不同的匹配度得分，比如第一条，命中都就很高，既有 护眼， 也有 带光源。 其他的命中度就比较低，没有护眼关键字的匹配，只有光源关键字的匹配。 思路图:整理一下做 Lucene的思路: 首先搜集数据数据可以是文件系统，数据库，网络上，手工输入的，或者像本例直接写在内存上的 通过数据创建索引 用户输入关键字 通过关键字创建查询器 根据查询器到索引里获取数据 然后把查询结果展示在用户面前 和like的区别：like 也可以进行查询，那么使用lucene 的方式有什么区别呢？ 主要是两点： 相关度:通过观察运行结果，可以看到不同相关度的结果都会查询出来，但是使用 like，就做不到这一点了 性能:数据量小的时候，like 也会有很好的表现，但是数据量一大，like 的表现就差很多了。 在接下来的教程里会演示对 14万条数据 的查询","tags":[{"name":"Lucene","slug":"Lucene","permalink":"http://example.com/tags/Lucene/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"Lucene","slug":"工具和中间件/搜索引擎技术/Lucene","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/Lucene/"}]},{"title":"Redis缓存及性能优化","date":"2017-12-15T07:08:20.000Z","path":"blog/Cloud/Redis/Redis缓存及性能优化/","text":"配置文件调优123456789101112131415161718192021222324252627282930313233343536373839# 列表对象listlist-max-ziplist-size -2 # 单个ziplist节点最大能存储8kb，超过则进行分裂将数据存储在新的ziplistlist-compress-depth 1 # 0表示所有节点都不压缩，1表示头结点和尾节点不压缩其他节点压缩# 哈希对象hashhash-max-ziplist-entries 512 # 元素个数超过512，将改为HashTable编码hash-max-ziplist-value 64 # 单个元素大小超过64byte，将改为HashTable编码# 集合对象setset-max-intset-entries 512 # 存储元素超过512时，使用HashTable编码# 有序集合对象zsetzset-max-ziplist-entries 128 # 元素个数超过128，将用skiplist编码zset-max-ziplist-value 64 # 单个元素大小超过64byte，将用skiplist编码# 持久化相关的save 60 1000 # 关闭RDB只需要将所有的save保存策略注释掉即可appendonly yes # 打开AOF功能appendfsync always # 每次有新命令追加到AOF文件时就执行一次fsync，非常慢也非常安全appendfsync everysec # 每秒fsync一次，足够快且在故障时只会丢失1秒钟的数据appendfsync no # 从不fsync，将数据交给操作系统来处理。更快，也更不安全的选择auto-aof-rewrite-min-size 64mb # aof文件至少达到64M才会自动重写，文件太小恢复速度本来就很快，重写意义不大auto-aof-rewrite-percentage 100 # aof文件自上一次重写后文件大小增长了100%则再次触发重写aof-use-rdb-preamble yes # 开启混合持久化，注意必须先开启aof# 集群相关的min-replicas-to-write 1 # 写数据成功最少同步的slave数量maxclients 10000 # redis支持的最大连接数maxmemory 0 # 最大可使用内存值byte，默认0不限制# volatile-lru：从已设置过期时间的key中，移出最近最少使用的key进行淘汰# volatile-ttl：从已设置过期时间的key中，根据过期时间的先后进行删除，越早过期的越先被删除# volatile-random：从已设置过期时间的key中，随机选择key淘汰# allkeys-lru：从所有key中选择最近最少使用的进行淘汰# allkeys-random：从所有key中随机选择key进行淘汰# noeviction：当内存达到阈值的时候，新写入操作报错# volatile-lfu：使用LFU算法筛选设置了过期时间的键值对删除最近一段时间被访问次数最少的数据# allkeys-lfu：使用LFU算法在所有数据中进行筛选删除最近一段时间被访问次数最少的数据maxmemory_policy noeviction # 当达到maxmemory时的淘汰策略 缓存穿透缓存穿透是指查询一个根本不存在的数据， 缓存层和存储层都不会命中， 通常出于容错的考虑， 若从存储层查不到数据则不写入缓存层。缓存穿透将导致不存在的数据每次请求都要到存储层去查询， 失去了缓存保护后端存储的意义。 缓存空对象空对象缓存过期时间设置的短一点，最长不超过5分钟 1234567891011121314151617String get(String key) &#123; // 从缓存中获取数据 String cacheValue = cache.get(key); // 缓存为空 if (StringUtils.isBlank(cacheValue)) &#123; // 从存储中获取 String storageValue = storage.get(key); cache.set(key, storageValue); // 若存储数据为空，需要设置一个过期时间(300秒) if (storageValue == null) &#123; cache.expire(key, 60 * 5); &#125; return storageValue; &#125; else &#123; return cacheValue; // 缓存非空 &#125;&#125; 布隆过滤器对于恶意攻击，向服务器请求大量不存在的数据造成的缓存穿透，可用布隆过滤器先做一次过滤，对于不存在的数据布隆过滤器一般都能够过滤掉，不让请求再往后端发送。布隆过滤器判定某个值存在时，该值可能不存在；当判定不存在时，则肯定不存在。 布隆过滤器适用于数据命中不高、 数据相对固定、 实时性低通常是数据集较大的应用场景，代码维护较为复杂，但是缓存空间占用很少。使用布隆过滤器需要把所有数据提前放入布隆过滤器，且在增加数据时也要往布隆过滤器里放。布隆过滤器不能删除数据，若要删除得重新初始化布隆过滤器。 12345&lt;dependency&gt; &lt;groupId&gt;org.redisson&lt;/groupId&gt; &lt;artifactId&gt;redisson&lt;/artifactId&gt; &lt;version&gt;3.6.5&lt;/version&gt; &lt;/dependency&gt; 1234567891011121314151617public class RedissonBloomFilter &#123; public static void main(String[] args) &#123; Config config = new Config(); config.useSingleServer().setAddress(&quot;redis://localhost:6379&quot;); // 构造Redisson RedissonClient redisson = Redisson.create(config); RBloomFilter&lt;String&gt; bloomFilter = redisson.getBloomFilter(&quot;nameList&quot;); // 初始化布隆过滤器：预计元素为100000000L，误差率为3%，根据这两个参数会计算出底层的bit数组大小 bloomFilter.tryInit(100000000L,0.03); // 将eleven插入到布隆过滤器中 bloomFilter.add(&quot;eleven&quot;); // 判断下面号码是否在布隆过滤器中 System.out.println(bloomFilter.contains(&quot;eleven&quot;)); //false System.out.println(bloomFilter.contains(&quot;张三&quot;)); //false System.out.println(bloomFilter.contains(&quot;李四&quot;)); //true &#125;&#125; 缓存失效大批量缓存在同一时间失效可能导致大量请求同时穿透缓存直达数据库，可能会造成数据库瞬间压力过大甚至挂掉，在批量增加缓存时最好将这一批数据的缓存过期时间设置为一个时间段内的不同时间。 123456789101112131415161718String get(String key) &#123; // 从缓存中获取数据 String cacheValue = cache.get(key); // 缓存为空 if (StringUtils.isBlank(cacheValue)) &#123; // 从存储中获取 String storageValue = storage.get(key); cache.set(key, storageValue); // 设置一个过期时间(300到600之间的一个随机数) int expireTime = new Random().nextInt(300) + 300; if (storageValue == null) &#123; cache.expire(key, expireTime); &#125; return storageValue; &#125; else &#123; return cacheValue; // 缓存非空 &#125;&#125; 缓存雪崩缓存雪崩是指缓存层支撑不住或宕掉后，大量请求打向后端存储层。由于缓存层承载着大量请求，有效地保护了存储层，但若缓存层由于某些原因不能提供服务，如超大并发缓存层支撑不住，或者由于缓存设计不好，类似大量请求访问**bigkey**，导致缓存能支撑的并发急剧下降，于是大量请求打到存储层，存储层调用量暴增，造成存储层也会级联宕机的情况。 预防和解决缓存雪崩问题， 可从以下三个方面进行着手。 事前：保证缓存层服务高可用性，比如使用**Redis Sentinel哨兵模式或Redis Cluster集群模式**。 事中：依赖隔离组件为后端限流熔断并降级。如使用**Sentinel或Hystrix**限流降级组件。可针对不同数据采取不同的处理方式。当业务应用访问的是非核心数据时，暂时停止从缓存中查询这些数据，而是直接返回预定义的默认降级信息、空值或是错误提示信息；当业务应用访问的是核心数据时，仍然允许查询缓存，如果缓存缺失，也可以继续通过数据库读取。 事后：开启Redis持久化机制，能尽快恢复缓存集群 提前演练。在项目上线前，演练缓存层宕掉后，应用以及后端的负载情况以及可能出现的问题，在此基础上做一些预案设定 热KEY重建优化使用缓存 + 过期时间策略既可以加速数据读写，又保证数据定期更新，这种模式基本能够满足绝大部分需求。但若当前key是一个热点key并发量非常大，或重建缓存不能在短时间完成，可能是一个复杂计算如复杂的SQL、多次IO、多个依赖等， 可能会对应用造成致命的危害。 在缓存失效的瞬间，有大量线程来重建缓存，造成后端负载加大，甚至可能会让应用崩溃，要解决该问题主要就是要避免大量线程同时重建缓存。可利用互斥锁来解决，只允许一个线程重建缓存，其他线程等待重建缓存的线程执行完，重新从缓存获取数据即可。 123456789101112131415161718192021String get(String key) &#123; // 从Redis中获取数据 String value = redis.get(key); // 如果value为空， 则开始重构缓存 if (value == null) &#123; // 只允许一个线程重建缓存， 使用nx， 并设置过期时间ex String mutexKey = &quot;mutext:key:&quot; + key; if (redis.set(mutexKey, &quot;1&quot;, &quot;ex 180&quot;, &quot;nx&quot;)) &#123; // 分布式锁 // 从数据源获取数据 value = db.get(key); // 回写Redis， 并设置过期时间 redis.setex(key, timeout, value); // 删除key_mutex redis.delete(mutexKey); &#125; else &#123; // 其他线程休息50毫秒后重试 Thread.sleep(50); get(key); &#125; &#125; return value;&#125; 缓存与数据库双写不一致在大并发下，同时操作数据库与缓存会存在数据不一致性问题 对于并发几率很小的数据，这种几乎不用考虑该问题，很少会发生缓存不一致，可给缓存数据加上过期时间，每隔一段时间触发读的主动更新即可。就算并发很高，若业务上能容忍短时间的缓存数据不一致，缓存加上过期时间依然可以解决大部分业务对于缓存的要求。 若不能容忍缓存数据不一致，可以通过加读写锁保证并发读写或写写的时候按顺序排好队，读读的时候相当于无锁。也可用阿里开源的**canal通过监听数据库的binlog日志**及时的去修改缓存，但是引入了新的中间件，增加了系统的复杂度。 以上针对的都是读多写少的情况加入缓存提高性能，若写多读多的情况又不能容忍缓存数据不一致，那就没必要加缓存了，可直接操作数据库。放入缓存的数据应该是对实时性、一致性要求不是很高的数据。切记不要为了用缓存，同时又要保证绝对的一致性做大量的过度设计和控制，增加系统复杂性。 性能优化KEY设计KEY的设计以业务名为前缀，用逗号分割，在保证语义的前提下，控制KEY的长度，不要包含空格、换行、单双引号等特殊字符。 bigkey对于value值要拒绝bigkey防止网卡流量限制以及慢查询，对于字符串类型value超过**10kb就是bigkey；非字符串类型元素个数不要超过5000；非字符串的bigkey不要使用del删除，使用hscan、sscan、zscan方式渐进式删除，同时要注意防止bigkey过期时间自动删除问题**。 bigkey会导致redis阻塞、网络拥堵等问题，每次获取要产生的网络流量较大，一般服务器会采用单机多实例的方式来部署，bigkey可能会对其他实例也造成影响。过期删除若未使用Redis 4.0的过期异步删除lazyfree-lazy-expire yes，则可能阻塞Redis。可通过bigkey拆分成几个段储存从而解决bigkey问题。 命令使用O(N)命令关注N的数量，如**hgetall、lrange、smembers、zrange、sinter等并非不能使用，但是需要明确N的值，有遍历的需求可使用hscan、sscan、zscan代替，禁止线上使用keys、flushall、flushdb**等，通过redis的rename机制禁掉命令，或者使用scan的方式渐进式处理。 redis的多数据库较弱，使用数字进行区分，很多客户端支持较差，同时多业务用多数据库实际还是单线程处理会有干扰，要合适使用数字进行分区。 过期策略惰性删除 | 被动删除当读或写key时，才对key进行检测，若已经达到过期时间，则删除。若这些过期的key没有被访问，那么他就一直无法被删除，而且一直占用内存。 定期删除 | 主动删除每隔一段时间对数据库做一次检查，删除里面的过期key。由于不可能对所有key去做轮询来删除，所以redis会每次随机取一些key去做检查和删除。 当前已用内存超过**maxmemory限定时，触发主动清理策略**。 定期+惰性都没有删除过期的key每次定期随机查询key的时候没有删掉，这些key也没有做查询的话，就会导致这些key一直保存无法被删除，这时候就会走到redis的内存淘汰机制。 volatile-lru：从已设置过期时间的key中，移出最近最少使用的key进行淘汰 volatile-ttl：从已设置过期时间的key中，根据过期时间的先后进行删除，越早过期的越先被删除 volatile-random：从已设置过期时间的key中，随机选择key淘汰 allkeys-lru：从所有key中选择最近最少使用的进行淘汰 allkeys-random：从所有key中随机选择key进行淘汰 noeviction：当内存达到阈值的时候，新写入操作报错 volatile-lfu：使用LFU算法筛选设置了过期时间的键值对删除最近一段时间被访问次数最少的数据 allkeys-lfu：使用LFU算法在所有数据中进行筛选删除最近一段时间被访问次数最少的数据 LRU &amp; LFULRU算法是以最近一次访问时间作为参考淘汰很久没被访问过的数据，LFU算法以次数作为参考淘汰最近一段时间被访问次数最少的数据。 当存在热点数据时LRU的效率很好，但偶发性、周期性的批量操作会导致LRU命中率急剧下降，缓存污染情况比较严重。这时使用LFU可能更好点。 根据自身业务类型，配置好**maxmemory-policy，默认是noeviction，推荐使用volatile-lru**。若不设置最大内存，当Redis内存超出物理内存限制时，内存数据会开始和磁盘产生频繁的交换swap，会让Redis性能急剧下降。当Redis运行在主从模式时，只有主结点才会执行过期删除策略，然后把删除操作del key同步到从结点删除数据。 连接池预热使用带有连接池的数据库，可以有效控制连接，同时提高效率 1234567891011121314151617181920212223242526List&lt;Jedis&gt; minIdleJedisList = new ArrayList&lt;Jedis&gt;(jedisPoolConfig.getMinIdle());for (int i = 0; i &lt; jedisPoolConfig.getMinIdle(); i++) &#123; Jedis jedis = null; try &#123; jedis = pool.getResource(); minIdleJedisList.add(jedis); jedis.ping(); &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; finally &#123; //注意，这里不能马上close将连接还回连接池，否则最后连接池里只会建立1个连接。。 //jedis.close(); &#125;&#125;//统一将预热的连接还回连接池for (int i = 0; i &lt; jedisPoolConfig.getMinIdle(); i++) &#123; Jedis jedis = null; try &#123; jedis = minIdleJedisList.get(i); //将连接归还回连接池 jedis.close(); &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; finally &#123; &#125;&#125;","tags":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"Redis","slug":"Cloud/Redis","permalink":"http://example.com/categories/Cloud/Redis/"}]},{"title":"Redis分布式锁实现","date":"2017-12-15T06:20:20.000Z","path":"blog/Cloud/Redis/Redis分布式锁实现/","text":"分布式锁的各种问题及优化并发情况下以下代码可能导致超买 12345678int stock = Integer.parseInt(stringRedisTemplate.opsForValue().get(&quot;stock&quot;)); // jedis.get(&quot;stock&quot;)if (stock &gt; 0) &#123; int realStock = stock - 1; stringRedisTemplate.opsForValue().set(&quot;stock&quot;, realStock + &quot;&quot;); // jedis.set(key,value) System.out.println(&quot;扣减成功，剩余库存:&quot; + realStock);&#125; else &#123; System.out.println(&quot;扣减失败，库存不足&quot;);&#125; 为了解决该问题可以通过redis加上分布式锁，该方式是解决了并发问题，但是引入了新的问题，若业务代码异常可能导致锁永远得不到释放。 1234567891011121314String lockKey = &quot;product_101&quot;;Boolean result = stringRedisTemplate.opsForValue().setIfAbsent(lockKey, &quot;product_id&quot;);if (!result) &#123; return &quot;error_code&quot;;&#125;int stock = Integer.parseInt(stringRedisTemplate.opsForValue().get(&quot;stock&quot;));if (stock &gt; 0) &#123; int realStock = stock - 1; stringRedisTemplate.opsForValue().set(&quot;stock&quot;, realStock + &quot;&quot;); System.out.println(&quot;扣减成功，剩余库存:&quot; + realStock);&#125; else &#123; System.out.println(&quot;扣减失败，库存不足&quot;);&#125;stringRedisTemplate.delete(lockKey); 可以通过finally中来释放锁来解决业务代码异常的情况，但若当锁获取成功后机器宕机了，同样锁还是不能得到释放。 1234567891011121314151617String lockKey = &quot;product_101&quot;;try &#123; Boolean result = stringRedisTemplate.opsForValue().setIfAbsent(lockKey, &quot;product_id&quot;); if (!result) &#123; return &quot;error_code&quot;; &#125; int stock = Integer.parseInt(stringRedisTemplate.opsForValue().get(&quot;stock&quot;)); if (stock &gt; 0) &#123; int realStock = stock - 1; stringRedisTemplate.opsForValue().set(&quot;stock&quot;, realStock + &quot;&quot;); System.out.println(&quot;扣减成功，剩余库存:&quot; + realStock); &#125; else &#123; System.out.println(&quot;扣减失败，库存不足&quot;); &#125;&#125; finally &#123; stringRedisTemplate.delete(lockKey);&#125; 可以通过给锁加上一个过期时间的方式来解决获取锁成功后机器宕机，导致锁不能被释放的情况，但是这种写法还是没有完全解决，因为加锁和设置缓存时间不是原子操作。 123456789101112131415161718String lockKey = &quot;product_101&quot;;try &#123; Boolean result = stringRedisTemplate.opsForValue().setIfAbsent(lockKey, &quot;product_id&quot;); stringRedisTemplate.expire(lockKey, 10, TimeUnit.SECONDS); if (!result) &#123; return &quot;error_code&quot;; &#125; int stock = Integer.parseInt(stringRedisTemplate.opsForValue().get(&quot;stock&quot;)); if (stock &gt; 0) &#123; int realStock = stock - 1; stringRedisTemplate.opsForValue().set(&quot;stock&quot;, realStock + &quot;&quot;); System.out.println(&quot;扣减成功，剩余库存:&quot; + realStock); &#125; else &#123; System.out.println(&quot;扣减失败，库存不足&quot;); &#125;&#125; finally &#123; stringRedisTemplate.delete(lockKey);&#125; 可通过在加锁的同时设置超时原子操作来解决该问题，但设置了超时时间若当前业务代码没有被执行完其本身没有释放锁，但由于过期锁被清理掉了，新的线程加锁进来后，之前执行业务代码的线程又去把新的线程的锁释放了，将导致锁完全失效。 1234567891011121314151617String lockKey = &quot;product_101&quot;;try &#123; Boolean result = stringRedisTemplate.opsForValue().setIfAbsent(lockKey, &quot;product_id&quot;, 30, TimeUnit.SECONDS); if (!result) &#123; return &quot;error_code&quot;; &#125; int stock = Integer.parseInt(stringRedisTemplate.opsForValue().get(&quot;stock&quot;)); if (stock &gt; 0) &#123; int realStock = stock - 1; stringRedisTemplate.opsForValue().set(&quot;stock&quot;, realStock + &quot;&quot;); System.out.println(&quot;扣减成功，剩余库存:&quot; + realStock); &#125; else &#123; System.out.println(&quot;扣减失败，库存不足&quot;); &#125;&#125; finally &#123; stringRedisTemplate.delete(lockKey);&#125; 可通过给锁设置唯一标识的方式来解决其他线程释放非自身设置的锁，所有线程只能释放本线程设置的锁。 1234567891011121314151617181920String lockKey = &quot;product_101&quot;;String clientId = UUID.randomUUID().toString();try &#123; Boolean result = stringRedisTemplate.opsForValue().setIfAbsent(lockKey, &quot;product_id&quot;, 30, TimeUnit.SECONDS); if (!result) &#123; return &quot;error_code&quot;; &#125; int stock = Integer.parseInt(stringRedisTemplate.opsForValue().get(&quot;stock&quot;)); if (stock &gt; 0) &#123; int realStock = stock - 1; stringRedisTemplate.opsForValue().set(&quot;stock&quot;, realStock + &quot;&quot;); System.out.println(&quot;扣减成功，剩余库存:&quot; + realStock); &#125; else &#123; System.out.println(&quot;扣减失败，库存不足&quot;); &#125;&#125; finally &#123; if (clientId.equals(stringRedisTemplate.opsForValue().get(lockKey))) &#123; stringRedisTemplate.delete(lockKey); &#125;&#125; 虽然上面的锁已经很完善了，但还是有锁因为超时时间导致的极小概率的并发问题，该问题可以通过给锁续命即判断业务代码是否执行完成，若未完成则重置超时时间的方式来解决该问题。**Redisson**就是这样做的。 1234567891011121314151617String lockKey = &quot;product_101&quot;;String clientId = UUID.randomUUID().toString();RLock redissonLock = redisson.getLock(lockKey);try &#123; //加锁 redissonLock.lock(); //setIfAbsent(lockKey, clientId, 30, TimeUnit.SECONDS); int stock = Integer.parseInt(stringRedisTemplate.opsForValue().get(&quot;stock&quot;)); // jedis.get(&quot;stock&quot;) if (stock &gt; 0) &#123; int realStock = stock - 1; stringRedisTemplate.opsForValue().set(&quot;stock&quot;, realStock + &quot;&quot;); // jedis.set(key,value) System.out.println(&quot;扣减成功，剩余库存:&quot; + realStock); &#125; else &#123; System.out.println(&quot;扣减失败，库存不足&quot;); &#125;&#125; finally &#123; redissonLock.unlock();&#125; 红锁**RedLock**是一种利用多Master对共享资源做互斥访问，基于N个完全独立的Redis节点，运行Redlock算法通过在客户端依次执行下面的步骤来完成获取锁的操作： 获取当前时间，毫秒数 按顺序依次向N个Redis节点执行获取锁操作，该获取操作跟前面基于单Redis节点获取锁过程相同，为了保证在某个Redis节点不可用的时候算法能够继续运行，该获取锁操作还有一个超时时间，几十毫秒量级，它要远小于锁的有效时间。客户端在向某个Redis节点获取锁失败后，应该立即尝试下一个Redis节点，这里的失败应该包含任何类型的失败，如该Redis节点不可用、该Redis节点上的锁已经被其它客户端持有 计算整个获取锁的过程总共消耗了多长时间，计算方法是用当前时间减去第1步记录的时间。若客户端从大多数Redis节点即**&gt;= N/2+1成功获取到了锁，且获取锁总耗时没有超过锁的有效时间**，则此时客户端才认为最终获取锁成功；否则认为最终获取锁失败 若最终获取锁成功，则该锁的有效时间应该重新计算，它等于最初的锁的有效时间减去第3步计算出来的获取锁消耗的时间 若最终获取锁失败了，可能由于获取到锁的Redis节点个数少于**N/2+1，或整个获取锁的过程耗时超过了锁的最初有效时间，则客户端应该立即向所有Redis节点发起释放锁操作** 释放锁的过程比较简单：客户端向所有Redis节点发起释放锁的操作，不管这些节点当时在获取锁时成功与否。在最后释放锁时，客户端应该向所有Redis节点发起释放锁的操作，即使当时向某个节点获取锁没有成功，在释放锁时也不应该漏掉该节点。因为若客户端发给某个Redis节点获取锁的请求成功到达了该Redis节点，该节点也成功执行了SET操作，但返回给客户端的响应包却丢失。在客户端看来，获取锁的请求由于超时而失败了，但在Redis这边看来，加锁已经成功了。因此释放锁时，客户端也应该对当时获取锁失败的那些Redis节点同样发起请求。 但由于N个Redis节点中的大多数能正常工作就能保证Redlock正常工作，因此理论上它的可用性更高。单Redis节点的分布式锁在failover的时锁失效的问题，在Redlock中不存在了，但若有节点发生崩溃重启，还是会对锁的安全性有影响，具体的影响程度跟Redis对数据的持久化程度有关。 假设一共有5个Redis节点**A、B、C、D、E，若客户端1成功锁住了A、B、C，获取锁成功， 但D和E没有锁住，节点C崩溃重启了，但客户端1在C上加的锁没有持久化下来，丢失了，节点C重启后，客户端2锁住了C、D、E， 获取锁成功，针对同一资源客户端1和客户端2同时获得了锁**。 Redis的**AOF持久化方式默认是每秒写一次磁盘，最坏情况下可能丢失1秒的数据，为了尽可能不丢数据，Redis允许设置成每次修改数据都进行fsync，但这会降低性能。当然，即使执行了fsync也仍然有可能丢失数据，这取决于系统而不是Redis的实现。故上面分析的由于节点重启引发的锁失效问题，总是有可能出现的。为了应对这一问题，可通过延迟重启，即一个节点崩溃后，先不立即重启它，而是等待一段时间再重启，该时间应该大于锁的有效时间，该节点在重启前所参与的锁都会过期**，它在重启后就不会对现有的锁造成影响。 Redisson锁原理123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119public class Redisson implements RedissonClient &#123; public RLock getLock(String name) &#123; return new RedissonLock(connectionManager.getCommandExecutor(), name); &#125;&#125;public class RedissonLock extends RedissonExpirable implements RLock &#123; public RedissonLock(CommandAsyncExecutor commandExecutor, String name) &#123; super(commandExecutor, name); this.commandExecutor = commandExecutor; this.id = commandExecutor.getConnectionManager().getId(); this.internalLockLeaseTime = commandExecutor.getConnectionManager().getCfg().getLockWatchdogTimeout(); &#125; public void lock(long leaseTime, TimeUnit unit) &#123; try &#123; lockInterruptibly(leaseTime, unit); &#125; catch (InterruptedException e) &#123; Thread.currentThread().interrupt(); &#125; &#125; public void lockInterruptibly(long leaseTime, TimeUnit unit) throws InterruptedException &#123; long threadId = Thread.currentThread().getId(); // 获取当前线程的ID Long ttl = tryAcquire(leaseTime, unit, threadId); // 尝试获取锁，并返回锁剩余持有时间 if (ttl == null) &#123; // 若锁剩余持有时间为null，表示获取锁成功 return; // 获取锁成功 &#125; RFuture&lt;RedissonLockEntry&gt; future = subscribe(threadId); commandExecutor.syncSubscription(future); try &#123; while (true) &#123; ttl = tryAcquire(leaseTime, unit, threadId); if (ttl == null) &#123; break; &#125; if (ttl &gt;= 0) &#123; getEntry(threadId).getLatch().tryAcquire(ttl, TimeUnit.MILLISECONDS); &#125; else &#123; getEntry(threadId).getLatch().acquire(); &#125; &#125; &#125; finally &#123; unsubscribe(future, threadId); &#125; &#125; private Long tryAcquire(long leaseTime, TimeUnit unit, long threadId) &#123; return get(tryAcquireAsync(leaseTime, unit, threadId)); &#125; private &lt;T&gt; RFuture&lt;Long&gt; tryAcquireAsync(long leaseTime, TimeUnit unit, final long threadId) &#123; if (leaseTime != -1) &#123; // 设置了超时时间的逻辑 return tryLockInnerAsync(leaseTime, unit, threadId, RedisCommands.EVAL_LONG); &#125; // 未设置超时时间默认设置超时时间为30s RFuture&lt;Long&gt; ttlRemainingFuture = tryLockInnerAsync(commandExecutor.getConnectionManager().getCfg().getLockWatchdogTimeout(), TimeUnit.MILLISECONDS, threadId, RedisCommands.EVAL_LONG); ttlRemainingFuture.addListener(new FutureListener&lt;Long&gt;() &#123; @Override public void operationComplete(Future&lt;Long&gt; future) throws Exception &#123; if (!future.isSuccess()) &#123; return; &#125; Long ttlRemaining = future.getNow(); if (ttlRemaining == null) &#123; // 若当前锁还没有释放，则给当前锁续超时时间 scheduleExpirationRenewal(threadId); &#125; &#125; &#125;); return ttlRemainingFuture; &#125; &lt;T&gt; RFuture&lt;T&gt; tryLockInnerAsync(long leaseTime, TimeUnit unit, long threadId, RedisStrictCommand&lt;T&gt; command) &#123; internalLockLeaseTime = unit.toMillis(leaseTime); // 异步执行lua命令获取锁，若获取锁成功返回null，否则返回剩余持有时间 return commandExecutor .evalWriteAsync(getName(), LongCodec.INSTANCE, command, &quot;if (redis.call(&#x27;exists&#x27;, KEYS[1]) == 0) then &quot; + // 判断锁是否存在 &quot;redis.call(&#x27;hset&#x27;, KEYS[1], ARGV[2], 1); &quot; + // 将锁的的状态设置为1 &quot;redis.call(&#x27;pexpire&#x27;, KEYS[1], ARGV[1]); &quot; + // 给锁加上失效时间 &quot;return nil; &quot; + &quot;end; &quot; + &quot;if (redis.call(&#x27;hexists&#x27;, KEYS[1], ARGV[2]) == 1) then &quot; + // 重入锁的处理，锁存在，且加锁对象是当前线程 &quot;redis.call(&#x27;hincrby&#x27;, KEYS[1], ARGV[2], 1); &quot; + // 将锁加一 &quot;redis.call(&#x27;pexpire&#x27;, KEYS[1], ARGV[1]); &quot; + // 重置失效时间 &quot;return nil; &quot; + &quot;end; &quot; + &quot;return redis.call(&#x27;pttl&#x27;, KEYS[1]);&quot;, // 返回锁剩余的失效时间 Collections.&lt;Object&gt;singletonList(getName()), internalLockLeaseTime, getLockName(threadId)); &#125; private void scheduleExpirationRenewal(final long threadId) &#123; if (expirationRenewalMap.containsKey(getEntryName())) &#123; return; &#125; // 每10s执行一次 Timeout task = commandExecutor.getConnectionManager().newTimeout(new TimerTask() &#123; @Override public void run(Timeout timeout) throws Exception &#123; RFuture&lt;Boolean&gt; future = commandExecutor .evalWriteAsync(getName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN, &quot;if (redis.call(&#x27;hexists&#x27;, KEYS[1], ARGV[2]) == 1) then &quot; + // 若KEY存在则返回true，否则返回false &quot;redis.call(&#x27;pexpire&#x27;, KEYS[1], ARGV[1]); &quot; + // 重置超时时间 &quot;return 1; &quot; + &quot;end; &quot; + &quot;return 0;&quot;, Collections.&lt;Object&gt;singletonList(getName()), internalLockLeaseTime, getLockName(threadId)); future.addListener(new FutureListener&lt;Boolean&gt;() &#123; @Override public void operationComplete(Future&lt;Boolean&gt; future) throws Exception &#123; expirationRenewalMap.remove(getEntryName()); if (!future.isSuccess()) &#123; return; &#125; if (future.getNow()) &#123; // 若当前锁还没有释放，则给当前锁续超时时间 scheduleExpirationRenewal(threadId); &#125; &#125; &#125;); &#125; &#125;, internalLockLeaseTime / 3, TimeUnit.MILLISECONDS); if (expirationRenewalMap.putIfAbsent(getEntryName(), task) != null) &#123; task.cancel(); &#125; &#125;&#125; LUA脚本Redis在2.6推出了脚本功能，允许开发者使用Lua语言编写脚本传到Redis中执行： 减少网络开销：本来5次网络请求的操作，可用一个请求完成，原先5次请求的逻辑放在redis服务器上完成。使用脚本，减少了网络往返时延。这点跟管道类似。 原子操作：Redis会将整个脚本作为一个整体执行，中间不会被其他命令插入。管道不是原子的，不过redis的批量操作命令是原子。 替代redis的事务功能：redis自带的事务功能很鸡肋，而redis的lua脚本几乎实现了常规的事务功能，官方推荐如果要使用redis的事务功能可以用redis lua替代。 可以使用EVAL命令对Lua脚本进行求值。EVAL命令的格式如下： 1EVAL script numkeys key [key ...] arg [arg ...] script参数是一段Lua脚本程序，它会被运行在Redis服务器上下文中，**numkeys参数用于指定键名参数的个数。键名参数key [key ...]从EVAL的第三个参数开始算起，表示在脚本中所用到的那些Redis键(key)，这些键名参数可在Lua中通过全局变量KEYS数组，用1为基址**的形式访问KEYS[1]，KEYS[2] 以此类推。 在命令的最后不是键名参数的附加参数**arg [arg ...]，可在Lua中通过全局变量ARGV数组访问，访问的形式和KEYS变量类似(ARGV[1]、ARGV[2]，在Lua脚本中，可使用redis.call()**函数来执行Redis命令： 1234567891011jedis.set(&quot;product_stock_10016&quot;, &quot;15&quot;); //初始化商品10016的库存String script = &quot; local count = redis.call(&#x27;get&#x27;, KEYS[1]) &quot; + &quot; local a = tonumber(count) &quot; + &quot; local b = tonumber(ARGV[1]) &quot; + &quot; if a &gt;= b then &quot; + &quot; redis.call(&#x27;set&#x27;, KEYS[1], a-b) &quot; + &quot; return 1 &quot; + &quot; end &quot; + &quot; return 0 &quot;;Object obj = jedis.eval(script, Arrays.asList(&quot;product_stock_10016&quot;), Arrays.asList(&quot;10&quot;));System.out.println(obj); 不要在Lua脚本中出现死循环和耗时的运算，否则redis会阻塞，将不接受其他的命令，所以使用时要注意不能出现死循环、耗时的运算。redis是单进程、单线程执行脚本。**管道不会阻塞redis**。","tags":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"Redis","slug":"Cloud/Redis","permalink":"http://example.com/categories/Cloud/Redis/"}]},{"title":"Redis实践-Java","date":"2017-12-15T06:08:20.000Z","path":"blog/Cloud/Redis/Redis实践-Java/","text":"什么是Jedis在常见命令中，使用各种Redis自带客户端的命令行方式访问Redis服务。 而在实际工作中却需要用到Java代码才能访问，使用第三方jar包 ：Jedis就能方便地访问Redis的各种服务了。 简单运用：TestJedis：12345678910111213package redis;import redis.clients.jedis.Jedis;public class TestRedis &#123; public static void main(String[] args) &#123; Jedis jedis = new Jedis(&quot;localhost&quot;); jedis.set(&quot;foo&quot;, &quot;bar&quot;); String value = jedis.get(&quot;foo&quot;); System.out.println(value); &#125;&#125; TestRedisManyCommands:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151package redis;import java.util.HashMap;import java.util.Iterator;import java.util.List;import java.util.Map; import org.junit.Before;import org.junit.Test; import redis.clients.jedis.Jedis;import redis.clients.jedis.JedisPool; public class TestRedisManyCommands &#123; JedisPool pool; Jedis jedis; @Before public void setUp() &#123; jedis = new Jedis(&quot;localhost&quot;); &#125; /** * Redis存储初级的字符串 * CRUD */ @Test public void testBasicString()&#123; //-----添加数据---------- jedis.set(&quot;name&quot;,&quot;meepo&quot;);//向key--&gt;name中放入了value--&gt;meepo System.out.println(jedis.get(&quot;name&quot;));//执行结果：meepo //-----修改数据----------- //1、在原来基础上修改 jedis.append(&quot;name&quot;,&quot;dota&quot;); //很直观，类似map 将dota append到已经有的value之后 System.out.println(jedis.get(&quot;name&quot;));//执行结果:meepodota //2、直接覆盖原来的数据 jedis.set(&quot;name&quot;,&quot;poofu&quot;); System.out.println(jedis.get(&quot;name&quot;));//执行结果：poofu //删除key对应的记录 jedis.del(&quot;name&quot;); System.out.println(jedis.get(&quot;name&quot;));//执行结果：null /** * mset相当于 * jedis.set(&quot;name&quot;,&quot;meepo&quot;); * jedis.set(&quot;dota&quot;,&quot;poofu&quot;); */ jedis.mset(&quot;name&quot;,&quot;meepo&quot;,&quot;dota&quot;,&quot;poofu&quot;); System.out.println(jedis.mget(&quot;name&quot;,&quot;dota&quot;)); &#125; /** * jedis操作Map */ @Test public void testMap()&#123; Map&lt;String,String&gt; user=new HashMap&lt;String,String&gt;(); user.put(&quot;name&quot;,&quot;meepo&quot;); user.put(&quot;pwd&quot;,&quot;password&quot;); jedis.hmset(&quot;user&quot;,user); //取出user中的name，执行结果:[meepo]--&gt;注意结果是一个泛型的List //第一个参数是存入redis中map对象的key，后面跟的是放入map中的对象的key，后面的key可以跟多个，是可变参数 List&lt;String&gt; rsmap = jedis.hmget(&quot;user&quot;, &quot;name&quot;); System.out.println(rsmap); //删除map中的某个键值 // jedis.hdel(&quot;user&quot;,&quot;pwd&quot;); System.out.println(jedis.hmget(&quot;user&quot;, &quot;pwd&quot;)); //因为删除了，所以返回的是null System.out.println(jedis.hlen(&quot;user&quot;)); //返回key为user的键中存放的值的个数1 System.out.println(jedis.exists(&quot;user&quot;));//是否存在key为user的记录 返回true System.out.println(jedis.hkeys(&quot;user&quot;));//返回map对象中的所有key [pwd, name] System.out.println(jedis.hvals(&quot;user&quot;));//返回map对象中的所有value [meepo, password] Iterator&lt;String&gt; iter=jedis.hkeys(&quot;user&quot;).iterator(); while (iter.hasNext())&#123; String key = iter.next(); System.out.println(key+&quot;:&quot;+jedis.hmget(&quot;user&quot;,key)); &#125; &#125; /** * jedis操作List */ @Test public void testList()&#123; //开始前，先移除所有的内容 jedis.del(&quot;java framework&quot;); // 第一个是key，第二个是起始位置，第三个是结束位置，jedis.llen获取长度 -1表示取得所有 System.out.println(jedis.lrange(&quot;java framework&quot;,0,-1)); //先向key java framework中存放三条数据 jedis.lpush(&quot;java framework&quot;,&quot;spring&quot;); jedis.lpush(&quot;java framework&quot;,&quot;struts&quot;); jedis.lpush(&quot;java framework&quot;,&quot;hibernate&quot;); //再取出所有数据jedis.lrange是按范围取出， // 第一个是key，第二个是起始位置，第三个是结束位置，jedis.llen获取长度 -1表示取得所有 System.out.println(jedis.lrange(&quot;java framework&quot;,0,-1)); &#125; /** * jedis操作Set */ @Test public void testSet()&#123; //添加 jedis.sadd(&quot;sname&quot;,&quot;meepo&quot;); jedis.sadd(&quot;sname&quot;,&quot;dota&quot;); jedis.sadd(&quot;sname&quot;,&quot;poofu&quot;); jedis.sadd(&quot;sname&quot;,&quot;noname&quot;); //移除noname jedis.srem(&quot;sname&quot;,&quot;noname&quot;); System.out.println(jedis.smembers(&quot;sname&quot;));//获取所有加入的value System.out.println(jedis.sismember(&quot;sname&quot;, &quot;meepo&quot;));//判断 meepo 是否是sname集合的元素 System.out.println(jedis.srandmember(&quot;sname&quot;)); System.out.println(jedis.scard(&quot;sname&quot;));//返回集合的元素个数 &#125; @Test public void test() throws InterruptedException &#123; //keys中传入的可以用通配符 System.out.println(jedis.keys(&quot;*&quot;)); //返回当前库中所有的key [sose, sanme, name, dota, foo, sname, java framework, user, braand] System.out.println(jedis.keys(&quot;*name&quot;));//返回的sname [sname, name] System.out.println(jedis.del(&quot;sanmdde&quot;));//删除key为sanmdde的对象 删除成功返回1 删除失败（或者不存在）返回 0 System.out.println(jedis.ttl(&quot;sname&quot;));//返回给定key的有效时间，如果是-1则表示永远有效 jedis.setex(&quot;timekey&quot;, 10, &quot;min&quot;);//通过此方法，可以指定key的存活（有效时间） 时间为秒 Thread.sleep(5000);//睡眠5秒后，剩余时间将为&lt;=5 System.out.println(jedis.ttl(&quot;timekey&quot;)); //输出结果为5 jedis.setex(&quot;timekey&quot;, 1, &quot;min&quot;); //设为1后，下面再看剩余时间就是1了 System.out.println(jedis.ttl(&quot;timekey&quot;)); //输出结果为1 System.out.println(jedis.exists(&quot;key&quot;));//检查key是否存在 System.out.println(jedis.rename(&quot;timekey&quot;,&quot;time&quot;)); System.out.println(jedis.get(&quot;timekey&quot;));//因为移除，返回为null System.out.println(jedis.get(&quot;time&quot;)); //因为将timekey 重命名为time 所以可以取得值 min //jedis 排序 //注意，此处的rpush和lpush是List的操作。是一个双向链表（但从表现来看的） jedis.del(&quot;a&quot;);//先清除数据，再加入数据进行测试 jedis.rpush(&quot;a&quot;, &quot;1&quot;); jedis.lpush(&quot;a&quot;,&quot;6&quot;); jedis.lpush(&quot;a&quot;,&quot;3&quot;); jedis.lpush(&quot;a&quot;,&quot;9&quot;); System.out.println(jedis.lrange(&quot;a&quot;,0,-1));// [9, 3, 6, 1] System.out.println(jedis.sort(&quot;a&quot;)); //[1, 3, 6, 9] //输入排序后结果 System.out.println(jedis.lrange(&quot;a&quot;,0,-1)); &#125; &#125;","tags":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"Redis","slug":"Cloud/Redis","permalink":"http://example.com/categories/Cloud/Redis/"}]},{"title":"Redis集群架构","date":"2017-12-15T04:08:20.000Z","path":"blog/Cloud/Redis/Redis集群架构/","text":"主从架构：12345678910111213141516171819# 复制一份redis.conf文件port 6380pidfile /var/run/redis_6380.pid # 把pid进程号写入pidfile配置的文件logfile &quot;6380.log&quot;dir /usr/local/redis-5.0.3/data/6380 # 指定数据存放目录# 需要注释掉bind# bind 127.0.0.1 绑定机器网卡ip，多块网卡可配多个ip，代表允许客户端通过机器的哪些网卡ip去访问，内网一般可不配置bind# 配置主从复制replicaof 192.168.0.60 6379 # 从本机6379的redis实例复制数据，Redis 5.0之前使用slaveofreplica-read-only yes # 配置从节点只读# 启动从节点redis-server redis.conf# 连接从节点redis-cli -p 6380# 测试在6379实例上写数据，6380实例是否能及时同步新修改数据# 可以自己再配置一个6381的从节点 若为**master主节点配置了一个slave从节点，不管该slave从节点是否是第一次连接上Master主节点，都会发送一个PSYNC**命令给master请求复制数据。 master主节点收到**PSYNC命令后，会在后台进行数据持久化，通过bgsave生成最新的rdb快照文件，持久化期间master会继续接收客户端请求，且把这些可能修改数据集的请求缓存在内存中。当持久化进行完毕以后，master主节点会把这份rdb文件数据集发送给slave从节点，slave会把接收到的数据进行持久化生成rdb，然后再加载到内存中。master主节点再将之前缓存在内存中的命令发送给slave从节点**。 当master主节点与slave从节点之间的连接由于某些原因而断开时，slave从节点能够自动重连Master主节点，若master收到了多个slave从节点并发连接请求，它只会进行一次持久化，然后把这一份持久化的数据发送给多个并发连接的slave从节点。 当master主节点和slave从节点断开重连后，一般都会对整份数据进行复制。但从**Redis 2.8开始，PSYNC命令支持部分数据复制去master同步数据，slave从节点与master主节点能够在网络连接断开重连后只进行部分数据复制即断点续传**。 若有很多从节点，多个从节点同时复制主节点导致主节点压力过大，为了缓解主从复制风暴，可让部分从节点与从节点同步数据： 哨兵模式sentinel哨兵是特殊的redis服务，不提供读写服务，主要用来监控redis实例节点，哨兵架构下**client端第一次从哨兵找出redis的主节点，后续直接访问redis主节点，不会每次都通过sentinel哨兵代理访问redis的主节点，当redis的主节点发生变化，哨兵会第一时间感知到，并且将新的redis主节点通知给client端，redis的client端一般都实现了订阅**功能，订阅sentinel哨兵发布的节点变动消息。 12345678910111213141516171819# 复制一份sentinel.conf文件cp sentinel.conf sentinel-26379.confport 26379daemonize yespidfile &quot;/var/run/redis-sentinel-26379.pid&quot;logfile &quot;26379.log&quot;dir &quot;/usr/local/redis-5.0.3/data&quot;# sentinel monitor &lt;master-redis-name&gt; &lt;master-redis-ip&gt; &lt;master-redis-port&gt; &lt;quorum&gt;# quorum是一个数字，指明当有多少个sentinel认为一个master失效时(值一般为：sentinel总数/2 + 1)，master才算真正失效sentinel monitor mmaster 192.168.0.60 6379 2 # mmaster名字随便取，客户端访问时会用到# 启动sentinel哨兵实例src/redis-sentinel sentinel-26379.conf# 查看sentinel的info信息src/redis-cli -p 26379127.0.0.1:26379&gt;info # 可以看到Sentinel的info里已经识别出了redis的主从# 可再配置两个sentinel，端口26380和26381，注意上述配置文件里的对应数字都要修改 sentinel集群都启动完毕后，会将哨兵集群的元数据信息写入所有sentinel配置文件中，追加在文件的最下面： 1234sentinel known-replica mmaster 192.168.0.60 6380 #代表redis主节点的从节点信息sentinel known-replica mmaster 192.168.0.60 6381 #代表redis主节点的从节点信息sentinel known-sentinel mmaster 192.168.0.60 26380 52d0a5d70c1f90475b4fc03b6ce7c3c56935760f # 感知到的其它哨兵节点sentinel known-sentinel mmaster 192.168.0.60 26381 e9f530d3882f8043f76ebb8e1686438ba8bd5ca6 当redis主节点如果挂了，哨兵集群会重新选举出新的**redis主节点**，同时修改所有sentinel节点配置文件的集群元数据信息，如6379的redis挂了，假设选举出的新主节点是6380： 1234sentinel known-replica mmaster 192.168.0.60 6379 # 主节点的从节点信息sentinel known-replica mmaster 192.168.0.60 6381 # 主节点的从节点信息sentinel known-sentinel mmaster 192.168.0.60 26380 52d0a5d70c1f90475b4fc03b6ce7c3c56935760f # 感知到的其它哨兵节点sentinel known-sentinel mmaster 192.168.0.60 26381 e9f530d3882f8043f76ebb8e1686438ba8bd5ca6 同时修改sentinel文件里之前配置的mmaster对应的**6379端口，改为6380，当6379的redis实例再次启动时，哨兵集群根据集群元数据信息就可以将6379端口的redis节点作为从节点**加入集群: 1sentinel monitor mmaster 192.168.0.60 6380 2 1234567891011121314151617181920212223242526272829public class JedisSentinelTest &#123; public static void main(String[] args) throws IOException &#123; JedisPoolConfig config = new JedisPoolConfig(); config.setMaxTotal(20); config.setMaxIdle(10); config.setMinIdle(5); String masterName = &quot;mmaster&quot;; Set&lt;String&gt; sentinels = new HashSet&lt;String&gt;(); sentinels.add(new HostAndPort(&quot;172.16.20.53&quot;, 26379).toString()); sentinels.add(new HostAndPort(&quot;172.16.20.53&quot;, 26380).toString()); sentinels.add(new HostAndPort(&quot;172.16.20.53&quot;, 26381).toString()); // JedisSentinelPool其实本质跟JedisPool类似，都是与redis主节点建立的连接池 // JedisSentinelPool并不是说与sentinel建立的连接池，而是通过sentinel发现redis主节点并与其建立连接 JedisSentinelPool jedisSentinelPool = new JedisSentinelPool(masterName, sentinels, config, 3000, null); Jedis jedis = null; try &#123; jedis = jedisSentinelPool.getResource(); System.out.println(jedis.set(&quot;sentinel&quot;, &quot;eleven&quot;)); System.out.println(jedis.get(&quot;sentinel&quot;)); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; // 注意这里不是关闭连接，在JedisPool模式下，Jedis会被归还给资源池。 if (jedis != null) &#123; jedis.close(); &#125; &#125; &#125;&#125; Spring Boot整合Redis哨兵模式:只需要引入如下依赖，并将哨兵的节点信息配置到配置文件中，即可通过自动注入的方式引入**StringRedisTemplate或RedisTemplate**进行使用: 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt;&lt;/dependency&gt; 12345678910111213spring: redis: database: 0 timeout: 3000 sentinel: # 哨兵模式 master: mmaster # 主服务器所在集群名称 nodes: 192.168.0.60:26379,192.168.0.60:26380,192.168.0.60:26381 lettuce: pool: max-idle: 50 min-idle: 10 max-active: 100 max-wait: 1000 12345678910111213141516171819202122232425@RestControllerpublic class IndexController &#123; private static final Logger logger = LoggerFactory.getLogger(IndexController.class); @Autowired private StringRedisTemplate stringRedisTemplate; /** * 测试节点挂了哨兵重新选举新的master节点，客户端是否能动态感知到 * 新的master选举出来后，哨兵会把消息发布出去，客户端实际上是实现了一个消息监听机制， * 当哨兵把新master的消息发布出去，客户端会立马感知到新master的信息，从而动态切换访问的masterip */ @RequestMapping(&quot;/test_sentinel&quot;) public void testSentinel() throws InterruptedException &#123; int i = 1; while (true)&#123; try &#123; stringRedisTemplate.opsForValue().set(&quot;zhuge&quot;+i, i+&quot;&quot;); System.out.println(&quot;设置key：&quot;+ &quot;zhuge&quot; + i); i++; Thread.sleep(1000); &#125;catch (Exception e)&#123; logger.error(&quot;错误：&quot;, e); &#125; &#125; &#125;&#125; 问题：Redis 3.0以前的版本要实现集群一般是借助哨兵sentinel工具来监控master节点的状态，若master节点异常则会做主从切换，将某一台slave作为master，哨兵的配置略微复杂，且性能和高可用性等各方面表现一般，且在主从切换瞬间存在访问瞬断情况，且哨兵模式只有一个主节点对外提供服务，无法支持很高的并发，且单个主节点内存也不宜设置得过大，否则会导致持久化文件过大，影响数据恢复或主从同步的效率。 集群模式： Redis集群是一个由多个主从节点群组成的分布式服务器群，具有复制、高可用和分片特性，Redis集群不需要sentinel哨兵也能完成节点移除和故障转移的功能。只需要将每个节点设置成集群模式，这种集群模式没有中心节点可水平扩展，据官方文档称可以线性扩展到上万个节点，官方推荐不超过1000个节点。Redis集群的性能和高可用性均优于之前版本的哨兵模式，且集群配置非常简单，**Redis集群需要至少三个master主节点**。 1234567891011121314151617181920212223242526272829303132333435363738# 第一步：在第一台机器的/usr/local下创建文件夹redis-cluster，然后在其下面分别创建2个文件夾如下mkdir -p /usr/local/redis-clustermkdir 8001 8004# 把之前的redis.conf配置文件copy到8001下，修改如下内容：daemonize yesport 8001 # 分别对每个机器的端口号进行设置pidfile /var/run/redis_8001.pid # 把pid进程号写入pidfile配置的文件dir /usr/local/redis-cluster/8001/（指定数据文件存放位置，必须要指定不同的目录位置，不然会丢失数据）cluster-enabled yes（启动集群模式）cluster-config-file nodes-8001.conf（集群节点信息文件，这里800x最好和port对应上）cluster-node-timeout 10000# bind 127.0.0.1 绑定机器网卡ip，若有多块网卡可配多个ip，代表允许客户端通过机器的哪些网卡ip去访问protected-mode no # 关闭保护模式appendonly yes# 如果要设置密码需要增加如下配置：requirepass eleven # 设置redis访问密码masterauth eleven # 设置集群节点间访问密码，跟上面一致# 分别启动redis实例，然后检查是否启动成功src/redis-server redis.confps -ef | grep redis # 查看是否启动成功# 首先需要确认集群机器之间redis实例能相互访问，可先把所有机器防火墙关掉，若不关闭防火墙则需打开redis服务端口和集群节点gossip通信端口16379，默认是在redis端口号上加1W# systemctl stop firewalld # 临时关闭防火墙# systemctl disable firewalld # 禁止开机启动# 用redis-cli创建整个redis集群，redis5以前版本集群依靠ruby脚本redis-trib.rb实现# 命令中的1代表为每个创建的主服务器节点创建一个从服务器节点src/redis-cli -a zhuge --cluster create --cluster-replicas 1 192.168.0.61:8001 192.168.0.62:8002 192.168.0.63:8003 192.168.0.61:8004 192.168.0.62:8005 192.168.0.63:8006# 验证集群， -a访问服务端密码，-c表示集群模式，指定ip地址和端口号src/redis-cli -a eleven -c -h 192.168.0.61 -p 8001cluster info # 查看集群信息cluster nodes # 查看节点列表# 关闭集群则需要逐个进行关闭，使用命令：src/redis-cli -a eleven -c -h 192.168.0.60 -p 8001 shutdown 集群使用:借助redis的java客户端jedis可以操作以上集群，引用jedis版本的maven如下: 12345&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt;&lt;/dependency&gt; 12345678910111213141516171819202122232425262728293031public class JedisClusterTest &#123; public static void main(String[] args) throws IOException &#123; JedisPoolConfig config = new JedisPoolConfig(); config.setMaxTotal(20); config.setMaxIdle(10); config.setMinIdle(5); Set&lt;HostAndPort&gt; jedisClusterNode = new HashSet&lt;HostAndPort&gt;(); jedisClusterNode.add(new HostAndPort(&quot;192.168.0.61&quot;, 8001)); jedisClusterNode.add(new HostAndPort(&quot;192.168.0.62&quot;, 8002)); jedisClusterNode.add(new HostAndPort(&quot;192.168.0.63&quot;, 8003)); jedisClusterNode.add(new HostAndPort(&quot;192.168.0.61&quot;, 8004)); jedisClusterNode.add(new HostAndPort(&quot;192.168.0.62&quot;, 8005)); jedisClusterNode.add(new HostAndPort(&quot;192.168.0.63&quot;, 8006)); JedisCluster jedisCluster = null; try &#123; // connectionTimeout：指的是连接一个url的连接等待时间 // soTimeout：指的是连接上一个url，获取response的返回等待时间 jedisCluster = new JedisCluster(jedisClusterNode, 6000, 5000, 10, &quot;eleven&quot;, config); System.out.println(jedisCluster.set(&quot;cluster&quot;, &quot;eleven&quot;)); System.out.println(jedisCluster.get(&quot;cluster&quot;)); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; if (jedisCluster != null) &#123; jedisCluster.close(); &#125; &#125; &#125;&#125; 集群的Spring Boot整合Redis连接12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt;&lt;/dependency&gt; 12345678910111213spring: redis: database: 0 timeout: 3000 password: root cluster: nodes: 192.168.0.61:8001,192.168.0.62:8002,192.168.0.63:8003,192.168.0.61:8004,192.168.0.62:8005,192.168.0.63:8006 lettuce: pool: max-idle: 50 min-idle: 10 max-active: 100 max-wait: 1000 1234567891011@RestControllerpublic class IndexController &#123; @Autowired private StringRedisTemplate stringRedisTemplate; @RequestMapping(&quot;/test_cluster&quot;) public void testCluster() throws InterruptedException &#123; stringRedisTemplate.opsForValue().set(&quot;eleven&quot;, &quot;666&quot;); System.out.println(stringRedisTemplate.opsForValue().get(&quot;eleven&quot;)); &#125;&#125;","tags":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"Redis","slug":"Cloud/Redis","permalink":"http://example.com/categories/Cloud/Redis/"}]},{"title":"Redis安装","date":"2017-12-15T03:08:20.000Z","path":"blog/Cloud/Redis/Redis安装/","text":"Redis官网： redis官网：http://redis.io windows版本的下载地址是： http://redis.io/download 点击进去之后会跳转到： https://github.com/mythz/redis-windows 是一个开源项目，所以从github上下载后，需要自己编译生成exe文件，但是为了编译生成exe文件，又需要用到Visual Studio一套。 启动服务端：redis-server.exe 启动客户端:redis-cli.exe 详细步骤：1234567891011121314151617181920212223242526272829303132333435# 安装gccyum install gcc# 把下载好的redis-5.0.3.tar.gz放在/usr/local文件夹下，并解压wget http://download.redis.io/releases/redis-5.0.3.tar.gztar xzf redis-5.0.3.tar.gzcd redis-5.0.3# 进入到解压好的redis-5.0.3目录下，进行编译与安装make# 修改配置daemonize yes # 后台启动protected-mode no # 关闭保护模式，若开启只有本机才可访问redis# bind 127.0.0.1 绑定机器网卡ip，若有多块网卡可配多个ip，代表允许客户端通过机器哪些网卡ip去访问，内网一般可不配置bind，注释掉即可# 启动服务src/redis-server redis.conf# 验证启动是否成功 ps -ef | grep redis # 进入redis客户端 src/redis-cli # 退出客户端quit# 退出redis服务pkill redis-server kill 进程号 src/redis-cli shutdown # 查看redis支持的最大连接数，在redis.conf文件中可修改，默认maxclients 10000CONFIG GET maxclients 简单运用:12set hero gareenget hero 就可以实现了向服务器设置 hero 这个键值，并从服务器获取hero对应的值","tags":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"Redis","slug":"Cloud/Redis","permalink":"http://example.com/categories/Cloud/Redis/"}]},{"title":"Redis基础","date":"2017-12-15T02:08:20.000Z","path":"blog/Cloud/Redis/Redis基础/","text":"什么是Redis： Redis是一个开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。 换句话说，Redis就像是一个HashMap，不过不是在JVM中运行，而是以一个独立进程的形式运行。 一般说来，会被当作缓存使用。 因为它比数据库(mysql)快，所以常用的数据，可以考虑放在这里，这样就提高了性能。 Redis是非关系型的键值对数据库，可根据键以O(1)时间复杂度取出或插入关联值，Redis数据是存在内存中，键值对中键可以是字符串、整型、浮点型等且键唯一。值的类型可以是string、list、hash、set、sorted set等。内置了复制、磁盘持久化、LUA脚本、事务、SSL、ACLs、客户端缓存、客户端代理等功能，通过哨兵模式和Cluster模式提供高可用。 Redis的速度非常的快，单机的Redis就可以支撑每秒10几万的并发，相对于MySQL来说，性能是MySQL的几十倍。 完全基于内存操作 C语言实现，优化过的数据结构，基于几种基础的数据结构，Redis做了大量的优化，性能极高 使用单线程，无上下文的切换成本 基于非阻塞的IO多路复用机制 常见命令5种数据类型： String（字符串） List（列表） Hash（字典） Set（集合） Sorted Set（有序集合） 不同的数据类型，有不同的命令方式:String 字符串： SET key value 设置key&#x3D;value GET key 获得键key对应的值 GETRANGE key start end 得到字符串的子字符串存放在一个键 GETSET key value 设置键的字符串值，并返回旧值 GETBIT key offset 返回存储在键位值的字符串值的偏移 MGET key1 [key2..] 得到所有的给定键的值 SETBIT key offset value 设置或清除该位在存储在键的字符串值偏移 SETEX key seconds value 键到期时设置值 SETNX key value 设置键的值，只有当该键不存在 SETRANGE key offset value 覆盖字符串的一部分从指定键的偏移 STRLEN key 得到存储在键的值的长度 MSET key value [key value…] 设置多个键和多个值 MSETNX key value [key value…] 设置多个键多个值，只有在当没有按键的存在时 PSETEX key milliseconds value 设置键的毫秒值和到期时间 INCR key 增加键的整数值一次 INCRBY key increment 由给定的数量递增键的整数值 INCRBYFLOAT key increment 由给定的数量递增键的浮点值 DECR key 递减键一次的整数值 DECRBY key decrement 由给定数目递减键的整数值 APPEND key value 追加值到一个键 DEL key 如果存在删除键 DUMP key 返回存储在指定键的值的序列化版本 EXISTS key 此命令检查该键是否存在 EXPIRE key seconds 指定键的过期时间 EXPIREAT key timestamp 指定的键过期时间。在这里，时间是在Unix时间戳格式 PEXPIRE key milliseconds 设置键以毫秒为单位到期 PEXPIREAT key milliseconds-timestamp 设置键在Unix时间戳指定为毫秒到期 KEYS pattern 查找与指定模式匹配的所有键 MOVE key db 移动键到另一个数据库 PERSIST key 移除过期的键 PTTL key 以毫秒为单位获取剩余时间的到期键。 TTL key 获取键到期的剩余时间。 RANDOMKEY 从Redis返回随机键 RENAME key newkey 更改键的名称 RENAMENX key newkey 重命名键，如果新的键不存在 TYPE key 返回存储在键的数据类型的值。 List 列表： BLPOP key1 [key2 ] timeout 取出并获取列表中的第一个元素，或阻塞，直到有可用 BRPOP key1 [key2 ] timeout 取出并获取列表中的最后一个元素，或阻塞，直到有可用 BRPOPLPUSH source destination timeout 从列表中弹出一个值，它推到另一个列表并返回它;或阻塞，直到有可用 LINDEX key index 从一个列表其索引获取对应的元素 LINSERT key BEFORE|AFTER pivot value 在列表中的其他元素之后或之前插入一个元素 LLEN key 获取列表的长度 LPOP key 获取并取出列表中的第一个元素 LPUSH key value1 [value2] 在前面加上一个或多个值的列表 LPUSHX key value 在前面加上一个值列表，仅当列表中存在 LRANGE key start stop 从一个列表获取各种元素 LREM key count value 从列表中删除元素 LSET key index value 在列表中的索引设置一个元素的值 LTRIM key start stop 修剪列表到指定的范围内 RPOP key 取出并获取列表中的最后一个元素 RPOPLPUSH source destination 删除最后一个元素的列表，将其附加到另一个列表并返回它 RPUSH key value1 [value2] 添加一个或多个值到列表 RPUSHX key value 添加一个值列表，仅当列表中存在 Hash 字典，哈希表： HDEL key field[field…] 删除对象的一个或几个属性域，不存在的属性将被忽略 HEXISTS key field 查看对象是否存在该属性域 HGET key field 获取对象中该field属性域的值 HGETALL key 获取对象的所有属性域和值 HINCRBY key field value 将该对象中指定域的值增加给定的value，原子自增操作，只能是integer的属性值可以使用 HINCRBYFLOAT key field increment 将该对象中指定域的值增加给定的浮点数 HKEYS key 获取对象的所有属性字段 HVALS key 获取对象的所有属性值 HLEN key 获取对象的所有属性字段的总数 HMGET key field[field…] 获取对象的一个或多个指定字段的值 HSET key field value 设置对象指定字段的值 HMSET key field value [field value …] 同时设置对象中一个或多个字段的值 HSETNX key field value 只在对象不存在指定的字段时才设置字段的值 HSTRLEN key field 返回对象指定field的value的字符串长度，如果该对象或者field不存在，返回0. HSCAN key cursor [MATCH pattern] [COUNT count] 类似SCAN命令 Set 集合： SADD key member [member …] 添加一个或者多个元素到集合(set)里 SCARD key 获取集合里面的元素数量 SDIFF key [key …] 获得队列不存在的元素 SDIFFSTORE destination key [key …] 获得队列不存在的元素，并存储在一个关键的结果集 SINTER key [key …] 获得两个集合的交集 SINTERSTORE destination key [key …] 获得两个集合的交集，并存储在一个集合中 SISMEMBER key member 确定一个给定的值是一个集合的成员 SMEMBERS key 获取集合里面的所有key SMOVE source destination member 移动集合里面的一个key到另一个集合 SPOP key [count] 获取并删除一个集合里面的元素 SRANDMEMBER key [count] 从集合里面随机获取一个元素 SREM key member [member …] 从集合里删除一个或多个元素，不存在的元素会被忽略 SUNION key [key …] 添加多个set元素 SUNIONSTORE destination key [key …] 合并set元素，并将结果存入新的set里面 SSCAN key cursor [MATCH pattern] [COUNT count] 迭代set里面的元素 Sorted Set 有序集合： ZADD key score1 member1 [score2 member2] 添加一个或多个成员到有序集合，或者如果它已经存在更新其分数 ZCARD key 得到的有序集合成员的数量 ZCOUNT key min max 计算一个有序集合成员与给定值范围内的分数 ZINCRBY key increment member 在有序集合增加成员的分数 ZINTERSTORE destination numkeys key [key …] 多重交叉排序集合，并存储生成一个新的键有序集合。 ZLEXCOUNT key min max 计算一个给定的字典范围之间的有序集合成员的数量 ZRANGE key start stop [WITHSCORES] 由索引返回一个成员范围的有序集合（从低到高） ZRANGEBYLEX key min max [LIMIT offset count]返回一个成员范围的有序集合（由字典范围） ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT] 返回有序集key中，所有 score 值介于 min 和 max 之间(包括等于 min 或 max )的成员，有序集成员按 score 值递增(从小到大)次序排列 ZRANK key member 确定成员的索引中有序集合 ZREM key member [member …] 从有序集合中删除一个或多个成员，不存在的成员将被忽略 ZREMRANGEBYLEX key min max 删除所有成员在给定的字典范围之间的有序集合 ZREMRANGEBYRANK key start stop 在给定的索引之内删除所有成员的有序集合 ZREMRANGEBYSCORE key min max 在给定的分数之内删除所有成员的有序集合 ZREVRANGE key start stop [WITHSCORES] 返回一个成员范围的有序集合，通过索引，以分数排序，从高分到低分 ZREVRANGEBYSCORE key max min [WITHSCORES] 返回一个成员范围的有序集合，以socre排序从高到低 ZREVRANK key member 确定一个有序集合成员的索引，以分数排序，从高分到低分 ZSCORE key member 获取给定成员相关联的分数在一个有序集合 ZUNIONSTORE destination numkeys key [key …] 添加多个集排序，所得排序集合存储在一个新的键 ZSCAN key cursor [MATCH pattern] [COUNT count] 增量迭代排序元素集和相关的分数 官方命令手册:如果还想查询每个命令的详细用法，请到redis官方命令手册： http://www.redis.cn/commands.html Redis备份策略 写crontab定时调度脚本，每小时都copy一份rdb或aof的备份到一个目录中去，仅仅保留最近48小时的备份； 每天都保留一份当日的数据备份到一个目录中去，可以保留最近1个月的备份，每次copy备份的时候，都把太旧的备份删除； 每天晚上将当前机器上的备份复制一份到其他机器上，以防机器损坏。 应用场景: 计数器：可对String进行自增自减运算从而实现计数器功能，这种内存型数据库读写性能非常高，很适合存储频繁读写的计数量 分布式ID生成：利用自增特性，一次请求一个大一点的步长如**incr 2000**，缓存在本地使用，用完再请求 海量数据统计：通过位图**bitmap存储是否参过某次活动，是否已读谋篇文章，用户是否为会员，日活统计** Session共享：可统一存储多台应用服务器会话信息，一个用户可请求任意一个应用服务器，从而更容易实现高可用性以及可伸缩性 分布式队列、阻塞队列：List双向链表可通过**lpush/rpush和rpop/lpop写入和读取消息，可通过使用brpop/blpop**来实现阻塞队列 分布式锁实现：使用Redis自带的**SETNX**命令实现分布式锁 热点数据存储：最新评论，最新文章列表，使用list存储，ltrim取出热点数据，删除老数据 社交类需求：可通过Set交集实现共同好友等功能，可通过Set求差集进行好友推荐、文章推荐 排行榜：**sorted_set**可实现有序性操作，从而实现排行榜等功能 延迟队列：通过**sorted_set使用当前时间戳 + 需要延迟的时长做score，消息内容作为元素，调用zadd来生产消息，消费者使用zrangbyscore获取当前时间之前的数据做轮询处理。消费完再删除任务rem key member**","tags":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"Redis","slug":"Cloud/Redis","permalink":"http://example.com/categories/Cloud/Redis/"}]},{"title":"Gateway源码分析","date":"2017-12-14T16:00:00.000Z","path":"blog/Cloud/Gateway源码分析/","text":"Gateway源码:网关作为流量的入口，常用的功能包括路由转发，权限校验，限流等，Spring Cloud Gateway是Spring Cloud官方推出的由**WebFlux + Netty + Reactor实现的响应式的第二代API网关**框架，定位于取代Netflix Zuul。 Spring Cloud Gateway的核心概念：路由Route、断言、过滤器。路由是网关中最基础的部分，路由信息包括一个ID、一个目的URI、一组断言工厂、一组Filter组成，若断言为真则说明请求的URL和配置的路由匹配；Spring Cloud Gateway中的断言函数类型是Spring5.0框架中的**ServerWebExchange，允许开发者去定义匹配Http Request中的任何信息，如请求头和参数等；Spring Cloud Gateway的过滤器分为GatewayFilIer和GlobalFilter，可对请求和响应进行处理**。 Spring Cloud Gateway工作原理跟Zuul的差不多，最大的区别就是Gateway的Filter只有**pre和post两种，客户端向Spring Cloud Gateway发出请求，若请求与网关定义的路由匹配，则该请求会被发送到网关Web处理程序，此时处理程序运行特定的请求过滤器链。过滤器之间用虚线分开的原因是过滤器可能会在发送代理请求的前后执行逻辑。所有pre过滤器逻辑先执行，然后执行代理请求；代理请求完成后执行post过滤器逻辑**。 Gateway对请求处理的核心逻辑是在**DispatcherHandler中，在DispatcherHandler中依次调用HandlerMapping、HandlerAdapter、HandlerResultHandler**三个核心接口 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class DispatcherHandler implements WebHandler, ApplicationContextAware &#123; public Mono&lt;Void&gt; handle(ServerWebExchange exchange) &#123; if (this.handlerMappings == null) &#123; return createNotFoundError(); &#125; return Flux.fromIterable(this.handlerMappings) .concatMap(mapping -&gt; mapping.getHandler(exchange)) // 获取具体的HandlerMapping，这里返回FilteringWebHandler .next() .switchIfEmpty(createNotFoundError()) // 若路由断言匹配未匹配到，则返回Empty，这里对Empty进行处理 .flatMap(handler -&gt; invokeHandler(exchange, handler)) // 调用具体的HandlerAdapter的handle .flatMap(result -&gt; handleResult(exchange, result)); &#125; private Mono&lt;HandlerResult&gt; invokeHandler(ServerWebExchange exchange, Object handler) &#123; if (this.handlerAdapters != null) &#123; for (HandlerAdapter handlerAdapter : this.handlerAdapters) &#123; if (handlerAdapter.supports(handler)) &#123; return handlerAdapter.handle(exchange, handler); &#125; &#125; &#125; return Mono.error(new IllegalStateException(&quot;No HandlerAdapter: &quot; + handler)); &#125; private Mono&lt;Void&gt; handleResult(ServerWebExchange exchange, HandlerResult result) &#123; return getResultHandler(result).handleResult(exchange, result) .checkpoint(&quot;Handler &quot; + result.getHandler() + &quot; [DispatcherHandler]&quot;) .onErrorResume(ex -&gt; result.applyExceptionHandler(ex).flatMap(exResult -&gt; &#123; String text = &quot;Exception handler &quot; + exResult.getHandler() + &quot;, error=\\&quot;&quot; + ex.getMessage() + &quot;\\&quot; [DispatcherHandler]&quot;; return getResultHandler(exResult).handleResult(exchange, exResult).checkpoint(text); &#125;)); &#125; private HandlerResultHandler getResultHandler(HandlerResult handlerResult) &#123; if (this.resultHandlers != null) &#123; for (HandlerResultHandler resultHandler : this.resultHandlers) &#123; if (resultHandler.supports(handlerResult)) &#123; return resultHandler; &#125; &#125; &#125; throw new IllegalStateException(&quot;No HandlerResultHandler for &quot; + handlerResult.getReturnValue()); &#125; private &lt;R&gt; Mono&lt;R&gt; createNotFoundError() &#123; return Mono.defer(() -&gt; &#123; Exception ex = new ResponseStatusException(HttpStatus.NOT_FOUND, &quot;No matching handler&quot;); return Mono.error(ex); &#125;); &#125;&#125; HandlerMappingHandlerMapping负责路径到Handler的映射，Gateway中RoutePredicateHandlerMapping实现了AbstractHandlerMapping，其作用是执行所有的Route的断言工厂PredicateFactory匹配路由信息，通过断言判断路由是否可用，且将路由信息绑定到请求上下文中，最终返回**FilteringWebHandler**。 也可自定义断言工厂需继承AbstractRoutePredicateFactory类重写apply方法的逻辑。在apply方法中可以通过exchange.getRequest()拿到ServerHttpRequest对象，从而可获取到请求的参数、请求方式、请求头等信息。 12345678910111213141516public abstract class AbstractHandlerMapping extends ApplicationObjectSupport implements HandlerMapping, Ordered, BeanNameAware &#123; public Mono&lt;Object&gt; getHandler(ServerWebExchange exchange) &#123; return getHandlerInternal(exchange).map(handler -&gt; &#123; ServerHttpRequest request = exchange.getRequest(); if (hasCorsConfigurationSource(handler) || CorsUtils.isPreFlightRequest(request)) &#123; // 处理跨域问题 CorsConfiguration config = (this.corsConfigurationSource != null ? this.corsConfigurationSource.getCorsConfiguration(exchange) : null); CorsConfiguration handlerConfig = getCorsConfiguration(handler, exchange); config = (config != null ? config.combine(handlerConfig) : handlerConfig); if (!this.corsProcessor.process(config, exchange) || CorsUtils.isPreFlightRequest(request)) &#123; return REQUEST_HANDLED_HANDLER; &#125; &#125; return handler; &#125;); &#125;&#125; 首先通过**lookupRoute方法找出所有与当前请求匹配的Route，在匹配之前从RouteLocator的实现类CachingRouteLocator中已经转换好的Route，在应用启动时会通过RouteLocator的实现类RouteDefinitionRouteLocator通过PropertiesRouteDefinitionLocator从GatewayProperties中读取路由配置RouteDefinition且将其转换为Route并缓存到CachingRouteLocator中。除此之外若在DiscoveryClientRouteDefinitionLocator会获取集群中所有的实例并将其构建成RouteDefinition，最终转换并合并到CachingRouteLocator**中。 在**lookupRoute中通过遍历所有的Route，并遍历调用其具体的PredicateFactory的test方法，过滤出其test方法放回true的route。然后将匹配的路由绑定到请求上下文中。最终返回FilteringWebHandler** 1234567891011121314151617181920212223242526public class RoutePredicateHandlerMapping extends AbstractHandlerMapping &#123; protected Mono&lt;?&gt; getHandlerInternal(ServerWebExchange exchange) &#123; if (this.managementPortType == DIFFERENT &amp;&amp; this.managementPort != null &amp;&amp; exchange.getRequest().getURI().getPort() == this.managementPort) &#123; return Mono.empty(); &#125; exchange.getAttributes().put(GATEWAY_HANDLER_MAPPER_ATTR, getSimpleName()); return lookupRoute(exchange).flatMap((Function&lt;Route, Mono&lt;?&gt;&gt;) r -&gt; &#123; exchange.getAttributes().remove(GATEWAY_PREDICATE_ROUTE_ATTR); exchange.getAttributes().put(GATEWAY_ROUTE_ATTR, r); // 将匹配的路由绑定到请求上下文中，以便FilteringWebHandler的handle方法中使用 return Mono.just(webHandler); // 最终返回FilteringWebHandler &#125;).switchIfEmpty(Mono.empty().then(Mono.fromRunnable(() -&gt; &#123; // 未找到匹配的路由 exchange.getAttributes().remove(GATEWAY_PREDICATE_ROUTE_ATTR); &#125;))); &#125; protected Mono&lt;Route&gt; lookupRoute(ServerWebExchange exchange) &#123; return this.routeLocator.getRoutes().concatMap(route -&gt; Mono.just(route).filterWhen(r -&gt; &#123; exchange.getAttributes().put(GATEWAY_PREDICATE_ROUTE_ATTR, r.getId()); return r.getPredicate().apply(exchange); // 调用具体的PredicateFactory的test方法，过滤出test方法放回true的route &#125;).doOnError(e -&gt; logger.error(&quot;Error applying predicate for route: &quot; + route.getId(), e)).onErrorResume(e -&gt; Mono.empty())) .next() .map(route -&gt; &#123; validateRoute(route, exchange); return route; &#125;); &#125;&#125; HandlerAdapter调用具体的**HandlerAdapter的调用，在DelegatingWebFluxConfiguration配置类的超类WebFluxConfigurationSupport中注入了SimpleHandlerAdapter。而FilteringWebHandler是WebHandler的子类。在SimpleHandlerAdapter的handle方法中调用FilteringWebHandler的handle方法。由于SimpleHandlerAdapter返回的是Mono.empty()故不会触发handleResult**方法。 123456789101112public class SimpleHandlerAdapter implements HandlerAdapter &#123; @Override public boolean supports(Object handler) &#123; return WebHandler.class.isAssignableFrom(handler.getClass()); &#125; @Override public Mono&lt;HandlerResult&gt; handle(ServerWebExchange exchange, Object handler) &#123; WebHandler webHandler = (WebHandler) handler; Mono&lt;Void&gt; mono = webHandler.handle(exchange); return mono.then(Mono.empty()); &#125;&#125; 在**GatewayAutoConfiguration配置类中注入了FilteringWebHandler，由于全局的过滤器GlobalFilter与GatewayFilter故在其构造方法中通过适配器模式将GlobalFilter转换成了GatewayFilter。然后通过责任链模式挨个调用GatewayFilter的filter**方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960@Configuration(proxyBeanMethods = false)@ConditionalOnProperty(name = &quot;spring.cloud.gateway.enabled&quot;, matchIfMissing = true)@EnableConfigurationProperties@AutoConfigureBefore(&#123; HttpHandlerAutoConfiguration.class, WebFluxAutoConfiguration.class &#125;)@AutoConfigureAfter(&#123; GatewayLoadBalancerClientAutoConfiguration.class, GatewayClassPathWarningAutoConfiguration.class &#125;)@ConditionalOnClass(DispatcherHandler.class)public class GatewayAutoConfiguration &#123; public FilteringWebHandler filteringWebHandler(List&lt;GlobalFilter&gt; globalFilters) &#123; return new FilteringWebHandler(globalFilters); &#125;&#125;public class FilteringWebHandler implements WebHandler &#123; private final List&lt;GatewayFilter&gt; globalFilters; public FilteringWebHandler(List&lt;GlobalFilter&gt; globalFilters) &#123; this.globalFilters = loadFilters(globalFilters);// 通过适配器模式将GlobalFilter转换为GatewayFilter &#125; private static List&lt;GatewayFilter&gt; loadFilters(List&lt;GlobalFilter&gt; filters) &#123; return filters.stream().map(filter -&gt; &#123; GatewayFilterAdapter gatewayFilter = new GatewayFilterAdapter(filter); if (filter instanceof Ordered) &#123; int order = ((Ordered) filter).getOrder(); return new OrderedGatewayFilter(gatewayFilter, order); &#125; return gatewayFilter; &#125;).collect(Collectors.toList()); &#125; public Mono&lt;Void&gt; handle(ServerWebExchange exchange) &#123; Route route = exchange.getRequiredAttribute(GATEWAY_ROUTE_ATTR); // 从请求上下文中取出前面绑定的Route List&lt;GatewayFilter&gt; gatewayFilters = route.getFilters(); // 获取Route中配置的filters List&lt;GatewayFilter&gt; combined = new ArrayList&lt;&gt;(this.globalFilters); combined.addAll(gatewayFilters); // 合并配置的filters和自动注入的全局的filters AnnotationAwareOrderComparator.sort(combined); // 对GatewayFilter列表排序 return new DefaultGatewayFilterChain(combined).filter(exchange); &#125;&#125;private static class DefaultGatewayFilterChain implements GatewayFilterChain &#123; private final int index; private final List&lt;GatewayFilter&gt; filters; DefaultGatewayFilterChain(List&lt;GatewayFilter&gt; filters) &#123; this.filters = filters; this.index = 0; &#125; private DefaultGatewayFilterChain(DefaultGatewayFilterChain parent, int index) &#123; this.filters = parent.getFilters(); this.index = index; &#125; public Mono&lt;Void&gt; filter(ServerWebExchange exchange) &#123; return Mono.defer(() -&gt; &#123; if (this.index &lt; filters.size()) &#123; GatewayFilter filter = filters.get(this.index); DefaultGatewayFilterChain chain = new DefaultGatewayFilterChain(this, this.index + 1); return filter.filter(exchange, chain); &#125; else &#123; return Mono.empty(); // complete &#125; &#125;); &#125;&#125; 也可自定义**GatewayFilter，自定义GatewayFilter是通过自定义过滤器工厂来完成的，自定义工厂可集成一些列的AbstractGatewayFilterFactory来完成响应的功能，还可通过实现GlobalFilter来自定义全局的过滤器。对于uri支持lb://的方式类配置目标微服务的请求地址，就是通过LoadBalancerClientFilter**过滤器来完成的。 123456789101112131415161718192021222324252627282930313233343536373839public class LoadBalancerClientFilter implements GlobalFilter, Ordered &#123; public static final int LOAD_BALANCER_CLIENT_FILTER_ORDER = 10100; protected final LoadBalancerClient loadBalancer; private LoadBalancerProperties properties; public LoadBalancerClientFilter(LoadBalancerClient loadBalancer, LoadBalancerProperties properties) &#123; this.loadBalancer = loadBalancer; this.properties = properties; &#125; public int getOrder() &#123; return LOAD_BALANCER_CLIENT_FILTER_ORDER; &#125; @Override @SuppressWarnings(&quot;Duplicates&quot;) public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; URI url = exchange.getAttribute(GATEWAY_REQUEST_URL_ATTR); String schemePrefix = exchange.getAttribute(GATEWAY_SCHEME_PREFIX_ATTR); if (url == null || (!&quot;lb&quot;.equals(url.getScheme()) &amp;&amp; !&quot;lb&quot;.equals(schemePrefix))) &#123; return chain.filter(exchange); &#125; addOriginalRequestUrl(exchange, url); final ServiceInstance instance = choose(exchange); if (instance == null) &#123; throw NotFoundException.create(properties.isUse404(), &quot;Unable to find instance for &quot; + url.getHost()); &#125; URI uri = exchange.getRequest().getURI(); String overrideScheme = instance.isSecure() ? &quot;https&quot; : &quot;http&quot;; if (schemePrefix != null) &#123; overrideScheme = url.getScheme(); &#125; URI requestUrl = loadBalancer.reconstructURI(new DelegatingServiceInstance(instance, overrideScheme), uri); exchange.getAttributes().put(GATEWAY_REQUEST_URL_ATTR, requestUrl); return chain.filter(exchange); &#125; protected ServiceInstance choose(ServerWebExchange exchange) &#123; // 通过负载均衡算法获取具体的实例对象 return loadBalancer.choose(((URI) exchange.getAttribute(GATEWAY_REQUEST_URL_ATTR)).getHost()); &#125;&#125;","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"}]},{"title":"Welcome TaoLiu's Blog","date":"2016-03-24T07:21:55.000Z","path":"blog/index/","text":"Welcome TaoLiu’s Blog","tags":[],"categories":[]},{"title":"Hello hexo","date":"2016-03-12T04:08:20.000Z","path":"blog/hello-hexo/","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","tags":[],"categories":[]},{"title":"访问者模式","date":"2016-01-04T05:50:20.000Z","path":"blog/设计模式/行为型模式/访问者模式/","text":"访问者模式是一种集中规整模式，特别适用于大规模重构的项目，通过访问者模式可以很容易把一些功能进行梳理。还可以与其他模式混编建立一套自己的过滤器或者拦截器。 访问者模式是对迭代器模式的扩充，可以遍历不同的对象，然后执行不同的操作，也就是针对访问的对象不同， 执行不同的操作。 访问者模式还可以充当**拦截器Interceptor**角色 。 访问者模式能把处理方法从数据结构中分离出来，并可以根据需要增加新的处理方法，且不用修改原来的程序代码与数据结构，这提高了程序的扩展性和灵活性。 定义封装一些作用于某种数据结构中的各元素的操作，它可以在不改变数据结构的前提下定义作用于这些元素的新的操作。 将作用于某种数据结构中的各元素的操作分离出来封装成独立的类，使其在不改变数据结构的前提下可以添加作用于这些元素的新的操作，为数据结构中的每个元素提供多种访问方式。它将对数据的操作与数据结构进行分离，是行为类模式中最复杂的一种模式。 实现抽象访问者Visitor：定义一个访问具体元素的接口，为每个具体元素类对应一个访问操作**visit()** ，该操作中的参数类型标识了被访问的具体元素。 1234public interface Visitor &#123; void visit(ConcreteElementA element); void visit(ConcreteElementB element);&#125; **具体访问者角色ConcreteVisitor**：实现抽象访问者角色中声明的各个访问操作，确定访问者访问一个元素时的具体功能。 1234567891011121314151617181920212223public class ConcreteVisitorA implements Visitor &#123; @Override public void visit(ConcreteElementA element) &#123; System.out.println(&quot;具体访问者A访问--&gt;&quot; + element.operationA()); &#125; @Override public void visit(ConcreteElementB element) &#123; System.out.println(&quot;具体访问者A访问--&gt;&quot; + element.operationB()); &#125;&#125;public class ConcreteVisitorB implements Visitor &#123; @Override public void visit(ConcreteElementA element) &#123; System.out.println(&quot;具体访问者B访问--&gt;&quot; + element.operationA()); &#125; @Override public void visit(ConcreteElementB element) &#123; System.out.println(&quot;具体访问者B访问--&gt;&quot; + element.operationB()); &#125;&#125; **抽象元素角色Element：声明一个包含接受操作accept()**的接口，被接受的访问者对象作为accept()方法的参数。 123public interface Element &#123; void accept(Visitor visitor);&#125; 具体元素角色ConcreteElement：实现抽象元素角色提供的 accept() 操作，其方法体通常都是visitor.visit(this)，另外具体元素中可能还包含本身业务逻辑的相关操作。 123456789101112131415161718192021public class ConcreteElementA implements Element &#123; @Override public void accept(Visitor visitor) &#123; visitor.visit(this); &#125; public String operationA() &#123; return &quot;具体元素A的操作。&quot;; &#125;&#125;public class ConcreteElementB implements Element &#123; @Override public void accept(Visitor visitor) &#123; visitor.visit(this); &#125; public String operationB() &#123; return &quot;具体元素B的操作。&quot;; &#125;&#125; 对象结构角色ObjectStructure：是一个包含元素角色的容器，提供让访问者对象遍历容器中的所有元素的方法，通常由 List、Set、Map 等聚合类实现。 12345678910111213141516171819202122232425262728public class ObjectStructure &#123; private List&lt;Element&gt; list = new ArrayList&lt;Element&gt;(); public void accept(Visitor visitor) &#123; for (Element element : list) &#123; element.accept(visitor); &#125; &#125; public void add(Element element) &#123; list.add(element); &#125; public void remove(Element element) &#123; list.remove(element); &#125; public static void main(String[] args) &#123; ObjectStructure os = new ObjectStructure(); os.add(new ConcreteElementA()); os.add(new ConcreteElementB()); Visitor visitor = new ConcreteVisitorA(); os.accept(visitor); System.out.println(&quot;------------------------&quot;); visitor = new ConcreteVisitorB(); os.accept(visitor); &#125;&#125; 优点 扩展性好：能够在不修改对象结构中的元素的情况下，为对象结构中的元素添加新的功能。 复用性好：可以通过访问者来定义整个对象结构通用的功能，从而提高系统的复用程度。 灵活性好：访问者模式将数据结构与作用于结构上的操作解耦，使得操作集合可相对自由地演化而不影响系统的数据结构。 符合单一职责原则：访问者模式把相关行为封装在一起构成一个访问者，使每个访问者功能都比较单一。 缺点 增加新的元素类很困难：每增加一个新的元素类，都要在每个具体访问者类中增加相应的具体操作，违背开闭原则。 破坏封装：具体元素对访问者公布细节，这破坏了对象的封装性。 违反了依赖倒置原则：访问者模式依赖了具体类，而没有依赖抽象类。 应用 需要对一个对象结构中的对象进行很多不同并且不相关的操作，而你想避免让这些操作污染这些对象的类 数据元素相对稳定而访问方式多种多样的数据结构 对象结构相对稳定，但其操作算法经常变化的程序。 对象结构中的对象需要提供多种不同且不相关的操作，而且要避免让这些操作的变化影响对象的结构。 对象结构包含很多类型的对象，希望对这些对象实施一些依赖于其具体类型的操作。 扩展 统计功能：数据统计和报表的批处理通过访问者模式来处理会比较简单 多个访问者：用于展示的访问者和用于汇总的访问者","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"行为型模式","slug":"设计模式/行为型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"迭代器模式","date":"2016-01-04T05:50:20.000Z","path":"blog/设计模式/行为型模式/迭代器模式/","text":"从JDK1.2开始增加java.util.Iterator接口， 并逐步把Iterator应用到各个Collection聚集类中，Collection、List、Set、Map 等都包含了迭代器 。正因为把迭代器模式已经融入到基本API中了，再去写迭代器， 就有点多余，所以迭代器模式没落了，基本上没人会单独写一个迭代器。 迭代器模式提供了遍历容器的方便性，容器只要管理增减元素就可以了，需要遍历时交由迭代器进行。 定义提供一种方法访问一个容器对象中各个元素，而又不暴露该对象的内部细节。 实现迭代器模式是通过将聚合对象的遍历行为分离出来，抽象成迭代器类来实现的，其目的是在不暴露聚合对象的内部结构的情况下，让外部代码透明地访问聚合的内部数据。 Iterator抽象迭代器，定义访问和遍历聚合元素的接口，通常包含hasNext()、first()、next()等方法 。 12345interface Iterator &#123; Object first(); Object next(); boolean hasNext();&#125; ConcreteIterator具体迭代器，实现抽象迭代器接口中所定义的方法，完成对聚合对象的遍历，记录遍历的当前位置。 1234567891011121314151617181920212223242526public class ConcreteIterator implements Iterator &#123; private List&lt;Object&gt; list = null; private int index = -1; public ConcreteIterator(List&lt;Object&gt; list) &#123; this.list = list; &#125; public boolean hasNext() &#123; if (index &lt; list.size() - 1) &#123; return true; &#125; else &#123; return false; &#125; &#125; public Object first() &#123; index = 0; Object obj = list.get(index); return obj; &#125; public Object next() &#123; Object obj = null; if (this.hasNext()) &#123; obj = list.get(++index); &#125; return obj; &#125;&#125; Aggregate抽象容器，定义存储、添加、删除聚合对象以及创建迭代器对象的接口。 12345public interface Aggregate &#123; public void add(Object obj); public void remove(Object obj); public Iterator getIterator();&#125; ConcreteAggregate具体容器 ，实现抽象聚合类，返回一个具体迭代器的实例。 123456789101112public class ConcreteAggregate implements Aggregate &#123; private List&lt;Object&gt; list = new ArrayList&lt;Object&gt;(); public void add(Object obj) &#123; list.add(obj); &#125; public void remove(Object obj) &#123; list.remove(obj); &#125; public Iterator getIterator() &#123; return (new ConcreteIterator(list)); &#125;&#125; 客户端调用 12345678910111213public static void main(String[] args) &#123; Aggregate ag = new ConcreteAggregate(); ag.add(&quot;中山大学&quot;); ag.add(&quot;华南理工&quot;); ag.add(&quot;西华大学&quot;); Iterator it = ag.getIterator(); while (it.hasNext()) &#123; Object ob = it.next(); System.out.print(ob.toString() + &quot;\\t&quot;); &#125; Object ob = it.first(); System.out.println(&quot;\\nFirst：&quot; + ob.toString());&#125; 优点 访问一个聚合对象的内容而无须暴露它的内部表示 遍历任务交由迭代器完成，这简化了聚合类 它支持以不同方式遍历一个聚合，甚至可以自定义迭代器的子类以支持新的遍历 增加新的聚合类和迭代器类都很方便，无须修改原有代码 封装性良好，为遍历不同的聚合结构提供一个统一的接口 缺点 增加了类的个数，这在一定程度上增加了系统的复杂性 应用当需要为聚合对象提供多种遍历方式时；当需要为遍历不同的聚合结构提供一个统一的接口时。当访问一个聚合对象的内容而无须暴露其内部细节的表示时。 迭代器模式常常与组合模式结合起来使用，在对组合模式中的容器构件进行访问时，经常将迭代器潜藏在组合模式的容器构成类中。","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"行为型模式","slug":"设计模式/行为型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"责任链模式","date":"2016-01-04T05:40:20.000Z","path":"blog/设计模式/行为型模式/责任链模式/","text":"定义：使多个对象都有机会处理请求，从而避免了请求的发送者和接受者之间的耦合关系。将这些对象连成一条链，并沿着这条链传递该请求，直到有对象处理它为止。 责任链模式的关键是在链上，链是由多个处理者ConcreteHandler组成，由一条链去处理相似的请求在链中决定谁来处理这个请求，并返回相应结果。 实现抽象处理者角色，定义一个处理请求的接口，包含抽象处理方法和一个后继连接，融合了模板方法模式。 123456789101112131415161718192021public abstract class AbstractChainHandler&lt;T&gt; &#123; private AbstractChainHandler next; protected abstract &lt;T&gt; T doHandler(Object... obj); protected abstract &lt;T&gt; boolean isAccordWith(T t); public &lt;T&gt; T handler(Object... obj) &#123; T result = doHandler(obj); if (!isAccordWith(result) &amp;&amp; next != null) &#123; return (T) next.handler(obj); &#125; else &#123; return result; &#125; &#125; public void setNext(AbstractChainHandler next) &#123; this.next = next; &#125;&#125; 具体处理者角色，实现抽象处理者的处理方法，判断能否处理本次请求，如果可以处理请求则处理，否则将该请求转给它的后继者。 12345678910111213141516171819202122232425public class ConcreteChainHandler1&lt;T&gt; extends AbstractChainHandler&lt;T&gt; &#123; protected &lt;T&gt; T doHandler(Object... obj) &#123; // 具体业务逻辑 return null; &#125; @Override protected &lt;T1&gt; boolean isAccordWith(T1 t1) &#123; // 根据具体业务逻辑判断返回true还是false return false; &#125;&#125;public class ConcreteChainHandler2&lt;T&gt; extends AbstractChainHandler&lt;T&gt; &#123; protected &lt;T&gt; T doHandler(Object... obj) &#123; // 具体业务逻辑 return null; &#125; @Override protected &lt;T1&gt; boolean isAccordWith(T1 t1) &#123; // 根据具体业务逻辑判断返回true还是false return false; &#125;&#125; 客户类角色，创建处理链，并向链头的具体处理者对象提交请求，它不关心处理细节和请求的传递过程。 123456public static void main(String[] args) &#123; AbstractChainHandler h1 = new ConcreteChainHandler1(); AbstractChainHandler h2 = new ConcreteChainHandler2(); h1.setNext(h2); h1.handler(new Object[]&#123;&#125;);&#125; 责任链模式的本质是解耦请求与处理，让请求在处理链中能进行传递与被处理；独到之处是将其节点处理者组合成了链式结构，并允许节点自身决定是否进行请求处理或转发，相当于让请求流动起来。 优点只需要将请求发送到责任链上即可，无须关心请求的处理细节和请求的传递过程，请求会自动进行传递。所以责任链将请求的发送者和请求的处理者解耦了。 降低了对象之间的耦合度，对象无须知道到底是哪一个对象处理其请求以及链的结构，发送者和接收者也无须拥有对方的明确信息 增强了系统的可扩展性，可以根据需要增加新的请求处理类 增强了给对象指派职责的灵活性，当工作流程发生变化，可以动态地改变链内的成员或者调动它们的次序，也可动态地新增或者删除责任 简化了对象之间的连接，每个对象只需保持一个指向其后继者的引用，不需保持其他所有处理者的引用，这避免了使用众多的 if 或者 if···else 语句。 责任分担，每个类只需要处理自己该处理的工作 缺点 不能保证每个请求一定被处理，没有明确的接收者，所以不能保证它一定会被处理，该请求可能一直传到链的末端都得不到处理 对比较长的职责链，请求的处理可能涉及多个处理对象，系统性能将受到一定影响 职责链建立的合理性要靠客户端来保证，增加了客户端的复杂性，可能会由于职责链的错误设置而导致系统出错，如可能会造成循环调用 应用场景过滤器链的实现，Spring中的拦截器链 多个对象可以处理一个请求，但具体由哪个对象处理该请求在运行时自动确定。 可动态指定一组对象处理请求，或添加新的处理者 需要在不明确指定请求处理者的情况下，向多个处理者中的一个提交请求","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"行为型模式","slug":"设计模式/行为型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"观察者模式","date":"2016-01-04T05:30:20.000Z","path":"blog/设计模式/行为型模式/观察者模式/","text":"实现观察者模式时要注意具体目标对象和具体观察者对象之间不能直接调用，否则将使两者之间紧密耦合起来，这违反了面向对象的设计原则。 定义定义对象间一种一对多的依赖关系，使得每当一个对象改变状态，则所有依赖于它的对象都会得到通知并被自动更新。 实现Subject被观察者，定义被观察者的实现职责，必须能够动态的增加、取消观察者，一般是抽象类或者实现类，仅仅完成作为被观察者必须实现的职责：管理观察者并通知观察者。 123456789101112131415161718public abstract class Subject &#123; //定义一个观察者数组 private Vector&lt;Observer&gt; obsVector = new Vector&lt;Observer&gt;(); //增加一个观察者 public void addObserver(Observer o)&#123; this.obsVector.add(o); &#125; //删除一个观察者 public void delObserver(Observer o)&#123; this.obsVector.remove(o); &#125; //通知所有观察者 public void notifyObservers()&#123; for(Observer o:this.obsVector)&#123; o.update(); &#125; &#125;&#125; Observer观察者，观察者接收到消息后，对消息进行处理。 123public interface Observer &#123; void update();&#125; ConcreteSubject具体的被观察者，定义被观察者自己的业务逻辑，同时定义对哪些事件进行通知。 1234567public class ConcreteSubject extends Subject &#123; //具体的业务 public void doSomething()&#123; System.out.println(&quot;do something&quot;); super.notifyObservers(); &#125;&#125; ConcreteObserver具体的观察者，每个观察者接收到消息后的处理逻辑是不一样的。 123456public class ConcreteObserver implements Observer &#123; @Override public void update() &#123; System.out.println(&quot;接收到信息， 并进行处理！ &quot;); &#125;&#125; 客户端使用 12345678910public static void main(String[] args) &#123; //创建一个被观察者 ConcreteSubject subject = new ConcreteSubject(); //定义一个观察者 Observer obs= new ConcreteObserver(); //观察者观察被观察者 subject.addObserver(obs); //观察者开始活动了 subject.doSomething();&#125; 优点 降低了目标与观察者之间的耦合关系，两者之间是抽象耦合关系。符合依赖倒置原则。 目标与观察者之间建立了一套触发机制。形成了一个触发链。 观察者模式可以完美地实现这里的链条形式。 缺点 目标与观察者之间的依赖关系并没有完全解除，而且有可能出现循环引用。 观察者对象很多时，开发和调试就会比较复杂，通知的发布会花费很多时间，影响程序的效率，且一个观察者卡壳，会影响整体的执行效率；在这种情况下，一般考虑采用异步的方式。 应用在软件系统中，当系统一方行为依赖另一方行为的变动时，可使用观察者模式松耦合联动双方，使得一方的变动可以通知到感兴趣的另一方对象，从而让另一方对象对此做出响应。 对象间存在一对多关系，一个对象的状态发生改变会影响其他对象。 当一个抽象模型有两个方面，其中一个方面依赖于另一方面时，可将这二者封装在独立的对象中以使它们可以各自独立地改变和复用。 实现类似广播机制的功能，不需要知道具体收听者，只需分发广播，系统中感兴趣的对象会自动接收该广播。 多层级嵌套使用，形成一种链式触发机制，使得事件具备跨域（跨越两种观察者类型）通知。 注意广播链的问题，一个观察者可以有双重身份，既是观察者，也是被观察者，链一旦建立，逻辑就比较复杂，可维护性非常差，根据经验建议，在一个观察者模式中最多出现一个对象既是观察者也是被观察者，也就是说消息最多转发一次（传递两次），这还是比较好控制的。 它和责任链模式的最大区别就是观察者广播链在传播的过程中消息是随时更改的，它是由相邻的两个节点协商的消息结构；而责任链模式在消息传递过程中基本上保持消息不可变，如果要改变，也只是在原有的消息上进行修正。 异步处理问题，被观察者发生动作，观察者要做出回应，如果观察者比较多，而且处理时间比较长，就用异步处理，异步处理就要考虑线程安全和队列的问题。 扩展Java提供了**java.util.Observable类和java.util.Observer**接口定义了观察者模式，只要实现它们的子类就可以编写观察者模式实例。 Observable类是抽象目标类，它有一个 Vector 向量，用于保存所有要通知的观察者对象； 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class Observable &#123; // 内部标志位，注明目标对象发生了变化,为true时，notifyObservers()才会通知观察者 private boolean changed = false; private Vector&lt;Observer&gt; obs; public Observable() &#123; obs = new Vector&lt;&gt;(); &#125; public synchronized void addObserver(Observer o) &#123; if (o == null) throw new NullPointerException(); if (!obs.contains(o)) &#123; obs.addElement(o); &#125; &#125; public synchronized void deleteObserver(Observer o) &#123; obs.removeElement(o); &#125; public void notifyObservers() &#123; notifyObservers(null); &#125; public void notifyObservers(Object arg) &#123; Object[] arrLocal; synchronized (this) &#123; if (!changed) return; arrLocal = obs.toArray(); clearChanged(); &#125; for (int i = arrLocal.length-1; i&gt;=0; i--) ((Observer)arrLocal[i]).update(this, arg); &#125; public synchronized void deleteObservers() &#123; obs.removeAllElements(); &#125; protected synchronized void setChanged() &#123; changed = true; &#125; protected synchronized void clearChanged() &#123; changed = false; &#125; public synchronized boolean hasChanged() &#123; return changed; &#125; public synchronized int countObservers() &#123; return obs.size(); &#125;&#125; Observer接口是抽象观察者，它监视目标对象的变化，当目标对象发生变化时，观察者得到通知，并调用**void update(Observable o,Object arg)**方法，进行相应的工作。 123public interface Observer &#123; void update(Observable o, Object arg);&#125; 利用Observable类和Observer接口实现观察者模式实例 1234567891011121314151617181920212223242526public class ConcreteSubject extends Observable &#123; public void doSomething()&#123; System.out.println(&quot;do something&quot;); // 设置内部标志位，注明数据发生变化 super.setChanged(); super.notifyObservers(&quot;msg&quot;); &#125;&#125;public class ConcreteObserver implements Observer &#123; @Override public void update(Observable o, Object arg) &#123; System.out.println(&quot;接收到信息：&quot; + arg); &#125;&#125;public static void main(String[] args) &#123; //创建一个被观察者 ConcreteSubject subject = new ConcreteSubject(); //定义一个观察者 Observer obs= new ConcreteObserver(); //观察者观察被观察者 subject.addObserver(obs); //观察者开始活动了 subject.doSomething();&#125;","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"行为型模式","slug":"设计模式/行为型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"策略模式","date":"2016-01-04T05:20:20.000Z","path":"blog/设计模式/行为型模式/策略模式/","text":"当实现某一个功能存在多种算法或者策略，可以根据环境或者条件的不同选择不同的算法或者策略来完成该功能。 如果使用多重条件转移语句实现即硬编码，不但使条件语句变得很复杂，而且增加、删除或更换算法要修改原代码，不易维护，违背开闭原则。采用策略模式就能很好解决该问题。 定义定义一系列算法，并将每个算法封装起来，使它们可以相互替换，且算法的变化不会影响使用算法的客户。 实现策略模式是准备一组算法，并将这组算法封装到一系列的策略类里面，作为一个抽象策略类的子类。策略模式的重心不是如何实现算法，而是如何组织这些算法，从而让程序结构更加灵活，具有更好的维护性和扩展性。 Strategy抽象策略类定义一个公共接口，各种不同算法以不同方式实现该接口，环境角色使用该接口调用不同的算法 123public interface Strategy &#123; void strategy();&#125; ConcreteStrategy具体策略类，实现了抽象策略定义的接口，提供具体的算法实现 12345678910111213public class ConcreteStrategyA implements Strategy &#123; @Override public void strategy() &#123; System.out.println(&quot;具体策略A的策略方法被访问！&quot;); &#125;&#125;public class ConcreteStrategyB implements Strategy &#123; @Override public void strategy() &#123; System.out.println(&quot;具体策略B的策略方法被访问！&quot;); &#125;&#125; Context环境类，持有一个策略类的引用，最终给客户端调用 1234567891011public class Context &#123; private Strategy strategy; public void setStrategy(Strategy strategy) &#123; this.strategy = strategy; &#125; public void strategy() &#123; this.strategy.strategy(); &#125;&#125; 客户端使用 123456789public static void main(String[] args) &#123; Context c = new Context(); Strategy strategyA = new ConcreteStrategyA(); c.setStrategy(strategyA); c.strategy(); Strategy strategyB = new ConcreteStrategyB(); c.setStrategy(strategyB); c.strategy();&#125; 如果一个策略家族的具体策略数量超过4个，则需要考虑使用混合模式，解决策略类膨胀和对外暴露的问题。 优点 多重条件语句不易维护，而使用策略模式可以避免使用多重条件语句 策略模式提供了一系列的可供重用的算法族，恰当使用继承可以把算法族的公共代码转移到父类里面，从而避免重复的代码 自由切换，策略模式可以提供相同行为的不同实现，客户可以根据不同时间或空间要求选择不同的 策略模式提供了对开闭原则的完美支持，可以在不修改原代码的情况下，灵活增加新算法 策略模式把算法的使用放到环境类中，而算法的实现移到具体策略类中，实现了二者的分离 缺点 会造成很多的策略类，增加维护难度 所有策略类都需要对外暴露，上层模块必须知道有哪些策略，才能决定使用哪个策略，与迪米特法则相违背 应用 多个类只有在算法或行为上稍有不同的场景 算法需要自由切换的场景 需要屏蔽算法规则的场景 扩展策略枚举，把原有定义在抽象策略中的方法移植到枚举中，每个枚举成员就成为一个具体策略 。略枚举是一个非常优秀和方便的模式，但是它受枚举类型的限制，每个枚举项都是public、final、static的，扩展性受到了一定的约束，因此在系统开发中，策略枚举一般担当不经常发生变化的角色。 1234567891011121314151617181920212223242526public enum StrategyEnum &#123; ADD(&quot;+&quot;)&#123; public int exec(int a,int b)&#123; return a + b; &#125; &#125;, SUB(&quot;-&quot;)&#123; public int exec(int a,int b)&#123; return a - b; &#125; &#125;; String value; private StrategyEnum(String _value)&#123; this.value = _value; &#125; public String getValue()&#123; return this.value; &#125; public abstract int exec(int a,int b);&#125;public static void main(String[] args) &#123; int a = Integer.parseInt(args[0]); int b = Integer.parseInt(args[2]); System.out.println(&quot;运行结果为： &quot; + StrategyEnum.ADD.exec(a, b));&#125;","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"行为型模式","slug":"设计模式/行为型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"中介者模式","date":"2016-01-04T05:10:20.000Z","path":"blog/设计模式/行为型模式/中介者模式/","text":"常常会出现好多对象之间存在复杂的交互关系，这种交互关系常常是网状结构，它要求每个对象都必须知道它需要交互的对象。若把这种网状结构改为星形结构的话，将大大降低它们之间的耦合性，这时只要找一个中介者就可以了。 定义一个中介对象来封装一系列对象之间的交互，中介者使各对象不需要显示地相互作用 ，使原有对象之间的耦合松散，且可以独立地改变它们之间的交互。中介者模式又叫调停模式，它是迪米特法则的典型应用。 实现中介者模式由抽象中介者、具体中介者、抽象同事、具体同事几个主要角色。 抽象中介者：定义统一的接口， 用于各同事角色之间的通信 12345678910@Datapublic abstract class Mediator &#123; //定义同事类 protected ConcreteColleague1 c1; protected ConcreteColleague2 c2; //中介者模式的业务逻辑 public abstract void doSomething1(); public abstract void doSomething2();&#125; 具体中介者：通过协调各同事角色实现协作行为， 因此它必须依赖于各个同事角色 12345678910111213public class ConcreteMediator extends Mediator &#123; @Override public void doSomething1() &#123; super.c1.selfMethod1(); super.c2.selfMethod2(); &#125; @Override public void doSomething2() &#123; super.c1.selfMethod1(); super.c2.selfMethod2(); &#125;&#125; 抽象同事类：定义同事类的接口，保存中介者对象，提供同事对象交互的抽象方法，实现所有相互影响的同事类的公共功能 1234567public abstract class Colleague &#123; protected Mediator mediator; public Colleague(Mediator mediator) &#123; this.mediator = mediator; &#125;&#125; 具体同事类：是抽象同事类的实现者，当需要与其他同事对象交互时，由中介者对象负责后续的交互，每个同事角色都知道中介者角色， 且与其他同事角色通信时， 一定要通过中介者角色协作 123456789101112131415public class ConcreteColleague1 extends Colleague &#123; public ConcreteColleague1(Mediator mediator) &#123; super(mediator); &#125; public void selfMethod1() &#123; //处理自己的业务逻辑 &#125; public void depMethod1() &#123; //处理自己的业务逻辑 //自己不能处理的业务逻辑， 委托给中介者处理 super.mediator.doSomething1(); &#125;&#125; 123456789101112131415public class ConcreteColleague2 extends Colleague &#123; public ConcreteColleague2(Mediator mediator) &#123; super(mediator); &#125; public void selfMethod2() &#123; //处理自己的业务逻辑 &#125; public void depMethod2() &#123; //处理自己的业务逻辑 //自己不能处理的业务逻辑， 委托给中介者处理 super.mediator.doSomething2(); &#125;&#125; 优点 类之间各司其职，符合迪米特法则 降低了对象之间的耦合性，使得对象易于独立地被复用 将对象间的一对多关联转变为一对一的关联，提高系统的灵活性，使得系统易于维护和扩展 缺点中介者模式将原本多个对象直接的相互依赖变成了中介者和多个同事类的依赖关系。当同事类越多时，中介者就会越臃肿，变得复杂且难以维护 应用在MVC框架中，控制器（C）就是模型（M）和视图（V）的中介者。","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"行为型模式","slug":"设计模式/行为型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"状态模式","date":"2016-01-04T03:40:20.000Z","path":"blog/设计模式/行为型模式/状态模式/","text":"状态模式适用于当某个对象在它的状态发生改变时，其行为也随着发生比较大的变化，在行为受状态约束的情况下可以使用状态模式，而且使用时对象的状态最好不要超过5个 。 定义当一个对象内在状态改变时允许其改变行为，这个对象看起来像改变了其类 优点 结构清晰，避免了过多的switch…case或者if…else语句的使用，避免了程序的复杂性,提高系统的可维护性 很好地体现了开闭原则和单一职责原则，每个状态都是一个子类 封装性非常好，状态变换放置到类内部实现，外部调用不用知道类内部如何实现状态和行为的变换 缺点 子类太多导致类膨胀 应用 行为随状态改变而改变的场景 条件、分支判断语句的替代者","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"行为型模式","slug":"设计模式/行为型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"模板方法模式","date":"2016-01-04T03:35:20.000Z","path":"blog/设计模式/行为型模式/模板方法模式/","text":"模板方法模式非常简单应用非常广泛的模式，定义一个操作中的算法框架，而将一些步骤延迟到子类中。使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。 AbstractClass叫做抽象模板，其方法分为基本方法和模板方法两类。基本方法也叫做基本操作，由子类实现的方法，且在模板方法中被调用。模板方法可以有一个或几个，用于实现对基本方法的调度，完成固定的逻辑。为了防止恶意操作，一般模板方法都使用final关键之修饰，防止被覆盖。 抽象模板类：1234567891011public abstract class AbstractPerson &#123; public final void prepareGotoSchool()&#123; dressUp(); eatBreakfast(); tackThings(); &#125; protected abstract void dressUp(); protected abstract void eatBreakfast(); protected abstract void tackThings();&#125; 具体的模板类： 1234567891011121314public class Student extends AbstractPerson&#123; @Override protected void dressUp() &#123; System.out.println(&quot;穿衣服&quot;); &#125; @Override protected void eatBreakfast() &#123; System.out.println(&quot;吃妈妈做的早餐&quot;); &#125; @Override protected void tackThings() &#123; System.out.println(&quot;背书包，带上家庭作业和红领巾&quot;); &#125;&#125; 1234567891011121314public class Teacher extends AbstractPerson&#123; @Override protected void dressUp() &#123; System.out.println(&quot;穿工作服&quot;); &#125; @Override protected void eatBreakfast() &#123; System.out.println(&quot;做早饭，照顾孩子吃早饭&quot;); &#125; @Override protected void tackThings() &#123; System.out.println(&quot;带上昨天晚上准备的考卷&quot;); &#125;&#125; 场景类的调用: 1234Student student = new Student();student.prepareGotoSchool();Teacher teacher = new Teacher();teacher.prepareGotoSchool(); 抽象模板中的基本方法尽量设计为protected类型，符合迪米特法则，不需要暴露的属性或方法尽量不要设置为protected类型。实现类若非必要，尽量不要扩大父类中的访问权限。 模板方法模式可封装不变部分，扩展可变部分；可提取公共部分代码，便于维护；行为由父类控制，子类实现。但一般的设计习惯，抽象类负责声明最抽象、最一般的事物属性和方法，实现类完成具体的事物属性和方法。但是模板方法模式却颠倒了，抽象类定义了部分抽象方法，由子类实现，子类执行的结果影响了父类的结果，也就是子类对父类产生了影响，在复杂的项目中，会带来代码阅读的难度。 使用场景 多个子类有公有的方法，且逻辑基本相同时 重要、复杂的算发，可以把核心算法设计为模板方法，周边的相关细节功能由各个子类实现 重构时，模板方法模式时一个经常使用的模式，把相同的代码抽取到父类中，然后通过钩子函数约束其行为 在Spring源码中refresh()就是典型的模板方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475public interface ConfigurableApplicationContext extends ApplicationContext, ifecycle, Closeable &#123; void refresh() throws BeansException, IllegalStateException;&#125;public abstract class AbstractApplicationContext extends DefaultResourceLoader implements ConfigurableApplicationContext &#123; @Override public void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; StartupStep contextRefresh = this.applicationStartup.start(&quot;spring.context.refresh&quot;); // Prepare this context for refreshing. prepareRefresh(); // Tell the subclass to refresh the internal bean factory. ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); StartupStep beanPostProcess = this.applicationStartup.start(&quot;spring.context.beans.post-process&quot;); // Invoke factory processors registered as beans in the context. invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. registerBeanPostProcessors(beanFactory); beanPostProcess.end(); // Initialize message source for this context. initMessageSource(); // Initialize event multicaster for this context. initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. onRefresh(); // Check for listener beans and register them. registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(&quot;Exception encountered during context initialization - &quot; + &quot;cancelling refresh attempt: &quot; + ex); &#125; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset &#x27;active&#x27; flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; finally &#123; // Reset common introspection caches in Spring&#x27;s core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); contextRefresh.end(); &#125; &#125; &#125;&#125; **JDK中HashMap、Map、AQS**中都有用到模板方法设计模式。 12345678910111213// AQS中用到的模板方法public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125;// JDK8 Map中的模板方法default V getOrDefault(Object key, V defaultValue) &#123; V v; return (((v = get(key)) != null) || containsKey(key)) ? v : defaultValue;&#125;","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"行为型模式","slug":"设计模式/行为型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"备忘录模式","date":"2016-01-04T03:30:20.000Z","path":"blog/设计模式/行为型模式/备忘录模式/","text":"备忘录模式又叫快照模式，就是一个对象的备份模式，提供了一种程序数据的备份方法。当后悔时能撤销当前操作，使数据恢复到它原先的状态。 备忘录创建出来就要在“最近”的代码中使用，要主动管理它的生命周期，建立就要使用，不使用就要立刻删除其引用。不要在频繁建立备份的场景中使用备忘录模式。 定义在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态。这样以后就可将该对象恢复到原先保存的状态。 **发起人角色Originator**：记录当前时刻的内部状态信息，提供创建备忘录和恢复备忘录数据的功能，实现其他业务功能，它可以访问备忘录里的所有信息。 123456789101112131415public class Originator &#123; private String state; public void setState(String state) &#123; this.state = state; &#125; public String getState() &#123; return state; &#125; public Memento createMemento() &#123; return new Memento(state); &#125; public void restoreMemento(Memento m) &#123; this.setState(m.getState()); &#125;&#125; **备忘录角色Memento**：负责存储发起人的内部状态，在需要的时候提供这些内部状态给发起人。 123456789101112131415public class Memento &#123; private String state; public Memento(String state) &#123; this.state = state; &#125; public void setState(String state) &#123; this.state = state; &#125; public String getState() &#123; return state; &#125;&#125; **管理者角色Caretaker**：对备忘录进行管理，提供保存与获取备忘录的功能，但其不能对备忘录的内容进行访问与修改。 123456789public class Caretaker &#123; private Memento memento; public void setMemento(Memento m) &#123; memento = m; &#125; public Memento getMemento() &#123; return memento; &#125;&#125; 客户端代码： 12345678910111213public class MementoPattern &#123; public static void main(String[] args) &#123; Originator or = new Originator(); Caretaker cr = new Caretaker(); or.setState(&quot;S0&quot;); System.out.println(&quot;初始状态:&quot; + or.getState()); cr.setMemento(or.createMemento()); //保存状态 or.setState(&quot;S1&quot;); System.out.println(&quot;新的状态:&quot; + or.getState()); or.restoreMemento(cr.getMemento()); //恢复状态 System.out.println(&quot;恢复状态:&quot; + or.getState()); &#125;&#125; 优点 提供了一种可以恢复状态的机制。当用户需要时能够比较方便地将数据恢复到某个历史的状态 实现了内部状态的封装。除了创建它的发起人之外，其他对象都不能够访问这些状态信息 发起人不需要管理和保存其内部状态的各个备份，所有状态信息都保存在备忘录中，并由管理者进行管理，符合单一职责原则 缺点 资源消耗大。如果要保存的内部状态信息过多或者特别频繁，将会占用比较大的内存资源 应用 需要保存和恢复数据的相关状态场景，游戏中的存档功能 提供一个可回滚rollback的操作，如Word、记事本、Photoshop，Eclipse 等软件在编辑时按 Ctrl+Z 组合键，还有数据库中事务操作 需要监控的副本场景中 扩展clone方式的备忘录发起人角色Originator 1234567891011121314151617181920212223class OriginatorPrototype implements Cloneable &#123; private String state; public void setState(String state) &#123; this.state = state; &#125; public String getState() &#123; return state; &#125; public OriginatorPrototype createMemento() &#123; return this.clone(); &#125; public void restoreMemento(OriginatorPrototype opt) &#123; this.setState(opt.getState()); &#125; public OriginatorPrototype clone() &#123; try &#123; return (OriginatorPrototype) super.clone(); &#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace(); &#125; return null; &#125;&#125; 管理者角色Caretaker 123456789class PrototypeCaretaker &#123; private OriginatorPrototype opt; public void setMemento(OriginatorPrototype opt) &#123; this.opt = opt; &#125; public OriginatorPrototype getMemento() &#123; return opt; &#125;&#125; 客户端代码：12345678910111213public class Client &#123; public static void main(String[] args) &#123; OriginatorPrototype or = new OriginatorPrototype(); PrototypeCaretaker cr = new PrototypeCaretaker(); or.setState(&quot;S0&quot;); System.out.println(&quot;初始状态:&quot; + or.getState()); cr.setMemento(or.createMemento()); //保存状态 or.setState(&quot;S1&quot;); System.out.println(&quot;新的状态:&quot; + or.getState()); or.restoreMemento(cr.getMemento()); //恢复状态 System.out.println(&quot;恢复状态:&quot; + or.getState()); &#125;&#125; 多状态的备忘录模式可以通过对 备忘录角色Memento 角色进行扩展，将存储状态的字段用Map来存储多个状态，从而实现多状态备忘录模式。","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"行为型模式","slug":"设计模式/行为型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"命令模式","date":"2016-01-04T02:30:20.000Z","path":"blog/设计模式/行为型模式/命令模式/","text":"命令模式是一个高内聚的模式 ，将一个请求封装成一个对象， 从而让你使用不同的请求把客户端参数化， 对请求排队或者记录请求日志， 可以提供命令的撤销和恢复功能 。 命令模式有三个角色： Receiver接收者角色：执行命令功能的相关操作，具体命令对象业务的真正实现者。 Command命令角色：需要执行的所有命令在该角色中声明，拥有执行命令的抽象方法execute()。 Invoker调用者角色：是请求发送者，通常拥有很多命令对象，并通过访问命令对象来执行相关请求，它不直接访问接收者 实现通用的Receiver类： 123456789public abstract class Receiver &#123; public abstract void find(); public abstract void add(); public abstract void delete(); public abstract void update();&#125; 接收者可以是多个，具体的Receiver类： 1234567891011121314151617public class ConcreteReceiver1 extends Receiver&#123; @Override public void find() &#123; &#125; @Override public void add() &#123; &#125; @Override public void delete() &#123; &#125; @Override public void update() &#123; &#125;&#125; 1234567891011121314151617public class ConcreteReceiver2 extends Receiver&#123; @Override public void find() &#123; &#125; @Override public void add() &#123; &#125; @Override public void delete() &#123; &#125; @Override public void update() &#123; &#125;&#125; 命令角色是命令模式的核心，抽象的Command类： 123public abstract class Command &#123; public abstract void execute();&#125; 具体的Command类，可以在实际应用中扩展该命令类，在每个命令类中，通过构造函数定义该命令是针对哪个接收者发出的，定义一个命令接收的主题，这样调用者就仅需要实现命令的传递即可： 12345678910111213141516public class ConcreteCommand1 extends Command &#123; private Receiver receiver; public ConcreteCommand1(Receiver receiver) &#123; this.receiver = receiver; &#125; @Override public void execute() &#123; this.receiver.find(); this.receiver.add(); this.receiver.delete(); this.receiver.update(); &#125;&#125; 12345678910111213141516public class ConcreteCommand2 extends Command &#123; private Receiver receiver; public ConcreteCommand2(Receiver receiver) &#123; this.receiver = receiver; &#125; @Override public void execute() &#123; this.receiver.find(); this.receiver.add(); this.receiver.delete(); this.receiver.update(); &#125;&#125; 调用者Invoker类，不管什么命令都要接收、执行： 1234567891011public class Invoker &#123; private Command command; public void setCommand(Command command) &#123; this.command = command; &#125; public void action() &#123; this.command.execute(); &#125;&#125; 场景类： 12345678910111213public class Client &#123; public static void main(String[] args) &#123; //首先声明调用者Invoker Invoker invoker = new Invoker(); //定义接收者 Receiver receiver = new ConcreteReceiver1(); //定义一个发送给接收者的命令 Command command = new ConcreteCommand1(receiver); //把命令交给调用者去执行 invoker.setCommand(command); invoker.action(); &#125;&#125; 命令模式的Receiver在实际应用中可以被封装掉，从而减少高层模块Client类对低层模块Receiver角色类的依赖关系，提高系统整体的稳定性。 123456789public abstract class Command &#123; //定义一个子类的全局共享变量 protected final Receiver receiver; //实现类必须定义一个接收者 public Command(Receiver _receiver)&#123; this.receiver = _receiver; &#125; public abstract void execute();&#125; 12345678910111213141516public class ConcreteCommand1 extends Command &#123; public ConcreteCommand1() &#123; super(new ConcreteReceiver1()); &#125; public ConcreteCommand1(Receiver receiver) &#123; super(receiver); &#125; @Override public void execute() &#123; this.receiver.find(); this.receiver.add(); this.receiver.delete(); this.receiver.update(); &#125;&#125; 优点 类间解耦：调用者角色和接收者角色之间没有任何依赖关系，调用者实现功能时只需要调用Command抽象类的execute方法即可，不需要了解到底是哪个接收者执行。 可扩展性：Command子类可以非常容易地扩展，而调用者Invoker和高层模块Client不产生严重代码耦合。 和其他模式结合会更优秀：命令模式和结合责任链模式，实现命令族解析任务；结合模板方法模式，可减少Command子类的膨胀问题。 缺点Command子类会出现膨胀问题。 应用命令模式在Spring框架**JdbcTemplate**源码的应用： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950private &lt;T&gt; T execute(StatementCallback&lt;T&gt; action, boolean closeResources) throws DataAccessException &#123; Assert.notNull(action, &quot;Callback object must not be null&quot;); Connection con = DataSourceUtils.getConnection(obtainDataSource()); Statement stmt = null; try &#123; stmt = con.createStatement(); applyStatementSettings(stmt); T result = action.doInStatement(stmt); handleWarnings(stmt); return result; &#125; catch (SQLException ex) &#123; String sql = getSql(action); JdbcUtils.closeStatement(stmt); stmt = null; DataSourceUtils.releaseConnection(con, getDataSource()); con = null; throw translateException(&quot;StatementCallback&quot;, sql, ex); &#125; finally &#123; if (closeResources) &#123; JdbcUtils.closeStatement(stmt); DataSourceUtils.releaseConnection(con, getDataSource()); &#125; &#125;&#125;public &lt;T&gt; T query(final String sql, final ResultSetExtractor&lt;T&gt; rse) throws DataAccessException &#123; Assert.notNull(sql, &quot;SQL must not be null&quot;); Assert.notNull(rse, &quot;ResultSetExtractor must not be null&quot;); if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Executing SQL query [&quot; + sql + &quot;]&quot;); &#125; class QueryStatementCallback implements StatementCallback&lt;T&gt;, SqlProvider &#123; @Override @Nullable public T doInStatement(Statement stmt) throws SQLException &#123; ResultSet rs = null; try &#123; rs = stmt.executeQuery(sql); return rse.extractData(rs); &#125; finally &#123; JdbcUtils.closeResultSet(rs); &#125; &#125; @Override public String getSql() &#123; return sql; &#125; &#125; return execute(new QueryStatementCallback(), true);&#125; StatementCallback接口，类似Command命令接口，QueryStatementCallback匿名内部类，实现了命令接口，同时也充当命令接收者；命令调用者是 JdbcTemplate，不同的实现StatementCallback接口的对象，对应不同的doInStatement实现逻辑； 扩展实现在没有执行或执行后撤回，有两种方法可以解决，一是结合备忘录模式还原最后状态，该方法适合接收者为状态的变更情况，而不适合事件处理；二是通过增加一个新的命令，实现事件的回滚。","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"行为型模式","slug":"设计模式/行为型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"适配器模式","date":"2016-01-03T05:30:20.000Z","path":"blog/设计模式/结构型模式/适配器模式/","text":"适配器模式是一个补偿模式，通常用来解决接口不相容的问题 ，又叫变压器模式，也叫包装模式。 适配器模式最好在详细设计阶段不要考虑它，它不是为了解决还处在开发阶段的问题，而是解决正在服役的项目问题，该模式使用的主要场景是扩展应用。 定义将一个类的接口变换成客户端所期待的另一种接口，从而使原本因接口不匹配儿无法再一起工作的两个类能够在一起工作。 实现适配器模式分为类结构型模式和对象结构型模式两种，前者类之间的耦合度比后者高，且要求了解现有组件库中的相关组件的内部结构。类结构型模式:对象结构型模式: Target目标接口，当前系统业务所期待的接口，它可以是抽象类或接口。 123public interface Target &#123; void request();&#125; Adaptee适配者类，它是被访问和适配的现存组件库中的组件接口。 12345public class Adaptee &#123; public void specificRequest() &#123; System.out.println(&quot;适配者中的业务代码被调用！&quot;); &#125;&#125; Adapter适配器类，它是一个转换器，通过继承或引用适配者的对象，把适配者接口转换成目标接口，让客户按目标接口的格式访问适配者。 通过继承进行的适配， 叫做类适配器 。 1234567891011public class ClassAdapter extends Adaptee implements Target &#123; @Override public void request() &#123; super.specificRequest(); &#125;&#125;public static void main(String[] args) &#123; Target target = new ClassAdapter(); target.request();&#125; 通过关联关系进行的适配，叫做对象适配器。可釆用将现有组件库中已经实现的组件引入适配器类中，该类同时实现当前系统的业务接口。 1234567891011121314151617public class ObjectAdapter implements Target &#123; private Adaptee adaptee; public ObjectAdapter(Adaptee adaptee) &#123; this.adaptee = adaptee; &#125; @Override public void request() &#123; adaptee.specificRequest(); &#125;&#125;public static void main(String[] args) &#123; Adaptee adaptee = new Adaptee(); Target target = new ObjectAdapter(adaptee); target.request();&#125; 对象适配器和类适配器的区别是：类适配器是类间继承，对象适配器是对象的组合关系，对象适配器是通过类间的关联关系进行耦合的，因此在设计时就可以做到比较灵活；而类适配器就只能通过覆写源角色的方法进行扩展。 优点 可以让两个没有任何关系的类在一起运行 增加了类的透明性，客户端通过适配器可以透明地调用目标接口 提高了类的复用度，复用了现存的类，不需要修改原有代码而重用现有的适配者类 将目标类和适配者类解耦，解决了目标类和适配者类接口不一致的问题 灵活性非常好 缺点 适配器编写过程需要结合业务场景全面考虑，可能会增加系统的复杂性 增加代码阅读难度，降低代码可读性，过多使用适配器会使系统代码变得凌乱 应用场景在Spring AOP源码中适配器模式应用非常广泛，Advice就是来增强被代理类的功能，Advice 的类型主要有 BeforeAdvice、AfterReturningAdvice、ThrowsAdvice。 1234567891011public interface Advice &#123;&#125;public interface AfterAdvice extends Advice &#123;&#125;public interface BeforeAdvice extends Advice &#123;&#125;public interface ThrowsAdvice extends AfterAdvice &#123;&#125; 每种Advice都有对应的拦截器，即MethodBeforeAdviceInterceptor、AfterReturningAdviceInterceptor、ThrowsAdviceInterceptor，不同类型的Interceptor，通过适配器统一对外提供接口，最终调用不同的 advice来实现被代理类的增强。 12345678910111213141516171819202122232425262728293031323334353637383940public interface Interceptor extends Advice &#123;&#125;public interface MethodInterceptor extends Interceptor &#123; @Nullable Object invoke(@Nonnull MethodInvocation invocation) throws Throwable;&#125;public class AfterReturningAdviceInterceptor implements MethodInterceptor, AfterAdvice, Serializable &#123; private final AfterReturningAdvice advice; public AfterReturningAdviceInterceptor(AfterReturningAdvice advice) &#123; Assert.notNull(advice, &quot;Advice must not be null&quot;); this.advice = advice; &#125; @Override @Nullable public Object invoke(MethodInvocation mi) throws Throwable &#123; Object retVal = mi.proceed(); this.advice.afterReturning(retVal, mi.getMethod(), mi.getArguments(), mi.getThis()); return retVal; &#125;&#125;public class MethodBeforeAdviceInterceptor implements MethodInterceptor, BeforeAdvice, Serializable &#123; private final MethodBeforeAdvice advice; public MethodBeforeAdviceInterceptor(MethodBeforeAdvice advice) &#123; Assert.notNull(advice, &quot;Advice must not be null&quot;); this.advice = advice; &#125; @Override @Nullable public Object invoke(MethodInvocation mi) throws Throwable &#123; this.advice.before(mi.getMethod(), mi.getArguments(), mi.getThis()); return mi.proceed(); &#125;&#125; Spring AOP的AdvisorAdapter类有 4 个实现类，即 SimpleBeforeAdviceAdapter、MethodBeforeAdviceAdapter、AfterReturningAdviceAdapter、ThrowsAdviceAdapter； 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public interface AdvisorAdapter &#123; boolean supportsAdvice(Advice advice); MethodInterceptor getInterceptor(Advisor advisor);&#125;class AfterReturningAdviceAdapter implements AdvisorAdapter, Serializable &#123; @Override public boolean supportsAdvice(Advice advice) &#123; return (advice instanceof AfterReturningAdvice); &#125; @Override public MethodInterceptor getInterceptor(Advisor advisor) &#123; AfterReturningAdvice advice = (AfterReturningAdvice) advisor.getAdvice(); return new AfterReturningAdviceInterceptor(advice); &#125;&#125;public class MethodBeforeAdviceInterceptor implements MethodInterceptor, BeforeAdvice, Serializable &#123; private final MethodBeforeAdvice advice; public MethodBeforeAdviceInterceptor(MethodBeforeAdvice advice) &#123; Assert.notNull(advice, &quot;Advice must not be null&quot;); this.advice = advice; &#125; @Override @Nullable public Object invoke(MethodInvocation mi) throws Throwable &#123; this.advice.before(mi.getMethod(), mi.getArguments(), mi.getThis()); return mi.proceed(); &#125;&#125;class SimpleBeforeAdviceAdapter implements AdvisorAdapter, Serializable &#123; @Override public boolean supportsAdvice(Advice advice) &#123; return (advice instanceof SimpleBeforeAdvice); &#125; @Override public MethodInterceptor getInterceptor(Advisor advisor) &#123; SimpleBeforeAdvice advice = (SimpleBeforeAdvice) advisor.getAdvice(); return new SimpleBeforeAdviceInterceptor(advice) ; &#125;&#125;class ThrowsAdviceAdapter implements AdvisorAdapter, Serializable &#123; @Override public boolean supportsAdvice(Advice advice) &#123; return (advice instanceof ThrowsAdvice); &#125; @Override public MethodInterceptor getInterceptor(Advisor advisor) &#123; return new ThrowsAdviceInterceptor(advisor.getAdvice()); &#125;&#125; 适配器模式在Spring MVC中的经典使用： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public interface HandlerAdapter &#123; boolean supports(Object handler); @Nullable ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception; long getLastModified(HttpServletRequest request, Object handler);&#125;public class SimpleServletHandlerAdapter implements HandlerAdapter &#123; @Override public boolean supports(Object handler) &#123; return (handler instanceof Servlet); &#125; @Override @Nullable public ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; ((Servlet) handler).service(request, response); return null; &#125; @Override public long getLastModified(HttpServletRequest request, Object handler) &#123; return -1; &#125;&#125;public class HttpRequestHandlerAdapter implements HandlerAdapter &#123; @Override public boolean supports(Object handler) &#123; return (handler instanceof HttpRequestHandler); &#125; @Override @Nullable public ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; ((HttpRequestHandler) handler).handleRequest(request, response); return null; &#125; @Override public long getLastModified(HttpServletRequest request, Object handler) &#123; if (handler instanceof LastModified) &#123; return ((LastModified) handler).getLastModified(request); &#125; return -1L; &#125;&#125; MVC中体现在它的核心方法doDispatch方法中： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; boolean multipartRequestParsed = false; WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); try &#123; ModelAndView mv = null; Exception dispatchException = null; try &#123; processedRequest = checkMultipart(request); multipartRequestParsed = (processedRequest != request); // Determine handler for the current request. mappedHandler = getHandler(processedRequest); if (mappedHandler == null) &#123; noHandlerFound(processedRequest, response); return; &#125; // Determine handler adapter for the current request. HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler()); // Process last-modified header, if supported by the handler. String method = request.getMethod(); boolean isGet = &quot;GET&quot;.equals(method); if (isGet || &quot;HEAD&quot;.equals(method)) &#123; long lastModified = ha.getLastModified(request, mappedHandler.getHandler()); if (new ServletWebRequest(request, response).checkNotModified(lastModified) &amp;&amp; isGet) &#123; return; &#125; &#125; if (!mappedHandler.applyPreHandle(processedRequest, response)) &#123; return; &#125; // Actually invoke the handler. mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); if (asyncManager.isConcurrentHandlingStarted()) &#123; return; &#125; applyDefaultViewName(processedRequest, mv); mappedHandler.applyPostHandle(processedRequest, response, mv); &#125; catch (Exception ex) &#123; dispatchException = ex; &#125; catch (Throwable err) &#123; // As of 4.3, we&#x27;re processing Errors thrown from handler methods as well, // making them available for @ExceptionHandler methods and other scenarios. dispatchException = new NestedServletException(&quot;Handler dispatch failed&quot;, err); &#125; processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException); &#125; catch (Exception ex) &#123; triggerAfterCompletion(processedRequest, response, mappedHandler, ex); &#125; catch (Throwable err) &#123; triggerAfterCompletion(processedRequest, response, mappedHandler, new NestedServletException(&quot;Handler processing failed&quot;, err)); &#125; finally &#123; if (asyncManager.isConcurrentHandlingStarted()) &#123; // Instead of postHandle and afterCompletion if (mappedHandler != null) &#123; mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response); &#125; &#125; else &#123; // Clean up any resources used by a multipart request. if (multipartRequestParsed) &#123; cleanupMultipart(processedRequest); &#125; &#125; &#125;&#125; 在doDispatch()方法中调用了getHandlerAdapter()方法，在getHandlerAdapter()方法中循环调用supports()方法来判断是否兼容，循环迭代集合中的Adapter在初始化时早已被赋值。 1234567891011protected HandlerAdapter getHandlerAdapter(Object handler) throws ServletException &#123; if (this.handlerAdapters != null) &#123; for (HandlerAdapter adapter : this.handlerAdapters) &#123; if (adapter.supports(handler)) &#123; return adapter; &#125; &#125; &#125; throw new ServletException(&quot;No adapter for handler [&quot; + handler + &quot;]: The DispatcherServlet configuration needs to include a HandlerAdapter that supports this handler&quot;);&#125;","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"结构型模式","slug":"设计模式/结构型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E7%BB%93%E6%9E%84%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"装饰模式","date":"2016-01-03T04:30:20.000Z","path":"blog/设计模式/结构型模式/装饰模式/","text":"动态地给一个对象添加一些额外的职责。就增加功能来说，装饰模式相比生成子类更为灵活。是对继承的有力补充。 扩展一个类的功能会使用继承方式来实现。但继承具有静态特征，耦合度高，并且随着扩展功能的增多，子类会很膨胀。装饰器模式的目标是使用组合关系来创建一个装饰对象来包裹真实对象，并在保持真实对象的类结构不变的前提下，为其提供额外的功能。 实现抽象构件角色：定义一个抽象接口以规范准备接收附加责任的对象。 123public interface Component &#123; void operation();&#125; 具体构件角色：实现抽象构件，通过装饰角色为其添加一些职责。 123456public class ConcreteComponent implements Component &#123; @Override public void operation() &#123; System.out.println(&quot;ConcreteComponent operation&quot;); &#125;&#125; 抽象装饰角色：继承抽象构件，并包含具体构件的实例，可以通过其子类扩展具体构件的功能。 123456789101112public abstract class Decorator implements Component &#123; private Component component; public Decorator(Component component) &#123; this.component = component; &#125; @Override public void operation() &#123; this.component.operation(); &#125;&#125; 具体装饰角色：实现抽象装饰的相关方法，并给具体构件对象添加附加的责任。 123456789101112public class ConcreteDecorator extends Decorator &#123; public ConcreteDecorator(Component component) &#123; super(component); &#125; public void operation() &#123; super.operation(); addedFunction(); &#125; public void addedFunction() &#123; System.out.println(&quot;为具体构件角色增加额外的功能addedFunction()&quot;); &#125;&#125; 场景类 123456public static void main(String[] args) &#123; Component p = new ConcreteComponent(); p.operation(); Component d = new ConcreteDecorator(p); d.operation();&#125; 若只有一个具体构件而没有抽象构件时，可以让抽象装饰继承具体构件。若只有一个具体装饰时，可以将抽象装饰和具体装饰合并。 优点 装饰类和被装饰类可以独立发展， 而不会相互耦合； 装饰模式是继承关系的一个替代方案； 装饰模式可以动态地扩展一个实现类的功能； 缺点装饰器模式会增加许多子类，过度使用会增加程序得复杂性，尽量减少装饰类的数量， 以便降低系统的复杂度。 应用场景 需要扩展一个类的功能， 或给一个类增加附加功能，而又不能采用生成子类的方法进行扩充时； 需要动态地给一个对象增加功能， 这些功能可以再动态地撤销； 当需要通过对现有的一组基本功能进行排列组合而产生非常多的功能时，采用继承关系很难实现； Java I/O 标准库的设计，InputStream的子类FilterInputStream，OutputStream的子类FilterOutputStream，Reader的子类BufferedReader以及FilterReader，还有Writer的子类BufferedWriter、FilterWriter以及 PrintWriter等，它们都是抽象装饰类。 12BufferedReader in = new BufferedReader(new FileReader(&quot;filename.txt&quot;));String s = in.readLine();","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"结构型模式","slug":"设计模式/结构型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E7%BB%93%E6%9E%84%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"组合模式","date":"2016-01-03T03:30:20.000Z","path":"blog/设计模式/结构型模式/组合模式/","text":"组合模式也叫合成模式，有时又叫部分整体模式，主要是用来描述部分与整体的关系； 只要是树形结构， 就要考虑使用组合模式， 只要是要体现局部和整体的关系的时候， 而且这种关系还可能比较深， 考虑使用组合模式。 定义将对象组合成树形结构以表示部分—整体的层次结构，使得用户对单个对象和组合对象的使用具有一致性。 实现组合模式一般用来描述整体与部分的关系，它将对象组织到树形结构中，顶层的节点被称为根节点，根节点下面可以包含树枝节点和叶子节点，树枝节点下面又可以包含树枝节点和叶子节点。 组合模式分为透明式的组合模式和安全式的组合模式。 透明式的组合模式中，抽象构件声明了所有子类中的全部方法，所以客户端无须区别树叶对象和树枝对象，对客户端来说是透明的。 缺点是树叶构件本来没有 add()、remove()、getChild() 方法，却要实现它们，空实现或抛异常，会带来一些安全性问题。 Component抽象构件角色，其主要作用是为树叶构件和树枝构件声明公共接口，并实现它们的默认行为。在透明式的组合模式中抽象构件还声明访问和管理子类的接口；在安全式的组合模式中不声明访问和管理子类的接口，管理工作由树枝构件完成。 123456789public interface Component &#123; void add(Component c); void remove(Component c); Component getChild(int i); void operation();&#125; Leaf树叶构件角色，是组合中的叶节点对象，它没有子节点，用于继承或实现抽象构件。 12345678910111213141516public class Leaf implements Component &#123; private String name; public Leaf(String name) &#123; this.name = name; &#125; public void add(Component c) &#123; &#125; public void remove(Component c) &#123; &#125; public Component getChild(int i) &#123; return null; &#125; public void operation() &#123; System.out.println(&quot;树叶&quot; + name + &quot;：被访问！&quot;); &#125;&#125; Composite树枝构件角色 &#x2F; 中间构件，是组合中的分支节点对象，它有子节点，用于继承和实现抽象构件。它的主要作用是存储和管理子部件，通常包含 add()、remove()、getChild() 等方法。 123456789101112131415161718192021public class Composite implements Component &#123; private ArrayList&lt;Component&gt; children = new ArrayList&lt;&gt;(); public void add(Component c) &#123; children.add(c); &#125; public void remove(Component c) &#123; children.remove(c); &#125; public Component getChild(int i) &#123; return children.get(i); &#125; public void operation() &#123; for (Object obj : children) &#123; ((Component) obj).operation(); &#125; &#125;&#125; 客户端使用： 123456789101112public static void main(String[] args) &#123; Component c0 = new Composite(); Component c1 = new Composite(); Component leaf1 = new Leaf(&quot;1&quot;); Component leaf2 = new Leaf(&quot;2&quot;); Component leaf3 = new Leaf(&quot;3&quot;); c0.add(leaf1); c0.add(c1); c1.add(leaf2); c1.add(leaf3); c0.operation();&#125; 安全式的组合模式中，将管理子构件的方法移到树枝构件中，抽象构件和树叶构件没有对子对象的管理方法，这样就避免了上一种方式的安全性问题，但由于叶子和分支有不同的接口，客户端在调用时要知道树叶对象和树枝对象的存在，所以失去了透明性。 安全式的组合模式与透明式组合模式的实现代码类似，只要对其做简单修改就可以了： 12345678910111213141516public interface Component &#123; void operation();&#125;public static void main(String[] args) &#123; Composite c0 = new Composite(); Composite c1 = new Composite(); Component leaf1 = new Leaf(&quot;1&quot;); Component leaf2 = new Leaf(&quot;2&quot;); Component leaf3 = new Leaf(&quot;3&quot;); c0.add(leaf1); c0.add(c1); c1.add(leaf2); c1.add(leaf3); c0.operation();&#125; 优点 简化客户端代码，使客户端代码可一致地处理单个对象和组合对象，无须关心处理的是单个对象，还是组合对象 更容易在组合体内加入新的对象，客户端不会因为加入了新的对象而更改源代码，满足开闭原则 缺点 设计较复杂，客户端需要花更多时间理清类之间的层次关系 不容易限制容器中的构件 容易用继承的方法来增加构件的新功能 应用在需要表示一个对象整体与部分的层次结构的场合；要求对用户隐藏组合对象与单个对象的不同，用户可以用统一的接口使用组合结构中的所有对象的场合；","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"结构型模式","slug":"设计模式/结构型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E7%BB%93%E6%9E%84%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"代理模式","date":"2016-01-03T03:00:20.000Z","path":"blog/设计模式/结构型模式/代理模式/","text":"由于某些原因需要给某对象提供一个代理以控制对该对象的访问。访问对象不适合或者不能直接引用目标对象，代理对象作为访问对象和目标对象之间的中介。 代理模式是一个使用率非常高的模式，为其他对象提供一种代理以控制这个对象的访问。代理模式也叫做委托模式，它是一项基本设计技巧。许多其他的模式，如状态模式、策略模式、访问者模式本质上是在更特殊的场合采用了委托模式，而且在日常的应用中，代理模式可以提供非常好的访问控制。 代理模式的结构比较简单，主要是通过定义一个继承抽象主题的代理来包含真实主题，从而实现对真实主题的访问； 抽象主题类**Subject通过接口或抽象类声明真实主题和代理对象**实现的业务方法： 123public interface Subject &#123; void request();&#125; 真实主题类RealSubject实现了抽象主题中的具体业务，是代理对象所代表的真实对象，是最终要引用的对象，为具体主题角色，也叫被委托角色或被代理角色，是业务逻辑的具体执行者： 123456public class RealSubject implements Subject &#123; @Override public void request() &#123; // 业务逻辑处理 &#125;&#125; 代理类Proxy提供了与真实主题相同的接口，其内部含有对真实主题的引用，它可以访问、控制或扩展真实主题的功能，也叫委托类或代理类： 1234567891011121314public class Proxy implements Subject &#123; private Subject subject; public Proxy(Subject subject) &#123; this.subject = subject; &#125; @Override public void request() &#123; this.before(); this.subject.request(); this.after(); &#125; private void before() &#123;&#125; private void after() &#123;&#125;&#125; 一般代理会被理解为代码增强，实际上就是在原代码逻辑前后增加一些代码逻辑，而使调用者无感知；一个代理类可以代理多个被委托者或被代理者， 因此一个代理类具体代理哪个真实主题角色， 是由场景类决定。 代理模式优点职责清晰，真实的角色就是实现实际的业务逻辑，不用关心其他非本职责的事务；高扩展性；智能化。 根据代理的创建时期，代理模式分为静态代理和动态代理，还可以通过反射的方式实现动态代理 优点 在客户端与目标对象之间起到一个中介作用和保护目标对象的作用 可以扩展目标对象的功能 能将客户端与目标对象分离，在一定程度上降低了系统的耦合度，增加了程序的可扩展性 缺点 会造成系统设计中类的数量增加 在客户端和目标对象之间增加一个代理对象，会造成请求处理速度变慢 增加了系统的复杂度 应用场景当无法或不想直接引用某个对象或访问某个对象存在困难时，可以通过代理对象来间接访问。使用代理模式主要有两个目的：保护目标对象，增强目标对象。 远程代理，通常是为了隐藏目标对象存在于不同地址空间的事实，方便客户端访问。 虚拟代理，通常用于要创建的目标对象开销很大时。 安全代理，通常用于控制不同种类客户对真实对象的访问权限。 智能指引，主要用于调用目标对象时，代理附加一些额外的处理功能。 延迟加载，指为了提高系统的性能，延迟对目标的加载。","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"结构型模式","slug":"设计模式/结构型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E7%BB%93%E6%9E%84%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"外观模式","date":"2016-01-03T02:00:20.000Z","path":"blog/设计模式/结构型模式/外观模式/","text":"外观模式也叫门面模式，注重统一的对象，是一种通过为多个复杂的子系统提供一个一致的接口，而使这些子系统更加容易被访问的模式。 该模式对外有一个统一接口，外部应用程序不用关心内部子系统的具体细节，这样会大大降低应用程序的复杂度，提高了程序的可维护性。 除了这个接口不允许有任何访问子系统的行为发生，是外界访问子系统内部的唯一通道，是一种比较常用的封装模式。 一般情况下，一个子系统只要一个门面，但若门面已经庞大到不能忍受的程度，可拆分成多个门面；需要子系统可以提供不同访问路径的情况，也可提供多个门面。 门面不参与子系统的业务逻辑，否则会产生倒依赖问题，子系统必须依赖门面才能被访问，违反了单一职责原则，同时也破坏了系统的封装性。 定义要求一个子系统的外部与其内部的通信必须通过一个统一的对象进行，外观模式提供一个高层次的接口，使得子系统更易于使用。 实现 **外观角色Facade**：为多个子系统对外提供一个共同的接口。 1234567891011public class Facade &#123; private SubSystem01 obj1 = new SubSystem01(); private SubSystem02 obj2 = new SubSystem02(); private SubSystem03 obj3 = new SubSystem03(); public void method() &#123; obj1.method1(); obj2.method2(); obj3.method3(); &#125;&#125; **子系统角色SubSystem**：实现系统的部分功能，客户可以通过外观角色访问它。 1234567891011121314151617public class SubSystem01 &#123; public void method1() &#123; System.out.println(&quot;子系统01的method1()被调用&quot;); &#125;&#125;public class SubSystem02 &#123; public void method2() &#123; System.out.println(&quot;子系统02的method2()被调用&quot;); &#125;&#125;public class SubSystem03 &#123; public void method3() &#123; System.out.println(&quot;子系统03的method3()被调用&quot;); &#125;&#125; **客户角色Client**：通过一个外观角色访问各个子系统的功能。 1234public static void main(String[] args) &#123; Facade facade = new Facade(); facade.method();&#125; 优点 减少了系统的相互依赖，所有的依赖都是对门面对象的依赖，与子系统无关，降低了子系统与客户端之间的耦合度 对客户屏蔽了子系统组件，减少了客户处理的对象数目，并使得子系统使用起来更加容易。 提高了灵活性，不管子系统内部如何变化，只要不影响到门面对象，可随意修改 提高了安全性，不在门面上开通的方法不能访问 缺点 不符合开闭原则，增加新的子系统可能需要修改外观类或客户端的源代码 应用场景 为一个复杂的模块或子系统提供一个供外界访问的接口 子系统相对独立，外界对子系统的访问只要黑箱操作即可，如利息计算问题 预防低水平人员带来的风险扩散 对分层结构系统构建时，使用外观模式定义子系统中每层的入口点可以简化子系统之间的依赖关系 当客户端与多个子系统之间存在很大的联系时，引入外观模式可将它们分离，从而提高子系统的独立性和可移植性。 使用外观模式整合已有的API","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"结构型模式","slug":"设计模式/结构型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E7%BB%93%E6%9E%84%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"建造者模式","date":"2016-01-02T09:08:20.000Z","path":"blog/设计模式/创建型模式/建造者模式/","text":"建造者模式也叫生成器模式，将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。当一个类的构造函数参数个数超过4个，而且这些参数有些是可选的参数，考虑使用构造者模式。 车辆模型抽象类： 1234567891011121314151617181920212223public abstract class CarModel &#123; private List&lt;String&gt; sequence = new ArrayList&lt;&gt;(); protected abstract void start(); protected abstract void stop(); protected abstract void alarm(); protected abstract void engineBoom(); public final void setSequence(List&lt;String&gt; sequence) &#123; this.sequence = sequence; &#125; public final void run() &#123; for (String actionName : sequence) &#123; if (&quot;start&quot;.equals(actionName)) &#123; this.start(); &#125; else if (&quot;stop&quot;.equals(actionName)) &#123; this.stop(); &#125; else if (&quot;alarm&quot;.equals(actionName)) &#123; this.alarm(); &#125; else if (&quot;engineBoom&quot;.equals(actionName)) &#123; this.engineBoom(); &#125; &#125; &#125;&#125; 车辆模型的具体代码： 12345678910111213141516171819202122232425262728293031323334353637public class BenzModel extends CarModel &#123; @Override protected void start() &#123; System.out.println(&quot;Benz开动&quot;); &#125; @Override protected void stop() &#123; System.out.println(&quot;Benz停车&quot;); &#125; @Override protected void alarm() &#123; System.out.println(&quot;Benz鸣笛&quot;); &#125; @Override protected void engineBoom() &#123; System.out.println(&quot;Benz发动引擎&quot;); &#125;&#125;public class BMWModel extends CarModel &#123; @Override protected void start() &#123; System.out.println(&quot;BMW开动&quot;); &#125; @Override protected void stop() &#123; System.out.println(&quot;BMW停车&quot;); &#125; @Override protected void alarm() &#123; System.out.println(&quot;BMW鸣笛&quot;); &#125; @Override protected void engineBoom() &#123; System.out.println(&quot;BMW发动引擎&quot;); &#125;&#125; 抽象汽车的组装者： 1234public abstract class CarBuilder &#123; public abstract void setSequence(List&lt;String&gt; seqence); public abstract CarModel getCarModel();&#125; 具体的车的组装者： 1234567891011121314151617181920212223public class BenzBuilder extends CarBuilder &#123; private BenzModel benz = new BenzModel(); @Override public void setSequence(List&lt;String&gt; sequence) &#123; this.benz.setSequence(sequence); &#125; @Override public CarModel getCarModel() &#123; return this.benz; &#125;&#125;public class BMWBuilder extends CarBuilder &#123; private BMWModel bmw = new BMWModel(); @Override public void setSequence(List&lt;String&gt; sequence) &#123; this.bmw.setSequence(sequence); &#125; @Override public CarModel getCarModel() &#123; return this.bmw; &#125;&#125; 场景类的调用： 123456789101112List&lt;String&gt; sequence = new ArrayList&lt;&gt;();sequence.add(&quot;engineBoom&quot;);sequence.add(&quot;start&quot;);sequence.add(&quot;stop&quot;);BenzBuilder benzBuilder = new BenzBuilder();benzBuilder.setSequence(sequence);BenzModel benz = (BenzModel)benzBuilder.getCarModel();benz.run();BMWBuilder bmwBuilder = new BMWBuilder();bmwBuilder.setSequence(sequence);BMWModel bmw = (BMWModel)bmwBuilder.getCarModel();bmw.run(); CarModel及其之类都是产品类，CarBuilder是抽象的建造者，用于规范产品的组建，其子类是具体的建造者，实现抽象类定义的所有，并返回一个组建好的对象。 建造者模式有良好的封装性，使用建造者模式可以使客户端不必知道产品内部组成的细节，建造者是独立的容易扩展，因此也便于控制细节风险，对建造过程逐步细化，而不对其他的模式产生任何影响。 使用场景 相同的方法，不同的执行顺序，产生不同的事件结果时。 多个部件或零件，都可以装配到一个对象中，但是产生的运行结果又不相同时。 产品类非常复杂，或者产品类中的调用顺序不同产生了不同的效能。 在对象创建过程中会使用到系统中的一些其他对象，这些对象在产品对象的创建过程中不易得到时，也可以采用建造者模式封装该对象的创建过程，该种场景只能是一个补偿方法。 与工厂模式的区别建造者模式最主要的功能是基本方法的调用顺序安排，也就是这些基本方法已经实现了，通俗地说就是零件的装配，顺序不同产生的对象也不同；而工厂方法则重点是创建，创建零件是它的主要职责，组装顺序则不是它关心的。","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"创建型模式","slug":"设计模式/创建型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E5%88%9B%E5%BB%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"工厂模式","date":"2016-01-02T08:08:20.000Z","path":"blog/设计模式/创建型模式/工厂模式/","text":"工厂方法模式工厂方法模式使用的频率非常高 ，用于创建对象的接口， 让子类决定实例化哪一个类。 工厂方法使一个类的实例化延迟到其子类 。用于封装和管理对象的创建，是一种创建模式。是典型的解耦框架，在需要灵活的、可扩展的框架时可以采用，可以用在异构项目中，可以使用在测试驱动的开发框架下。抽象产品类，抽象人种类： 1234public interface Human &#123; void getColor(); void talk();&#125; 具体的产品类可以有多个， 都继承于抽象产品类，具体的人种类： 1234567891011public class BlackHuman implements Human &#123; @Override public void getColor() &#123; System.out.println(&quot;黑色人种&quot;); &#125; @Override public void talk() &#123; System.out.println(&quot;我是黑色人种&quot;); &#125;&#125; 1234567891011public class WhiteHuman implements Human &#123; @Override public void getColor() &#123; System.out.println(&quot;白色人种&quot;); &#125; @Override public void talk() &#123; System.out.println(&quot;我是白色人种&quot;); &#125;&#125; 1234567891011public class YellowHuman implements Human &#123; @Override public void getColor() &#123; System.out.println(&quot;黄色人种&quot;); &#125; @Override public void talk() &#123; System.out.println(&quot;我是黄色人种&quot;); &#125;&#125; 抽象工厂类负责定义产品对象的产生： 123public abstract class AbstractHumanFactory &#123; public abstract &lt;T extends Human&gt; T createHuman(Class&lt;T&gt; clazz);&#125; 具体如何产生一个产品的对象， 是由具体的工厂类实现的，具体的工厂类： 1234567891011public class HumanFactory extends AbstractHumanFactory &#123; @Override public &lt;T extends Human&gt; T createHuman(Class&lt;T&gt; clazz) &#123; try &#123; return (T) Class.forName(clazz.getName()).newInstance(); &#125; catch (Exception e) &#123; System.out.println(&quot;人种生成错误&quot;); &#125; return null; &#125;&#125; 场景类的调用: 12345678910AbstractHumanFactory TaoLiu = new HumanFactory();Human whiteHuman = TaoLiu.createHuman(WhiteHuman.class);whiteHuman.getColor();whiteHuman.talk();Human blackHuman = TaoLiu.createHuman(BlackHuman.class);blackHuman.getColor();blackHuman.talk();Human yellowHuman = TaoLiu.createHuman(YellowHuman.class);yellowHuman.getColor();yellowHuman.talk(); 优点 良好的封装性， 代码结构清晰 良好的扩展性，增加产品类， 只要适当地修改具体的工厂类或扩展一个工厂类 屏蔽产品类，产品类的实现如何变化， 调用者都不需要关心，上层模块不发生变化 典型的解耦框架，高层模块值需要知道产品的抽象类，符合迪米特法则、依赖倒置原则、里氏替换原则 使用场景 需要生成对象的地方都可以使用， 但是需要慎重考虑是否要增加一个工厂类进行管理， 增加代码的复杂度 需要灵活的、 可扩展的框架时 异构项目中，如通过WebService与一个非Java的项目交互 可以使用在测试驱动开发的框架下 扩展工厂方法模式有很多扩展，且与其他模式结合使用威力更大，可将其缩小为简单工厂模式，可升级为多个工厂类，可替代单例模式，可延迟初始化。 缩小为简单工厂模式该模式是工厂方法模式的弱化，简单工厂模式又叫静态工厂模式，仅简单的对不同类对象的创建进行了简单的封装。缺点是工厂类的扩展比较困难， 不符合开闭原则。 简单工厂模式相对于工厂方法模式，去掉了AbstractHumanFactory抽象类， 同时把createHuman方法设置为静态类型， 简化了类的创建过程。 12345678910public class HumanFactory &#123; public static &lt;T extends Human&gt; T createHuman(Class&lt;T&gt; clazz) &#123; try &#123; return (T) Class.forName(clazz.getName()).newInstance(); &#125; catch (Exception e) &#123; System.out.println(&quot;人种生成错误&quot;); &#125; return null; &#125;&#125; 场景类的调用: 123456789Human whiteHuman = HumanFactory.createHuman(WhiteHuman.class);whiteHuman.getColor();whiteHuman.talk();Human blackHuman = HumanFactory.createHuman(BlackHuman.class);blackHuman.getColor();blackHuman.talk();Human yellowHuman = HumanFactory.createHuman(YellowHuman.class);yellowHuman.getColor();yellowHuman.talk(); 升级为多个工厂类在相对比较复杂的项目中，经常遇到初始化一个对象很耗费精力的情况，所有产品类都放到一个工厂方法中进行初始化会使代码结构不清晰。为每个产品定义一个创造者， 然后由调用者自己去选择与哪个工厂方法关联。 多工厂模式的工厂抽象类，抽象方法中已经不再需要传递相关参数了， 因为每一个具体的工厂都已经非常明确自己的职责。但也给可扩展性和可维护性带来了一定的影响。 多工厂模式的抽象工厂类： 123public abstract class AbstractHumanFactory &#123; public abstract Human createHuman();&#125; 黑色人种的创建工厂实现： 12345public class BlackHumanFactory extends AbstractHumanFactory &#123; public Human createHuman() &#123; return new BlackHuman(); &#125;&#125; 黄色人种的创建工厂实现： 12345public class YellowHumanFactory extends AbstractHumanFactory &#123; public Human createHuman() &#123; return new BlackHuman(); &#125;&#125; 白色人种的创建工厂实现： 12345public class WhiteHumanFactory extends AbstractHumanFactory &#123; public Human createHuman() &#123; return new BlackHuman(); &#125;&#125; 场景类的调用: 123456789Human whiteHuman = (new WhiteHumanFactory()).createHuman();whiteHuman.getColor();whiteHuman.talk();Human blackHuman = (new BlackHumanFactory()).createHuman();blackHuman.getColor();blackHuman.talk();Human yellowHuman = (new YellowHumanFactory()).createHuman();yellowHuman.getColor();yellowHuman.talk(); 在复杂的应用中一般采用多工厂的方法， 然后再增加一个协调类， 避免调用者与各个子工厂交流， 协调类的作用是封装子工厂类， 对高层模块提供统一的访问接口。 替代单例模式通过获得类构造器， 然后设置访问权限， 生成一个对象， 然后提供外部访问， 保证内存中的对象唯一。 通过工厂方法模式创建了一个单例对象， 该框架可以继续扩展， 在一个项目中可以产生一个单例构造器， 所有需要产生单例的类都遵循一定的规则 ， 然后通过扩展该框架。 12345678910111213141516171819202122232425public class Singleton &#123; private Singleton() &#123;&#125; public void doSomething() &#123;&#125;&#125;public class SingletonFactory &#123; private static Singleton singleton; static&#123; try &#123; Class cl= Class.forName(Singleton.class.getName()); // 获得无参构造 Constructor constructor = cl.getDeclaredConstructor(); // 设置无参构造是可访问的 constructor.setAccessible(true); // 产生一个实例对象 singleton = (Singleton)constructor.newInstance(); &#125; catch (Exception e) &#123; // 异常处理 &#125; &#125; public static Singleton getSingleton()&#123; return singleton; &#125;&#125; 延迟初始化一个对象被消费完后，并不立即释放，工厂类保持其初始状态，等待再次被调用。 12345678910111213141516171819public class ProductFactory &#123; private static final Map&lt;String, Human&gt; humanMap = new HashMap&lt;&gt;(); public static synchronized Human createHuman(String type) throws Exception &#123; Human human; if (humanMap.containsKey(type)) &#123; human = humanMap.get(type); &#125; else &#123; if (type.equals(&quot;BlackHuman&quot;)) &#123; human = new BlackHuman(); &#125; else if (type.equals(&quot;WhiteHuman&quot;)) &#123; human = new WhiteHuman(); &#125; else &#123; human = new YellowHuman(); &#125; humanMap.put(type, human); &#125; return human; &#125;&#125; 延迟加载框架是可扩展的， 例如限制某一个产品类的最大实例化数量， 可以通过判断Map中已有的对象数量来实现，还可以用在对象初始化比较复杂的情况下， 例如硬件访问， 涉及多方面的交互， 则可以通过延迟加载降低对象的产生和销毁带来的复杂性。 抽象工厂模式抽象工厂模式是一种比较常用的模式，为创建一组相关或相互依赖的对象提供一个接口， 且无须指定它们的具体类。 当一个对象族有相同的约束时可以使用抽象工厂模式。 优点封装性，产品的具体实现细节高层模块不需要关心；产品族内的约束为非公开状态。缺点产品族扩展非常困难，严重违反开闭原则。 抽象工厂模式是工厂方法模式的升级版， 在有多个业务品种、 业务分类时， 通过抽象工厂模式产生需要的对象是一种非常好的解决方式。 人种接口： 12345public interface Human &#123; void getColor(); void talk(); void getSex();&#125; 人种有三个抽象类， 负责人种的抽象属性定义： 1234567891011121314151617181920212223242526272829303132333435public abstract class AbstractBlackHuman implements Human &#123; @Override public void getColor() &#123; System.out.println(&quot;黑色人种&quot;); &#125; @Override public void talk() &#123; System.out.println(&quot;我是黑色人种&quot;); &#125;&#125;public abstract class AbstractWhiteHuman implements Human &#123; @Override public void getColor() &#123; System.out.println(&quot;白色人种&quot;); &#125; @Override public void talk() &#123; System.out.println(&quot;我是白色人种&quot;); &#125;&#125;public abstract class AbstractYellowHuman implements Human &#123; @Override public void getColor() &#123; System.out.println(&quot;黄色人种&quot;); &#125; @Override public void talk() &#123; System.out.println(&quot;我是黄色人种&quot;); &#125;&#125; 每个抽象类都有两个实现类， 分别实现公共的最细节、 最具体的事物： 123456789101112public class FemaleYellowHuman extends AbstractYellowHuman &#123; @Override public void getSex() &#123; System.out.println(&quot;黄种女人&quot;); &#125;&#125;public class MaleYellowHuman extends AbstractYellowHuman &#123; @Override public void getSex() &#123; System.out.println(&quot;黄种男人&quot;); &#125;&#125; 制造人类的抽象工厂类： 12345public interface HumanFactory &#123; Human createYellowHuman(); Human createWhiteHuman(); Human createBlackHuman();&#125; 制造男人和女人的具体工厂类： 123456789101112131415161718192021222324252627282930313233public class FemaleFactory implements HumanFactory &#123; @Override public Human createYellowHuman() &#123; return new FemaleYellowHuman(); &#125; @Override public Human createWhiteHuman() &#123; return new FemaleWhiteHuman(); &#125; @Override public Human createBlackHuman() &#123; return new FemaleBlackHuman(); &#125;&#125;public class MaleFactory implements HumanFactory &#123; @Override public Human createYellowHuman() &#123; return new MaleYellowHuman(); &#125; @Override public Human createWhiteHuman() &#123; return new MaleWhiteHuman(); &#125; @Override public Human createBlackHuman() &#123; return new MaleBlackHuman(); &#125;&#125; 场景类的调用: 12345678910HumanFactory maleHumanFactory = new MaleFactory();HumanFactory femaleHumanFactory = new FemaleFactory();Human maleYellowHuman = maleHumanFactory.createYellowHuman();Human femaleYellowHuman = femaleHumanFactory.createYellowHuman();femaleYellowHuman.getColor();femaleYellowHuman.talk();femaleYellowHuman.getSex();maleYellowHuman.getColor();maleYellowHuman.talk();maleYellowHuman.getSex();","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"创建型模式","slug":"设计模式/创建型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E5%88%9B%E5%BB%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"原型模式","date":"2016-01-02T07:08:20.000Z","path":"blog/设计模式/创建型模式/原型模式/","text":"用一个已经创建的实例作为原型，通过复制该原型对象来创建一个和原型相同或相似的新对象。用这种方式创建对象非常高效，无须知道对象创建的细节。 在实际项目中，原型模式很少单独出现，一般是和工厂方法模式一起出现， 通过clone的方法创建一个对象，然后由工厂方法提供给调用者。 原型模式简单程度仅次于单例模式和迭代器模式，Java中的Object类提供了浅克隆的clone()方法，具体原型类只要实现**Cloneable接口就可实现对象的浅克隆。Cloneable 接口只是一个标记**作用， 在JVM中具有这个标记的对象才有可能被拷贝。 原型模式的克隆分为 浅克隆 和 深克隆浅克隆：创建一个新对象，新对象的属性和原来对象 完全相同，对于非基本类型属性，仍指向原有属性所指向的对象的内存地址。 12345678910111213public class Thing implements Cloneable &#123; private ArrayList&lt;String&gt; arrayList = new ArrayList&lt;String&gt;(); @Override public Thing clone() &#123; Thing thing = null; try &#123; thing = (Thing) super.clone(); &#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace(); &#125; return thing; &#125;&#125; 深克隆：创建一个新对象，属性中引用的其他对象 也会被克隆，不再指向原有对象地址。 1234567891011121314public class Thing implements Cloneable &#123; private ArrayList&lt;String&gt; arrayList = new ArrayList&lt;String&gt;(); @Override public Thing clone() &#123; Thing thing = null; try &#123; thing = (Thing) super.clone(); thing.arrayList = (ArrayList&lt;String&gt;)this.arrayList.clone(); &#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace(); &#125; return thing; &#125;&#125; 对象的clone与对象内的final关键字是有冲突的 ，要使用clone方法， 类的成员变量上不要增加final关键字。 优点Java自带的原型模式基于内存二进制流的复制，在性能上比直接new一个对象更加优良，特别是要在一个循环体内产生大量的对象时, 可以使用深克隆方式保存对象的状态，使用原型模式将对象复制一份，并将其状态保存起来，简化了创建对象的过程，以便在需要的时候使用。 逃避构造函数的约束，直接在内存中拷贝， 构造函数是不会执行的 缺点需要为每一个类都配置一个**clone**方法, clone 方法位于类的内部，当对已有类进行改造的时候，需要修改代码，违背了开闭原则当实现深克隆时，需要编写较为复杂的代码，而且当对象之间存在多重嵌套引用时，为了实现深克隆，每一层对象对应的类都必须支持深克隆，实现起来会比较麻烦。 应用场景 对象之间相同或相似，即只是个别的几个属性不同的时候, 创建对象成本较大，例如初始化时间长，占用CPU太多，或者占用网络资源太多等，需要优化资源, 创建一个对象需要繁琐的数据准备或访问权限等，需要提高性能或者提高安全性, 系统中大量使用该类对象，且各个调用者都需要给它的属性重新赋值 一个对象需要提供给其他对象访问， 而且各个调用者可能都需要修改其值时， 可以考虑使用原型模式拷贝多个对象供调用者使用 JDK源码中 ArrayList的应用： 1234567891011public Object clone() &#123; try &#123; ArrayList&lt;?&gt; v = (ArrayList&lt;?&gt;) super.clone(); v.elementData = Arrays.copyOf(elementData, size); v.modCount = 0; return v; &#125; catch (CloneNotSupportedException e) &#123; // this shouldn&#x27;t happen, since we are Cloneable throw new InternalError(e); &#125;&#125;","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"创建型模式","slug":"设计模式/创建型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E5%88%9B%E5%BB%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"单例模式","date":"2016-01-02T06:08:20.000Z","path":"blog/设计模式/创建型模式/单例模式/","text":"单例模式的核心代码就是将构造方法私有化，只有一个实例，自己负责创建自己的对象即自行实例化，提供一种访问其唯一对象的方式，可直接访问，不需要实例化该类的对象。 优点： 内存中只有一个实例，减少了内存开支，特别是一个对象需要频繁创建和销毁时。 只生成一个实例，减少了系统性能开销，当一个对象的产生需要比较多的资源时，如读取配置、产生其他依赖对象时，则可通过在应用启动时直接产生一个单例对象，永久驻留内存的方式解决。 可以避免对资源的多重占用，例如写文件动作，避免了对同一个资源文件同事写操作。 可以在系统设置全局访问点，优化和共享资源访问。如设计一个单例类，负责所有数据表的映射处理。 缺点： 单例模式一般没有接口，扩展困难。单例模式要求自行实例化，且提供单一实例，接口和抽象类是不能被实例化的。 对测试不利，单例模式未开发完，是不能进行测试的，没有接口也不能使用mock方式来进行测试。 与单一职责原则冲突。 懒汉式实例在使用时才去创建，用的时候才去检查有没有实例。有线程安全和线程不安全两种写法，区别就是synchronized关键字。下面这种写法存在线程安全问题，在并发获取实例时，可能会存在创建多个实例的情况。 123456789101112public class LazySingleton &#123; private static LazySingleton instance; private LazySingleton() &#123;&#125; public static LazySingleton getInstance() &#123; if (instance == null) &#123; instance = new LazySingleton(); &#125; return instance; &#125;&#125; 饿汉式在类加载时实例被创建。实现简单且没有线程安全的问题，可能在还不需要此实例的时候就已经把实例创建出来了，浪费内存空间，没起到lazy loading的效果。 123456789public class HungrySingleton &#123; private static HungrySingleton instance = new HungrySingleton(); private HungrySingleton() &#123;&#125; private static HungrySingleton getInstance() &#123; return instance; &#125;&#125; 双检锁双重校验锁，综合了懒汉式和饿汉式两者的优缺点。特点在synchronized关键字内外都加了一层 if 条件判断，既保证了线程安全，又比直接上锁提高了执行效率，还节省了内存空间。这里还用到了volatile关键字来修饰instance，其最关键的作用是防止指令重排。 12345678910111213141516public class Singleton &#123; private static volatile Singleton instance; private Singleton()&#123;&#125; public static Singleton getInstance()&#123; if (instance == null) &#123; synchronized (Singleton.class) &#123; if (instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; 静态内部类静态内部类的方式效果类似双检锁，但实现更简单且线程安全。同时静态内部类不会在Singleton类加载时就加载，而是在调用getInstance()方法时才进行加载，达到了懒加载的效果。但这种方式只适用于静态域的情况，双检锁方式可在实例域需要延迟初始化时使用。 1234567891011public class Singleton &#123; private static class SingletonHolder &#123; private static final Singleton INSTANCE = new Singleton(); &#125; private Singleton()&#123;&#125; public static Singleton getInstance() &#123; return SingletonHolder.INSTANCE; &#125;&#125; 枚举枚举的方式是比较少见的一种实现方式，却更简洁清晰。还自动支持序列化机制，绝对防止多次实例化。单元素的枚举类型已经成为实现Singleton的最佳方法。 123456789101112131415161718public class Singleton &#123; private enum SingletonEnum &#123; INSTANCE; private Singleton singleton; private SingletonEnum() &#123; singleton = new Singleton(); &#125; public Singleton getInstance() &#123; return singleton; &#125; &#125; public static Singleton getInstance() &#123; return SingletonEnum.INSTANCE.getInstance(); &#125;&#125; 使用场景在系统中要求一个类有且仅有一个对象，若出现多个对象会出现副作用，可以采用单例模式。 要求生成唯一序列号的环境 在整个项目中需要一个共享访问点或共享数据 创建一个对象需要消耗的资源过多，如访问IO和数据库等资源 需要定义大量的静态常量和静态方法的环境 Spring中典型应用1234567891011121314151617181920212223242526/** Cache of singleton objects: bean name to bean instance. */private final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;&gt;(256);/** Cache of singleton factories: bean name to ObjectFactory. */private final Map&lt;String, ObjectFactory&lt;?&gt;&gt; singletonFactories = new HashMap&lt;&gt;(16);/** Cache of early singleton objects: bean name to bean instance. */private final Map&lt;String, Object&gt; earlySingletonObjects = new HashMap&lt;&gt;(16);protected Object getSingleton(String beanName, boolean allowEarlyReference) &#123; Object singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) &#123; synchronized (this.singletonObjects) &#123; singletonObject = this.earlySingletonObjects.get(beanName); if (singletonObject == null &amp;&amp; allowEarlyReference) &#123; ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName); if (singletonFactory != null) &#123; singletonObject = singletonFactory.getObject(); this.earlySingletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); &#125; &#125; &#125; &#125; return singletonObject;&#125;","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"创建型模式","slug":"设计模式/创建型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E5%88%9B%E5%BB%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"SOLID基本原则","date":"2016-01-01T06:08:20.000Z","path":"blog/设计模式/SOLID基本原则/","text":"6大设计基本原则：单一职责原则、里氏替换原则、依赖倒置原则、接口隔离原则、迪米特法则、开闭原则 单一职责原则SRP​ 单一职责原则提出了一个编写程序的标准，用职责或变化原因来衡量接口或类设计得是否优良，但职责和变化原因都是不可度量得，因项目和环境而异。单一职责适用于接口、类、方法。定义：应该有且仅有一个原因引起类的变更。优点：类复杂性降低，实现职责清晰明确；可读性高；可维护性高；变更引起的风险低； 里氏替换原则LSP定义：每一个类型为S的对象s，都有类型为T的对象t，使得以T定义的所有程序P在所有的对象s都代替成t时，程序P的行为无变化，则类型S是类型T的子类；所有引用基类的地方必须能透明的使用其子类的对象。 子类必须完全实现父类的方法：若子类不能完全实现父类方法，或某些方法在子类种已发生畸变，建议断开父子继承关系。 子类可以有自己的个性：子类出现的地方父类未必能出现 覆盖或实现父类方法时输入参数可以被放大 覆写或实现父类的方法时输出结果可以被缩小 在类中调用其他类时务必使用父类或接口，否则即是违背LSP原则。 依赖倒置原则DIP​ 采用依赖倒置原则可以减少类间的耦合性，提高系统的稳定性，降低并行开发引起的风险，提高代码的可读性和可维护性。可以通过依赖倒置原则涉及的接口或抽象类对实现类进行约束，可减少需求变化引起的工作量剧增的情况，可让维护人员轻松地扩展和维护，是实现开闭原则的重要途径。TDD测试驱动开发模式就是依赖倒置原则的最高级应用。 定义：高层模块不应该依赖底层模块两者都应该依赖其抽象；抽象不应该依赖细节；细节应该依赖抽象；表现：模块间依赖通过抽象发生，实现类之间不发生直接的依赖关系，其依赖关系是通过接口或抽象类产生；接口和抽象类不依赖于实现类；实现类依赖接口或抽象类； 依赖的三种写法： 构造函数传递依赖对象，也叫构造函数注入 Setter方法传递依赖对象，也叫Setter依赖注入 接口声明依赖对象，也叫接口注入 依赖倒置原则的本质就是通过抽象（接口或抽象类）使各个类或模块的实现彼此独立，不互相影响，实现模块间的松耦合。 每个类尽量都有接口或抽象类，或抽象类和接口两者都具备 变量的表面类型尽量是接口或抽象类 任何类都不应该从具体类派生 尽量不要覆写基类的方法 结合里氏替换原则使用 接口隔离原则ISP定义：客户端不应该依赖它不需要的接口；类间的依赖关系应该建立在最小的接口上。建立单一的接口，不要建立臃肿庞大的接口； 接口尽量小 接口要高内聚：提高接口、类、模块的处理能力，减少对外的交互 定制服务，单独为一个个体提供优良的服务 接口设计要有限度 根据接口隔离原则拆分接口时，首先必须满足单一职责原则。接口和类尽量使用原子接口或原子类来组装。 一个接口只服务玉一个子模块或业务 通过业务逻辑压缩接口中的public方法 已经被污染的接口，尽量去修改，若变更风险较大，则采用适配器模式进行转化处理 了解环境，拒绝盲从 迪米特法则LD也称最少知识原则：一个对象应该对其他对象有最少的了解，对需要耦合或调用的类知道越少越好。 只和朋友交流：类与类间的关系是建立在类之间而不是方法间，一个方法尽量不引入一个类中不存在的对象 朋友间也是有距离的：尽量不对外公布太多public方法和非静态得public变量，尽量内敛 是自己的就是自己的：若一个方法放在本类中，即不增加类间关系，也对本类不产生负面影响，那就放置在本类中。 谨慎使用Serializable 两个对象之间的耦合就成为朋友关系，朋友关系类型很多如组合、聚合、依赖等。 注：朋友类的定义，出现在成员变量、方法输入输出参数中的类称为成员朋友类，出现在方法体内部的类不属于朋友类。 迪米尔法则要求类羞涩一点，尽量不对外公布太多public方法和非静态得public变量，尽量内敛，多使用private、package-private、protected等访问权限。类公开的public属性或方法越多，修改时涉及得面也就越大，变更引起得风险扩散也就越大。迪米特法则核心观念是类间解耦、弱耦合。 缺点：会产生大量中转或跳转类，导致系统的复杂性提高，同时也为维护带来了难度。使用时请反复权衡，既做到让结构清晰，又做到高内聚底耦合。 开闭原则OCP一个软件实体如类、模块和函数应该对扩展开放，对修改关闭。应该通过扩展来实现变化，而不是通过修改已有代码来实现变化。 开闭原则对扩展开放，对修改关闭，并不意味着不做任何修改，底层模块的变更，必然要有更高层模块进行耦合。 可把变化大致分为三类： 逻辑变化：可以通过修改原有类中的方法来完成，前提是所有依赖或者关联类都按照相同的逻辑处理。 子模块变化：底层模块变化必然引起高层模块变化，因此通过扩展完成变化时，高层模块修改是必然的。 可见视图变化 开闭原则是最基础的一个原则，前五个原则都是开闭原则的具体形态，前五个原则就是指导设计的工具和方法，而开闭原则才是精神领袖。 开闭原则对测试的影响在比较重要的方法，测试方法都会很多，可能测试逻辑都很复杂，若要通过修改修改一个方法或多个方法来完成变化，基本上测试用例都得重新写。所以需要通过扩展来实现业务逻辑而不是修改。 开闭原则可以提高复用性在面向对象设计中，所有的逻辑都是从原子逻辑组合而来，而不是在一个类中独立实现一个业务逻辑。颗粒度越小，被复用的可能性就越大。避免相同的逻辑分撒在多个角落，缩小颗粒度，直到一个逻辑不可再拆分为止。 开闭原则可以提高可维护性面向对象开发的要求开闭原则应用抽象约束通过接口或抽象类可以约束一组可能变化的行为，并且能够实现对扩展开放： 通过接口或抽象类约束扩展，对扩展边界限定，不允许出现在接口或抽象类中不存在的public方法 参数类型、引用对象尽量使用接口或抽象类，而不是实现类 抽象层尽量保持稳定 元数据（metadata）控制模块行为尽量使用元数据来控制程序行为，减少重复开发，如login方法中提供的先检查IP地址是否在允许访问的列表中，然后在确定是否需要到数据库中验证密码，表达的极致其实就是控制反转，如Spring的IoC容器。 注：元数据是用来描述环境和数据的数据，通俗的说就是配置参数。 制定项目章程对于项目来说约定优于配置。 封装变化对变化的封装：将相同的变化封装到一个接口或抽象类中，将不同的变化封装到不同的接口或抽象类中，不应该有两个不同的变化出现在同一个接口或抽象类中。 封装变化，也就是受保护的变化，找出预计有变化或不稳定的点。","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"设计模式概览","date":"2016-01-01T02:08:20.000Z","path":"blog/设计模式/设计模式概览/","text":"设计模式分类23种设计模式大体上可以分为三类： 创建型模式（5个）：对象实例化的模式，用于解耦对象的实例化过程； 结构型模式（7个）：把类或对象结合在一起形成一个更大的结构； 行为型模式（11个）：类和对象如何交互，及划分职责和算法； 各种模式的关键点：创建型模式：单例模式：某个类只能生成一个实例，该类提供了一个全局访问点供外部获取该实例。简单工厂：一个工厂类根据传入的参量决定创建出那一种产品类的实例。工厂方法：定义一个用于创建产品的接口，由子类决定生产什么产品。抽象工厂：提供一个创建产品族的接口，其每个子类可以生产一系列相关的产品。建造者模式：封装一个复杂对象的构建过程，并可以按步骤构造。原型模式：将一个对象作为原型，通过对其进行复制而克隆出多个和原型类似的新实例。 结构型模式适配器模式：将一个类的接口转换成客户希望的另外一个接口，使得原本由于接口不兼容而不能一起工作的那些类能一起工作。组合模式：将对象组合成树状层次结构，使用户对单个对象和组合对象具有一致的访问性。装饰模式：动态的给对象增加一些职责，即增加其额外的功能。代理模式：为某对象提供一种代理以控制对该对象的访问。即客户端通过代理间接地访问该对象，从而限制、增强或修改该对象的一些特性。亨元模式：运用共享技术来有效地支持大量细粒度对象的复用。外观模式：为多个复杂的子系统提供一个一致的接口，使这些子系统更加容易被访问。桥接模式：将抽象与实现分离，使它们可以独立变化。它是用组合关系代替继承关系来实现，从而降低了抽象和实现这两个可变维度的耦合度。 行为型模式：模板模式：定义一个操作中的算法骨架，而将算法的一些步骤延迟到子类中，使得子类可以不改变该算法结构的情况下重定义该算法的某些特定步骤。解释器模式：提供如何定义语言的文法，以及对语言句子的解释方法，即解释器。策略模式：定义了一系列算法，并将每个算法封装起来，使它们可以相互替换，且算法的改变不会影响使用算法的客户。状态模式：允许一个对象在其内部状态发生改变时改变其行为能力。观察者模式：多个对象间存在一对多关系，当一个对象发生改变时，把这种改变通知给其他多个对象，从而影响其他对象的行为。备忘录模式：在不破坏封装性的前提下，获取并保存一个对象的内部状态，以便以后恢复它。中介者模式：定义一个中介对象来简化原有对象之间的交互关系，降低系统中对象间的耦合度，使原有对象之间不必相互了解。命令模式：将一个请求封装为一个对象，使发出请求的责任和执行请求的责任分割开。访问者模式：在不改变集合元素的前提下，为一个集合中的每个元素提供多种访问方式，即每个元素有多个访问者对象访问。责任链模式：把请求从链中的一个对象传到下一个对象，直到请求被响应为止。通过这种方式去除对象之间的耦合。迭代器模式：提供一种方法来顺序访问聚合对象中的一系列数据，而不暴露聚合对象的内部表示。 23种设计模式间的关系：","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"ElasticSearch","slug":"工具和中间件/搜索引擎技术/ElasticSearch","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/ElasticSearch/"},{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"},{"name":"数据结构和算法","slug":"数据结构和算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"},{"name":"SpringBoot","slug":"Spring/SpringBoot","permalink":"http://example.com/categories/Spring/SpringBoot/"},{"name":"Test","slug":"Test","permalink":"http://example.com/categories/Test/"},{"name":"RocketMQ","slug":"工具和中间件/消息队列/RocketMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RocketMQ/"},{"name":"RabbitMQ","slug":"工具和中间件/消息队列/RabbitMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/"},{"name":"Activemq","slug":"工具和中间件/消息队列/Activemq","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Activemq/"},{"name":"Kafka","slug":"工具和中间件/消息队列/Kafka","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Kafka/"},{"name":"Solr","slug":"工具和中间件/搜索引擎技术/Solr","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/Solr/"},{"name":"Lucene","slug":"工具和中间件/搜索引擎技术/Lucene","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/Lucene/"},{"name":"Redis","slug":"Cloud/Redis","permalink":"http://example.com/categories/Cloud/Redis/"},{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"行为型模式","slug":"设计模式/行为型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"},{"name":"结构型模式","slug":"设计模式/结构型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E7%BB%93%E6%9E%84%E5%9E%8B%E6%A8%A1%E5%BC%8F/"},{"name":"创建型模式","slug":"设计模式/创建型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E5%88%9B%E5%BB%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"http://example.com/tags/ElasticSearch/"},{"name":"Kibana","slug":"Kibana","permalink":"http://example.com/tags/Kibana/"},{"name":"JAVA数据结构和算法","slug":"JAVA数据结构和算法","permalink":"http://example.com/tags/JAVA%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://example.com/tags/SpringBoot/"},{"name":"Test","slug":"Test","permalink":"http://example.com/tags/Test/"},{"name":"RocketMQ","slug":"RocketMQ","permalink":"http://example.com/tags/RocketMQ/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://example.com/tags/RabbitMQ/"},{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"http://example.com/tags/ActiveMQ/"},{"name":"Kafka","slug":"Kafka","permalink":"http://example.com/tags/Kafka/"},{"name":"Solr","slug":"Solr","permalink":"http://example.com/tags/Solr/"},{"name":"Lucene","slug":"Lucene","permalink":"http://example.com/tags/Lucene/"},{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"},{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]}