{"pages":[{"title":"Categories","date":"2022-07-01T02:42:53.324Z","path":"categories/index.html","text":""},{"title":"About","date":"2022-07-01T02:42:52.396Z","path":"about/index.html","text":"Welcome TaoLiu’s Blog"},{"title":"Tags","date":"2022-07-01T02:42:53.358Z","path":"tags/index.html","text":""}],"posts":[{"title":"","date":"2022-07-21T07:24:25.218Z","path":"blog/DB/mysql/MVCC与BufferPool缓存机制/","text":"title: “MVCC与BufferPool缓存机制”date: 2021-4-25 21:12:21tags: “MySQL” 快照读即不加锁的简单SELECT都属于快照读，当前读即读取最新数据而不是历史数据，加锁的SELECT或对数据进行增删改都会进行当前读。 MVCC多版本并发控制机制MySQL在可重复读隔离级别下同样的SQL查询语句在一个事务里多次执行查询结果相同，就算其它事务对数据有修改也不会影响当前事务SQL语句的查询结果。 该隔离性是靠MVCC(Multi-Version Concurrency Control)机制来保证的，对同一行数据的读和写默认不通过加锁互斥来保证隔离性，避免频繁加锁互斥，而在串行化隔离级别为了保证较高的隔离性是通过将所有操作加锁互斥来实现的。MySQL在读已提交和可重复读隔离级别下都实现了**MVCC机制**。 undo日志版本链与read view机制详解undo日志版本链是指同一行数据被多个事务依次修改过后，在每个事务修改完后，MySQL会保留修改前的数据即**undo回滚日志，且用两个隐藏字段trx_id和roll_pointer把这些undo日志串联起来形成一个历史记录版本链**。 每开启一个日志都会从数据库中获得一个事务id即trx_id，且trx_id是自增的，可判断事务的时间顺序。**roll_pointer为回滚指针**，指向undo日志中的上一个版本。 在可重复读隔离级别，当事务开启，执行第一条查询SQL时会生成当前事务的一致性视图read-view，该视图在事务结束之前都不会变化，该视图是由执行查询时所有未提交事务id组成的数组，数组里最小的事务id为**min_id，已创建的最大事务id为max_id，事务里的任何SQL查询结果需要从对应版本链里的最新数据开始逐条跟read-view做对比从而得到最终的快照结果**。 对于读已提交隔离级别在**每次执行查询SQL时都会重新生成read-view**，其他逻辑跟可重复读一致。 版本链比对规则若row的trx_id落在绿色部分即**trx_id&lt;min_id，表示该版本是已提交的事务生成的，则该数据是可见**的； 若row的trx_id落在红色部分即**trx_id&gt;max_id，表示该版本是由将来启动的事务生成的，则该数据是不可见的，若row的trx_id就是当前自己的事务是可见的**； 若row的trx_id落在黄色部分即**min_id &lt;=trx_id&lt;= max_id**，则包括两种情况： 若row的**trx_id在视图数组中，表示该版本是由还没提交的事务生成的，则该数据不可见，若row的trx_id是当前自己的事务则可见** 若row的**trx_id不在视图数组中，表示该版本是已经提交了的事务生成的，则该数据可见**。 删除可认为是update的特殊情况，会将版本链上最新的数据复制一份，然后将trx_id修改成删除操作的trx_id，同时在该条记录的头信息record header里的**deleted_flag标记位写上true**，表示当前记录已经被删除，在查询时按照上面的规则查到对应的记录若delete_flag标记位为true，意味着记录已被删除，则不返回数据。 begin或start transaction命令并不是一个事务的起点，在执行到它们之后的第一个修改InnoDB表的语句，事务才真正启动，才会向MySQL申请事务id，MySQL内部是严格按照事务的启动顺序来分配事务id的。 MVCC机制的实现就是通过read-view机制与**undo版本链比对机制，使得不同事务根据数据版本链对比规则读取同一条数据在版本链上的不同版本数据**。 BufferPool缓存机制数据库的增删改查都是**直接操作BufferPool，BufferPool一般设置为机器内存的60%**左右，执行SQL执行流程如下： 加载缓存数据记录所在的整页数据到BufferPool 写入更新数据旧值到undo日志中，便于回滚恢复BufferPool中的缓存数据 更新BufferPool中缓存的数据 写redo日志，首先写到Redo Log Buffer中 准备提交事务，redo日志写入磁盘redo日志文件中 准备提交事务，binlog日志写入磁盘binlog日志文件中，用来恢复数据库磁盘中的数据 写入commit标记到redo日志文件中，事务提交完成。该标记为了保证事务提交后redo与binlog数据一致 以page页为单位将数据随机写入磁盘 若来一个请求就直接对磁盘文件进行随机读写，然后更新磁盘文件里的数据性能可能相当差。因为磁盘随机读写的性能非常差，所以直接更新磁盘文件是不能让数据库抗住很高并发的。 MySQL这套机制看起来复杂，但它可以保证每个更新请求都是更新内存BufferPool，然后顺序写日志文件，同时还能保证各种异常情况下的数据一致性。若事务提交成功，BufferPool中的数据还没来得及写入磁盘，此时若系统宕机了，可以用redo日志中的数据恢复BufferPool中的缓存数据。 更新内存的性能是极高的，然后顺序写磁盘上的日志文件的性能也是非常高的，要远高于随机读写磁盘文件。正是通过这套机制，才能让MySQL数据库在较高配置的机器上每秒可以抗下几干的读写请求。 BufferPool默认为128M，MySQL的数据是以文件页16K为单位加载到BufferPool，故默认BufferPool可放8192个文件页，且BufferPool分冷热数据，一般热数据占八分之五，冷数据占八分之三，且通过升级版的**LRU链表维护。若对于一个大表进行全表扫描时，可能很快就把缓存页数据占满了，故MySQL会判断超过1s再次被访问的数据才会放入热数据区域**，否则使用冷数据区域。 且**BufferPool通过空闲列表维护了空闲页free链表，当数据被查询到BufferPool中会判断空闲页，写到固定的位置，且若发生数据更新则会产生脏页，这些脏页也会被维护到一个Flush链表中。且通过基节点**维护了链表信息。 redo log记录的是某一页的哪个地址开始的数据被修改，**redo log有两个日志文件，会滚动写入即当一个文件写满了就会写另一个文件，且有一个检查点的概念，若覆盖写入时发现了脏数据即BufferPool中缓存页数据被修改过，则会先触发刷盘操作将FlushList中的文件页的数据批量刷到磁盘中，则redo log文件配置越小则刷盘越频繁性能就越受影响，但若redo log配置的很大可能导致启动缓慢，redo log**可通过配置值从而配置其持久化到redo log文件的时机： 0：事务提交时，不立即对redo log进行持久化，交给后台线程异步去完成 1：默认值，事务提交时，立即把redo log进行持久化 2：事务提交时，立即将redo log写到操作系统的缓冲区，并不会直接将redo log进行持久化，若数据库挂了，但操作系统没有挂，则事务的持久性还可以保持 Change Buffer存储的是索引的更新信息，当执行SELECT时加载索引页时，会将索引页与Change Buffer中的缓存数据融合。","tags":[],"categories":[{"name":"DB","slug":"DB","permalink":"http://example.com/categories/DB/"},{"name":"mysql","slug":"DB/mysql","permalink":"http://example.com/categories/DB/mysql/"}]},{"title":"秒杀问题及解决方案","date":"2022-01-02T12:08:20.000Z","path":"blog/Cloud/秒杀问题及解决方案/","text":"秒杀业务特性秒杀具有瞬时高并发的特点，秒杀请求在时间上高度集中于某一特定的时间点（秒杀开始那一秒），就会导致一个特别高的流量峰值，它对资源的消耗是瞬时的。 但对秒杀场景来说，最终能够抢到商品的人数是固定的，也就是说100人和10000人发起请求的结果都是一样的，并发度越高，无效请求也越多。 但是从业务上来说，秒杀活动是希望更多的人来参与，开始之前希望有更多的人来刷页面，但是真正开始下单时，秒杀请求并不是越多越好。 流量削峰服务器处理资源是恒定的，用或者不用它的处理能力都是一样的，出现峰值很容易导致忙到处理不过来，闲的时候却又没有什么要处理。 流量削峰，一是可以让服务端处理变得更加平稳，二是可以节省服务器的资源成本。针对秒杀这一场景，削峰从本质上来说就是更多地延缓用户请求的发出，以便减少和过滤掉一些无效请求，它遵从请求数要尽量少的原则。流量削峰的比较常见的思路：排队、答题、分层过滤。 秒杀业务设计 营销工具：系统整理的促销工具，可以对某些特定的工具详细解释营销活动：从营销工具中提出创建一个活动营销活动订单：针对营销活动产生的订单 商品级优惠：限时促销、限时抢购、秒杀、商品包邮 订单级优惠：满就赠、满立减、送优惠券、折扣、Vip折扣、订单包邮 全站级促销优惠：优惠券、优化券补发、银行促销、支付红包、团购预售、微信砍价 秒杀技术特性单一职责、流量错峰、限流、熔断、降级、队列削峰、预热快速扣减、动静分离 一般下单流程分为下单确认和下单提交，核心点为价格计算和库存处理，在下单确认时首先做一些检查、然后获取会员、商品等信息计算金额生成商品信息。 信息检查：检查本地缓存售罄状态、校验token是否有权限购买、判断redis库存是否充足、检查是否正在排队中 调用会员服务获取会员信息 调用产品服务获取产品信息 验证秒杀时间是否超时 获取用户收获列表 构建商品信息 根据各种优惠计算订单金额 下单提交的核心流程为： 信息检查：检查本地缓存售罄状态、校验token是否有权限购买、判断redis库存是否充足、检查是否正在排队中 调用会员服务获取会员信息 调用产品服务获取产品信息 验证秒杀时间是否超时 预减库存（异步流程） 生成下单商品信息 库存处理 库存问题高并发下会出现超卖问题、何时扣减库存 超卖问题可通过数据库锁、redis特性、异步下单等解决方案来解决 数据库锁悲观锁，通过**MySQL提供的select...for update实现的悲观锁方式，但select...for update语句执行中所有扫描过的行都会被锁上，因此在MySQL中用悲观锁务必须确定走索引**，而不是全表扫描，否则将会将整个数据表锁住。 12345begin;select flash_promotion_count from sms_flash_promotion_product_relation where id = 43 for UPDATE;update sms_flash_promotion_product_relation set flash_promotion_count = flash_promotion_count - 1 where id = 43;--ROLLBACK;commit； 悲观锁大多数情况下依靠数据库的锁机制实现，以保证操作最大程度的独占性，若加锁时间过长，其他用户长时间无法访问，影响了程序的并发访问性，同时这样对数据库性能开销影响很大，特别是对长事务而言，这样的开销往往无法承受，这时就需要乐观锁。 乐观锁，在数据进行提交更新时，才会正式对数据的冲突与否进行检测，若发现冲突则返回错误信息，让用户决定如何去做。版本号的实现有数据版本机制和时间催机制两种。 12345begin;select flash_promotion_count from sms_flash_promotion_product_relation where id = 43 ;update sms_flash_promotion_product_relation set flash_promotion_count = flash_promotion_count, version = version + 1 where id = 43 and version = #version#;-- ROLLBACK;Commit； 除了查询库存还需要更新库存，还有订单、订单日志、订单详情等需要插入数据库。库存更新没问题，但插入订单时失败了是否回滚，若不在一个事务就会出错。若在一个事务又涉及到事务过长甚至可能是跨库然后无法用本地事务来解决。 12345678910-- 扣减库存，防止库存超卖，若可以买多个，上面的SQL就有问题UPDATE sms_flash_promotion_product_relationSET flash_promotion_count = CASE WHEN flash_promotion_count &gt;= #&#123;stock&#125; THEN flash_promotion_count - #&#123;stock&#125; ELSE flash_promotion_count ENDWHEREid = #&#123;id&#125; 数据库锁的问题：若数据库只有10个商品，1000个人来抢，意味着990个请求没有意义，但这种方案1000个请求都会到数据库尝试扣减库存，大量请求会导致数据库超载。 Redis版本使用数据库锁方案数据库性能相对来说是有很大瓶颈，故可把库存放到redis中，秒杀下单时先从redis中获取库存数量，然后根据库存数量判断是否可进行下一步，若有库存就直接下单没有库存就不能下单。这样可拦截大部分流量进入到数据库中。需要将商品库存预先加载到Redis中。 12345// 从redis缓存当中取出当前要购买的商品库存Integer stock = redisOpsUtil.get(RedisKeyPrefixConst.MIAOSHA_STOCK_CACHE_PREFIX + productId, Integer.class);if (stock == null || stock &lt;= 0) &#123; return CommonResult.failed(&quot;商品已经售罄，请购买其它商品!&quot;);&#125; 对于Redis来说还是有网络IO，当商品售罄时在本地缓存中设置该商品的售罄标志为true，从而减少Redis的网络IO。 Boolean localcache &#x3D; cache.getCache(RedisKeyPrefixConst.MIAOSHA_STOCK_CACHE_PREFIX + productId);if (localcache !&#x3D; null &amp;&amp; localcache) { return CommonResult.failed(“商品已经售罄,请购买其它商品!”);}&#x2F;&#x2F; 从redis缓存当中取出当前要购买的商品库存Integer stock &#x3D; redisOpsUtil.get(RedisKeyPrefixConst.MIAOSHA_STOCK_CACHE_PREFIX + productId, Integer.class);if (stock &#x3D;&#x3D; null || stock &lt;&#x3D; 0) { &#x2F;&#x2F; 设置标记，如果售罄了在本地cache中设置为true cache.setLocalCache(RedisKeyPrefixConst.MIAOSHA_STOCK_CACHE_PREFIX + productId, true); return CommonResult.failed(“商品已经售罄,请购买其它商品!”);} 虽然可通过增加本地缓存减少Redis网络IO，但会存在产品售罄标志同步问题，可通过Zookeeper的watcher机制来实现同步，给每个JVM都监听Zookeeper的某个节点，一旦数据有改变之后通知到其他节点上。还可以利用Redis的Channel机制实现的发布订阅模式来实现产品售罄标志同步。 1234567891011121314151617181920212223public class RedisOpsUtil &#123; public void publish(String channel,Object message)&#123; redisTemplate.convertAndSend(channel,message); &#125;&#125;public boolean shouldPublishCleanMsg(Long productId) &#123; Integer stock = redisOpsUtil.get(RedisKeyPrefixConst.MIAOSHA_STOCK_CACHE_PREFIX + productId, Integer.class); return (stock == null || stock &lt;= 0);&#125;//通知服务群,清除本地售罄标记缓存if (shouldPublishCleanMsg(productId)) &#123; redisOpsUtil.publish(&quot;cleanNoStockCache&quot;, productId);&#125;public class RedisChannelListener implements MessageListener &#123; @Autowired private LocalCache localCache; @Override public void onMessage(Message message, @Nullable byte[] pattern) &#123; log.info(&quot;sub message :) channel[cleanNoStockCache] !&quot;); String productId = new String(message.getBody(), StandardCharsets.UTF_8); localCache.remove(RedisKeyPrefixConst.MIAOSHA_STOCK_CACHE_PREFIX + productId); &#125;&#125; Zookeeper和Redis各有各的优缺点，Zookeeper是CP模式的可保证高可用，但吞吐量会比较低，Redis这种发布订阅模式没有Ack，发出去后不管是否收到，因为减少了通讯吞吐量相对来说会比较高。 异步下单前面的方案，下单时会插入很多张表， 异步下单可以分流、让服务器处理压力变小、数据库压力减少 解耦，业务更清晰 天然排队处理能力 消息中间件有很多特性可以利用，如订单取消 订单超时取消 定时任务：时间不准确，定时扫数据库的话消耗性能也很大，效率也会很低，对数据库压力太大，集群还需要保证处理的幂等性和分布式问题 消息队列异步取消：通过延时消息实现 何时扣减库存下单时扣减**redis中的库存支付时扣减数据库中的库存扣减库存系统**中的库存 秒杀总结尽量将请求拦截在系统上游，后续占据99%的请求，直接Nginx层面拦截掉都多写少的场景多使用缓存，多级缓存保护好数据库用消息中间件解决流量削峰，订单请求写入RocketMQ进行削峰，让RocketMQ轻松抗下高并发压力，让订单系统慢慢消费和处理下单操作 秒杀商品详细页架构解决方案将秒杀活动商品详情页做成静态化 提前从数据库中把该页面需要的数据都提取出来组装成一份静态数据放在别的地方，避免每次访问都要访问后端数据库，该方案不适用商品比较多的商城如京东，适合商品较少的如小米，因为一旦修改了模板需要全部进行改动。 CDN+Nginx+Redis多级缓存架构 第一级缓存：请求秒杀商品详情页数据时，从就近CND上加载，不需要每次请求都到某个机房 Nginx基于Lua脚本实现本地缓存：提前把秒杀商品详情页的数据放到Nginx中缓存，不需要把请求转发到商品系统上 第二级缓存：Nginx上存在缓存数据过期之类的问题，导致没有找到需要的数据，此时由Nginx中的Lua脚本发送请求到本地缓存 第三级缓存：若还没找到，把请求转发到Redis集群中加载提前放入的秒杀商品数据 秒杀下单TPS压力过大的解决方案 加数据库服务器方案 会导致公司服务器成本急剧飙升 库存超卖：乐观锁和悲观锁，都会影响性能 用答题、复杂验证码的方案避免作弊以及延时下单：在前端或客户端设置秒杀答题，错开大量人下单的时间，阻止作弊器刷单 为秒杀独立出一套订单系统，专门负责秒杀请求：若秒杀下单请求和普通下单请求都由一套订单系统来承载，可能导致秒杀下单请求耗尽订单系统资源，或导致系统不稳定，从而导致其他普通下单请求也出现问题。 基于Redis实现下单时精准扣减库存，一旦库存扣减完则秒杀结束：一般会将每个秒杀商品库存提前写入Redis，在下单请求来后直接对Redis中的库存进行扣减 抢购完毕后提前过滤无效请求，大幅度消减转发到后端的流量 在Redis中库存扣减完成后，说明后续其他请求没有必要发送到秒杀系统中了，因为商品已经被抢购完成了，此时可让Nginx接收到后续请求时直接把后续请求过滤掉 一旦商品抢购完毕，可在Redis或Zookeeper中写入一个秒杀完毕的标志位，然后反向通知Nginx中自己写的Lua脚本，通过Lua脚本将后续请求直接过滤掉 在网关层或Sentinel做流量控制 瞬时高并发下单请求进入RocketMQ进行削峰，订单系统慢慢拉取消息完成下单操作：若判断发现通过Redis完成了库存扣减，此时直接发送消息到RocketMQ即可，让普通订单系统从RocketMQ中消费秒杀成功的消息进行常规的流程处理即可，后续订单系统以每秒几千的速率慢慢处理，延迟可能几十秒，这些订单就能被处理完毕 前端验证问题针对前端验证问题，可通过提前发Token，在秒杀前设置一个预约活动，如一个秒杀活动有**20W个商品，可预先准备200W**个Token，用户进行预约时，只发放200W个Token，其他人也能预约成功，但是其实没有获得token，后面秒杀直接通过该Token就可过滤掉一大部分人，相当于没有Token的人都只预约了个寂寞。 针对超卖问题针对超卖问题，可使用**Redis分布式锁防超卖**，针对同一个商品ID，使用一把分布式锁，若同时有成千上万个商品要进行秒杀，那就意味着同一时间Redis上锁解锁的操作会要执行成千上万次，这对Redis的性能消耗是相当巨大的，Redis就有可能升级成为新的性能瓶颈。 可把秒杀超卖的问题从分布式降级到本地JVM中，来获取极限性能。将秒杀服务接入配置中心，然后在秒杀服务开始前，由配置中心给每个应用服务实例下发一个库存数量。然后每次下单，每个服务器只管自己的库存数量，与其他应用服务器完全不进行库存同步，在各自的内存里扣减库存，这样就不会有超卖的情况发生。减少了网络消耗，性能也能够进一步提升。 可能给某服务器上的库存很快消耗完了，而其他的服务器上仍有库存，整个服务就会表现为你抢不到商品，但是在你后面抢商品的人却能抢到商品，但是这在秒杀这种场景下，完全是可以接受的。 若某一个应用服务器挂了，给他分配的库存就会丢失，这时只需要统计好订单的数量，可通过MQ来统计，也可通过Redis统计，等秒杀活动30分钟等待支付期过去后，再将没卖出去的库存重新丢回库存池，与没有付款而被取消的订单商品一起返场售卖即可。 兜底方案之限流&amp;降级对于很多秒杀系统而言，在诸如双十一这样的大流量的迅猛冲击下，都曾经或多或少发生过宕机的情况。当一个系统面临持续的大流量时，它其实很难单靠自身调整来恢复状态，必须等待流量自然下降或人为地把流量切走才行，这无疑会严重影响用户的购物体验。 在系统达到不可用状态之前就做好流量限制，防止最坏情况的发生。针对秒杀系统，在遇到大流量时，更多考虑的是运行阶段如何保障系统的稳定运行，常用的手段：限流，降级，拒绝服务。 限流相对降级是一种更极端的保存措施，限流就是当系统容量达到瓶颈时，需要通过限制一部分流量来保护系统，并做到既可人工执行开关，也支持自动化保护的措施。 限流既可在客户端限流，也可在服务端限流。限流的实现方式既要支持**URL以及方法级别的限流，也要支持基于 QPS和线程的限流。限流必然会导致一部分用户请求失败，因此在系统处理这种异常时一定要设置超时时间**，防止因被限流的请求不能fast fail（快速失败）而拖垮系统。 Nginx限流可使用**ngx_http_limit_conn_module对于一些服务器流量异常、负载过大，甚至是大流量的恶意攻击访问等，进行并发数的限制；该模块可根据定义的键来限制每个键值的连接数**，只有那些正在被处理的请求，这些请求的头信息已被完全读入，所在的连接才会被计数。 123456789101112# 限制连接数，客户端的IP地址作为键，# binary_remote_addr变量长度是固定4字节，在32位平台中占用32字节或64字节，在64位平台中占用64字节# 1M共享空间可以保存3.2万个32位的状态，1.6万个64位的状态# 若共享内存空间被耗尽，服务器将会对后续所有的请求返回503即Service Temporarily Unavailable错误limit_conn_zone $binary_remote_addr zone=addr:10m;server &#123; location /download/ &#123; # 指定每个给定键值的最大同时连接数，同一IP同一时间只允许有1个连接 limit_conn addr 1; &#125;&#125;# 缺点：前端做LVS或反向代理，会出现大量的503错误，需要设置白名单对某些ip不做限制 通过**ngx_http_limit_req_module模块可通过定义的键值来限制请求处理的频率**。特别的可限制来自单个IP地址的请求处理频率。限制的方法如同漏斗，每秒固定处理请求数，推迟过多请求。 123456789101112http &#123; # 区域名称为one，大小为10m，平均处理的请求频率不能超过每秒一次。键值是客户端IP limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s; ... server &#123; ... location /search/ &#123; # 允许超出频率限制的请求数为5，默认会被延迟处理，如果不希望延迟处理，可以使用nodelay参数 limit_req zone=one burst=5 nodelay; &#125; &#125;&#125; OpenResty利用Lua限流 网关接入Sentinel控制台Route维度限流API维度限流应用层限流系统第一次上线启动，或系统在Redis故障情况下重新启动，这时在高并发的场景下就会出现所有的流量都打到数据库上，导致数据库崩溃。因此需要通过缓存预热的方案，提前给Redis灌入部分数据后再提供服务。 可在流控规则中配置关联模式，将数据库资源加入限流资源中，当对数据库访问达到阈值，可对商品详情请求限流。","tags":[{"name":"springCloud","slug":"springCloud","permalink":"http://example.com/tags/springCloud/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"}]},{"title":"分布式系统常见问题","date":"2022-01-02T11:08:20.000Z","path":"blog/Cloud/分布式系统常见问题/","text":"对于分布式高并发系统需要考虑的问题：容量规划、架构设计、数据库设计、缓存设计、框架选型、数据迁移方案、性能压测、监控报警、领域模型、回滚方案、高并发、分库分表。 一致性Hash一致性哈希算法通过一致性哈希环数据结构实现，该环的起点是**0，终点是2^32 - 1，且起点与终点连接，故该环的整数分布范围是[0, 2^32-1]**。 将对象和服务器都放置到同一个哈希环后，在哈希环上顺时针查找距离这个对象的hash值最近的机器，即是该对象所属的机器。引入虚拟节点来解决负载不均衡的问题。将每台物理服务器虚拟为一组虚拟服务器，将虚拟服务器放置到哈希环上，如果要确定对象的服务器，需先确定对象的虚拟服务器，再由虚拟服务器确定物理服务器。 分布式IDUUID优点：生成简单、本地生成无网络成本； 缺点：无序的字符串，不具备趋势自增特性、没有具体的业务含义、长度过长16字节128位，36位长度的字符串，存储以及查询对MySQL的性能消耗较大，作为数据库主键UUID的无序性会导致数据位置频繁变动，严重影响性能 数据库自增ID需要一个单独的MySQL实例用来生成ID，要一个ID时，向表中插入一条记录返回主键ID，但该方式在访问量激增时MySQL本身就是系统的瓶颈，用它来实现分布式服务风险比较大。 优点：实现简单，ID单调自增，数值类型查询速度快 缺点：DB单点存在宕机风险，无法扛住高并发场景 数据库多主模式主从模式或多主模式集群，设置起始值和自增步长优点：解决DB单点问题缺点：不利于后续扩容，且实际上单个数据库自身压力还是大，依旧无法满足高并发场景 号段模式一次获取一批号段，可以基于MySQL也可以局域Redis或Zookeeper等 RedisRDB模式：若连续自增但redis没及时持久化，但Redis挂掉了，重启Redis后会出现ID重复的情况AOF会对每条写命令进行持久化，即使Redis挂掉了也不会出现ID重复的情况，但由于incr命令的特殊性，会导致Redis重启恢复的数据时间过长 雪花算法SnowFlake雪花算法能保证不同进程主键不重复相同进程主键有序，二进制形式包含4部分，从高位到低位分表为：**1bit符号位、41bit时间戳位、10bit工作进程位，12bit序列号位。毫秒数在高位自增序列在低位，整个ID趋势递增；不依赖第三方组件稳定性高，生成ID性能也非常高；可根据自身业务特性分配bit位，非常灵活；但强依赖机器时钟，若机器上时钟回拨会导致发号重复**。 1bit符号位：预留的符号位恒为零 41bit时间戳位：41位时间戳可容纳毫秒数为2的41次幂，一年所使用的毫秒数为**365 * 24 * 60 * 60 * 1000 Math.pow(2, 41) / (365 * 24 * 60 * 60 * 1000L) = 69.73**年不重复 10bit工作进程位：该标志Java进程内唯一，若分布式应用部署应保证每个工作进程的id不同，默认为0，可通过属性设置 12bit序列号位：该序列用来在同一个毫秒内生成不同的ID，若在该毫秒内生成数量超过**4096**即2的12次幂，则生成器会等待到下个毫秒继续生成。 滴滴出品TinyIDTinyid是基于号段模式原理实现的 百度uid-generatoruid-generator是基于Snowflake算法实现，与原始的snowflake算法不同在于，uid-generator支持自定义时间戳、工作机器ID和序列号等各部分的位数，而且uid-generator中采用用户自定义workId的生成策略。 uid-generator需要与数据库配合使用，需要新增一个WORKER_NODE表。当应用启动时会向数据库表中去插入一条数据，插入成功后返回的自增ID就是该机器的workId数据由host，port组成。 美团LeafLeaf同时支持号段模式和snowflake算法模式，可以切换使用；Leaf的snowflake模式依赖于ZooKeeper，不同于原始snowflake算法也主要是在workId的生成上，Leaf中workId是基于ZooKeeper的顺序Id来生成的，每个应用在使用Leaf-snowflake时，启动时都会都在Zookeeper中生成一个顺序Id，相当于一台机器对应一个顺序节点，也就是一个workId。 不存在数据过滤使用布隆过滤器 接口幂等性解决方案需要判断哪些操作是需要回滚的，以及这次成功下次不需要再处理了，数据积累问题怎么解决 全局唯一ID 去重表：可以在redis中做去重表 状态机：将状态从0改成1 分布式Session解决方案Session Sticky对IP进行hash分发到固定的机器上，但是会存在单点故障问题， Session Relication即Session复制，可解决单点复制，但耗内存、耗宽带 Session Center将Session存入Redis应用与Redis通信 数据库优化 换数据库：MySQL -&gt; Redis；读多写少使用Redis做缓存，ES搜索（全量更新、增量更新） 分库分表，读写分离； **JDBC应用层：shardingsphere、tddl**；性能更高、不支持夸语言 **Proxy代理层：mycat、mysql-proxy**；性能相对较差、支持夸语言、业务侵入性低 图片处理可以存OSS等 后端优化一般商品详情页都是读多写少，通过多级缓存 缓存应用场景 访问量大、QPS高、更新频率不是很高的业务 数据一致性要求不高 缓存一致性问题提高请求的吞吐量 减少磁盘IO 减少网络IO 若商品详情页数据过大，Redis会存在网络瓶颈，需要对数据进行压缩后再缓存到Redis，提升通讯性能。 最终一致性 设置超时时间 实时一致性 canal binlog日志实时同步 二级缓存L1缓存失效时间短，**L2缓存失效时间长。请求优先从L1缓存**获取数据，如果未命中则加锁，保证只有一个线程去数据库中读取数据然后再更新到L1和L2中。然后其他线程依然在L2缓存获取数据。 多级缓存设计对于高并发系统来说，网络IO和磁盘IO对系统的影响比较大，引入Redis缓存的目的是提高网站的性能，本质是不走磁盘走内存减少磁盘IO来提高性能，但是增加了网络的操作，若是本地缓存的既可以减少磁盘IO也可以减少网络IO。引入Guava缓存， 1234567891011121314151617public class LocalCache &#123; private Cache&lt;String, ProductParam&gt; localCache = null; @PostConstruct private void init() &#123; localCache = CacheBuilder.newBuilder() .initialCapacity(10) //设置本地缓存容器的初始容量 .maximumSize(500) //设置本地缓存的最大容量 .expireAfterWrite(60, TimeUnit.SECONDS) //设置写缓存后多少秒过期 .build(); &#125; public void setLocalCache(String key, PmsProductParam object) &#123; localCache.put(key, object); &#125; public PmsProductParam get(String key) &#123; return localCache.getIfPresent(key); &#125;&#125; 前端页面静态化处理可通过FreeMarker模板引擎，基于模板和数据源生成前端静态页面，适用于小流量商品详情页缓存架构，缺点是每个商品都需要生成一个静态页面，且若有多个机房每个产品得生成多个静态页面或生成一个静态页面同步多个机房。且若插入、修改、数据调整导致模板变化所有产品得重新生成。 架构问题：数据新增分增量更新或全量更新，不同应用部署在不同服务器甚至不同的机房或国家，存在数据同步问题 通过网络方式同步：其中一台服务器静态化，把文件同步到其他应用服务器上，如scp命令 定时任务：在每个应用使用一个定时任务，分别执行数据库需要静态话的数据，解决了同步问题，但产生了数据重复执行问题 消息中间件：通过消息中间件，订阅Topic生成当前服务器静态化的页面 后天数据有变更如何及时更新同步到其他服务端，页面静态化后，搜索打开一个商品详细页，怎么确定需要访问的静态页面，或若模板修改等问题 前端缓存小流量架构可通过FreeMarker模板引擎，基于模板和数据源生成前端静态页面，适用于小流量商品详情页缓存架构，缺点是每个商品都需要生成一个静态页面，且若有多个机房每个产品得生成多个静态页面或生成一个静态页面同步多个机房。且若插入、修改、数据调整导致模板变化所有产品得重新生成。 架构问题：数据新增分增量更新或全量更新，不同应用部署在不同服务器甚至不同的机房或国家，存在数据同步问题 通过网络方式同步：其中一台服务器静态化，把文件同步到其他应用服务器上，如scp命令 定时任务：在每个应用使用一个定时任务，分别执行数据库需要静态话的数据，解决了同步问题，但产生了数据重复执行问题 消息中间件：通过消息中间件，订阅Topic生成当前服务器静态化的页面 数据有变更如何及时更新同步到其他服务端，页面静态化后，搜索打开一个商品详细页，怎么确定需要访问的静态页面，或若模板修改等问题 大型网站架构可使用OpenResty来搭建能够处理超高并发、扩展性极高的动态Web应用、Web服务和动态网关。OpenResty是基于Nginx和Lua脚本的高性能Web平台，内部集成了大量精良的Lua库、第三方模块以及大多数的依赖项。通过汇聚各种设计精良的Nginx模块，从而将Nginx有效的变成一个强大的通用Web应用平台。 高并发整体架构高并发架构v1使用静态化技术，按照商品维度生成静态化HTML 通过MQ得到变更通知 通过Java Worker调用多个依赖系统生成详情页HTML 通过rsync同步到其他机器 通过Nginx直接输出静态页 接入层负责负载均衡 随着商品数量的增加这种架构的存储容量到达了瓶颈，且按照商品维度生成整个页面会存在如分类维度变更就要全部刷一遍该分类下所有信息的问题 若只有分类、模板变更，所有相关的商品都需要重新静态化 随着商品数量的增加，**rsync**会成为瓶颈 无法迅速响应一些页面需求变更，大部分都是通过JavaScript动态改页面元素。 方案改进： 容量问题通过按照商品尾号做路由分散到多台机器，按照自营商品单独一台，第三方商品分散到11台 按维度生成HTML片段（框架、商品介绍、规格参数、面包屑、相关分类、店铺信息），而不是一个大HTML 通过**Nginx SSI合并片段输出** 接入层负责负载均衡 多机房部署也无法通过rsync同步，而是使用部署多套相同架构来实现 该方案主要缺点，随着业务的发展，无法满足迅速变化、还有一些变态的需求 碎片文件太多，导致无法rsync 机械盘做**SSI合并时，高并发时性能差** 模板如果要变更，数亿商品需要数天才能刷完 到达容量瓶颈时，会删除一部分静态化商品，然后通过动态渲染输出，动态渲染系统在高峰时会导致依赖系统压力大，抗不住 还是无法迅速响应一些业务需求 高并发架构v2存在需要解决的问题： 能迅速响瞬变的需求，和各种变态需求 支持各种垂直化页面改版 页面模块化 AB测试 高性能、水平扩容 多机房多活、异地多活 目前架构的目标不仅仅是为商品详情页提供数据，只要是Key-Value获取的而非关系的都可以提供服务，叫做动态服务系统 数据变更还是通过MQ通知 数据异构Worker得到通知，然后按照一些维度进行数据存储，存储到数据异构JIMDB集群即**Redis+持久化引擎**，存储的数据都是未加工的原子化数据，如商品基本信息、商品扩展属性、商品其他一些相关信息、商品规格参数、分类、商家信息等 数据异构Worker存储成功后，会发送一个MQ给数据同步Worker，数据同步Worker也可叫做数据聚合Worker，按照相应的维度聚合数据存储到相应的**JIMDB集群**；三个维度：基本信息（基本信息+扩展属性等的一个聚合）、商品介绍（PC版、移动版）、其他信息（分类、商家等维度，数据量小，直接Redis存储） 前端展示分为两个：商品详情页和商品介绍，使用**Nginx+Lua技术获取数据并渲染模板输出**","tags":[{"name":"springCloud","slug":"springCloud","permalink":"http://example.com/tags/springCloud/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"}]},{"title":"分布式事务解决方案","date":"2022-01-02T10:08:20.000Z","path":"blog/Cloud/分布式事务解决方案/","text":"大多数场景下应用都只需要操作单一数据库，该情况下的事务称之为本地事务(Local Transaction)。本地事务的ACID特性是数据库直接提供支持。在JDBC编程中通过**java.sql.Connection对象来开启、关闭或提交**事务。 12345678910Connection conn = ... ; //获取数据库连接conn.setAutoCommit(false); //开启事务try &#123; // 执行增删改查sql conn.commit(); // 提交事务&#125; catch (Exception e) &#123; conn.rollback(); // 事务回滚&#125; finally&#123; conn.close(); // 关闭链接&#125; 绝大部分公司都进行了数据库拆分和服务化，完成某一个业务功能可能需要横跨多个服务，操作多个数据库，需要操作的资源位于多个资源服务器上，分布式事务就是为了保证不同资源服务器的数据一致性。典型的分布式事务场景：垮库事务、分库分表、服务化。 DTP模型构成DTP模型的5个基本元素： AP应用程序Application Program：用于定义事务边界即定义事务的开始和结束，并在事务边界内对资源进行操作 RM资源管理器Resource Manager：如数据库、文件系统等，并提供访问资源的方式 TM事务管理器Transaction Manager：负责分配事务唯一标识，监控事务的执行进度，并负责事务的提交、回滚等 CRM通信资源管理器Communication Resource Manager：控制一个TM域内或者跨TM域的分布式应用之间的通信 CP通信协议Communication Protocol：提供CRM提供的分布式应用节点之间的底层通信服务 XA规范在DTP本地模型实例中，由**AP应用程序、RMs资源管理器和TM事务管理器组成，不需要其他元素，AP、RM和TM之间彼此都需要进行交互。XA规范主要作用是定义了RM-TM的交互接口，还对两阶段提交协议进行了优化**。 两阶段协议是在**OSI TP标准中提出的，在DTP参考模型中，指定了全局事务的提交要使用两阶段提交协议；而XA规范只是定义了两阶段提交协议中需要使用到的接口，也就是上述提到的RM-TM交互的接口**。 两阶段提交协议两阶段提交协议不是在XA规范中提出，但XA规范对其进行了优化，将提交过程划分为两个阶段。 第一阶段：TM通知各个RM准备提交它们的事务分支；若RM判断自己进行的工作可以被提交，则对工作内容进行持久化，再给TM肯定答复；若发生了其他情况则给TM的都是否定答复。在发送了否定答复并回滚了工作后，RM就可以丢弃该事务分支信息。 第二阶段：TM根据第一阶段各个RM prepare的结果，决定是提交还是回滚事务；若所有RM都prepare成功，则TM通知所有RM进行提交；若有RM prepare失败则TM通知所有RM回滚事务分支。 二阶段提交看起来确实能够提供原子性的操作，但二阶段提交还是有几个缺点： 同步阻塞问题：两阶段提交方案下全局事务的ACID特性是依赖于RM的，一个全局事务内部包含了多个独立的事务分支，这一组事务分支要不都成功要不都失败，各个事务分支的ACID特性共同构成了全局事务的ACID特性。可重复读隔离级别不足以保证分布式事务一致性，若使用MySQL来支持XA分布式事务最好将事务隔离级别设置为**SERIALIZABLE，而SERIALIZABLE**是四个事务隔离级别中最高且执行效率最低一个级别。 单点故障：由于协调者的重要性，一旦协调者TM发生故障，参与者RM会一直阻塞下去。尤其在第二阶段，协调者发生故障，所有参与者还都处于锁定事务资源状态中，而无法继续完成事务操作。若协调者挂掉，可重新选举一个协调者，但无法解决因为协调者宕机导致的参与者处于阻塞状态的问题 数据不一致：在第二阶段中当协调者向参与者发送commit请求之后，发生了局部网络异常或在发送commit请求过程中协调者发生故障，会导致只有一部分参与者接受到了commit请求，而在这部分参与者接到commit请求之后就会执行commit操作，但是其他部分未接到commit请求的机器则无法执行事务提交。于是整个分布式系统便出现了数据不一致性的现象。 JTA&#x2F;XA规范实现针对实现了JDBC规范中规定的实现**XADataSource接口的数据库连接池，典型的XADataSource**实现包括： MySQL官方提供的**com.mysql.jdbc.jdbc2.optional.MysqlXADataSource** 阿里巴巴开源的druid连接池，对应的实现类为**com.alibaba.druid.pool.xa.DruidXADataSource** tomcat-jdbc连接池提供的**org.apache.tomcat.jdbc.pool.XADataSource** 123456&lt;!-- MySQL JDBC实现了XA规范 --&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.39&lt;/version&gt;&lt;/dependency&gt; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// true表示打印XA语句,，用于调试boolean logXaCommands = true;// 获得资源管理器操作接口实例 RM1Connection conn1 = DriverManager.getConnection(&quot;jdbc:mysql://localhost:3306/db_user&quot;, &quot;root&quot;, &quot;root&quot;);XAConnection xaConn1 = new MysqlXAConnection((com.mysql.jdbc.Connection) conn1, logXaCommands);XAResource rm1 = xaConn1.getXAResource();// 获得资源管理器操作接口实例 RM2Connection conn2 = DriverManager.getConnection(&quot;jdbc:mysql://localhost:3306/db_account&quot;, &quot;root&quot;, &quot;root&quot;);XAConnection xaConn2 = new MysqlXAConnection((com.mysql.jdbc.Connection) conn2, logXaCommands);XAResource rm2 = xaConn2.getXAResource();// AP请求TM执行一个分布式事务，TM生成全局事务idbyte[] gtrid = &quot;g12345&quot;.getBytes();int formatId = 1;try &#123; // ==============分别执行RM1和RM2上的事务分支==================== // TM生成rm1上的事务分支id byte[] bqual1 = &quot;b00001&quot;.getBytes(); Xid xid1 = new MysqlXid(gtrid, bqual1, formatId); // 执行rm1上的事务分支 rm1.start(xid1, XAResource.TMNOFLAGS);// One of TMNOFLAGS, TMJOIN, or TMRESUME. PreparedStatement ps1 = conn1.prepareStatement(&quot;INSERT into user(name) VALUES (&#x27;Eleven&#x27;)&quot;); ps1.execute(); rm1.end(xid1, XAResource.TMSUCCESS); // TM生成rm2上的事务分支id byte[] bqual2 = &quot;b00002&quot;.getBytes(); Xid xid2 = new MysqlXid(gtrid, bqual2, formatId); // 执行rm2上的事务分支 rm2.start(xid2, XAResource.TMNOFLAGS); PreparedStatement ps2 = conn2.prepareStatement(&quot;INSERT into account(user_id, money) VALUES (1, 10000000)&quot;); ps2.execute(); rm2.end(xid2, XAResource.TMSUCCESS); // ===================两阶段提交================================ // phase1：询问所有的RM 准备提交事务分支 int rm1_prepare = rm1.prepare(xid1); int rm2_prepare = rm2.prepare(xid2); // phase2：提交所有事务分支 boolean onePhase = false; //TM判断有2个事务分支，所以不能优化为一阶段提交 if (rm1_prepare == XAResource.XA_OK &amp;&amp; rm2_prepare == XAResource.XA_OK) &#123; // 所有事务分支都prepare成功，提交所有事务分支 rm1.commit(xid1, onePhase); rm2.commit(xid2, onePhase); &#125; else &#123;// 如果有事务分支没有成功，则回滚 rm1.rollback(xid1); rm2.rollback(xid2); &#125;&#125; catch (XAException e) &#123; // 如果出现异常，也要进行回滚 e.printStackTrace();&#125; 开源框架**Atomikos：TransactionEssentials开源的免费产品，ExtremeTransactions**上商业版需要收费。 TransactionEssentials实现了**JTA/XA规范中的事务管理器应该实现的相关接口，如UserTransaction实现了com.atomikos.icatch.jta.UserTransactionImp，用户只需要直接操作该类，TransactionManager实现了com.atomikos.icatch.jta.UserTransactionManager，Transaction**实现了com.atomikos.icatch.jta.TransactionImp。 123456789101112&lt;!-- JTA规范扩展包 --&gt;&lt;dependency&gt; &lt;groupId&gt;javax.transaction&lt;/groupId&gt; &lt;artifactId&gt;jta&lt;/artifactId&gt; &lt;version&gt;1.1&lt;/version&gt;&lt;/dependency&gt;&lt;!-- atomikos JTA/XA全局事务 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.atomikos&lt;/groupId&gt; &lt;artifactId&gt;transactions-jdbc&lt;/artifactId&gt; &lt;version&gt;4.0.6&lt;/version&gt;&lt;/dependency&gt; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465private static AtomikosDataSourceBean createAtomikosDataSourceBean(String dbName) &#123; // 连接池基本属性 Properties p = new Properties(); p.setProperty(&quot;url&quot;, &quot;jdbc:mysql://localhost:3306/&quot; + dbName); p.setProperty(&quot;user&quot;, &quot;root&quot;); p.setProperty(&quot;password&quot;, &quot;root&quot;); // 使用AtomikosDataSourceBean封装com.mysql.jdbc.jdbc2.optional.MysqlXADataSource AtomikosDataSourceBean ds = new AtomikosDataSourceBean(); // 设置resourceName 唯一 ds.setUniqueResourceName(dbName); ds.setXaDataSourceClassName(&quot;com.mysql.jdbc.jdbc2.optional.MysqlXADataSource&quot;); ds.setXaProperties(p); return ds;&#125;public static void main(String[] args) &#123; AtomikosDataSourceBean ds1 = createAtomikosDataSourceBean(&quot;db_user&quot;); AtomikosDataSourceBean ds2 = createAtomikosDataSourceBean(&quot;db_account&quot;); Connection conn1 = null; Connection conn2 = null; PreparedStatement ps1 = null; PreparedStatement ps2 = null; UserTransaction userTransaction = new UserTransactionImp(); try &#123; // 开启事务 userTransaction.begin(); // 执行db1上的sql conn1 = ds1.getConnection(); ps1 = conn1.prepareStatement(&quot;INSERT into user(name) VALUES (?)&quot;, Statement.RETURN_GENERATED_KEYS); ps1.setString(1, &quot;Eleven&quot;); ps1.executeUpdate(); ResultSet generatedKeys = ps1.getGeneratedKeys(); int userId = -1; while (generatedKeys.next()) &#123; // 获得自动生成的userId userId = generatedKeys.getInt(1); &#125; // 模拟异常 ，直接进入catch代码块，2个都不会提交 // int i=1/0; // 执行db2上的sql conn2 = ds2.getConnection(); ps2 = conn2.prepareStatement(&quot;INSERT into account(user_id,money) VALUES (?,?)&quot;); ps2.setInt(1, userId); ps2.setDouble(2, 10000000); ps2.executeUpdate(); // 两阶段提交 userTransaction.commit(); &#125; catch (Exception e) &#123; try &#123; e.printStackTrace(); userTransaction.rollback(); &#125; catch (SystemException e1) &#123; e1.printStackTrace(); &#125; &#125; finally &#123; try &#123; ps1.close(); ps2.close(); conn1.close(); conn2.close(); ds1.close(); ds2.close(); &#125; catch (Exception ignore) &#123; &#125; &#125;&#125; Seata AT模式Seata相比与其它分布式事务框架有以下几个优势: 应用层基于SQL解析实现了自动补偿，从而最大程度的降低业务侵入性 将分布式事务中TC事务协调者独立部署，负责事务的注册、回滚 通过全局锁实现了写隔离与读隔离 Seata提供了**AT、TCC、SAGA和XA事务模式，AT模式是Seata首推模式，Seata有TC事务协调者、TM事务管理器、RM资源管理器三大角色，TC为单独部署的Server服务端，TM和RM为嵌入到应用中的Client客户端** TC事务协调者：维护全局和分支事务的状态驱动全局事务提交或回滚 TM事务管理器：定义全局事务的范围开始全局事务、提交或回滚全局事务 RM资源管理器：管理分支事务处理的资源，与TC交谈以注册分支事务和报告分支事务状态，并驱动分支事务提交或回滚 TM请求TC开启一个全局事务，TC会生成一个XID作为该全局事务的编号，**XID会在微服务的调用链路中传播，保证将多个微服务的子事务关联在一起；RM请求TC将本地事务注册为全局事务的分支事务，通过全局事务的XID进行关联**；TM请求TC告诉XID对应的全局事务是进行提交还是回滚；TC驱动RM们将XID对应的自己的本地事务进行提交还是回滚。 AT模式的核心是对业务无侵入，是一种改进后的两阶段提交，前提是基于支持本地ACID事务的关系型数据库，**Java应用通过JDBC访问数据库**。通过两阶段提交： 一阶段：业务数据和回滚日志记录在同一个本地事务中提交，释放本地锁和连接资源，本地事务提交前，需确保先拿到全局锁，否则不能提交本地事务，且拿全局锁的尝试被限制在一定范围内，超出范围将放弃，并回滚本地事务释放本地锁 二阶段：提交异步化非常快速地完成，回滚通过一阶段的回滚日志进行反向补偿 一阶段会解析SQL类型是更新删除还是新增、表名、条件等相关信息，根据解析得到的条件信息，生成查询语句定位数据生成前置镜像，然后执行业务SQL，根据前镜像的结果，通过主键定位数据得到后置镜像，把前置镜像和后置镜像数据以及业务SQL相关的信息组成一条回滚日志记录，插入到**UNDO_LOG表中。提交前向TC注册分支申请目标表中，对应主键值的记录的全局锁，业务数据的更新和前面步骤中生成的UNDO LOG**一并提交，将本地事务提交的结果上报给TC。 二阶段回滚，收到TC分支回滚请求，开启一个本地事务，通过XID和Branch ID查找到相应的UNDO LOG记录，拿 UNDO LOG中的后镜与当前数据进行比较，若有不同说明数据被当前全局事务之外的动作做了修改。该情况需要根据配置策略来做处理，根据UNDO LOG中前镜像和业务SQL相关信息生成并执行回滚的语句，提交本地事务并把本地事务的执行结果即分支事务回滚结果上报给TC事务协调者。 二阶段提交，即分布式事务操作成功，**TC通知RM异步删除undolog，收到TC分支提交请求，把请求放入一个异步任务队列中，马上返回提交成功结果给TC，异步任务阶段的分支提交请求将异步和批量地删除相应UNDO LOG记录**。 Seata AT模式存在的问题： 性能损耗：一条Update的SQL需要与TC通讯获取全局事务xid、before image解析SQL查询一次数据库、after image查询一次数据库、insert undo log写一次数据库、before commit与TC通讯判断锁冲突，这些操作都需要同步远程通讯RPC，且undo log写入时blob字段插入性能也不高。每条写SQL都会增加这么多开销，粗略估计会增加5倍响应时间 性价比：为了进行自动补偿，需要对所有交易生成前后镜像并持久化，在实际业务场景下分布式事务失败需要回滚的有多少比率，按照二八原则预估，为了20%的交易回滚，需要将80%的成功交易的响应时间增加5倍，这样的代价相比于让应用开发一个补偿交易是否是值得 全局锁：相比XA，Seata虽然在一阶段成功后会释放数据库锁，但一阶段在commit前全局锁的判定也拉长了对数据锁的占有时间，这个开销比XA的prepare低多少需要根据实际业务场景进行测试。全局锁的引入实现了隔离性，但带来的问题就是阻塞，降低并发性，尤其是热点数据，这个问题会更加严重。 回滚锁释放时间：Seata在回滚时，需要先删除各节点的undo log，然后才能释放TC内存中的锁，所以若第二阶段是回滚，释放锁的时间会更长 死锁问题：Seata的引入全局锁会额外增加死锁风险，若出现死锁会不断进行重试，最后靠等待全局锁超时，这种方式并不优雅，也延长了对数据库锁的占有时间 柔性事务TCCTCC是比较常用的一种柔性事务方案。开源的TCC框架：**Tcc-Transaction、Hmily、ByteTCC、EasyTransaction、Seata TCC**。 TCC两阶段提交与XA两阶段提交的区别是：XA是资源层面的分布式事务，强一致性，在两阶段提交的整个过程中，一直会持有资源的锁，TCC是业务层面的分布式事务，最终一致性，不会一直持有资源的锁。 TCC事务的优点是有效了的避免了XA两阶段提交占用资源锁时间过长导致的性能底下的问题。相对于AT模式，TCC模式对业务代码有一定的侵入性，但TCC模式无AT模式的全局行锁，TCC性能会比AT模式高很多。 TCC事务的缺点是主业务服务和从业务服务都需要进行改造，从业务方改造成本更高。原来只需要提供一个接口，现在需要改造成**try、confirm、canel**三个接口开发成本高。 空回滚在没有调用TCC资源Try方法的情况下，调用了二阶段的Cancel方法，Cancel方法需要识别出这是一个空回滚，然后直接返回成功，空回滚出现的原因是**Try超时丢包，分布式事务回滚触发Cancel，出现未收到Try，收到Cancel的情况**。 悬挂悬挂即**Cancel比Try先执行，要运行空回滚，但要拒绝空回滚之后的Try操作，悬挂出现的原因是Try超时拥堵，分布式事务回滚触发Cancel，之后拥堵的Try到达**。 幂等控制Try，Confirm，Cancel都需要保证幂等性，因为网络抖动或拥堵可能会超时，事务管理器会对资源进行重试操作，所以很可能一个业务操作会被重复调用，为了不因为重复调用而多次占用资源，需要对服务设计时进行幂等控制，通常可用事务xid或业务主键判重来控制。 TCC设计注意事项以扣钱场景为例，场景为A转账30元给B，A和B账户在不同的服务。在微服务架构下，很有可能出现网络超时、重发，机器宕机等一系列的异常，出现空回滚、幂等、悬挂的问题。 对于以下示例，都是先执行账户A的try方法，从而执行账户B的try方法，若成功则执行账户A的confirm方法，然后执行账户B的confirm方法，若失败则执行账户A的concel方法，然后再执行账户B的cancel方法。 方案A方案C优于方案B优于方案A 123456789101112131415# 账户Atry： 检查余额是否够30元 扣减30元confirm： 空cancel： 增加30元# 账户Btry： 增加30元 confirm： 空 cancel： 减少30元 方案B123456789101112131415# 账户Atry： 检查余额是否够30元 扣减30元confirm： 空 cancel： 增加30元# 账户Btry： 空 confirm： 增加30元 cancel： 空 方案C需要创建**local_transaction_log日志表用于幂等性、空回滚、try悬挂处理**时校验 1234567891011121314151617181920# 账户Atry： try幂等校验 try悬挂处理 检查余额是否够30元 扣减30元 confirm： 空 cancel： cancel幂等校验 cancel空回滚处理 增加可用余额30元# 账户Btry： 空confirm： confirm幂等校验 正式增加30元cancel： 空 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273@Service@Slf4jpublic class AccountServiceImpl implements AccountService &#123; @Autowired AccountMapper accountMapper; @Autowired Bank2FeignClient bank2FeignClient; // try方法执行逻辑：try幂等校验，try悬挂处理，检查余额是否足够扣减，扣减金额 // 只要标记@Hmily就是try方法，在注解中指定confirm、cancel两个方法的名字 @Transactional(timeout = 60) @Hmily(confirmMethod = &quot;commit&quot;, cancelMethod = &quot;rollback&quot;) @Override public void transfer(String fromAccountNo, String toAccountNo, Double amount) &#123; // 获取全局事务id String transId = HmilyTransactionContextLocal.getInstance().get().getTransId(); log.info(&quot;bank1 try begin 开始执行...xid:&#123;&#125;&quot;, transId); // 幂等判断 判断local_transaction_log表中是否有try日志记录，如果有则不再执行 if (accountMapper.isExistTransactionLogByType(transId, TransactionEnum.TRY.getValue()) &gt; 0) &#123; log.info(&quot;bank1 try 已经执行，无需重复执行,xid:&#123;&#125;&quot;, transId); return; &#125; // try悬挂处理，如果cancel、confirm有一个已经执行了，try不再执行 if (accountMapper.isExistTransactionLogByType(transId, TransactionEnum.CONFIRM.getValue()) &gt; 0 || accountMapper.isExistTransactionLogByType(transId, TransactionEnum.CANCEL.getValue()) &gt; 0) &#123; log.info(&quot;bank1 try悬挂处理 cancel或confirm已经执行，不允许执行try,xid:&#123;&#125;&quot;, transId); return; &#125; // 扣减金额 if (accountMapper.subtractAccountBalance(fromAccountNo, amount) &lt;= 0) &#123; // 扣减失败 throw new RuntimeException(&quot;bank1 try 扣减金额失败,xid:&quot; + transId); &#125; // 插入try执行记录,用于幂等判断 accountMapper.addTransactionLog(transId, TransactionEnum.TRY.getValue()); // 转账,远程调用bank2 if (!bank2FeignClient.transferTo(toAccountNo, amount)) &#123; throw new RuntimeException(&quot;bank1 远程调用bank2微服务失败,xid:&quot; + transId); &#125; log.info(&quot;bank2 request end 结束执行...xid:&#123;&#125;&quot;, transId); if (amount == 20) &#123; throw new RuntimeException(&quot;人为制造异常,xid:&quot; + transId); &#125; log.info(&quot;bank1 try end 结束执行...xid:&#123;&#125;&quot;, transId); &#125; @Transactional public void commit(String fromAccountNo, String toAccountNo, Double amount) &#123; // 获取全局事务id String transId = HmilyTransactionContextLocal.getInstance().get().getTransId(); log.info(&quot;bank1 confirm begin 开始执行...xid:&#123;&#125;,accountNo:&#123;&#125;,amount:&#123;&#125;&quot;, transId, fromAccountNo, amount); &#125; // cancel方法执行逻辑： 1.cancel幂等校验 2.cancel空回滚处理 3.增加可用余额 @Transactional(timeout = 60) public void rollback(String fromAccountNo, String toAccountNo, Double amount) &#123; // 获取全局事务id String transId = HmilyTransactionContextLocal.getInstance().get().getTransId(); log.info(&quot;bank1 cancel begin 开始执行...xid:&#123;&#125;&quot;, transId); // cancel幂等校验 if (accountMapper.isExistTransactionLogByType(transId, TransactionEnum.CANCEL.getValue()) &gt; 0) &#123; log.info(&quot;bank1 cancel 已经执行，无需重复执行,xid:&#123;&#125;&quot;, transId); return; &#125; // cancel空回滚处理，如果try没有执行，cancel不允许执行 if (accountMapper.isExistTransactionLogByType(transId, TransactionEnum.TRY.getValue()) &lt;= 0) &#123; log.info(&quot;bank1 空回滚处理，try没有执行，不允许cancel执行,xid:&#123;&#125;&quot;, transId); return; &#125; // 增加可用余额 accountMapper.addAccountBalance(fromAccountNo, amount); //插入一条cancel的执行记录 accountMapper.addTransactionLog(transId, TransactionEnum.CANCEL.getValue()); log.info(&quot;bank1 cancel end 结束执行...xid:&#123;&#125;&quot;, transId); &#125;&#125; 上面的设计并不能进行并发控制，即隔离性的保证，对业务模型进行优化，在业务模型中增加冻结金额字段，用来表示账户有多少金额处以冻结状态。 对于用户下单场景，整个业务逻辑由仓储服务、订单服务、帐户服务三个微服务构成，分别完成对给定的商品扣除库存数量、根据采购需求创建订单、从用户帐户中扣除余额。 柔性事务：可靠消息最终一致性方案实现本地消息表方案本地消息表这个方案最初是eBay提出的，此方案的核心是通过本地事务保证数据业务操作和消息的一致性，然后通过定时任务将消息发送至消息中间件，待确认消息发送给消费方成功再将消息删除。 Rocketmq事务消息实现 柔性事务：最大努力通知最大努力通知型是最简单的一种柔性事务，是分布式事务中对一致性要求最低的一种，适用于一些最终一致性时间敏感度低的业务，且被动方处理结果不影响主动方的处理结果，典型的使用场景：银行通知、商户通知等。最大努力通知型的实现方案，一般符合以下特点，且需要实现消息重复通知机制、息校对机制： 不可靠消息：业务活动主动方，在完成业务处理之后，向业务活动的被动方发送消息，直到通知N次后不再通知，允许消息丢失 定期校对：业务活动的被动方，根据定时策略，向业务活动主动方查询，主动方提供查询接口，恢复丢失的业务消息","tags":[{"name":"springCloud","slug":"springCloud","permalink":"http://example.com/tags/springCloud/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"}]},{"title":"ElasticSearch-Springboot","date":"2022-01-02T06:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/ElasticSearch/ElasticSearch-Springboot/","text":"版本问题springboot 有一个 spring data 组件，可以用来连接各种数据源。 用来连接 elasticsearch 的是 spring-data-elasticsearch。 启动 elasticsearch运行elasticsearch.bat, 启动后, 可以看到左上角的版本号。 创建 springboot 项目:pom.xml各种jar包，主要是 spring-boot-starter-data-elastisearch 这个 jar包。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.howToElasticSearch&lt;/groupId&gt; &lt;artifactId&gt;springboot&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;springboot&lt;/name&gt; &lt;description&gt;springboot&lt;/description&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.9.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- servlet依赖. --&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- tomcat的支持.--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt; &lt;artifactId&gt;tomcat-embed-jasper&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;!-- 这个需要为 true 热部署才有效 --&gt; &lt;/dependency&gt; &lt;!-- mysql--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.21&lt;/version&gt; &lt;/dependency&gt; &lt;!-- elastisearch依赖包 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-elasticsearch&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; Category.javaCategory 实体类，其中的 @Document就表明了要连接到 ElasticSearch 的哪个索引和哪个 type 上 @Document(indexName &#x3D; “howToElasticSearch”,type &#x3D; “category”)索引相当于就是数据库，type 相当于就是表 1234567891011121314151617181920212223package cn.peach.springboot.pojo; import org.springframework.data.elasticsearch.annotations.Document; @Document(indexName = &quot;howToElasticSearch&quot;,type = &quot;category&quot;)public class Category &#123; private int id; private String name; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; &#125; 控制类：CategoryController.java控制类提供 CRUD 一套 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889package cn.peach.springboot.web;import java.text.SimpleDateFormat;import java.util.Date;import org.elasticsearch.index.query.QueryBuilders;import org.elasticsearch.index.query.functionscore.FunctionScoreQueryBuilder;import org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.domain.Page;import org.springframework.data.domain.PageRequest;import org.springframework.data.domain.Pageable;import org.springframework.data.domain.Sort;import org.springframework.data.elasticsearch.core.query.NativeSearchQueryBuilder;import org.springframework.data.elasticsearch.core.query.SearchQuery;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam;import cn.peach.springboot.dao.CategoryDAO;import cn.peach.springboot.pojo.Category; @Controllerpublic class CategoryController &#123; @Autowired CategoryDAO categoryDAO; //每页数量 @GetMapping(&quot;/listCategory&quot;) public String listCategory(Model m,@RequestParam(value = &quot;start&quot;, defaultValue = &quot;0&quot;) int start,@RequestParam(value = &quot;size&quot;, defaultValue = &quot;5&quot;) int size)&#123; String query = &quot;商品&quot;; //查询条件，但是并未使用，放在这里，为的是将来使用，方便参考，知道如何用 SearchQuery searchQuery=getEntitySearchQuery(start,size,query); Page&lt;Category&gt; page = categoryDAO.search(searchQuery); m.addAttribute(&quot;page&quot;, page); return &quot;listCategory&quot;; &#125; private SearchQuery getEntitySearchQuery(int start, int size, String searchContent) &#123; FunctionScoreQueryBuilder functionScoreQueryBuilder = QueryBuilders.functionScoreQuery() .add(QueryBuilders.matchAllQuery(), //查询所有 ScoreFunctionBuilders.weightFactorFunction(100))// 查询条件，但是并未使用，放在这里，为的是将来使用，方便参考，知道如何用// .add(QueryBuilders.matchPhraseQuery(&quot;name&quot;, searchContent),// ScoreFunctionBuilders.weightFactorFunction(100)) //设置权重分 求和模式 .scoreMode(&quot;sum&quot;) //设置权重分最低分 .setMinScore(10); // 设置分页 Sort sort = new Sort(Sort.Direction.DESC,&quot;id&quot;); Pageable pageable = new PageRequest(start, size,sort); return new NativeSearchQueryBuilder() .withPageable(pageable) .withQuery(functionScoreQueryBuilder).build(); &#125; @RequestMapping(&quot;/addCategory&quot;) public String addCategory(Category c) throws Exception &#123; int id = currentTime(); c.setId(id); categoryDAO.save(c); return &quot;redirect:listCategory&quot;; &#125; private int currentTime() &#123; SimpleDateFormat sdf = new SimpleDateFormat(&quot;MMddHHmmss&quot;); String time= sdf.format(new Date()); return Integer.parseInt(time); &#125; @RequestMapping(&quot;/deleteCategory&quot;) public String deleteCategory(Category c) throws Exception &#123; categoryDAO.delete(c); return &quot;redirect:listCategory&quot;; &#125; @RequestMapping(&quot;/updateCategory&quot;) public String updateCategory(Category c) throws Exception &#123; categoryDAO.save(c); return &quot;redirect:listCategory&quot;; &#125; @RequestMapping(&quot;/editCategory&quot;) public String ediitCategory(int id,Model m) throws Exception &#123; Category c= categoryDAO.findOne(id); m.addAttribute(&quot;c&quot;, c); return &quot;editCategory&quot;; &#125;&#125; 配置文件：application.properties配置 jsp 作为视图配置spring端口 为8080配置 elastic链接地址为 127.0.0.1:9300 1234spring.mvc.view.prefix=/WEB-INF/jsp/spring.mvc.view.suffix=.jspserver.port=8080spring.data.elasticsearch.cluster-nodes = 127.0.0.1:9300 启动并测试:运行 Application.java 启动项目, 接着访问地址： 1http://127.0.0.1:8080/listCategory kibana查看数据启动 kibana 并访问: http://127.0.0.1:5601, 选择索引刚开始是没有选定索引的，所以要自己指定索引。 把默认勾选的 Index contians time-based evens 去掉 输入 howToElasticSearch 点击 Create 按钮 查看数据然后点击上面的Discover，就可以看到左边是当前的索引 :howToElasticSearch. 右边就是数据了。","tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"http://example.com/tags/ElasticSearch/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"ElasticSearch","slug":"工具和中间件/搜索引擎技术/ElasticSearch","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/ElasticSearch/"}]},{"title":"ElasticSearch工具-Kibana","date":"2022-01-02T05:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/ElasticSearch/ElasticSearch工具-Kibana/","text":"Kibana 是什么Kibana 是一个针对 ElasticSearch 的开源分析及可视化平台，用来搜索、查看交互存储在 ElasticSearch 索引中的数据。使用 Kibana，可以通过各种图表进行高级数据分析及展示。 Kibana 是在ElasticSearch 有了相当多的数据之后，进行分析这些数据用的工具。 但是现在还么有数据呀，为什么就要介绍这个工具呢？ 因为Kibana 里面有一个叫做 Dev Tools的，可以很方便地以Restful 风格向 ElasticSearch 服务器提交请求。Kibana 让海量数据更容易理解。它操作简单，基于浏览器的用户界面可以快速创建仪表板（DashBoard）实时显示 ElasticSearch 查询动态。 官网下载(https://www.elastic.co/cn/kibana/)下载rar，并解压。 假设下载路径在：C:\\Users\\X7TI运行启动中的 kibana.bat 1C:\\Users\\X7TI\\Downloads\\kibana-6.2.2-windows-x86_64\\bin\\kibana.bat 验证启动浏览器输入 http://localhost:5601/app/kibana#/dev_tools/console?_g=(), 打开当前的开发工具 Dev Tools 界面 运行测试在控制台里输入 1GET /_cat/health?v 然后点击绿色箭头进行运行，就可以看到右侧出现查询结果GET &#x2F;_cat&#x2F;health?v 这个命令用来查看服务器状态（健康度）， green 表示一切OK。 索引概念索引相当于就是一个数据库服务器上的某个数据库，所以索引也可以看成是Elastic Search里的某个数据库 Restful 风格管理索引，管理无非就是增删改查，即 CRUD。在使用Restful风格之前，进行所以管理需要这样的访问地址： add,delete,update,get 等不同的访问地址来表示不同的业务请求。但是使用Restful 风格，就通过提交不同的method 来表示 CRUD： PUT 表示增加 GET 表示获取 DELETE 表示删除 POST表示更新 增加索引:在 kibana 控制台中输入如下命令：打开 kibana控制台： 1http://localhost:5601/app/kibana#/dev_tools/console?_g=() 运行如下命令： 1PUT /howToKibana?pretty 返回： 12345&#123; &quot;acknowledged&quot;: true, &quot;shards_acknowledged&quot;: true, &quot;index&quot;: &quot;howToKibana&quot;&#125; 表示创建成功了，索引名称是howToKibana注： 要运行kibana控制台，需要先安装kibana: 查询运行如下命令： 1GET /_cat/indices?v 可以观察到新建立的索引 删除运行如下命令：DELETE &#x2F;howToKibana?pretty再运行 1GET /_cat/indices?v 可以观察到索引howToKibana被删除了，右侧一个索引也看不到了 修改修改两种方式， 第一种还是用PUT，PUT本来用来做增加的，但是当输入的id已经存在的时候，就自动变成修改功能了; 第二种使用 POST，这才是正规的修改，其实和第一种效果一样的。 批量导入批量导入两条数据在 kibana 控制台中输入如下命令：打开 kibana控制台： 1http://localhost:5601/app/kibana#/dev_tools/console?_g=() 运行如下命令： 12345POST _bulk&#123;&quot;index&quot;:&#123;&quot;_index&quot;:&quot;howToKibana&quot;,&quot;_type&quot;:&quot;product&quot;,&quot;_id&quot;:10001&#125;&#125;&#123;&quot;code&quot;:&quot;540785126782&quot;,&quot;price&quot;:398,&quot;name&quot;:&quot;房屋卫士自流平美缝剂瓷砖地砖专用双组份真瓷胶防水填缝剂镏金色&quot;,&quot;place&quot;:&quot;上海&quot;,&quot;category&quot;:&quot;品质建材&quot;&#125;&#123;&quot;index&quot;:&#123;&quot;_index&quot;:&quot;howToKibana&quot;,&quot;_type&quot;:&quot;product&quot;,&quot;_id&quot;:10002&#125;&#125;&#123;&quot;code&quot;:&quot;24727352473&quot;,&quot;price&quot;:21.799999237060547,&quot;name&quot;:&quot;艾瑞泽手工大号小号调温热熔胶枪玻璃胶枪硅胶条热溶胶棒20W-100W&quot;,&quot;place&quot;:&quot;山东青岛&quot;,&quot;category&quot;:&quot;品质建材&quot;&#125; 注： 要运行kibana控制台，需要先安装kibana并启动 注： 其中的product在elastic search里是type的概念，相当于数据库里的表，这里就相当于向 product 表里插入了一条数据 验证插入的数据使用命令查询howToKibana 索引里所有的数据： 1234GET /howToKibana/_search&#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;&#125; 可以看到刚刚批量插入的两条数据.","tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"http://example.com/tags/ElasticSearch/"},{"name":"Kibana","slug":"Kibana","permalink":"http://example.com/tags/Kibana/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"ElasticSearch","slug":"工具和中间件/搜索引擎技术/ElasticSearch","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/ElasticSearch/"}]},{"title":"ElasticSearch进阶","date":"2022-01-02T04:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/ElasticSearch/ElasticSearch进阶/","text":"分值计算首先根据用户query条件,过滤出包含指定term的doc,Field-length norm即field长度越长相关度越弱。 123query &quot;hello world&quot; --&gt; hello / world / hello &amp; worldbool --&gt; must/must not/should --&gt; 过滤 --&gt; 包含 / 不包含 / 可能包含doc --&gt; 不打分数 --&gt; 正或反 true or false --&gt; 为了减少后续要计算的doc的数量,提升性能 relevance score算法：计算出一个 索引中文本 与 搜索文本 之间 关联匹配程度,ES使用 term frequency/inverse document frequency算法 简称为 TF/IDF 算法。 Term frequency 即 搜索文本 中 各个词条 在 field 文本中 出现次数,次数越多越相关 。Inverse document frequency 即 搜索文本 中 各个词条 在 整个索引所有文档 中 出现次数,出现次数越多越不相关 。 向量空间模型vector space model向量空间模型,多个term对一个doc的总分数,es会根据查询字符串在所有doc中的评分情况,计算出一个 query vector 即 query向量,会给每一个doc,拿每个term计算出一个分数来。每个doc vector计算出对 query vector 的 弧度,最后基于该弧度给出一个doc相对于query中多个term的总分数,弧度越大分数越低,弧度越小分数越高 。若是多个term,那么就是线性代数来计算,无法用图表示若查询条件字符串为hello world,hello这个term,给的基于所有doc的一个评分就是3,world这个term,给的基于所有doc的一个评分就是6,则 query向量 为 [3, 6],若3个doc一个包含hello,一个包含world,一个包含hello和world,doc向量分别为[3, 0]、[0, 6]、[3, 6] 分词器工作流程首先进行 normalization切分词语,将目标文本拆分成单个单词,同时对每个单词进行 normalization时态转换单复数转换、分词器recall、搜索时召回率、增加能搜索到的结果的数量 。分词器将文本进行各种处理,最后处理好的结果才会用来建立倒排索引 。 123character filter：在一段文本进行分词之前,先进行预处理,如过滤html标签（&lt;span&gt;hello&lt;span&gt; --&gt; hello）,&amp; --&gt; and (I&amp;you --&gt; I and you)tokenizer：分词,hello you and me --&gt; hello, you, and, metoken filter：lowercase,stop word,synonymom,liked --&gt; like,Tom --&gt; tom,a/the/an --&gt; 干掉,small --&gt; little 对于默认的 standard分词器 ： standard tokenizer： 以单词边界进行切分 standard token filter：什么都不做 lowercase token filter：将所有字母转换为小写 stop token filer：默认被禁用,移除停用词,比如a the it等等1234567891011121314151617181920212223242526272829303132333435363738394041424344454647POST _analyze&#123; &quot;analyzer&quot;: &quot;standard&quot;, &quot;text&quot;: &quot;Set the shape to semi-transparent by calling set_trans(5)&quot;&#125;PUT /my_index&#123; &quot;settings&quot;: &#123; &quot;analysis&quot;: &#123; &quot;analyzer&quot;: &#123; &quot;es_std&quot;: &#123; &quot;type&quot;: &quot;standard&quot;, &quot;stopwords&quot;: &quot;_english_&quot; // 启用english停用词token filter &#125; &#125; &#125; &#125;&#125;GET /my_index/_analyze&#123; &quot;analyzer&quot;: &quot;standard&quot;, &quot;text&quot;: &quot;a dog is in the house&quot;&#125;GET /my_index/_analyze&#123; &quot;analyzer&quot;: &quot;es_std&quot;, &quot;text&quot;:&quot;a dog is in the house&quot;&#125;PUT /my_index // 定制化分词器&#123; &quot;settings&quot;: &#123; &quot;analysis&quot;: &#123; &quot;char_filter&quot;: &#123;&quot;&amp;_to_and&quot;: &#123;&quot;type&quot;: &quot;mapping&quot;,&quot;mappings&quot;: [&quot;&amp;=&gt; and&quot;]&#125;&#125;, &quot;filter&quot;: &#123;&quot;my_stopwords&quot;: &#123;&quot;type&quot;: &quot;stop&quot;,&quot;stopwords&quot;: [&quot;the&quot;,&quot;a&quot;]&#125; &#125;, &quot;analyzer&quot;: &#123; &quot;my_analyzer&quot;: &#123;&quot;type&quot;: &quot;custom&quot;,&quot;char_filter&quot;: [&quot;html_strip&quot;,&quot;&amp;_to_and&quot;],&quot;tokenizer&quot;: &quot;standard&quot;,&quot;filter&quot;: [&quot;lowercase&quot;,&quot;my_stopwords&quot;]&#125; &#125; &#125; &#125;&#125;GET /my_index/_analyze&#123; &quot;text&quot;: &quot;tom&amp;jerry are a friend in the house, &lt;a&gt;, HAHA!!&quot;, &quot;analyzer&quot;: &quot;my_analyzer&quot;&#125; IK分词器IK分词器配置文件地址为 es/plugins/ik/config,ik原生最重要的是 main.dic 和 stopword.dic 两个配置文件 IKAnalyzer.cfg.xml：用来配置自定义词库 main.dic：ik原生内置中文词库,总共有27万多条,会按照该文件中的词语去分词 quantifier.dic：单位相关的词 suffix.dic：后缀相关的词 surname.dic：中国姓氏 stopword.dic：英文停用词,停用词会在分词时被干掉,不会建立在倒排索引中 可通过在 IKAnalyzer.cfg.xml 配置文件中通过修改 &lt;entry key=&quot;ext_dict&quot;&gt;&lt;/entry&gt; 配置内容 扩展自己的词库,需重启es才能生效,还可以通过修改 &lt;entry key=&quot;ext_stopwords&quot;&gt;&lt;/entry&gt; 配置扩展停用词 。 每次在es扩展词典中,手动添加新词语,添加完都要重启es才能生效,非常麻烦,且es是分布式的,可能有数百个节点,不能每次都一个一个节点上面去修改。 IKAnalyzer.cfg.xml 配置文件中可通过 &lt;entry key=&quot;remote_ext_dict&quot;&gt;words_location&lt;/entry&gt; 和 &lt;entry key=&quot;remote_ext_stopwords&quot;&gt;words_location&lt;/entry&gt; 配置支持 远程扩展字典 。 高亮显示搜索中经常需要对搜索关键字做高亮显示,ES默认通过添加 &lt;em&gt;&lt;/em&gt;标签,在HTML中会变成红色,指定的field中若包含了搜索词,就会在那个field文本中,对搜索词进行红色高亮显示。highlight中的field必须跟 query 中field一一对齐 默认的 highlight 为 plain highlight 即 lucene highlight,在 mapping 中设置 index_options 为 offsets 使用 posting highlight 。在 mapping 中设置 term_vector 为 term_vector 使用 fast verctor highlight,对 大于1mb的field性能更高 。也可通过在查询时强制使用某种highlighter 。 一般情况下用 plain highlight 也就足够了,不需要做其他额外设置,若对高亮性能要求很高,可尝试启用 posting highlight,若 field值特别大超过了1M,则可用 fast vector highlight 。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455PUT /news_website&#123; &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123; &quot;title&quot;: &#123;&quot;type&quot;: &quot;text&quot;,&quot;analyzer&quot;: &quot;ik_max_word&quot;&#125;, &quot;content&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;index_options&quot;: &quot;offsets&quot; &#125; &#125; &#125;&#125;PUT /news_website&#123; &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123; &quot;title&quot;: &#123;&quot;type&quot;: &quot;text&quot;,&quot;analyzer&quot;: &quot;ik_max_word&quot;&#125;, &quot;content&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;term_vector&quot;: &quot;with_positions_offsets&quot; &#125; &#125; &#125;&#125;GET /news_website/_doc/_search&#123; &quot;query&quot;: &#123;&quot;match&quot;: &#123;&quot;content&quot;: &quot;文章&quot;&#125;&#125;, &quot;highlight&quot;: &#123; &quot;fields&quot;: &#123;&quot;content&quot;: &#123;&quot;type&quot;: &quot;plain&quot;&#125;&#125; &#125;&#125;GET /news_website/_doc/_search&#123; &quot;query&quot;: &#123;&quot;match&quot;: &#123;&quot;content&quot;: &quot;文章&quot;&#125;&#125;, &quot;highlight&quot;: &#123; // 设置高亮html标签,默认是&lt;em&gt;标签 &quot;pre_tags&quot;: [&quot;&lt;span color=&#x27;red&#x27;&gt;&quot;], &quot;post_tags&quot;: [&quot;&lt;/span&gt;&quot;], &quot;fields&quot;: &#123;&quot;content&quot;: &#123;&quot;type&quot;: &quot;plain&quot;&#125;&#125; &#125;&#125;GET /_search&#123; &quot;query&quot;: &#123;&quot;match&quot;: &#123;&quot;content&quot;: &quot;文章&quot;&#125;&#125;, &quot;highlight&quot;: &#123; &quot;fields&quot;: &#123; &quot;content&quot;: &#123; &quot;fragment_size&quot;: 150, // 设置要显示出来的fragment文本长度,默认100 &quot;number_of_fragments&quot;: 3 // 指定显示高亮fragment文本片段个数 &#125; &#125; &#125;&#125;用一个大家容易理解的SQL语法来解释,如：select count(*) from table group by column。那么group by column分组后的每组数据就是bucket。对每个分组执行的count(*)就是metric。 聚合搜索bucket就是一个聚合搜索时的数据分组,metric就是对一个bucket数据执行的统计分析,metric有求和,最大值,最小值,平均值等多种统计 。如 select count(*) from table group by column 其中 group by column 分组后的 每组数据就是bucket,每个分组执行的 count(*) 就是 metric 。 1234567891011121314151617181920PUT /cars&#123;&quot;mappings&quot;:&#123;&quot;properties&quot;:&#123;&quot;price&quot;:&#123;&quot;type&quot;:&quot;long&quot;&#125;,&quot;color&quot;:&#123;&quot;type&quot;:&quot;keyword&quot;&#125;,&quot;brand&quot;:&#123;&quot;type&quot;:&quot;keyword&quot;&#125;,&quot;model&quot;:&#123;&quot;type&quot;:&quot;keyword&quot;&#125;,&quot;sold_date&quot;:&#123;&quot;type&quot;:&quot;date&quot;&#125;,&quot;remark&quot;:&#123;&quot;type&quot;:&quot;text&quot;,&quot;analyzer&quot;:&quot;ik_max_word&quot;&#125;&#125;&#125;&#125;POST /cars/_bulk&#123;&quot;index&quot;:&#123;&#125;&#125;&#123;&quot;price&quot;:258000,&quot;color&quot;:&quot;金色&quot;,&quot;brand&quot;:&quot;大众&quot;,&quot;model&quot;:&quot;大众迈腾&quot;,&quot;sold_date&quot;:&quot;2021-10-28&quot;,&quot;remark&quot;:&quot;大众中档车&quot;&#125;&#123;&quot;index&quot;:&#123;&#125;&#125;&#123;&quot;price&quot;:123000,&quot;color&quot;:&quot;金色&quot;,&quot;brand&quot;:&quot;大众&quot;,&quot;model&quot;:&quot;大众速腾&quot;,&quot;sold_date&quot;:&quot;2021-11-05&quot;,&quot;remark&quot;:&quot;大众神车&quot;&#125;&#123;&quot;index&quot;:&#123;&#125;&#125;&#123;&quot;price&quot;:239800,&quot;color&quot;:&quot;白色&quot;,&quot;brand&quot;:&quot;标志&quot;,&quot;model&quot;:&quot;标志508&quot;,&quot;sold_date&quot;:&quot;2021-05-18&quot;,&quot;remark&quot;:&quot;标志品牌全球上市车型&quot;&#125;&#123;&quot;index&quot;:&#123;&#125;&#125;&#123;&quot;price&quot;:148800,&quot;color&quot;:&quot;白色&quot;,&quot;brand&quot;:&quot;标志&quot;,&quot;model&quot;:&quot;标志408&quot;,&quot;sold_date&quot;:&quot;2021-07-02&quot;,&quot;remark&quot;:&quot;比较大的紧凑型车&quot;&#125;&#123;&quot;index&quot;:&#123;&#125;&#125;&#123;&quot;price&quot;:1998000,&quot;color&quot;:&quot;黑色&quot;,&quot;brand&quot;:&quot;大众&quot;,&quot;model&quot;:&quot;大众辉腾&quot;,&quot;sold_date&quot;:&quot;2021-08-19&quot;,&quot;remark&quot;:&quot;大众最让人肝疼的车&quot;&#125;&#123;&quot;index&quot;:&#123;&#125;&#125;&#123;&quot;price&quot;:218000,&quot;color&quot;:&quot;红色&quot;,&quot;brand&quot;:&quot;奥迪&quot;,&quot;model&quot;:&quot;奥迪A4&quot;,&quot;sold_date&quot;:&quot;2021-11-05&quot;,&quot;remark&quot;:&quot;小资车型&quot;&#125;&#123;&quot;index&quot;:&#123;&#125;&#125;&#123;&quot;price&quot;:489000,&quot;color&quot;:&quot;黑色&quot;,&quot;brand&quot;:&quot;奥迪&quot;,&quot;model&quot;:&quot;奥迪A6&quot;,&quot;sold_date&quot;:&quot;2022-01-01&quot;,&quot;remark&quot;:&quot;政府专用？&quot;&#125;&#123;&quot;index&quot;:&#123;&#125;&#125;&#123;&quot;price&quot;:1899000,&quot;color&quot;:&quot;黑色&quot;,&quot;brand&quot;:&quot;奥迪&quot;,&quot;model&quot;:&quot;奥迪A 8&quot;,&quot;sold_date&quot;:&quot;2022-02-12&quot;,&quot;remark&quot;:&quot;很贵的大A6。。。&quot;&#125; 根据color 分组统计销售数量,只执行聚合分组,ES中 最基础的聚合 为 terms,相当于SQL中的count,ES中默认为分组数据做排序,使用的是 doc_count 数据执行 降序排列 。可使用 _key 元数据根据分组后的 字段数据 执行不同的排序方案,也可根据 _count 元数据,根据分组后的统计值执行不同的排序方案 。 1234567891011GET /cars/_search&#123; &quot;aggs&quot;: &#123; &quot;group_by_color&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;color&quot;, &quot;order&quot;: &#123;&quot;_count&quot;: &quot;desc&quot;&#125; &#125; &#125; &#125;&#125; 先根据color执行聚合分组,在此分组的基础上,对组内数据执行聚合统计,组内数据的聚合统计就是 metric,同样可执行排序,因为组内有聚合统计,且对统计数据给予了命名avg_by_price,所以可根据该聚合统计数据字段名执行排序逻辑。 size可设置为0,表示不返回文档只返回聚合之后的数据,提高查询速度,若需要这些文档也可按照实际情况进行设置。对聚合统计数据进行排序,若有多层 aggs 执行 下钻聚合 时也可 根据最内层聚合数据执行排序 。 1234567891011121314151617181920212223242526272829GET /cars/_search&#123; &quot;aggs&quot;: &#123; &quot;group_by_color&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;color&quot;, &quot;order&quot;: &#123;&quot;avg_by_price&quot;: &quot;asc&quot;&#125; &#125;, &quot;aggs&quot;: &#123; &quot;avg_by_price&quot;: &#123;&quot;avg&quot;: &#123;&quot;field&quot;: &quot;price&quot;&#125;&#125; &#125; &#125; &#125;&#125;GET /cars/_search&#123; &quot;size&quot;: 0, &quot;aggs&quot;: &#123; &quot;group_by_color&quot;: &#123; &quot;terms&quot;: &#123;&quot;field&quot;: &quot;color&quot;&#125;, &quot;aggs&quot;: &#123; &quot;group_by_brand&quot;: &#123; &quot;terms&quot;: &#123;&quot;field&quot;: &quot;brand&quot;,&quot;order&quot;: &#123;&quot;avg_by_price&quot;: &quot;desc&quot;&#125;&#125;, &quot;aggs&quot;: &#123;&quot;avg_by_price&quot;: &#123;&quot;avg&quot;: &#123;&quot;field&quot;: &quot;price&quot;&#125;&#125;&#125; &#125; &#125; &#125; &#125;&#125; 先根据color聚合分组,在组内根据brand再次聚合分组,这种操作可称为下钻分析,aggs若定义比较多,则会感觉语法格式混乱,aggs语法格式有一个相对固定的结构,aggs可嵌套定义也可水平定义 。嵌套定义称为下钻分析,水平定义就是平铺多个分组方式 123456789101112131415GET /index_name/type_name/_search&#123; &quot;aggs&quot;: &#123; &quot;定义分组名称&quot;: &#123; &quot;分组策略如：terms、avg、sum&quot;: &#123; &quot;field&quot;: &quot;根据哪一个字段分组&quot;, &quot;其他参数&quot;: &quot;&quot; &#125;, &quot;aggs&quot;: &#123; &quot;分组名称1&quot;: &#123;&#125;, &quot;分组名称2&quot;: &#123;&#125; &#125; &#125; &#125;&#125; 统计不同color中的最大和最小价格、总价,聚合分析最常用的种类就是统计数量,最大,最小,平均,总计等 12345678910111213141516171819202122232425262728293031GET /cars/_search&#123; &quot;aggs&quot;: &#123; &quot;group_by_color&quot;: &#123; &quot;terms&quot;: &#123;&quot;field&quot;: &quot;color&quot;&#125;, &quot;aggs&quot;: &#123; &quot;max_price&quot;: &#123;&quot;max&quot;: &#123;&quot;field&quot;: &quot;price&quot;&#125;&#125;, &quot;min_price&quot;: &#123;&quot;min&quot;: &#123;&quot;field&quot;: &quot;price&quot;&#125;&#125;, &quot;sum_price&quot;: &#123;&quot;sum&quot;: &#123;&quot;field&quot;: &quot;price&quot;&#125;&#125; &#125; &#125; &#125;&#125;GET cars/_search // 统计不同品牌汽车中价格排名最高的车型&#123; &quot;size&quot;: 0, &quot;aggs&quot;: &#123; &quot;group_by_brand&quot;: &#123; &quot;terms&quot;: &#123;&quot;field&quot;: &quot;brand&quot;&#125;, &quot;aggs&quot;: &#123; &quot;top_car&quot;: &#123; &quot;top_hits&quot;: &#123; &quot;size&quot;: 1, // 取组内多少条数据,默认为10 &quot;sort&quot;: [&#123;&quot;price&quot;: &#123;&quot;order&quot;: &quot;desc&quot;&#125;&#125;], // 组内使用什么字段什么规则排序,默认使用_doc的asc规则排序 &quot;_source&quot;: &#123;&quot;includes&quot;: [&quot;model&quot;,&quot;price&quot;]&#125; // 结果中包含document中的哪些字段,默认包含全部字段 &#125; &#125; &#125; &#125; &#125;&#125; histogram区间统计 类似 terms, 也是用于 bucket分组操作, 是根据一个field实现数据区间分组 。如以100万为一个范围,统计不同范围内车辆销售量和平均价格。使用 histogram聚合 时field指定价格字段price,区间范围是100万,此时ES会将price价格区间划分为： [0, 1000000), [1000000, 2000000), [2000000, 3000000)等依次类推。在划分区间同时 histogram 会类似 terms 进行 数据数量统计, 可通过嵌套aggs对聚合分组后的组内数据做再次聚合分析 。 123456789101112GET /cars/_search&#123; &quot;aggs&quot;: &#123; &quot;histogram_by_price&quot;: &#123; &quot;histogram&quot;: &#123; &quot;field&quot;: &quot;price&quot;, &quot;interval&quot;: 1000000 &#125;, &quot;aggs&quot;: &#123;&quot;avg_by_price&quot;: &#123;&quot;avg&quot;: &#123;&quot;field&quot;: &quot;price&quot;&#125;&#125;&#125; &#125; &#125;&#125; date_histogram区间分组可对date类型的field执行区间聚合分组,若以月为单位,统计不同月份汽车销售数量及销售总金额。此时可使用 date_histogram 实现聚合分组,其中field来指定用于聚合分组的字段,interval指定 区间范围,可选值有 year、quarter、month、week、day、hour、minute、second,format指定日期格式化,min_doc_count指定每个区间最少document,若不指定默认为0,当区间范围内没有document时,也会显示bucket分组,extended_bounds指定起始时间和结束时间,若不指定默认使用字段中日期最小值和最大值作为起始和结束时间。 123456789101112131415GET /cars/_search&#123; &quot;aggs&quot;: &#123; &quot;histogram_by_date&quot;: &#123; &quot;date_histogram&quot;: &#123; &quot;field&quot;: &quot;sold_date&quot;, &quot;interval&quot;: &quot;month&quot;, // 7.X之后使用calendar_interval,指定区间范围 &quot;format&quot;: &quot;yyyy-MM-dd&quot;, // 指定日期格式化 &quot;min_doc_count&quot;: 1, &quot;extended_bounds&quot;: &#123;&quot;min&quot;: &quot;2021-01-01&quot;,&quot;max&quot;: &quot;2022-12-31&quot;&#125; &#125;, &quot;aggs&quot;: &#123;&quot;sum_by_price&quot;: &#123;&quot;sum&quot;: &#123;&quot;field&quot;: &quot;price&quot;&#125;&#125;&#125; &#125; &#125;&#125; 聚合统计数据时,有时需要对比部分数据和总体数据,如统计某品牌车辆平均价格和所有车辆平均价格。 global 是用于定义一个全局bucket,该 bucket 会 忽略query 的条件,检索所有document进行对应的聚合统计。 123456789101112GET /cars/_search&#123; &quot;size&quot;: 0, &quot;query&quot;: &#123;&quot;match&quot;: &#123;&quot;brand&quot;: &quot;大众&quot;&#125;&#125;, &quot;aggs&quot;: &#123; &quot;volkswagen_of_avg_price&quot;: &#123;&quot;avg&quot;: &#123;&quot;field&quot;: &quot;price&quot;&#125;&#125;, // 统计某品牌车辆平均价格 &quot;all_avg_price&quot;: &#123; // 所有车辆平均价格 &quot;global&quot;: &#123;&#125;, &quot;aggs&quot;: &#123;&quot;all_of_price&quot;: &#123;&quot;avg&quot;: &#123;&quot;field&quot;: &quot;price&quot;&#125;&#125;&#125; &#125; &#125;&#125; filter也可和aggs组合使用,实现相对复杂的过滤聚合分析,filter的范围决定了其过滤的范围,将filter放在aggs内部,代表该过滤器只对query搜索得到的结果执行filter过滤 。若filter放在aggs外部,过滤器则会过滤所有数据。 12345678910111213141516171819GET /cars/_search // filter和aggs组合使用,实现相对复杂的过滤聚合分析&#123; &quot;query&quot;: &#123; &quot;constant_score&quot;: &#123; &quot;filter&quot;: &#123;&quot;range&quot;: &#123;&quot;price&quot;: &#123;&quot;gte&quot;: 100000,&quot;lte&quot;: 500000&#125;&#125;&#125; &#125; &#125;, &quot;aggs&quot;: &#123;&quot;avg_by_price&quot;: &#123;&quot;avg&quot;: &#123;&quot;field&quot;: &quot;price&quot;&#125;&#125;&#125;&#125;GET /cars/_search&#123; &quot;query&quot;: &#123;&quot;match&quot;: &#123;&quot;brand&quot;: &quot;大众&quot;&#125;&#125;, &quot;aggs&quot;: &#123; &quot;count_last_year&quot;: &#123; // 12M/M表示12个月,1y/y表示1年,d表示天 &quot;filter&quot;: &#123;&quot;range&quot;: &#123;&quot;sold_date&quot;: &#123;&quot;gte&quot;: &quot;now-12M&quot;&#125;&#125;&#125;, &quot;aggs&quot;: &#123;&quot;sum_of_price_last_year&quot;: &#123;&quot;sum&quot;: &#123;&quot;field&quot;: &quot;price&quot;&#125;&#125;&#125; &#125; &#125;&#125; 数据建模如下设计一个用户document数据类型,其中包含一个地址数据的数组,该设计方式相对复杂,但在管理数据时更加的灵活。但也有明显的缺陷,针对地址数据做数据搜索时,经常会搜索出不必要的数据 。 123456789101112131415161718192021222324252627282930313233343536373839404142434445PUT /user_index&#123; &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123; &quot;login_name&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;&#125;, &quot;age &quot;: &#123;&quot;type&quot;: &quot;short&quot;&#125;, &quot;address&quot;: &#123; &quot;properties&quot;: &#123; &quot;province&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;&#125;, &quot;city&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;&#125;, &quot;street&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;&#125; &#125; &#125; &#125; &#125;&#125;PUT /user_index/_doc/1&#123; &quot;login_name&quot;: &quot;jack&quot;, &quot;age&quot;: 25, &quot;address&quot;: [ &#123;&quot;province&quot;: &quot;北京&quot;,&quot;city&quot;: &quot;北京&quot;,&quot;street&quot;: &quot;枫林三路&quot;&#125;, &#123;&quot;province&quot;: &quot;天津&quot;,&quot;city&quot;: &quot;天津&quot;,&quot;street&quot;: &quot;华夏路&quot;&#125; ]&#125;PUT /user_index/_doc/2&#123; &quot;login_name&quot;: &quot;rose&quot;, &quot;age&quot;: 21, &quot;address&quot;: [ &#123;&quot;province&quot;: &quot;河北&quot;,&quot;city&quot;: &quot;廊坊&quot;,&quot;street&quot;: &quot;燕郊经济开发区&quot;&#125;, &#123;&quot;province&quot;: &quot;天津&quot;,&quot;city&quot;: &quot;天津&quot;,&quot;street&quot;: &quot;华夏路&quot;&#125; ]&#125;GET /user_index/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [ &#123;&quot;match&quot;: &#123;&quot;address.province&quot;: &quot;北京&quot;&#125;&#125;, &#123;&quot;match&quot;: &#123;&quot;address.city&quot;: &quot;天津&quot;&#125;&#125; ] &#125; &#125;&#125; 可使用 nested object 作为 地址数组 的集体类型可解决上述问题,且搜索时需要 使用nested对应的搜索语法 123456789101112131415161718192021222324252627282930PUT /user_index&#123; &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123; &quot;login_name&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;&#125;, &quot;age &quot;: &#123;&quot;type&quot;: &quot;short&quot;&#125;, &quot;address&quot;: &#123; &quot;type&quot;: &quot;nested&quot;, &quot;properties&quot;: &#123; &quot;province&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;&#125;, &quot;city&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;&#125;, &quot;street&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;&#125; &#125; &#125; &#125; &#125;&#125;GET /user_index/_search&#123; &quot;query&quot;: &#123;&quot;bool&quot;: &#123;&quot;must&quot;: [ &#123;&quot;nested&quot;: &#123;&quot;path&quot;: &quot;address&quot;, &quot;query&quot;: &#123; &quot;bool&quot;: &#123;&quot;must&quot;: [ &#123;&quot;match&quot;: &#123;&quot;address.province&quot;: &quot;北京&quot;&#125;&#125;, &#123;&quot;match&quot;: &#123;&quot;address.city&quot;: &quot;北京&quot;&#125;&#125; ]&#125; &#125;&#125; &#125;] &#125;&#125;&#125; 普通数组数据在ES中会被扁平化处理,nested object数据类型ES在保存时不会扁平化处理 1234567891011121314151617181920&#123; // 普通数组 &quot;login_name&quot; : &quot;jack&quot;, &quot;address.province&quot; : [ &quot;北京&quot;, &quot;天津&quot; ], &quot;address.city&quot; : [ &quot;北京&quot;, &quot;天津&quot; ] &quot;address.street&quot; : [ &quot;枫林三路&quot;, &quot;华夏路&quot; ]&#125;// nested数据&#123; &quot;login_name&quot; : &quot;jack&quot;&#125;&#123; &quot;address.province&quot; : &quot;北京&quot;, &quot;address.city&quot; : &quot;北京&quot;, &quot;address.street&quot; : &quot;枫林三路&quot;&#125;&#123; &quot;address.province&quot; : &quot;天津&quot;, &quot;address.city&quot; : &quot;天津&quot;, &quot;address.street&quot; : &quot;华夏路&quot;,&#125; nested object建模缺点是采取的是类似冗余数据的方式,将多个数据放在一起,维护成本比较高,每次更新需要重新索引整个对象,包括根对象和嵌套对象。ES提供 类似关系型数据库 中 Join 的实现,使用Join数据类型实现父子关系,从而分离两个文档对象。 更新父文档无需重新索引整个子文档,子文档被新增,更改和删除也不会影响到父文档和其他子文档,父子关系元数据映射,用于确保查询时高性能,但是有一个限制父子数据包括映射其关联关系的元数据必须存在于一个shard中,搜索父子关系数据时,不用跨分片性能高。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495PUT my_blogs&#123; &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123; &quot;blog_comments_relation&quot;: &#123; &quot;type&quot;: &quot;join&quot;, // 指明join类型 &quot;relations&quot;: &#123; // 声明父子关系 &quot;blog&quot;: &quot;comment&quot; // blog为父文档名称,comment为子文档名称 &#125; &#125;, &quot;content&quot;: &#123;&quot;type&quot;: &quot;text&quot;&#125;, &quot;title&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;&#125; &#125; &#125;&#125;PUT my_blogs/_doc/blog1 // blog1为父文档id&#123; &quot;title&quot;: &quot;Learning Elasticsearch&quot;, &quot;content&quot;: &quot;learning ELK is happy&quot;, &quot;blog_comments_relation&quot;: &#123; // 声明文档类型 &quot;name&quot;: &quot;blog&quot; &#125;&#125;PUT my_blogs/_doc/blog2 // blog2为父文档id&#123; &quot;title&quot;: &quot;Learning Hadoop&quot;, &quot;content&quot;: &quot;learning Hadoop&quot;, &quot;blog_comments_relation&quot;: &#123; // 声明文档类型 &quot;name&quot;: &quot;blog&quot; &#125;&#125;// 父文档和子文档必须存在相同的分片上, 当指定文档时候,必须指定它的父文档IDPUT my_blogs/_doc/comment1?routing=blog1 // 使用route参数来保证,分配到相同分片&#123; &quot;comment&quot;: &quot;I am learning ELK&quot;, &quot;username&quot;: &quot;Jack&quot;, &quot;blog_comments_relation&quot;: &#123; &quot;name&quot;: &quot;comment&quot;, &quot;parent&quot;: &quot;blog1&quot; &#125;&#125;PUT my_blogs/_doc/comment2?routing=blog2 // comment2为子文档id,blog2为父文档id&#123; &quot;comment&quot;: &quot;I like Hadoop!!!!!&quot;, &quot;username&quot;: &quot;Jack&quot;, &quot;blog_comments_relation&quot;: &#123; &quot;name&quot;: &quot;comment&quot;, &quot;parent&quot;: &quot;blog2&quot; &#125;&#125;PUT my_blogs/_doc/comment3?routing=blog2&#123; &quot;comment&quot;: &quot;Hello Hadoop&quot;, &quot;username&quot;: &quot;Bob&quot;, &quot;blog_comments_relation&quot;: &#123; &quot;name&quot;: &quot;comment&quot;, &quot;parent&quot;: &quot;blog2&quot; &#125;&#125;POST my_blogs/_search // 查询所有文档&#123;&#125;GET my_blogs/_doc/blog2 // 根据父文档ID查看POST my_blogs/_search // parent_id查询,返回所有相关子文档&#123; &quot;query&quot;: &#123; &quot;parent_id&quot;: &#123;&quot;type&quot;: &quot;comment&quot;,&quot;id&quot;: &quot;blog2&quot;&#125; &#125;&#125;POST my_blogs/_search // has_child查询,返回父文档&#123; &quot;query&quot;: &#123; &quot;has_child&quot;: &#123; &quot;type&quot;: &quot;comment&quot;, &quot;query&quot;: &#123;&quot;match&quot;: &#123;&quot;username&quot;: &quot;Jack&quot;&#125;&#125; &#125; &#125;&#125;POST my_blogs/_search // has_parent查询,返回相关的子文档&#123; &quot;query&quot;: &#123; &quot;has_parent&quot;: &#123; &quot;parent_type&quot;: &quot;blog&quot;, &quot;query&quot;: &#123;&quot;match&quot;: &#123;&quot;title&quot;: &quot;Learning Hadoop&quot;&#125;&#125; &#125; &#125;&#125;PUT my_blogs/_doc/comment3?routing=blog2 //更新子文档不会影响到父文档&#123; &quot;comment&quot;: &quot;Hello Hadoop??&quot;, &quot;blog_comments_relation&quot;: &#123; &quot;name&quot;: &quot;comment&quot;, &quot;parent&quot;: &quot;blog2&quot; &#125;&#125; 文件系统数据若需要使用 文件路径搜索 内容,只需要为其中的字段定义一个特殊的 path_hierarchy 分词器 123456789101112131415161718192021222324252627282930313233343536373839404142PUT /codes&#123; &quot;settings&quot;: &#123;&quot;analysis&quot;: &#123;&quot;analyzer&quot;: &#123;&quot;path_analyzer&quot;: &#123;&quot;tokenizer&quot;: &quot;path_hierarchy&quot;&#125;&#125;&#125;&#125;, &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123; &quot;fileName&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;&#125;, &quot;path&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;path_analyzer&quot;, &quot;fields&quot;: &#123;&quot;keyword&quot;: &#123;&quot;type&quot;: &quot;text&quot;,&quot;analyzer&quot;: &quot;standard&quot;&#125;&#125; &#125;, &quot;content&quot;: &#123;&quot;type&quot;: &quot;text&quot;,&quot;analyzer&quot;: &quot;standard&quot;&#125; &#125; &#125;&#125;PUT /codes/_doc/1&#123; &quot;fileName&quot;: &quot;HelloWorld.java&quot;, &quot;path&quot;: &quot;/com/eleven/first&quot;, &quot;content&quot;: &quot;package com.eleven.first; public class HelloWorld &#123; // some code... &#125;&quot;&#125;GET /codes/_search&#123; &quot;query&quot;: &#123;&quot;match&quot;: &#123;&quot;path&quot;: &quot;/com&quot;&#125;&#125;&#125;GET /codes/_analyze&#123; &quot;text&quot;: &quot;/a/b/c/d&quot;, &quot;field&quot;: &quot;path&quot;&#125;GET /codes/_search&#123; &quot;query&quot;: &#123;&quot;match&quot;: &#123;&quot;path.keyword&quot;: &quot;/com&quot;&#125;&#125;&#125;GET /codes/_search&#123; &quot;query&quot;: &#123;&quot;bool&quot;: &#123;&quot;should&quot;: [ &#123;&quot;match&quot;: &#123;&quot;path&quot;: &quot;/com&quot;&#125;&#125;, &#123;&quot;match&quot;: &#123;&quot;path.keyword&quot;: &quot;/com/eleven&quot;&#125;&#125; ]&#125;&#125;&#125; Scroll分页使用 from 和 size 方式查询1W以内的数据都OK,但若数据比较多时会出现性能问题。ES做了一个限制 不允许查询1W条以后的数据 。若要查询1W条以后的数据,可使用ES中提供的 scroll游标 来查询。 在进行大量分页时,每次分页都需要将要查询数据进行重新排序,这样非常浪费性能。使用 scroll游标 是 将要用的数据一次性排序好, 然后 分批取出 。性能要比from + size好得多,使用scroll查询后,排序后的数据会保持一定的时间, 后续分页查询都从该快照取数据。响应结果中会返回_scroll_id,第二次查询直接使用_scroll_id来查询。 1234567891011121314GET /es_db/_search?scroll=1m // 让排序的数据保持1分钟&#123; &quot;query&quot;: &#123; &quot;multi_match&quot;: &#123; &quot;query&quot;: &quot;广州长沙张三&quot;, &quot;fields&quot;: [&quot;address&quot;,&quot;name&quot;] &#125; &#125;, &quot;size&quot;: 100&#125;GET _search/scroll?scroll=1m&#123; &quot;scroll_id&quot;: &quot;FGluY2x1ZGVfY29udGV4dF91dWlkDXF1ZXJ5QW5kRmV0Y2gBFnJKUnZmX1pIVGVpM05TWDBQX0JJeXcAAAAAAAaeghZDUkdZN1FJNVIwYUJhYUxvNWVxd1Rn&quot;&#125; SQL支持ES SQL允许执行类SQL查询,REST接口、命令行或 JDBC 等都可使用 SQL 来进行 数据检索 和 数据聚合 。特点： 本地集成：ES SQL是专门为ES构建的,每个SQL查询都根据底层存储对相关节点有效执行 无额外要求：不依赖其他硬件、进程、运行时库,可直接运行在ES集群上 轻量且高效：像SQL那样简洁、高效地完成查询1234567891011121314GET /es_db/_search?scroll=1m // 让排序的数据保持1分钟&#123; &quot;query&quot;: &#123; &quot;multi_match&quot;: &#123; &quot;query&quot;: &quot;广州长沙张三&quot;, &quot;fields&quot;: [&quot;address&quot;,&quot;name&quot;] &#125; &#125;, &quot;size&quot;: 100&#125;GET _search/scroll?scroll=1m&#123; &quot;scroll_id&quot;: &quot;FGluY2x1ZGVfY29udGV4dF91dWlkDXF1ZXJ5QW5kRmV0Y2gBFnJKUnZmX1pIVGVpM05TWDBQX0JJeXcAAAAAAAaeghZDUkdZN1FJNVIwYUJhYUxvNWVxd1Rn&quot;&#125; 目前 FROM只支持单表, 不支持JOIN、不支持较复杂的子查询,format 表示 指定返回数据类型, 支持的类型有 逗号分隔csv、json、制表符分隔符tsv、txt、yaml 。 12345678910111213141516GET /_sql?format=json&#123; &quot;query&quot;: &quot;SELECT * FROM es_db limit 1&quot;&#125;GET /_sql/translate // 将SQL转换为DSL&#123; &quot;query&quot;: &quot;SELECT * FROM es_db limit 1&quot;&#125;GET /_sql?format=json // field_exp匹配字段,constant_exp匹配常量表达式,&#123; // 检索address包含广州和name中包含张三的用户 &quot;query&quot;: &quot;select * from es_db where MATCH(address, &#x27;广州&#x27;) or MATCH(name, &#x27;张三&#x27;) limit 10&quot;&#125;GET /_sql?format=txt // 统计分组&#123; &quot;query&quot;: &quot;select age, count(*) as age_cnt from es_db group by age&quot;&#125; 模板模板搜索可将一些搜索进行模板化,每次执行该搜索就直接调用模板,传入一些参数即可。 123456789101112131415161718192021222324252627282930GET /cars/_search/template // 简单定义参数并传递&#123; &quot;source&quot;: &#123; &quot;query&quot;: &#123;&quot;match&quot;: &#123;&quot;remark&quot;: &quot;&#123;&#123;kw&#125;&#125;&quot;&#125;&#125;, &quot;size&quot;: &quot;&#123;&#123;size&#125;&#125;&quot; &#125;, &quot;params&quot;: &#123;&quot;kw&quot;: &quot;大众&quot;,&quot;size&quot;: 2&#125;&#125;GET cars/_search/template // toJson方式传递参数&#123; &quot;source&quot;: &quot;&quot;&quot;&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123;&#123;#toJson&#125;&#125;parameter&#123;&#123;/toJson&#125;&#125; &#125;&#125;&quot;&quot;&quot;, &quot;params&quot;: &#123; &quot;parameter&quot;: &#123;&quot;remark&quot;: &quot;大众&quot;&#125; &#125;&#125;GET cars/_search/template // json方式传递参数&#123; &quot;source&quot;: &#123;&quot;query&quot;: &#123;&quot;match&quot;: &#123; &quot;remark&quot;: &quot;&#123;&#123;#join delimiter=&#x27; &#x27;&#125;&#125;kw&#123;&#123;/join delimiter=&#x27; &#x27;&#125;&#125;&quot; &#125;&#125;&#125;, &quot;params&quot;: &#123;&quot;kw&quot;: [&quot;大众&quot;,&quot;标致&quot;]&#125;&#125;GET cars/_search/template&#123; &quot;source&quot;: &#123;&quot;query&quot;: &#123;&quot;range&quot;: &#123;&quot;price&quot;: &#123; &quot;gte&quot;: &quot;&#123;&#123;start&#125;&#125;&quot;, &quot;lte&quot;: &quot;&#123;&#123;end&#125;&#125;&#123;&#123;^end&#125;&#125;200000&#123;&#123;/end&#125;&#125;&quot; // 默认值定义 &#125;&#125;&#125;&#125;, &quot;params&quot;: &#123;&quot;start&quot;: 100000,&quot;end&quot;: 140000&#125;&#125; 记录template实现重复调用 可使用 Mustache 语言作为 搜索请求预处理, 它提供模板 通过键值对 来替换模板中的变量。把 脚本存储在本地磁盘中, 默认位置为 elasticsearch\\config\\scripts, 通过引用脚本名称进行使用 12345678910111213POST _scripts/test // test为脚本id&#123; &quot;script&quot;: &#123; &quot;lang&quot;: &quot;mustache&quot;, // 指定mustache语言 &quot;source&quot;: &#123;&quot;query&quot;: &#123;&quot;match&quot;: &#123;&quot;remark&quot;: &quot;&#123;&#123;kw&#125;&#125;&quot;&#125;&#125;&#125; &#125;&#125;GET cars/_search/template&#123; &quot;id&quot;: &quot;test&quot;, // 指定调用脚本的id &quot;params&quot;: &#123;&quot;kw&quot;: &quot;大众&quot;&#125;&#125;DELETE _scripts/test // 删除脚本id为test的脚本 suggest searchsuggest search(completion suggest) 即 建议搜索 或 搜索建议, 也可叫做自动完成,类似百度中搜索联想提示功能。ES实现 suggest时 性能非常高, 其构建的不是倒排索引也不是正排索引,是纯粹用于前缀搜索的一种特殊数据结构,且会全部放在内存中,所以suggest search进行前缀搜索提示性能是非常高。需要使用suggest时候,必须在定义index时为其mapping指定开启suggest 。 12345678910111213141516171819202122232425262728293031323334PUT /movie&#123; &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123;&quot;title&quot;: &#123;&quot;type&quot;: &quot;text&quot;,&quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;fields&quot;: &#123;&quot;suggest&quot;: &#123;&quot;type&quot;: &quot;completion&quot;,&quot;analyzer&quot;: &quot;ik_max_word&quot;&#125;&#125; &#125;, &quot;content&quot;: &#123;&quot;type&quot;: &quot;text&quot;,&quot;analyzer&quot;: &quot;ik_max_word&quot;&#125; &#125; &#125;&#125;PUT /movie/_doc/1&#123; &quot;title&quot;: &quot;西游记电影系列&quot;, &quot;content&quot;: &quot;西游记之月光宝盒将与2021年进行......&quot;&#125;PUT /movie/_doc/2&#123; &quot;title&quot;: &quot;西游记文学系列&quot;, &quot;content&quot;: &quot;某知名网络小说作家已经完成了大话西游同名小说的出版&quot;&#125;PUT /movie/_doc/3&#123; &quot;title&quot;: &quot;西游记之大话西游手游&quot;, &quot;content&quot;: &quot;网易游戏近日出品了大话西游经典IP的手游,正在火爆内测中&quot;&#125;GET /movie/_search&#123; &quot;suggest&quot;: &#123; &quot;my-suggest&quot;: &#123; &quot;prefix&quot;: &quot;西游记&quot;, &quot;completion&quot;: &#123;&quot;field&quot;: &quot;title.suggest&quot;&#125; &#125; &#125;&#125; 地理位置搜索ES支持 地理位置搜索 和 聚合分析, 可实现 在指定区域内搜索数据、搜索指定地点附近的数据、聚合分析指定地点附近的数据 等操作。ES中若使用地理位置搜索,必须提供一个特殊的字段类型 geo_point, 用于指定地理位置坐标点。 新增一个基于 geo_point 类型数据,可使用多种方式。多种类型描述 geo_point 类型字段时,在 搜索数据时显示格式和录入格式是统一的 。 任何数据描述 的 geo_point 类型字段, 都适用地理位置搜索 。 数据范围要求 纬度范围 是-90~90之间, 经度范围 是-180~180之间,经纬度数据都是 浮点数 或 数字串, 最大精度为 小数点后7位 。 latitude ： 纬度 、 longitude ： 经度 。 123456789101112131415161718192021222324PUT /hotel_app&#123; &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123; &quot;pin&quot;: &#123;&quot;type&quot;: &quot;geo_point&quot;&#125;, &quot;name&quot;: &#123;&quot;type&quot;: &quot;text&quot;,&quot;analyzer&quot;: &quot;ik_max_word&quot;&#125; &#125; &#125;&#125;PUT /hotel_app/_doc/1&#123; &quot;name&quot;: &quot;七天连锁酒店&quot;, &quot;pin&quot;: &#123;&quot;lat&quot;: 40.12,&quot;lon&quot;: -71.34&#125;&#125;PUT /hotel_app/_doc/2&#123; &quot;name&quot;: &quot;维多利亚大酒店&quot;, &quot;pin&quot;: &quot;40.99, -70.81&quot;&#125;PUT /hotel_app/_doc/3&#123; &quot;name&quot;: &quot; 红树林宾馆&quot;, &quot;pin&quot;: [40,-73.81] // 基于数组：依次定义经度、纬度,不推荐使用&#125; 矩形范围搜索 传入 top_left 和 bottom_right 坐标点是有固定要求的, top_left 即 从西北向东南, Bottom_right 即从东南向西北, 且 top_left纬度应大于bottom_right, top_left经度应小于bottom_right 。多边形范围搜索 对传入若干点坐标顺序没有任何要求,只要传入若干地理位置坐标点,即可形成多边形。 12345678910111213141516171819202122232425GET /hotel_app/_doc/_search // 矩形搜索&#123; &quot;query&quot;: &#123; &quot;geo_bounding_box&quot;: &#123; &quot;pin&quot;: &#123; &quot;top_left&quot;: &#123;&quot;lat&quot;: 41.73,&quot;lon&quot;: -74.1&#125;, &quot;bottom_right&quot;: &#123;&quot;lat&quot;: 40.01,&quot;lon&quot;: -70.12&#125; &#125; &#125; &#125;&#125;GET /hotel_app/_doc/_search // 多边形搜索&#123; &quot;query&quot;: &#123; &quot;geo_polygon&quot;: &#123; &quot;pin&quot;: &#123; &quot;points&quot;: [ &#123;&quot;lat&quot;: 40.73,&quot;lon&quot;: -74.1&#125;, &#123;&quot;lat&quot;: 40.01,&quot;lon&quot;: -71.12&#125;, &#123;&quot;lat&quot;: 50.56,&quot;lon&quot;: -90.58&#125; ] &#125; &#125; &#125;&#125; Distance距离的单位,常用米m和千米km,建议使用 filter 来过滤 geo_point 数据,因为 geo_point 数据相关度评分计算比较耗时。使用query来搜索geo_point数据效率相对会慢一些。 12345678910111213141516171819GET /hotel_app/_doc/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;filter&quot;: &#123; &quot;geo_distance&quot;: &#123;&quot;distance&quot;: &quot;200km&quot;,&quot;pin&quot;: &#123;&quot;lat&quot;: 40,&quot;lon&quot;: -70&#125;&#125; &#125; &#125; &#125;&#125;GET hotel_app/_search&#123; &quot;query&quot;: &#123; &quot;geo_distance&quot;: &#123; &quot;distance&quot;: &quot;90km&quot;, &quot;pin&quot;: &#123;&quot;lat&quot;: 40.55,&quot;lon&quot;: -71.12&#125; &#125; &#125;&#125; 聚合统计某位置附近区域内的数据,unit是距离单位,常用单位有米m,千米km,英里mi,distance_type是统计算法：sloppy_arc默认算法、 arc最高精度 、 plane最高效率 。 12345678910111213141516171819GET /hotel_app/_doc/_search&#123; &quot;size&quot;: 0, &quot;aggs&quot;: &#123; &quot;agg_by_pin&quot;: &#123; &quot;geo_distance&quot;: &#123; &quot;distance_type&quot;: &quot;arc&quot;, &quot;field&quot;: &quot;pin&quot;, &quot;origin&quot;: &#123;&quot;lat&quot;: 40,&quot;lon&quot;: -70&#125;, &quot;unit&quot;: &quot;mi&quot;, &quot;ranges&quot;: [ // 聚合统计分别距离某位置80英里,300英里,1000英里范围内的数据数量 &#123;&quot;to&quot;: 80&#125;, &#123;&quot;from&quot;: 80,&quot;to&quot;: 300&#125;, &#123;&quot;from&quot;: 300,&quot;to&quot;: 1000&#125; ] &#125; &#125; &#125;&#125; ElasticSearch: 进一步学习Elasticsearch 官方学习文档：https://www.elastic.co/guide/en/elasticsearch/reference/current/index.htmlJava API:https://www.elastic.co/guide/en/elasticsearch/client/java-api/current/java-api.html","tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"http://example.com/tags/ElasticSearch/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"ElasticSearch","slug":"工具和中间件/搜索引擎技术/ElasticSearch","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/ElasticSearch/"}]},{"title":"ElasticSearch实战","date":"2022-01-02T03:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/ElasticSearch/ElasticSearch实战/","text":"引入pom依赖：12345&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch-rest-high-level-client&lt;/artifactId&gt; &lt;version&gt;7.6.1&lt;/version&gt;&lt;/dependency&gt; 使用Java API来操作ES集群初始化连接，基于 RestClient.builder 方法来构建 RestClientBuilder, 使用 RestHighLevelClient 去连接ES集群，用 HttpHost 来添加ES的节点。 123456789// 建立与ES的连接// 1. 使用RestHighLevelClient构建客户端连接。// 2. 基于RestClient.builder方法来构建RestClientBuilder// 3. 用HttpHost来添加ES的节点RestClientBuilder restClientBuilder = RestClient.builder( new HttpHost(&quot;192.168.21.130&quot;, 9200, &quot;http&quot;) , new HttpHost(&quot;192.168.21.131&quot;, 9200, &quot;http&quot;) , new HttpHost(&quot;192.168.21.132&quot;, 9200, &quot;http&quot;));RestHighLevelClient restHighLevelClient = new RestHighLevelClient(restClientBuilder); 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155public void add(JobDetail jobDetail) throws IOException &#123; // 构建IndexRequest对象，用来描述ES发起请求的数据 IndexRequest indexRequest = new IndexRequest(JOB_IDX); // 设置文档ID indexRequest.id(String.valueOf(jobDetail.getId())); // 使用FastJSON将实体类对象转换为JSON String json = JSONObject.toJSONString(jobDetail); // 使用IndexRequest.source方法设置文档数据，并设置请求的数据为JSON格式 indexRequest.source(json, XContentType.JSON); // 使用ES RestHighLevelClient调用index方法发起请求，将一个文档添加到索引中 restHighLevelClient.index(indexRequest, RequestOptions.DEFAULT);&#125;public JobDetail findById(long id) throws IOException &#123; GetRequest getRequest = new GetRequest(JOB_IDX, id + &quot;&quot;); // 构建GetRequest请求 // 使用RestHighLevelClient.get发送GetRequest请求，并获取到ES服务器的响应。 GetResponse getResponse = restHighLevelClient.get(getRequest, RequestOptions.DEFAULT); String json = getResponse.getSourceAsString();// 将ES响应的数据转换为JSON字符串 // 并使用FastJSON将JSON字符串转换为JobDetail类对象 JobDetail jobDetail = JSONObject.parseObject(json, JobDetail.class); jobDetail.setId(id);// 单独设置ID return jobDetail;&#125;public void update(JobDetail jobDetail) throws IOException &#123; // 判断对应ID的文档是否存在，构建GetRequest GetRequest getRequest = new GetRequest(JOB_IDX, jobDetail.getId() + &quot;&quot;); // 执行client的exists方法，发起请求，判断是否存在 boolean exists = restHighLevelClient.exists(getRequest, RequestOptions.DEFAULT); if(exists) &#123; // 构建UpdateRequest请求 UpdateRequest updateRequest = new UpdateRequest(JOB_IDX, jobDetail.getId() + &quot;&quot;); // 设置UpdateRequest的文档，并配置为JSON格式 updateRequest.doc(JSONObject.toJSONString(jobDetail), XContentType.JSON); // 执行client发起update请求 restHighLevelClient.update(updateRequest, RequestOptions.DEFAULT); &#125;&#125;public void deleteById(long id) throws IOException &#123; DeleteRequest deleteRequest = new DeleteRequest(JOB_IDX, id + &quot;&quot;);// 构建delete请求 restHighLevelClient.delete(deleteRequest, RequestOptions.DEFAULT);// 使用RestHighLevelClient执行delete请求&#125;public List&lt;JobDetail&gt; searchByKeywords(String keywords) throws IOException &#123; // 构建SearchRequest检索请求 专门用来进行全文检索、关键字检索的API SearchRequest searchRequest = new SearchRequest(JOB_IDX); // 创建一个SearchSourceBuilder专门用于构建查询条件 SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); // 使用QueryBuilders.multiMatchQuery构建一个查询条件（搜索title、jd），并配置到SearchSourceBuilder MultiMatchQueryBuilder multiMatchQueryBuilder = QueryBuilders.multiMatchQuery(keywords, &quot;title&quot;, &quot;jd&quot;); searchSourceBuilder.query(multiMatchQueryBuilder);// 将查询条件设置到查询请求构建器中 searchRequest.source(searchSourceBuilder);// 调用SearchRequest.source将查询条件设置到检索请求 // 执行RestHighLevelClient.search发起请求 SearchResponse searchResponse = restHighLevelClient.search(searchRequest, RequestOptions.DEFAULT); SearchHit[] hitArray = searchResponse.getHits().getHits(); ArrayList&lt;JobDetail&gt; jobDetailArrayList = new ArrayList&lt;&gt;(); for (SearchHit documentFields : hitArray) &#123;// 遍历结果 String json = documentFields.getSourceAsString();// 获取命中的结果 JobDetail jobDetail = JSONObject.parseObject(json, JobDetail.class);// 将JSON字符串转换为对象 jobDetail.setId(Long.parseLong(documentFields.getId()));// 使用SearchHit.getId设置文档ID jobDetailArrayList.add(jobDetail); &#125; return jobDetailArrayList;&#125;public Map&lt;String, Object&gt; searchByPage(String keywords, int pageNum, int pageSize) throws IOException &#123; // 构建SearchRequest检索请求 专门用来进行全文检索、关键字检索的API SearchRequest searchRequest = new SearchRequest(JOB_IDX); // 创建一个SearchSourceBuilder专门用于构建查询条件 SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); // 使用QueryBuilders.multiMatchQuery构建一个查询条件（搜索title、jd），并配置到SearchSourceBuilder MultiMatchQueryBuilder multiMatchQueryBuilder = QueryBuilders.multiMatchQuery(keywords, &quot;title&quot;, &quot;jd&quot;); searchSourceBuilder.query(multiMatchQueryBuilder); // 将查询条件设置到查询请求构建器中 searchSourceBuilder.size(pageSize);// 每页显示多少条 searchSourceBuilder.from((pageNum - 1) * pageSize);// 设置从第几条开始查询 searchRequest.source(searchSourceBuilder);// 调用SearchRequest.source将查询条件设置到检索请求 // 执行RestHighLevelClient.search发起请求 SearchResponse searchResponse = restHighLevelClient.search(searchRequest, RequestOptions.DEFAULT); SearchHit[] hitArray = searchResponse.getHits().getHits(); ArrayList&lt;JobDetail&gt; jobDetailArrayList = new ArrayList&lt;&gt;(); for (SearchHit documentFields : hitArray) &#123;// 遍历结果 String json = documentFields.getSourceAsString();// 获取命中的结果 JobDetail jobDetail = JSONObject.parseObject(json, JobDetail.class);// 将JSON字符串转换为对象 jobDetail.setId(Long.parseLong(documentFields.getId()));// 使用SearchHit.getId设置文档ID jobDetailArrayList.add(jobDetail); &#125; // 将结果封装到Map结构中（带有分页信息） long totalNum = searchResponse.getHits().getTotalHits().value; Map&lt;String, Object&gt; resultMap = new HashMap&lt;&gt;(); resultMap.put(&quot;total&quot;, totalNum); // total -&gt; 使用SearchHits.getTotalHits().value获取到所有的记录数 resultMap.put(&quot;content&quot;, jobDetailArrayList); content -&gt; 当前分页中的数据 return resultMap;&#125;public Map&lt;String, Object&gt; searchByScrollPage(String keywords, String scrollId, int pageSize) throws IOException &#123; SearchResponse searchResponse = null; if(scrollId == null) &#123; // 构建SearchRequest检索请求 专门用来进行全文检索、关键字检索的API SearchRequest searchRequest = new SearchRequest(JOB_IDX); // 创建一个SearchSourceBuilder专门用于构建查询条件 SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); // 使用QueryBuilders.multiMatchQuery构建一个查询条件（搜索title、jd），并配置到SearchSourceBuilder MultiMatchQueryBuilder multiMatchQueryBuilder = QueryBuilders.multiMatchQuery(keywords, &quot;title&quot;, &quot;jd&quot;); searchSourceBuilder.query(multiMatchQueryBuilder);// 将查询条件设置到查询请求构建器中 HighlightBuilder highlightBuilder = new HighlightBuilder(); // 设置高亮 highlightBuilder.field(&quot;title&quot;); highlightBuilder.field(&quot;jd&quot;); highlightBuilder.preTags(&quot;&lt;font color=&#x27;red&#x27;&gt;&quot;); highlightBuilder.postTags(&quot;&lt;/font&gt;&quot;); searchSourceBuilder.highlighter(highlightBuilder); // 给请求设置高亮 searchSourceBuilder.size(pageSize); // 每页显示多少条 searchRequest.source(searchSourceBuilder); // 调用SearchRequest.source将查询条件设置到检索请求 searchRequest.scroll(TimeValue.timeValueMinutes(5)); // 设置scroll查询 // 执行RestHighLevelClient.search发起请求 searchResponse = restHighLevelClient.search(searchRequest, RequestOptions.DEFAULT); &#125; else &#123; // 第二次查询的时候，直接通过scroll id查询数据 SearchScrollRequest searchScrollRequest = new SearchScrollRequest(scrollId); searchScrollRequest.scroll(TimeValue.timeValueMinutes(5)); // 使用RestHighLevelClient发送scroll请求 searchResponse = restHighLevelClient.scroll(searchScrollRequest, RequestOptions.DEFAULT); &#125; SearchHit[] hitArray = searchResponse.getHits().getHits(); ArrayList&lt;JobDetail&gt; jobDetailArrayList = new ArrayList&lt;&gt;(); for (SearchHit documentFields : hitArray) &#123; // 遍历结果，迭代ES响应的数据 String json = documentFields.getSourceAsString(); // 获取命中的结果 JobDetail jobDetail = JSONObject.parseObject(json, JobDetail.class); // 将JSON字符串转换为对象 jobDetail.setId(Long.parseLong(documentFields.getId())); // 使用SearchHit.getId设置文档ID jobDetailArrayList.add(jobDetail); // 设置高亮的一些文本到实体类中 封装了高亮 Map&lt;String, HighlightField&gt; highlightFieldMap = documentFields.getHighlightFields(); HighlightField titleHL = highlightFieldMap.get(&quot;title&quot;); HighlightField jdHL = highlightFieldMap.get(&quot;jd&quot;); if(titleHL != null) &#123; Text[] fragments = titleHL.getFragments(); // 获取指定字段的高亮片段 StringBuilder builder = new StringBuilder(); for(Text text : fragments) &#123; // 将这些高亮片段拼接成一个完整的高亮字段 builder.append(text); &#125; jobDetail.setTitle(builder.toString()); // 设置到实体类中 &#125; if(jdHL != null) &#123; Text[] fragments = jdHL.getFragments(); // 获取指定字段的高亮片段 StringBuilder builder = new StringBuilder(); for(Text text : fragments) &#123;// 将这些高亮片段拼接成一个完整的高亮字段 builder.append(text); &#125; jobDetail.setJd(builder.toString()); // 设置到实体类中 &#125; &#125; // 将结果封装到Map结构中，带有分页信息 long totalNum = searchResponse.getHits().getTotalHits().value; Map&lt;String, Object&gt; hashMap = new HashMap&lt;&gt;(); hashMap.put(&quot;scroll_id&quot;, searchResponse.getScrollId()); hashMap.put(&quot;content&quot;, jobDetailArrayList); // content -&gt; 当前分页中的数据 hashMap.put(&quot;total_num&quot;, totalNum); // total -&gt; 使用SearchHits.getTotalHits().value获取到所有的记录数 return hashMap;&#125;public void close() throws IOException &#123; restHighLevelClient.close();&#125; 京东商城搜索效果实现ES索引库表结构分析 1234567891011121314151617181920212223242526272829303132333435363738PUT product_db // 创建索引库&#123;&quot;mappings&quot;:&#123;&quot;properties&quot;:&#123;&quot;id&quot;:&#123;&quot;type&quot;:&quot;long&quot;&#125;,&quot;name&quot;:&#123;&quot;type&quot;:&quot;text&quot;,&quot;analyzer&quot;:&quot;ik_max_word&quot;&#125;,&quot;keywords&quot;:&#123;&quot;type&quot;:&quot;text&quot;,&quot;analyzer&quot;:&quot;ik_max_word&quot;&#125;,&quot;subTitle&quot;:&#123;&quot;type&quot;:&quot;text&quot;,&quot;analyzer&quot;:&quot;ik_max_word&quot;&#125;,&quot;salecount&quot;:&#123;&quot;type&quot;:&quot;long&quot;&#125;,&quot;putawayDate&quot;:&#123;&quot;type&quot;:&quot;date&quot;&#125;,&quot;price&quot;:&#123;&quot;type&quot;:&quot;double&quot;&#125;,&quot;promotionPrice&quot;:&#123;&quot;type&quot;:&quot;keyword&quot;&#125;,&quot;originalPrice&quot;:&#123;&quot;type&quot;:&quot;keyword&quot;&#125;,&quot;pic&quot;:&#123;&quot;type&quot;:&quot;keyword&quot;&#125;,&quot;sale&quot;:&#123;&quot;type&quot;:&quot;long&quot;&#125;,&quot;hasStock&quot;:&#123;&quot;type&quot;:&quot;boolean&quot;&#125;,&quot;brandId&quot;:&#123;&quot;type&quot;:&quot;long&quot;&#125;,&quot;brandName&quot;:&#123;&quot;type&quot;:&quot;keyword&quot;&#125;,&quot;brandImg&quot;:&#123;&quot;type&quot;:&quot;keyword&quot;&#125;,&quot;categoryId&quot;:&#123;&quot;type&quot;:&quot;long&quot;&#125;,&quot;categoryName&quot;:&#123;&quot;type&quot;:&quot;keyword&quot;&#125;,&quot;attrs&quot;:&#123;&quot;type&quot;:&quot;nested&quot;,&quot;properties&quot;:&#123;&quot;attrId&quot;:&#123;&quot;type&quot;:&quot;long&quot;&#125;,&quot;attrName&quot;:&#123;&quot;type&quot;:&quot;keyword&quot;&#125;,&quot;attrValue&quot;:&#123;&quot;type&quot;:&quot;keyword&quot;&#125;&#125;&#125;&#125;&#125;&#125;// 索引数据准备PUT /product_db/_doc/1&#123;&quot;id&quot;:&quot;26&quot;,&quot;name&quot;:&quot;小米 11 手机&quot;,&quot;keywords&quot;:&quot;小米手机&quot;,&quot;subTitle&quot;:&quot;AI智慧全面屏 6GB +64GB 亮黑色 全网通版 移动联通电信4G手机 双卡双待 双卡双待&quot;,&quot;price&quot;:&quot;3999&quot;,&quot;promotionPrice&quot;:&quot;2999&quot;,&quot;originalPrice&quot;:&quot;5999&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/xiaomi.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:999,&quot;putawayDate&quot;:&quot;2021-04-01&quot;,&quot;brandId&quot;:6,&quot;brandName&quot;:&quot;小米&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/1e34aef2a409119018a4c6258e39ecfb_222_222.png&quot;,&quot;categoryId&quot;:19,&quot;categoryName&quot;:&quot;手机通讯&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:1,&quot;attrName&quot;:&quot;cpu&quot;,&quot;attrValue&quot;:&quot;2核&quot;&#125;,&#123;&quot;attrId&quot;:2,&quot;attrName&quot;:&quot;颜色&quot;,&quot;attrValue&quot;:&quot;黑色&quot;&#125;]&#125;PUT /product_db/_doc/2&#123;&quot;id&quot;:&quot;27&quot;,&quot;name&quot;:&quot;小米 10 手机&quot;,&quot;keywords&quot;:&quot;小米手机&quot;,&quot;subTitle&quot;:&quot;AI智慧全面屏 4GB +64GB 亮白色 全网通版 移动联通电信4G手机 双卡双待 双卡双待&quot;,&quot;price&quot;:&quot;2999&quot;,&quot;promotionPrice&quot;:&quot;1999&quot;,&quot;originalPrice&quot;:&quot;3999&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/xiaomi.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:false,&quot;salecount&quot;:99,&quot;putawayDate&quot;:&quot;2021-04-02&quot;,&quot;brandId&quot;:6,&quot;brandName&quot;:&quot;小米&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/1e34aef2a409119018a4c6258e39ecfb_222_222.png&quot;,&quot;categoryId&quot;:19,&quot;categoryName&quot;:&quot;手机通讯&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:1,&quot;attrName&quot;:&quot;cpu&quot;,&quot;attrValue&quot;:&quot;4核&quot;&#125;,&#123;&quot;attrId&quot;:2,&quot;attrName&quot;:&quot;颜色&quot;,&quot;attrValue&quot;:&quot;白色&quot;&#125;]&#125;PUT /product_db/_doc/3&#123;&quot;id&quot;:&quot;28&quot;,&quot;name&quot;:&quot;小米 手机&quot;,&quot;keywords&quot;:&quot;小米手机&quot;,&quot;subTitle&quot;:&quot;AI智慧全面屏 4GB +64GB 亮蓝色 全网通版 移动联通电信4G手机 双卡双待 双卡双待&quot;,&quot;price&quot;:&quot;2999&quot;,&quot;promotionPrice&quot;:&quot;1999&quot;,&quot;originalPrice&quot;:&quot;3999&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/xiaomi.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:199,&quot;putawayDate&quot;:&quot;2021-04-03&quot;,&quot;brandId&quot;:6,&quot;brandName&quot;:&quot;小米&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/1e34aef2a409119018a4c6258e39ecfb_222_222.png&quot;,&quot;categoryId&quot;:19,&quot;categoryName&quot;:&quot;手机通讯&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:1,&quot;attrName&quot;:&quot;cpu&quot;,&quot;attrValue&quot;:&quot;2核&quot;&#125;,&#123;&quot;attrId&quot;:2,&quot;attrName&quot;:&quot;颜色&quot;,&quot;attrValue&quot;:&quot;蓝色&quot;&#125;]&#125;PUT /product_db/_doc/4&#123;&quot;id&quot;:&quot;29&quot;,&quot;name&quot;:&quot;Apple iPhone 8 Plus 64GB 金色特别版 移动联通电信4G手机&quot;,&quot;keywords&quot;:&quot;苹果手机&quot;,&quot;subTitle&quot;:&quot;苹果手机 Apple产品年中狂欢节，好物尽享，美在智慧！速来 &gt;&gt; 勾选[保障服务][原厂保2年]，获得AppleCare+全方位服务计划，原厂延保售后无忧。&quot;,&quot;price&quot;:&quot;5999&quot;,&quot;promotionPrice&quot;:&quot;4999&quot;,&quot;originalPrice&quot;:&quot;7999&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/5acc5248N6a5f81cd.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:1199,&quot;putawayDate&quot;:&quot;2021-04-04&quot;,&quot;brandId&quot;:51,&quot;brandName&quot;:&quot;苹果&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180607/timg.jpg&quot;,&quot;categoryId&quot;:19,&quot;categoryName&quot;:&quot;手机通讯&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:1,&quot;attrName&quot;:&quot;cpu&quot;,&quot;attrValue&quot;:&quot;4核&quot;&#125;,&#123;&quot;attrId&quot;:2,&quot;attrName&quot;:&quot;颜色&quot;,&quot;attrValue&quot;:&quot;金色&quot;&#125;]&#125;PUT /product_db/_doc/5&#123;&quot;id&quot;:&quot;30&quot;,&quot;name&quot;:&quot;HLA海澜之家简约动物印花短袖T恤&quot;,&quot;keywords&quot;:&quot;海澜之家衣服&quot;,&quot;subTitle&quot;:&quot;HLA海澜之家短袖T恤&quot;,&quot;price&quot;:&quot;199&quot;,&quot;promotionPrice&quot;:&quot;99&quot;,&quot;originalPrice&quot;:&quot;299&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/5ad83a4fN6ff67ecd.jpg!cc_350x449.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:19,&quot;putawayDate&quot;:&quot;2021-04-05&quot;,&quot;brandId&quot;:50,&quot;brandName&quot;:&quot;海澜之家&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/99d3279f1029d32b929343b09d3c72de_222_222.jpg&quot;,&quot;categoryId&quot;:8,&quot;categoryName&quot;:&quot;T恤&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:3,&quot;attrName&quot;:&quot;尺寸&quot;,&quot;attrValue&quot;:&quot;M&quot;&#125;,&#123;&quot;attrId&quot;:4,&quot;attrName&quot;:&quot;颜色&quot;,&quot;attrValue&quot;:&quot;黑色&quot;&#125;]&#125;PUT /product_db/_doc/6&#123;&quot;id&quot;:&quot;31&quot;,&quot;name&quot;:&quot;HLA海澜之家蓝灰花纹圆领针织布短袖T恤&quot;,&quot;keywords&quot;:&quot;海澜之家衣服&quot;,&quot;subTitle&quot;:&quot;HLA海澜之家短袖T恤&quot;,&quot;price&quot;:&quot;299&quot;,&quot;promotionPrice&quot;:&quot;199&quot;,&quot;originalPrice&quot;:&quot;299&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/5ac98b64N70acd82f.jpg!cc_350x449.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:399,&quot;putawayDate&quot;:&quot;2021-04-06&quot;,&quot;brandId&quot;:50,&quot;brandName&quot;:&quot;海澜之家&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/99d3279f1029d32b929343b09d3c72de_222_222.jpg&quot;,&quot;categoryId&quot;:8,&quot;categoryName&quot;:&quot;T恤&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:3,&quot;attrName&quot;:&quot;尺寸&quot;,&quot;attrValue&quot;:&quot;X&quot;&#125;,&#123;&quot;attrId&quot;:4,&quot;attrName&quot;:&quot;颜色&quot;,&quot;attrValue&quot;:&quot;蓝灰&quot;&#125;]&#125;PUT /product_db/_doc/7&#123;&quot;id&quot;:&quot;32&quot;,&quot;name&quot;:&quot;HLA海澜之家短袖T恤男基础款&quot;,&quot;keywords&quot;:&quot;海澜之家衣服&quot;,&quot;subTitle&quot;:&quot;HLA海澜之家短袖T恤&quot;,&quot;price&quot;:&quot;269&quot;,&quot;promotionPrice&quot;:&quot;169&quot;,&quot;originalPrice&quot;:&quot;399&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/5a51eb88Na4797877.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:399,&quot;putawayDate&quot;:&quot;2021-04-07&quot;,&quot;brandId&quot;:50,&quot;brandName&quot;:&quot;海澜之家&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/99d3279f1029d32b929343b09d3c72de_222_222.jpg&quot;,&quot;categoryId&quot;:8,&quot;categoryName&quot;:&quot;T恤&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:3,&quot;attrName&quot;:&quot;尺寸&quot;,&quot;attrValue&quot;:&quot;L&quot;&#125;,&#123;&quot;attrId&quot;:4,&quot;attrName&quot;:&quot;颜色&quot;,&quot;attrValue&quot;:&quot;蓝色&quot;&#125;]&#125;PUT /product_db/_doc/8&#123;&quot;id&quot;:&quot;33&quot;,&quot;name&quot;:&quot;小米（MI）小米电视4A &quot;,&quot;keywords&quot;:&quot;小米电视机家用电器&quot;,&quot;subTitle&quot;:&quot;小米（MI）小米电视4A 55英寸 L55M5-AZ/L55M5-AD 2GB+8GB HDR 4K超高清 人工智能网络液晶平板电视&quot;,&quot;price&quot;:&quot;2269&quot;,&quot;promotionPrice&quot;:&quot;2169&quot;,&quot;originalPrice&quot;:&quot;2399&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/5b02804dN66004d73.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:132,&quot;putawayDate&quot;:&quot;2021-04-09&quot;,&quot;brandId&quot;:6,&quot;brandName&quot;:&quot;小米&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/1e34aef2a409119018a4c6258e39ecfb_222_222.png&quot;,&quot;categoryId&quot;:35,&quot;categoryName&quot;:&quot;手机数码&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:5,&quot;attrName&quot;:&quot;屏幕尺寸&quot;,&quot;attrValue&quot;:&quot;52&quot;&#125;,&#123;&quot;attrId&quot;:6,&quot;attrName&quot;:&quot;机身颜色&quot;,&quot;attrValue&quot;:&quot;黑色&quot;&#125;]&#125;PUT /product_db/_doc/9&#123;&quot;id&quot;:&quot;34&quot;,&quot;name&quot;:&quot;小米（MI）小米电视4A 65英寸&quot;,&quot;keywords&quot;:&quot;小米电视机家用电器&quot;,&quot;subTitle&quot;:&quot;小米（MI）小米电视4A 65英寸 L55M5-AZ/L55M5-AD 2GB+8GB HDR 4K超高清 人工智能网络液晶平板电视&quot;,&quot;price&quot;:&quot;3269&quot;,&quot;promotionPrice&quot;:&quot;3169&quot;,&quot;originalPrice&quot;:&quot;3399&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/5b028530N51eee7d4.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:999,&quot;putawayDate&quot;:&quot;2021-04-10&quot;,&quot;brandId&quot;:6,&quot;brandName&quot;:&quot;小米&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/1e34aef2a409119018a4c6258e39ecfb_222_222.png&quot;,&quot;categoryId&quot;:35,&quot;categoryName&quot;:&quot;手机数码&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:5,&quot;attrName&quot;:&quot;屏幕尺寸&quot;,&quot;attrValue&quot;:&quot;65&quot;&#125;,&#123;&quot;attrId&quot;:6,&quot;attrName&quot;:&quot;机身颜色&quot;,&quot;attrValue&quot;:&quot;金色&quot;&#125;]&#125;PUT /product_db/_doc/10&#123;&quot;id&quot;:&quot;35&quot;,&quot;name&quot;:&quot;耐克NIKE 男子 休闲鞋 ROSHE RUN 运动鞋 511881-010黑色41码&quot;,&quot;keywords&quot;:&quot;耐克运动鞋 鞋子&quot;,&quot;subTitle&quot;:&quot;耐克NIKE 男子 休闲鞋 ROSHE RUN 运动鞋 511881-010黑色41码&quot;,&quot;price&quot;:&quot;569&quot;,&quot;promotionPrice&quot;:&quot;369&quot;,&quot;originalPrice&quot;:&quot;899&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/5b235bb9Nf606460b.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:399,&quot;putawayDate&quot;:&quot;2021-04-11&quot;,&quot;brandId&quot;:58,&quot;brandName&quot;:&quot;NIKE&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/timg (51).jpg&quot;,&quot;categoryId&quot;:29,&quot;categoryName&quot;:&quot;男鞋&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:7,&quot;attrName&quot;:&quot;尺码&quot;,&quot;attrValue&quot;:&quot;42&quot;&#125;,&#123;&quot;attrId&quot;:8,&quot;attrName&quot;:&quot;颜色&quot;,&quot;attrValue&quot;:&quot;黑色&quot;&#125;]&#125;PUT /product_db/_doc/11&#123;&quot;id&quot;:&quot;36&quot;,&quot;name&quot;:&quot;耐克NIKE 男子 气垫 休闲鞋 AIR MAX 90 ESSENTIAL 运动鞋 AJ1285-101白色41码&quot;,&quot;keywords&quot;:&quot;耐克运动鞋 鞋子&quot;,&quot;subTitle&quot;:&quot;AIR MAX 90 ESSENTIAL 运动鞋 AJ1285-101白色&quot;,&quot;price&quot;:&quot;769&quot;,&quot;promotionPrice&quot;:&quot;469&quot;,&quot;originalPrice&quot;:&quot;999&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/5b19403eN9f0b3cb8.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:499,&quot;putawayDate&quot;:&quot;2021-04-13&quot;,&quot;brandId&quot;:58,&quot;brandName&quot;:&quot;NIKE&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/timg (51).jpg&quot;,&quot;categoryId&quot;:29,&quot;categoryName&quot;:&quot;男鞋&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:7,&quot;attrName&quot;:&quot;尺码&quot;,&quot;attrValue&quot;:&quot;44&quot;&#125;,&#123;&quot;attrId&quot;:8,&quot;attrName&quot;:&quot;颜色&quot;,&quot;attrValue&quot;:&quot;白色&quot;&#125;]&#125;PUT /product_db/_doc/12&#123;&quot;id&quot;:&quot;37&quot;,&quot;name&quot;:&quot;(华为)HUAWEI MateBook X Pro 2019款 13.9英寸3K触控全面屏 轻薄笔记本&quot;,&quot;keywords&quot;:&quot;轻薄笔记本华为 笔记本电脑&quot;,&quot;subTitle&quot;:&quot;轻薄华为笔记本 电脑&quot;,&quot;price&quot;:&quot;4769&quot;,&quot;promotionPrice&quot;:&quot;4469&quot;,&quot;originalPrice&quot;:&quot;4999&quot;,&quot;pic&quot;:&quot;http://tuling-mall.oss-cn-shenzhen.aliyuncs.com/tulingmall/images/20200317/800_800_1555752016264mp.png&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:699,&quot;putawayDate&quot;:&quot;2021-04-14&quot;,&quot;brandId&quot;:3,&quot;brandName&quot;:&quot;华为&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/17f2dd9756d9d333bee8e60ce8c03e4c_222_222.jpg&quot;,&quot;categoryId&quot;:19,&quot;categoryName&quot;:&quot;手机通讯&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:9,&quot;attrName&quot;:&quot;容量&quot;,&quot;attrValue&quot;:&quot;16G&quot;&#125;,&#123;&quot;attrId&quot;:10,&quot;attrName&quot;:&quot;网络&quot;,&quot;attrValue&quot;:&quot;4G&quot;&#125;]&#125;PUT /product_db/_doc/13&#123;&quot;id&quot;:&quot;38&quot;,&quot;name&quot;:&quot;华为nova6se 手机 绮境森林 全网通（8G+128G)&quot;,&quot;keywords&quot;:&quot;轻薄笔记本华为 手机&quot;,&quot;subTitle&quot;:&quot;华为nova6se 手机&quot;,&quot;price&quot;:&quot;6769&quot;,&quot;promotionPrice&quot;:&quot;6469&quot;,&quot;originalPrice&quot;:&quot;6999&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180607/5ac1bf58Ndefaac16.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:899,&quot;putawayDate&quot;:&quot;2021-04-15&quot;,&quot;brandId&quot;:3,&quot;brandName&quot;:&quot;华为&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/17f2dd9756d9d333bee8e60ce8c03e4c_222_222.jpg&quot;,&quot;categoryId&quot;:19,&quot;categoryName&quot;:&quot;手机通讯&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:9,&quot;attrName&quot;:&quot;容量&quot;,&quot;attrValue&quot;:&quot;64G&quot;&#125;,&#123;&quot;attrId&quot;:10,&quot;attrName&quot;:&quot;网络&quot;,&quot;attrValue&quot;:&quot;5G&quot;&#125;]&#125;PUT /product_db/_doc/14&#123;&quot;id&quot;:&quot;39&quot;,&quot;name&quot;:&quot;iPhone7/6s/8钢化膜苹果8Plus全屏复盖抗蓝光防窥防偷看手机膜&quot;,&quot;keywords&quot;:&quot;手机膜&quot;,&quot;subTitle&quot;:&quot;iPhone7/6s/8钢化膜苹果8Plus全屏复盖抗蓝光防窥防偷看手机膜&quot;,&quot;price&quot;:&quot;29&quot;,&quot;promotionPrice&quot;:&quot;39&quot;,&quot;originalPrice&quot;:&quot;49&quot;,&quot;pic&quot;:&quot;http://tuling-mall.oss-cn-shenzhen.aliyuncs.com/tulingmall/images/20200311/6df99dab78bb2014.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:799,&quot;putawayDate&quot;:&quot;2021-04-16&quot;,&quot;brandId&quot;:51,&quot;brandName&quot;:&quot;苹果&quot;,&quot;brandImg&quot;:&quot;http://tuling-mall.oss-cn-shenzhen.aliyuncs.com/tulingmall/images/20200311/2b84746650fc122d67749a876c453619.png&quot;,&quot;categoryId&quot;:30,&quot;categoryName&quot;:&quot;手机配件&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:11,&quot;attrName&quot;:&quot;手机膜-材料&quot;,&quot;attrValue&quot;:&quot;钢化&quot;&#125;,&#123;&quot;attrId&quot;:12,&quot;attrName&quot;:&quot;手机膜-颜色&quot;,&quot;attrValue&quot;:&quot;白色&quot;&#125;]&#125;PUT /product_db/_doc/15&#123;&quot;id&quot;:&quot;40&quot;,&quot;name&quot;:&quot;七匹狼短袖T恤男纯棉舒适春夏修身运动休闲短袖三条装 圆领3条装&quot;,&quot;keywords&quot;:&quot;七匹狼服装 衣服&quot;,&quot;subTitle&quot;:&quot;七匹狼短袖T恤男纯棉舒适春夏修身运动休闲短袖三条装 圆领3条装&quot;,&quot;price&quot;:&quot;129&quot;,&quot;promotionPrice&quot;:&quot;139&quot;,&quot;originalPrice&quot;:&quot;149&quot;,&quot;pic&quot;:&quot;http://tuling-mall.oss-cn-shenzhen.aliyuncs.com/tulingmall/images/20200311/19e846e727dff337.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:199,&quot;putawayDate&quot;:&quot;2021-04-20&quot;,&quot;brandId&quot;:49,&quot;brandName&quot;:&quot;七匹狼&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/18d8bc3eb13533fab466d702a0d3fd1f40345bcd.jpg&quot;,&quot;categoryId&quot;:8,&quot;categoryName&quot;:&quot;T恤&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:3,&quot;attrName&quot;:&quot;尺寸&quot;,&quot;attrValue&quot;:&quot;M&quot;&#125;,&#123;&quot;attrId&quot;:4,&quot;attrName&quot;:&quot;颜色&quot;,&quot;attrValue&quot;:&quot;白色&quot;&#125;]&#125;PUT /product_db/_doc/16&#123;&quot;id&quot;:&quot;41&quot;,&quot;name&quot;:&quot;华为P40 Pro手机&quot;,&quot;keywords&quot;:&quot;华为手机&quot;,&quot;subTitle&quot;:&quot;华为P40 Pro手机&quot;,&quot;price&quot;:&quot;2129&quot;,&quot;promotionPrice&quot;:&quot;2139&quot;,&quot;originalPrice&quot;:&quot;2149&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180607/5ac1bf58Ndefaac16.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:199,&quot;putawayDate&quot;:&quot;2021-05-03&quot;,&quot;brandId&quot;:3,&quot;brandName&quot;:&quot;华为&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/17f2dd9756d9d333bee8e60ce8c03e4c_222_222.jpg&quot;,&quot;categoryId&quot;:19,&quot;categoryName&quot;:&quot;手机通讯&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:9,&quot;attrName&quot;:&quot;容量&quot;,&quot;attrValue&quot;:&quot;128G&quot;&#125;,&#123;&quot;attrId&quot;:10,&quot;attrName&quot;:&quot;网络&quot;,&quot;attrValue&quot;:&quot;5G&quot;&#125;]&#125;PUT /product_db/_doc/17&#123;&quot;id&quot;:&quot;42&quot;,&quot;name&quot;:&quot;朵唯智能手机 4G全网通 老人学生双卡双待手机&quot;,&quot;keywords&quot;:&quot;朵唯手机&quot;,&quot;subTitle&quot;:&quot;朵唯手机后置双摄，国产虎贲芯片！优化散热结构！浅薄机身！朵唯4月特惠！&quot;,&quot;price&quot;:&quot;3129&quot;,&quot;promotionPrice&quot;:&quot;3139&quot;,&quot;originalPrice&quot;:&quot;3249&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/xiaomi.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:1199,&quot;putawayDate&quot;:&quot;2021-06-01&quot;,&quot;brandId&quot;:59,&quot;brandName&quot;:&quot;朵唯&quot;,&quot;brandImg&quot;:&quot;http://tuling-mall.oss-cn-shenzhen.aliyuncs.com/tulingmall/images/20200311/2b84746650fc122d67749a876c453619.png&quot;,&quot;categoryId&quot;:19,&quot;categoryName&quot;:&quot;手机通讯&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:9,&quot;attrName&quot;:&quot;容量&quot;,&quot;attrValue&quot;:&quot;32G&quot;&#125;,&#123;&quot;attrId&quot;:10,&quot;attrName&quot;:&quot;网络&quot;,&quot;attrValue&quot;:&quot;4G&quot;&#125;]&#125; 检索DSL语句构建 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647POST /product_db/_doc/_search&#123; &quot;from&quot;: 0, &quot;size&quot;: 8, &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [&#123;&quot;match&quot;: &#123;&quot;name&quot;: &#123;&quot;query&quot;: &quot;手机&quot;&#125;&#125;&#125;], &quot;filter&quot;: [ &#123;&quot;term&quot;: &#123;&quot;hasStock&quot;: &#123;&quot;value&quot;: true&#125;&#125;&#125;, &#123;&quot;range&quot;: &#123;&quot;price&quot;: &#123;&quot;from&quot;: &quot;1&quot;,&quot;to&quot;: &quot;5000&quot;&#125;&#125;&#125; ] &#125; &#125;, &quot;sort&quot;: [&#123;&quot;salecount&quot;: &#123;&quot;order&quot;: &quot;asc&quot;&#125;&#125;], &quot;aggregations&quot;: &#123; &quot;brand_agg&quot;: &#123; &quot;terms&quot;: &#123;&quot;field&quot;: &quot;brandId&quot;,&quot;size&quot;: 50&#125;, &quot;aggregations&quot;: &#123; &quot;brand_name_agg&quot;: &#123;&quot;terms&quot;: &#123;&quot;field&quot;: &quot;brandName&quot;&#125;&#125;, &quot;brand_img_agg&quot;: &#123;&quot;terms&quot;: &#123;&quot;field&quot;: &quot;brandImg&quot;&#125;&#125; &#125; &#125;, &quot;category_agg&quot;: &#123; &quot;terms&quot;: &#123;&quot;field&quot;: &quot;categoryId&quot;,&quot;size&quot;: 50,&quot;min_doc_count&quot;: 1&#125;, &quot;aggregations&quot;: &#123; &quot;category_name_agg&quot;: &#123;&quot;terms&quot;: &#123;&quot;field&quot;: &quot;categoryName&quot;&#125;&#125; &#125; &#125;, &quot;attr_agg&quot;: &#123; &quot;nested&quot;: &#123;&quot;path&quot;: &quot;attrs&quot;&#125;, &quot;aggregations&quot;: &#123; &quot;attr_id_agg&quot;: &#123; &quot;terms&quot;: &#123;&quot;field&quot;: &quot;attrs.attrId&quot;&#125;, &quot;aggregations&quot;: &#123; &quot;attr_name_agg&quot;: &#123;&quot;terms&quot;: &#123;&quot;field&quot;: &quot;attrs.attrName&quot;&#125;&#125;, &quot;attr_value_agg&quot;: &#123;&quot;terms&quot;: &#123;&quot;field&quot;: &quot;attrs.attrValue&quot;&#125;&#125; &#125; &#125; &#125; &#125; &#125;, &quot;highlight&quot;: &#123; &quot;pre_tags&quot;: [&quot;&lt;b style=&#x27;color:red&#x27;&gt;&quot;], &quot;post_tags&quot;: [&quot;&lt;/b&gt;&quot;], &quot;fields&quot;: &#123;&quot;name&quot;: &#123;&#125;&#125; &#125;&#125; Java代码实现 1234567@ResponseBody@RequestMapping(value = &quot;/searchList&quot;)public CommonResult&lt;ESResponseResult&gt; listPage(ESRequestParam param, HttpServletRequest request) &#123; // 根据传递来的页面的查询参数，去es中检索商品 ESResponseResult searchResult = tulingMallSearchService.search(param); return CommonResult.success(searchResult);&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221@Overridepublic ESResponseResult search(ESRequestParam param) &#123; try &#123; // 构建检索对象-封装请求相关参数信息 SearchRequest searchRequest = startBuildRequestParam(param); // 进行检索操作 SearchResponse response = client.search(searchRequest, RequestOptions.DEFAULT); // 分析响应数据，封装成指定的格式 ESResponseResult responseResult = startBuildResponseResult(response, param); return responseResult; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null;&#125;/** * 封装请求参数信息，关键字查询、根据属性、分类、品牌、价格区间、是否有库存等进行过滤、分页、高亮、以及聚合统计品牌分类属性 */private SearchRequest startBuildRequestParam(ESRequestParam param) &#123; SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); // 关键字查询、根据属性、分类、品牌、价格区间、是否有库存等进行过滤、分页、高亮、以及聚合统计品牌分类属性 BoolQueryBuilder boolQueryBuilder = new BoolQueryBuilder(); if (!StringUtils.isEmpty(param.getKeyword())) &#123; //单字段查询 boolQueryBuilder.must(QueryBuilders.matchQuery(&quot;name&quot;, param.getKeyword())); //多字段查询 boolQueryBuilder.must(QueryBuilders.multiMatchQuery(param.getKeyword(),&quot;name&quot;,&quot;keywords&quot;,&quot;subTitle&quot;)); &#125; // 根据类目ID进行过滤 if (null != param.getCategoryId()) &#123; boolQueryBuilder.filter(QueryBuilders.termQuery(&quot;categoryId&quot;, param.getCategoryId())); &#125; // 根据品牌ID进行过滤 if (null != param.getBrandId() &amp;&amp; param.getBrandId().size() &gt; 0) &#123; boolQueryBuilder.filter(QueryBuilders.termsQuery(&quot;brandId&quot;, param.getBrandId())); &#125; // 根据属性进行相关过滤 if (param.getAttrs() != null &amp;&amp; param.getAttrs().size() &gt; 0) &#123; param.getAttrs().forEach(item -&gt; &#123; //attrs=1_白色&amp;2_4核 BoolQueryBuilder boolQuery = QueryBuilders.boolQuery(); //attrs=1_64G String[] s = item.split(&quot;_&quot;); String attrId = s[0]; String[] attrValues = s[1].split(&quot;:&quot;);//这个属性检索用的值 boolQuery.must(QueryBuilders.termQuery(&quot;attrs.attrId&quot;, attrId)); boolQuery.must(QueryBuilders.termsQuery(&quot;attrs.attrValue&quot;, attrValues)); NestedQueryBuilder nestedQueryBuilder = QueryBuilders.nestedQuery(&quot;attrs&quot;, boolQuery, ScoreMode.None); boolQueryBuilder.filter(nestedQueryBuilder); &#125;); &#125; // 是否有库存 if (null != param.getHasStock()) &#123; boolQueryBuilder.filter(QueryBuilders.termQuery(&quot;hasStock&quot;, param.getHasStock() == 1)); &#125; // 根据价格过滤 if (!StringUtils.isEmpty(param.getPrice())) &#123; // 价格的输入形式为：10-100（起始价格和最终价格）或-100（不指定起始价格）或10-（不限制最终价格） RangeQueryBuilder rangeQueryBuilder = QueryBuilders.rangeQuery(&quot;price&quot;); String[] price = param.getPrice().split(&quot;_&quot;); if (price.length == 2) &#123; rangeQueryBuilder.gte(price[0]).lte(price[1]); &#125; else if (price.length == 1) &#123; if (param.getPrice().startsWith(&quot;_&quot;)) &#123; rangeQueryBuilder.lte(price[1]); &#125; if (param.getPrice().endsWith(&quot;_&quot;)) &#123; rangeQueryBuilder.gte(price[0]); &#125; &#125; boolQueryBuilder.filter(rangeQueryBuilder); &#125; // 封装所有查询条件 searchSourceBuilder.query(boolQueryBuilder); //实现排序、高亮、分页操作，排序，页面传入的参数值形式 sort=price_asc/desc if (!StringUtils.isEmpty(param.getSort())) &#123; String sort = param.getSort(); String[] sortFileds = sort.split(&quot;_&quot;); System.out.println(&quot;sortFileds:&quot;+sortFileds.length); if(!StringUtils.isEmpty(sortFileds[0]))&#123; SortOrder sortOrder = &quot;asc&quot;.equalsIgnoreCase(sortFileds[1]) ? SortOrder.ASC : SortOrder.DESC; searchSourceBuilder.sort(sortFileds[0], sortOrder); &#125; &#125; // 分页查询 searchSourceBuilder.from((param.getPageNum() - 1) * SearchConstant.PAGE_SIZE); searchSourceBuilder.size(SearchConstant.PAGE_SIZE); // 高亮显示 if (!StringUtils.isEmpty(param.getKeyword())) &#123; HighlightBuilder highlightBuilder = new HighlightBuilder(); highlightBuilder.field(&quot;name&quot;); highlightBuilder.preTags(&quot;&lt;b style=&#x27;color:red&#x27;&gt;&quot;); highlightBuilder.postTags(&quot;&lt;/b&gt;&quot;); searchSourceBuilder.highlighter(highlightBuilder); &#125; // 对品牌、分类信息、属性信息进行聚合分析，按照品牌进行聚合 TermsAggregationBuilder brand_agg = AggregationBuilders.terms(&quot;brand_agg&quot;); brand_agg.field(&quot;brandId&quot;).size(50); // 品牌的子聚合-品牌名聚合 brand_agg.subAggregation(AggregationBuilders.terms(&quot;brand_name_agg&quot;).field(&quot;brandName&quot;).size(1)); // 品牌的子聚合-品牌图片聚合 brand_agg.subAggregation(AggregationBuilders.terms(&quot;brand_img_agg&quot;).field(&quot;brandImg&quot;).size(1)); searchSourceBuilder.aggregation(brand_agg); // 按照分类信息进行聚合 TermsAggregationBuilder category_agg = AggregationBuilders.terms(&quot;category_agg&quot;); category_agg.field(&quot;categoryId&quot;).size(50); category_agg.subAggregation(AggregationBuilders.terms(&quot;category_name_agg&quot;).field(&quot;categoryName&quot;).size(1)); searchSourceBuilder.aggregation(category_agg); // 按照属性信息进行聚合 NestedAggregationBuilder attr_agg = AggregationBuilders.nested(&quot;attr_agg&quot;, &quot;attrs&quot;); // 按照属性ID进行聚合 TermsAggregationBuilder attr_id_agg = AggregationBuilders.terms(&quot;attr_id_agg&quot;).field(&quot;attrs.attrId&quot;); attr_agg.subAggregation(attr_id_agg); // 在每个属性ID下，按照属性名进行聚合 attr_id_agg.subAggregation(AggregationBuilders.terms(&quot;attr_name_agg&quot;).field(&quot;attrs.attrName&quot;).size(1)); // 在每个属性ID下，按照属性值进行聚合 attr_id_agg.subAggregation(AggregationBuilders.terms(&quot;attr_value_agg&quot;).field(&quot;attrs.attrValue&quot;).size(50)); searchSourceBuilder.aggregation(attr_agg); System.out.println(&quot;构建的DSL语句 &#123;&#125;:&quot;+ searchSourceBuilder.toString()); SearchRequest searchRequest = new SearchRequest(new String[]&#123;SearchConstant.INDEX_NAME&#125;, searchSourceBuilder); return searchRequest;&#125;/** * 封装查询到的结果信息，关键字查询、根据属性、分类、品牌、价格区间、是否有库存等进行过滤、分页、高亮、以及聚合统计品牌分类属性 */private ESResponseResult startBuildResponseResult(SearchResponse response, ESRequestParam param) &#123; ESResponseResult result = new ESResponseResult(); // 获取查询到的商品信息 SearchHits hits = response.getHits(); List&lt;EsProduct&gt; esModels = new ArrayList&lt;&gt;(); // 遍历所有商品信息 if (hits.getHits() != null &amp;&amp; hits.getHits().length &gt; 0) &#123; for (SearchHit hit : hits.getHits()) &#123; String sourceAsString = hit.getSourceAsString(); EsProduct esModel = JSON.parseObject(sourceAsString, EsProduct.class); // 判断是否按关键字检索，若是就显示高亮，否则不显示 if (!StringUtils.isEmpty(param.getKeyword())) &#123; // 拿到高亮信息显示标题 HighlightField name = hit.getHighlightFields().get(&quot;name&quot;); // 判断name中是否含有查询的关键字(因为是多字段查询，因此可能不包含指定的关键字，假设不包含则显示原始name字段的信息) String nameValue = name!=null ? name.getFragments()[0].string() : esModel.getName(); esModel.setName(nameValue); &#125; esModels.add(esModel); &#125; &#125; result.setProducts(esModels); // 当前商品涉及到的所有品牌信息，小米手机和小米电脑都属于小米品牌，过滤重复品牌信息 Set&lt;ESResponseResult.BrandVo&gt; brandVos = new LinkedHashSet&lt;&gt;(); // 获取到品牌的聚合 ParsedLongTerms brandAgg = response.getAggregations().get(&quot;brand_agg&quot;); for (Terms.Bucket bucket : brandAgg.getBuckets()) &#123; ESResponseResult.BrandVo brandVo = new ESResponseResult.BrandVo(); // 获取品牌的id long brandId = bucket.getKeyAsNumber().longValue(); brandVo.setBrandId(brandId); // 获取品牌的名字 ParsedStringTerms brandNameAgg = bucket.getAggregations().get(&quot;brand_name_agg&quot;); String brandName = brandNameAgg.getBuckets().get(0).getKeyAsString(); brandVo.setBrandName(brandName); // 获取品牌的LOGO ParsedStringTerms brandImgAgg = bucket.getAggregations().get(&quot;brand_img_agg&quot;); String brandImg = brandImgAgg.getBuckets().get(0).getKeyAsString(); brandVo.setBrandImg(brandImg); System.out.println(&quot;brandId:&quot;+brandId+&quot;brandName:&quot;+brandName+&quot;brandImg&quot;); brandVos.add(brandVo); &#125; System.out.println(&quot;brandVos.size:&quot;+brandVos.size()); result.setBrands(brandVos); // 当前商品相关的所有类目信息，获取到分类的聚合 List&lt;ESResponseResult.categoryVo&gt; categoryVos = new ArrayList&lt;&gt;(); ParsedLongTerms categoryAgg = response.getAggregations().get(&quot;category_agg&quot;); for (Terms.Bucket bucket : categoryAgg.getBuckets()) &#123; ESResponseResult.categoryVo categoryVo = new ESResponseResult.categoryVo(); // 获取分类id String keyAsString = bucket.getKeyAsString(); categoryVo.setCategoryId(Long.parseLong(keyAsString)); // 获取分类名 ParsedStringTerms categoryNameAgg = bucket.getAggregations().get(&quot;category_name_agg&quot;); String categoryName = categoryNameAgg.getBuckets().get(0).getKeyAsString(); categoryVo.setCategoryName(categoryName); categoryVos.add(categoryVo); &#125; result.setCategorys(categoryVos); // 获取商品相关的所有属性信息 List&lt;ESResponseResult.AttrVo&gt; attrVos = new ArrayList&lt;&gt;(); // 获取属性信息的聚合 ParsedNested attrsAgg = response.getAggregations().get(&quot;attr_agg&quot;); ParsedLongTerms attrIdAgg = attrsAgg.getAggregations().get(&quot;attr_id_agg&quot;); for (Terms.Bucket bucket : attrIdAgg.getBuckets()) &#123; ESResponseResult.AttrVo attrVo = new ESResponseResult.AttrVo(); // 获取属性ID值 long attrId = bucket.getKeyAsNumber().longValue(); attrVo.setAttrId(attrId); // 获取属性的名字 ParsedStringTerms attrNameAgg = bucket.getAggregations().get(&quot;attr_name_agg&quot;); String attrName = attrNameAgg.getBuckets().get(0).getKeyAsString(); attrVo.setAttrName(attrName); // 获取属性的值 ParsedStringTerms attrValueAgg = bucket.getAggregations().get(&quot;attr_value_agg&quot;); List&lt;String&gt; attrValues = attrValueAgg.getBuckets().stream().map(item -&gt; item.getKeyAsString()).collect(Collectors.toList()); attrVo.setAttrValue(attrValues); attrVos.add(attrVo); &#125; result.setAttrs(attrVos); // 进行分页操作 result.setPageNum(param.getPageNum()); // 获取总记录数 long total = hits.getTotalHits().value; result.setTotal(total); // 计算总页码 int totalPages = (int) total % SearchConstant.PAGE_SIZE == 0 ? (int) total / SearchConstant.PAGE_SIZE : ((int) total / SearchConstant.PAGE_SIZE + 1); result.setTotalPages(totalPages); List&lt;Integer&gt; pageNavs = new ArrayList&lt;&gt;(); for (int i = 1; i &lt;= totalPages; i++) &#123; pageNavs.add(i); &#125; result.setPageNavs(pageNavs); return result;&#125;","tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"http://example.com/tags/ElasticSearch/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"ElasticSearch","slug":"工具和中间件/搜索引擎技术/ElasticSearch","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/ElasticSearch/"}]},{"title":"ElasticSearch基础","date":"2022-01-02T02:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/ElasticSearch/ElasticSearch基础/","text":"Elasticsearch是什么？ Elasticsearch 是用 Java开发 的当前 最流行 的 开源 的企业级搜索引擎,能够达到 实时搜索, 稳定, 可靠, 快速,安装使用方便。 和Solr一样的,Elasticsearch 是基于 Lucene 进行了封装, 提供了更为便利的访问和调用, Lucene可被认为是迄今为止最先进、性能最好、功能最全的搜索引擎框架。 ES与Solr对比：单纯对已有数据进行搜索时 Solr更快,当实时建立索引时Solr会产生 IO阻塞,查询性能较差,该情况下 Elasticsearch 具有明显优势。 Solr利用Zookeeper进行分布式管理,而 Elasticsearch自带分布式协调管理功能 Solr支持更多格式数据,如JSON、XML、CSV,而 Elasticsearch仅支持JSON文件格式 Solr在传统搜索应用中表现好于Elasticsearch,但在处理实时搜索应用时效率明显低于Elasticsearch Solr是传统搜索应用的有力解决方案,但Elasticsearch更适用于新兴实时搜索应用。 ES与关系型数据库: 关系型数据库 Database数据库 Table表 ROW行 Column列 Elasticsearch Index索引库 Type类型 Document文档 Field字段 ES核心概念: 索引index:一个索引就是一个拥有几分相似特征的文档集合,相当于关系型数据库中的database,一个索引由一个名字来标识, 必须全部是小写字母,且当要对对应于该索引中的文档进行索引搜索、更新和删除时,都要使用该名字。 Mapping映射:ElasticSearch中的Mapping映射用来定义一个文档,Mapping是处理数据的方式和规则方面做一些限制,如某个字段的数据类型、默认值、分词器、是否被索引等,这都是映射里面可设置的。 Field字段:相当于是数据表的字段或列。 Type字段类型：每个字段都应该有一个对应的类型,如 Text、Keyword、Byte 等。 Document文档：一个文档是一个可被索引的基础信息单元,类似一条记录, 文档以JSON格式来表示。 Cluster集群：一个集群由一个或多个节点组织在一起, 共同持有整个数据,并一起提供索引和搜索功能 Node节点：一个节点即集群中一个服务器,作为集群的一部分,它存储数据,参与集群的索引和搜索功能,一个节点可通过配置集群名称的方式来加入一个指定的集群。默认每个节点都会被安排加入到一个叫做 elasticsearch的集群中。一个集群中可拥有任意多个节点,且若当前网络中没有运行任何Elasticsearch节点,这时启动一个节点,会默认创建并加入一个叫做 elasticsearch 的集群。 分片：一个索引可存储超出单个结点硬件限制的大量数据,如一个具有10亿文档的索引占据1TB磁盘空间,而任一节点都没有这样大的磁盘空间,或者单个节点处理搜索请求,响应太慢,为了解决这个问题,Elasticsearch提供了将索引划分成多份的能力,每一份就是一个分片。当创建索引时可指定分片数量, 每个分片本身也是一个功能完善且独立的索引,该分片可被放置到集群中任何节点上, 分片允许水平分割扩展内容容量,允许在分片之上进行分布式并行操作,进而提高性能和吞吐量,每个分片怎样分布, 文档怎样聚合回搜索请求,完全由Elasticsearch管理,对于用户透明 副本：在一个网络环境中,失败随时都可能发生,在某个分片或节点处于离线状态,或由于任何原因消失,该情况下有一个故障转移机制是非常有用且强烈推荐。为此 Elasticsearch允许创建分片的一份或多份拷贝,这些拷贝叫做副本分片或直接叫副本。扩展搜索量和吞吐量,搜索可在所有的副本上并行运行, 每个索引可被分成多个分片, 一个索引有零个或者多个副本, 一旦设置了副本,每个索引就有了主分片和副本分片, 分片和副本数量可在索引创建时指定,在索引创建后, 可在任何时候动态地改变副本数量,但不能改变分片数量。 ES安装注： ES不能使用root用户来启动,必须使用普通用户来安装启动。 12345678910groupadd elasticsearch # 创建elasticsearch用户组useradd eleven # 创建eleven用户passwd eleven # 给eleven用户设置密码为elevenusermod -G elasticsearch eleven # 将用户eleven添加到elasticsearch用户组mkdir -p /usr/local/es # 创建es文件夹chown -R eleven /usr/local/es/elasticsearch-7.6.1 # 修改owner为eleven用户visudo # 使用root用户执行visudo命令然后为es用户添加权限eleven ALL=(ALL) ALL # 在root ALL=(ALL) ALL 一行下面添加eleven用户 修改elasticsearch.yml,可通过修改jvm.options配置文件调整JVM参数: 123456789101112cluster.name: eleven-es # 集群名称node.name: node1 # 节点名称path.data: /usr/local/es/elasticsearch-7.6.1/data # 数据目录path.logs: /usr/local/es/elasticsearch-7.6.1/log # 日志目录network.host: 0.0.0.0http.port: 9200discovery.seed_hosts: [&quot;IP1&quot;, &quot;IP2&quot;, &quot;IP3&quot;]cluster.initial_master_nodes: [&quot;节点1名称&quot;, &quot;节点2名称&quot;, &quot;节点3名称&quot;]bootstrap.system_call_filter: falsebootstrap.memory_lock: falsehttp.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot; ES需要大量创建索引文件,需要大量打开系统文件,所以需要解除linux系统当中打开文件最大数目限制,不然ES启动会抛错：max file descriptors [4096] for elasticsearch process likely too low, increase to at least [65536] 12345sudo vim /etc/security/limits.conf* soft nofile 65536* hard nofile 131072* soft nproc 2048* hard nproc 4096 若出现max number of threads [1024] for user [es] likely too low, increase to at least [4096] 错误信息,是由于普通用户启动线程数限制最大可创建线程数太小,无法创建本地线程问题。 安装IK分词器使用ElasticSearch来进行中文分词,需要单独给Elasticsearch安装IK分词器插件, 123mkdir -p /usr/local/es/elasticsearch-7.6.1/plugins/ikcd /usr/local/es/elasticsearch-7.6.1/plugins/ikunzip elasticsearch-analysis-ik-7.6.1.zip ES的默认分词设置是 standard单字拆分,可使用 IK分词器 的 ik_smart 和 ik_max_word 分词方式, ik_smart 会做 最粗粒度拆分, ik_max_word会将文本做最细粒度拆分。修改默认分词方法,修改 eleven_index索引的默认分词为 ik_max_word 1234567891011121314151617181920212223PUT /school_index&#123; &quot;settings&quot;: &#123; &quot;index&quot;: &#123; &quot;analysis.analyzer.default.type&quot;: &quot;ik_max_word&quot; &#125; &#125;&#125;POST _analyze&#123; &quot;analyzer&quot;: &quot;standard&quot;, &quot;text&quot;: &quot;中华人民共和国&quot;&#125;POST _analyze&#123; &quot;analyzer&quot;: &quot;ik_smart&quot;, &quot;text&quot;: &quot;中华人民共和国&quot;&#125;POST _analyze&#123; &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;text&quot;: &quot;中华人民共和国&quot;&#125; ES基础ES是面向文档Document的, 使用JSON作为文档序列化格式,这其可存储整个对象或文档Document,不仅仅是存储,还会索引index每个文档内容使之可被搜索。ES中可对文档而非成行成列的数据进行索引、搜索、排序、过滤。 条件查询：GET /索引名称/类型/_search?q=字段1:字段值,字段2:字段值,条件之间是通过逗号分隔多个条件,如分页、排序、输出指定字段等通过 &amp;符号分隔 123456789101112131415161718192021222324252627GET _cat/nodes?v // 查看集群节点状态GET _cat/health?v // 查看集群健康状态GET /es_db // 查询索引：GET /索引名称PUT /es_db // 创建索引：PUT /索引名称DELETE /es_db // 删除索引：DELETE /索引名称PUT /es_db/_doc/1 // 添加文档：PUT /索引名称/类型/id&#123; &quot;name&quot;: &quot;张三&quot;, &quot;sex&quot;: 1, &quot;age&quot;: 25, &quot;address&quot;: &quot;广州天河公园&quot;, &quot;remark&quot;: &quot;java developer&quot;&#125;GET /es_db/_doc/1 // 查询文档：GET /索引名称/类型/idDELETE /es_db/_doc/1 // 删除文档：DELETE /索引名称/类型/idGET /es_db/_doc/_search // 查询当前类型中的所有文档：GET /索引名称/类型/_searchGET /es_db/_doc/_search?q=age:28 // 条件查询：GET /索引名称/类型/_search?q=*:***GET /es_db/_doc/_search?q=age[25 TO 26] // 范围查询：GET /索引名称/类型/_search?q=***[** TO **]GET /es_db/_doc/_mget // 根据多个ID进行批量查询：GET /索引名称/类型/_mget&#123;&quot;ids&quot;:[&quot;1&quot;,&quot;2&quot;]&#125;GET /es_db/_doc/_search?q=age:&lt;=28 // 查询小于等于：GET /索引名称/类型/_search?q=age:&lt;=**GET /es_db/_doc/_search?q=age:&gt;=28 // 查询大于等于：GET /索引名称/类型/_search?q=age:&gt;=**GET /es_db/_doc/_search?q=age[25 TO 26]&amp;from=0&amp;size=1 // 分页查询：from=*&amp;size=*GET /es_db/_doc/_search?_source=name,age // 对查询结果只输出某些字段：_search?_source=字段,字段GET /es_db/_doc/_search?q=age[25 TO 26],sex:0 // 多条件查询GET /es_db/_doc/_search?sort=age:desc // 对查询结果排序sort=字段:desc/asc ES是基于Restful API和所有客户端交互都是使用JSON格式数据,其他所有程序语言都可使用RESTful API,通过9200端口的与ES进行通信,GET查询、PUT添加、POST修改、DELETE删除, POST和PUT都能起到创建&#x2F;更新的作用： PUT需要对一个具体的资源进行操作,也就是要确定id才能进行更新&#x2F;创建,而 POST可针对整个资源集合进行操作,若不写id则由ES生成一个唯一id进行创建新文档,过填了id则针对该id文档进行创建&#x2F;更新 PUT会将JSON数据都进行替换,POST只会更新相同字段的值 PUT与DELETE都是幂等性操作,不论操作多少次结果都一样 文档批量操作通过 _mget 的API来实现 批量操作多个文档,可通过 _id 批量获取 不同index和type的数据,若查询的是同一个文档可将index和type放到URL上。且可 通过_source指定查询字段。 1234567891011121314151617181920212223242526GET _mget&#123; &quot;docs&quot;: [ &#123; &quot;_index&quot;: &quot;es_db_1&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: 1, &#125;, &#123; &quot;_index&quot;: &quot;es_db&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: 2 &#125; ]&#125;GET /es_db/_doc/_mget?_source=age,name&#123; &quot;docs&quot;: [ &#123; &quot;_id&quot;: 1 &#125;, &#123; &quot;_id&quot;: 2 &#125; ]&#125; 批量 对文档进行 写操作 是通过 _bulk 的API来实现的,通过 _bulk 写操作文档,一般至少有两行参数,第一行参数为指定 操作的类型 及 操作的对象 如index、type、id,第二行参数为 操作的数据. actionName 表示 操作类型, 主要有 create、index、delete、update 。 1234567891011&#123; &quot;actionName&quot;: &#123; &quot;_index&quot;: &quot;indexName&quot;, &quot;_type&quot;: &quot;typeName&quot;, &quot;_id&quot;: &quot;id&quot; &#125;&#125;&#123; &quot;field1&quot;: &quot;value1&quot;, &quot;field2&quot;: &quot;value2&quot;&#125; 1234567891011&#123; &quot;actionName&quot;: &#123; &quot;_index&quot;: &quot;indexName&quot;, &quot;_type&quot;: &quot;typeName&quot;, &quot;_id&quot;: &quot;id&quot; &#125;&#125;&#123; &quot;field1&quot;: &quot;value1&quot;, &quot;field2&quot;: &quot;value2&quot;&#125; 乐观并发控制在数据库领域中,有悲观并发控制和乐观并发控制两种方法来确保并发更新不丢失数据, 悲观并发控制被关系型数据库广泛使用,阻塞访问资源以防止冲突；ES使用乐观并发控制,若源数据在读写当中被修改,更新将会失败。 12345678PUT /db_index/_doc/1?if_seq_no=1&amp;if_primary_term=1&#123; &quot;name&quot;: &quot;Jack&quot;, &quot;sex&quot;: 1, &quot;age&quot;: 25, &quot;book&quot;: &quot;Spring Boot 入门到精通2&quot;, &quot;remark&quot;: &quot;hello world2&quot;&#125; ES老版本是使用 version字段来乐观并发控制,新版本7.x使用if_seq_no&#x3D;文档版本号&amp;if_primary_term&#x3D;文档位置来乐观并发控制。 每当Primary Shard发生重新分配时如 重启, Primary选举 等, _primary_term会递增1, _primary_term 主要是用来 恢复数据时 处理当多个文档的 _seq_no一样 时的冲突. 如当一个shard宕机了,raplica需要用到最新的数据,就会根据_primary_term和_seq_no两个值来拿到最新的document。 文档映射ES中映射可以分为动态映射和静态映射,在关系数据库中,需要事先在数据库下创建数据表,并创建表字段、类型、长度、主键等,最后才能基于表插入数据。而Elasticsearch中不需要定义Mapping映射,在文档写入ES时,会根据文档字段自动识别类型,该机制为动态映射；也可事先定义好映射,包含文档的各字段类型、分词器等,该方式为静态映射 字符串： string类型包含text和keyword text： 该类型被用来索引长文本,创建索引前会将文本进行分词,转化为词的组合,建立索引；允许es来检索这些词, 不能用来排序和聚合 keyword： 该类型不能分词,可被用来检索过滤、排序和聚合, 不可用text进行分词模糊检索 数值型： long、integer、short、byte、double、float 日期型： date 布尔型： boolean 123456789101112131415161718192021222324252627282930313233343536GET /es_db/_mapping // 获取文档映射 PUT /es_db2 // 创建索引且设置文档映射&#123; &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123; &quot;name&quot;: &#123; &quot;type&quot;: &quot;keyword&quot;, &quot;index&quot;: true, &quot;store&quot;: true &#125;, &quot;sex&quot;: &#123; &quot;type&quot;: &quot;integer&quot;, &quot;index&quot;: true, &quot;store&quot;: true &#125;, &quot;age&quot;: &#123; &quot;type&quot;: &quot;integer&quot;, &quot;index&quot;: true, &quot;store&quot;: true &#125;, &quot;book&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;index&quot;: true, &quot;store&quot;: true, &quot;analyzer&quot;: &quot;ik_smart&quot;, // 指定text类型的ik分词器 &quot;search_analyzer&quot;: &quot;ik_smart&quot; // 指定text类型的ik分词器 &#125;, &quot;address&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;index&quot;: true, &quot;store&quot;: true &#125; &#125; &#125;&#125; 若要推倒现有的映射,得重新建立一个静态索引,然后把之前索引里的数据导入到新的索引里, 删除原创建的索引, 为新索引起个别名,为原索引名。 1234567891011POST _reindex // 把之前索引里的数据导入到新的索引里&#123; &quot;source&quot;: &#123; &quot;index&quot;: &quot;db_index&quot; &#125;, &quot;dest&quot;: &#123; &quot;index&quot;: &quot;db_index_2&quot; &#125;&#125;DELETE /db_index // 删除原创建的索引PUT /db_index_2/_alias/db_index // 为新索引起个别名, 为原索引名 若要推倒现有的映射,得重新建立一个静态索引,然后把之前索引里的数据导入到新的索引里, 删除原创建的索引, 为新索引起个别名,为原索引名。 1234567891011POST _reindex // 把之前索引里的数据导入到新的索引里&#123; &quot;source&quot;: &#123; &quot;index&quot;: &quot;db_index&quot; &#125;, &quot;dest&quot;: &#123; &quot;index&quot;: &quot;db_index_2&quot; &#125;&#125;DELETE /db_index // 删除原创建的索引PUT /db_index_2/_alias/db_index // 为新索引起个别名, 为原索引名 DSL高级查询Domain Specific Language领域专用语言,由叶子查询子句和复合查询子句两种子句组成。DSL查询语言又分为查询DSL和过滤DSL。ES中索引的数据都会存储一个 _score分值, 分值越高就代表越匹配, 查询上下文中不仅要判断查询条件与文档是否匹配,且还要关心相关度即 _score分值,需要根据分值排序；过滤器上下文中值关心查询条件与文档是否匹配,不计算 _score分值, 不关心排序问题,经常使用过滤器,ES会自动缓存过滤器内容。 12GET /es_db/_doc/_search // 无查询条件是查询所有,默认查询所有,或使用match_all表示所有&#123;&quot;query&quot;:&#123;&quot;match_all&quot;:&#123;&#125;&#125;&#125; 叶子查询模糊匹配模糊匹配主要是针对文本类型的字段,文本类型的字段会对内容进行分词, 查询时也会对搜索条件进行分词,然后通过倒排索引查找到匹配数据,模糊匹配主要通过 match 等参数来实现 match：通过match关键词模糊匹配条件内容, 需指定字段名, 会进行分词 query：指定匹配的值 operator：匹配条件类型 and：条件分词后都要匹配 or：条件分词后有一个匹配即可,默认为or minmum_should_match：指定最小匹配数量 query_string：和match类似, 可不指定字段即所有字段中搜索,范围更广泛 match_phase：会对输入做分词,但结果中也包含所有分词,且顺序一样 prefix：前缀匹配 regexp：通过正则表达式来匹配数据 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566POST /es_db/_doc/_search&#123; &quot;from&quot;: 0, &quot;size&quot;: 2, &quot;query&quot;: &#123; &quot;match&quot;: &#123; // match会根据该字段的分词器,进行分词查询 &quot;address&quot;: &quot;广州&quot; &#125; &#125;&#125;POST /es_db/_doc/_search&#123; &quot;query&quot;: &#123; &quot;multi_match&quot;: &#123; // 多字段模糊匹配查询 &quot;query&quot;: &quot;长沙&quot;, &quot;fields&quot;: [&quot;address&quot;, &quot;name&quot;] // address或name字段中匹配到“长沙” &#125; &#125;&#125;POST /es_db/_doc/_search&#123; &quot;query&quot;: &#123; &quot;query_string&quot;: &#123; // 未指定字段条件查询query_string, 含AND与OR条件 &quot;query&quot;: &quot;广州 OR 长沙&quot; // 所有的字段中只要包含“广州”或“长沙” &#125; &#125;&#125;POST /es_db/_doc/_search&#123; &quot;query&quot;: &#123; &quot;query_string&quot;: &#123; // 指定字段条件查询query_string &quot;query&quot;: &quot;admin AND 长沙&quot;, &quot;fields&quot;: [&quot;name&quot;, &quot;address&quot;] // name或address匹配admin和长沙 &#125; &#125;&#125;GET /es_db/_search&#123; &quot;query&quot;: &#123; // ES执行搜索时,默认operator为or &quot;match&quot;: &#123; // remark字段包含java或developer词组,则符合搜索条件。 &quot;remark&quot;: &quot;java developer&quot; &#125; &#125;&#125;GET /es_db/_search&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;remark&quot;: &#123; // remark字段包含java和developer词组 &quot;query&quot;: &quot;java developer&quot;, &quot;operator&quot;: &quot;and&quot; &#125; &#125; &#125;&#125;GET /es_db/_search&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;remark&quot;: &#123; // 需要remark字段中包含多个搜索词条中的一定比例 &quot;query&quot;: &quot;java architect assistant&quot;, &quot;minimum_should_match&quot;: &quot;50%&quot; // minimum_should_match可使用百分比或固定数字 &#125; &#125; &#125;&#125; match_phrase短语搜索,使用短语搜索时和match类似,首先对搜索条件进行分词,ES在做分词时除了将数据切分外,还会保留一个词在整个数据中的下标position。当ES执行match phrase短语搜索时,首先将搜索条件分词,然后在倒排索引中检索数据,若搜索条件分词数据在某个document某个field出现时,则检查匹配到的单词的position是否连续,若不连续则匹配失败。 ES对match phrase短语搜索提供了 slop参数,可实现数据在所有匹配结果中,多个单词距离越近相关度评分越高排序越靠前,若当 slop 移动次数使用完毕还没有匹配成功则无搜索结果。 12345678910111213141516171819GET _search&#123; &quot;query&quot;: &#123; &quot;match_phrase&quot;: &#123; // 短语搜索,搜索条件不分词 &quot;remark&quot;: &quot;java assistant&quot; &#125; &#125;&#125;GET /es_db/_search&#123; &quot;query&quot;: &#123; &quot;match_phrase&quot;: &#123; &quot;remark&quot;: &#123; &quot;query&quot;: &quot;java assistant&quot;, &quot;slop&quot;: 1 &#125; &#125; &#125;&#125; 前缀搜索通常针对 keyword 类型字段即不分词字段, keyword类型字段数据大小写敏感, 前缀搜索效率比较低,且不计算相关度分数, 前缀越短效率越低。若使用前缀搜索,建议使用长前缀,因为前缀搜索需要扫描完整索引内容,所以前缀越长相对效率越高。 12345678GET /test_a/_search&#123; &quot;query&quot;: &#123; &quot;prefix&quot;: &#123; &quot;f.keyword&quot;: &#123;&quot;value&quot;: &quot;Jav&quot;&#125; &#125; &#125;&#125; 通配符搜索通配符可在倒排索引中使用,也可在 keyword类型字段中使用。?问号匹配一个任意字符, *星号匹配0到n个任意字符。性能也很低,也需要扫描完整索引。 12345678GET /test_a/_search&#123; &quot;query&quot;: &#123; &quot;wildcard&quot;: &#123; &quot;f.keyword&quot;: &#123; &quot;value&quot;: &quot;?e*o*&quot; &#125; &#125; &#125;&#125; 正则搜索可在 倒排索引 或 keyword 类型字段中使用, 性能很低需要扫描完整索引。 123456GET /test_a/_search&#123; &quot;query&quot;: &#123; &quot;regexp&quot;: &#123;&quot;f.keyword&quot;: &quot;[A-z].+&quot;&#125; &#125;&#125; 搜索推荐其原理和 match phrase类似,先使用match匹配term数据即示例中的java,然后在指定 slop移动次数范围内前缀匹配示例数据sp, max_expansions是用于指定prefix最多匹配多少个term,超过该数量就不再匹配了。该语法限制只有最后一个term会执行前缀搜索。执行性能很差, 最后一个term 需要 扫描所有符合slop要求的倒排索引的term. 若必须使用一定要使用参数 max_expansions. 12345678GET /test_a/_search&#123; &quot;query&quot;: &#123; &quot;match_phrase_prefix&quot;: &#123; &quot;f&quot;: &#123;&quot;query&quot;: &quot;java sp&quot;,&quot;slop&quot;: 10,&quot;max_expansions&quot;: 10&#125; &#125; &#125;&#125; 模糊搜索搜索时可能搜索条件文本输入错误,fuzzy技术就是用于解决错误拼写的,英文中很有效但中文中几乎无效,其中 fuzziness 代表 value值word可修改多少个字母来进行拼写错误纠正,修改字母数量包含字母变更,增加或减少字母. 12345678GET /test_a/_search&#123; &quot;query&quot;: &#123; &quot;fuzzy&quot;: &#123; &quot;f&quot;: &#123;&quot;value&quot;: &quot;word&quot;,&quot;fuzziness&quot;: 2&#125; &#125; &#125;&#125; 精确匹配 term： 单个条件相等,查询字段映射类型属于为 keyword, 不会被分词 terms： 单个字段属于某个值数组内的值 range： 字段属于某个范围内的值 gte： 大于等于 lte： 小于等于 gt： 大于 lt： 小于 now： 当前时间 exists： 某个字段的值是否存在 ids： 通过ID批量查询 12345678910111213141516171819202122232425262728POST /es_db/_doc/_search&#123; &quot;query&quot;: &#123; &quot;term&quot;: &#123; // term查询不会对字段进行分词查询,会采用精确匹配 &quot;name&quot;: &quot;admin&quot; &#125; &#125;&#125;POST /es_db/_doc/_search&#123; &quot;query&quot;: &#123; &quot;range&quot;: &#123; // 范围查询 &quot;age&quot;: &#123;&quot;gte&quot;: 25,&quot;lte&quot;: 28&#125; &#125; &#125;&#125;POST /es_db/_doc/_search // 范围、分页、输出字段、综合查询&#123; &quot;query&quot;: &#123; &quot;range&quot;: &#123; // 范围查询 &quot;age&quot;: &#123;&quot;gte&quot;: 25,&quot;lte&quot;: 28&#125; &#125; &#125;, &quot;from&quot;: 0, // 分页 &quot;size&quot;: 2, &quot;_source&quot;: [&quot;name&quot;, &quot;age&quot;, &quot;book&quot;], // 指定输出字段 &quot;sort&quot;: &#123;&quot;age&quot;: &quot;desc&quot;&#125;// 排序&#125; 组合查询组合条件查询是将叶子条件查询语句进行组合而形成的一个完整的查询条件, must、filter、shoud、must_not等子条件是通过 term、terms、range、ids、exists、match等叶子条件为参数,当只有一个搜索条件时,must等对应的是一个对象,当多个条件时,对应的是一个数组。 bool： 各条件之间有 and, or 或 not 关系 must： 各个条件都必须满足,即各条件是 and 关系 should： 各个条件有一个满足即可,即各条件是 or 关系 must_not： 不满足所有条件,即各条件是 not 关系 filter： 不计算相关度评分,即不计算_score, 不对结果排序,效率更高, 查询结果可被缓存 constant_score： 不计算相关度评分 1234567891011121314151617181920212223POST /es_db/_doc/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;filter&quot;: &#123; // 对数据进行过滤 &quot;term&quot;: &#123;&quot;age&quot;: 25&#125; &#125; &#125; &#125;&#125; GET /es_db/_search&#123; &quot;query&quot;: &#123; // 使用should+bool搜索,控制搜索条件的匹配度 &quot;bool&quot;: &#123; &quot;should&quot;: [ // 必须匹配java、developer、assistant三个词条中的至少2个 &#123;&quot;match&quot;: &#123;&quot;remark&quot;: &quot;java&quot;&#125;&#125;, &#123;&quot;match&quot;: &#123;&quot;remark&quot;: &quot;developer&quot;&#125;&#125;, &#123;&quot;match&quot;: &#123;&quot;remark&quot;: &quot;assistant&quot;&#125;&#125; ], &quot;minimum_should_match&quot;: 2 // 控制搜索条件的匹配度 &#125; &#125;&#125; ES中执行 match搜索 时,ES底层通常会对搜索条件进行底层转换,来实现最终的搜索结果,若不怕麻烦, 尽量使用转换后的语法执行搜索, 效率更高。 123456789101112131415GET /es_db/_search // 转换前&#123;&quot;query&quot;:&#123;&quot;match&quot;:&#123;&quot;remark&quot;:&quot;java developer&quot;&#125;&#125;&#125;GET /es_db/_search // 转换后&#123;&quot;query&quot;:&#123;&quot;bool&quot;:&#123;&quot;should&quot;:[&#123;&quot;term&quot;:&#123;&quot;remark&quot;:&quot;java&quot;&#125;&#125;,&#123;&quot;term&quot;:&#123;&quot;remark&quot;:&#123;&quot;value&quot;:&quot;developer&quot;&#125;&#125;&#125;]&#125;&#125;&#125;GET /es_db/_search // 转换前&#123;&quot;query&quot;:&#123;&quot;match&quot;:&#123;&quot;remark&quot;:&#123;&quot;query&quot;:&quot;java developer&quot;,&quot;operator&quot;:&quot;and&quot;&#125;&#125;&#125;&#125;GET /es_db/_search // 转换后&#123;&quot;query&quot;:&#123;&quot;bool&quot;:&#123;&quot;must&quot;:[&#123;&quot;term&quot;:&#123;&quot;remark&quot;:&quot;java&quot;&#125;&#125;,&#123;&quot;term&quot;:&#123;&quot;remark&quot;:&#123;&quot;value&quot;:&quot;developer&quot;&#125;&#125;&#125;]&#125;&#125;&#125;GET /es_db/_search // 转换前&#123;&quot;query&quot;:&#123;&quot;match&quot;:&#123;&quot;remark&quot;:&#123;&quot;query&quot;:&quot;java architect assistant&quot;,&quot;minimum_should_match&quot;:&quot;68%&quot;&#125;&#125;&#125;&#125;GET /es_db/_search // 转换后&#123;&quot;query&quot;:&#123;&quot;bool&quot;:&#123;&quot;should&quot;:[&#123;&quot;term&quot;:&#123;&quot;remark&quot;:&quot;java&quot;&#125;&#125;,&#123;&quot;term&quot;:&#123;&quot;remark&quot;:&quot;architect&quot;&#125;&#125;,&#123;&quot;term&quot;:&#123;&quot;remark&quot;:&quot;assistant&quot;&#125;&#125;],&quot;minimum_should_match&quot;:2&#125;&#125;&#125; boost权重控制boost权重控制一般用于搜索时相关度排序使用,将某字段数据匹配时相关度分数增加 123456789101112GET /es_db/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [&#123;&quot;match&quot;: &#123;&quot;remark&quot;: &quot;java&quot;&#125;&#125;], &quot;should&quot;: [ &#123;&quot;match&quot;: &#123;&quot;remark&quot;: &#123;&quot;query&quot;: &quot;developer&quot;,&quot;boost&quot;: 3&#125;&#125;&#125;, &#123;&quot;match&quot;: &#123;&quot;remark&quot;: &#123;&quot;query&quot;: &quot;architect&quot;,&quot;boost&quot;: 1&#125;&#125;&#125; ] &#125; &#125;&#125; dis_maxdis_max 语法是直接 获取搜索多条件 中 单条件query相关度分数最高 的数据,以该数据做 相关度排序。基于dis_max 实现 best fields策略 进行 多字段搜索, best fields策略是搜索document中某个field, 尽可能多的匹配搜索条件。与之相反的是 most fields策略 即 尽可能多的字段匹配到搜索条件 。 best fields策略优点是精确匹配的数据可尽可能排列在最前端,且可通过 minimum_should_match 去除 长尾数据,避免长尾数据字段对排序结果的影响。缺点相对排序不均匀。 1234567891011GET /es_db/_search&#123; &quot;query&quot;: &#123; &quot;dis_max&quot;: &#123; // 找name字段中rod匹配相关度分数或remark字段中java developer匹配相关度分数,哪个高就使用哪个相关度分数进行结果排序 &quot;queries&quot;: [ &#123;&quot;match&quot;: &#123;&quot;name&quot;: &quot;rod&quot;&#125;&#125;, &#123;&quot;match&quot;: &#123;&quot;remark&quot;: &quot;java developer&quot;&#125;&#125; ] &#125; &#125;&#125; dis_max 是将 多个 搜索query条件中 相关度分数最高 的用于结果排序, 忽略其他query分数,在某些情况下 需要其他query条件中相关度介入最终结果排序,此时可 使用tie_breaker参数来优化dis_max搜索。 tie_breaker 参数表示 将其他query搜索条件相关度分数乘以参数值再参与结果排序。若不定义 tie_breaker 参数相当于 参数值为0,故其他query条件的相关度分数被忽略。 123456789101112GET /es_db/_search&#123; &quot;query&quot;: &#123; &quot;dis_max&quot;: &#123; // 找name字段中rod匹配相关度分数或remark字段中java developer匹配相关度分数,哪个高就使用哪个相关度分数进行结果排序 &quot;queries&quot;: [ &#123;&quot;match&quot;: &#123;&quot;name&quot;: &quot;rod&quot;&#125;&#125;, &#123;&quot;match&quot;: &#123;&quot;remark&quot;: &quot;java developer&quot;&#125;&#125; ], &quot;tie_breaker&quot;: 0.5 &#125; &#125;&#125; 使用multi_match简化dis_max+tie_breaker,ES中相同结果搜索也可使用不同语法语句来实现。 123456789101112131415161718192021222324252627GET /es_db/_search&#123; &quot;query&quot;: &#123; &quot;dis_max&quot;: &#123; &quot;queries&quot;: [ &#123;&quot;match&quot;: &#123;&quot;name&quot;: &quot;rod&quot;&#125;&#125;, &#123;&quot;match&quot;: &#123;&quot;remark&quot;: &#123;&quot;query&quot;: &quot;java assistant&quot;,&quot;boost&quot;: 2&#125;&#125;&#125; ], &quot;tie_breaker&quot;: 0.5 &#125; &#125;&#125;GET /es_db/_search&#123; &quot;query&quot;: &#123; &quot;multi_match&quot;: &#123; &quot;query&quot;: &quot;rod java developer&quot;, &quot;fields&quot;: [ &quot;name&quot;, &quot;remark^2&quot; // ^n代表权重,相当于&quot;boost&quot;:n ], &quot;type&quot;: &quot;best_fields&quot;, // 其中type常用的有best_fields和most_fields &quot;tie_breaker&quot;: 0.5, &quot;minimum_should_match&quot;: &quot;50%&quot; &#125; &#125;&#125; cross fields 是一个 唯一标识,且分布在 多个fields 中, 使用该唯一标识搜索数据即cross fields搜索。如人名可分为姓和名,地址可分为省、市、区县、街道等。使用人名或地址来搜索document,就称为cross fields搜索。 实现这种搜索,一般都是使用 most fields搜索策略,因为这就是 多个field 问题。 Cross fields 搜索策略是 从多个字段中搜索条件数据, 默认和most fields搜索逻辑一致 但 计算相关度分数和best fields策略一致。一般若使用cross fields搜索策略,都会携带 operator 额外参数,用来标记搜索条件如何在多个字段中匹配。 1234567891011GET /es_db/_search&#123; &quot;query&quot;: &#123; &quot;multi_match&quot;: &#123; // 搜索条件中java必须在name或remark字段中匹配,developer也必须在name或remark字段中匹配 &quot;query&quot;: &quot;java developer&quot;, &quot;fields&quot;: [&quot;name&quot;, &quot;remark&quot;], &quot;type&quot;: &quot;cross_fields&quot;, &quot;operator&quot;: &quot;and&quot; &#125; &#125;&#125; most fields策略 是尽可能匹配更多字段,会导致 精确搜索结果排序问题 ,又因为cross fields搜索,不能使用 minimum_should_match 来去除长尾数据。故在使用 most fields 和 cross fields 策略搜索数据时,都有不同缺陷,商业项目开发中都 推荐使用best fields策略 实现搜索。 可通过 copy_to 解决 cross fields搜索问题, copy_to 就是将 多个字段复制到一个字段 中实现一个 多字段组合,在商业项目中,也用于 解决搜索条件默认字段问题。若需要使用copy_to语法,则需要在定义 index 时手工指定 mapping映射策略。 123456789PUT /es_db/_mapping&#123; &quot;properties&quot;: &#123; &quot;provice&quot;: &#123;&quot;type&quot;: &quot;text&quot;,&quot;analyzer&quot;: &quot;standard&quot;,&quot;copy_to&quot;: &quot;address&quot;&#125;, &quot;city&quot;: &#123;&quot;type&quot;: &quot;text&quot;,&quot;copy_to&quot;: &quot;address&quot;&#125;, &quot;street&quot;: &#123;&quot;type&quot;: &quot;text&quot;,&quot;analyzer&quot;: &quot;standard&quot;,&quot;copy_to&quot;: &quot;address&quot;&#125;, &quot;address&quot;: &#123;&quot;type&quot;: &quot;text&quot;,&quot;analyzer&quot;: &quot;standard&quot;&#125; &#125;&#125; 在mapping定义中新增provice、city、street、address等字段,其中provice、city、street三个字段值会自动复制到address字段中,实现一个字段组合。在搜索地址时可在address字段中做条件匹配,从而避免most fields策略导致的问题。在维护数据时不需对address字段特殊维护,ES会自动维护组合字段。在存储时物理上不一定存在但逻辑上存在,因为address由3个物理存在属性province、city、street组成。 使用 match 和 proximity search 实现 召回率 和 精准度平衡 ,若搜索时只使用match phrase语法,会导致 召回率低下,若只使用match语法,会导致 精准度低下,因为搜索结果排序是根据相关度分数算法计算得到。若需要在结果中 兼顾召回率 和 精准度,就需要将 match 和 proximity search 混合使用。 召回率：搜索结果比率,如索引A中有100个document,搜索时返回多少个document 精准度：搜索结果准确率,如搜索条件为hello java,搜索结果中尽可能让短语匹配和hello java离的近的结果排序靠前1234567891011121314151617181920POST /test_a/_doc/3&#123;&quot;f&quot;:&quot;hello, java is very good, spark is also very good&quot;&#125;POST /test_a/_doc/4&#123;&quot;f&quot;:&quot;java and spark, development language &quot;&#125;POST /test_a/_doc/5&#123;&quot;f&quot;:&quot;Java Spark is a fast and general-purpose cluster computing system. It provides high-level APIs in Java, Scala, Python and R, and an optimized engine that supports general execution graphs.&quot;&#125;POST /test_a/_doc/6&#123;&quot;f&quot;:&quot;java spark and, development language &quot;&#125;GET /test_a/_search&#123;&quot;query&quot;:&#123;&quot;match&quot;:&#123;&quot;f&quot;:&quot;java spark&quot;&#125;&#125;&#125;GET /test_a/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [&#123;&quot;match&quot;: &#123;&quot;f&quot;: &quot;java spark&quot;&#125;&#125;], &quot;should&quot;: [&#123;&quot;match_phrase&quot;: &#123;&quot;f&quot;: &#123;&quot;query&quot;: &quot;java spark&quot;,&quot;slop&quot;: 50&#125;&#125;&#125;] &#125; &#125;&#125; 连接查询 父子 文档查询： parent/child 嵌套 文档查询： nested ES架构原理在ES中主要分成 Master 和 DataNode 两类节点,ES启动时会选举出一个Master节点,当某个节点启动后,使用 Zen Discovery机制 找到集群中的其他节点并 建立连接,并 从候选主节点中选举出一个主节点。一个ES集群中只有一个Master节点,但会有 N个DataNode 节点,在生产环境中内存可相对小一点但机器要稳定。 Master：管理索引即创建、删除索引, 分配分片, 维护元数据, 管理集群节点状态, 不负责数据写入和查询,比较轻量级 DataNode：数据写入, 数据检索,大部分ES压力都在DataNode节点上 分片ShardES是一个分布式搜索引擎,索引数据也分成若干部分,分布在不同服务器节点中,分布在不同服务器节点中的索引数据,就是Shard分片。Elasticsearch会自动管理分片,若发现分片分布不均衡,会自动迁移一个索引index由多个shard分片组成, 分片是分布在不同的服务器上。 副本为了对ES分片进行容错,假设某个节点不可用,会导致整个索引库都将不可用。故需要对分片进行副本容错, 每个分片都会有对应的副本。默认创建索引为1个分片、每个分片有 1个主分片 和 1个副本分片。 每个分片都会有一个Primary Shard主分片,也会有若干个Replica Shard副本分片, Primary Shard和Replica Shard不在同一个节点上。 12345678910111213141516PUT /job_idx_shard_temp // 创建指定分片数量、副本数量的索引&#123; &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123; &quot;id&quot;: &#123;&quot;type&quot;: &quot;long&quot;,&quot;store&quot;: true&#125;, &quot;area&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;,&quot;store&quot;: true&#125;, &quot;edu&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;,&quot;store&quot;: true&#125; &#125; &#125;, &quot;settings&quot;: &#123; &quot;number_of_shards&quot;: 3, // 指定分片数量 &quot;number_of_replicas&quot;: 2 // 指定副本数量 &#125;&#125;GET /_cat/indices?v // 查看分片、主分片、副本分片 文档写入原理 选择 任意一个DataNode发送请求 如node2,此时node2就成为一个 coordinating node协调节点,通过协调节点 计算得到文档要写入的分片shard = hash(routing) % number_of_primary_shards,其中 routing 是一个 可变值, 默认为文档_id,然后 协调节点会进行路由,将请求 转发给对应 primary shard主分片所在的 DataNode,假设primary shard主分片在node1、replica shard副分片在node2,node1节点上的Primary Shard处理请求,写入数据到索引库中,并将数据同步到Replica shard副分片,Primary Shard和Replica Shard都保存好了文档则返回Client。 检索原理 Client发起查询请求某个 DataNode 接收到请求后,该 DataNode 就成为 Coordinating Node协调节点, 协调节点将查询请求广播到每一个数据节点,这些 数据节点 的 分片 会处理该查询请求, 每个分片进行数据查询,将符合条件的数据放在一个 优先队列 中,并将这些数据的 文档ID 、 节点信息 、 分片信息 返回给 协调节点 , 协调节点将所有结果进行汇总并全局排序,协调节点向包含这些 文档ID 的 分片 发送 get请求,对应的分片将文档数据返回给协调节点,最后协调节点将数据返回给客户端。 准实时索引 当数据写入到ES分片时会 首先写入到内存中,然后通过 内存buffer 生成一个 Segment,并刷到 文件系统缓存 中而 不是直接刷到磁盘,数据可被检索,ES中 默认1秒refresh一次。数据在 写入内存的同时,也会 记录Translog日志,若 在refresh期间出现异常,会 根据Translog 来进行 数据恢复,等到 文件系统缓存 中的 Segment 数据 都刷到磁盘中,则 清空Translog文件,ES 默认每隔30分钟 会将 文件系统缓存 的数据 刷入到磁盘. Segment太多 时ES 定期 会将多个 Segment合并 成为大的Segment, 减少索引查询时IO开销,此阶段ES会真正的 物理删除 之前 执行过delete的数据。","tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"http://example.com/tags/ElasticSearch/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"ElasticSearch","slug":"工具和中间件/搜索引擎技术/ElasticSearch","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/ElasticSearch/"}]},{"title":"Ribbon集成原理","date":"2021-12-31T10:08:20.000Z","path":"blog/Cloud/Ribbon集成原理/","text":"主流的负载方案分为集中式负载均衡，在消费者和服务提供方中间使用独立的代理方式进行负载，如硬件的**F5，软件的Nginx；客户端负载均衡**，客户端会有一个服务器地址列表，在发送请求前通过负载均衡算法选择一个服务器，然后进行访问。 Spring Cloud Ribbon是基于Netflix Ribbon实现的一套客户端负载均衡工具，Ribbon客户端组件提供一系列的完善的配置如超时，重试等。通过**Load Balancer获取到服务提供的所有机器实例，Ribbon会自动基于某种负载策略去调用这些服务，Ribbon**也可以实现自己的负载均衡算法。 对于**RestTemplate通过Ribbon实现负载均衡调用，需要在声明RestTemplate Bean时加上@LoadBalanced注解。调用时直接通过服务名称即可。@LoadBalanced利用@Qualifier作为restTemplates注入的筛选条件，筛选出具有负载均衡标识的RestTemplate，被@LoadBalanced注解的restTemplate会被定制，添加LoadBalancerInterceptor**拦截器。 123456789@Bean@LoadBalancedpublic RestTemplate restTemplate() &#123; return new RestTemplate();&#125;@Autowiredprivate RestTemplate restTemplate;String url = &quot;http://mall-order/order/findOrderByUserId/&quot; + userId;Object result = restTemplate.getForObject(url, Object.class); Ribbon集成到RestTemplate中是通过RibbonAutoConfiguration配置类中导入LoadBalancerClient，然后通过LoadBalancerAutoConfiguration配置类将LoadBalancerClient封装到LoadBalancerInterceptor拦截器中，再通过RestTemplateCustomizer和SmartInitializingSingleton在Bean初始化完成后将该拦截器封装到**RestTemplate**拦截器集合中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465@Configuration@Conditional(RibbonAutoConfiguration.RibbonClassesConditions.class)@RibbonClients@AutoConfigureAfter(name = &quot;org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration&quot;)@AutoConfigureBefore(&#123; LoadBalancerAutoConfiguration.class, AsyncLoadBalancerAutoConfiguration.class &#125;)@EnableConfigurationProperties(&#123; RibbonEagerLoadProperties.class, ServerIntrospectorProperties.class &#125;)public class RibbonAutoConfiguration &#123; @Autowired(required = false) private List&lt;RibbonClientSpecification&gt; configurations = new ArrayList&lt;&gt;(); @Bean @ConditionalOnMissingBean public SpringClientFactory springClientFactory() &#123; SpringClientFactory factory = new SpringClientFactory(); factory.setConfigurations(this.configurations); return factory; &#125; @Bean @ConditionalOnMissingBean(LoadBalancerClient.class) public LoadBalancerClient loadBalancerClient() &#123; return new RibbonLoadBalancerClient(springClientFactory()); &#125;&#125;@Configuration(proxyBeanMethods = false)@ConditionalOnClass(RestTemplate.class)@ConditionalOnBean(LoadBalancerClient.class)@EnableConfigurationProperties(LoadBalancerRetryProperties.class)public class LoadBalancerAutoConfiguration &#123; @LoadBalanced // 该注解被@Qualifier注解修饰，这里会导入所有被@LoadBalanced注解标记的RestTemplate @Autowired(required = false) private List&lt;RestTemplate&gt; restTemplates = Collections.emptyList(); @Autowired(required = false) private List&lt;LoadBalancerRequestTransformer&gt; transformers = Collections.emptyList(); @Bean @ConditionalOnMissingBean public LoadBalancerRequestFactory loadBalancerRequestFactory(LoadBalancerClient loadBalancerClient) &#123; return new LoadBalancerRequestFactory(loadBalancerClient, this.transformers); &#125; @Configuration(proxyBeanMethods = false) @ConditionalOnMissingClass(&quot;org.springframework.retry.support.RetryTemplate&quot;) static class LoadBalancerInterceptorConfig &#123; @Bean // 将LoadBalancerClient封装到LoadBalancerInterceptor拦截器中 public LoadBalancerInterceptor ribbonInterceptor(LoadBalancerClient loadBalancerClient, LoadBalancerRequestFactory requestFactory) &#123; return new LoadBalancerInterceptor(loadBalancerClient, requestFactory); &#125; @Bean @ConditionalOnMissingBean public RestTemplateCustomizer restTemplateCustomizer(final LoadBalancerInterceptor loadBalancerInterceptor) &#123; return restTemplate -&gt; &#123; // 将拦截器添加到RestTemplate的拦截器链中 List&lt;ClientHttpRequestInterceptor&gt; list = new ArrayList&lt;&gt;(restTemplate.getInterceptors()); list.add(loadBalancerInterceptor); restTemplate.setInterceptors(list); &#125;; &#125; &#125; @Bean public SmartInitializingSingleton loadBalancedRestTemplateInitializerDeprecated(final ObjectProvider&lt;List&lt;RestTemplateCustomizer&gt;&gt; restTemplateCustomizers) &#123; return () -&gt; restTemplateCustomizers.ifAvailable(customizers -&gt; &#123; for (RestTemplate restTemplate : LoadBalancerAutoConfiguration.this.restTemplates) &#123; for (RestTemplateCustomizer customizer : customizers) &#123; customizer.customize(restTemplate); // 在所有Bean初始化完成后被调用 &#125; &#125; &#125;); &#125;&#125; 在调用**RestTemplate的方法请求时，会被LoadBalancerInterceptor拦截器拦截从而调用RibbonLoadBalancerClient的execute方法，通过getLoadBalancer获取负载均衡器，通过获取到的负载均衡器根据负载均衡算法**挑选一个Server。 1234567891011121314151617181920212223242526272829303132public class LoadBalancerInterceptor implements ClientHttpRequestInterceptor &#123; private LoadBalancerClient loadBalancer; private LoadBalancerRequestFactory requestFactory; public LoadBalancerInterceptor(LoadBalancerClient loadBalancer, LoadBalancerRequestFactory requestFactory) &#123; this.loadBalancer = loadBalancer; this.requestFactory = requestFactory; &#125; public LoadBalancerInterceptor(LoadBalancerClient loadBalancer) &#123; this(loadBalancer, new LoadBalancerRequestFactory(loadBalancer)); &#125; @Override public ClientHttpResponse intercept(final HttpRequest request, final byte[] body, final ClientHttpRequestExecution execution) throws IOException &#123; final URI originalUri = request.getURI(); String serviceName = originalUri.getHost(); Assert.state(serviceName != null, &quot;Request URI does not contain a valid hostname: &quot; + originalUri); return this.loadBalancer.execute(serviceName, this.requestFactory.createRequest(request, body, execution)); &#125;&#125;public class RibbonLoadBalancerClient implements LoadBalancerClient &#123; public &lt;T&gt; T execute(String serviceId, LoadBalancerRequest&lt;T&gt; request) throws IOException &#123; return execute(serviceId, request, null); &#125; public &lt;T&gt; T execute(String serviceId, LoadBalancerRequest&lt;T&gt; request, Object hint) throws IOException &#123; ILoadBalancer loadBalancer = getLoadBalancer(serviceId); // 获取负载均衡器 Server server = getServer(loadBalancer, hint); // 负载均衡器LoadBalancer根据负载均衡算法挑选一个Server if (server == null) &#123; throw new IllegalStateException(&quot;No instances available for &quot; + serviceId); &#125; RibbonServer ribbonServer = new RibbonServer(serviceId, server, isSecure(server, serviceId), serverIntrospector(serviceId).getMetadata(server)); return execute(serviceId, ribbonServer, request); &#125;&#125; 获取负载均衡器ILoadBalancer负载均衡器是通过**RibbonClientConfiguration**配置类导入的。 12345678910111213141516171819202122232425262728293031323334353637383940@Configuration(proxyBeanMethods = false)@EnableConfigurationProperties@Import(&#123; HttpClientConfiguration.class, OkHttpRibbonConfiguration.class, RestClientRibbonConfiguration.class, HttpClientRibbonConfiguration.class &#125;)public class RibbonClientConfiguration &#123; @Bean @ConditionalOnMissingBean public ILoadBalancer ribbonLoadBalancer(IClientConfig config, ServerList&lt;Server&gt; serverList, ServerListFilter&lt;Server&gt; serverListFilter, IRule rule, IPing ping, ServerListUpdater serverListUpdater) &#123; if (this.propertiesFactory.isSet(ILoadBalancer.class, name)) &#123; return this.propertiesFactory.get(ILoadBalancer.class, config, name); &#125; return new ZoneAwareLoadBalancer&lt;&gt;(config, rule, ping, serverList, serverListFilter, serverListUpdater); &#125;&#125;public class ZoneAwareLoadBalancer&lt;T extends Server&gt; extends DynamicServerListLoadBalancer&lt;T&gt; &#123; public ZoneAwareLoadBalancer(IClientConfig clientConfig, IRule rule, IPing ping, ServerList&lt;T&gt; serverList, ServerListFilter&lt;T&gt; filter, ServerListUpdater serverListUpdater) &#123; super(clientConfig, rule, ping, serverList, filter, serverListUpdater); &#125;&#125;public class DynamicServerListLoadBalancer&lt;T extends Server&gt; extends BaseLoadBalancer &#123; public DynamicServerListLoadBalancer(IClientConfig clientConfig, IRule rule, IPing ping, ServerList&lt;T&gt; serverList, ServerListFilter&lt;T&gt; filter, ServerListUpdater serverListUpdater) &#123; super(clientConfig, rule, ping); this.serverListImpl = serverList; this.filter = filter; this.serverListUpdater = serverListUpdater; if (filter instanceof AbstractServerListFilter) &#123; ((AbstractServerListFilter) filter).setLoadBalancerStats(getLoadBalancerStats()); &#125; restOfInit(clientConfig); &#125; void restOfInit(IClientConfig clientConfig) &#123; boolean primeConnection = this.isEnablePrimingConnections(); this.setEnablePrimingConnections(false); enableAndInitLearnNewServersFeature(); // Ribbon定时更新Nacos实例列表 updateListOfServers(); // 获取所有Nacos实例列表 if (primeConnection &amp;&amp; this.getPrimeConnections() != null) &#123; this.getPrimeConnections().primeConnections(getReachableServers()); &#125; this.setEnablePrimingConnections(primeConnection); &#125;&#125; 定时更新Nacos实例列表最终调用**PollingServerListUpdater的start方法，将更新任务添加到周期延时线程池中，且每30s执行一次该任务。该任务最终调用DynamicServerListLoadBalancer的updateListOfServers方法完成实例列表的更新，最终通过updateAllServerList方法将服务实例列表设置到父类BaseLoadBalancer的allServerList**中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677public class DynamicServerListLoadBalancer&lt;T extends Server&gt; extends BaseLoadBalancer &#123; protected final ServerListUpdater.UpdateAction updateAction = new ServerListUpdater.UpdateAction() &#123; @Override public void doUpdate() &#123; updateListOfServers(); // 真正去做定时更新的方法 &#125; &#125;; public void enableAndInitLearnNewServersFeature() &#123; serverListUpdater.start(updateAction); &#125; public void updateListOfServers() &#123; List&lt;T&gt; servers = new ArrayList&lt;T&gt;(); if (serverListImpl != null) &#123; servers = serverListImpl.getUpdatedListOfServers(); if (filter != null) &#123; servers = filter.getFilteredListOfServers(servers); &#125; &#125; updateAllServerList(servers); // 将服务实例俩表设置到父类BaseLoadBalancer的allServerList中 &#125; protected void updateAllServerList(List&lt;T&gt; ls) &#123; if (serverListUpdateInProgress.compareAndSet(false, true)) &#123; try &#123; for (T s : ls) &#123; s.setAlive(true); // set so that clients can start using these &#125; setServersList(ls); super.forceQuickPing(); &#125; finally &#123; serverListUpdateInProgress.set(false); &#125; &#125; &#125; public void setServersList(List lsrv) &#123; super.setServersList(lsrv); List&lt;T&gt; serverList = (List&lt;T&gt;) lsrv; Map&lt;String, List&lt;Server&gt;&gt; serversInZones = new HashMap&lt;String, List&lt;Server&gt;&gt;(); for (Server server : serverList) &#123; getLoadBalancerStats().getSingleServerStat(server); String zone = server.getZone(); if (zone != null) &#123; zone = zone.toLowerCase(); List&lt;Server&gt; servers = serversInZones.get(zone); if (servers == null) &#123; servers = new ArrayList&lt;Server&gt;(); serversInZones.put(zone, servers); &#125; servers.add(server); &#125; &#125; setServerListForZones(serversInZones); &#125;&#125;public class PollingServerListUpdater implements ServerListUpdater &#123; public synchronized void start(final UpdateAction updateAction) &#123; if (isActive.compareAndSet(false, true)) &#123; final Runnable wrapperRunnable = new Runnable() &#123; @Override public void run() &#123; if (!isActive.get()) &#123; // 不是存活状态 if (scheduledFuture != null) &#123; scheduledFuture.cancel(true); &#125; return; &#125; try &#123; updateAction.doUpdate(); // 调用定义时创建的匿名方法从而调用updateListOfServers lastUpdated = System.currentTimeMillis(); &#125; catch (Exception e) &#123; &#125; &#125; &#125;; // 第一次1s后开始执行，后续每30s执行一次 scheduledFuture = getRefreshExecutor().scheduleWithFixedDelay(wrapperRunnable, initialDelayMs, refreshIntervalMs, TimeUnit.MILLISECONDS); &#125; &#125;&#125; 若集成了**Nacos最终会调用NacosServerList的getServers方法，从Nacos**服务获取最新的实例列表。 1234567891011121314151617181920212223242526272829public class NacosServerList extends AbstractServerList&lt;NacosServer&gt; &#123; public List&lt;NacosServer&gt; getUpdatedListOfServers() &#123; return getServers(); &#125; private List&lt;NacosServer&gt; getServers() &#123; try &#123; String group = discoveryProperties.getGroup(); // 调用Nacos的方法获取最新的实例列表 List&lt;Instance&gt; instances = discoveryProperties.namingServiceInstance().selectInstances(serviceId, group, true); return instancesToServerList(instances); &#125; catch (Exception e) &#123; throw new IllegalStateException(&quot;Can not get service instances from nacos, serviceId=&quot; + serviceId, e); &#125; &#125;&#125;public class NacosNamingService implements NamingService &#123; public List&lt;Instance&gt; selectInstances(String serviceName, String groupName, boolean healthy) throws NacosException &#123; return selectInstances(serviceName, groupName, healthy, true); &#125; public List&lt;Instance&gt; selectInstances(String serviceName, String groupName, List&lt;String&gt; clusters, boolean healthy, boolean subscribe) throws NacosException &#123; ServiceInfo serviceInfo; if (subscribe) &#123; serviceInfo = hostReactor.getServiceInfo(NamingUtils.getGroupedName(serviceName, groupName), StringUtils.join(clusters, &quot;,&quot;)); &#125; else &#123; serviceInfo = hostReactor .getServiceInfoDirectlyFromServer(NamingUtils.getGroupedName(serviceName, groupName), StringUtils.join(clusters, &quot;,&quot;)); &#125; return selectInstances(serviceInfo, healthy); &#125;&#125; 负载均衡算法选择负载均衡策略IRule，默认采用ZoneAvoidanceRule实现，在多区域环境下选出最佳区域的实例进行访问。实例检查策略IPing，默认采用DummyPing实现，是一个特殊的实现始终返回true，并不会检查实例是否可用。服务实例清单的维护机制ServerList，默认采用ConfigurationBasedServerList实现。服务实例清单过滤机制ServerListFilter，默认采ZonePreferenceServerListFilter，该策略能够优先过滤出与请求方处于同区域的服务实例。负载均衡器**ILoadBalancer，默认采用ZoneAwareLoadBalancer实现，它具备了区域感知**的能力。 **RandomRule**： 随机选择一个Server。 **RetryRule**： 对选定的负载均衡策略机上重试机制，在一个配置时间段内当选择Server不成功，则一直尝试使用subRule的方式选择一个可用的server。 **RoundRobinRule**： 轮询选择， 轮询index，选择index对应位置的Server。 **AvailabilityFilteringRule： 过滤一直连接失败被标记为Circuit Tripped的后端Server，并过滤高并发的后端Server或使用一个AvailabilityPredicate**来包含过滤Server的逻辑，其实就是检查status里记录的各个Server的运行状态。 BestAvailableRule： 选择一个最小的并发请求的Server，逐个考察Server若Server被tripped了则跳过。 WeightedResponseTimeRule： 根据响应时间加权，响应时间越长，权重越小，被选中的可能性越低。 **ZoneAvoidanceRule： 默认的负载均衡策略，复合判断Server所在区域的性能和Server的可用性选择Server，在没有区域的环境下，类似于RandomRule**轮询 NacosRule: 同集群优先调用 可通过主动注入**IRule Bean的方式修改全局**的负载均衡策略 1234@Beanpublic IRule ribbonRule() &#123; return new NacosRule();&#125; 同在在配置文件中指定调用指定微服务提供的服务时，使用对应的负载均衡算法 123mall-order: # 被调用的微服务名 ribbon: NFLoadBalancerRuleClassName: com.alibaba.cloud.nacos.ribbon.NacosRule 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class RibbonLoadBalancerClient implements LoadBalancerClient &#123; protected Server getServer(ILoadBalancer loadBalancer, Object hint) &#123; if (loadBalancer == null) &#123; return null; &#125; return loadBalancer.chooseServer(hint != null ? hint : &quot;default&quot;); &#125;&#125;public class BaseLoadBalancer extends AbstractLoadBalancer implements PrimeConnections.PrimeConnectionListener, IClientConfigAware &#123; public Server chooseServer(Object key) &#123; if (counter == null) &#123; counter = createCounter(); &#125; counter.increment(); if (rule == null) &#123; return null; &#125; else &#123; try &#123; return rule.choose(key); // 调用具体规则的choose方法 &#125; catch (Exception e) &#123; return null; &#125; &#125; &#125;&#125;public class NacosRule extends AbstractLoadBalancerRule &#123; public Server choose(Object key) &#123; try &#123; String clusterName = this.nacosDiscoveryProperties.getClusterName(); String group = this.nacosDiscoveryProperties.getGroup(); DynamicServerListLoadBalancer loadBalancer = (DynamicServerListLoadBalancer) getLoadBalancer(); String name = loadBalancer.getName(); NamingService namingService = nacosServiceManager.getNamingService(nacosDiscoveryProperties.getNacosProperties()); List&lt;Instance&gt; instances = namingService.selectInstances(name, group, true); if (CollectionUtils.isEmpty(instances)) &#123; return null; &#125; List&lt;Instance&gt; instancesToChoose = instances; if (StringUtils.isNotBlank(clusterName)) &#123; List&lt;Instance&gt; sameClusterInstances = instances.stream().filter(instance -&gt; Objects.equals(clusterName, instance.getClusterName())).collect(Collectors.toList()); if (!CollectionUtils.isEmpty(sameClusterInstances)) &#123; instancesToChoose = sameClusterInstances; &#125; &#125; Instance instance = ExtendBalancer.getHostByRandomWeight2(instancesToChoose); return new NacosServer(instance); &#125; catch (Exception e) &#123; return null; &#125; &#125;&#125;","tags":[{"name":"springCloud","slug":"springCloud","permalink":"http://example.com/tags/springCloud/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"}]},{"title":"Feign集成原理","date":"2021-12-31T07:08:20.000Z","path":"blog/Cloud/Feign集成原理/","text":"Feign是Netflix开发的声明式、模板化的HTTP客户端，可帮助我们更加便捷、优雅地调用**HTTP API**，Feign可以做到使用HTTP请求远程服务时就像调用本地方法一样的体验。 Spring Cloud整合Feign只需要引入以下依赖，且需要通过**@EnableFeignClients**注解开启Feign： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt; 日志配置若需要需要对Feign的接口进行问题排查，或者想看看调用性能，就需要配置Feign的日志，可通过配置类的方式指定日志级别。 1234567891011121314// 注意： 此处配置@Configuration注解就会全局生效，如果想指定对应微服务生效，就不能配置public class FeignConfig &#123; /** * 日志级别: * NONE【性能最佳，适用于生产】：不记录任何日志（默认值）。 * BASIC【适用于生产环境追踪问题】：仅记录请求方法、URL、响应状态代码以及执行时间。 * HEADERS：记录BASIC级别的基础上，记录请求和响应的header。 * FULL【比较适用于开发及测试环境定位问题】：记录请求和响应的header、body和元数据。 */ @Bean public Logger.Level feignLoggerLevel() &#123; return Logger.Level.FULL; &#125;&#125; 局部配置，让调用的微服务生效，在**@FeignClient**注解中指定使用的配置类： 12345@FeignClient(value = &quot;mall-order&quot;, path = &quot;/order&quot;, configuration = FeignConfig.class, fallback = FallbackOrderFeignService.class)public interface OrderFeignService &#123; @RequestMapping(value = &quot;/findOrderByUserId/&#123;userId&#125;&quot;) Object findOrderByUserId(@PathVariable(value = &quot;userId&quot;) Integer userId);&#125; 局部配置还可以通过yml配置类完成，对应属性配置类为**FeignClientProperties.FeignClientConfiguration，如拦截器、契约、超时时间等，Feign的底层用的是Ribbon，但超时时间以Feign配置为准**。 12345678910111213141516171819202122232425262728feign: client: config: mall-order: #对应微服务 loggerLevel: FULL contract: feign.Contract.Default #指定Feign原生注解契约配置 #配置拦截器 requestInterceptors[0]: com.eleven.***.interceptor.FeignAuthRequestInterceptor # 连接超时时间，默认2s connectTimeout: 5000 # 请求处理超时时间，默认5s readTimeout: 10000 # 配置编解码器 encoder: feign.jackson.JacksonEncoder decoder: feign.jackson.JacksonDecoder httpclient: enabled: true #feign 使用 Apache HttpClient 可以忽略，默认开启 okhttp: enabled: true #feign 使用 okhttp compression: # 配置 GZIP 来压缩数据 request: enabled: true # 配置压缩的类型 mime-types: text/xml,application/xml,application/json # 最小压缩值 min-request-size: 2048 response: enabled: true Feign对SpringMvc的支持是通过配置契约来完成的，Spring Cloud中默认的是**SpringMvcContract**契约。若调用的接口有权限控制，可通过配置拦截器的方式实现，每次Feign发起HTTP调用之前，会去执行拦截器中的逻辑。 12345678@Beanpublic Contract feignContract() &#123; return new Contract.Default();&#125;@Beanpublic BasicAuthRequestInterceptor basicAuthRequestInterceptor() &#123; return new BasicAuthRequestInterceptor(&quot;eleven&quot;, &quot;123456&quot;);&#125; 集成原理Feign的集成是通过**@EnableFeignClients注解中导入了FeignClientsRegistrar类，该类实现了ImportBeanDefinitionRegistrar接口，故在Spring容器启动时会调用其registerBeanDefinitions完成将所有被@FeignClient注解标注的接口通过FeignClientFactoryBean**注册到Spring容器中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899class FeignClientsRegistrar implements ImportBeanDefinitionRegistrar, ResourceLoaderAware, EnvironmentAware &#123; public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry) &#123; registerDefaultConfiguration(metadata, registry); registerFeignClients(metadata, registry); &#125; public void registerFeignClients(AnnotationMetadata metadata, BeanDefinitionRegistry registry) &#123; ClassPathScanningCandidateComponentProvider scanner = getScanner(); scanner.setResourceLoader(this.resourceLoader); Set&lt;String&gt; basePackages; Map&lt;String, Object&gt; attrs = metadata.getAnnotationAttributes(EnableFeignClients.class.getName()); AnnotationTypeFilter annotationTypeFilter = new AnnotationTypeFilter(FeignClient.class); final Class&lt;?&gt;[] clients = attrs == null ? null : (Class&lt;?&gt;[]) attrs.get(&quot;clients&quot;); if (clients == null || clients.length == 0) &#123; scanner.addIncludeFilter(annotationTypeFilter); // 添加过滤器，过滤出所有被@FeignClient注解标注的类 basePackages = getBasePackages(metadata); // 获取扫描的包路径，若未配置则默认为当前类所在的包 &#125; else &#123; final Set&lt;String&gt; clientClasses = new HashSet&lt;&gt;(); basePackages = new HashSet&lt;&gt;(); for (Class&lt;?&gt; clazz : clients) &#123; basePackages.add(ClassUtils.getPackageName(clazz)); clientClasses.add(clazz.getCanonicalName()); &#125; AbstractClassTestingTypeFilter filter = new AbstractClassTestingTypeFilter() &#123; @Override protected boolean match(ClassMetadata metadata) &#123; String cleaned = metadata.getClassName().replaceAll(&quot;\\\\$&quot;, &quot;.&quot;); return clientClasses.contains(cleaned); &#125; &#125;; scanner.addIncludeFilter(new AllTypeFilter(Arrays.asList(filter, annotationTypeFilter))); &#125; for (String basePackage : basePackages) &#123; // 遍历所有的包 Set&lt;BeanDefinition&gt; candidateComponents = scanner.findCandidateComponents(basePackage); // 扫描出所有被@FeignClient注解标注的接口 for (BeanDefinition candidateComponent : candidateComponents) &#123; // @FeignClient直接标注在接口上 if (candidateComponent instanceof AnnotatedBeanDefinition) &#123; AnnotatedBeanDefinition beanDefinition = (AnnotatedBeanDefinition) candidateComponent; AnnotationMetadata annotationMetadata = beanDefinition.getMetadata(); Assert.isTrue(annotationMetadata.isInterface(), &quot;@FeignClient can only be specified on an interface&quot;); Map&lt;String, Object&gt; attributes = annotationMetadata.getAnnotationAttributes(FeignClient.class.getCanonicalName()); String name = getClientName(attributes); // 获取配置的客户端名称 registerClientConfiguration(registry, name, attributes.get(&quot;configuration&quot;)); registerFeignClient(registry, annotationMetadata, attributes); &#125; &#125; &#125; &#125; private String getClientName(Map&lt;String, Object&gt; client) &#123; if (client == null) &#123; return null; &#125; String value = (String) client.get(&quot;contextId&quot;); if (!StringUtils.hasText(value)) &#123; // 获取@FeignClient注解的value属性值 value = (String) client.get(&quot;value&quot;); &#125; if (!StringUtils.hasText(value)) &#123; // 获取@FeignClient注解的name属性值 value = (String) client.get(&quot;name&quot;); &#125; if (!StringUtils.hasText(value)) &#123; // 获取@FeignClient注解的serviceId属性值 value = (String) client.get(&quot;serviceId&quot;); &#125; if (StringUtils.hasText(value)) &#123; return value; &#125; throw new IllegalStateException(&quot;Either &#x27;name&#x27; or &#x27;value&#x27; must be provided in @&quot; + FeignClient.class.getSimpleName()); &#125; private void registerFeignClient(BeanDefinitionRegistry registry, AnnotationMetadata annotationMetadata, Map&lt;String, Object&gt; attributes) &#123; String className = annotationMetadata.getClassName(); // 获取@FeignClient注解标注的接口的全限定名 // 将BeanDefinition的beanClass设置为FeignClientFactoryBean.class BeanDefinitionBuilder definition = BeanDefinitionBuilder.genericBeanDefinition(FeignClientFactoryBean.class); validate(attributes); // 校验@FeignClient注解fallback和fallbackFactory属性 definition.addPropertyValue(&quot;url&quot;, getUrl(attributes)); // 若@FeignClient注解中配置的是url对其进行处理 definition.addPropertyValue(&quot;path&quot;, getPath(attributes)); // 对@FeignClient注解中配置的是path属性进行处理 String name = getName(attributes); // 获取配置的客户端名称，即value或name或serviceId属性中配置的值，优先级从低到高 definition.addPropertyValue(&quot;name&quot;, name); String contextId = getContextId(attributes); // 若默认未配置contextId注解，则默认为上面获取到的客户端名称name definition.addPropertyValue(&quot;contextId&quot;, contextId); definition.addPropertyValue(&quot;type&quot;, className); // 这里将原接口的Type设置到了FeignClientFactoryBean中，便于通过类型注入 definition.addPropertyValue(&quot;decode404&quot;, attributes.get(&quot;decode404&quot;)); definition.addPropertyValue(&quot;fallback&quot;, attributes.get(&quot;fallback&quot;)); definition.addPropertyValue(&quot;fallbackFactory&quot;, attributes.get(&quot;fallbackFactory&quot;)); definition.setAutowireMode(AbstractBeanDefinition.AUTOWIRE_BY_TYPE); String alias = contextId + &quot;FeignClient&quot;; AbstractBeanDefinition beanDefinition = definition.getBeanDefinition(); beanDefinition.setAttribute(FactoryBean.OBJECT_TYPE_ATTRIBUTE, className); boolean primary = (Boolean) attributes.get(&quot;primary&quot;); beanDefinition.setPrimary(primary); String qualifier = getQualifier(attributes); if (StringUtils.hasText(qualifier)) &#123; alias = qualifier; &#125; BeanDefinitionHolder holder = new BeanDefinitionHolder(beanDefinition, className, new String[] &#123; alias &#125;); BeanDefinitionReaderUtils.registerBeanDefinition(holder, registry); &#125; public static BeanDefinitionBuilder genericBeanDefinition(Class&lt;?&gt; beanClass) &#123; BeanDefinitionBuilder builder = new BeanDefinitionBuilder(new GenericBeanDefinition()); builder.beanDefinition.setBeanClass(beanClass); // 将BeanDefinition的beanClass设置为FeignClientFactoryBean.class return builder; &#125;&#125; 由于**@FeignClient注解只能标注在接口上，而Spring容器中的Bean不能是接口，故这里通过FactoryBean的子类FeignClientFactoryBean来完成将被@FeignClient**注解标注接口注册到Spring容器中。 1234567891011121314151617181920212223242526272829303132333435class FeignClientFactoryBean implements FactoryBean&lt;Object&gt;, InitializingBean, ApplicationContextAware &#123; public Object getObject() throws Exception &#123; return getTarget(); &#125; &lt;T&gt; T getTarget() &#123; FeignContext context = applicationContext.getBean(FeignContext.class); Feign.Builder builder = feign(context); // 对具体的Client接口进行配置，如encoder、decoder、retryer等 if (!StringUtils.hasText(url)) &#123; if (!name.startsWith(&quot;http&quot;)) &#123; url = &quot;http://&quot; + name; &#125; else &#123; url = name; &#125; url += cleanPath(); // 对url进行拼接，例：http://mall-order/order // 若FeignClient没有地址属性，用JDK动态代理生成FeignBlockingLoadBalancerClient代理 return (T) loadBalance(builder, context, new HardCodedTarget&lt;&gt;(type, name, url)); &#125; if (StringUtils.hasText(url) &amp;&amp; !url.startsWith(&quot;http&quot;)) &#123; url = &quot;http://&quot; + url; &#125; String url = this.url + cleanPath(); Client client = getOptional(context, Client.class); if (client != null) &#123; if (client instanceof LoadBalancerFeignClient) &#123; client = ((LoadBalancerFeignClient) client).getDelegate(); &#125; if (client instanceof FeignBlockingLoadBalancerClient) &#123; client = ((FeignBlockingLoadBalancerClient) client).getDelegate(); &#125; builder.client(client); &#125; Targeter targeter = get(context, Targeter.class); return (T) targeter.target(this, builder, context, new HardCodedTarget&lt;&gt;(type, name, url)); &#125;&#125; 用**JDK动态代理生成FeignBlockingLoadBalancerClient代理，通过Feign接口时通过代理类最终会调用FeignBlockingLoadBalancerClient代理类的execute方法，最终会通过LoadBalancerClient去获取ServiceInstance**让后调用具体的服务。 123456789101112131415161718192021222324public class FeignBlockingLoadBalancerClient implements Client &#123; private final Client delegate; private final BlockingLoadBalancerClient loadBalancerClient; public FeignBlockingLoadBalancerClient(Client delegate, BlockingLoadBalancerClient loadBalancerClient) &#123; this.delegate = delegate; this.loadBalancerClient = loadBalancerClient; &#125; public Response execute(Request request, Request.Options options) throws IOException &#123; final URI originalUri = URI.create(request.url()); String serviceId = originalUri.getHost(); Assert.state(serviceId != null, &quot;Request URI does not contain a valid hostname: &quot; + originalUri); ServiceInstance instance = loadBalancerClient.choose(serviceId); if (instance == null) &#123; return Response.builder().request(request) .status(HttpStatus.SERVICE_UNAVAILABLE.value()) .body(message, StandardCharsets.UTF_8).build(); &#125; String reconstructedUrl = loadBalancerClient.reconstructURI(instance, originalUri).toString(); Request newRequest = Request.create(request.httpMethod(), reconstructedUrl, request.headers(), request.body(), request.charset(), request.requestTemplate()); return delegate.execute(newRequest, options); &#125;&#125; Feign中默认使用JDK原生的**URLConnection发送HTTP请求，可集成别的组件来替换掉URLConnection，如Apache HttpClient，OkHttp**等。Feign发起调用真正执行逻辑： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public interface Client &#123; class Default implements Client &#123; public Response execute(Request request, Options options) throws IOException &#123; HttpURLConnection connection = convertAndSend(request, options); return convertResponse(connection, request); &#125; &#125;&#125;@ConditionalOnClass(Feign.class)@ConditionalOnBean(BlockingLoadBalancerClient.class)@AutoConfigureBefore(FeignAutoConfiguration.class)@AutoConfigureAfter(FeignRibbonClientAutoConfiguration.class)@EnableConfigurationProperties(FeignHttpClientProperties.class)@Configuration(proxyBeanMethods = false)@Import(&#123; HttpClientFeignLoadBalancerConfiguration.class, OkHttpFeignLoadBalancerConfiguration.class, DefaultFeignLoadBalancerConfiguration.class &#125;)public class FeignLoadBalancerAutoConfiguration &#123;&#125;@Configuration(proxyBeanMethods = false)@ConditionalOnClass(ApacheHttpClient.class)@ConditionalOnBean(BlockingLoadBalancerClient.class)@ConditionalOnProperty(value = &quot;feign.httpclient.enabled&quot;, matchIfMissing = true)@Import(HttpClientFeignConfiguration.class)class HttpClientFeignLoadBalancerConfiguration &#123; @Bean @ConditionalOnMissingBean public Client feignClient(BlockingLoadBalancerClient loadBalancerClient, HttpClient httpClient) &#123; ApacheHttpClient delegate = new ApacheHttpClient(httpClient); return new FeignBlockingLoadBalancerClient(delegate, loadBalancerClient); &#125;&#125;@Configuration(proxyBeanMethods = false)@ConditionalOnClass(OkHttpClient.class)@ConditionalOnProperty(&quot;feign.okhttp.enabled&quot;)@ConditionalOnBean(BlockingLoadBalancerClient.class)@Import(OkHttpFeignConfiguration.class)class OkHttpFeignLoadBalancerConfiguration &#123; @Bean @ConditionalOnMissingBean public Client feignClient(okhttp3.OkHttpClient okHttpClient, BlockingLoadBalancerClient loadBalancerClient) &#123; OkHttpClient delegate = new OkHttpClient(okHttpClient); return new FeignBlockingLoadBalancerClient(delegate, loadBalancerClient); &#125;&#125;@Configuration(proxyBeanMethods = false)class DefaultFeignLoadBalancerConfiguration &#123; @Bean @ConditionalOnMissingBean public Client feignClient(BlockingLoadBalancerClient loadBalancerClient) &#123; return new FeignBlockingLoadBalancerClient(new Client.Default(null, null), loadBalancerClient); &#125;&#125;","tags":[{"name":"springCloud","slug":"springCloud","permalink":"http://example.com/tags/springCloud/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"}]},{"title":"Canal基础","date":"2021-12-30T07:08:20.000Z","path":"blog/Cloud/Canal基础/","text":"Canal模拟MySQL Slave的交互协议伪装自己为MySQL Slave，向MySQL Master发送Dump协议MySQL Master收到Dump请求，开始推送Binary Log给Slave即Canal，Canal解析Binary Log对象，原始为byte流。 安装配置12345678910111213141516171819202122cd /usr/localmkdir canaltar -zxvf canal.deployer-1.1.5.tar.gzvim conf/example/instance.properties# 修改mysql配置vim /etc/my.cnflog-bin=mysql-bin # 添加这一行就ok binlog-format=ROW # 选择row模式 server-id=1 # 配置mysql replaction需要定义，不能和canal的slaveId重复binlog-do-db=micromall# 执行mysql 创建canal用户create user canal identified by &#x27;canal&#x27;;GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO &#x27;canal&#x27;@&#x27;%&#x27;;FLUSH PRIVILEGES;# 查看是否授权成功select * from user where user=&#x27;canal&#x27; # 启动canalcd bin./startup.sh 基础配置修改**instance.properties**配置文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859################################################### mysql serverId , v1.0.26+ will autoGen# canal.instance.mysql.slaveId=0# enable gtid use true/falsecanal.instance.gtidon=false# position infocanal.instance.master.address=127.0.0.1:3306canal.instance.master.journal.name=canal.instance.master.position=canal.instance.master.timestamp=canal.instance.master.gtid=# rds oss binlogcanal.instance.rds.accesskey=canal.instance.rds.secretkey=canal.instance.rds.instanceId=# table meta tsdb infocanal.instance.tsdb.enable=true#canal.instance.tsdb.url=jdbc:mysql://127.0.0.1:3306/canal_tsdb#canal.instance.tsdb.dbUsername=canal#canal.instance.tsdb.dbPassword=canal#canal.instance.standby.address =#canal.instance.standby.journal.name =#canal.instance.standby.position =#canal.instance.standby.timestamp =#canal.instance.standby.gtid=# 数据库username/passwordcanal.instance.dbUsername=rootcanal.instance.dbPassword=rootcanal.instance.connectionCharset = UTF-8canal.instance.defaultDatabaseName=eleven# enable druid Decrypt database passwordcanal.instance.enableDruid=false#canal.instance.pwdPublicKey=MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBALK4BUxdDltRRE5/zXpVEVPUgunvscYFtEip3pmLlhrWpacX7y7GCMo2/JM6LeHmiiNdH1FWgGCpUfircSwlWKUCAwEAAQ==# table regex# canal.instance.filter.regex=.*\\\\..*# 配置表canal.instance.filter.regex=micromall.pms_product,micromall.sms_flash_promotion_product_relation# table black regexcanal.instance.filter.black.regex=mysql\\\\.slave_.*# table field filter(format: schema1.tableName1:field1/field2,schema2.tableName2:field1/field2)#canal.instance.filter.field=test1.t_product:id/subject/keywords,test2.t_company:id/name/contact/ch# table field black filter(format: schema1.tableName1:field1/field2,schema2.tableName2:field1/field2)#canal.instance.filter.black.field=test1.t_product:subject/product_image,test2.t_company:id/name/contact/ch# mq config# 消息队列Topiccanal.mq.topic=productDetailChange# dynamic topic route by schema or table regex#canal.mq.dynamicTopic=mytest1.user,mytest2\\\\..*,.*\\\\..*canal.mq.partition=0# hash partition config#canal.mq.partitionsNum=3#canal.mq.partitionHash=test.table:id^name,.*\\\\..*#canal.mq.dynamicTopicPartitionNum=test.*:4,mycanal:6 修改**canal.properties**配置文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174########################################################## common argument ############################################################### tcp bind ipcanal.ip =# register ip to zookeepercanal.register.ip =canal.port = 11111canal.metrics.pull.port = 11112# canal instance user/passwd# canal.user = canal# canal.passwd = E3619321C1A937C46A0D8BD1DAC39F93B27D4458# canal admin config#canal.admin.manager = 127.0.0.1:8089canal.admin.port = 11110canal.admin.user = admincanal.admin.passwd = 4ACFE3202A5FF5CF467898FC58AAB1D615029441# admin auto register#canal.admin.register.auto = true#canal.admin.register.cluster =#canal.admin.register.name =canal.zkServers =# flush data to zkcanal.zookeeper.flush.period = 1000canal.withoutNetty = false# tcp, kafka, rocketMQ, rabbitMQcanal.serverMode = tcp# flush meta cursor/parse position to filecanal.file.data.dir = $&#123;canal.conf.dir&#125;canal.file.flush.period = 1000## memory store RingBuffer size, should be Math.pow(2,n)canal.instance.memory.buffer.size = 16384## memory store RingBuffer used memory unit size , default 1kbcanal.instance.memory.buffer.memunit = 1024 ## meory store gets mode used MEMSIZE or ITEMSIZEcanal.instance.memory.batch.mode = MEMSIZEcanal.instance.memory.rawEntry = true## detecing configcanal.instance.detecting.enable = false#canal.instance.detecting.sql = insert into retl.xdual values(1,now()) on duplicate key update x=now()canal.instance.detecting.sql = select 1canal.instance.detecting.interval.time = 3canal.instance.detecting.retry.threshold = 3canal.instance.detecting.heartbeatHaEnable = false# support maximum transaction size, more than the size of the transaction will be cut into multiple transactions deliverycanal.instance.transaction.size = 1024# mysql fallback connected to new master should fallback timescanal.instance.fallbackIntervalInSeconds = 60# network configcanal.instance.network.receiveBufferSize = 16384canal.instance.network.sendBufferSize = 16384canal.instance.network.soTimeout = 30# binlog filter configcanal.instance.filter.druid.ddl = truecanal.instance.filter.query.dcl = falsecanal.instance.filter.query.dml = falsecanal.instance.filter.query.ddl = falsecanal.instance.filter.table.error = falsecanal.instance.filter.rows = falsecanal.instance.filter.transaction.entry = falsecanal.instance.filter.dml.insert = falsecanal.instance.filter.dml.update = falsecanal.instance.filter.dml.delete = false# binlog format/image checkcanal.instance.binlog.format = ROW,STATEMENT,MIXED canal.instance.binlog.image = FULL,MINIMAL,NOBLOB# binlog ddl isolationcanal.instance.get.ddl.isolation = false# parallel parser configcanal.instance.parser.parallel = true## concurrent thread number, default 60% available processors, suggest not to exceed Runtime.getRuntime().availableProcessors()#canal.instance.parser.parallelThreadSize = 16## disruptor ringbuffer size, must be power of 2canal.instance.parser.parallelBufferSize = 256# table meta tsdb infocanal.instance.tsdb.enable = truecanal.instance.tsdb.dir = $&#123;canal.file.data.dir:../conf&#125;/$&#123;canal.instance.destination:&#125;canal.instance.tsdb.url = jdbc:h2:$&#123;canal.instance.tsdb.dir&#125;/h2;CACHE_SIZE=1000;MODE=MYSQL;canal.instance.tsdb.dbUsername = canalcanal.instance.tsdb.dbPassword = canal# dump snapshot interval, default 24 hourcanal.instance.tsdb.snapshot.interval = 24# purge snapshot expire , default 360 hour(15 days)canal.instance.tsdb.snapshot.expire = 360########################################################## destinations ##############################################################canal.destinations = example# conf root dircanal.conf.dir = ../conf# auto scan instance dir add/remove and start/stop instancecanal.auto.scan = truecanal.auto.scan.interval = 5# set this value to &#x27;true&#x27; means that when binlog pos not found, skip to latest.# WARN: pls keep &#x27;false&#x27; in production env, or if you know what you want.canal.auto.reset.latest.pos.mode = falsecanal.instance.tsdb.spring.xml = classpath:spring/tsdb/h2-tsdb.xml#canal.instance.tsdb.spring.xml = classpath:spring/tsdb/mysql-tsdb.xmlcanal.instance.global.mode = springcanal.instance.global.lazy = falsecanal.instance.global.manager.address = $&#123;canal.admin.manager&#125;#canal.instance.global.spring.xml = classpath:spring/memory-instance.xmlcanal.instance.global.spring.xml = classpath:spring/file-instance.xml#canal.instance.global.spring.xml = classpath:spring/default-instance.xml########################################################### MQ Properties ################################################################ aliyun ak/sk , support rds/mqcanal.aliyun.accessKey =canal.aliyun.secretKey =canal.aliyun.uid=canal.mq.flatMessage = truecanal.mq.canalBatchSize = 50canal.mq.canalGetTimeout = 100# Set this value to &quot;cloud&quot;, if you want open message trace feature in aliyun.canal.mq.accessChannel = localcanal.mq.database.hash = truecanal.mq.send.thread.size = 30canal.mq.build.thread.size = 8########################################################### Kafka ###############################################################kafka.bootstrap.servers = 127.0.0.1:9092kafka.acks = allkafka.compression.type = nonekafka.batch.size = 16384kafka.linger.ms = 1kafka.max.request.size = 1048576kafka.buffer.memory = 33554432kafka.max.in.flight.requests.per.connection = 1kafka.retries = 0kafka.kerberos.enable = falsekafka.kerberos.krb5.file = &quot;../conf/kerberos/krb5.conf&quot;kafka.kerberos.jaas.file = &quot;../conf/kerberos/jaas.conf&quot;########################################################### RocketMQ ###############################################################rocketmq.producer.group = testrocketmq.enable.message.trace = falserocketmq.customized.trace.topic =rocketmq.namespace =rocketmq.namesrv.addr = 127.0.0.1:9876rocketmq.retry.times.when.send.failed = 0rocketmq.vip.channel.enabled = falserocketmq.tag = ########################################################### RabbitMQ ###############################################################rabbitmq.host =rabbitmq.virtual.host =rabbitmq.exchange =rabbitmq.username =rabbitmq.password =rabbitmq.deliveryMode = Canal内部原理Canal源码入口**AbstractEventParser的start**方法 server代表一个canal运行实例，对应于一个jvm instance对应于一个数据队列 （1个server对应1..n个instance) eventParser (数据源接入，模拟slave协议和master进行交互，协议解析) eventSink (Parser和Store链接器，进行数据过滤，加工，分发的工作) eventStore (数据存储) metaManager (增量订阅&amp;消费信息管理器) Canal集群高可用Canal的HA分为Canal Server和Canal Client两部分实现，整个HA机制的控制主要是依赖了Zookeeper的几个特性，watcher和EPHEMERAL节点和session生命周期绑定。 Canal Server：为了减少对MySQL Dump的请求，不同Server上的instance要求**同一时间只能有一个处于Running，其他的处于Standby**状态 Canal Client：为了保证有序性，一份instance同一时间只能由一个Canal Client进行get&#x2F;ack&#x2F;rollback操作，否则客户端接收无法保证有序 Canal Server要启动某个Canal instance时都先向Zookeeper进行一次尝试启动判断，创建EPHEMERAL临时节点，谁创建成功就允许谁启动 创建Zookeeper节点成功后，对应的Canal Server就启动对应的Canal instance，没有创建成功的Canal instance就会处于Standby状态 一旦Zookeeper发现Canal Server A创建的节点消失后，立即通知其他的Canal Server再次进行步骤1的操作，重新选出一个Canal Server启动instance. Canal Client每次进行connect时，会首先向Zookeeper询问当前是谁启动了Canal instance，然后和其建立链接，一旦链接不可用，会重新尝试connect. Canal Client的方式和Canal Server方式类似，也是利用Zookeeper的抢占EPHEMERAL节点的方式进行控制。 使用12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.otter&lt;/groupId&gt; &lt;artifactId&gt;canal.client&lt;/artifactId&gt; &lt;version&gt;1.1.3&lt;/version&gt;&lt;/dependency&gt; 123456789101112131415@Component@RocketMQMessageListener(topic = &quot;$&#123;rocketmq.canal.topic&#125;&quot;, consumerGroup = &quot;$&#123;rocketmq.canal.group&#125;&quot;)public class RefreshCacheListener implements RocketMQListener&lt;FlatMessage&gt; &#123; @Autowired private RedisOpsUtil redisOpsUtil; private final static String PRODUCT = &quot;pms_product&quot;; private final static String SKU = &quot;pms_sku_stock&quot;; @Override public void onMessage(FlatMessage flatMessage) &#123; //修改后的新记录 List&lt;Map&lt;String, String&gt;&gt; records = flatMessage.getData(); //修改前的数据 List&lt;Map&lt;String, String&gt;&gt; old = flatMessage.getOld(); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public class SimpleCanalClientExample &#123; public static void main(String args[]) &#123; // 创建链接 CanalConnector connector = CanalConnectors.newSingleConnector(new InetSocketAddress(&quot;127.0.0.1&quot;, 11111), &quot;example&quot;, &quot;&quot;, &quot;&quot;); int batchSize = 1000; int emptyCount = 0; try &#123; connector.connect(); connector.subscribe(&quot;.*\\\\..*&quot;); connector.rollback(); int totalEmptyCount = 120; while (emptyCount &lt; totalEmptyCount) &#123; Message message = connector.getWithoutAck(batchSize); // 获取指定数量的数据 long batchId = message.getId(); int size = message.getEntries().size(); if (batchId == -1 || size == 0) &#123; emptyCount++; System.out.println(&quot;empty count : &quot; + emptyCount); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; &#125; &#125; else &#123; emptyCount = 0; // System.out.printf(&quot;message[batchId=%s,size=%s] \\n&quot;, batchId, size); printEntry(message.getEntries()); &#125; connector.ack(batchId); // 提交确认 // connector.rollback(batchId); // 处理失败, 回滚数据 &#125; System.out.println(&quot;empty too many times, exit&quot;); &#125; finally &#123; connector.disconnect(); &#125; &#125; private static void printEntry(List&lt;Entry&gt; entrys) &#123; for (Entry entry : entrys) &#123; if (entry.getEntryType() == EntryType.TRANSACTIONBEGIN || entry.getEntryType() == EntryType.TRANSACTIONEND) &#123; continue; &#125; RowChange rowChage = null; try &#123; rowChage = RowChange.parseFrom(entry.getStoreValue()); &#125; catch (Exception e) &#123; throw new RuntimeException(&quot;ERROR ## parser of eromanga-event has an error , data:&quot; + entry.toString(), e); &#125; EventType eventType = rowChage.getEventType(); System.out.println(String.format(&quot;================&amp;gt; binlog[%s:%s] , name[%s,%s] , eventType : %s&quot;, entry.getHeader().getLogfileName(), entry.getHeader().getLogfileOffset(), entry.getHeader().getSchemaName(), entry.getHeader().getTableName(), eventType)); for (RowData rowData : rowChage.getRowDatasList()) &#123; if (eventType == EventType.DELETE) &#123; printColumn(rowData.getBeforeColumnsList()); &#125; else if (eventType == EventType.INSERT) &#123; printColumn(rowData.getAfterColumnsList()); &#125; else &#123; System.out.println(&quot;-------&amp;gt; before&quot;); printColumn(rowData.getBeforeColumnsList()); System.out.println(&quot;-------&amp;gt; after&quot;); printColumn(rowData.getAfterColumnsList()); &#125; &#125; &#125; &#125; private static void printColumn(List&lt;Column&gt; columns) &#123; for (Column column : columns) &#123; System.out.println(column.getName() + &quot; : &quot; + column.getValue() + &quot; update=&quot; + column.getUpdated()); &#125; &#125;&#125;","tags":[{"name":"springCloud","slug":"springCloud","permalink":"http://example.com/tags/springCloud/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"}]},{"title":"SpringCloud系列14-总结","date":"2021-10-07T04:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列14-总结/","text":"多个微服务:12345678910&lt;modules&gt; &lt;module&gt;eureka-server&lt;/module&gt; &lt;module&gt;product-data-service&lt;/module&gt; &lt;module&gt;product-view-service-ribbon&lt;/module&gt; &lt;module&gt;product-view-service-feign&lt;/module&gt; &lt;module&gt;config-server&lt;/module&gt; &lt;module&gt;hystrix-dashboard&lt;/module&gt; &lt;module&gt;turbine&lt;/module&gt; &lt;module&gt;productServiceZuul&lt;/module&gt;&lt;/modules&gt; 端口号总结:微服务： eureka-server: 8761 product-data-service: 8001,8002,8003 product-view-service-ribbon: 8010 product-view-service-feign: 8012, 8013, 8014 hystrix-dashboard: 8020 turbine: 8021 config-server: 8030 zuul: 8040 第三方: zipkin:9411 rabbitMQ: 5672","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"SpringCloud系列13-网关Zuul","date":"2021-10-07T03:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列13-网关Zuul/","text":"问题：为何要用网关? 我们现在有两种微服务，分别是数据微服务和视图微服务。它们有可能放在不同的 ip 地址上，有可能是不同的端口。 为了访问他们，就需要记录这些地址和端口。 而地址和端口都可能会变化，这就增加了访问者的负担。这个时候，我们就可以用网关来解决这个问题。 如图所示，我们只需要记住网关的地址和端口号就行了： 如果要访问数据服务，访问地址 http://ip:port/api-data/products 即可。 如果要访问视图服务，访问地址 http://ip:port/api-view/products 即可 创建子项目： zuulpom.xml：12345678910111213141516171819202122232425262728293031&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;spring-cloud-parent&lt;/artifactId&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-parent/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;productServiceZuul&lt;/artifactId&gt; &lt;name&gt;productServiceZuul&lt;/name&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; ProductServiceZuulApplication.java:12345678910111213141516171819202122232425package cn.peach;import cn.hutool.core.util.NetUtil;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.boot.builder.SpringApplicationBuilder;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.cloud.netflix.eureka.EnableEurekaClient;import org.springframework.cloud.netflix.zuul.EnableZuulProxy;@SpringBootApplication@EnableZuulProxy@EnableEurekaClient@EnableDiscoveryClientpublic class ProductServiceZuulApplication&#123; public static void main( String[] args ) &#123; int port = 8040; if(!NetUtil.isUsableLocalPort(port)) &#123; System.err.printf(&quot;端口%d被占用了，无法启动%n&quot;, port ); System.exit(1); &#125; new SpringApplicationBuilder(ProductServiceZuulApplication.class).properties(&quot;server.port=&quot; + port).run(args); &#125;&#125; application.yml:配置文件，进行了路由映射 12345678zuul: routes: api-a: path: /api-data/** serviceId: PRODUCT-DATA-SERVICE api-b: path: /api-view/** serviceId: PRODUCT-VIEW-SERVICE-FEIGN 完整代码： 123456789101112131415eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/spring: application: name: product-service-zuulzuul: routes: api-a: path: /api-data/** serviceId: PRODUCT-DATA-SERVICE api-b: path: /api-view/** serviceId: PRODUCT-VIEW-SERVICE-FEIGN 启动： 首先挨个运行 EurekaServerApplication, ConfigServerApplication, ProductDataServiceApplication， ProductViewServiceFeignApplication。 然后启动 ProductServiceZuulApplication 接着访问地址: http://localhost:8040/api-data/products http://localhost:8040/api-view/products 这样就可以访问数据微服务和视微服务集群了，并且无需去记住那么多ip地址和端口号了。","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"SpringCloud系列12-断路器聚合监控","date":"2021-10-07T02:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列12-断路器聚合监控/","text":"需求:前面是针对一个微服务的断路器监控，但是微服务通常会是多个实例组成的一个集群。 倘若集群里的实例比较多，难道要挨个挨个去监控这些实例吗？ 何况有时候，根据集群的需要，会动态增加或者减少实例，监控起来就更麻烦了。 为了方便监控集群里的多个实例，springCloud 提供了一个 turbine 项目，它的作用是把一个集群里的多个实例汇聚在一个 turbine里，这个然后再在 断路器监控里查看这个 turbine, 这样就能够在集群层面进行监控了。 创建子项目： turbinepom.xml:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;spring-cloud-parent&lt;/artifactId&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-parent/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;turbine&lt;/artifactId&gt; &lt;name&gt;turbine&lt;/name&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-turbine&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; ProductServiceTurbineApplication.java1234567891011121314151617181920package cn.peach;import cn.hutool.core.util.NetUtil;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.boot.builder.SpringApplicationBuilder;import org.springframework.cloud.netflix.turbine.EnableTurbine;@SpringBootApplication@EnableTurbinepublic class ProductServiceTurbineApplication &#123; public static void main(String[] args) &#123; int port = 8021; if(!NetUtil.isUsableLocalPort(port)) &#123; System.err.printf(&quot;端口%d被占用了，无法启动%n&quot;, port ); System.exit(1); &#125; new SpringApplicationBuilder(ProductServiceTurbineApplication.class).properties(&quot;server.port=&quot; + port).run(args); &#125;&#125; application.yml配置信息，主要是：appConfig: product-view-service-feign, 这就表示它会把所有微服务名称是product-view-service-feign 的实例信息都收集起来。 1234567891011121314spring: application.name: turbineturbine: aggregator: clusterConfig: default # 指定聚合哪些集群，多个使用&quot;,&quot;分割，默认为default。可使用http://.../turbine.stream?cluster=&#123;clusterConfig之一&#125;访问 appConfig: product-view-service-feign ### 配置Eureka中的serviceId列表，表明监控哪些服务 clusterNameExpression: new String(&quot;default&quot;) # 1. clusterNameExpression指定集群名称，默认表达式appName；此时：turbine.aggregator.clusterConfig需要配置想要监控的应用名称 # 2. 当clusterNameExpression:default时，turbine.aggregator.clusterConfig可以不写，因为默认就是default # 3. 当clusterNameExpression:metadata[&#x27;cluster&#x27;]时，假设想要监控的应用配置了eureka.instance.metadata-map.cluster: ABC，则需要配置，同时turbine.aggregator.clusterConfig: ABCeureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"SpringCloud系列11-断路器监控","date":"2021-10-06T13:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列11-断路器监控/","text":"需求:断路器，是当数据服务不可用的时候， 断路器就会发挥作用。那么数据服务什么时候可用，什么时候不可用，如何监控这个事情呢？ 我们就要用到 断路器监控 来可视化掌控这个情况了。 创建子项目：hystrix-dashboardpom.xml文件1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;spring-cloud-parent&lt;/artifactId&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-parent/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;hystrix-dashboard&lt;/artifactId&gt; &lt;name&gt;hystrix-dashboard&lt;/name&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; ProductServiceHystrixDashboardApplication.java断路器监控启动类，主要就是@EnableHystrixDashboard 1234567891011121314151617181920package cn.peach;import cn.hutool.core.util.NetUtil;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.boot.builder.SpringApplicationBuilder;import org.springframework.cloud.netflix.hystrix.dashboard.EnableHystrixDashboard;@SpringBootApplication@EnableHystrixDashboardpublic class ProductServiceHystrixDashboardApplication&#123; public static void main(String[] args) &#123; int port = 8020; if(!NetUtil.isUsableLocalPort(port)) &#123; System.err.printf(&quot;端口%d被占用了，无法启动%n&quot;, port ); System.exit(1); &#125; new SpringApplicationBuilder(ProductServiceHystrixDashboardApplication.class).properties(&quot;server.port=&quot; + port).run(args); &#125;&#125; application.yml:123spring: application: name: hystrix-dashboard ProductViewServiceFeignApplication.java 修改视图微服务项目，以使得它可以把信息共享给监控中心。 修改ProductViewServiceFeignApplication， 增加 @EnableCircuitBreaker 1234567891011121314151617181920212223242526272829303132333435package cn.peach;import brave.sampler.Sampler;import cn.hutool.core.util.NetUtil;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.circuitbreaker.EnableCircuitBreaker;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.cloud.netflix.eureka.EnableEurekaClient;import org.springframework.cloud.openfeign.EnableFeignClients;import org.springframework.context.annotation.Bean;@SpringBootApplication@EnableEurekaClient@EnableDiscoveryClient@EnableFeignClients@EnableCircuitBreaker //把信息共享给监控中心public class ProductViewServiceFeignApplication &#123; public static void main(String[] args) &#123; // 判断 rabiitMQ 是否启动 int rabbitMQPort = 5672; if(NetUtil.isUsableLocalPort(rabbitMQPort)) &#123; System.err.printf(&quot;未在端口%d 发现 rabbitMQ服务，请检查rabbitMQ 是否启动&quot;, rabbitMQPort ); System.exit(1); &#125; // 推荐 8012 、 8013 或者 8014 SpringApplication.run(ProductViewServiceFeignApplication.class, args); &#125; @Bean public Sampler defaultSampler() &#123; return Sampler.ALWAYS_SAMPLE; &#125;&#125; AccessViewService.java:准备一个不停访问服务的类： AccessViewService。 这样可以不断地访问服务，才便于在监控那里观察现象。 1234567891011121314151617181920212223242526package cn.peach.util;import cn.hutool.core.thread.ThreadUtil;import cn.hutool.http.HttpUtil;public class AccessViewService &#123; public static void main(String[] args) &#123; while(true) &#123; ThreadUtil.sleep(1000); access(8012); access(8013); &#125; &#125; public static void access(int port) &#123; try &#123; String html= HttpUtil.get(String.format(&quot;http://127.0.0.1:%d/products&quot;,port)); System.out.printf(&quot;%d 地址的视图服务访问成功，返回大小是 %d%n&quot; ,port, html.length()); &#125; catch(Exception e) &#123; System.err.printf(&quot;%d 地址的视图服务无法访问%n&quot;,port); &#125; &#125;&#125; 启动： 首先挨个运行 EurekaServerApplication, ConfigServerApplication, ProductDataServiceApplication， ProductViewServiceFeignApplication，ProductServiceHystrixDashboardApplication; 运行视图微服务里的 AccessViewService 来周期性地访问 http://127.0.0.1:8012/products 。 因为只有访问了，监控里才能看到数据; 打开监控地址 http://localhost:8020/hystrix; 如图所示，在最上面输入http://localhost:8012/actuator/hystrix.stream : 点击 Monitor Stream 就可以看到监控信息了。","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"SpringCloud系列10-断路器Hystrix","date":"2021-10-06T12:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列10-断路器Hystrix/","text":"问题:视图微服务是依赖于数据微服务的。那么当数据微服务不可用的时候，会怎么样呢？我们主动把 ProductDataServiceApplication 关闭，然后再访问：http://localhost:8012/products 就会抛出异常。客户也看不懂这个是什么。为了解决这个问题，我们就会引入断路器的概念。 断路器:断路器: 就是当被访问的微服务无法使用的时候，当前服务能够感知这个现象，并且提供一个备用的方案出来。 改造:pom.xml:增加 jar spring-cloud-starter-netflix-hystrix 以支持断路器。 12345&lt;!--增加 jar spring-cloud-starter-netflix-hystrix 以支持断路器--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;&lt;/dependency&gt; ProductClientFeign.java注解由原来的 @FeignClient(value = &quot;PRODUCT-DATA-SERVICE&quot;)修改为 @FeignClient(value = &quot;PRODUCT-DATA-SERVICE&quot;,fallback = ProductClientFeignHystrix.class)。 123456789101112131415package cn.peach.client;import cn.peach.pojo.Product;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;import java.util.List;@FeignClient(value = &quot;PRODUCT-DATA-SERVICE&quot;,fallback = ProductClientFeignHystrix.class)public interface ProductClientFeign &#123; @GetMapping(&quot;/products&quot;) public List&lt;Product&gt; listProdcuts();&#125; ProductClientFeignHystrix.javaProductClientFeignHystrix 实现了 ProductClientFeign 接口，并提供了 listProdcuts() 方法。这个方法就会固定返回包含一条信息的集合。 1234567891011121314151617181920package cn.peach.client;/* * Create By Tao on 2022/4/24. * * */import cn.peach.pojo.Product;import org.springframework.stereotype.Component;import java.util.ArrayList;import java.util.List;@Componentpublic class ProductClientFeignHystrix implements ProductClientFeign&#123; public List&lt;Product&gt; listProdcuts()&#123; List&lt;Product&gt; result = new ArrayList&lt;&gt;(); result.add(new Product(0,&quot;产品数据微服务现在不可用&quot;,0)); return result; &#125;&#125; application.yml在配置文件里开启断路器: 1feign.hystrix.enabled: true 启动:挨个启动： EurekaServerApplication, ConfigServerApplication, ProductViewServiceFeignApplication。注意: 数据服务是没有启动的。然后访问地址：http://127.0.0.1:8012/products会发现，依然可以打开，并且得到提示信息： 产品数据微服务不可用。","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"SpringCloud系列9-消息总线Bus","date":"2021-10-06T11:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列9-消息总线Bus/","text":"问题：虽然配置了config-server, 也把视图服务改造成了配置客户端，但是当需要刷新配置信息的时候，不得不既重启 config-server, 又重启微服务。 这样的体验当然是不太好的。 我们当然是希望一旦 git 上的配置信息修改之后，就可以自动地刷新到微服务里，而不是需要手动重启才可以。 RabbitMQ： springCloud 通过 rabbitMQ 来进行消息广播，以达到有配置信息发生改变的时候，广播给多个微服务的效果。 需要先安装 rabbitMQ 服务器。 改造:pom.xml:product-view-service-feign: 新增spring-boot-starter-actuator 用于访问路径：&#x2F;actuator&#x2F;bus-refresh 新增spring-cloud-starter-bus-amqp 用于支持 rabbitmq 12345678910&lt;!--多了spring-boot-starter-actuator 用于访问路径：/actuator/bus-refresh--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--多了spring-cloud-starter-bus-amqp 用于支持 rabbitmq--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt;&lt;/dependency&gt; bootstrap.yml:新增 but总线配置: 123456spring: cloud: bus: enabled: true trace: enabled: true 新增 rabbitMQ 配置: 12345rabbitmq: host: localhost port: 5672 username: guest password: guest 完整代码： 123456789101112131415161718192021spring: cloud: config: label: develop profile: dev discovery: enabled: true serviceId: config-server bus: enabled: true trace: enabled: true client: serviceUrl: defaultZone: http://localhost:8761/eureka/rabbitmq: host: localhost port: 5672 username: guest password: guest application.yml:新增路径访问允许,这样才能访问 &#x2F;actuator&#x2F;bus-refresh: 12345678management: endpoints: web: exposure: include: &quot;*&quot; cors: allowed-origins: &quot;*&quot; allowed-methods: &quot;*&quot; FreshConfigUtil.java使用 post 的方式访问 http://localhost:8012/actuator/bus-refresh 地址，之所以要专门做一个 FreshConfigUtil 类，就是为了可以使用 post 访问，因为它不支持 get 方式访问，直接把这个地址放在浏览器里，是会抛出 405错误的。 12345678910111213141516171819202122package cn.peach.util;/* * Create By Tao on 2022/4/24. * * */import cn.hutool.http.HttpUtil;import java.util.HashMap;public class FreshConfigUtil &#123; public static void main(String[] args) &#123; HashMap&lt;String,String&gt; headers =new HashMap&lt;&gt;(); headers.put(&quot;Content-Type&quot;, &quot;application/json; charset=utf-8&quot;); System.out.println(&quot;因为要去git获取，还要刷新config-server, 会比较卡，所以一般会要好几秒才能完成，请耐心等待&quot;); String result = HttpUtil.createPost(&quot;http://localhost:8012/actuator/bus-refresh&quot;).addHeaders(headers).execute().body(); System.out.println(&quot;result:&quot;+result); System.out.println(&quot;refresh 完成&quot;); &#125;&#125; 对服务链路追踪的影响因为视图服务进行了改造，支持了 rabbitMQ, 那么在默认情况下，它的信息就不会进入 Zipkin了。 在Zipkin 里看不到视图服务的资料了。为了解决这个问题，在启动 Zipkin 的时候 带一个参数就好了：–zipkin.collector.rabbitmq.addresses&#x3D;localhost即改成了： 1java -jar zipkin-server-2.10.1-exec.jar --zipkin.collector.rabbitmq.addresses=localhost 注： 重启 zipkin 后，要再访问业务地址才可以看到依赖关系。","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"SpringCloud系列8-配置客户端","date":"2021-10-06T10:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列8-配置客户端/","text":"配置客户端把现成的 视图微服务-Feign 改造成配置客户端，使得其可以从配置服务器上获取版本信息。 pom.xml增加一个 spring-cloud-starter-config 用于访问配置服务器。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;&lt;/dependency&gt; bootstrap.yml 作为配置客户端，它需要在 bootstrap.yml 里配置 config-server 的信息，而不是像以前那样在 application.yml 里进行配置。 bootstrap.yml 和 application.yml 的区别，简单说就是前者先启动，并且一些系统方面的配置需要在 bootstrap.yml 里进行配置。 在 bootstrap.yml 里配置提供了 serviceId: config-server, 这个是配置服务器在 eureka server 里的服务名称，这样就可以定位 config-server了。123456789101112131415spring: cloud: config: label: develop profile: dev discovery: enabled: true serviceId: config-server bus: enabled: true trace: enabled: true client: serviceUrl: defaultZone: http://localhost:8761/eureka/ application.yml把 eureka 地址信息移动到了 bootstrap.yml 里。 123456789101112spring: application: name: product-view-service-feign thymeleaf: cache: false prefix: classpath:/templates/ suffix: .html encoding: UTF-8 content-type: text/html mode: HTML5 zipkin: base-url: http://localhost:9411 ProductController.java增加这个属性，就可以从 config-server 去获取 version 信息了。 12@Value(&quot;$&#123;version&#125;&quot;)String version; 然后把这个信息放在 Model里 1m.addAttribute(&quot;version&quot;, version); 完整代码： 12345678910111213141516@Controller@RefreshScopepublic class ProductController &#123; @Autowired ProductService productService; @Value(&quot;$&#123;version&#125;&quot;) String version; @RequestMapping(&quot;/products&quot;) public Object products(Model m) &#123; List&lt;Product&gt; ps = productService.listProducts(); m.addAttribute(&quot;version&quot;, version); m.addAttribute(&quot;ps&quot;, ps); return &quot;products&quot;; &#125;&#125; products.html:12345&lt;tr&gt; &lt;td align=&quot;center&quot; colspan=&quot;3&quot;&gt; &lt;p th:text=&quot;$&#123;version&#125;&quot; &gt;how2j springcloud version unknown&lt;/p&gt; &lt;/td&gt;&lt;/tr&gt; 启动:挨个启动 EurekaServerApplication, ConfigServerApplication, ProductDataServiceApplication, ProductViewServiceFeignApplication, 然后访问如下地址：http://localhost:8012/products","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"SpringCloud系列7-配置服务器","date":"2021-10-06T09:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列7-配置服务器/","text":"配置服务的需要:有时候，微服务要做集群，这就意味着，会有多个微服务实例。 在业务上有时候需要修改一些配置信息，比如说 版本信息吧~ 倘若没有配置服务， 那么就需要挨个修改微服务，挨个重新部署微服务，这样就比较麻烦。为了偷懒， 这些配置信息就会放在一个公共的地方，比如git, 然后通过配置服务器把它获取下来，然后微服务再从配置服务器上取下来。这样只要修改git上的信息，那么同一个集群里的所有微服务都立即获取相应信息了，这样就大大节约了开发，上线和重新部署的时间了。 如图所示，我们先在 git 里保存 version 信息， 然后通过 ConfigServer 去获取 version 信息， 接着不同的视图微服务实例再去 ConfigServer 里获取 version. git首先要准备git。如下是已经准备好的 git:https://github.com/taoliu-hub/spring-cloud-angular11/blob/develop/respo/product-view-service-feign-dev.properties这里就准备了版本信息： version &#x3D; Version 1.1 创建子项目: config-serverpom.xml主要是 spring-cloud-config-server 这个 jar 包 1234567891011121314151617181920212223242526272829303132&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;spring-cloud-parent&lt;/artifactId&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-parent/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;artifactId&gt;config-server&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;config-server&lt;/name&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 启动类：ConfigServerApplication123456789101112131415161718package cn.peach;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.cloud.config.server.EnableConfigServer;import org.springframework.cloud.netflix.eureka.EnableEurekaClient;@SpringBootApplication@EnableConfigServer@EnableDiscoveryClient@EnableEurekaClientpublic class ConfigServerApplication &#123; public static void main(String[] args) &#123; // 推荐 8030 SpringApplication.run(ConfigServerApplication.class, args); &#125;&#125; application.yml12345678910111213141516171819spring: application: name: config-server cloud: config: label: develop name: product-view-service-feign profile: dev server: git: uri: https://github.com/taoliu-hub/spring-cloud-angular11.git searchPaths: respo default-label: main timeout: 500000eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/ 启动先启动 EurekaServerApplication， 再启动 ConfigServerApplication， 然后访问http://localhost:8030/version/dev","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"SpringCloud系列6-服务链路追踪","date":"2021-10-06T08:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列6-服务链路追踪/","text":"什么是服务链路我们有两个微服务，分别是数据服务和视图服务，随着业务的增加，就会有越来越多的微服务存在，他们之间也会有更加复杂的调用关系。这个调用关系，仅仅通过观察代码，会越来越难以识别，所以就需要通过 zipkin 服务链路追踪服务器 这个东西来用图片进行识别了 改造 eureka-server 不需要做改造; product-data-service和product-view-service 需要进行改造以使其可以被追踪到。 pom.xml都加上以下依赖：12345&lt;!--服务链路追踪--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt;&lt;/dependency&gt; application.yml都加上以下配置信息：123spring: zipkin: base-url: http://localhost:9411 启动类都加上以下配置信息：ProductDataServiceApplication.java 和 ProductViewServiceFeignApplication.java： 1234@Beanpublic Sampler defaultSampler() &#123; return Sampler.ALWAYS_SAMPLE;&#125; 启动测试： 需要启动链路追踪服务器：zipkin-server-2.10.1-exec.jar, 命令启动:1java -jar zipkin-server-2.10.1-exec.jar 启动 eureka-server, 改造后的 product-data-service 和 product-view-service-feign; 访问一次 http://127.0.0.1:8012/products 通过 视图微服务去访问数据微服务，这样链路追踪服务器才知道有这事儿发生 然后打开链路追踪服务器 http://localhost:9411/zipkin/dependency/ 就可以看到如图所示的 视图微服务调用数据微服务 的图形了","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"SpringCloud系列5-视图微服务-Feign","date":"2021-10-06T07:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列5-视图微服务-Feign/","text":"Feign 概念:是对Ribbon的封装，调用起来更简单。 代码片段的区别 Ribbon方式：123456@AutowiredRestTemplate restTemplate;public List&lt;Product&gt; listProdcuts() &#123; return restTemplate.getForObject(&quot;http://PRODUCT-DATA-SERVICE/products&quot;,List.class);&#125; Feign方式：123456@FeignClient(value = &quot;PRODUCT-DATA-SERVICE&quot;)public interface ProductClientFeign &#123; @GetMapping(&quot;/products&quot;) public List&lt;Product&gt; listProdcuts();&#125; 创建子项目 product-view-service-feignpom.xml:123456789101112131415161718192021222324252627282930313233&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;spring-cloud-parent&lt;/artifactId&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-parent/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;product-view-service-feign&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; Feign 客户端:Feign 客户端， 通过 注解方式 访问 访问PRODUCT-DATA-SERVICE服务的 products路径， product-data-service 既不是域名也不是ip地址，而是 数据服务在 eureka 注册中心的名称。 注意: 这里只是指定了要访问的 微服务名称，但是并没有指定端口号到底是 8001, 还是 8002. Feign方式：1234567891011121314package cn.peach.client;import cn.peach.pojo.Product;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;import java.util.List;@FeignClient(value = &quot;PRODUCT-DATA-SERVICE&quot;)public interface ProductClientFeign &#123; @GetMapping(&quot;/products&quot;) public List&lt;Product&gt; listProdcuts();&#125; Java code: 注意：这里忽略controller、 service、 repository, html层的代码，只列出重要部分代码，如需了解详情可参阅以下地址获取代码：https://github.com/taoliu-hub/spring-cloud-angular11/tree/main/spring-cloud. 服务类: ProductServiceImpl 123456789101112131415161718192021package cn.peach.service.impl;import cn.peach.client.ProductClientFeign;import cn.peach.pojo.Product;import cn.peach.service.ProductService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import java.util.List;@Servicepublic class ProductServiceImpl implements ProductService &#123; @Autowired ProductClientFeign productClientFeign; @Override public List&lt;Product&gt; listProducts() &#123; return productClientFeign.listProdcuts(); &#125;&#125; 启动类，注解多了个 @EnableFeignClients， 表示用于使用 Feign 方式。 1234567891011121314151617181920package cn.peach;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.EnableEurekaClient;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.cloud.openfeign.EnableFeignClients;@SpringBootApplication@EnableEurekaClient@EnableDiscoveryClient@EnableFeignClientspublic class ProductViewServiceFeignApplication &#123; public static void main(String[] args) &#123; // 推荐 8012 、 8013 或者 8014 SpringApplication.run(ProductViewServiceFeignApplication.class, args); &#125;&#125; 配置application.yml配置类，指定了 eureka server 的地址，以及自己的名称。 另外是一些 thymeleaf 的默认配置。 1234567891011121314eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/spring: application: name: product-view-service-feign thymeleaf: cache: false prefix: classpath:/templates/ suffix: .html encoding: UTF-8 content-type: text/html mode: HTML5 启动并访问注册中心Eureka:刷新访问：http://127.0.0.1:8761/。 启动并访问视图微服务product-view-service-feign:刷新访问：http://127.0.0.1:8012/products。 调用图：如图所示： 首先数据微服务和视图微服务都被 eureka 管理起来了。 数据服务是由两个实例的集群组成的，端口分别是 8001 ， 8002 视图微服务通过 注册中心调用微服务， 然后负载均衡到 8001 或者 8002 端口的应用上。","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"SpringCloud系列4-视图微服务-RIBBON","date":"2021-10-06T06:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列4-视图微服务-RIBBON/","text":"Ribbon 概念访问前面注册好的数据微服务, springcloud 提供了两种方式: Ribbon: 是使用 restTemplate 进行调用，并进行客户端负载均衡。 Feign: 是对 Ribbon的封装，调用起来更简单。 什么是客户端负载均衡:在前面注册数据微服务里，注册了8001和8002两个微服务， Ribbon会从注册中心获知这个信息，然后由 Ribbon 这个客户端自己决定是调用哪个，这个就叫做客户端负载均衡。 创建子项目: product-view-service-ribbonpom.xml包含以下jar: spring-cloud-starter-netflix-eureka-client: eureka 客户端 spring-boot-starter-web： springmvc spring-boot-starter-thymeleaf： thymeleaf 做服务端渲染，(前后端分离项目不用配置)。 12345678910111213141516171819202122232425262728293031&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;spring-cloud-parent&lt;/artifactId&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-parent/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;product-view-service-ribbon&lt;/artifactId&gt; &lt;name&gt;product-view-service-ribbon&lt;/name&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; Ribbon 客户端Ribbon客户端: 通过restTemplate 访问 http://PRODUCT-DATA-SERVICE/products,而 product-data-service既不是域名也不是ip地址，而是数据服务在eureka 注册中心的名称. 注意: 这里只是指定了要访问的 微服务名称，但是并没有指定端口号到底是8001, 还是8002. 12345678910111213141516171819package cn.peach.client;import cn.peach.pojo.Product;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Component;import org.springframework.web.client.RestTemplate;import java.util.List;@Componentpublic class ProductClientRibbon &#123; @Autowired RestTemplate restTemplate; public List&lt;Product&gt; listProdcuts() &#123; return restTemplate.getForObject(&quot;http://PRODUCT-DATA-SERVICE/products&quot;,List.class); &#125;&#125; Java code: 注意：这里忽略controller、 service、 repository, html层的代码，只列出重要部分代码，如需了解详情可参阅以下地址获取代码：https://github.com/taoliu-hub/spring-cloud-angular11/tree/main/spring-cloud. 服务类: ProductServiceImpl 12345678910111213141516171819202122package cn.peach.service.impl;import cn.peach.client.ProductClientRibbon;import cn.peach.pojo.Product;import cn.peach.service.ProductService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import java.util.List;@Servicepublic class ProductServiceImpl implements ProductService &#123; @Autowired ProductClientRibbon productClientRibbon; @Override public List&lt;Product&gt; listProducts() &#123; return productClientRibbon.listProdcuts(); &#125;&#125; 启动类，注解多了个 @EnableDiscoveryClient，表示用于发现eureka 注册中心的微服务, 启动类，多了个 RestTemplate，就表示用 restTemplate 这个工具来做负载均衡, 考虑到要做集群。 自己输入端口，推荐 80010，8002，8003. 1234567891011121314151617181920212223import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.EnableEurekaClient;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.context.annotation.Bean;import org.springframework.cloud.client.loadbalancer.LoadBalanced;import org.springframework.web.client.RestTemplate;@SpringBootApplication@EnableEurekaClient@EnableDiscoveryClientpublic class ProductViewServiceRibbonApplication &#123; public static void main( String[] args ) &#123; SpringApplication.run(ProductDataServiceApplication.class, args); &#125; @Bean @LoadBalanced RestTemplate restTemplate() &#123; return new RestTemplate(); &#125;&#125; 配置application.yml配置类，指定了 eureka server 的地址，以及自己的名称。 另外是一些 thymeleaf 的默认配置。 1234567891011121314eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/spring: application: name: product-view-service-ribbon thymeleaf: cache: false prefix: classpath:/templates/ suffix: .html encoding: UTF-8 content-type: text/html mode: HTML5 启动并访问注册中心Eureka:刷新访问：http://127.0.0.1:8761/。 启动并访问视图微服务product-view-service-ribbon:刷新访问：http://127.0.0.1:8010/products。 调用图：如图所示： 首先数据微服务和视图微服务都被 eureka 管理起来了。 数据服务是由两个实例的集群组成的，端口分别是 8001 ， 8002 视图微服务通过 注册中心调用微服务， 然后负载均衡到 8001 或者 8002 端口的应用上。","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"SpringCloud系列3-注册数据微服务","date":"2021-10-06T05:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列3-注册数据微服务/","text":"创建子项目: product-data-service注意：若前面父子(聚合)项目创建了数据微服务，可直接更新此微服务。修改 pom.xml 为如下： spring-cloud-starter-netflix-eureka-client 表示这是个 eureka 客户端。 spring-boot-starter-web: 表示这是个web服务，会提供控制层1234567891011121314151617181920212223242526&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;spring-cloud-parent&lt;/artifactId&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-parent/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;product-data-service&lt;/artifactId&gt; &lt;name&gt;product-data-service&lt;/name&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 启动类ProductDataServiceApplication 启动类， 考虑到要做集群。 自己输入端口，推荐 8001，8002，8003. 注意：这里忽略controller、 service、 repository, html层的代码，只列出重要部分代码，如需了解详情可参阅以下地址获取代码：https://github.com/taoliu-hub/spring-cloud-angular11/tree/main/spring-cloud. 123456789101112131415package cn.peach;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.EnableEurekaClient;@SpringBootApplication@EnableEurekaClientpublic class ProductDataServiceApplication&#123; public static void main( String[] args ) &#123; SpringApplication.run(ProductDataServiceApplication.class, args); &#125;&#125; 配置application.yml 设置微服务的名称： product-data-service 设置注册中心的地址： http://localhost:8761/eureka/, 与eureka-server中的配置 application.yml一致。 12345678910# server:# port: 因为会启动多个 product-data-service, 所以端口号由用户自动设置，推荐 8001,8002,8003 spring: application: name: product-data-serviceeureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/ 启动并访问注册中心Eureka:刷新访问：http://127.0.0.1:8761/。 补充(上图红色信息)： EMERGENCY! EUREKA MAY BE INCORRECTLY CLAIMING INSTANCES ARE UP WHEN THEY’RE NOT. RENEWALS ARE LESSER THAN THRESHOLD AND HENCE THE INSTANCES ARE NOT BEING EXPIRED JUST TO BE SAFE. 上面这句话意思是，Eureka可能会声明已经不存在的实例。刷新数小于阈值时，为了安全起见不会剔除过期实例。 Eureka的默认阈值为：85% 比如目前有10个微服务，只有8个有心跳反应时，（8&#x2F;10&#x3D;80%&lt;85%）Eureka就会开启保护机制，过期的实例不会立马剔除。并且出这个紧急警告，在搭建Eureka Server时，比如我们搭建了2个Eureka Server，并且禁止自注册，Eureka Server自身算一个服务，那么其中任意一个Eureka，只能获得一个心跳，1&#x2F;2&#x3D;50%。那么也会出现这个警告。 当不想有这个红色警告是，本机自测可以关闭Eureka保护配置。生产环境下不要关。在application.yml文件中配置：12server: enable-self-preservation: false","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"SpringCloud系列2-服务注册中心","date":"2021-10-06T04:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列2-服务注册中心/","text":"创建子项目: eureka-serverpom.xml ，增加 spring-cloud-starter-netflix-eureka-server jar 包 12345678910111213141516171819202122&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;spring-cloud-parent&lt;/artifactId&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-parent/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;eureka-server&lt;/artifactId&gt; &lt;name&gt;eureka-server&lt;/name&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 启动类: EurekaServerApplication EurekaServer，它扮演的角色是注册中心，用于注册各种微服务，以便于其他微服务找到和访问。 EurekaServer 本身就是个 Springboot 微服务, 所以它有 @SpringBootApplication 注解。 @EnableEurekaServer 表示这是个 EurekaServer 。完整代码：123456789101112131415161718192021package cn.peach;import cn.hutool.core.util.NetUtil;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.boot.builder.SpringApplicationBuilder;import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;@SpringBootApplication@EnableEurekaServerpublic class EurekaServerApplication&#123; public static void main(String[] args) &#123; //8761 这个端口是默认的，就不要修改了，后面的子项目，都会访问这个端口。 int port = 8761; if(!NetUtil.isUsableLocalPort(port)) &#123; System.err.printf(&quot;端口%d被占用了，无法启动%n&quot;, port ); System.exit(1); &#125; new SpringApplicationBuilder(EurekaServerApplication.class).properties(&quot;server.port=&quot; + port).run(args); &#125;&#125; 配置application.yml 设置微服务的名称： eureka-server hostname: localhost 表示主机名称。 registerWithEureka：false. 表示是否注册到服务器。 因为它本身就是服务器，所以就无需把自己注册到服务器了。 fetchRegistry: false. 表示是否获取服务器的注册信息，和上面同理，这里也设置为 false。 defaultZone： http:&#x2F;&#x2F;${eureka.instance.hostname}:${server.port}&#x2F;eureka&#x2F; 自己作为服务器，公布出来的地址。 比如后续某个微服务要把自己注册到 eureka server, 那么就要使用这个地址： http://localhost:8761/eureka/ 123456789101112eureka: instance: hostname: localhost client: registerWithEureka: false fetchRegistry: false serviceUrl: defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ spring: application: name: eureka-server 启动并访问注册中心Eureka:运行 EurekaServerApplication，并访问：http://127.0.0.1:8761/，默认端口号为：8761。","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"SpringCloud系列1-父子(聚合)项目","date":"2021-10-06T03:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列1-父子(聚合)项目/","text":"SpringCloud代码结构 创建父项目: spring-cloud-parent修改pom： 1&lt;packaging&gt;pom&lt;/packaging&gt; 注意： 父项目只有pom.xml文件， packaging值为pom. 完整代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.6.RELEASE&lt;/version&gt; &lt;!-- 踩坑:版本不对会导致Feign连接不上，亲测其它版本, 2.3.3.RELEASE version. --&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-parent&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;spring-cloud-parent&lt;/name&gt; &lt;description&gt;spring-cloud-parent project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Finchley.SR2&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt;&lt;/project&gt; 创建子项目: product-data-service修改pom： 123456789&lt;parent&gt; &lt;artifactId&gt;spring-cloud-parent&lt;/artifactId&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-parent/pom.xml&lt;/relativePath&gt;&lt;/parent&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;artifactId&gt;product-data-service&lt;/artifactId&gt;&lt;name&gt;product-data-service&lt;/name&gt;","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"JAVA数据结构和算法","date":"2021-10-06T02:08:20.000Z","path":"blog/数据结构和算法/JAVA数据结构和算法/","text":"JAVA数据结构和算法： 数据结构分类：线性结构和非线性结构： 问题一：什么是线性和非线性； 个人的理解是：数据结构中线性结构指的是数据元素之间存在着“一对一”的线性关系的数据结构；线性结构包括：数组，链表，队列，栈；非线性结构包括：树，图，表； 详解：一.线性结构 1.数组特点：我们都知道数组中的元素在内存中连续存储的，可以根据是下标快速访问元素，因此，查询速度很快，然而插入和删除时，需要对元素移动空间，比较慢。数组使用场景：频繁查询，很少增加和删除的情况。 2.链表特点：元素可以不连续内存中，是以索引将数据联系起来的，当查询元素的时候需要从头开始查询，所以效率比较低，然而添加和删除的只需要修改索引就可以了链表使用场景：少查询，需要频繁的插入或删除情况 3.队列特点：先进先出，队列使用场景：多线程阻塞队列管理非常有用 4.栈特点：先进后出，就像一个箱子，栈使用场景：实现递归以及表示式 5.数组与链表的区别数组连续，链表不连续（从数据存储形式来说）数组内存静态分配，链表动态分配数组查询复杂度O(1)，链表查询复杂度O(n)数组添加或删除，复杂度O(n),链表添加删除，复杂度O(1)数组从栈中分配内存。链表从堆中分配内存。 补充：时间复杂度O(1), O(n), O(logn), O(nlogn)指什么 描述算法复杂度时,常用o(1), o(n), o(logn), o(nlogn)表示对应算法的时间复杂度，是算法的时空复杂度的表示。不仅仅用于表示时间复杂度，也用于表示空间复杂度。O后面的括号中有一个函数，指明某个算法的耗时&#x2F;耗空间与数据增长量之间的关系。其中的n代表输入数据的量。 O(1)： 是最低的时空复杂度了，代表耗时&#x2F;耗空间与输入数据大小无关，无论输入数据增大多少倍，耗时&#x2F;耗空间都不变。 哈希算法就是典型的O(1)时间复杂度，无论数据规模多大，都可以在一次计算后找到目标（不考虑冲突的话） O(n)： 代表数据量增大几倍，耗时也增大几倍。比如常见的遍历算法。 O(n^2)： 代表数据量增大n倍时，耗时增大n的平方倍，这是比线性更高的时间复杂度。比如冒泡排序，就是典型的O(n^2)的算法，对n个数排序，需要扫描n×n次。 O(logn)： 代表当数据增大n倍时，耗时增大logn倍（这里的log是以2为底的，比如，当数据增大256倍时，耗时只增大8倍，是比线性还要低的时间复杂度）。二分查找就是O(logn)的算法，每找一次排除一半的可能，256个数据中查找只要找8次就可以找到目标。 O(nlogn)： 代表n乘以logn，当数据增大256倍时，耗时增大256*8&#x3D;2048倍。这个复杂度高于线性低于平方。归并排序就是O(nlogn)的时间复杂度。 问题二：c1）插入排序（直接插入排序、希尔排序） 2）交换排序（冒泡排序、快速排序）3）选择排序（直接选择排序、堆排序）4）归并排序5）分配排序（基数排序）特点:所需辅助空间最多：归并排序所需辅助空间最少：堆排序平均速度最快：快速排序不稳定：快速排序，希尔排序，堆排序 直接插入排序 基本思想：在要排序的一组数中，假设前面(n-1)[n&gt;&#x3D;2] 个数已经是排好顺序的，现在要把第n 个数插到前面的有序数中，使得这 n个数也是排好顺序的。如此反复循环，直到全部排好顺序 12345678910111213141516/** * 插入排序法 * * @param datas */ public static int[] sortInsert(int[] datas) &#123; for (int i = 1; i &lt; datas.length; i++) &#123; int j = i - 1; AlgorithmUtil.temp = datas[i]; for (; j &gt;= 0 &amp;&amp; AlgorithmUtil.temp &lt; datas[j]; j--) &#123; datas[j + 1] = datas[j]; &#125; datas[j + 1] = AlgorithmUtil.temp; &#125; return datas; &#125; 简单选择排序 基本思想：在要排序的一组数中，选出最小的一个数与第一个位置的数交换；然后在剩下的数当中再找最小的与第二个位置的数交换，如此循环到倒数第二个数和最后一个数比较为止。 1234567891011121314151617/** * 选择排序 * * @return */ public static int[] sortSelect(int[] datas) &#123; for (int i = 0; i &lt; datas.length; i++) &#123; int index = i; for (int j = i + 1; j &lt; datas.length; j++) &#123; if (datas[j] &lt; datas[index]) index = j; &#125; if (i != index) AlgorithmUtil.swap(datas, i, index); &#125; return datas; &#125; 冒泡排序 基本思想：在要排序的一组数中，对当前还未排好序的范围内的全部数，自上而下对相邻的两个数依次进行比较和调整，让较大的数往下沉，较小的往上冒。即：每当两相邻的数比较后发现它们的排序与排序要求相反时，就将它们互换。 1234567891011121314/** * 冒泡排序 * * @return */ public static int[] sortBubble(int[] datas) &#123; for (int i = 0; i &lt; datas.length - 1; i++) &#123; for (int j = 0; j &lt; datas.length - 1 - i; j++) &#123; if (datas[j] &gt; datas[j + 1]) AlgorithmUtil.swap(datas, j, j + 1); &#125; &#125; return datas; &#125; 快速排序 基本思想：选择一个基准元素,通常选择第一个元素或者最后一个元素,通过一趟扫描，将待排序列分成两部分,一部分比基准元素小,一部分大于等于基准元素,此时基准元素在其排好序后的正确位置,然后再用同样的方法递归地排序划分的两部分。 1234567891011121314151617181920212223242526272829303132/** * 快速排序；分割数组 * * @param datas */ public static int QuickPartition(int[] datas, int left, int right) &#123; int pivot = datas[left]; while (left &lt; right) &#123; while (left &lt; right &amp;&amp; datas[right] &gt;= pivot) --right; datas[left] = datas[right]; // 将比枢轴小的元素移到低端，此时right位相当于空，等待低位比pivotkey大的数补上 while (left &lt; right &amp;&amp; datas[left] &lt;= pivot) ++left; datas[right] = datas[left]; // 将比枢轴大的元素移到高端，此时left位相当于空，等待高位比pivotkey小的数补上 &#125; datas[left] = pivot; // 当left == right，完成一趟快速排序，此时left位相当于空，等待pivotkey补上 return left; &#125; /** * 快速排序；递归返回数组 * * @param datas */ public static int[] sortQuick(int[] datas, int left, int right) &#123; if (left &lt; right) &#123; int data = QuickPartition(datas, left, right); sortQuick(datas, left, data - 1); sortQuick(datas, data + 1, right); &#125; return datas; &#125; 1.冒泡算法，2.选择算法，3.快速算法。4.插入算法，5.希尔算法，6.堆算法 基本思想：在要排序的一组数中，选出最小的一个数与第一个位置的数交换；然后在剩下的数当中再找最小的与第二个位置的数交换，如此循环到倒数第二个数和最后一个数比较为止。 123456789101112131415161718192021222324252627282930313233343536public class AlgorithmUtil &#123; public static int temp,index = 0; /** * 临时值交换 * * @param datas * 数组 * @param i * @param j */ public static void swap(int[] datas, int i, int j) &#123; temp = datas[i]; datas[i] = datas[j]; datas[j] = temp; &#125; /** * 扩充数组长度 * * @param datas * @param value * @return */ public static int[] expandArray(int[] datas, int value) &#123; if (datas.length &lt;= index) &#123; int[] arrays = new int[datas.length * 2]; System.arraycopy(datas, 0, arrays, 0, datas.length); datas = arrays; &#125; datas[index] = value; index++; return datas; &#125; &#125;","tags":[{"name":"JAVA数据结构和算法","slug":"JAVA数据结构和算法","permalink":"http://example.com/tags/JAVA%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/"}],"categories":[{"name":"数据结构和算法","slug":"数据结构和算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/"}]},{"title":"SpringCloud介绍","date":"2021-10-06T02:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud/","text":"基础知识介绍：单体架构系统：单体架构就是所有功能，都放在一个应用里。 好处：便于开发，测试，部署也很方便，直接打成一个 jar 或者 war, 就什么都好了。 弊端：要体现在高访问，高并发的上限是固定的。 比如一个单体架构，能够承受 1000次访问&#x2F;秒。 但是访问量达到 2000次&#x2F;秒的时候，就会非常卡顿，严重影响业务，并且仅仅依靠单体架构本身，很难突破这个瓶颈了。 集群和分布式：既然单体架构会有性能上的瓶颈，那么总要解决呀。 解决办法通常就是采用集群和分布式来做。 集群：指一组相互独立的计算机，通过高速的网络组成一个计算机系统。服务器集群就是指将很多服务器集中起来一起进行同一种服务，在客户端看来就像是只有一个服务器。 集群的特点和优势: 高性能 性价比 可伸缩性集群的分类 负载均衡集群（Load balancing clusters）简称LBC 高可用性集群（High-availability clusters）简称HAC 高性能计算集群（High-perfomance clusters）简称HPC 分布式：指将不同的业务分布在不同的地方，而集群指的是将几台服务器集中在一起，实现同一业务。分布式中的每一个节点，都可以做集群，而集群并不一定就是分布式的。 分布式一致性：分布式系统中，一个问题是负载均衡，另外一个问题就是数据的一致性。 在分布式集群中，很难保障数据的一致性。在以往的单节点服务中，通常使用锁来实现，当发生并发冲突时 通过对锁的持有获得对象的操作权，从而保证数据在同一时刻只允许被一个请求操作。但是在集群中，若同样采用锁的机制，那么需要一台节点用来管理分配锁，当其他节点进行请求前，首先去获取锁从而获得执行权。但是这样会产生单节点问题，即若管理锁的节点down掉，那么整个集群将无法工作。同时，由于锁的机制会使整个集群变成串行化单节点的形式，失去了集群的意义。 分布式和集群的关系： 根据分布式的介绍看出，其主要的功能是用了将我们的系统模块化，将系统进行解耦的，方便我们的维护和开发的，但是其并不能解决我们的并发问题，也无法保证我们的系统在服务器宕机后的正常运转。 集群就恰好弥补了分布式的缺陷，集群就是多个服务器处理相同的业务，这在一方面可以解决或者说改善我们系统的并发问题，一方面可以解决我们服务器如果出现一定数量的宕机后，系统仍然可以正常运转。 SpringCloud介绍：SpringCloud 就是一套工具。 Spring Cloud 并不是一个项目，而是一组项目的集合。包含了很多的子项目，每一个子项目都是一种微服务开发过程中遇到的问题的一种解决方案。它利用 Spring Boot的开发便利性巧妙地简化了分布式系统基础设施的开发，如服务发现注册、配置中心、消息总线、负载均衡、断路器、数据监控等，都可以用 Spring Boot的开发风格做到一键启动和部署。Spring Cloud并没有重复制造轮子，它只是将目前各家公司开发的比较成熟、经得起实际考验的服务框架组合起来，通过Spring Boot风格进行再封装屏蔽掉了复杂的配置和实现原理，最终给开发者留出了一套简单易懂、易部署和易维护的分布式系统开发工具包。 子项目介绍: Spring Cloud Config：集中配置管理工具，分布式系统中统一的外部配置管理，可以支持客户端配置的刷新及加密、解密操作, 可以让你把配置放到远程服务器，目前支持本地存储、Git 以及 Subversion。 Spring Cloud Netflix：针对多种 Netflix 组件提供的开发工具包，其中包括 Eureka、Hystrix、Ribbon、Feign、Zuul、Archaius 等组件, 如下: Eureka：服务治理组件，包括服务端的注册中心和客户端的服务发现机制； Hystrix：服务容错组件，实现了断路器模式，为依赖服务的出错和延迟提供了容错能力； Ribbon：负载均衡的服务调用组件，具有多种负载均衡调用策略； Feign：基于Ribbon和Hystrix的声明式服务调用组件； Zuul：API网关组件，对请求提供路由及过滤功能； Archaius：基于java的配置管理类库，主要用于多配置存储的动态获取。 Spring Cloud Bus：事件、消息总线，用于在集群（例如，配置变化事件）中传播状态变化，可与 Spring Cloud Config 联合实现热部署。 Spring Cloud Consul：封装了 Consul 操作，consul 是一个服务发现与配置工具，与 Docker 容器可以无缝集成。 Spring Cloud Security ：安全工具包，对Zuul代理中的负载均衡OAuth2客户端及登录认证进行支持。 Spring Cloud Sleuth：日志收集工具包，封装了 Dapper，Zipkin 和 HTrace 操作. Spring Cloud 应用的分布式跟踪实现。 Spring Cloud Stream：数据流操作开发包，封装了与 Redis，Rabbit、Kafka 等发送接收消息，实现的消息微服务。 Spring Cloud Task：用于快速构建短暂、有限数据处理任务的微服务框架，用于向应用中添加功能性和非功能性的特性。 Spring Cloud Zookeeper：基于 ZooKeeper 的服务发现与配置管理组件。 Spring Cloud Gateway：API网关组件，对请求提供路由及过滤功能, Spring Cloud 网关相关的整合实现。 Spring Cloud Aws：用于简化整合 Amazon Web Service 的组件。 Spring Cloud Cli：基于 Spring Boot CLI，可以让你以命令行方式快速建立云组件。 Spring Cloud Commons：服务发现、负载均衡、熔断机制这种模式为 Spring Cloud 客户端提供了一个通用的抽象层。 Spring Cloud Contract：Spring Cloud Contract是一个总体项目，其中包含帮助用户成功实施消费者驱动合同方法的解决方案(契约测试)。 Spring Cloud Cloudfoundry：通过 Oauth2 协议绑定服务到 CloudFoundry，CloudFoundry 是 VMware 推出的开源 PaaS 云平台。 Spring Cloud OpenFeign：基于Ribbon和Hystrix的声明式服务调用组件，可以动态创建基于Spring MVC注解的接口实现用于服务调用，在Spring Cloud 2.0中已经取代Feign成为了一等公民。","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"索引优化三","date":"2021-05-25T11:52:21.000Z","path":"blog/DB/索引/索引优化三/","text":"分页查询优化业务系统分页功能可能会用如下sql实现，表示取出从10001行开始的10行记录，看似只查询10条，实际SQL是先读取10010条记录，然后抛弃前10000条记录，然后读到后面10条目标数据。因此要查询一张大表比较靠后的数据，执行效率是非常低的： 1explain select * from employees limit 10000,10; 根据自增且连续的主键排序的分页查询改写后的SQL走了索引，且扫描行数大大减少，执行效率更高，但很多场景并不实用，表中可能某些记录被删主键空缺，导致主键不连续结果不一致，这里没添加单独order by，表示通过主键排序，该优化只适合于主键自增且连续且结果按照主键排序： 1explain select * from employees where id &gt; 90000 limit 10; 根据非主键字段排序的分页查询并没有使用name字段的索引，扫描整个索引并查找到没索引的行的成本比扫描全表的成本更高，所以优化器放弃使用索引。 1explain select * from employees ORDER BY name limit 90000, 10; 优化关键是让排序时返回的字段尽可能少，可让排序和分页操作先查出主键，然后根据主键查到对应的记录 1explain select * from employees e inner join (select id from employees order by name limit 90000,5) ed on e.id = ed.id; Join关联查询优化1234567891011121314151617181920212223242526272829303132333435363738394041CREATE TABLE `t1`( `id` int(11) NOT NULL AUTO_INCREMENT, `a` int(11) DEFAULT NULL, `b` int(11) DEFAULT NULL, PRIMARY KEY (`id`), KEY `idx_a` (`a`)) ENGINE = InnoDB DEFAULT CHARSET = utf8;create table t2 like t1;-- 插入一些示例数据，往t1表插入1万行记录drop procedure if exists insert_t1;delimiter ;;create procedure insert_t1()begin declare i int; set i = 1; while(i &lt;= 10000) do insert into t1(a, b) values (i, i); set i = i + 1; end while;end;;delimiter ;call insert_t1();-- 往t2表插入100行记录drop procedure if exists insert_t2;delimiter ;;create procedure insert_t2()begin declare i int; set i = 1; while(i &lt;= 100) do insert into t2(a, b) values (i, i); set i = i + 1; end while;end;;delimiter ;call insert_t2(); MySQL的表关联常见有 Nested-Loop Join嵌套循环连接算法和 Block Nested-Loop Join基于块的嵌套循环连接算法两种算法 嵌套循环连接算法一次一行循环地从第一张表即驱动表中读取行，在这行数据中取到关联字段，根据关联字段在另一张表即被驱动表里取出满足条件的行，然后取出两张表的结果合集。 执行计划结果的id如果一样则按从上到下顺序执行sql，先执行的就是驱动表，从执行计划中可知，t2是驱动表，t1是被驱动表， 优化器一般会优先选择小表做驱动表，使用 inner join 时，排在前面的表并不一定是驱动表。 1EXPLAIN select * from t1 inner join t2 on t1.a= t2.a; !] 从t2表中读取一行数据，若t2表有查询过滤条件，会从过滤结果里取出一行数据，取出关联字段a，到t1表中查找；取出t1表中满足条件的行，跟t2中获取到的结果合并，作为结果返回给客户端；然后继续下一条数据。 整个过程会读取t2表的所有数据，即扫描t2表100行，然后遍历每行数据中字段a的值，根据t2表中a的值索引扫描 t1表中的对应行，1次扫描可认为读取t1表一行完整数据，由于t1表的a字段有索引，故扫描100次。因此整个过程扫描了200行。若被驱动表的关联字段没索引，使用 NLJ嵌套循环连接算法性能会比较低； left join左表是驱动表，right join右表是驱动表，join优化器会选择数据量比较小的表作为驱动表。 一般join语句中，若执行计划Extra中未出现Using join buffer 则表示使用的是 NLJ嵌套循环连接算法 基于块的嵌套循环连接算法把驱动表的数据读入到join_buffer中，然后扫描被驱动表，把被驱动表每一行取出来跟join_buffer中的数据做对比。 Extra中的 Using join buffer (Block Nested Loop) 说明该关联查询使用的是基于块的嵌套循环连接算法。 1EXPLAIN select * from t1 inner join t2 on t1.b= t2.b; 首先将t2表的所有数据放入到 join_buffer 中，把t1表中每一行取出，跟join_buffer中的数据对比，返回满足join条件的数据。 整个过程对t1表和t2表都做了一次全表扫描，因此扫描的总行数为10000+100=10100。且join_buffer里的数据是无序的，故对t1表中的每一行，都要做100次判断，故内存中的判断次数是100 * 10000&#x3D; 100万次。 join_buffer是由参数join_buffer_size设定的，默认为256k 。若放不下所有数据，就是分段放。若t2表有1000行记录，join_buffer一次只能放800行，则先往join_buffer里放800行，然后从t1表里取数据跟join_buffer 中数据对比得到部分结果，然后清空join_buffer，再放入t2表剩余200行，再次从t1表里取数据跟join_buffer中数据对比，所以就多扫了一次t1表。 若使用嵌套循环连接算法，这里扫描行数为100万次，且是磁盘扫描，而基于块的嵌套循环连接算法是内存计算，即使扫描次数更多但性能更高。对于被驱动表的关联字段没索引的关联查询，一般都会使用 BNL算法，若有索引一般选择 NLJ算法，有索引的情况下NLJ算法比BNL算法性能更高； 关联SQL优化关联字段加索引，让MySQL做join操作时尽量选择嵌套循环连接算法，小表驱动大表，写多表连接SQL时若明确知道哪张表是小表可以用 straight_join 写法固定连接驱动方式，省去MySQL优化器自己判断时间 ； straight_join 功能同join类似，能让左表来驱动右表，能改表优化器对于联表查询的执行顺序。 由于left join，right join已代表指定了表的执行顺序，故 straight_join只适用于inner join ； 1EXPLAIN select * from t2 straight_join t1 on t2.a = t1.a; 尽可能让优化器去判断，大部分情况下MySQL优化器是比人要聪明，使用straight_join一定要慎重，因为部分情况下人为指定的执行顺序并不一定比优化引擎靠谱； 在决定哪个表做驱动表时，是两个表按照各自的条件过滤，过滤完成之后，计算参与join的各个字段的总数据量，数据量小的是小表作为驱动表。 in和exsits优化当t2表的数据集小于t1表的数据集时，in优于exists 的写法 1explain select * from t1 where a in (select a from t2); 等价于： 123for(select a from t2)&#123; select * from t1 where t1.a = t2.a&#125; exists优于in的写法，将主查询t2的数据，放到子查询t1中做条件验证，根据验证结果true或false来决定主查询的数据是否保留 1explain select * from t2 where exists(select 1 from t1 where t1.a = t2.a); exists子查询只返回true或false，因此子查询中的 select * 也可以用 select 1 替换，官方说法是实际执行时会忽略select清单，因此没有区别；exists子查询的实际执行过程可能经过了优化而不是理解上的逐条对比；exists子查询往往也可以用join来代替，何种最优需要具体问题具体分析； count(*)查询优化只有根据某个字段count才不会统计字段为null值的数据行，下面4个语句的执行计划跑出来都一样，执行效率差不多，全都是使用的二级索引 1234EXPLAIN select count(1) from employees;EXPLAIN select count(id) from employees;EXPLAIN select count(name) from employees;EXPLAIN select count(*) from employees; 字段有索引时执行效率从大到小：count(*)≈count(1)&gt;count(字段)&gt;count(主键id)；因为字段有索引，count(字段)统计走二级索引，因为二级索引存储数据比主键索引少，所以count(字段)&gt;count(主键id) 字段无索引时执行效率从大到小：count(*)≈count(1)&gt;count(主键id)&gt;count(字段) ；因为字段没有索引count(字段)统计走不了索引，count(主键id)还可以走主键索引，所以count(主键id)&gt;count(字段) count(1)跟count(字段)执行过程类似，不过 count(1)不需要取出字段统计，就用常量1做统计，count(字段)还需要取出字段，故理论上count(1)比count(字段)会快一点。 count(*) 是例外，MySQL并不会把全部字段取出来，而是专门做了优化，不取值按行累加，效率很高，故不需要用count(列名)或count(常量)来替代count(*)。 count(id)最终选择辅助索引而不是主键聚集索引，因为二级索引相对主键索引存储数据更少，检索性能应该更高，大概5.7版本才优化。 查询MySQL自己维护的总行数myisam存储引擎的表做不带where条件的count查询性能是很高的，因为myisam存储引擎的表的总行数会被mysql存储在磁盘上，查询不需要计算 1explain select count(*) from test_myisam; 对于InnoDB存储引擎的表，因为有MVCC机制MySQL不会存储表的总记录行数，查询count需要实时计算 show table status若只需要知道表总行数的估计值可以用如下SQL查询，性能很高 1show table status like &#x27;employees&#x27;; 将总数维护到Redis插入或删除表数据行的时候同时维护redis里的表总行数key的计数值，用incr或decr命令，但是这种方式可能不准，很难保证表操作和redis操作的事务一致性 增加数据库计数表插入或删除表数据行的时候同时维护计数表，让它们在同一个事务里操作","tags":[{"name":"索引","slug":"索引","permalink":"http://example.com/tags/%E7%B4%A2%E5%BC%95/"}],"categories":[{"name":"DB","slug":"DB","permalink":"http://example.com/categories/DB/"},{"name":"索引","slug":"DB/索引","permalink":"http://example.com/categories/DB/%E7%B4%A2%E5%BC%95/"}]},{"title":"索引优化二","date":"2021-05-25T09:52:21.000Z","path":"blog/DB/索引/索引优化二/","text":"索引设计原则代码先行，索引后上建完表不要立马就建立索引，一般应等主体业务功能开发完毕，把涉及到该表相关sql都要拿出来分析之后再建立索引。 联合索引尽量覆盖条件可设计一个或两三个联合索引，尽量少建单值索引，让每一个联合索引都尽量去包含sql语句里的where、order by、group by的字段，还要确保这些联合索引的字段顺序尽量满足sql查询的最左前缀原则。 不要在小基数字段上建立索引索引基数是指这个字段在表里总共有多少个不同的值，若一张表总共100万行记录，其中性别字段其值不是男就是女，则该字段基数就是2。 若对这种小基数字段建立索引，还不如全表扫描，因为你的索引树里就包含男和女两种值，根本没法进行快速的二分查找，那用索引就没有太大的意义了。 一般建立索引，尽量使用那些基数比较大的字段，才能发挥出B+树快速二分查找的优势。 当然也存在特例，类似 delete_status 这类字段，用 0 和 1 分别表示未删除和已删除，一般仅仅只用到 0 的情况下也可以建立索引。 长字符串我们可以采用前缀索引尽量对字段类型较小的列设计索引，如tinyint类型的字段，字段类型较小的话，占用磁盘空间也会比较小，搜索时性能也会比较好。所谓的字段类型小一点的列，也不是绝对的，很多时候要针对varchar(255)这种字段建立索引，哪怕多占用一些磁盘空间也是有必要的。 对于这种varchar(255)的大字段可能会比较占用磁盘空间，可以稍微优化下，比如针对该字段的前20个字符建立索引，对这个字段里的每个值的前20个字符放在索引树里，类似于KEY， index(name(20),age,position) 。 在where条件里搜索时，若根据name字段来搜索，此时就会先到索引树里根据name字段的前20个字符去搜索，定位到之后前20个字符的前缀匹配的部分数据之后，再回到聚簇索引提取出来完整的name字段值进行比对。 若要对字段name做排序order by 和分组group by ，此时name因为在索引树里仅仅包含了前20个字符，故该排序和分组没法用上索引。 where与order by冲突时优先where一般这种时候往往都是让where条件去使用索引来快速筛选出来一部分指定的数据，接着再进行排序。大多数情况基于索引进行where筛选往往可以最快速度筛选出需要的少部分数据，然后做排序的成本可能会小很多。 基于慢sql查询做优化可根据监控后台的一些慢sql，针对这些慢sql查询做特定的索引优化。 索引下推对于辅助的联合索引 (name, age, position)，正常情况按照最左前缀原则，SELECT * FROM employees WHERE name like &#39;LiLei%&#39; AND age = 22 AND position =&#39;manager&#39;该情况只会走name字段索引，因为根据name字段过滤完，得到的索引行里age和position是无序的，无法很好的利用索引。 MySQL5.6之前的版本，该查询只能在联合索引里匹配到名字是’LiLei’开头的索引，然后拿这些索引对应的主键逐个回表，到主键索引上找出相应的记录，再比对age和position这两个字段的值是否符合。 MySQL5.6 引入了索引下推优化，可在索引遍历过程中，对索引中包含的所有字段先做判断，过滤掉不符合条件的记录之后再回表，可有效减少回表次数。使用索引下推优化后，查询在联合索引里匹配到名字’LiLei’开头的索引后，同时还会在索引里过滤age和position这两个字段，拿着过滤完剩下的索引对应的主键id再回表查整行数据。 索引下推会减少回表次数，对于 InnoDB引擎的表索引下推只能用于二级索引，InnoDB的主键索引是聚簇索引叶子节点上保存的是全行数据，故这时索引下推并不会起到减少查询全行数据的效果。 Using filesort文件排序原理详解 filesort 文件排序方式有单路排序和双路排序又叫回表排序模式 单路排序：一次性取出满足条件行的所有字段，然后在sort buffer中进行排序；用trace工具可看到sort_mode信息里显示 &lt;sort_key, additional_fields&gt; 或者 &lt;sort_key, packed_additional_fields&gt; 双路排序：首先根据相应条件取出相应的排序字段和可直接定位行数据的行ID，然后在sort buffer中进行排序，排序完后需要再次取回其它需要的字段；用trace工具可看到 sort_mode 信息里显示 &lt;sort_key, rowid&gt; MySQL通过比较系统变量max_length_for_sort_data与需查询字段总大小来判断使用哪种排序模式，默认1024字节，若字段总长度小于 max_length_for_sort_data 则使用单路排序模式；否则使用双路排序模式。 123set session optimizer_trace=&quot;enabled=on&quot;,end_markers_in_json=on;explain select * from employees where name = &#x27;zhangsan&#x27; order by position;select * from information_schema.OPTIMIZER_TRACE; 123456789101112131415161718192021222324252627&#123;//Sql执行阶段 &quot;select#&quot;: 1, &quot;steps&quot;: [ &#123; &quot;filesort_information&quot;: [ &#123; &quot;direction&quot;: &quot;asc&quot;, &quot;table&quot;: &quot;`employees`&quot;, &quot;field&quot;: &quot;position&quot; &#125; ] /* filesort_information */, &quot;filesort_priority_queue_optimization&quot;: &#123; &quot;usable&quot;: false, &quot;cause&quot;: &quot;not applicable (no LIMIT)&quot; &#125; /* filesort_priority_queue_optimization */, &quot;filesort_execution&quot;: [ ] /* filesort_execution */, &quot;filesort_summary&quot;: &#123;//文件排序信息 &quot;rows&quot;: 10000, //预计扫描行数 &quot;examined_rows&quot;: 10000, //参与排序的行 &quot;number_of_tmp_files&quot;: 3, //使用临时文件的个数，这个值若为0代表全部使用sort_buffer内存排序，否则使用磁盘文件排序 &quot;sort_buffer_size&quot;: 262056, //排序缓存的大小，单位Byte &quot;sort_mode&quot;: &quot;&lt;sort_key, packed_additional_fields&gt;&quot; //排序方式，这里用的单路排序 &#125; /* filesort_summary */ &#125; ] /* steps */&#125; /* join_execution */ 1234set max_length_for_sort_data = 10; --employees表所有字段长度总和肯定大于10字节explain select * from employees where name = &#x27;zhangsan&#x27; order by position;select * from information_schema.OPTIMIZER_TRACE;set session optimizer_trace=&quot;enabled=off&quot;; --关闭trace 123456789101112131415161718192021222324252627&#123; &quot;select#&quot;: 1, &quot;steps&quot;: [ &#123; &quot;filesort_information&quot;: [ &#123; &quot;direction&quot;: &quot;asc&quot;, &quot;table&quot;: &quot;`employees`&quot;, &quot;field&quot;: &quot;position&quot; &#125; ] /* filesort_information */, &quot;filesort_priority_queue_optimization&quot;: &#123; &quot;usable&quot;: false, &quot;cause&quot;: &quot;not applicable (no LIMIT)&quot; &#125; /* filesort_priority_queue_optimization */, &quot;filesort_execution&quot;: [ ] /* filesort_execution */, &quot;filesort_summary&quot;: &#123; &quot;rows&quot;: 10000, &quot;examined_rows&quot;: 10000, &quot;number_of_tmp_files&quot;: 2, &quot;sort_buffer_size&quot;: 262136, &quot;sort_mode&quot;: &quot;&lt;sort_key, rowid&gt;&quot;// 排序方式， 这里用的双路排序 &#125; /* filesort_summary */ &#125; ] /* steps */&#125; /* join_execution */ 单路排序：从索引name找到第一个满足name &#x3D; ‘zhangsan’ 条件的主键id，根据主键id取出整行，取出所有字段的值，存入sort_buffer中，直到将所以满足条件的数据找完，对sort_buffer中的数据按照字段position进行排序。 双路排序：从索引name找到第一个满足name &#x3D; ‘zhuge’的主键id，根据主键id取出整行，把排序字段position和主键id放到sort buffer中，直到将所以满足条件的数据找完，对sort_buffer中的字段position和主键id按照字段 position进行排序，遍历排序好的id和字段position，按照id的值回到原表中取出所有字段的值返回给客户端 对比两个排序模式，单路排序会把所有需要查询的字段都放到sort buffer中，而双路排序只会把主键和需要排序的字段放到sort buffer中进行排序，然后再通过主键回到原表查询需要的字段。 若MySQL排序内存sort_buffer配置比较小且没有条件继续增加，可适当把 max_length_for_sort_data 配置小点，让优化器选择使用双路排序算法，可在 sort_buffer 中一次排序更多的行，只需要再根据主键回到原表取数据。 若MySQL排序内存有条件可配置比较大，可以适当增大max_length_for_sort_data的值，让优化器优先选择单路排序，把需要的字段放到 sort_buffer 中，这样排序后就会直接从内存里返回查询结果。 MySQL通过 max_length_for_sort_data 参数来控制排序，在不同场景使用不同的排序模式，从而提升排序效率。若全部使用 sort_buffer内存排序一般情况下效率会高于磁盘文件排序，但不能因为这个就随便增大 sort_buffer默认1M ，mysql很多参数设置都是做过优化的，不要轻易调整。 优化实例示例数据12345678910111213141516171819202122232425262728CREATE TABLE `employees` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(24) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;姓名&#x27;, `age` int(11) NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;年龄&#x27;, `position` varchar(20) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;职位&#x27;, `hire_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#x27;入职时间&#x27;, PRIMARY KEY (`id`), KEY `idx_name_age_position` (`name`,`age`,`position`) USING BTREE) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8 COMMENT=&#x27;员工记录表&#x27;;INSERT INTO employees(name,age,position,hire_time) VALUES(&#x27;LiLei&#x27;,22,&#x27;manager&#x27;,NOW());INSERT INTO employees(name,age,position,hire_time) VALUES(&#x27;HanMeimei&#x27;, 23,&#x27;dev&#x27;,NOW());INSERT INTO employees(name,age,position,hire_time) VALUES(&#x27;Lucy&#x27;,23,&#x27;dev&#x27;,NOW()); -- 插入一些示例数据drop procedure if exists insert_emp;delimiter ;;create procedure insert_emp()begin declare i int; set i=1; while(i&lt;=100000)do insert into employees(name,age,position) values(CONCAT(&#x27;zhangsan&#x27;,i),i,&#x27;dev&#x27;); set i=i+1; end while;end;;delimiter ;call insert_emp(); 联合索引第一个字段用范围查找第一个字段用范围查找，可能不会走索引，mysql内部计算第一个字段查询范围，若结果集很大，回表效率不高，或扫描的行很多，还不如就全表扫描，就不会走索引，很明显这里没有走索引，但是不同的数据是有可能走索引的，即使走索引也只是name字段能走索引。 1EXPLAIN SELECT * FROM employees WHERE name &gt; &#x27;LiLei&#x27; AND age = 22 AND position =&#x27;manager&#x27;; 这里使用like就能走索引，且三个字段的索引都走了，但 like 也不一定必定走索引 1EXPLAIN SELECT * FROM employees WHERE name like &#x27;LiLei%&#x27; AND age = 22 AND position =&#x27;manager&#x27;; 强制索引使用 force index 强制使用索引，虽然使用了强制走索引让联合索引第一个字段范围查找也走索引，扫描的行rows看上去也少了点，但是最终查找效率不一定比全表扫描高，因为回表效率不高 1EXPLAIN SELECT * FROM employees force index(idx_name_age_position) WHERE name &gt; &#x27;LiLei&#x27; AND age = 22 AND position =&#x27;manager&#x27;; 关闭查询缓存，分别查询如下两个语句，很明强制索引比不走索引慢得多l 123456set global query_cache_size=0;set global query_cache_type=0;-- 执行时间0.103sSELECT * FROM employees WHERE name &gt; &#x27;LiLei&#x27;;-- 执行时间0.623sSELECT * FROM employees force index(idx_name_age_position) WHERE name &gt; &#x27;LiLei&#x27;; 覆盖索引优化1EXPLAIN SELECT name,age,position FROM employees WHERE name &gt; &#x27;LiLei&#x27; AND age = 22 AND position =&#x27;manager&#x27;; in和or in 和 or 在表数据量比较大的情况会走索引，在表记录不多的情况下会选择全表扫描 12EXPLAIN SELECT * FROM employees WHERE name in (&#x27;LiLei&#x27;, &#x27;HanMeimei&#x27;, &#x27;Lucy&#x27;) AND age = 22 AND position = &#x27;manager&#x27;;EXPLAIN SELECT * FROM employees WHERE (name = &#x27;LiLei&#x27; or name = &#x27;HanMeimei&#x27;) AND age = 22 AND position = &#x27;manager&#x27;; 将employees表复制一张employees_copy的表，只保留两三条记录 12EXPLAIN SELECT * FROM employees_copy WHERE name in (&#x27;LiLei&#x27;, &#x27;HanMeimei&#x27;, &#x27;Lucy&#x27;) AND age = 22 AND position = &#x27;manager&#x27;;EXPLAIN SELECT * FROM employees_copy WHERE (name = &#x27;LiLei&#x27; or name = &#x27;HanMeimei&#x27;) AND age = 22 AND position = &#x27;manager&#x27;; like like KK%一般情况都会走索引，之所以走索引，是因为用到了索引下推优化 1EXPLAIN SELECT * FROM employees WHERE name like &#x27;LiLei%&#x27; AND age = 22 AND position =&#x27;manager&#x27;; 但若扫表数据过多，也可能不走索引 1EXPLAIN SELECT * FROM employees WHERE name like &#x27;zhangsan%&#x27; AND age = 22 AND position =&#x27;manager&#x27;; order by与group by优化最左前缀法则，中间字段不能断，因此查询用到了name索引，从 key_len=74 也能看出，age索引列用在排序过程中，因为Extra字段里没有using filesort 1explain select * from employees where name = &#x27;Lilei&#x27; and position = &#x27;dev&#x27; order by age; key_len=74 查询使用了name索引，由于用了position进行排序，跳过了age，出现了 Using filesort 1explain select * from employees where name = &#x27;Lilei&#x27; order by position; 查找只用到索引name，age和position用于排序，无Using filesort 1explain select * from employees where name = &#x27;Lilei&#x27; order by age, position; 出现Using filesort ，因为索引的创建顺序为name,age,position，但是排序的时候age和position颠倒位置了 1explain select * from employees where name = &#x27;Lilei&#x27; order by position,age; 未出现Using filesort ，因为age为常量，在排序中被优化，所以索引未颠倒 1explain select * from employees where name = &#x27;Lilei&#x27; and age = 18 order by position,age; 虽然排序的字段列与索引顺序一样，且 order by默认升序，这里position desc变成了降序，导致与索引的排序方式不同，从而产生Using filesort。Mysql8以上版本有降序索引可以支持该种查询方式。 1explain select * from employees where name = &#x27;zhangsan&#x27; order by age asc, position desc; 对于排序来说，多个相等条件也是范围查询 1explain select * from employees where name in (&#x27;zhangsan&#x27;, &#x27;LiLei&#x27;) order by age, position; 1explain select * from employees where name &gt; &#x27;a&#x27; order by name; 用覆盖索引优化 1explain select name, age, position from employees where name &gt; &#x27;a&#x27; order by name; MySQL支持两种方式的排序 filesort 和 index ， Using index 是指MySQL扫描索引本身完成排序。 index效率高，filesort效率低。 order by满足两种情况会使用Using index：order by语句使用索引最左前列；使用 where子句与order by子句条件列组合满足索引最左前列。 尽量在索引列上完成排序，遵循索引建立时的最左前缀法则。若 order by 的条件不在索引列上，就会产生Using filesort。能用覆盖索引尽量用覆盖索引； group by与order by很类似，其实质是先排序后分组，遵照索引创建顺序的最左前缀法则，对于group by的优化若不需要排序的可加上order by null禁止排序 where高于having，能写在where中的限定条件就不要去having限定了 trace工具示例数据中name大于a的数据非常多，而大于zzz的数据几乎没有，由于用name索引需要遍历name字段联合索引树，然后还需要根据遍历出来的主键值去主键索引树里再去查出最终数据，成本比全表扫描还高； 1EXPLAIN select * from employees where name &gt; &#x27;a&#x27;; 使用覆盖索引优化 1EXPLAIN select name,age,position from employees where name &gt; &#x27;a&#x27; ; 1EXPLAIN select * from employees where name &gt; &#x27;zzz&#x27; ; 最终是否选择走索引或一张表涉及多个索引，最终如何选择索引，可通过 trace工具来具体分析，开启trace工具会影响MySQL性能，只能临时分析sql使用，用完之后立即关闭，如下是开启trace工具命令，然后调用具体的查询语句，在查询 information_schema.OPTIMIZER_TRACE 的trace字段。 123456-- 开启traceset session optimizer_trace = &quot;enabled=on&quot;,end_markers_in_json = on;select * from employees where name &gt; &#x27;a&#x27; order by position;select * from information_schema.OPTIMIZER_TRACE;-- 关闭traceset session optimizer_trace=&quot;enabled=off&quot;; 查询结果如下，可以很明显看到全表扫描的成本低于索引扫描，所以mysql最终选择全表扫描： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221&#123; &quot;steps&quot;: [ &#123; &quot;join_preparation&quot;: &#123; -- 第一阶段：SQL准备阶段，格式化sql &quot;select#&quot;: 1, &quot;steps&quot;: [ &#123; &quot;expanded_query&quot;: &quot;/* select#1 */ select `employees`.`id` AS `id`,`employees`.`name` AS `name`,`employees`.`age` AS `age`,`employees`.`position` AS `position`,`employees`.`hire_time` AS `hire_time` from `employees` where (`employees`.`name` &gt; &#x27;a&#x27;) order by `employees`.`position`&quot; &#125; ] /* steps */ &#125; /* join_preparation */ &#125;, &#123; &quot;join_optimization&quot;: &#123; --第二阶段：SQL优化阶段 &quot;select#&quot;: 1, &quot;steps&quot;: [ &#123; &quot;condition_processing&quot;: &#123; --条件处理 &quot;condition&quot;: &quot;WHERE&quot;, &quot;original_condition&quot;: &quot;(`employees`.`name` &gt; &#x27;a&#x27;)&quot;, &quot;steps&quot;: [ &#123; &quot;transformation&quot;: &quot;equality_propagation&quot;, &quot;resulting_condition&quot;: &quot;(`employees`.`name` &gt; &#x27;a&#x27;)&quot; &#125;, &#123; &quot;transformation&quot;: &quot;constant_propagation&quot;, &quot;resulting_condition&quot;: &quot;(`employees`.`name` &gt; &#x27;a&#x27;)&quot; &#125;, &#123; &quot;transformation&quot;: &quot;trivial_condition_removal&quot;, &quot;resulting_condition&quot;: &quot;(`employees`.`name` &gt; &#x27;a&#x27;)&quot; &#125; ] /* steps */ &#125; /* condition_processing */ &#125;, &#123; &quot;substitute_generated_columns&quot;: &#123; &#125; /* substitute_generated_columns */ &#125;, &#123; &quot;table_dependencies&quot;: [ --表依赖详情 &#123; &quot;table&quot;: &quot;`employees`&quot;, &quot;row_may_be_null&quot;: false, &quot;map_bit&quot;: 0, &quot;depends_on_map_bits&quot;: [ ] /* depends_on_map_bits */ &#125; ] /* table_dependencies */ &#125;, &#123; &quot;ref_optimizer_key_uses&quot;: [ ] /* ref_optimizer_key_uses */ &#125;, &#123; &quot;rows_estimation&quot;: [ --预估表的访问成本 &#123; &quot;table&quot;: &quot;`employees`&quot;, &quot;range_analysis&quot;: &#123; &quot;table_scan&quot;: &#123; --全表扫描情况 &quot;rows&quot;: 97275, --扫描行数 &quot;cost&quot;: 19810 --查询成本 &#125; /* table_scan */, &quot;potential_range_indexes&quot;: [ --查询可能使用的索引 &#123; &quot;index&quot;: &quot;PRIMARY&quot;, --主键索引 &quot;usable&quot;: false, &quot;cause&quot;: &quot;not_applicable&quot; &#125;, &#123; &quot;index&quot;: &quot;idx_name_age_position&quot;, --辅助索引 &quot;usable&quot;: true, &quot;key_parts&quot;: [ &quot;name&quot;, &quot;age&quot;, &quot;position&quot;, &quot;id&quot; ] /* key_parts */ &#125; ] /* potential_range_indexes */, &quot;setup_range_conditions&quot;: [ ] /* setup_range_conditions */, &quot;group_index_range&quot;: &#123; &quot;chosen&quot;: false, &quot;cause&quot;: &quot;not_group_by_or_distinct&quot; &#125; /* group_index_range */, &quot;analyzing_range_alternatives&quot;: &#123; --分析各个索引使用成本 &quot;range_scan_alternatives&quot;: [ &#123; &quot;index&quot;: &quot;idx_name_age_position&quot;, &quot;ranges&quot;: [ &quot;a &lt; name&quot; --索引使用范围 ] /* ranges */, &quot;index_dives_for_eq_ranges&quot;: true, &quot;rowid_ordered&quot;: false, --使用该索引获取的记录是否按照主键排序 &quot;using_mrr&quot;: false, &quot;index_only&quot;: false, --是否使用覆盖索引 &quot;rows&quot;: 48637, --索引扫描行数 &quot;cost&quot;: 58365, --索引使用成本 &quot;chosen&quot;: false, --是否选择该索引 &quot;cause&quot;: &quot;cost&quot; &#125; ] /* range_scan_alternatives */, &quot;analyzing_roworder_intersect&quot;: &#123; &quot;usable&quot;: false, &quot;cause&quot;: &quot;too_few_roworder_scans&quot; &#125; /* analyzing_roworder_intersect */ &#125; /* analyzing_range_alternatives */ &#125; /* range_analysis */ &#125; ] /* rows_estimation */ &#125;, &#123; &quot;considered_execution_plans&quot;: [ &#123; &quot;plan_prefix&quot;: [ ] /* plan_prefix */, &quot;table&quot;: &quot;`employees`&quot;, &quot;best_access_path&quot;: &#123; --最优访问路径 &quot;considered_access_paths&quot;: [ --最终选择的访问路径 &#123; &quot;rows_to_scan&quot;: 97275, &quot;access_type&quot;: &quot;scan&quot;, --访问类型：为scan，全表扫描 &quot;resulting_rows&quot;: 97275, &quot;cost&quot;: 19808, &quot;chosen&quot;: true, --确定选择 &quot;use_tmp_table&quot;: true &#125; ] /* considered_access_paths */ &#125; /* best_access_path */, &quot;condition_filtering_pct&quot;: 100, &quot;rows_for_plan&quot;: 97275, &quot;cost_for_plan&quot;: 19808, &quot;sort_cost&quot;: 97275, &quot;new_cost_for_plan&quot;: 117083, &quot;chosen&quot;: true &#125; ] /* considered_execution_plans */ &#125;, &#123; &quot;attaching_conditions_to_tables&quot;: &#123; &quot;original_condition&quot;: &quot;(`employees`.`name` &gt; &#x27;a&#x27;)&quot;, &quot;attached_conditions_computation&quot;: [ ] /* attached_conditions_computation */, &quot;attached_conditions_summary&quot;: [ &#123; &quot;table&quot;: &quot;`employees`&quot;, &quot;attached&quot;: &quot;(`employees`.`name` &gt; &#x27;a&#x27;)&quot; &#125; ] /* attached_conditions_summary */ &#125; /* attaching_conditions_to_tables */ &#125;, &#123; &quot;clause_processing&quot;: &#123; &quot;clause&quot;: &quot;ORDER BY&quot;, &quot;original_clause&quot;: &quot;`employees`.`position`&quot;, &quot;items&quot;: [ &#123; &quot;item&quot;: &quot;`employees`.`position`&quot; &#125; ] /* items */, &quot;resulting_clause_is_simple&quot;: true, &quot;resulting_clause&quot;: &quot;`employees`.`position`&quot; &#125; /* clause_processing */ &#125;, &#123; &quot;reconsidering_access_paths_for_index_ordering&quot;: &#123; &quot;clause&quot;: &quot;ORDER BY&quot;, &quot;steps&quot;: [ ] /* steps */, &quot;index_order_summary&quot;: &#123; &quot;table&quot;: &quot;`employees`&quot;, &quot;index_provides_order&quot;: false, &quot;order_direction&quot;: &quot;undefined&quot;, &quot;index&quot;: &quot;unknown&quot;, &quot;plan_changed&quot;: false &#125; /* index_order_summary */ &#125; /* reconsidering_access_paths_for_index_ordering */ &#125;, &#123; &quot;refine_plan&quot;: [ &#123; &quot;table&quot;: &quot;`employees`&quot; &#125; ] /* refine_plan */ &#125; ] /* steps */ &#125; /* join_optimization */ &#125;, &#123; &quot;join_execution&quot;: &#123; --第三阶段：SQL执行阶段 &quot;select#&quot;: 1, &quot;steps&quot;: [ &#123; &quot;filesort_information&quot;: [ &#123; &quot;direction&quot;: &quot;asc&quot;, &quot;table&quot;: &quot;`employees`&quot;, &quot;field&quot;: &quot;position&quot; &#125; ] /* filesort_information */, &quot;filesort_priority_queue_optimization&quot;: &#123; &quot;usable&quot;: false, &quot;cause&quot;: &quot;not applicable (no LIMIT)&quot; &#125; /* filesort_priority_queue_optimization */, &quot;filesort_execution&quot;: [ ] /* filesort_execution */, &quot;filesort_summary&quot;: &#123; &quot;rows&quot;: 100003, &quot;examined_rows&quot;: 100003, &quot;number_of_tmp_files&quot;: 31, &quot;sort_buffer_size&quot;: 262056, &quot;sort_mode&quot;: &quot;&lt;sort_key, packed_additional_fields&gt;&quot; &#125; /* filesort_summary */ &#125; ] /* steps */ &#125; /* join_execution */ &#125; ] /* steps */&#125;","tags":[{"name":"索引","slug":"索引","permalink":"http://example.com/tags/%E7%B4%A2%E5%BC%95/"}],"categories":[{"name":"DB","slug":"DB","permalink":"http://example.com/categories/DB/"},{"name":"索引","slug":"DB/索引","permalink":"http://example.com/categories/DB/%E7%B4%A2%E5%BC%95/"}]},{"title":"索引优化一","date":"2021-05-25T07:52:21.000Z","path":"blog/DB/索引/索引优化一/","text":"示例数据12345678910111213CREATE TABLE `employees`( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(24) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;姓名&#x27;, `age` int(11) NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;年龄&#x27;, `position` varchar(20) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;职位&#x27;, `hire_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#x27;入职时间&#x27;, PRIMARY KEY (`id`), KEY `idx_name_age_position` (`name`, `age`, `position`) USING BTREE) ENGINE = InnoDB AUTO_INCREMENT = 4 DEFAULT CHARSET = utf8 COMMENT =&#x27;员工记录表&#x27;;INSERT INTO employees(name, age, position, hire_time) VALUES (&#x27;LiLei&#x27;, 22, &#x27;manager&#x27;, NOW());INSERT INTO employees(name, age, position, hire_time) VALUES (&#x27;HanMeimei&#x27;, 23, &#x27;dev&#x27;, NOW());INSERT INTO employees(name, age, position, hire_time) VALUES (&#x27;Lucy&#x27;, 23, &#x27;dev&#x27;, NOW()); 全值匹配通过key_len和ref可以明显的看出生效的索引个数 1EXPLAIN SELECT * FROM employees WHERE name= &#x27;LiLei&#x27;; 1EXPLAIN SELECT * FROM employees WHERE name= &#x27;LiLei&#x27; AND age = 22; 12EXPLAIN SELECT * FROM employees WHERE name= &#x27;LiLei&#x27; AND age = 22 AND position =&#x27;manager&#x27;;EXPLAIN SELECT * FROM employees WHERE name= &#x27;LiLei%&#x27; AND age = 22 AND position =&#x27;manager&#x27;; 最左前缀法则若索引了多列，要遵守最左前缀法则，即查询从索引的最左前列开始并且不跳过索引中的列，但MySQL在执行时会做一些顺序优化，一下三条SQL语句都是使用到了索引，explain出来的结果一样 123EXPLAIN SELECT * FROM employees WHERE name= &#x27;LiLei&#x27; AND position =&#x27;manager&#x27; AND age = 22;EXPLAIN SELECT * FROM employees WHERE position =&#x27;manager&#x27; AND name= &#x27;LiLei&#x27; AND age = 22;EXPLAIN SELECT * FROM employees WHERE position =&#x27;manager&#x27; AND age = 22 AND name= &#x27;LiLei&#x27;; 一下两个SQL由于跳过了索引中的name列，导致索引失效 12EXPLAIN SELECT * FROM employees WHERE age = 30 AND position = &#x27;dev&#x27;;EXPLAIN SELECT * FROM employees WHERE position = &#x27;manager&#x27;; 以下情况仍然可以用到name列的索引 12EXPLAIN SELECT * FROM employees WHERE name= &#x27;LiLei&#x27; AND position =&#x27;manager&#x27;;EXPLAIN SELECT * FROM employees WHERE position =&#x27;manager&#x27; AND name= &#x27;LiLei&#x27;; 不在索引列上做任何计算、函数、自动or手动类型转换，会导致索引失效转向全表扫描对name列做left计算导致索引失效 1EXPLAIN SELECT * FROM employees WHERE left(name, 3) = &#x27;LiLei&#x27;; 给hire_time增加一个普通索引，查询时进行日期类型转换，导致索引失效 12ALTER TABLE `employees` ADD INDEX `idx_hire_time` (`hire_time`) USING BTREE ;EXPLAIN select * from employees where date(hire_time) =&#x27;2018‐09‐30&#x27;; 转化为日期范围查询，有可能会走索引，具体是否会走索引，MySQL底层会做一些评估 12EXPLAIN select * from employees where hire_time &gt;=&#x27;2018‐09‐30 00:00:00&#x27; and hire_time &lt;= &#x27;2018‐09‐30 23:59:59&#x27;;ALTER TABLE `employees` DROP INDEX `idx_hire_time`; 存储引擎不能使用索引中范围条件右边的列以下两种情况一样仅联合索引的name列和age生效了 12EXPLAIN SELECT * FROM employees WHERE name= &#x27;LiLei&#x27; AND age &gt; 22 AND position =&#x27;manager&#x27;;EXPLAIN SELECT * FROM employees WHERE name= &#x27;LiLei&#x27; AND age &gt; 22; 尽量使用覆盖索引减少 select * 语句，只访问索引的查询，即索引列包含查询列。下面的例子使用了覆盖索引： 1EXPLAIN SELECT name, age, position FROM employees WHERE name= &#x27;LiLei&#x27; AND age = 23 AND position = &#x27;manager&#x27;; 下面的情况是未使用覆盖索引的情况，先从联合索引中查出数据的主键索引，然后再回表到主键索引中查询数据 1EXPLAIN SELECT * FROM employees WHERE name= &#x27;LiLei&#x27; AND age = 23 AND position =&#x27;manager&#x27;; 使用不等于在使用不等于 != ， &lt;&gt; ， not in ， not exists 时候无法使用索引会导致全表扫描；使用范围查询 &lt; 、 &gt; 、 &lt;= 、 &gt;= 等，mysql内部优化器会根据检索比例、表大小等多个因素整体评估是否使用索引 1EXPLAIN SELECT * FROM employees WHERE name != &#x27;LiLei&#x27;; is null，is not null一般情况下也无法使用索引1EXPLAIN SELECT * FROM employees WHERE name is null like以通配符开头索引失效会变成全表扫描操作1EXPLAIN SELECT * FROM employees WHERE name like &#x27;%Lei%&#x27;; like Lei%相当于&#x3D;常量， Lei%和Lei%33%相当于范围 12EXPLAIN SELECT * FROM employees WHERE name like &#x27;Lei%&#x27;;EXPLAIN SELECT * FROM employees WHERE name like &#x27;Lei%33%&#x27;; 解决like’%字符串%’索引不被使用的方法，使用覆盖索引，查询字段必须是建立覆盖索引字段，如果不能使用覆盖索引则可能需要借助搜索引擎 1EXPLAIN SELECT name, age, position FROM employees WHERE name like &#x27;%Lei%&#x27;; 字符串不加单引号索引失效1EXPLAIN SELECT * FROM employees WHERE name = 1000; 少用or或in用or或in查询时，mysql不一定使用索引，mysql内部优化器会根据检索比例、表大小等多个因素整体评估是否使用索引，详见范围查询优化 1EXPLAIN SELECT * FROM employees WHERE name = &#x27;LiLei&#x27; or name = &#x27;HanMeimei&#x27;; 范围查询优化给年龄添加单值索引，mysql内部优化器会根据检索比例、表大小等多个因素整体评估是否使用索引，可能由于单次数据量查询过大导致优化器最终选择不走索引，优化方法可将大的范围拆分成多个小范围 1234ALTER TABLE `employees` ADD INDEX `idx_age` (`age`) USING BTREE;explain select * from employees where age &gt;=1 and age &lt;=2000;explain select * from employees where age &gt;=1 and age &lt;=10;ALTER TABLE `employees` DROP INDEX `idx_age`;","tags":[{"name":"索引","slug":"索引","permalink":"http://example.com/tags/%E7%B4%A2%E5%BC%95/"}],"categories":[{"name":"DB","slug":"DB","permalink":"http://example.com/categories/DB/"},{"name":"索引","slug":"DB/索引","permalink":"http://example.com/categories/DB/%E7%B4%A2%E5%BC%95/"}]},{"title":"索引的原理与使用","date":"2021-05-25T05:52:21.000Z","path":"blog/DB/索引/索引的原理与使用/","text":"索引是帮助MySQL高效获取数据的排好序的数据结构。索引的数据结构：二叉树、红黑树、Hash表、B-Tree； MySQL的索引使用的是 B+ 树而不是使用的B树，因为 B树不管叶子节点还是非叶子节点，都会保存数据，这样导致在非叶子节点中能保存的指针数量变少，指针少的情况下要保存大量数据，只能增加树的高度，而在查找数据时一次页的查找代表一次IO ，导致IO操作变多，查询性能变低； Hash对索引的key进行一次hash计算就可以定位出数据存储的位置，很多时候Hash索引要比B+ 树索引更高效，仅能满足 = ， IN ，不支持范围查询，hash冲突问题 B-Tree叶子节点具有相同的深度，叶子节点的指针为空，所有索引元素不重复，节点中的数据索引从左到右依次递增排列 B+Tree非叶子节点不存储数据，只存储索引即冗余，可以放更多的索引，叶子节点包含所有索引字段，叶子节点用指针连接，方便范围查询，提高区间访问的性能。冗余索引的构建时，是提取叶子节点中索引最小的索引。 MySQL文件页大小为16K，假设一行数据大小为1K，一页就能存16条数据，也就是一个叶子节点能存16条数据；再看非叶子节点，假设主键ID为bigint类型，那么长度为8B，指针大小在Innodb源码中为6B，一共就是14B ，一页里就可以存储 16K/14=1170 个(主键+指针)，一颗高度为2的B+树能存储的数据为： 1170*16=18720 条，一颗高度为3的B+树能存储的数据为：1170 * 1170 * 16 = 21902400（千万级条） 1SHOW GLOBAL STATUS like &#x27;Innodb_page_size’; B+Tree是一颗有序的树，对于联合索引 A、B、C ，在A相等的情况B是有序的，在A、B相等的情况C是有序的 聚集索引聚集索引即叶节点包含了完整的数据记录，每个InnoDB表有且仅有一个主键索引即聚集索引，二级索引等都是非聚集索引，需要回表，再去查询聚集索引从而找到具体的数据。 单从索引查询效率来说，聚集索引比非聚集索引要快，非聚集索引叶节点上的数据是存储的主键索引的 ID 。当表未建立主键索引时，MySQL会使用唯一性索引来作为主键索引，当表没有主键索引和唯一性索引时，将使用隐藏字段 rowId 作为主键索引。 主键索引中行是按照聚集索引物理排序的，若主键频繁改变，物理顺序会改变，MySQL要不断调整B+树，且中间可能会产生页面的分裂和合并等等，会导致性能会急剧降低。 非聚集索引除了主键索引以外的索引都叫做非聚集索引，或叫辅助索引、二级索引，非聚集索引叶子节点不包含行记录全部数据，叶子节点除了包含键值以外，每个叶子节点中的索引行中还包含了相应行数据的聚集索引键。 辅助索引的存在并不影响数据在聚集索引中的组织，因此每张表上可有多个辅助索引，当通过辅助索引来寻找数据时，InnoDB存储引擎会遍历辅助索引并通过叶级别的指针获得指向主键索引的主键，然后再通过主键索引来找到一个完整的行记录，该过程也被称为回表。根据辅助索引的值查询一条完整的用户记录需要使用到2棵B+树，一次辅助索引一次聚集索引。 非聚集索引查询时需要回表到主键索引中查询具体的数据，但一般查询到的主键ID可能是乱序的，回表效率很低下，故引入了 MRR即Multi Range Read多范围读取针对于辅助索引上的范围查询进行优化，收集辅助索引对应主键rowid ，进行排序后回表查询，将随机IO转顺序IO 。但 MRR 优化措施的条件比较苛刻。 辅助索引上之虽然可以存放完整数据从而避免回表操作，但存放完整数据太占磁盘空间，导致存储空间大量浪费，且每次对数据的变化要在所有包含数据的索引中全部都修改一次，性能也非常低下。 自适应哈希索引 InnoDB 存储引擎内部监控索引热数据，然后内部创建一个Hash索引，称之为自适应哈希索引Adaptive Hash Index, AHI 仅数据库自身创建并使用，并不能对其进行干预，控制参数 Innodb_adaptive_hash_index 和 innodb_adaptive_hash_index_parts ，可通过 show engine innodb status 命令查看hash索引使用情况。InnoDB存储引擎使用的哈希函数采用除法散列方式，其冲突机制采用链表方式。 哈希索引只能用来搜索等值的查询，如 SELECT * FROM table WHERE index co=xxx ，对于其他查找类型，如范围查找，是不能使用哈希索引的，可通过 hash searches和non-hash searches 可大概了解使用哈希索引后的效率，默认AHI为开启状态。若发现监视索引查找和维护哈希索引结构的额外开销远远超过了自适应哈希索引带来的性能提升就需要关闭这个功能。 同时在 MySQL 5.7 中自适应哈希索引搜索系统被分区，每个索引都绑定到一个特定的分区，每个分区都由一个单独的latch锁保护，分区由 innodb_adaptive_hash_index_parts 配置选项控制，早期版本中自适应哈希索引搜索系统受到单个latch锁的保护，这可能成为繁重工作负载下的争用点， innodb_adaptive_hash_index_parts 默认情况下为 8 最大设置为 512 。 联合索引 例： where age = 30 and position = &#39;dev&#39; 该语句是不能用到索引的，因为虽然在某一个页里面age和position是排好序的，但跳过name在不同的页相比较age和position是乱序的。 MylSAM存储引擎MylSAM索引文件和数据文件是分离的，即索引是非聚集索引（非聚蔟索引） InnoDB存储引擎 InnoDB 三大特性：自适应哈希索引、双写缓存区、 BufferPool 文件系统的最小单元是块，一个块的大小是 4K ，在文件系统中即使一个文件只有一个字节，但也不得不占 4KB 的磁盘空间。 InnoDB存储引擎的最小存储单元是Page页，页可用于存放数据也可用于存放键值+指针，指针大小在InnoDB源码中设置为 6字节，在B+树中叶子节点存放数据，非叶子节点存放键值+指针，默认一个页的大小是 16382 即 16K 。InnoDB的所有数据文件后缀为 ibd ，其大小始终都是 16K的整倍数。数据表中的数据都是存储在页中，若一行数据大小为1K，则一页可存放16行这样的数据。InnoDB索引文件和数据文件是一个文件，表数据文件本身就是按B+Tree组织的一个索引结构文件。 一个页中不可能所有空间都用于存放数据，它还会存放一些少量的其他字段比如page level，index number等等。 为什么建议InnoDB表必须建主键，并且推荐使用整型的自增主键？若InnoDB表没有设置主键，MySQL会从数据表中选择一列数据都不相等的列作为主键索引，若找不到这样的列，MySQL会创建一个隐藏列来作为主键索引。使用整型作为主键在做比较时效率高很多。之所以用自增主键，若插入数据的主键是无序的，插入时需要对数据索引做平衡之类的操作，插入效率变低。 为什么非主键索引结构叶子节点存储的是主键的索引值？一致性和节省存储空间 InnoDB二级索引结构 全文索引InnoDB也支持全文索引即倒排索引，只对数据类型 char 、 vachar 、 text 支持创建全文索引， MySQL5.6.X 版本开始支持全文索引。但不推荐使用MySQL全文索引，一张表只能有一个全文索引，对中文或非拉丁文分词非常差。 索引的代价空间上每建立一个索引都要为它建立一棵B+树，每一棵B+树的每一个节点都是一个数据页，一个页默认会占用16KB的存储空间，一棵很大的B+树由许多数据页组成会占据很多的存储空间。 时间上每次对表中的数据进行增、删、改操作时，都需要去修改各个B+树索引，而增、删、改操作可能会对节点和记录的排序造成破坏，故存储引擎需要额外的时间进行一些记录移位，页面分裂、页面回收的操作来维护好节点和记录的排序。若建了许多索引，每个索引对应的B+树都要进行相关的维护操作，必然会对性能造成影响。一般一张表6-7个索引以下都能够取得比较好的性能权衡。 前缀索引有时候需要索引很长的字符列，这会让索引变得大且慢，可以使用拟哈希索引，将很长的字符串进行hash运算，最终将hash值存库，还可以使用前缀索引来解决。 在 Varchar 字段上建立索引时，必须指定索引长度，没有必要对全字段建立索引，根据实际文本区分度决定索引长度，索引长度与区分度是一对矛盾体，一般对字符串类型数据，长度为20的索引，区分度会高达90%以上，可以使用 count(distinct left(列名, 索引长度))/count(*) 来确定区分度。 但是前缀索引的缺点很明显，无法使用前缀索引做 ORDER BY 和 GROUP BY ，也无法使用前缀索引做覆盖扫描。 有时候后缀索引也有用途，如找到某个域名的所有电子邮件地址，MSQL原生并不支持反向索引，但是可以把字符串反转后存储，并基于此建立前缀索引，也可以通过触发器或者应用程序自行处理来维护索引。 MySQL索引类型从数据结构角度可分为B+Tree树索引、哈希索引、FULLTEXT索引、用于GIS数据类型创建的SPATIAL索引即R-Tree索引 从物理角度分为聚集索引、非聚集索引 从逻辑角度分为主键索引、普通索引或单列索引、联合索引或多列索引、唯一索引、非唯一索引 密集索引即索引中不仅存储了索引的key还包括数据，MySQL中主键索引即聚集索引才是密集索引。与之相对的是稀疏索引，非聚集索引都是稀疏索引，所有二级索引都是稀疏索引。 三星索引索引将相关的记录放到一起即一个查询相关的索引行是相邻的或者至少相距足够靠近必须扫描的索引片宽度就会缩至最短则获得一星，若索引中的数据顺序和查找中的排列顺序一致则获得二星即排序星；若索引中的列包含了查询中需要的全部列则获得三星即宽索引星； 可以理解为第三颗星比重是50% ，第一颗星为27% ，第二颗星为23% ，所以大部分情况下，会先考虑第一颗星，但会根据业务情况调整这两颗星的优先度。 对于一个查询而言，一个三星索引，可能是其最好的索引，若查询使用三星索引，一次查询通常只需要进行一次磁盘随机读以及一次窄索引片的扫描，因此其响应时间通常比使用一个普通索引的响应时间少几个数量级。","tags":[{"name":"索引","slug":"索引","permalink":"http://example.com/tags/%E7%B4%A2%E5%BC%95/"}],"categories":[{"name":"DB","slug":"DB","permalink":"http://example.com/categories/DB/"},{"name":"索引","slug":"DB/索引","permalink":"http://example.com/categories/DB/%E7%B4%A2%E5%BC%95/"}]},{"title":"分库分表","date":"2021-05-24T05:52:21.000Z","path":"blog/DB/分库分表/分库分表/","text":"中大型项目中，一旦遇到数据量比较大，都知道对数据进行拆分，有垂直拆分和水平拆分两种。 垂直拆分：从业务角度拆分多个库。 水平拆分：同一个业务数据量大，进行水平拆分。Redis集群就是典型的水平分片 常用分片策略 取余\\取模 ： 优点均匀存放数据，缺点扩容非常麻烦 按范围分片 ： 比较好扩容， 数据分布不够均匀 按时间分片 ： 比较容易将热点数据区分出来。 按枚举值分片 ： 例如按地区分片 按目标字段前缀指定进行分区：自定义业务规则分片 水平分片从理论上突破了单机数据量处理的瓶颈，且扩展相对自由，是分库分表的标准解决方案。一般在系统设计阶段就应该根据业务耦合松紧来确定垂直分库、分表方案，在数据量及访问压力不是特别大的情况，首先考虑缓存、读写分离、索引技术等方案。若数据量极大，且持续增长，再考虑水平分库、分表方案。 分库分表缺点虽然数据分片解决了性能、可用性以及单点备份恢复等问题，但是分布式的架构在获得收益的同时，也引入了非常多新的问题。 事务一致性问题：原本单机数据库有很好的事务机制能保证数据一致性，但是分库分表后，由于数据分布在不同库甚至不同服务器，不可避免会产生分布式事务问题 跨节点关联查询问题：没有分库时可很容易进行跨表关联查询，但是在分库后表被分散在不同数据库，无法关联查询。需要将关联查询拆分成多次查询，然后将获得结果拼装 跨节点分页、排序函数：跨节点多库进行查询时 limit分页、 order by排序等问题，就变得比较复杂。需要先在不同分片节点中将数据排序返回，然后将不同分片返回的结果集进行汇总再排序。这时非常容易出现内存崩溃的问题 主键避重问题：由于表中数据同时存在不同数据库中，无法再使用自增主键，某个分区数据库生成的ID无法保证全局唯一，因此需要单独设计全局主键，以避免跨库主键重复问题 公共表处理：参数表、数据字典表等都是数据量较小，变动少，且属于高频联合查询的依赖表。这一类表一般需要在每个数据库中都保存一份，且所有对公共表的操作都要分发到所有的分库去执行 运维工作量：面对散乱的分库分表之后的数据，应用开发工程师和数据库管理员对数据库的操作都变得非常繁重 分库分表时机单表记录达到500W 这个级别，或单表容量达到2GB ，建议进行分库分表。而考虑到分库分表需要对数据进行再平衡，所以若要使用分库分表，就要在系统设计之初就详细考虑好分库分表的方案，这里要分两种情况。 一般对用户数据这类后期增长比较缓慢的数据，一般可按照三年左右的业务量来预估使用人数，按照标准预设好分库分表的方案。 对于业务数据这一类增长快速且稳定的数据，一般则需要按照预估量的两倍左右预设分库分表方案，且由于分库分表后期扩容是非常麻烦的，所以在进行分库分表时，尽量根据情况多分一些表 在设计分库分表方案时，尽量兼顾业务场景和数据分布。在支持业务场景的前提下，尽量保证数据能够分得更均匀。 一旦用到了分库分表，就会表现为对数据查询业务的灵活性有一定的影响，进行排序、分页、聚合等操作，很容易扛不住。尽量在分库分表的同时，再补充设计一个降级方案，如将数据转存一份到ES ，ES可实现更灵活的大数据聚合查询。 常见分库分表组件由于分库分表之后，数据被分散在不同的数据库、服务器。因此对数据的操作就无法通过常规方式完成，且还带来了一系列的问题。 ShardingSphereSharding-JDBC是当当网研发的开源分布式数据库中间件，他是一套开源的分布式数据库中间件解决方案组成的生态圈，它由 Sharding-JDBC 、 Sharding-Proxy 和 Sharding-Sidecar （计划中）这3款相互独立的产品组成。 他们均提供标准化的数据分片、分布式事务和数据库治理功能，可适用于如Java同构、异构语言、容器、云原生等各种多样化的应用场景。 MyCatMyCat基于阿里开源的 Cobar 产品研发，Cobar的稳定性、可靠性、优秀的架构和性能以及众多成熟的使用案例使得MyCat一开始就拥有一个很好的起点。MyCat虽然是从阿里技术体系中出来的，但跟阿里其实没什么关系。 DBLEDBLE该网站包含几个重要产品。其中分布式中间件可以认为是MyCAT的一个增强版，专注于MySQL的集群化管理。另外还有数据传输组件和分布式事务框架组件可供选择。 分库分表方案 hash取模和 range范围方案是分库分表方案中常用的方案；分库分表方案最主要就是路由算法，把路由的key按照指定的算法进行路由存放。 hash取模方案 hash 的方案就是对指定的路由key对分表总数进行取模，可以参考 HashMap 源码。 优点：是可以将数据均匀放到各个分表中，不会出现热点问题。 缺点：是数据迁移和扩容会比较困难。因为若之前分表是4，现在分表变成了8，由于取模基数变化导致之前的数据可能会找不到。要解决这样的问题，就需要将之前的数据重新按照新的取模基数做hash方案把数据进行迁移，放到新规划的分表中。但是对某些不允许停机做数据迁移的业务就会非常痛苦。 range范围方案range方案比较简单，就是把一定范围内的订单，存放到一个表中；如id&#x3D;12放到0表中，id&#x3D;1300万的放到1表中。设计这个方案时就是前期把表的范围设计好。通过id进行路由存放。 优点：有利于将来的扩容，不需要做数据迁移。 缺点：有热点问题。 扩展hash是可以解决数据均匀的问题，range可以解决数据迁移问题，可以将两种方案结合，在一定的范围内数据均匀，每次扩容肯定会先设计好这次扩容的范围大小，只要保证这次的范围内的数据均匀就行了。 可以先定义一个 group组的概念，首先通过范围range定位是哪个group组，然后根据hash方案定位是哪个DB，再根据range方案定位哪个Table。 例如对10进行取模，如果值为【0，1，2，3】就路由到DB_0，【4，5，6】路由到DB_1，【7，8，9】路由到DB_2。1000万以内的id都均匀的分配到DB_0，DB_1，DB_2三个数据库中的Table_0表中。 扩容的时候只需要再设计一个 group02 组就行了。 设计是比较简单的，就3张表，把group，DB，table之间建立好关联关系就行了。 在开发的时候把三张关联数据保存到缓存中。","tags":[{"name":"数据库优化","slug":"数据库优化","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"}],"categories":[{"name":"DB","slug":"DB","permalink":"http://example.com/categories/DB/"},{"name":"分库分表","slug":"DB/分库分表","permalink":"http://example.com/categories/DB/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"}]},{"title":"MySQL事务隔离级别与锁机制","date":"2021-04-24T14:12:21.000Z","path":"blog/DB/mysql/MySQL事务隔离级别与锁机制/","text":"事务基本特征ACID 事务是并发控制的单位，是用户定义的一个操作序列，由一组SQL语句组成的逻辑处理单元，这些操作要么都成功，要么都失败，是一个不可分割的工作单位。 Atomicity原子性：事务中的包含的操作被看做是一个逻辑单元，要么全部成功，要么全部失败 Isolation隔离性：多个用户可对同一个数据并发访问，而不破坏数据的正确性和完整性，并行事务的修改必须与其他并行事务的修改相互独立 Consistency一致性：合法的数据被写入到数据库，否则事务回滚到最初状态 Durability持久性：事务结束后，事务处理的结果必须能够得到固化 四种隔离级别数据库一般都会并发执行多个事务，多个事务可能会并发的对相同的一批数据进行增删改查操作，可能就会导致脏写、脏读、不可重复读、幻读等问题；为了解决多事务并发问题，数据库设计了事务隔离机制、锁机制、MVCC多版本并发控制隔离机制，用一整套机制来解决多事务并发问题。 Read Uncommitted读未提交级别最低，一个事务可读到另外一个事务未提交的数据，事务在读数据的时候并未对数据加锁，在修改数据的时候只对数据增加行级共享锁。 事务1读取某行记录时，事务2也能对这行记录进行读取、更新，因为事务1并未对数据增加任何锁； 当事务2对该记录进行更新时，事务1再次读取该记录，能读到事务2对该记录的修改版本，因为事务2只增加了共享读锁，事务1可以再增加共享读锁读取数据，即使该修改尚未被提交； 事务1更新某行记录时，事务2不能对这行记录做更新，直到事务1结束，因为事务1对数据增加了共享读锁，事务2不能增加排他写锁进行数据的修改 1set tx_isolation=&#x27;Read-Uncommitted&#x27;; Read Committed读已提交在一个事务修改数据过程中，如果事务还没提交，其他事务不能读该数据，事务对当前被读取的数据加行级共享锁且当读到时才加锁，一旦读完该行，立即释放该行级共享锁；事务在更新某数据的瞬间，必须先对其加行级排他锁，直到事务结束才释放。 事务1在读取某行记录的整个过程中，事务2都可以对该行记录进行读取，因为事务1对该行记录增加行级共享锁的情况下，事务2同样可以对该数据增加共享锁来读数据； 事务1读取某行的一瞬间，事务2不能修改该行数据，但只要事务1读取完改行数据，事务2就可以对该行数据进行修改。因为事务1在读取的一瞬间会对数据增加共享锁，任何其他事务都不能对该行数据增加排他锁。但事务1只要读完该行数据，就会释放行级共享锁，一旦锁释放，事务2就可以对数据增加排他锁并修改数据； 事务1更新某行记录时，事务2不能对这行记录做更新，直到事务1结束。因为事务1在更新数据时，会对该行数据增加排他锁，直到事务结束才会释放锁，所以在事务2没有提交之前，事务1都能不对数据增加共享锁进行数据的读取。所以可以解决脏读的现象，但不能解决不可重复读现象。 1set tx_isolation=&#x27;Read-Committed&#x27;; Repeatable Read可重复读事务在读取某数据的瞬间，必须先对其加行级共享锁，直到事务结束才释放；事务在更新某数据的瞬间，必须先对其加行级排他锁，直到事务结束才释放。 事务1在读取某行记录的整个过程中，事务2都可以对该行记录进行读取，因为事务1对该行记录增加行级共享锁的情况下，事务2同样可以对该数据增加共享锁来读数据； 事务1在读取某行记录的整个过程中，事务2都不能修改该行数据，事务1在读取的整个过程会对数据增加共享锁，直到事务提交才会释放锁，所以整个过程中，任何其他事务都不能对该行数据增加排他锁。所以能解决不可重复读的读现象； 事务1更新某行记录时，事务2不能对这行记录做更新，直到事务1结束，事务1在更新数据的时候，会对该行数据增加排他锁，直到事务结束才会释放锁，所以在事务2没有提交之前，事务1都能不对数据增加共享锁进行数据的读取。所以可以解决可重复读的现象，但不能解决幻读现象。若事务1对数据进行修改，事务2也对数据进行修改，此时事务2会被阻塞，直到事务1提交事务，事务1提交事务后，事务2会马上执行完成，但此时事务1只能查到自己更新的数据。事务2也只能查到自己更新的数据，不能查到事务1更新的数据即使事务1提交事务后。 1set tx_isolation=&#x27;Repeatable-Read&#x27;; Serializable串行化可序列化的隔离级别中可以解决幻读，产生幻读的原因是事务在进行范围查询的时候没有增加范围锁所以导致幻读，范围锁**range-locks：给SELECT 的查询中使用一个WHERE子句描述范围加锁。事务在读取数据时，必须先对其加表级共享锁** ，直到事务结束才释放；事务在更新数据时，必须先对其加表级排他锁 ，直到事务结束才释放。 事务1正在读取A表中的记录时，则事务2也能读取A表，但不能对A表做更新、新增、删除，直到事务1结束，因为事务1对表增加了表级共享锁，其他事务只能增加共享锁读取数据，不能进行其他任何操作； 事务1正在更新A表中的记录时，则事务2不能读取A表的任意记录，更不可能对A表做更新、新增、删除，直到事务1结束，事务1对表增加了表级排他锁，其他事务不能对表增加共享锁或排他锁，也就无法进行任何操作； 可序列化解决了脏读、不可重复读、幻读等读现象，但无法读取其它事务已修改但未提交的记录，在当前事务完成之前，其它事务不能修改目前事务已读取的记录，在当前事务完成之前，其它事务所插入的新记录，其索引键值不能在当前事务的任何语句所读取的索引键范围中。 1set tx_isolation=&#x27;Serializable&#x27;; 脏读脏读又称无效数据的读出，在一个事务的处理过程中读到另一个未提的交事务中的数据。 不可重复读在对数据库中的某个数据，一个事务范围内多次查询却返回了不同的数据值与脏读的区别是：不可重复读是读取了前一事务提交的数据 虚读（幻读）事务在操作过程中两次查询，第二次查询的结果包含了第一次查询中未出现的数据或缺少第一次查询中出现的数据，一般解决幻读的方法是增加间隙锁，锁定检锁范围为只读，这样就避免了幻读。 四种事务隔离级别从隔离程度上越来越高，但同时在并发性上也就越来越低。之所以有这么几种隔离级别，就是为了方便开发人员在开发过程中根据业务需要选择最合适的隔离级别。 隔离级别 脏读 不可重复读 幻读 读未提交 可能 可能 可能 读已提交 不可能 可能 可能 可重复读 不可能 不可能 可能 可串行化 不可能 不可能 不可能 默认的事务隔离级别是可重复读，用Spring开发程序时，若不设置隔离级别默认用MySQL设置的隔离级别，若Spring设置了就用已经设置的隔离级别 ，查询和设置当前数据库事务隔离级别： 12show variables like &#x27;tx_isolation&#x27;;set tx_isolation=&#x27;REPEATABLE-READ&#x27;; 锁分类从性能上分为乐观锁，用版本对比来实现和悲观锁，从对数据库操作的类型分，分为读锁和写锁，都属于悲观锁，读锁是共享锁，S锁(Shared）：针对同一份数据，多个读操作可同时进行而互相不影响，写锁是排它锁，X锁(eXclusive）：当前写操作没有完成前，它会阻断其他写锁和读锁，从对数据操作的粒度分，分为表锁、间隙锁和行锁。 表级锁每次操作锁住整张表。开销小，加锁快，不会出现死锁，锁定粒度大，发生锁冲突的概率最高，并发度最低；一般用在整表数据迁移的场景。 表锁相关操作： 123456-- 手动增加表锁lock tables mylock write, employees read;-- 查看表上加过的锁show open tables;-- 删除表锁unlock tables; 行级锁每次操作锁住一行数据。开销大，加锁慢，会出现死锁，锁定粒度最小，发生锁冲突的概率最低，并发度最高。 InnoDB支持事务和行级锁，**MylSAM两者皆不支持。MyISAM在执行查询语句SELECT前，会自动给涉及的所有表加读锁，在执行update、insert、delete操作会自动给涉及的表加写锁**。 InnoDB在非串行隔离级别下执行查询语句**SELECT时，不会加锁，但update、insert、delete操作会加行锁。简而言之，就是读锁会阻塞写，但是不会阻塞读。而写锁则会把读和写都阻塞** 对MyISAM表的读操作，即加读锁，不会阻塞其他进程对同一表的读请求，但会阻赛对同一表的写请求，只有当，读锁释放后，才会执行其它进程的写操作。 对MylSAM表的写操作，即加写锁，会阻塞其他进程对同一表的读和写操作，只有当写锁释放后，才会执行其它进程的读写操作。 行锁分析通过检查InnoDB_row_lock状态变量来分析系统上的行锁的争夺情况 1show status like &#x27;innodb_row_lock%&#x27;; Innodb_row_lock_current_waits：当前正在等待锁的数量 Innodb_row_lock_time：从系统启动到现在锁定总时间长度 Innodb_row_lock_time_avg：每次等待平均时间 Innodb_row_lock_time_max：从系统启动到现在等待最长的一次所花时间 Innodb_row_lock_waits：系统启动后到现在总共等待的次数 当等待次数很高，且每次等待时长也不小时，就需要分析系统中为什么会有如此多的等待，然后根据分析结果着手制定优化计划 间隙锁锁的就是两个值之间的空隙，间隙锁在某些情况下可解决幻读问题，间隙锁在可重复读隔离级别下才会生效。 1select * from account; 该数据的间隙有id为**(2, 10)，(10, 20)，(20, 正无穷)**这三个区间，全都是开区间；在Session1下执行： 1update account set name = &#x27;eleven11&#x27; where id &gt; 8 and id &lt;18; 则其他Session没法在这个范围所包含的所有行记录，包括间隙行记录，以及行记录所在的间隙里插入或修改任何数据，即**id在(3,20]区间都无法修改插入数据，这里的(3,20]叫做临键锁**； 若上面例子中**id &lt; 25，则相当于整个表都被锁住了，无法再更新或插入任何数据**。 临键锁Next-Key Locks是行锁与间隙锁的组合。 无索引行锁会升级为表锁锁主要是加在索引上，如果对非索引字段更新，行锁可能会变表锁，InnoDB的行锁是针对索引加的锁，不是针对记录加的锁。且该索引不能失效，否则都会从行锁升级为表锁。 锁定某一行可用**lock in share mode加共享锁，用for update**加排它锁： 1234-- 加排它锁，其他session只能读这行数据，修改则会被阻塞，直到锁定行的session提交select * from employees where id = 1 for update;-- 加共享锁select * from employees where id = 1 lock in share mode; Innodb存储引擎由于实现了行级锁定，虽然在锁定机制的实现方面所带来的性能损耗可能比表级锁更高，但在整体并发处理能力方面要远远优于MyISAM的表级锁。当系统并发量高时，InnoDB整体性能和MyISAM相比会有比较明显的优势。 但InnoDB的行级锁同样也有其脆弱的一面，当使用不当时，可能会让Innodb整体性能表现不仅不能比MyISAM高，甚至可能会更差。 查看INFORMATION_SCHEMA系统库锁相关数据表12345678910-- 查看事务select * from INFORMATION_SCHEMA.INNODB_TRX;-- 查看锁select * from INFORMATION_SCHEMA.INNODB_LOCKS;-- 查看锁等待select * from INFORMATION_SCHEMA.INNODB_LOCK_WAITS;-- 释放锁，trx_mysql_thread_id可以从INNODB_TRX表里查看到kill trx_mysql_thread_id;-- 查看锁等待详细信息show engine innodb status; 死锁1234567891011set tx_isolation=&#x27;repeatable-read&#x27;;-- Session_1执行select * from account where id = 1 for update;-- Session_2执行：select * from account where id = 2 for update;-- Session_1执行：select * from account where id = 2 for update;-- Session_2执行：select * from account where id = 1 for update;-- 查看近期死锁日志信息：show engine innodb status; 大多数情况mysql可以自动检测死锁并回滚产生死锁的那个事务，但是有些情况mysql没法自动检测死锁。 优化 尽可能让所有数据检索都通过索引来完成，避免无索引行锁升级为表锁 合理设计索引，尽量缩小锁的范围 尽可能减少检索条件范围，避免间隙锁 尽量控制事务大小，减少锁定资源量和时间长度，涉及事务加锁的sql尽量放在事务最后执行 尽可能低级别事务隔离 示例数据123456789101112CREATE TABLE `account` ( `id` INT (11) NOT NULL AUTO_INCREMENT, `name` VARCHAR (20) DEFAULT NULL, `balance` VARCHAR (20) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE = InnoDb DEFAULT CHARSET = utf8;-- 插入数据INSERT INTO`account` (`id`, `name`, `balance`) VALUES (&#x27;1&#x27;, &#x27;zhangsan&#x27;, 800);INSERT INTO`account` (`id`, `name`, `balance`) VALUES (&#x27;2&#x27;, &#x27;lisi&#x27;, 3000);INSERT INTO`account` (`id`, `name`, `balance`) VALUES (&#x27;10&#x27;, &#x27;wanger&#x27;, 2000);INSERT INTO`account` (`id`, `name`, `balance`) VALUES (&#x27;20&#x27;, &#x27;mazi&#x27;, 1000);","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/tags/MySQL/"}],"categories":[{"name":"DB","slug":"DB","permalink":"http://example.com/categories/DB/"},{"name":"mysql","slug":"DB/mysql","permalink":"http://example.com/categories/DB/mysql/"}]},{"title":"MongoDB基础","date":"2021-04-24T14:12:21.000Z","path":"blog/DB/MongoDB/MongoDB基础/","text":"MongoDB的安装和启动，MongoDB启动默认使用**/data/db路径作为数据存放路径，也可通过--dbpath参数指定其他路径，若未创建则启动报错，通过--auth参数以授权模式启动，通过--logpath**参数设置日志文件存储路径。 MongoDB基于安全性考虑，默认安装后只会绑定**本地回环IP即127.0.0.1，可通过启动服务时--bind_ip绑定IP**。绑定后登陆时也需要通过该IP登陆。 12345678910111213wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-rhel70-4.4.2.tgztar -xvzf mongodb-linux-x86_64-rhel70-4.4.2.tgzmkdir -p /data/db # 该路径是MongoDB默认的数据存放路径# --auth以授权模式启动，--logpath指定日志文件，--dbpath指定数据存放路径，若省略默认使用/data/db路径bin/mongod --auth --logpath /data/db/logpath/output --dbpath /data/db --bind_ip 192.168.109.200 --fork# 登陆 若是本机--host和--port可省略bin/mongo -host 192.168.109.200 -u eleven# 设置密码，登陆mongo后use admin # 切换数据库到admindb.createUser(&#123;user: &quot;eleven&quot;, pwd: &quot;eleven&quot;, roles: [&quot;root&quot;]&#125;) # 创建用户show users # 查看所有用户信息db.shutdownServer() # 停掉服务exit # 退出mongo MongoDB基本操作writeConcern定义了本次文档创建操作的安全写级别， 安全写级别用来判断一次数据库写入操作是否成功，安全写级别越高，丢失数据的风险就越低，但写入操作延迟也可能更高。**writeConcern决定一个写操作落到多少个节点上才算成功**。 发起写操作的程序将阻塞到写操作到达指定的节点数为止： 0：发起写操作，不关心是否成功 1 集群中最大数据节点数：写操作需要被复制到指定节点数才算成功 majority：写操作需要被复制到大多数节点上才算成功，过半机制 插入文档时若没有显示指定主键，MongoDB将默认创建一个主键，字段固定为**_id，ObjectId()可快速生成12字节id作为主键，ObjectId前四个字节代表主键生成时间，精确到秒。主键ID在客户端驱动生成，一定程度上代表了顺序性但不保证顺序性， 可通过ObjectId(&quot;id值&quot;).getTimestamp()**获取创建时间。 1234# insertOne和insertMany命令不支持explain命令db.collection.insertMany([&#123;&lt;JSON对象1&gt;&#125;,&#123;&lt;JSON对象2&gt;&#125;],&#123;writeConcern: 安全级别,ordered: true/false&#125;) # 批量添加文档db.collection.insert(&lt;JSON对象&gt;, &#123;writeConcern: 安全级别&#125;) # 添加单个文档db.collection.insertOne(&lt;JSON对象&gt;, &#123;writeConcern: 安全级别&#125;) # 添加单个文档 ordered决定是否按顺序写入，顺序写入时，一旦遇到错误，便会退出，剩余的文档无论正确与否，都不会写入，乱序写入，则只要文档可正确写入，不管前面的文档是否是错误的文档。 123456789db.collection.find(&#123;&#125;) # 查询所有的文档 db.collection.find(&#123;&#125;).pretty() # 返回格式化后的文档db.collection.find(&#123;qty:0, status:&quot;D&quot;&#125;) # 精准等值查询db.collection.find(&#123;&quot;size.uom&quot;: &quot;in&quot;&#125;) # 嵌套对象精准查询# 返回指定字段，默认会返回_id字段，同样可以通过指定_id:0，剩余字段不能混合指定db.collection.find(&#123;&#125;, &#123;item: 1, status: 1&#125;)# and和or条件查询，以及$in，$nin，$existsdb.collection.find(&#123;$and:[&#123;&quot;qty&quot;:0&#125;,&#123;&quot;status&quot;:&quot;A&quot;&#125;]&#125;).pretty()db.collection.find(&#123;$or:[&#123;&quot;qty&quot;:0&#125;,&#123;&quot;status&quot;:&quot;A&quot;&#125;]&#125;).pretty() 复合主键，若字段顺序变换即使内容完全一致，也会当做不同的对象被创建 1db.demeDoc.insert(&#123;_id: &#123;product_name: 1, product_type: 2&#125;, supplierId: &quot;001&quot;, create_Time: new Date()&#125;) 逻辑操作符匹配 $not：匹配筛选条件不成立的文档 $and：匹配多个筛选条件同时满足的文档 $or：匹配至少一个筛选条件成立的文档 $nor：匹配多个筛选条件全部不满足的文档 12345db.members.find(&#123;points: &#123;$not: &#123; $lt: 100&#125;&#125;&#125;);db.members.find(&#123;$and: [&#123;nickName:&#123;$eq : &quot;曹操&quot;&#125;&#125;, &#123;points:&#123;$gt: 1000&#125;&#125;]&#125;);db.members.find(&#123;nickName:&#123;$eq: &quot;曹操&quot;&#125;, points:&#123;$gt: 1000&#125;&#125;); # 当作用在不同字段上可省略 $anddb.members.find(&#123;points:&#123;$gte:1000, $lte:2000&#125;&#125;); # 当作用在同一字段时可简化db.members.find(&#123;$or: [&#123;nickName:&#123;$eq : &quot;曹操&quot;&#125;&#125;, &#123;points:&#123;$gt: 1000&#125;&#125;]&#125;); 默认**count()不考虑skip和limit效果，若希望考虑limit和skip，需要设置为true。 分布式环境下count不保证数据绝对正确。当同时应用sort，skip，limit时，应用顺序为sort，skip，limit。可使用$slice返回数组中部分元素，可使用$elementMatch进行数组元素匹配**。 12345db.members.find().skip(1).limit(10).count();db.members.find().skip(1).limit(10).count(true);db.members.find().sort(&#123;field: 1/-1&#125;); # 排序，1：顺序，-1：逆序db.members.find(&#123;&#125;,&#123;_id:0, nickName:1, points:1, address: &#123;$slice:1&#125;&#125;); # 返回第一个元素db.members.find(&#123;&#125;,&#123;_id:0, nickName:1, points:1, tag: &#123;$elemMatch: &#123;$eq: &quot;00&quot;&#125;&#125;&#125;); 投影设置：{field: &lt;1：1表示需要返回，0：表示不需要返回，只能为0或1，非主键字段不能同时混选0或1&gt;} 1db.members.find(&#123;&#125;,&#123;_id:0, nickName:1, points:1&#125;) 更新操作，**updateOne/updateMany**方法要求更新条件部分必须具有以下之一，否则将报错 $set 给符合条件的文档新增一个字段，有该字段则修改其值 $unset 给符合条件的文档，删除一个字段 $push： 增加一个对象到数组底部 $pop：从数组底部删除一个对象 $pull：如果匹配指定的值，从数组中删除相应的对象 $pullAll：如果匹配任意的值，从数据中删除相应的对象 $addToSet：如果不存在则增加一个值到数组 $rename：重命名字段 $inc：加减字段值 $mul：相乘字段值 $min：采用最小值 $max：次用最大值 默认只会更新第一个匹配的值，可通过设置options **&#123;multi: true&#125;**设置匹配多个文档并更新 12345678# &lt;query&gt; 定义了更新时的筛选条件# &lt;update&gt; 文档提供了更新内容# &lt;options&gt; 声明了一些更新操作的参数db.collection.update(&lt;query&gt;,&lt;update&gt;,&lt;options&gt;)# 默认删除所有满足条件的文档，可设定参数&#123;justOne:true&#125;，只删除满足条件的第一条文档db.collection.remove(&lt;query&gt;,&lt;options&gt;)# 删除集合，不但删除集合内的所有文档，且删除集合的索引db.collection.drop(&#123;writeConcern:&lt;doc&gt;&#125;) 聚合操作聚合表达式 **$&lt;field&gt;.&lt;sub_field&gt;**：获取字段信息，sub_field字段可0个或多个 **$literal: &lt;value&gt;**：常量表达式 **$$&lt;variable&gt;**：系统变量表达式 **$$CURRENT**：指示管道中当前操作的文档 聚合管道阶段筛选管道操作和其他管道操作配合时候时，尽量放到开始阶段，可减少后续管道操作符要操作的文档数，提升效率 $project：对输入文档进行再次投影 $match：对输入文档进行筛选 $limit：筛选出管道内前 N 篇文档 $skip：跳过管道内前N篇文档 $unwind：展开输入文档中的数组字段 $sort：对输入文档进行排序 $lookup：对输入文档进行查询操作 $group：对输入文档进行分组 $out：对管道中的文档输出 1234567891011121314db.userInfo.aggregate(&#123;$project:&#123;name:&quot;$nickName&quot;&#125;&#125;) # 将原始字段投影成指定名称db.userInfo.aggregate(&#123;$project:&#123; name:&quot;$nickName&quot;,_id:0,age:1&#125;&#125;); # 也可剔除不需要的字段db.userInfo.aggregate(&#123;$match:&#123;nickName:&quot;lisi&quot;&#125;&#125;); # 文档筛选db.userInfo.aggregate([&#123;$match:&#123;$and:[&#123;age:&#123;$gte:20&#125;&#125;,&#123;nickName:&#123;$eq:&quot;lisi&quot;&#125;&#125;]&#125;&#125;, &#123;$project: &#123;_id:0, name: &quot;$nickName&quot;, age:1&#125;&#125;]);db.userInfo.aggregate(&#123;$limit:1&#125;);db.userInfo.aggregate(&#123;$skip:1&#125;);db.userInfo.aggregate(&#123;$unwind:&#123;path:&quot;$tags&quot;&#125;&#125;); # tags是一个数组db.userInfo.aggregate(&#123;$unwind:&#123;path:&quot;$tags&quot;,includeArrayIndex:&quot;arrIndex&quot;&#125;&#125;); # 赋值给指定的字段# 展开时保留空数组，或者不存在数组字段的文档db.userInfo.aggregate(&#123;$unwind:&#123;path: &quot;$tags&quot;,includeArrayIndex:&quot;arrIndex&quot;,preserveNullAndEmptyArrays:true&#125;&#125;);# 对文档进行排序：1正序，-1倒序 db.userInfo.aggregate(&#123;$sort:&#123;age:-1&#125;&#125;);# 单一字段值进行关联查询db.accountDetail.aggregate(&#123;$lookup:&#123; from: &quot;需要关联的文档&quot;,localField: &quot;本地字段&quot;，foreignField: &quot;外部文档关联字段&quot;，as &quot;作为新的字段，添加到文档中&quot;&#125;); 索引索引默认名称是索引键和索引中每个键的方向即1或-1的连接，使用下划线作为分隔符， 也可以通过指定name来自定义索引名称； 12345678db.collection.createIndex(&lt;keys&gt;, &lt;options&gt;) # 创建索引db.members.createIndex(&#123;name:1&#125;，&#123;name: &quot;index_name&quot;&#125;);db.members.getIndexes(); # 查询集合中已经存在的索引db.members.createIndex(&#123; name:1,age:-1&#125;); # 复合索引，按name升序排age降序db.members.createIndex(&#123;age:1&#125;,&#123;unique:true&#125;); # 唯一性索引db.sparsedemo.createIndex(&#123;name:1&#125;,&#123;unique:true ,sparse:true&#125;); # 稀疏索引# 日期字段或包含日期元素的数组字段，可使用设定生存时间的索引，来自动删除字段值超过生存时间的文档db.members.createIndex(&#123;create_time:1&#125;,&#123;expireAfterSeconds:30&#125;); 复制集MongoDB复制集主要意义在于实现服务高可用，类似于Redis哨兵模式，数据写入Primary主节点时将数据复制到另一个Secondary副本节点上，主节点发生故障时自动选举出一个新的替代节点。实现高可用的同时，复制集还有如下作用 数据分发：将数据从一个区域复制到另一个区域，减少另一个区域的读延迟 读写分离：不同类型的压力分别在不同的节点上执行 异地容灾：在数据中心故障时快速切换到异地 典型的复制集由三个或三个以上具有投票权的节点组成，其中一个**Primary主节点接收写入操作，读操作和选举时投票，两个或多个Secondary从节点复制主节点上的新数据和选举时投票**。 当一个修改操作到达主节点时，它对数据的操作将被记录下来，这些记录称为**oplog，从节点通过从主节点上不断获取新进入主节点的oplog，并在自己的数据上回放**，以此保持跟主节点的数据一致。 具有投票权的节点之间两两互相发送心跳，当5次心跳未收到时判断为节点失联，若主节点失联，从节点会发起选举，选出新的主节点，若从节点失联则不会产生新的选举，选举基于**RAFT一致性算法实现，选举成功的必要条件是大多数投票节点存活，复制集中最多可有50个节点，但具有投票权的节点最多7个**。 整个集群必须有大多数节点存活，被选举为主节点的节点必须能够与多数节点建立连接，具有较新的oplog，具有较高优先级。复制集节点有以下的选配项： **v**：是否具有投票权，有则参与投票 **priority**：优先级，优先级越高的节点越优先成为主节点。优先级为0的节点无法成为主节点,默认值为1。 **hidden**：隐藏，复制数据，但对应用不可见。隐藏节点可具有投票权，但优先级必须为0 **slaveDelay**：延迟，复制n秒之前的数据，保持与主节点的时间差 **buildIndexes**：从节点不建立索引 mongod -f /data/db/mongod.conf，默认情况下非主节点不允许读数据，可通过执行**rs.secondaryOk()**开启读权限 12345678910111213systemLog: destination: file path: /data/db/mongod.log logAppend: truestorage: dbPath: /data/db1net: bindIp: 0.0.0.0 port: 28017replication: replSetName: rs0processManagement: fork: true 分片集群 mongos路由节点： 提供集群单一入口，转发应用端请求，选择合适的数据节点进行读写，合并多个数据节点的返回。无状态，建议**mongos**节点集群部署以提供高可用性。客户请求应发给mongos而不是分片服务器，当查询包含分片键时，mongos将查询发送到指定分片，否则mongos将查询发送到所有分片，并汇总所有查询结果。 配置节点: 普通的mongod进程， 建议以复制集部署，提供高可用，提供集群元数据存储分片数据分布的数据。主节点故障时配置服务器进入只读模式，只读模式下数据段分裂和集群平衡都不可执行。整个复制集故障时，分片集群不可用。 数据节点：以复制集为单位，横向扩展最大1024分片，分片之间数据不重复，所有数据在一起才可以完整工作。 数据段的分裂，当数据段尺寸过大，或包含过多文档时，触发数据段分裂，只有新增、更新文档时才可能自动触发数据段分裂，数据段分裂通过更新元数据来实现 集群的平衡，后台运行的平衡器负责监视和调整集群的平衡，当最大和最小分片之间的数据段数量相差过大时触发 ，集群中添加或移除分片时也会触发 MongoDB分片集群特点：应用全透明，数据自动均衡，动态扩容，无需下线","tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"http://example.com/tags/MongoDB/"}],"categories":[{"name":"DB","slug":"DB","permalink":"http://example.com/categories/DB/"},{"name":"MongoDB","slug":"DB/MongoDB","permalink":"http://example.com/categories/DB/MongoDB/"}]},{"title":"MySQL内部组件结构","date":"2021-04-24T13:52:21.000Z","path":"blog/DB/mysql/MySQL内部组件结构/","text":"MySQL大体来说可以分为Server层和存储引擎层两部分 Server层主要包括连接器、查询缓存、分析器、优化器、执行器等，涵盖大多数核心服务功能，以及所有的内置函数，如日期、时间、数学和加密函数等，所有跨存储引擎的功能都在这一层实现，如存储过程、触发器、视图等。 连接器MySQl有navicat、mysql front、jdbc、SQLyog等非常丰富的客户端，客户端要发起通信都必须先跟Server端建立通信连接，而建立连接的工作由连接器来完成。连接器负责跟客户端建立连接、获取权限、维持和管理连接。 1mysql ‐h host[数据库地址] ‐u root[用户] ‐p root[密码] ‐P 3306 连接器会到权限表里面查出拥有的权限，连接里面的权限判断逻辑，将依赖于此时读到的权限。一个用户成功建立连接后，即使管理员账号对该用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，新建的连接才会使用新的权限设置。用户的权限表在系统表空间的mysql的user表中。 12345678910-- 创建新用户CREATE USER &#x27;test&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;test&#x27;;-- 赋权限,%表示所有(host)grant all privileges on *.* to &#x27;test&#x27;@&#x27;%&#x27;;-- 刷新数据库flush privileges; -- (设置用户名密码)set password for &#x27;test&#x27;@&#x27;localhost&#x27; = password(&#x27;test&#x27;);-- 查看当前用户的权限show grants for &#x27;test&#x27;@&#x27;%&#x27;; 连接完成后，若没有后续动作，连接将处于空闲状态，可在**show processlist**命令中看到它。其中的Command列显示为Sleep表示空闲连接。 1234-- 查询连接列表show processlist;-- 关闭具体的连接kill 3; 客户端如果长时间不发送command到Server端，连接器就会自动将它断开。该时间由参数**wait_timeout控制，默认8小时**。 1234-- 查看wait_timeoutshow global variables like &#x27;wait_timeout&#x27;;-- 设置全局服务器关闭非交互连接之前等待活动的秒数set global wait_timeout=28800; 长连接指连接成功后，若客户端持续有请求，则一直使用同一个连接。短连接则是每次执行完很少的几次查询就断开连接。大多数用的都是长连接，把连接放在Pool内进行管理，但长连接有些时候会导致MySQL占用内存涨得特别快，因为在执行过程中临时使用的内存是管理在连接对象里面的，这些资源会在连接断开的时候才释放。 若长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是MySQL异常重启了。可以定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后断开连接，要查询再重连。若用的是MySQL 5.7或更新版本，可在每次执行一个比较大的操作后，通过执行mysql_reset_connection来重新初始化连接资源。该过程不需要重连和重新做权限验证，但会将连接恢复到刚刚创建完时的状态。 Store层存储引擎层负责数据的存储和提取。插件式的架构模式，支持InnoDB、MyISAM、Memory等多个存储引擎。InnoDB从**MySQL5.5.5版本开始成为默认存储引擎，是最常用的存储引擎，若在create table**时不指定表的存储引擎类型，默认会设置存储引擎为InnoDB。 bin-log归档binlog是Server层实现的二进制日志，会记录cud操作。Binlog在MySQL的Server层实现是引擎共用的，是逻辑日志，记录的是一条语句的原始逻辑，不限大小，追加写入，不会覆盖以前的日志；若误删了数据库,可使用binlog进行归档，要使用binlog归档，首先得记录binlog，因此需要先开启MySQL的binlog功能。 binlog格式有3种**statement，row，mixed**； 从bin‐log恢复数据 123456# 恢复全部数据/usr/local/mysql/bin/mysqlbinlog --no-defaults /usr/local/mysql/data/binlog/mysql-bin.000001|mysql -uroot -p eleven# 恢复指定位置数据/usr/local/mysql/bin/mysqlbinlog --no-defaults --start-position=&quot;408&quot; --stop-position=&quot;731&quot; /usr/local/mysql/data/binlog/mysql-bin.000001|mysql -uroot -p eleven# 恢复指定时间段数据/usr/local/mysql/bin/mysqlbinlog --no-defaults /usr/local/mysql/data/binlog/mysql-bin.000001 --stop-date=&quot;2018-03-02 12:00:00&quot; --start-date=&quot;2019-03-02 11:55:00&quot;|mysql -uroot -p eleven","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/tags/MySQL/"}],"categories":[{"name":"DB","slug":"DB","permalink":"http://example.com/categories/DB/"},{"name":"mysql","slug":"DB/mysql","permalink":"http://example.com/categories/DB/mysql/"}]},{"title":"MySQL主从架构","date":"2021-04-24T11:52:21.000Z","path":"blog/DB/mysql/MySQL主从架构/","text":"实际生产中，往往数据量会极为庞大，并且数据的安全性要求也更高，生产环境中MySQL必须是要搭建一套主从复制架构，同时可基于一些工具实现高可用架构。在此基础上则可基于一些中间件实现读写分离架构。若数据量非常大，还必须可实现分库分表的架构。 通过搭建MySQL主从集群可缓解MySQL数据存储及访问压力，搭建主从集群时，双方MySQL必须版本一致，至少主服务版本低于从服务，且两节点间时间需要同步。 数据安全：给主服务增加一个数据备份，可搭建主从架构或基于主从架构搭建互主架构 读写分离：读多写少的情况，主服务访问压力过大时，可将数据读请求转为由从服务来分担，主服务只负责数据写入请求 故障转移：当MySQL主服务宕机后可由一台从服务切换成为主服务，继续提供数据读写功能 MySQL主从架构一般都是通过 binlog日志文件来进行的，即在主服务上打开binlog 记录每一步数据库操作，从服务上会有一个 IO线程，负责跟主服务建立一个 TCP连接请求主服务将 binlog 传输过来。且主库上会有一个 IO dump线程，负责通过该 TCP 连接把 Binlog 日志传输给从库IO线程。从服务IO线程会把读取到的 binlog 日志数据写入自己的 relay日志文件中。然后从服务上另外一个SQL线程读取relay日志内容进行操作重演，达到还原数据的目的。通常对MySQL做的读写分离配置必须基于主从架构来搭建。 MySQL的 Binlog 不光可用于主从同步，还可用于缓存数据同步等场景。如 Canal ，可模拟一个Slave节点向MySQL发起Binlog同步，然后将数据落到Redis、Kafka等其他组件，实现数据实时流转。 主从搭建主节点配置对于主节点的配置文件 my.cnf 中，主要是添加打开 binlog 日志，以及指定 server-id ，配置好后 service mysqld restart 重启MySQL服务。 123456789101112131415161718192021222324252627282930313233[mysqld]# 服务节点的唯一标识，需要给集群中的每个服务分配一个单独的IDserver-id=47# 打开Binlog日志记录，并指定文件名log_bin=master-bin# Binlog日志文件log_bin-index=master-bin.indexskip-name-resolve# 设置连接端口port=3306# 设置mysql的安装目录basedir=/usr/local/mysql# 设置mysql数据库的数据的存放目录datadir=/usr/local/mysql/mysql-files# 允许最大连接数max_connections=200# 允许连接失败的次数。max_connect_errors=10# 服务端使用的字符集默认为UTF8character-set-server=utf8# 创建新表时将使用的默认存储引擎default-storage-engine=INNODB# 默认使用mysql_native_password插件认证default_authentication_plugin=mysql_native_password# 需要同步的二进制数据库名binlog-do-db=masterdemo# 只保留7天的二进制日志，以防磁盘被日志占满(可选)expire-logs-days=7# 不备份的数据库binlog-ignore-db=information_schemabinlog-ignore-db=performation_schemabinlog-ignore-db=sys 给root用户分配一个 replication slave 的权限，然后通过 show master status 命令查看主节点同步状态。 123456# 登录主数据库mysql -u root -pGRANT REPLICATION SLAVE ON *.* TO &#x27;root&#x27;@&#x27;%&#x27;;flush privileges;# 查看主节点同步状态：show master status; File 和 Position 表示当前日志 binlog 文件和文件中的索引。 Binlog_Do_DB 表示需要记录binlog文件的库， Binlog_Ignore_DB 不需要记录binlog文件的库，若没有进行配置，则表示针对全库记录日志。 开启binlog 后数据库中所有操作都会被记录到 datadir 当中，以一组轮询文件的方式循环记录。上面指令查到的 File 和 Position 就是当前日志文件和位置，配置从服务时需要通过 File 和 Position 通知从服务从哪个地方开始记录 binlog 。 从节点配置从服务同样需要配置服务节点的唯一标识 server-id ，且需要打开 bin-log 日志记录，且需要打开 relay-log 日志。 12345678910111213141516171819202122232425262728293031323334[mysqld]# 主库和从库需要不一致server-id=48# 打开MySQL中继日志relay-log-index=slave-relay-bin.indexrelay-log=slave-relay-bin# 打开从服务二进制日志log-bin=mysql-bin# 使得更新的数据写进二进制日志中log-slave-updates=1# 设置3306端口port=3306# 设置mysql的安装目录basedir=/usr/local/mysql# 设置mysql数据库的数据的存放目录datadir=/usr/local/mysql/mysql-files# 允许最大连接数max_connections=200# 允许连接失败的次数。max_connect_errors=10# 服务端使用的字符集默认为UTF8character-set-server=utf8# 创建新表时将使用的默认存储引擎default-storage-engine=INNODB# 默认使用mysql_native_password插件认证default_authentication_plugin=mysql_native_password# 若salve库名称与master库名相同，使用本配置replicate-do-db = masterdemo # 若master库名[mastdemo]与salve库名[mastdemo01]不同，使用以下配置[需要做映射]replicate-rewrite-db = masterdemo -&gt; masterdemo01# 若不是要全部同步[默认全部同步]，则指定需要同步的表replicate-wild-do-table=masterdemo01.t_dictreplicate-wild-do-table=masterdemo01.t_num 启动从服务设置其主节点同步状态， CHANGE MASTER 指令中需要指定的 MASTER_LOG_FILE 和 MASTER_LOG_POS 必须与主服务中查到的保持一致。且后续若要检查主从架构是否成功，也可通过检查主服务与从服务之间File和Position两个属性是否一致。 123456789101112131415#登录从服务mysql -u root -p;#设置同步主节点：CHANGE MASTER TOMASTER_HOST=&#x27;192.168.232.128&#x27;,MASTER_PORT=3306,MASTER_USER=&#x27;root&#x27;,MASTER_PASSWORD=&#x27;root&#x27;,MASTER_LOG_FILE=&#x27;master-bin.000008&#x27;,MASTER_LOG_POS=154GET_MASTER_PUBLIC_KEY=1;# 开启slavestart slave;# 查看主从同步状态，或者用show slave status \\G;这样查看比较简洁show slave status; 主从架构可能失败，若在 slave从服务上查看slave状态，发现 Slave_SQL_Running=no 表示主从同步失败。这可能因为在从数据库进行了写操作，与同步过来的SQL操作冲突了，也可能 slave从服务重启后有事务回滚了。 读写分离主从集群是单向的只能从主服务同步到从服务，而从服务的数据表更新无法同步到主服务。为了保证数据一致，通常需要保证数据只在主服务上写，而从服务只进行数据读取。但MySQL主从本身无法提供读写分离服务，需要由业务自己来实现。 需要限制用户写数据，可在从服务中将 read_only 参数的值设为 1 ，set global read_only=1;可限制用户写入数据。但该属性有两个需要注意的地方： read_only=1 设置只读模式，不影响slave同步复制功能 read_only=1 设置的只读模式， 限定的是普通用户进行数据修改的操作，但不限定具有super权限的用户的数据修改操作。 若需限定super权限的用户写数据可设置 super_read_only=0 。若想连super权限用户的写操作也禁止使用 flush tables with read lock; ，但该设置会阻止主从同步复制。 其他集群方式若想进一步提高整个集群的读能力，可扩展出一主多从，为了减轻主节点进行数据同步的压力，可继续扩展出多级从的主从集群。为了提高整个集群的高可用能力，可扩展出多主集群。 也可扩展出互为主从的互主集群甚至是环形的主从集群，实现MySQL多活部署。搭建互主集群只需要按照主从方式，且在主服务上打开一个slave进程，且指向slave节点binlog当前文件地址和位置。 传统的Binlog方式搭建集群是基于日志记录点的方式来进行主从同步，还可通过GTID搭建方式搭建主从同步， GTID本质也是基于Binlog来实现的主从同步，GTID是基于一个全局事务ID来标识同步进度。该GTID全局事务ID是一个全局唯一且趋势递增的分布式ID策略。 GTID搭建方式是从MySQL5.6版本引入，即用到上面 Executed_Grid_Set 列，首先从服务器会告诉主服务器已经在从服务器执行完了哪些事务的GTID值，主库会把所有没有在从库上执行的事务，发送到从库上进行执行，且使用 GTID 复制可保证同一个事务只在指定从库上执行一次，可避免由于偏移量问题造成数据不一致。 1234567891011# 主节点my.cnf文件中添加如下配置gtid_mode=onenforce_gtid_consistency=onlog_bin=onserver_id=1binlog_format=row# 从节点my.cnf文件中添加如下配置gtid_mode=onenforce_gtid_consistency=onlog_slave_updates=1server_id=2 集群扩容若集群已运行一段时间，这时若要扩展新的从节点，之前的数据没办法从binlog来恢复。这时在扩展新的slave节点时，需要增加一个数据复制的操作。使用mysql的bin目录下的 mysqldump 工具生成数据备份文件。 12345# 在主库生成数据备份文件mysqldump -u root -p --all-databases &gt; backup.sql# 从库上将该文件导入即可mysql -u root -p &lt; backup.sql 延迟问题主从复制之间会有延迟，在做了读写分离后会更容易体现出来。即数据往主服务写，而读数据在从服务读。主从复制延迟可能造成刚插入了数据但查不到，大型集群中会很容易出现。 出现这个问题的根本在于，面向业务的主服务数据都是多线程并发写入的，而从服务是单个线程慢慢拉取binlog ，这中间会有效率差。所以解决这个问题的关键是要让从服务也用多线程并行复制binlog数据。MySQL5.7开始支持并行复制。可在从服务上设置 slave_parallel_workers 为一个大于0 的数，然后把 slave_parallel_type 设置为 LOGICAL_CLOCK 。 半同步赋值MySQL主从集群默认采用异步复制机制。主服务在执行用户提交的事务后写入binlog日志，然后给客户端返回成功响应，而binlog会由一个dump线程异步发送给Slave从服务。 由于发送binlog过程是异步的，主服务在向客户端反馈执行结果时，不知道binlog是否同步成功。若此时主服务宕机，而从服务还没有备份到新执行的binlog可能会丢数据。这就要靠MySQL的半同步复制机制来保证数据安全。 半同步复制机制是一种介于异步复制和全同步复制之前的机制，主库在执行完客户端提交的事务后，并不是立即返回客户端响应，而是等待至少一个从库接收并写到 relay log 中才返回给客户端，MySQL在等待确认时默认等待 10s ，若超过10s没有收到ack则会降级成为异步复制。 半同步复制相比异步复制，能够有效的提高数据的安全性，但这种安全性不是绝对的，其只保证事务提交后的binlog至少传输到了一个从库，不保证从库应用该事务binlog成功。 半同步复制机制会造成一定程度的延迟，该延迟时间至少是一个 TCP/IP 请求往返的时间。整个服务性能会有所下降。而当从服务出现问题时，主服务需要等待的时间就会更长，要等到从服务的服务恢复或者请求超时才能给用户响应。 半同步复制需要基于特定扩展模块来实现，而 MySQL5.5 版本开始默认自带了该模块。该模块包含在MySQL安装目录下lib/plugin目录下semisync_master.so和semisync_slave.so两个文件中。需在主服务上安装semisync_master模块，从服务上安装semisync_slave模块。 12345678910111213141516171819# 通过扩展库来安装半同步复制模块，需要指定扩展库的文件名mysql&gt; install plugin rpl_semi_sync_master soname &#x27;semisync_master.so&#x27;;Query OK, 0 rows affected (0.01 sec)# 打开半同步复制开关mysql&gt; set global rpl_semi_sync_master_enabled=ON;Query OK, 0 rows affected (0.00 sec)# 查看系统全局参数，rpl_semi_sync_master_timeout就是半同步复制等待应答最长等待时间，默认10秒mysql&gt; show global variables like &#x27;rpl_semi%&#x27;;+-------------------------------------------+------------+| Variable_name | Value |+-------------------------------------------+------------+| rpl_semi_sync_master_enabled | ON || rpl_semi_sync_master_timeout | 10000 | # 默认10秒| rpl_semi_sync_master_trace_level | 32 || rpl_semi_sync_master_wait_for_slave_count | 1 || rpl_semi_sync_master_wait_no_slave | ON || rpl_semi_sync_master_wait_point | AFTER_SYNC | # 表示一种半同步复制的方式+-------------------------------------------+------------+6 rows in set, 1 warning (0.02 sec) 半同步复制有 AFTER_SYNC 和 AFTER_COMMIT 两种方式： AFTER_SYNC 方式，主库把日志写入binlog且复制给从库，然后开始等待从库的响应。从库返回成功后主库再提交事务，接着给客户端返回一个成功响应。 AFTER_COMMIT 方式，主库写入binlog后等待binlog复制到从库，主库就提交自己本地事务，再等待从库返回给自己一个成功响应，然后主库再给客户端返回响应。123456789101112131415161718192021# 通过扩展库来安装半同步复制模块，需要指定扩展库的文件名mysql&gt; install plugin rpl_semi_sync_slave soname &#x27;semisync_slave.so&#x27;;Query OK, 0 rows affected (0.01 sec)# 打开半同步复制开关mysql&gt; set global rpl_semi_sync_slave_enabled = on;Query OK, 0 rows affected (0.00 sec)# 查看系统全局参数mysql&gt; show global variables like &#x27;rpl_semi%&#x27;;+---------------------------------+-------+| Variable_name | Value |+---------------------------------+-------+| rpl_semi_sync_slave_enabled | ON || rpl_semi_sync_slave_trace_level | 32 |+---------------------------------+-------+2 rows in set, 1 warning (0.00 sec)# 安装完slave端的半同步插件后，需要重启下slave服务mysql&gt; stop slave;Query OK, 0 rows affected (0.01 sec)mysql&gt; start slave;Query OK, 0 rows affected (0.01 sec) MySQL高可用方案使用MySQL自身功能来搭建的集群，不具备高可用功能，若MySQL主服务挂了，从服务没办法自动切换成主服务。常见的MySQL集群方案有三种: MMM 、 MHA 、 MGR 。共同点： 对主从复制集群中的Master节点进行监控 自动的对Master进行迁移，通过VIP虚拟IP。 重新配置集群中其它slave对新的Master进行同步 MMMMaster-Master replication manager for MySQL即 MySQL主主复制管理器是一套由 Perl 语言实现的脚本程序，可对MySQL集群进行监控和故障迁移，需要两个Master，但同一时间只有一个Master对外提供服务，可以说是主备模式。 通过一个VIP即虚拟IP机制来保证集群高可用，主节点上会通过一个虚拟IP地址来提供数据读写服务，当出现故障时，虚拟IP从原来主节点漂移到其他节点，由其他节点提供服务。提供了读写VIP的配置，使读写请求都可以达到高可用；工具包相对比较完善，不需要额外的开发脚本；完成故障转移之后可对MySQL集群进行高可用监控；但故障简单粗暴，容易丢失事务，建议采用半同步复制方式，减少失败的概率；目前 MMM社区已经缺少维护，不支持基于GTID的复制；适用于读写都需要高可用的场景以及基于日志点的复制方式。 MHAMaster High Availability Manager and Tools for MySQL由日本人开发基于 Perl 脚本。专门用于监控主库状态，当发现Master节点故障时，会提升其中拥有新数据的Slave节点成为新的Master节点，在此期间MHA会通过其他从节点获取额外信息来避免数据一致性方面的问题。MHA还提供了Mater节点的在线切换功能，MHA能够在 30秒内实现故障切换，并能在故障切换过程中，最大程度的保证数据一致性。 MHA需要单独部署，分为Manager节点和Node节点。Manager节点一般是单独部署一台机器。而Node节点一般部署在每台MySQL机器上，Node节点得通过解析各个MySQL的日志来进行一些操作。 Manager节点会通过探测集群里Node节点去判断各个Node所在机器上的MySQL运行是否正常，若发现某个Master故障则直接把他的一个Slave提升为Master，然后让其他Slave都挂到新的Master上去，完全透明。支持日志点复制方式和GTID方式；同MMM相比，MHA会尝试从旧Master中恢复旧二进制日志，但未必每次都能成功。若希望更少的数据丢失场景，建议使用MHA架构。但 MHA需要自行开发VIP转移脚本；MHA只监控Master状态未监控Slave状态； MGRMGR：MySQL Group Replication是MySQL官方在5.7.17版本正式推出的一种组复制机制。主要是解决传统异步复制和半同步复制的数据一致性问题。由若干个节点共同组成一个复制组，一个事务提交后，必须经过超过半数节点的决议并通过后才可提交。MGR依靠分布式一致性协议Paxos协议的一个变体，实现了分布式下数据的最终一致性，提供了真正的数据高可用方案。 支持多主模式，但官方推荐单主模式，多主模式下，客户端可以随机向MySQL节点写入数据，单主模式下MGR集群会选出primary节点负责写请求，primary节点与其它节点都可以进行读请求处理。基本无延迟，延迟比异步的小很多，支持多写模式，但是目前还不是很成熟，数据的强一致性，可以保证数据事务不丢失；仅支持innodb，且每个表必须提供主键，只能用在GTID模式下，且日志格式为row格式。适用于对主从延迟比较敏感，希望对写服务提供高可用，又不想安装第三方软件，数据强一致的场景。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/tags/MySQL/"}],"categories":[{"name":"DB","slug":"DB","permalink":"http://example.com/categories/DB/"},{"name":"mysql","slug":"DB/mysql","permalink":"http://example.com/categories/DB/mysql/"}]},{"title":"MySQL常用SQL总结","date":"2021-04-24T07:52:21.000Z","path":"blog/DB/mysql/MySQL常用SQL总结/","text":"查看索引1show index from compliance_page_info; 创建联合唯一性索引1234567alter table compliance_page_info add unique index unique_index_name(uuid, type);alter table compliance_page_info add unique unique_index_name(uuid, type);alter table compliance_page_info add unique key unique_index_name(uuid, type);alter table compliance_page_info add primary key unique_index_name(uuid, type);create unique index unique_index_name on compliance_page_info(uuid, type);# 创建唯一性索引时表中存在重复记录，删除重复记录后创建唯一性索引alter ignore table compliance_page_info add unique unique_index_name(uuid, type); 创建全文索引1alter table compliance_page_info add fulltext(uuid); 删除索引123alter table compliance_page_info drop index table_unique_index;drop index unique_index_name on compliance_page_info;alter table compliance_page_info drop primary key; 当记录不存在时Insert，存在时update1234insert into compliance_page_info (uuid, total_page, total_count, type) values (&#x27;d60bc0d38b7a36fba07b2b9e4177d9cf&#x27;, 1, 10, &#x27;OVERVIEW-JUDGEMENT&#x27;)ON DUPLICATE KEY UPDATE total_page = values(total_page), total_count = values(total_count);# 使用replace，记录存在先删除再插入（故受影响的列为2条），不存在直接插入replace into compliance_page_info (uuid, total_page, total_count, type) values (&#x27;d60bc0d38b7a36fba07b2b9e4177d9cf&#x27;, 1, 10, &#x27;OVERVIEW-JUDGEMENT&#x27;) 查询数据库表结构1234select column_name, column_type, is_nullable, column_key, column_default, extra, column_commentfrom information_schema.columnswhere table_schema = &#x27;ent_compliance&#x27; #表所在数据库 and table_name = &#x27;third_page_info&#x27; ; #你要查的表 删除重复数据1234# 必须多嵌套一层select否则MySQL报错delete from update_log where id not in ( select * from (select min(id) from update_log group by uuid, did_or_page, type) b); 正则&amp;字符长度查询1delete from update_log where LENGTH(did_or_page) &gt; 30 or did_or_page REGEXP &#x27;[0-9]+&#x27;; 将一个表中的字段更新到另一表中1234update asset_certificate a, base_static_data b set a.certificate_type = b.code_value, a.certificate_authority = b.extend_valuewhere a.certificate_type_code = b.code_name and a.certificate_type in (&#x27;null&#x27;, &#x27;-&#x27;, &#x27;&#x27;) or a.certificate_type is null; 关联更新123update old_product op, new_product np set np.category = op categorywhere op.name = np.name 分组查询最大ID数据12345select a.* from component a, ( select component_id, max(version) as version from component group by component_id) bwhere a.component_id = b.component_id and a.version = b.version 死锁排查123456-- 查看当前的事务SELECT * FROM INFORMATION_SCHEMA.INNODB_TRX;-- 查看当前锁定的事务SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS;-- 查看当前等锁的事务SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCK_WAITS;","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/tags/MySQL/"}],"categories":[{"name":"DB","slug":"DB","permalink":"http://example.com/categories/DB/"},{"name":"mysql","slug":"DB/mysql","permalink":"http://example.com/categories/DB/mysql/"}]},{"title":"MySQL基础","date":"2021-04-24T05:52:21.000Z","path":"blog/DB/mysql/MySQL基础/","text":"范式设计实际应用中经常需要混用范式设计和反范式设计，最常见的反范式化数据的方法是缓存表、汇总表，缓存表即在不同的表中存储相同的特定列，汇总表即汇总count等信息。对于维护缓存表和汇总表中的数据，通常通过实时维护和定期重建两种方式，取决于应用程序，一般缓存表用实时维护数据更多点，汇总表则用定期重建更多，使用定时任务对汇总表进行更新。 第一范式1NF属于第一范式关系的所有属性都不可再分，即数据项不可分，强调数据表的原子性，是其他范式的基础 第二范式2NF要求数据库表中的每个实例或行必须可被惟一地区分，通常需要为表加上一个列，以存储各个实例的惟一标识，该属性列被称为主关键字或主键，实体的属性完全依赖于主关键字，不能存在仅依赖主关键字一部分的属性即联合主键的情况 第三范式3NF每一个非主属性既不部分依赖也不传递依赖于业务主键，即在第二范式基础上消除非主键对主键的传递依赖。 反范式设计实际业务查询中会大量存在表关联查询，大量表关联很多时候非常影响查询性能，反范式化就是为了性能和读取效率考虑而适当对数据库设计范式要求进行违反，允许存在少量得冗余，即反范式化就是使用空间来换取时间。 范式化设计优缺点优点 范式化更新操作通常比反范式化快 当数据较好地范式化时，则只有很少或没有重复数据，故只需修改更少的数据 范式化表通常更小，可更好地放在内存中，故执行操作会更快 很少有多余数据，检索列表数据时更少需要 DISTINCT 或 GROUP BY 语句 缺点 通常需要关联，稍微复杂一些的查询语句在符合范式的表上都可能需要至少一次关联，也许更多，不但代价昂贵，也可能使一些索引策略无效 反范式化设计优缺点 可减少表的关联 可更好的进行索引优化 缺点 存在数据冗余及数据维护异常 对数据修改需要更多成本 数据类型选择选择正确的数据类型，对于性能至关重要，在数据类型设置方面，尽量用更小的数据类型，因为它们通常有更好的性能，花费更少的硬件资源，且尽量把字段定义为NOT NULL ，避免使用NULL。一般应该遵循下面两步： 确定合适的大类型：数字、字符串、时间、二进制 确定具体的类型：有无符号、取值范围、变长定长等 数值类型若整形数据没有负数，如ID号，建议指定为UNSIGNED无符号类型，容量可以扩大一倍；建议使用TINYINT代替ENUM、BITENUM、SET；避免使用整数的显示宽度，不要用INT(10)类似的方法指定字段显示宽度，直接用INT。 DECIMAL最适合保存准确度要求高，且用于计算的数据，如价格。但在使用DECIMAL类型时，注意长度设置。建议使用整形类型来运算和存储实数，方法是实数乘以相应的倍数后再操作。整数通常是最佳的数据类型，因为它速度快，且能使用AUTO_INCREMENT。 INT显示宽度：在使用ZEROFILL时有用，让查询结果前填充0，如TINYINT(5) ，若结果是5，则输出就是00005，实际存储的值还是5，且存储的数据不会超过255，只是输出数据时在前面填充了0。 类型 大小 范围（有符号） 范围（无符号） 用途 TINYINT 1 字节 -2^7 ~ 2^7-1 (0, 255) 小整数值 SMALLINT 2 字节 -2^15 ~ 2^15-1 (0, 255) 大整数值 MEDIUMINT 3 字节 -2^23 ~ 2^23-1 (0, 255) 大整数值 INT或 INTEGER 4 字节 -2^31 ~ 2^31-1 (0, 255) 大整数值 BIGINT 8 字节 -2^63 ~ 2^63-1 (0, 255) 极大整数值 FLOAT 4 字节 单精度浮点数值 DOUBLE 8 字节 双精度浮点数值 DECIMAL DECIMAL(M,D) 若M&gt;D为M+2否则为D+2 -2^7 ~ 2^7-1 (0, 255) 小整数值 日期和时间MySQL能存储的最小时间粒度为秒。建议用DATE数据类型来保存日期，默认日期格式yyyy-MM-dd 。用内建类型DATE、TIME、DATETIME来存储时间，而不是使用字符串。 当数据格式为 TIMESTAMP 和 DATETIME 时，可用 CURRENT_TIMESTAMP 作为默认值，MySQL会自动返回记录插入的确切时间， TIMESTAMP 是 UTC 时间戳，与时区相关。 DATETIME 的存储格式是一个 yyyy-MM-dd HH:mm:ss 的整数，与时区无关，存什么读出来就是什么。除非有特殊需求，一般的公司建议使用 TIMESTAMP ，它比DATETIME更节约空间，但大公司一般用 DATETIME ，因为不用考虑TIMESTAMP将来的时间上限问题。不推荐把Unix的时间戳保存为整数值。 类型 大小 (字节) 范围 格式 用途 DATE 3 1000-01-01到9999-12-31 YYYY-MM-DD 日期值 TIME 3 -838:59:59到838:59:59 HH:mm:ss 时间值或持续时间 YEAR 1 1901到2155 YYYY 年份值 DATETIME 8 1000-01-01 00:00:00到9999-12-31 23:59:59 YYYY-MM-DD HH:mm:ss 混合日期和时间值 TIMESTAMP 4 1970-01-01 00:00:00到2038-01-19 03:14:07 YYYYMMDDhhmmss 混合日期、时间，时间戳 字符串字符串长度相差较大用VARCHAR ；字符串短且所有值都接近一个长度用CHAR 。 CHAR 和 VARCHAR适用于包括人名、邮政编码、电话号码和不超过255个字符长度的任意字母数字组合。需要用来计算的数字不要用 VARCHAR 类型保存，可能会导致一些与计算相关的问题，可能影响到计算的准确性和完整性。 尽量少用BLOB和TEXT ，若实在要用可考虑将BLOB和TEXT字段单独存一张表用 id 关联。 BLOB系列存储二进制字符串，与字符集无关。 TEXT 系列存储非二进制字符串，与字符集相关。BLOB和TEXT都不能有默认值。 类型 大小 用途 CHAR 0-255字节 定长字符串， char(n) 当插入字符串实际长度不足n时，插入空格进行补充保存。检索时尾部的空格会被去掉 VARCHAR 0-65535字节 变长字符串， varchar(n) 中n代表最大列长度，插入字符串实际长度不足n时不会补充空格 TINYBLOB 0-255字节 不超过255个字符的二进制字符串 TINYTEXT 0-255字节 短文本字符串 BLOB 0-65535字节 二进制形式的长文本数据 TEXT 0-65535字节 长文本数据 MEDIUMBLOB 0-16777215字节 二进制形式的中等长度文本数据 MEDIUMTEXT 0-16777215字节 中等长度文本数据 LONGBLOB 0-4294967295字节 二进制形式的极大文本数据 LONGTEXT 0-4294967295字节 极大文本数据","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/tags/MySQL/"}],"categories":[{"name":"DB","slug":"DB","permalink":"http://example.com/categories/DB/"},{"name":"mysql","slug":"DB/mysql","permalink":"http://example.com/categories/DB/mysql/"}]},{"title":"Explain工具","date":"2021-04-23T11:52:21.000Z","path":"blog/DB/Explain工具/","text":"用 EXPLAIN 关键字可以模拟优化器执行SQL语句， 分析查询语句或是结构的性能瓶颈 ，在 select语句之前增加explain关键字 ，MySQL会在查询上设置一个标记，执行查询会返回执行计划的信息，而不是执行这条SQL，若from中包含子查询，仍会执行该子查询，将结果放入临时表中。 1explain select * from actor; 在查询中的每个表会输出一行，如果有两个表通过join连接查询，那么会输出两行 示例数据使用示例数据时需特别关注表的主键、二级索引、联合索引等在各种SQL下产生的不同影响 12345678910111213141516171819202122232425262728293031323334353637383940-- 以id作为主键DROP TABLE IF EXISTS `actor`;CREATE TABLE `actor` ( `id` int(11) NOT NULL, `name` varchar(45) DEFAULT NULL, `update_time` datetime DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;INSERT INTO `actor` VALUES (&#x27;1&#x27;, &#x27;a&#x27;, &#x27;2017-12-22 15:27:18&#x27;);INSERT INTO `actor` VALUES (&#x27;2&#x27;, &#x27;b&#x27;, &#x27;2017-12-22 15:27:18&#x27;);INSERT INTO `actor` VALUES (&#x27;3&#x27;, &#x27;c&#x27;, &#x27;2017-12-22 15:27:18&#x27;);-- 以id为主键，name为二级索引DROP TABLE IF EXISTS `film`;CREATE TABLE `film` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(10) DEFAULT NULL, PRIMARY KEY (`id`), KEY `idx_name` (`name`)) ENGINE=InnoDB AUTO_INCREMENT=4 DEFAULT CHARSET=utf8;INSERT INTO `film` VALUES (&#x27;3&#x27;, &#x27;film0&#x27;);INSERT INTO `film` VALUES (&#x27;1&#x27;, &#x27;film1&#x27;);INSERT INTO `film` VALUES (&#x27;2&#x27;, &#x27;film2&#x27;);-- 以id为主键，film_id和actor_id为联合索引DROP TABLE IF EXISTS `film_actor`;CREATE TABLE `film_actor` ( `id` int(11) NOT NULL, `film_id` int(11) NOT NULL, `actor_id` int(11) NOT NULL, `remark` varchar(255) DEFAULT NULL, PRIMARY KEY (`id`), KEY `idx_film_actor_id` (`film_id`,`actor_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;INSERT INTO `film_actor` VALUES (&#x27;1&#x27;, &#x27;1&#x27;, &#x27;1&#x27;, null);INSERT INTO `film_actor` VALUES (&#x27;2&#x27;, &#x27;1&#x27;, &#x27;2&#x27;, null);INSERT INTO `film_actor` VALUES (&#x27;3&#x27;, &#x27;2&#x27;, &#x27;1&#x27;, null); Explain两个变种explain extended会在explain的基础上额外提供一些查询优化的信息。紧随其后通过 show warnings 命令可得到优化后的查询语句，从而看出优化器优化了什么。额外还有 filtered 列，是一个百分比的值， rows * filtered/100 可以估算出将要和explain中前一个表进行连接的行数，前一个表指explain中的id值比当前表id值小的表。 1explain extended select * from film where id = 1; 1show warnings; explain partitions相比explain多了个 partitions字段 ，若查询是 基于分区表 的话， 会显示查询将访问的分区 。 1explain partitions select * from film where id = 1; Explain列详情idid列的编号是 select的序列号，有几个select就有几个id ，并且id的顺序是按select出现的顺序增长的， id列越大执行优先级越高，id相同则从上往下执行，id为NULL最后执行。 select_type表示对应行是简单还是复杂的查询 simple ：简单查询。查询不包含子查询和 union primary ：复杂查询中最外层的select subquery ：包含在select中但不在from子句中的子查询 derived ：包含在from子句中的子查询。MySQL会将结果存放在一个临时表中，也称为派生表 union ：在union中的第二个和随后的select123set session optimizer_switch=&#x27;derived_merge=off&#x27;; #关闭mysql5.7新特性对衍生表的合并优化explain select (select 1 from actor where id = 1) from (select * from film where id = 1) der;set session optimizer_switch=&#x27;derived_merge=on&#x27;; #还原默认配置 1explain select 1 union all select 1; type表示关联类型或访问类型，即MySQL决定如何查找表中的行，查找数据行记录的大概范围。依次从最优到最差分别为： system 、 const 、 eq_ref 、 ref 、 range 、 index 、 ALL ，一般来说得保证查询达到range级别，最好达到ref 。 NULL ：mysql能够在优化阶段分解查询语句，在执行阶段用不着再访问表或索引。如：在索引列中选取最小值，可以单独查找索引来完成，不需要在执行时访问表 1explain select min(id) from film; const ： mysql能对查询的某部分进行优化并将其转化成一个常量，可看show warnings的结果，用于 primary key 或 unique key 的所有列与常数比较时，表最多有一个匹配行，读取1次，速度比较快。 1explain extended select * from (select * from film where id = 1) tmp; system ： system是const的特例，表里只有一条元组匹配时为system eq_ref ： primary key 或 unique key 索引的所有部分被连接使用，最多只会返回一条符合条件的记录。这可能是在const之外最好的联接类型了，简单的select查询不会出现这种type。 1explain select * from film_actor left join film on film_actor.film_id = film.id; ref ：相比eq_ref 不使用唯一索引，而是使用普通索引或者唯一性索引的部分前缀，索引要和某个值相比较，可能会找到多个符合条件的行。 简单 select 查询，name是普通索引（非唯一索引) 1explain select * from film where name = &#x27;film1&#x27;; 关联表查询，idx_film_actor_id是film_id和actor_id的联合索引，这里使用film_actor的左边前缀film_id部分 1explain select film_id from film left join film_actor on film.id = film_actor.film_id; range ：范围扫描通常出现在 in() , between , &gt; , &lt; , &gt;= 等操作中。使用一个索引来检索给定范围的行。 1explain select * from actor where id &gt; 1; index ：扫描全索引拿到结果，一般是扫描某个二级索引，这种扫描不会从索引树根节点开始快速查找，而是直接对二级索引的叶子节点遍历和扫描，速度还是比较慢的，这种查询一般为使用覆盖索引，二级索引一般比较小，所以这种通常比ALL快一些。 1explain select * from film; ALL ：即全表扫描，扫描聚簇索引的所有叶子节点，通常情况下这需要增加索引来进行优化了。 1explain select * from actor; possible_keys显示查询可能使用哪些索引来查找，explain时可能出现possible_keys有值，而key为NULL的情况，这种情况是因为表中数据不多，mysql认为索引对此查询帮助不大，选择了全表查询。若该列是NULL，则没有相关的索引，可通过检查where子句看是否可以创造一个适当的索引来提高查询性能，然后用explain查看效果。 key显示实际采用哪个索引来优化对该表的访问，若没有使用索引，则该列是NULL。若想强制使用或忽视possible_keys 列中的索引，在查询中使用 force index 、 ignore index key_len显示在索引里使用的字节数，通过该值可算出具体使用了索引中的哪些列，如film_actor的联合索引 idx_film_actor_id由film_id和actor_id两个int列组成，并且每个int是4字节。通过结果中的key_len&#x3D;4可推断出查询使用了第一个列film_id列来执行索引查找。 1explain select * from film_actor where film_id = 2; key_len 计算规则如下： 字符串： char(n) 和 varchar(n) ，5.0.3以后版本中， n均代表字符数，而不是字节数，若是utf-8，一个数字或字母占1个字节，一个汉字占3个字节， char(n) ：若存汉字长度就是3n字节， varchar(n) ：若存汉字则长度是3n + 2字节，加的2字节用来存储字符串长度，因为varchar是变长字符串 数值类型： tinyint：1字节，smallint：2字节，int：4字节，bigint：8字节 时间类型： date：3字节，timestamp：4字节，datetime：8字节 若字段允许为 NULL，需要1字节记录是否为NUL 索引最大长度是768字节，当字符串过长时，mysql会做一个类似左前缀索引的处理，将前半部分的字符提取出来做索引。 ref显示在key列记录的索引中，表查找值所用到的列或常量，常见的有 const常量，字段名，如film.id rows估计要读取并检测的行数，不是结果集里的行数。 ExtraUsing index：使用覆盖索引覆盖索引：mysql执行计划explain结果里的key有使用索引，若select后面查询的字段都可以从这个索引的树中获取，该情况一般可以说是用到了覆盖索引，extra里一般都有using index； 覆盖索引一般针对的是辅助索引，整个查询结果只通过辅助索引就能拿到结果，不需要通过辅助索引树找到主键，再通过主键去主键索引树里获取其它字段值 1explain select film_id from film_actor where film_id = 1; Using where：使用where语句来处理结果，且查询的列未被索引覆盖1explain select * from actor where name = &#x27;a&#x27;; Using index condition：查询的列不完全被索引覆盖，where条件中是一个前导列的范围1explain select * from film_actor where film_id &gt; 1; Using temporary：需创建临时表来处理查询，该情况一般是要进行优化，首先考虑用索引来优化actor.name没有索引，此时创建了张临时表来distinct 1explain select distinct name from actor; film.name建立了idx_name索引，此时查询时extra是using index，没有用临时表 1explain select distinct name from film; Using filesort：用外部排序而非索引排序，数据较小时从内存排序，否则在磁盘完成排序该情况一般也要考虑用索引来优化，actor.name未创建索引，会浏览actor整个表，保存排序关键字name和对应的id，然后排序name并检索行记录 1explain select * from actor order by name; film.name建立了idx_name索引，此时查询时extra是using index 1explain select * from film order by name; Select tables optimized away：使用某些聚合函数，如max、min来访问存在索引的某个字段1explain select min(id) from film;","tags":[{"name":"DB","slug":"DB","permalink":"http://example.com/tags/DB/"}],"categories":[{"name":"DB","slug":"DB","permalink":"http://example.com/categories/DB/"}]},{"title":"ShardingSphere基础","date":"2021-04-23T11:52:21.000Z","path":"blog/DB/ShardingSphere基础/","text":"ShardingSphereSharding-JDBC是当当网研发的开源分布式数据库中间件，他是一套开源的分布式数据库中间件解决方案组成的生态圈，它由**Sharding-JDBC、Sharding-Proxy和Sharding-Sidecar（计划中）这3款相互独立的产品组成。 他们均提供标准化的数据分片、分布式事务和数据库治理**功能，可适用于如Java同构、异构语言、容器、云原生等各种多样化的应用场景。 ShardingSphere包含ShardingJDBC、ShardingProxy和ShardingSidecar三个重要的产品。ShardingJDBC是用来做客户端分库分表的产品，而**ShardingProxy是用来做服务端分库分表的产品，其中ShardingSidecar**是针对Service Mesh定位的一个分库分表插件。 ShardingJDBC为轻量级Java框架，是客户端的一个工具包，在Java的JDBC层提供的额外服务。它使⽤客户端直连数据库，以Jar包形式提供服务无需额外部署和依赖，可理解为增强版的JDBC驱动，完全兼容JDBC和各种ORM框架。所有分库分表逻辑均由业务方自己控制，功能相对灵活，支持的数据库也非常多，但对业务侵入大，需要业务方自己定制所有的分库分表逻辑。 ShardingProxy为透明化的数据库代理端，是一个独立部署的服务，提供封装了数据库二进制协议的服务端版本，⽤于完成对异构语言的⽀持。对业务方无侵入，业务方可以像用一个普通的MySQL服务一样进行数据交互，基本上感觉不到后端分库分表逻辑的存在，但也意味着功能会比较固定，能够支持的数据库也比较少；目前提供**MySQL和PostgreSQL版本，可使用任何兼容MySQL/PostgreSQL**协议的访问客户端。 ShardingSphere核心功能是数据分片和读写分离，通过**ShardingJDBC应用可透明的使用JDBC访问已经分库分表、读写分离的多个数据源**，而不用关心数据源的数量以及数据如何分布。 逻辑表：水平拆分的数据库的相同逻辑和数据结构表的总称 真实表：在分片的数据库中真实存在的物理表 数据节点：数据分片的最小单元，由数据源名称和数据表组成 绑定表：分片规则一致的主表和子表 广播表：也叫公共表指所有分片数据源中都存在的表，表结构和表中的数据在每个数据库中都完全一致 分片键：用于分片的数据库字段，是将数据库或表进行水平拆分的关键字段，SQL中若没有分片字段，将会执行全路由，性能会很差。 分片算法：通过分片算法将数据进行分片，支持通过**=、BETWEEN和IN**分片，分片算法需要由应用开发者自行实现，灵活度非常高 分片策略：真正用于进行分片操作的是分片键+分片算法即分片策略，在**ShardingJDBC中一般采用基于Groovy表达式的inline分片策略，通过一个包含分片键的算法表达式来制定分片策略，如t_user_$-&gt;&#123;u_id%8&#125;**。 分片算法ShardingJDBC整个分库分表的核心在于配置的分片算法，使用**inline分片算法提供一个分片键和一个分片表达式来制定分片算法，该方式配置简单，功能灵活，是分库分表最佳的配置方式，且可满足绝大多数分库分片场景。但若针对一些更为复杂的分片策略，如多分片键、按范围分片等场景，inline分片算法就不能满足了，ShardingSphere还提供的其他几种分片策略，目前提供了五种**分片策略。 NoneShardingStrategy不分片，严格来说不算是一种分片策略了，只是**ShardingSphere**也提供了这么一个配置。 InlineShardingStrategy最常用的分片方式，通过**inline.sharding-column配置分片键，通过algorithm-expression配置分片表达式，最终按照分片表达式来进行分片。通过table-strategy配置表的分片策略，通过database-strategy配置库的分片策略**。 123456# inline分片策略spring.shardingsphere.sharding.tables.course.table-strategy.inline.sharding-column=cidspring.shardingsphere.sharding.tables.course.table-strategy.inline.algorithm-expression=course_$-&gt;&#123;cid%2+1&#125;spring.shardingsphere.sharding.tables.course.database-strategy.inline.sharding-column=cidspring.shardingsphere.sharding.tables.course.database-strategy.inline.algorithm-expression=m$-&gt;&#123;cid%2+1&#125; StandardShardingStrategy只支持单分片键的标准分片策略，通过**standard.sharding-column配置分片键，通过standard.precise-algorithm-class-name配置按照=或IN逻辑的精确分片算法类名且该类必须实现io.shardingsphere.api.algorithm.sharding.standard.PreciseShardingAlgorithm接口，通过standard.range-algorithm-class-name配置按照Between条件进行的范围分片算法类名且该类必须实现io.shardingsphere.api.algorithm.sharding.standard.RangeShardingAlgorithm接口，分库和分表的精确分片算法和范围分片算法都是实现这两个接口。精确分片算法是必须提供的，范围分片算法是可选的**。 1234567spring.shardingsphere.sharding.tables.course.table-strategy.standard.sharding-column=cidspring.shardingsphere.sharding.tables.course.table-strategy.standard.precise-algorithm-class-name=com.eleven.icode.shardingsphere.algorithem.MyPreciseTableShardingAlgorithmspring.shardingsphere.sharding.tables.course.table-strategy.standard.range-algorithm-class-name=com.eleven.icode.shardingsphere.algorithem.MyRangeTableShardingAlgorithmspring.shardingsphere.sharding.tables.course.database-strategy.standard.sharding-column=cidspring.shardingsphere.sharding.tables.course.database-strategy.standard.precise-algorithm-class-name=com.eleven.icode.shardingsphere.algorithem.MyPreciseDSShardingAlgorithmspring.shardingsphere.sharding.tables.course.database-strategy.standard.range-algorithm-class-name=com.eleven.icode.shardingsphere.algorithem.MyRangeDSShardingAlgorithm 12345678910111213141516public class MyPreciseTableShardingAlgorithm implements PreciseShardingAlgorithm&lt;Long&gt; &#123; @Override public String doSharding(Collection&lt;String&gt; availableTargetNames, PreciseShardingValue&lt;Long&gt; shardingValue) &#123; String logicTableName = shardingValue.getLogicTableName(); // 获取逻辑表 String cid = shardingValue.getColumnName(); // 获取分片键 Long cidValue = shardingValue.getValue(); // 实现 course_$-&gt;&#123;cid%2+1) BigInteger shardingValueB = BigInteger.valueOf(cidValue); BigInteger resB = shardingValueB.mod(new BigInteger(&quot;2&quot;)).add(new BigInteger(&quot;1&quot;)); String key = logicTableName + &quot;_&quot; + resB; if (availableTargetNames.contains(key)) &#123; // couse_1, course_2 return key; &#125; throw new UnsupportedOperationException(&quot;route &quot; + key + &quot; is not supported ,please check your config&quot;); &#125;&#125; 1234567891011public class MyRangeTableShardingAlgorithm implements RangeShardingAlgorithm&lt;Long&gt; &#123; @Override public Collection&lt;String&gt; doSharding(Collection&lt;String&gt; availableTargetNames, RangeShardingValue&lt;Long&gt; shardingValue) &#123; // select * from course where cid between 1 and 100; Long upperVal = shardingValue.getValueRange().upperEndpoint(); //100 Long lowerVal = shardingValue.getValueRange().lowerEndpoint(); //1 // TODO 完成具体的分表策略 String logicTableName = shardingValue.getLogicTableName(); return Arrays.asList(logicTableName + &quot;_1&quot;, logicTableName + &quot;_2&quot;); &#125;&#125; ComplexShardingStrategy支持多分片键的复杂分片策略，通过**complex.sharding-columns配置分片键，多个分片键用逗号分隔，通过complex.algorithm-class-name配置按多个分片列进行综合分片的分片算法实现类，且该实现类必须实现org.apache.shardingsphere.api.sharding.complex.ComplexKeysShardingAlgorithm**接口。 12345spring.shardingsphere.sharding.tables.course.table-strategy.complex.sharding-columns= cid, user_idspring.shardingsphere.sharding.tables.course.table-strategy.complex.algorithm-class-name=com.eleven.icode.shardingsphere.algorithem.MyComplexTableShardingAlgorithmspring.shardingsphere.sharding.tables.course.database-strategy.complex.sharding-columns=cid, user_idspring.shardingsphere.sharding.tables.course.database-strategy.complex.algorithm-class-name=com.eleven.icode.shardingsphere.algorithem.MyComplexDSShardingAlgorithm 12345678910111213141516public class MyComplexTableShardingAlgorithm implements ComplexKeysShardingAlgorithm&lt;Long&gt; &#123; @Override public Collection&lt;String&gt; doSharding(Collection&lt;String&gt; availableTargetNames, ComplexKeysShardingValue&lt;Long&gt; shardingValue) &#123; Range&lt;Long&gt; cidRange = shardingValue.getColumnNameAndRangeValuesMap().get(&quot;cid&quot;); Collection&lt;Long&gt; userIdCol = shardingValue.getColumnNameAndShardingValuesMap().get(&quot;user_id&quot;); Long upperVal = cidRange.upperEndpoint(); Long lowerVal = cidRange.lowerEndpoint(); List&lt;String&gt; res = new ArrayList&lt;&gt;(); for (Long userId : userIdCol) &#123;// course_&#123;userID%2+1&#125; BigInteger userIdB = BigInteger.valueOf(userId); BigInteger target = userIdB.mod(new BigInteger(&quot;2&quot;)).add(new BigInteger(&quot;1&quot;)); res.add(shardingValue.getLogicTableName() + &quot;_&quot; + target); &#125; return res; &#125;&#125; HintShardingStrategy不需要分片键的强制分片策略，其分片键不跟SQL语句关联而是程序指定。对于一些复杂的情况如**select count(*) from (select userid from t_user where userid in (1,3,5,7,9))**这样的SQL语句，无法通过SQL语句指定一个分片键，这时就可通过程序给他指定一个分片键，如按userid奇偶分片的策略下，可指定1作为分片键，然后自行指定他的分片策略。 通过**hint.algorithm-class-name配置分片算法实现类，且该类必须实现org.apache.shardingsphere.api.sharding.hint.HintShardingAlgorithm接口，该算法类同样需要分片键，通过HintManager.addDatabaseShardingValue方法指定分库分片键和通过HintManager.addTableShardingValue方法指定分表分片键。使用时该分片键是线程隔离的，只在当前线程有效，建议使用之后立即关闭，或者用try**资源方式打开。 Hint分片策略并没有完全按照SQL解析树来构建分片策略，绕开了SQL解析，对某些比较复杂语句，Hint分片策略性能有可能会比较好。但Hint强制路由在使用时有非常多的限制： 1234567-- 不支持UNIONSELECT * FROM t_order1 UNION SELECT * FROM t_order2INSERT INTO tbl_name (col1, col2, …) SELECT col1, col2, … FROM tbl_name WHERE col3 = ?-- 不支持多层子查询SELECT COUNT(*) FROM (SELECT * FROM t_order o WHERE o.id IN (SELECT id FROM t_order WHERE status = ?))-- 不支持函数计算，ShardingSphere只能通过SQL字面提取用于分片的值SELECT * FROM t_order WHERE to_date(create_time, &#x27;yyyy-mm-dd&#x27;) = &#x27;2019-01-01&#x27;; 1spring.shardingsphere.sharding.tables.course.table-strategy.hint.algorithm-class-name=com.eleven.icode.shardingsphere.algorithem.MyHintTableShardingAlgorithm 12345678910public class MyHintTableShardingAlgorithm implements HintShardingAlgorithm&lt;Integer&gt; &#123; @Override public Collection&lt;String&gt; doSharding(Collection&lt;String&gt; availableTargetNames, HintShardingValue&lt;Integer&gt; shardingValue) &#123; String key = shardingValue.getLogicTableName() + &quot;_&quot; + shardingValue.getValues().toArray()[0]; if (availableTargetNames.contains(key)) &#123; return Arrays.asList(key); &#125; throw new UnsupportedOperationException(&quot;route &quot; + key + &quot; is not supported ,please check your config&quot;); &#125;&#125; 实例首先定义一个数据源m1，并对m1进行实际的JDBC参数配置，**spring.shardingsphere.sharding.tables.course开头的一系列属性即定义了一个名为course的逻辑表，actual-data-nodes属性即定义course逻辑表的实际数据分布情况，他分布在m1.course_1和m1.course_2两个表。key-generator属性配置主键列以及主键生成策略，ShardingJDBC默认提供了UUID和SNOWFLAKE两种分布式主键生成策略。table-strategy属性配置分库分表策略，分片键为cid属性，分片算法为course_$-&gt;{cid%2+1}，表示按照cid模2+1的结果，然后加上前面的course__ 部分作为前缀就是其实际表结果，该表达式计算出来的结果需要能够与实际数据分布中的一种情况对应上否则就会报错**。 1234567891011121314151617181920212223# 配置数据源，可配置多个，用逗号分隔spring.shardingsphere.datasource.names=m1# 数据源m1spring.shardingsphere.datasource.m1.type=com.alibaba.druid.pool.DruidDataSourcespring.shardingsphere.datasource.m1.driver-class-name=com.mysql.cj.jdbc.Driverspring.shardingsphere.datasource.m1.url=jdbc:mysql://localhost:3307/coursedb?serverTimezone=GMT%2B8spring.shardingsphere.datasource.m1.username=rootspring.shardingsphere.datasource.m1.password=root# 通过groovy脚本配置真实表分布，指定course表分布情况，配置表在哪个数据库里面，表名称都是什么spring.shardingsphere.sharding.tables.course.actual-data-nodes=m1.course_$-&gt;&#123;1..2&#125;# 指定course表里中主键cid生成策略SNOWFLAKEspring.shardingsphere.sharding.tables.course.key-generator.column=cidspring.shardingsphere.sharding.tables.course.key-generator.type=SNOWFLAKE# 雪花算法的一个可选参数spring.shardingsphere.sharding.tables.course.key-generator.props.worker.id=1# 通过groovy脚本指定分表分片策略，约定cid值偶数添加到course_1表，奇数添加到course_2表spring.shardingsphere.sharding.tables.course.table-strategy.inline.sharding-column=cid# 根据计算的字段算出对应的表名spring.shardingsphere.sharding.tables.course.table-strategy.inline.algorithm-expression=course_$-&gt;&#123;cid%2+1&#125;# 打开sql输出日志spring.shardingsphere.props.sql.show=true# 一个实体类对应两张表，覆盖spring.main.allow-bean-definition-overriding=true 通过上面的配置**ShardingJDBC会帮我们完成具体的SQL转换以及数据的调用，不需要做其他特别的处理。最终这些配置被转换映射到ShardingRuleConfiguration**中： 12345678910111213tables: course: actualDataNodes: m1.course_$-&gt;&#123;1..2&#125; # 数据节点 keyGenerator: # 主键生成策略配置 column: cid # 主键 props: worker.id: &#x27;1&#x27; type: SNOWFLAKE # 具体的主键生成策略 logicTable: course # 逻辑表 tableStrategy: # 分表策略 inline: # 分片策略 algorithmExpression: course_$-&gt;&#123;cid%2+1&#125; # 具体的分片算法 shardingColumn: cid # 分片键 多数据源多数据源的情况除了要配置分表分片策略，还需要配置分库分片策略，与前面的区别在于指定了多个数据源，**actual-data-nodes**数据节点配置所有变化，且增加了分库分片策略。 1234567891011121314151617181920212223242526272829303132# 配置数据源，可配置多个，用逗号分隔spring.shardingsphere.datasource.names=m1,m2# 数据源m1spring.shardingsphere.datasource.m1.type=com.alibaba.druid.pool.DruidDataSourcespring.shardingsphere.datasource.m1.driver-class-name=com.mysql.cj.jdbc.Driverspring.shardingsphere.datasource.m1.url=jdbc:mysql://localhost:3307/coursedb?serverTimezone=GMT%2B8spring.shardingsphere.datasource.m1.username=rootspring.shardingsphere.datasource.m1.password=root# 数据源m2spring.shardingsphere.datasource.m2.type=com.alibaba.druid.pool.DruidDataSourcespring.shardingsphere.datasource.m2.driver-class-name=com.mysql.cj.jdbc.Driverspring.shardingsphere.datasource.m2.url=jdbc:mysql://localhost:3307/coursedb2?serverTimezone=GMT%2B8spring.shardingsphere.datasource.m2.username=rootspring.shardingsphere.datasource.m2.password=root# 通过groovy脚本配置真实表分布，指定course表分布情况，配置表在哪个数据库里面，表名称都是什么spring.shardingsphere.sharding.tables.course.actual-data-nodes=m$-&gt;&#123;1..2&#125;.course_$-&gt;&#123;1..2&#125;# 指定course表里中主键cid生成策略SNOWFLAKEspring.shardingsphere.sharding.tables.course.key-generator.column=cidspring.shardingsphere.sharding.tables.course.key-generator.type=SNOWFLAKE# 雪花算法的一个可选参数spring.shardingsphere.sharding.tables.course.key-generator.props.worker.id=1# 通过groovy脚本指定分表分片策略，约定cid值偶数添加到course_1表，奇数添加到course_2表spring.shardingsphere.sharding.tables.course.table-strategy.inline.sharding-column=cid# 根据计算的字段算出对应的表名spring.shardingsphere.sharding.tables.course.table-strategy.inline.algorithm-expression=course_$-&gt;&#123;cid%2+1&#125;# 分库策略spring.shardingsphere.sharding.tables.course.database-strategy.inline.sharding-column=cidspring.shardingsphere.sharding.tables.course.database-strategy.inline.algorithm-expression=m$-&gt;&#123;cid%2+1&#125;# 打开sql输出日志spring.shardingsphere.props.sql.show=true# 一个实体类对应两张表，覆盖spring.main.allow-bean-definition-overriding=true 广播表配置1234# 广播表配置spring.shardingsphere.sharding.broadcast-tables=t_dictspring.shardingsphere.sharding.tables.t_dict.key-generator.column=dict_idspring.shardingsphere.sharding.tables.t_dict.key-generator.type=SNOWFLAKE 绑定表绑定表之间的多表关联查询不会出现笛卡尔积关联，关联查询效率将⼤⼤提升。 1234567891011121314151617181920212223242526272829303132# 配置数据源，可配置多个，用逗号分隔spring.shardingsphere.datasource.names=m1# 数据源m1spring.shardingsphere.datasource.m1.type=com.alibaba.druid.pool.DruidDataSourcespring.shardingsphere.datasource.m1.driver-class-name=com.mysql.cj.jdbc.Driverspring.shardingsphere.datasource.m1.url=jdbc:mysql://localhost:3306/coursedb?serverTimezone=GMT%2B8spring.shardingsphere.datasource.m1.username=rootspring.shardingsphere.datasource.m1.password=root# 通过groovy脚本配置真实表分布，指定t_dict表分布情况，配置表在哪个数据库里面，表名称都是什么spring.shardingsphere.sharding.tables.t_dict.actual-data-nodes=m1.t_dict_$-&gt;&#123;1..2&#125;spring.shardingsphere.sharding.tables.t_dict.key-generator.column=dict_idspring.shardingsphere.sharding.tables.t_dict.key-generator.type=SNOWFLAKEspring.shardingsphere.sharding.tables.t_dict.key-generator.props.worker.id=1# t_dict表的分片键和分片算法spring.shardingsphere.sharding.tables.t_dict.table-strategy.inline.sharding-column=ustatusspring.shardingsphere.sharding.tables.t_dict.table-strategy.inline.algorithm-expression=t_dict_$-&gt;&#123;ustatus.toInteger()%2+1&#125;# 通过groovy脚本配置真实表分布，指定user表分布情况，配置表在哪个数据库里面，表名称都是什么spring.shardingsphere.sharding.tables.user.actual-data-nodes=m1.t_user_$-&gt;&#123;1..2&#125;# 指定user表里中主键user_id生成策略SNOWFLAKEspring.shardingsphere.sharding.tables.user.key-generator.column=user_idspring.shardingsphere.sharding.tables.user.key-generator.type=SNOWFLAKEspring.shardingsphere.sharding.tables.user.key-generator.props.worker.id=1# user表的分片键和分片算法spring.shardingsphere.sharding.tables.user.table-strategy.inline.sharding-column=ustatusspring.shardingsphere.sharding.tables.user.table-strategy.inline.algorithm-expression=t_user_$-&gt;&#123;ustatus.toInteger()%2+1&#125;# 绑定表示spring.shardingsphere.sharding.binding-tables[0]=user,t_dict# 打开sql输出日志spring.shardingsphere.props.sql.show = true# 一个实体类对应两张表，覆盖spring.main.allow-bean-definition-overriding=true 读写分离123456789101112131415161718192021222324252627# 配置主从数据源，要基于MySQL主从架构。spring.shardingsphere.datasource.names=m0,s0# 数据源m0spring.shardingsphere.datasource.m0.type=com.alibaba.druid.pool.DruidDataSourcespring.shardingsphere.datasource.m0.driver-class-name=com.mysql.cj.jdbc.Driverspring.shardingsphere.datasource.m0.url=jdbc:mysql://localhost:3307/masterdemo?serverTimezone=GMT%2B8spring.shardingsphere.datasource.m0.username=rootspring.shardingsphere.datasource.m0.password=root# 数据源s0spring.shardingsphere.datasource.s0.type=com.alibaba.druid.pool.DruidDataSourcespring.shardingsphere.datasource.s0.driver-class-name=com.mysql.cj.jdbc.Driverspring.shardingsphere.datasource.s0.url=jdbc:mysql://localhost:3308/masterdemo?serverTimezone=GMT%2B8spring.shardingsphere.datasource.s0.username=rootspring.shardingsphere.datasource.s0.password=root# 读写分离规则，m0主库，s0从库spring.shardingsphere.sharding.master-slave-rules.ds0.master-data-source-name=m0spring.shardingsphere.sharding.master-slave-rules.ds0.slave-data-source-names[0]=s0# 基于读写分离的表分片spring.shardingsphere.sharding.tables.t_dict.actual-data-nodes=ds0.t_dict# 指定t_dict表里中主键dict_id生成策略SNOWFLAKEspring.shardingsphere.sharding.tables.t_dict.key-generator.column=dict_idspring.shardingsphere.sharding.tables.t_dict.key-generator.type=SNOWFLAKEspring.shardingsphere.sharding.tables.t_dict.key-generator.props.worker.id=1# 打开sql输出日志spring.shardingsphere.props.sql.show = true# 一个实体类对应两张表，覆盖spring.main.allow-bean-definition-overriding=true 核心原理 解析引擎解析过程分为词法解析和语法解析，词法解析器用于将SQL拆解为不可再分的原子符号称为**Token，并根据不同数据库方言所提供的字典，将其归类为关键字、表达式、字面量和操作符，再使用语法解析器将SQL转换为Abstract Syntax Tree抽象语法树**简称AST。 1SELECT id, name FROM t_user WHERE status = &#x27;ACTIVE&#x27; AND age &gt; 18 SQL解析是整个分库分表的核心，其性能和兼容性是最重要的衡量指标，灰色表示需要进⼀步拆分，关键字的Token用绿色表示。 路由引擎根据解析上下文匹配数据库和表的分片策略，生成路由路径，**ShardingSphere分片策略主要分为单片路由即分片键操作符是等号、多片路由即分片键的操作符是IN和范围路由即分片键的操作符是Between，不携带分片键的SQL则是广播路由**。 分片策略通常可由数据库内置也可由用户方配置，内置分片策略大致可分为尾数取模、哈希、范围、标签、时间等，由用户方配置的分片策略则更加灵活，可根据使用方需求定制复合分片策略。实际使用时应尽量使用分片路由明确路由策略，因为广播路由影响过大不利于集群管理及扩展。 全库表路由：不带分片键的**DQL、DML、DDL语句会遍历所有库表逐一执行。如select * from course或select * from course where ustatus=&#39;1&#39;**不带分片键 全库路由：对数据库的操作都会遍历所有真实库，如**set autocommit=0** 全实例路由：**DCL语句每个数据库实例只执行一次，如**CREATE USER customer@127.0.0.1 identified BY &#39;123&#39;; 单播路由：从任意库中获取数据即可，如**DESCRIBE course** 阻断路由：屏蔽SQL对数据库的操作，如**USE coursedb**不会在真实库中执行，虚拟表操作不需要切换数据库 改写引擎只需要面向逻辑库和逻辑表来写SQL，最终由**ShardigSphere的改写引擎将SQL改写为在真实数据库中可正确执行的语句，SQL改写分为正确性改写和优化改写**。 执行引擎ShardingSphere并不是简单的将改写完的SQL提交到数据库执行，执行引擎的目标是自动化的平衡资源控制和执行效率。连接模式分为**内存限制模式MEMORY_STRICTLY和连接限制模式CONNECTION_STRICTLY**。 内存限制模式：只关注一个数据库连接的处理数量，通常一张真实表一个数据库连接 连接限制模式：只关注数据库连接的数量，较大的查询会进行串行操作 这两个模式通过**spring.shardingsphere.props.max.connections.size.per.query=50参数配置，默认值为1，参见源码ConfigurationPropertyKey类。ShardingSphere会根据路由到某一个数据源的路由结果计算出所有需在数据库上执行的SQL数量，用该数量除以用户的配置项，得到每个数据库连接需执行的SQL数量。若数量&gt;1选择连接限制模式，数量&lt;=1就会选择内存限制模式**。 内存限制模式不限制连接数，建立多个数据连接并发控制每个连接只去读取一个数据分片的数据，可最快把所有需要的数据读出来。且在归并阶段选择以每一条数据为单位进行归并即流式归并，归并完一批数据后释放内存，可很好的提高数据归并的效率，且防止出现内存溢出或垃圾回收频繁，吞吐量比较大，适合**OLAP**场景 连接限制模式限制连接数，至少有一个数据库连接会要去读取多个数据分片的数据，数据库连接采用串行方式依次读取多个数据分片的数据，将数据全部读到内存，进行统一数据归并即内存归并，归并效率会比较高适合**OLTP**场景 归并引擎将从各个数据节点获取的多数据结果集，组合成为一个结果集并正确的返回至请求客户端，有流式归并和内存归并两种归并方式： 流式归并：一条一条数据的方式进行归并 内存归并：将所有结果集都查询到内存中进行统一归并 分布式主键内置生成器支持**UUID和SNOWFLAKE**，并抽离出分布式主键生成器的接口，方便用户自行实现自定义的自增主键生成器。 UUID采用UUID.randomUUID()的方式产生唯一且不重复的分布式主键。最终生成一个字符串类型的主键。缺点是生成的主键无序。 SNOWFLAKE雪花算法能保证不同进程主键不重复相同进程主键有序，二进制形式包含4部分，从高位到低位分表为：**1bit符号位、41bit时间戳位、10bit工作进程位，12bit序列号位。毫秒数在高位自增序列在低位，整个ID趋势递增；不依赖第三方组件稳定性高，生成ID性能也非常高；可根据自身业务特性分配bit位，非常灵活；但强依赖机器时钟，若机器上时钟回拨会导致发号重复**。 1bit符号位：预留的符号位恒为零 41bit时间戳位：41位时间戳可容纳毫秒数为2的41次幂，一年所使用的毫秒数为**365 * 24 * 60 * 60 * 1000 Math.pow(2, 41) / (365 * 24 * 60 * 60 * 1000L) = 69.73**年不重复 10bit工作进程位：该标志Java进程内唯一，若分布式应用部署应保证每个工作进程的id不同，默认为0，可通过属性设置 12bit序列号位：该序列用来在同一个毫秒内生成不同的ID，若在该毫秒内生成数量超过**4096**即2的12次幂，则生成器会等待到下个毫秒继续生成。 SQL使用限制支持的SQL123456789101112131415161718192021222324SELECT * FROM tbl_name SELECT * FROM tbl_name WHERE (col1 = ? or col2 = ?) and col3 = ? SELECT * FROM tbl_name WHERE col1 = ? ORDER BY col2 DESC LIMIT ? SELECT COUNT(*), SUM(col1), MIN(col1), MAX(col1), AVG(col1) FROM tbl_name WHERE col1 = ? SELECT COUNT(col1) FROM tbl_name WHERE col2 = ? GROUP BY col1 ORDER BY col3 DESC LIMIT ?, ? INSERT INTO tbl_name (col1, col2,…) VALUES (?, ?, ….) INSERT INTO tbl_name VALUES (?, ?,….) INSERT INTO tbl_name (col1, col2, …) VALUES (?, ?, ….), (?, ?, ….) -- INSERT表和SELECT表必须为相同表或绑定表INSERT INTO tbl_name (col1, col2, …) SELECT col1, col2, … FROM tbl_name WHERE col3 = ?-- REPLACE表和SELECT表必须为相同表或绑定表REPLACE INTO tbl_name (col1, col2, …) SELECT col1, col2, … FROM tbl_name WHERE col3 = ?UPDATE tbl_name SET col1 = ? WHERE col2 = ? DELETE FROM tbl_name WHERE col1 = ? CREATE TABLE tbl_name (col1 int, …) ALTER TABLE tbl_name ADD col1 varchar(10) DROP TABLE tbl_name TRUNCATE TABLE tbl_name CREATE INDEX idx_name ON tbl_name DROP INDEX idx_name ON tbl_name DROP INDEX idx_name SELECT DISTINCT * FROM tbl_name WHERE col1 = ? SELECT COUNT(DISTINCT col1) FROM tbl_name SELECT subquery_alias.col1 FROM (select tbl_name.col1 from tbl_name where tbl_name.col2=?) subquery_alias 不支持的SQL123456789101112131415161718-- VALUES语句不支持运算表达式INSERT INTO tbl_name (col1, col2, …) VALUES(1+2, ?, …)-- SELECT子句暂不支持使用*号简写及内置的分布式主键生成器INSERT INTO tbl_name (col1, col2, …) SELECT * FROM tbl_name WHERE col3 = ?-- SELECT子句暂不支持使用*号简写及内置的分布式主键生成器REPLACE INTO tbl_name (col1, col2, …) SELECT * FROM tbl_name WHERE col3 = ?-- UNIONSELECT * FROM tbl_name1 UNION SELECT * FROM tbl_name2-- UNION ALLSELECT * FROM tbl_name1 UNION ALL SELECT * FROM tbl_name2-- 详见DISTINCT支持情况详细说明SELECT SUM(DISTINCT col1), SUM(col1) FROM tbl_name-- 会导致全路由SELECT * FROM tbl_name WHERE to_date(create_time, &#x27;yyyy-mm-dd&#x27;) = ?-- 暂不支持加括号的查询(SELECT * FROM tbl_name)-- 查询列是函数表达式时，查询列前不能使用表名，若查询表存在别名，则可使用表的别名SELECT MAX(tbl_name.col1) FROM tbl_name DISTINCT支持的SQL1234567891011121314SELECT DISTINCT * FROM tbl_name WHERE col1 = ?SELECT DISTINCT col1 FROM tbl_nameSELECT DISTINCT col1, col2, col3 FROM tbl_nameSELECT DISTINCT col1 FROM tbl_name ORDER BY col1SELECT DISTINCT col1 FROM tbl_name ORDER BY col2SELECT DISTINCT(col1) FROM tbl_nameSELECT AVG(DISTINCT col1) FROM tbl_nameSELECT SUM(DISTINCT col1) FROM tbl_nameSELECT COUNT(DISTINCT col1) FROM tbl_nameSELECT COUNT(DISTINCT col1) FROM tbl_name GROUP BY col1SELECT COUNT(DISTINCT col1 + col2) FROM tbl_nameSELECT COUNT(DISTINCT col1), SUM(DISTINCT col1) FROM tbl_nameSELECT COUNT(DISTINCT col1), col1 FROM tbl_name GROUP BY col1SELECT col1, COUNT(DISTINCT col1) FROM tbl_name GROUP BY col1 DISTINCT不支持的SQL12-- 查询列是函数表达式时，查询列前不能使用表名，若查询表存在别名，则可使用表的别名SELECT SUM(DISTINCT tbl_name.col1), SUM(tbl_name.col1) FROM tbl_name","tags":[{"name":"DB","slug":"DB","permalink":"http://example.com/tags/DB/"}],"categories":[{"name":"DB","slug":"DB","permalink":"http://example.com/categories/DB/"}]},{"title":"消息队列","date":"2021-03-23T02:00:20.000Z","path":"blog/工具和中间件/消息队列/消息队列/","text":"什么是消息中间件呢？以公众号为例，如果某用户订阅（关注）了这个公众号，每当管理员发布新文章的时候，都可以在这个公众号得到通知，这就是一种广播订阅模式。 公众号如何实现这一点呢？ 可以通过 消息中间件 来轻松实现。 管理员把最新的教程信息 发给 消息中间件服务器， 用户手机上的微信里的 消息中间件客户端，就会自动去把消息获取出来显示，这样管理员就达到了文章广播的效果了。 消息队列的作用： 应用耦合：多应用间通过消息队列对同一消息进行处理，避免调用接口失败导致整个过程失败； 异步处理：多应用对消息队列中同一消息进行处理，应用间并发处理消息，相比串行处理，减少处理时间； 限流削峰：广泛应用于秒杀或抢购活动中，避免流量过大导致应用系统挂掉的情况； 消息驱动的系统：系统分为消息队列、消息生产者、消息消费者，生产者负责产生消息，消费者(可能有多个)负责对消息进行处理； 选择消息队列要满足以下几个条件： 开源 流行 兼容性强 消息队列需要： 消息的可靠传递：确保不丢消息； 性能：具备足够好的性能，能满足绝大多数场景的性能要求。 Cluster：支持集群，确保不会因为某个节点宕机导致服务不可用，当然也不能丢消息； 实现选择：消息中间件有很多种，如 Activemq, Rabbitmq, RocketMQ, Kafka 等等 几种常见MQ的对比:","tags":[],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"}]},{"title":"事务调用原理","date":"2020-10-23T11:52:21.000Z","path":"blog/Spring/事务调用原理/","text":"@Transactional 生效的方法的调用，还是走 AOP代理调用逻辑，即通过 ReflectiveMethodInvocation 的 proceed() 调用逻辑，不过这里调用的拦截器链不是通过注解自定义配置的，而是在 ProxyTransactionManagementConfiguration 配置类中配置的 TransactionInterceptor 。 12345678public class TransactionInterceptor extends TransactionAspectSupport implements MethodInterceptor, Serializable &#123; public Object invoke(MethodInvocation invocation) throws Throwable &#123; // 获取代理对象的class属性 Class&lt;?&gt; targetClass = (invocation.getThis() != null ? AopUtils.getTargetClass(invocation.getThis()) : null); // 在事务中执行目标方法，在这埋了一个钩子函数invocation::proceed，用来回调目标方法 return invokeWithinTransaction(invocation.getMethod(), targetClass, invocation::proceed); &#125;&#125; 这里解释事务的核心逻辑，首先通过事务属性主要是传播属性是否为嵌套事务等判断是否有必要创建事务，然后通过 invocation.proceedWithInvocation() 函数式接口回到 ReflectiveMethodInvocation 的 proceed() 中去调用真正的目标方法，若调用目标方法抛出异常，则会走事务回滚逻辑，否则提交事务。 TransactionAttributeSource配置类中导入的，TransactionAttribute做切点匹配时已经解析完成其包含事务属性，PlatformTransactionManager是配置类中添加其包含数据源，连接点标识符joinpointIdentification是匹配事务时得到的并设置到事务属性的 descriptor 中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public abstract class TransactionAspectSupport implements BeanFactoryAware, InitializingBean &#123; protected Object invokeWithinTransaction(Method method, @Nullable Class&lt;?&gt; targetClass, final InvocationCallback invocation) throws Throwable &#123; // 获取在配置类中添加的事务属源对象，在创建代理进行匹配时将解析的事务属性赋值 TransactionAttributeSource tas = getTransactionAttributeSource(); // 获取解析后的事务属性信息，创建代理时已调用getTransactionAttribute，这里从解析后的缓存中获取 final TransactionAttribute txAttr = (tas != null ? tas.getTransactionAttribute(method, targetClass) : null); // 获取配置的事务管理器对象 final PlatformTransactionManager tm = determineTransactionManager(txAttr); // 从tx属性对象中获取出标注了@Transactionl的方法描述符 final String joinpointIdentification = methodIdentification(method, targetClass, txAttr); if (txAttr == null || !(tm instanceof CallbackPreferringPlatformTransactionManager)) &#123; // 处理声明式事务 // 若有必要创建事务 TransactionInfo txInfo = createTransactionIfNecessary(tm, txAttr, joinpointIdentification); Object retVal; try &#123; retVal = invocation.proceedWithInvocation(); // 调用钩子函数进行回调目标方法 &#125; catch (Throwable ex) &#123; // 抛出异常进行回滚处理 completeTransactionAfterThrowing(txInfo, ex); throw ex; &#125; finally &#123; cleanupTransactionInfo(txInfo); // 清空我们的线程变量中transactionInfo的值 &#125; commitTransactionAfterReturning(txInfo); // 提交事务 return retVal; &#125; else &#123; // 编程式事务：（回调偏向） final ThrowableHolder throwableHolder = new ThrowableHolder(); try &#123; Object result = ((CallbackPreferringPlatformTransactionManager) tm).execute(txAttr, status -&gt; &#123; TransactionInfo txInfo = prepareTransactionInfo(tm, txAttr, joinpointIdentification, status); try &#123; return invocation.proceedWithInvocation(); &#125; catch (Throwable ex) &#123; if (txAttr.rollbackOn(ex)) &#123; if (ex instanceof RuntimeException) &#123; throw (RuntimeException) ex; &#125; else &#123; throw new ThrowableHolderException(ex); &#125; &#125; else &#123; throwableHolder.throwable = ex; return null; &#125; &#125; finally &#123; cleanupTransactionInfo(txInfo); &#125; &#125;); if (throwableHolder.throwable != null) &#123; throw throwableHolder.throwable; &#125; return result; &#125; catch (ThrowableHolderException ex) &#123; throw ex.getCause(); &#125; catch (TransactionSystemException ex2) &#123; if (throwableHolder.throwable != null) &#123; ex2.initApplicationException(throwableHolder.throwable); &#125; throw ex2; &#125; catch (Throwable ex2) &#123; throw ex2; &#125; &#125; &#125;&#125; 若事务没有定义名称，则把连接点的名称定义成事务的名称，然后获取当前事务状态，并将事物状态和事物属性等信息封装成一个TransactionInfo对象便于后续使用。 1234567891011121314151617181920212223242526272829public abstract class TransactionAspectSupport implements BeanFactoryAware, InitializingBean &#123; protected TransactionInfo createTransactionIfNecessary(@Nullable PlatformTransactionManager tm, @Nullable TransactionAttribute txAttr, final String joinpointIdentification) &#123; // 若没定义名字，把连接点的名称定义成事务的名称 if (txAttr != null &amp;&amp; txAttr.getName() == null) &#123; txAttr = new DelegatingTransactionAttribute(txAttr) &#123; @Override public String getName() &#123; return joinpointIdentification; &#125; &#125;; &#125; TransactionStatus status = null; if (txAttr != null) &#123; if (tm != null) &#123;//获取一个事务状态 status = tm.getTransaction(txAttr); &#125; &#125; // 把事物状态和事物属性等信息封装成一个TransactionInfo对象 return prepareTransactionInfo(tm, txAttr, joinpointIdentification, status); &#125; protected TransactionInfo prepareTransactionInfo(@Nullable PlatformTransactionManager tm, @Nullable TransactionAttribute txAttr, String joinpointIdentification, @Nullable TransactionStatus status) &#123; TransactionInfo txInfo = new TransactionInfo(tm, txAttr, joinpointIdentification); if (txAttr != null) &#123; txInfo.newTransactionStatus(status); &#125; txInfo.bindToThread(); //把事务信息对象绑定到当前线程变量中 return txInfo; &#125;&#125; 在执行事务前会将上层事务状态，从事务信息线程本地变量中获取存入 oldTransactionInfo ，若为顶层事务该值肯定为null，但嵌套事务肯定不为null，当执行完用户代码逻辑后在finally中调用 cleanupTransactionInfo 从而调用 restoreThreadLocalStatus 将上层事务信息再返回线程本地变量中。 123456789101112protected static final class TransactionInfo &#123; public void newTransactionStatus(@Nullable TransactionStatus status) &#123; this.transactionStatus = status; &#125; private void bindToThread() &#123; this.oldTransactionInfo = transactionInfoHolder.get(); transactionInfoHolder.set(this); &#125; private void restoreThreadLocalStatus() &#123; transactionInfoHolder.set(this.oldTransactionInfo); &#125;&#125; 首先 New 一个事务对象 DataSourceTransactionObject ，其实主要是看数据库连接持有者 ConnectionHolder 是否存在，然后判断是否已存在事务对象，判断依据是通过事务对象中的是否存在ConnectionHolder，以及ConnectionHolder中事务是否已经激活，若已经存在事务说明是嵌套事务，则走 handleExistingTransaction 单独的嵌套事务逻辑。若不存在说明是新事务，则根据事务的传播属性进行相关的逻辑处理。 当事务传播行为是 MANDATORY 直接抛出异常，当事务传播行为是 REQUIRED 、 REQUIRES_NEW 、 NESTED 将开启一个新事务，首先挂起当前事务，由于顶层事务当前还没创建事务不需要挂起，故suspend(null)传入null。newSynchronization允许开启同步事务，status构造事务状态对象并将事务信息封装进去，然后 doBegin 开启一个新事务，最后将当前事务信息绑定到线程本地变量中，为嵌套事务提供支持。 事务传播行为类型 外部不存在事务 外部存在事务 备注 REQUIRED （默认） 开启新事务 融合到外部事务中 外层影响内层，内层影响外层 SUPPORTS 不开启新事务 融合到外部事务中 外层影响内层，内层影响外层 REQUIRES_NEW 开启新事务 挂起外部事务，创建新的事务 外层影响内层，内层影响外层 NOT_SUPPORTED 不开启新事务 挂起外部事务，不开启事务 外层影响内层，内层影响外层 且内层没有事务，即使异常也不滚 NEVER 不开启新事务 抛出异常 不常用 MANDATORY 抛出异常 融合到外部事务中 外层影响内层，内层影响外层 NESTED 开启新事务 融合到外部事务中，SavePoint机制 外层影响内层，内层不会影响外层 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public abstract class AbstractPlatformTransactionManager implements PlatformTransactionManager, Serializable &#123; public final TransactionStatus getTransaction(@Nullable TransactionDefinition definition) throws TransactionException &#123; Object transaction = doGetTransaction(); // 尝试获取一个事务对象 // Cache debug flag to avoid repeated checks. boolean debugEnabled = logger.isDebugEnabled(); if (definition == null) &#123; // 判断从上一个方法传递进来的事务属性是不是为空 definition = new DefaultTransactionDefinition(); &#125; if (isExistingTransaction(transaction)) &#123; // 判断是不是已经存在了事务对象（事务嵌套） return handleExistingTransaction(definition, transaction, debugEnabled);//处理存在的事务 &#125; if (definition.getTimeout() &lt; TransactionDefinition.TIMEOUT_DEFAULT) &#123;//检查事务设置的超时时间 throw new InvalidTimeoutException(&quot;Invalid transaction timeout&quot;, definition.getTimeout()); &#125; // 若当前的事务属性为PROPAGATION_MANDATORY表示必须运行在事务中，若当前没有事务就抛出异常 // 由于isExistingTransaction(transaction)跳过了这里，说明当前是不存在事务的，那么就会抛出异常 if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_MANDATORY) &#123; throw new IllegalTransactionStateException(&quot;No existing transaction found for transaction marked with propagation &#x27;mandatory&#x27;&quot;); &#125; // PROPAGATION_REQUIRED：当前存在事务就加入到当前的事务，没有就新开一个 // PROPAGATION_REQUIRES_NEW：新开一个事务,若当前存在事务就挂起当前事务 // PROPAGATION_NESTED： 表示若当前正有一个事务在运行中，则该方法应该运行在一个嵌套的事务中， // 被嵌套的事务可独立于封装事务进行提交或回滚(保存点)，若封装事务不存在，行为就像PROPAGATION_REQUIRES_NEW else if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_REQUIRED || definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_REQUIRES_NEW || definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_NESTED) &#123; // 经过上面的isExistingTransaction(transaction)判断当前是不存在事务的，故在此处是挂起当前事务传递一个null进去 SuspendedResourcesHolder suspendedResources = suspend(null); try &#123; boolean newSynchronization = (getTransactionSynchronization() != SYNCHRONIZATION_NEVER); // 可进行同步 // 构造事务状态对象，newTransaction=true代表是一个新事务 DefaultTransactionStatus status = newTransactionStatus(definition, transaction, true, newSynchronization, debugEnabled, suspendedResources); doBegin(transaction, definition); //开启一个新的事物 prepareSynchronization(status, definition);// 把当前的事务信息绑定到线程本地变量中 return status; &#125; catch (RuntimeException | Error ex) &#123; resume(null, suspendedResources); throw ex; &#125; &#125; else &#123; //创建一个空的事务 boolean newSynchronization = (getTransactionSynchronization() == SYNCHRONIZATION_ALWAYS); return prepareTransactionStatus(definition, null, true, newSynchronization, debugEnabled, null); &#125; &#125;&#125; TransactionSynchronizationManager事务同步管理器对象，该类中都是局部线程变量，用来保存当前事务的信息，第一次从这里去线程变量中获取事务连接持有器对象，通过数据源为key去获取，由于第一次进来开始事务，事务同步管理器中没有被存放，所以此时获取出来的conHolder为null。 doBegin 中首先判断事务对象有没有数据库连接持有器，对于顶层事务明显是没有，则从数据源中获取一个 Connection 连接，然后新建一个将 ConnectionHolder 并将其设置其中，将synchronizedWithTransaction属性设置为true，通过将autoCommit属性这是为false来开启一个事务，将ConnectionHolder的 transactionActive 属性设置为 true ，为嵌套事务做准备，最后将该数据源的该连接存入事务同步管理器中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class DataSourceTransactionManager extends AbstractPlatformTransactionManager implements ResourceTransactionManager, InitializingBean &#123; protected Object doGetTransaction() &#123; DataSourceTransactionObject txObject = new DataSourceTransactionObject(); // 创建一个数据源事务对象 txObject.setSavepointAllowed(isNestedTransactionAllowed()); // 是否允许当前事务设置保持点 ConnectionHolder conHolder = (ConnectionHolder) TransactionSynchronizationManager.getResource(obtainDataSource()); txObject.setConnectionHolder(conHolder, false); return txObject; //返回事务对象 &#125; protected boolean isExistingTransaction(Object transaction) &#123; DataSourceTransactionObject txObject = (DataSourceTransactionObject) transaction; // 若第一次进来开始事务，txObject.hasConnectionHolder()返回的null，表示不存在事务 return (txObject.hasConnectionHolder() &amp;&amp; txObject.getConnectionHolder().isTransactionActive()); &#125; protected void doBegin(Object transaction, TransactionDefinition definition) &#123; DataSourceTransactionObject txObject = (DataSourceTransactionObject) transaction; // 强制转换事物对象 Connection con = null; try &#123; // 判断事务对象没有数据库连接持有器 if (!txObject.hasConnectionHolder() || txObject.getConnectionHolder().isSynchronizedWithTransaction()) &#123; Connection newCon = obtainDataSource().getConnection(); // 若没有，则通过数据源获取一个数据库连接对象 // 把数据库连接包装成一个ConnectionHolder对象，然后设置到txObject对象中去 txObject.setConnectionHolder(new ConnectionHolder(newCon), true); &#125; // 标记当前的连接是一个同步事务 txObject.getConnectionHolder().setSynchronizedWithTransaction(true); con = txObject.getConnectionHolder().getConnection(); // 设置isReadOnly、隔离级别 Integer previousIsolationLevel = DataSourceUtils.prepareConnectionForTransaction(con, definition); txObject.setPreviousIsolationLevel(previousIsolationLevel); // setAutoCommit默认为true，即每条SQL语句在各自的一个事务中执行。 if (con.getAutoCommit()) &#123; txObject.setMustRestoreAutoCommit(true); if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Switching JDBC Connection [&quot; + con + &quot;] to manual commit&quot;); &#125; con.setAutoCommit(false); // 开启事务 &#125; prepareTransactionalConnection(con, definition); // 判断事务为只读事务 txObject.getConnectionHolder().setTransactionActive(true); // 设置事务激活 int timeout = determineTimeout(definition); // 设置事务超时时间 if (timeout != TransactionDefinition.TIMEOUT_DEFAULT) &#123; txObject.getConnectionHolder().setTimeoutInSeconds(timeout); &#125; // 绑定数据源和连接到同步管理器上，把数据源作为key，数据库连接作为value，设置到线程本地变量中 if (txObject.isNewConnectionHolder()) &#123; TransactionSynchronizationManager.bindResource(obtainDataSource(), txObject.getConnectionHolder()); &#125; &#125; catch (Throwable ex) &#123; if (txObject.isNewConnectionHolder()) &#123; DataSourceUtils.releaseConnection(con, obtainDataSource()); // 释放数据库连接 txObject.setConnectionHolder(null, false); &#125; throw new CannotCreateTransactionException(&quot;Could not open JDBC Connection for transaction&quot;, ex); &#125; &#125;&#125; 123456789101112131415public abstract class AbstractPlatformTransactionManager implements PlatformTransactionManager, Serializable &#123; protected void prepareSynchronization(DefaultTransactionStatus status, TransactionDefinition definition) &#123; if (status.isNewSynchronization()) &#123; //绑定事务激活 TransactionSynchronizationManager.setActualTransactionActive(status.hasTransaction()); //当前事务的隔离级别 TransactionSynchronizationManager.setCurrentTransactionIsolationLevel(definition.getIsolationLevel() != TransactionDefinition.ISOLATION_DEFAULT ? definition.getIsolationLevel() : null); //是否为只读事务 TransactionSynchronizationManager.setCurrentTransactionReadOnly(definition.isReadOnly()); //事务的名称 TransactionSynchronizationManager.setCurrentTransactionName(definition.getName()); TransactionSynchronizationManager.initSynchronization(); &#125; &#125;&#125; 若执行异常则回滚事务，否则提交事务，不论是提交事务还是回滚事务之前都做了一个判断，当 status.isNewTransaction() 为 false 时不会去执行响应的提交或回滚逻辑，主要是为了支持融合事务。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100public abstract class AbstractPlatformTransactionManager implements PlatformTransactionManager, Serializable &#123; private void processRollback(DefaultTransactionStatus status, boolean unexpected) &#123; try &#123; boolean unexpectedRollback = unexpected; try &#123; triggerBeforeCompletion(status); if (status.hasSavepoint()) &#123; status.rollbackToHeldSavepoint(); &#125; else if (status.isNewTransaction()) &#123; doRollback(status); &#125; else &#123; if (status.hasTransaction()) &#123; if (status.isLocalRollbackOnly() || isGlobalRollbackOnParticipationFailure()) &#123; doSetRollbackOnly(status); &#125; &#125; if (!isFailEarlyOnGlobalRollbackOnly()) &#123; unexpectedRollback = false; &#125; &#125; &#125; catch (RuntimeException | Error ex) &#123; triggerAfterCompletion(status, TransactionSynchronization.STATUS_UNKNOWN); throw ex; &#125; triggerAfterCompletion(status, TransactionSynchronization.STATUS_ROLLED_BACK); if (unexpectedRollback) &#123; throw new UnexpectedRollbackException(&quot;Transaction rolled back because it has been marked as rollback-only&quot;); &#125; &#125; finally &#123; cleanupAfterCompletion(status); &#125; &#125; private void processCommit(DefaultTransactionStatus status) throws TransactionException &#123; try &#123; boolean beforeCompletionInvoked = false; try &#123; boolean unexpectedRollback = false; prepareForCommit(status); triggerBeforeCommit(status); triggerBeforeCompletion(status); beforeCompletionInvoked = true; if (status.hasSavepoint()) &#123; unexpectedRollback = status.isGlobalRollbackOnly(); status.releaseHeldSavepoint(); &#125; else if (status.isNewTransaction()) &#123; unexpectedRollback = status.isGlobalRollbackOnly(); doCommit(status); &#125; else if (isFailEarlyOnGlobalRollbackOnly()) &#123; unexpectedRollback = status.isGlobalRollbackOnly(); &#125; if (unexpectedRollback) &#123; throw new UnexpectedRollbackException(&quot;Transaction silently rolled back because it has been marked as rollback-only&quot;); &#125; &#125; catch (UnexpectedRollbackException ex) &#123; triggerAfterCompletion(status, TransactionSynchronization.STATUS_ROLLED_BACK); throw ex; &#125; catch (TransactionException ex) &#123; if (isRollbackOnCommitFailure()) &#123; doRollbackOnCommitException(status, ex); &#125; else &#123; triggerAfterCompletion(status, TransactionSynchronization.STATUS_UNKNOWN); &#125; throw ex; &#125; catch (RuntimeException | Error ex) &#123; if (!beforeCompletionInvoked) &#123; triggerBeforeCompletion(status); &#125; doRollbackOnCommitException(status, ex); throw ex; &#125; try &#123; triggerAfterCommit(status); &#125; finally &#123; triggerAfterCompletion(status, TransactionSynchronization.STATUS_COMMITTED); &#125; &#125; finally &#123; cleanupAfterCompletion(status); &#125; &#125;&#125;public class DataSourceTransactionManager extends AbstractPlatformTransactionManager implements ResourceTransactionManager, InitializingBean &#123; protected void doRollback(DefaultTransactionStatus status) &#123; DataSourceTransactionObject txObject = (DataSourceTransactionObject) status.getTransaction(); Connection con = txObject.getConnectionHolder().getConnection(); try &#123; con.rollback(); &#125; catch (SQLException ex) &#123; throw new TransactionSystemException(&quot;Could not roll back JDBC transaction&quot;, ex); &#125; &#125; protected void doCommit(DefaultTransactionStatus status) &#123; DataSourceTransactionObject txObject = (DataSourceTransactionObject) status.getTransaction(); Connection con = txObject.getConnectionHolder().getConnection(); try &#123; con.commit(); &#125; catch (SQLException ex) &#123; throw new TransactionSystemException(&quot;Could not commit JDBC transaction&quot;, ex); &#125; &#125;&#125; 存在嵌套事务要触发嵌套事务，若调用的是本类方法一点要保证将动态代理暴露在线程中并结合 AopContext 使用。嵌套事务的处理同样是根据事务的传播性来处理的。若事务传播性为 NEVER 则嵌套事务直接抛出异常； 若事务传播性为 REQUIRES_NEW 则挂起外部事务，然后创建一个新的事务，并将旧的事务信息暂存，执行事务和顶层事务没什么区别； 若事务传播性为 SUPPORTS 则融合到外部事务中，返回的事务状态中 newTransaction 和 newSynchronization 属性都为 false ，事务的 newConnectionHolder 和 mustRestoreAutoCommit 属性也为默认值 false ，由于 newSynchronization 属性为false这内部事务执行完后提交事务 triggerAfterCommit 中不会做任务处理，当内部事务执行完毕后交由外部事务处理相关提交事务和回滚事务逻辑； 若事务传播性为 NOT_SUPPORTED 则挂起外部事务，返回的事务状态中 transaction 属性为 null ， newTransaction 属性为false， newSynchronization 属性为true，故执行完后也不会有事务的提交。 若事务传播性为 NESTED 则融合到外部事务中，且创建一个保存点，返回的事务状态中， newTransaction 和 newSynchronization 属性为false。这里的内层不影响外层指的是可将内层异常捕获，内层事务回滚，外层事务正常提交，若是其他几种融合到外部事务的传播属性捕获异常会导致程序异常，因为其在回滚时会通过 doSetRollbackOnly(status) 将事务设置为只能回滚的，若捕获内层异常，在外层事务提交时将抛出异常。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public abstract class AbstractPlatformTransactionManager implements PlatformTransactionManager, Serializable &#123; private TransactionStatus handleExistingTransaction(TransactionDefinition definition, Object transaction, boolean debugEnabled) throws TransactionException &#123; // NEVER存在外部事务则抛出异常 if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_NEVER) &#123; throw new IllegalTransactionStateException(&quot;Existing transaction found for transaction marked with propagation &#x27;never&#x27;&quot;); &#125; // NOT_SUPPORTED存在外部事务则挂起外部事务 if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_NOT_SUPPORTED) &#123; // 挂起存在的事物 Object suspendedResources = suspend(transaction); boolean newSynchronization = (getTransactionSynchronization() == SYNCHRONIZATION_ALWAYS); // 创建一个新的非事物状态，保存了上一个存在事物状态的属性 return prepareTransactionStatus(definition, null, false, newSynchronization, debugEnabled, suspendedResources); &#125; // REQUIRES_NEW存在外部事务则挂起外部事务，创建新的事务 if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_REQUIRES_NEW) &#123; // 挂起已经存在的事物 SuspendedResourcesHolder suspendedResources = suspend(transaction); try &#123; // 是否需要新开启同步 boolean newSynchronization = (getTransactionSynchronization() != SYNCHRONIZATION_NEVER); //创建一个新的事物状态(包含了挂起的事务的属性) DefaultTransactionStatus status = newTransactionStatus(definition, transaction, true, newSynchronization, debugEnabled, suspendedResources); //开启新的事物 doBegin(transaction, definition); //把新的事物状态设置到当前的线程变量中去 prepareSynchronization(status, definition); return status; &#125; catch (RuntimeException | Error beginEx) &#123; resumeAfterBeginException(transaction, suspendedResources, beginEx); throw beginEx; &#125; &#125; // NESTED存在外部事务则融合到外部事务中，应用层面和REQUIRED一样，源码层面 if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_NESTED) &#123; if (!isNestedTransactionAllowed()) &#123; throw new NestedTransactionNotSupportedException(&quot;Transaction manager does not allow nested transactions by default - specify &#x27;nestedTransactionAllowed&#x27; property with value &#x27;true&#x27;&quot;); &#125; // 是否支持保存点：非JTA事务走这个分支。AbstractPlatformTransactionManager默认是true，JtaTransactionManager复写了该方法false，DataSourceTransactionManager没有复写，还是true, if (useSavepointForNestedTransaction()) &#123; //开启一个新的事物 DefaultTransactionStatus status = prepareTransactionStatus(definition, transaction, false, false, debugEnabled, null); // 为事物设置一个回退点，savepoint可以在一组事务中，设置一个回滚点，点以上的不受影响，点以下的回滚。即外层影响内层，内层不会影响外层 status.createAndHoldSavepoint(); return status; &#125; else &#123; // JTA事务走这个分支，创建新事务 boolean newSynchronization = (getTransactionSynchronization() != SYNCHRONIZATION_NEVER); DefaultTransactionStatus status = newTransactionStatus(definition, transaction, true, newSynchronization, debugEnabled, null); doBegin(transaction, definition); prepareSynchronization(status, definition); return status; &#125; &#125; // Assumably PROPAGATION_SUPPORTS or PROPAGATION_REQUIRED. if (isValidateExistingTransaction()) &#123; if (definition.getIsolationLevel() != TransactionDefinition.ISOLATION_DEFAULT) &#123; Integer currentIsolationLevel = TransactionSynchronizationManager.getCurrentTransactionIsolationLevel(); if (currentIsolationLevel == null || currentIsolationLevel != definition.getIsolationLevel()) &#123; Constants isoConstants = DefaultTransactionDefinition.constants; throw new IllegalTransactionStateException(&quot;Participating transaction with definition [&quot; + definition + &quot;] specifies isolation level which is incompatible with existing transaction: &quot; + (currentIsolationLevel != null ? isoConstants.toCode(currentIsolationLevel, DefaultTransactionDefinition.PREFIX_ISOLATION) : &quot;(unknown)&quot;)); &#125; &#125; if (!definition.isReadOnly()) &#123; if (TransactionSynchronizationManager.isCurrentTransactionReadOnly()) &#123; throw new IllegalTransactionStateException(&quot;Participating transaction with definition [&quot; + definition + &quot;] is not marked as read-only but existing transaction is&quot;); &#125; &#125; &#125; boolean newSynchronization = (getTransactionSynchronization() != SYNCHRONIZATION_NEVER); return prepareTransactionStatus(definition, transaction, false, newSynchronization, debugEnabled, null); &#125;&#125; 挂起外部事务其实就是将外部事务的从事务同步管理器即线程本地变量中获取到封装成一个 SuspendedResourcesHolder ，然后清空事务同步管理器中的数据。顶层事务这里返回 null 。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public abstract class AbstractPlatformTransactionManager implements PlatformTransactionManager, Serializable &#123; protected final SuspendedResourcesHolder suspend(@Nullable Object transaction) throws TransactionException &#123; // 嵌套事务 已经激活，在doBegin后激活 if (TransactionSynchronizationManager.isSynchronizationActive()) &#123; List&lt;TransactionSynchronization&gt; suspendedSynchronizations = doSuspendSynchronization(); try &#123; Object suspendedResources = null; if (transaction != null) &#123; suspendedResources = doSuspend(transaction); &#125; //获取已存在的事物的名称 String name = TransactionSynchronizationManager.getCurrentTransactionName(); //清空线程变量的 TransactionSynchronizationManager.setCurrentTransactionName(null); //获取出只读事务的名称 boolean readOnly = TransactionSynchronizationManager.isCurrentTransactionReadOnly(); //清空线程变量的 TransactionSynchronizationManager.setCurrentTransactionReadOnly(false); //获取已存在事务的隔离级别 Integer isolationLevel = TransactionSynchronizationManager.getCurrentTransactionIsolationLevel(); //清空隔离级别 TransactionSynchronizationManager.setCurrentTransactionIsolationLevel(null); //获取激活标志 boolean wasActive = TransactionSynchronizationManager.isActualTransactionActive(); //清空标记Actual=外层事务 TransactionSynchronizationManager.setActualTransactionActive(false); //把上诉从线程变量中获取出来的存在事务属性封装为挂起的事务属性返回出去 return new SuspendedResourcesHolder(suspendedResources, suspendedSynchronizations, name, readOnly, isolationLevel, wasActive); &#125; catch (RuntimeException | Error ex) &#123; doResumeSynchronization(suspendedSynchronizations); throw ex; &#125; &#125; else if (transaction != null) &#123; Object suspendedResources = doSuspend(transaction); return new SuspendedResourcesHolder(suspendedResources); &#125; else &#123; return null; &#125; &#125;&#125;public class DataSourceTransactionManager extends AbstractPlatformTransactionManager implements ResourceTransactionManager, InitializingBean &#123; protected Object doSuspend(Object transaction) &#123; DataSourceTransactionObject txObject = (DataSourceTransactionObject) transaction; txObject.setConnectionHolder(null); return TransactionSynchronizationManager.unbindResource(obtainDataSource()); &#125;&#125; 若为融合事务则 status.isNewSynchronization() 一定为 false ，则 prepareSynchronization 中不会做任何事情。 1234567891011121314151617181920public abstract class AbstractPlatformTransactionManager implements PlatformTransactionManager, Serializable &#123; protected final DefaultTransactionStatus prepareTransactionStatus(TransactionDefinition definition, @Nullable Object transaction, boolean newTransaction, boolean newSynchronization, boolean debug, @Nullable Object suspendedResources) &#123; DefaultTransactionStatus status = newTransactionStatus(definition, transaction, newTransaction, newSynchronization, debug, suspendedResources); prepareSynchronization(status, definition); return status; &#125; protected void prepareSynchronization(DefaultTransactionStatus status, TransactionDefinition definition) &#123; if (status.isNewSynchronization()) &#123; //绑定事务激活 TransactionSynchronizationManager.setActualTransactionActive(status.hasTransaction()); //当前事务的隔离级别 TransactionSynchronizationManager.setCurrentTransactionIsolationLevel(definition.getIsolationLevel() != TransactionDefinition.ISOLATION_DEFAULT ? definition.getIsolationLevel() : null); //是否为只读事务 TransactionSynchronizationManager.setCurrentTransactionReadOnly(definition.isReadOnly()); //事务的名称 TransactionSynchronizationManager.setCurrentTransactionName(definition.getName()); TransactionSynchronizationManager.initSynchronization(); &#125; &#125;&#125; 在执行完嵌套事务的内层事务后在finally中会调用cleanupAfterCompletion方法，并将上层事务resume，即将事务的相关信息放回事务同步管理器中。 12345678910111213141516171819202122232425262728293031323334353637private void cleanupAfterCompletion(DefaultTransactionStatus status) &#123; status.setCompleted(); if (status.isNewSynchronization()) &#123; TransactionSynchronizationManager.clear(); &#125; if (status.isNewTransaction()) &#123; doCleanupAfterCompletion(status.getTransaction()); &#125; if (status.getSuspendedResources() != null) &#123; if (status.isDebug()) &#123; logger.debug(&quot;Resuming suspended transaction after completion of inner transaction&quot;); &#125; Object transaction = (status.hasTransaction() ? status.getTransaction() : null); resume(transaction, (SuspendedResourcesHolder) status.getSuspendedResources()); &#125;&#125;protected final void resume(@Nullable Object transaction, @Nullable SuspendedResourcesHolder resourcesHolder) throws TransactionException &#123; if (resourcesHolder != null) &#123; Object suspendedResources = resourcesHolder.suspendedResources; if (suspendedResources != null) &#123; doResume(transaction, suspendedResources); &#125; List&lt;TransactionSynchronization&gt; suspendedSynchronizations = resourcesHolder.suspendedSynchronizations; if (suspendedSynchronizations != null) &#123; TransactionSynchronizationManager.setActualTransactionActive(resourcesHolder.wasActive); TransactionSynchronizationManager.setCurrentTransactionIsolationLevel(resourcesHolder.isolationLevel); TransactionSynchronizationManager.setCurrentTransactionReadOnly(resourcesHolder.readOnly); TransactionSynchronizationManager.setCurrentTransactionName(resourcesHolder.name); doResumeSynchronization(suspendedSynchronizations); &#125; &#125;&#125;protected void doResume(@Nullable Object transaction, Object suspendedResources) &#123; TransactionSynchronizationManager.bindResource(obtainDataSource(), suspendedResources);&#125;","tags":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}]},{"title":"事务解析原理","date":"2020-10-22T11:52:21.000Z","path":"blog/Spring/事务解析原理/","text":"事务的解析与执行是依赖AOP实现的，Spring中开启事务是通过 @EnableTransactionManagement 注解来完成的，在该注解上通过 @Import 为容器导入了一个组件 TransactionManagementConfigurationSelector ，该组件是一个 ImportSelector 其为容器注册一个为 AutoProxyRegistrar 的 ImportBeanDefinitionRegistrar 开启AOP代理，以及一个事务代理的配置类ProxyTransactionManagementConfiguration 导入关于事务的切面信息。 12345678910111213141516171819public class TransactionManagementConfigurationSelector extends AdviceModeImportSelector&lt;EnableTransactionManagement&gt; &#123; // 在容器中加载Bean定义时回调selectImports方法，该方法返回值需要导入类的全类名路径，然后这个类会被加载到容器中 @Override protected String[] selectImports(AdviceMode adviceMode) &#123; switch (adviceMode) &#123; // 为容器中导入AutoProxyRegistrar、ProxyTransactionManagementConfiguration case PROXY: return new String[] &#123;AutoProxyRegistrar.class.getName(), ProxyTransactionManagementConfiguration.class.getName()&#125;; case ASPECTJ: // 绝大部分情况下，不会使用AspectJ的静态代理的 return new String[] &#123;TransactionManagementConfigUtils.TRANSACTION_ASPECT_CONFIGURATION_CLASS_NAME&#125;; default: return null; &#125; &#125; private String determineTransactionAspectClass() &#123; return (ClassUtils.isPresent(&quot;javax.transaction.Transactional&quot;, getClass().getClassLoader()) ? TransactionManagementConfigUtils.JTA_TRANSACTION_ASPECT_CONFIGURATION_CLASS_NAME : TransactionManagementConfigUtils.TRANSACTION_ASPECT_CONFIGURATION_CLASS_NAME); &#125;&#125; AdviceModeImportSelector 目前所知有 AsyncConfigurationSelector 、 TransactionManagementConfigurationSelector 、 CachingConfigurationSelector 三个子类。明显缓存体系 @EnableCaching 和异步 @EnableAsync 模式也是和这个极其类似的。自动代理注册 AutoProxyRegistrar 的作用是向容器注册一个解析事务的后置处理器InfrastructureAdvisorAutoProxyCreator 。首先获取到所有的注解类型，而不是只获取 @EnableAspectJAutoProxy 注解，因为 mode 、 proxyTargetClass 等属性会直接影响到代理得方式，而 @EnableTransactionManagement 、 @EnableAsync 、 @EnableCaching 、 @EnableAspectJAutoProxy 等注解都拥有这些属性。 1234567891011121314151617181920212223242526public class AutoProxyRegistrar implements ImportBeanDefinitionRegistrar &#123; public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; boolean candidateFound = false; Set&lt;String&gt; annTypes = importingClassMetadata.getAnnotationTypes(); // 获取所有的注解类型 for (String annType : annTypes) &#123; AnnotationAttributes candidate = AnnotationConfigUtils.attributesFor(importingClassMetadata, annType); if (candidate == null) &#123; continue; &#125; Object mode = candidate.get(&quot;mode&quot;); // 默认PROXY Object proxyTargetClass = candidate.get(&quot;proxyTargetClass&quot;); // 是否强制使用Cglib代理 // 存在mode且存在proxyTargetClass属性，且两个属性的class类型也是对的 if (mode != null &amp;&amp; proxyTargetClass != null &amp;&amp; AdviceMode.class == mode.getClass() &amp;&amp; Boolean.class == proxyTargetClass.getClass()) &#123; candidateFound = true; // 标志找到候选注解 if (mode == AdviceMode.PROXY) &#123; // 注册了internalAutoProxyCreator，但若出现多次，这里不是覆盖而是以第一次的为主 AopConfigUtils.registerAutoProxyCreatorIfNecessary(registry); if ((Boolean) proxyTargetClass) &#123; AopConfigUtils.forceAutoProxyCreatorToUseClassProxying(registry); return; &#125; &#125; &#125; &#125; &#125;&#125; 和开启AOP代理类似这里通过 AopConfigUtils 的 registerAutoProxyCreatorIfNecessary 真正去注册该后置处理器。最终调用 registerOrEscalateApcAsRequired 该方法和开启AOP代理时调用的是同一个方法，且向容器中注册的Bean的名称都是同一个 internalAutoProxyCreator 。这里会根据优先级来确定注册哪个类。AOP的会覆盖事务的， 因为AOP优先级更大。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public abstract class AopConfigUtils &#123; private static final List&lt;Class&lt;?&gt;&gt; APC_PRIORITY_LIST = new ArrayList&lt;&gt;(3); static &#123; APC_PRIORITY_LIST.add(InfrastructureAdvisorAutoProxyCreator.class); APC_PRIORITY_LIST.add(AspectJAwareAdvisorAutoProxyCreator.class); APC_PRIORITY_LIST.add(AnnotationAwareAspectJAutoProxyCreator.class); &#125; public static BeanDefinition registerAutoProxyCreatorIfNecessary(BeanDefinitionRegistry registry) &#123; return registerAutoProxyCreatorIfNecessary(registry, null); &#125; public static BeanDefinition registerAutoProxyCreatorIfNecessary(BeanDefinitionRegistry registry, @Nullable Object source) &#123; return registerOrEscalateApcAsRequired(InfrastructureAdvisorAutoProxyCreator.class, registry, source); &#125; private static BeanDefinition registerOrEscalateApcAsRequired(Class&lt;?&gt; cls, BeanDefinitionRegistry registry, @Nullable Object source) &#123; Assert.notNull(registry, &quot;BeanDefinitionRegistry must not be null&quot;); if (registry.containsBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME)) &#123; BeanDefinition apcDefinition = registry.getBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME); if (!cls.getName().equals(apcDefinition.getBeanClassName())) &#123; int currentPriority = findPriorityForClass(apcDefinition.getBeanClassName()); int requiredPriority = findPriorityForClass(cls); if (currentPriority &lt; requiredPriority) &#123; apcDefinition.setBeanClassName(cls.getName()); &#125; &#125; return null; &#125; RootBeanDefinition beanDefinition = new RootBeanDefinition(cls); beanDefinition.setSource(source); beanDefinition.getPropertyValues().add(&quot;order&quot;, Ordered.HIGHEST_PRECEDENCE); beanDefinition.setRole(BeanDefinition.ROLE_INFRASTRUCTURE); registry.registerBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME, beanDefinition); return beanDefinition; &#125; private static int findPriorityForClass(Class&lt;?&gt; clazz) &#123; return APC_PRIORITY_LIST.indexOf(clazz); &#125; private static int findPriorityForClass(@Nullable String className) &#123; for (int i = 0; i &lt; APC_PRIORITY_LIST.size(); i++) &#123; Class&lt;?&gt; clazz = APC_PRIORITY_LIST.get(i); if (clazz.getName().equals(className)) &#123; return i; &#125; &#125; throw new IllegalArgumentException(&quot;Class name [&quot; + className + &quot;] is not a known auto-proxy creator class&quot;); &#125;&#125; 若同时开启 AOP 和事务则根据优先级最终还是加载的解析和创建AOP代理的后置处理器 AnnotationAwareAspectJAutoProxyCreator ，且其与 InfrastructureAdvisorAutoProxyCreator 都是上层接口都是一样的。这里重写了 isEligibleAdvisorBean 方法。 12345678public class InfrastructureAdvisorAutoProxyCreator extends AbstractAdvisorAutoProxyCreator &#123; @Override protected boolean isEligibleAdvisorBean(String beanName) &#123; // 容器中包含了这个bean定义，并且bean定义角色为BeanDefinition.ROLE_INFRASTRUCTURE return (this.beanFactory != null &amp;&amp; this.beanFactory.containsBeanDefinition(beanName) &amp;&amp; this.beanFactory.getBeanDefinition(beanName).getRole() == BeanDefinition.ROLE_INFRASTRUCTURE); &#125;&#125; ProxyTransactionManagementConfiguration 是一个 @Configuration事务配置类，其主要作用是配置一个处理事务的Advisor 。配置的事务拦截器是一个 MethodInterceptor ，也可以自定义一个同名的TransactionInterceptor来覆盖此Bean。 1234567891011121314151617181920212223242526272829@Configurationpublic class ProxyTransactionManagementConfiguration extends AbstractTransactionManagementConfiguration &#123; @Bean(name = TransactionManagementConfigUtils.TRANSACTION_ADVISOR_BEAN_NAME) @Role(BeanDefinition.ROLE_INFRASTRUCTURE) public BeanFactoryTransactionAttributeSourceAdvisor transactionAdvisor() &#123; BeanFactoryTransactionAttributeSourceAdvisor advisor = new BeanFactoryTransactionAttributeSourceAdvisor(); advisor.setTransactionAttributeSource(transactionAttributeSource()); advisor.setAdvice(transactionInterceptor()); if (this.enableTx != null) &#123; advisor.setOrder(this.enableTx.&lt;Integer&gt;getNumber(&quot;order&quot;)); &#125; return advisor; // 导入了关于事务的切面信息 &#125; @Bean @Role(BeanDefinition.ROLE_INFRASTRUCTURE) public TransactionAttributeSource transactionAttributeSource() &#123; return new AnnotationTransactionAttributeSource(); // 事务属性源对象，用于获取事务属性对象 &#125; @Bean @Role(BeanDefinition.ROLE_INFRASTRUCTURE) public TransactionInterceptor transactionInterceptor() &#123; // 用户拦截事务方法执行的 TransactionInterceptor interceptor = new TransactionInterceptor(); interceptor.setTransactionAttributeSource(transactionAttributeSource()); if (this.txManager != null) &#123; interceptor.setTransactionManager(this.txManager); &#125; return interceptor; &#125;&#125; AnnotationTransactionAttributeSource 是基于注解驱动的事务管理的事务属性源，其作用是解析@Transactional注解，将其解析成TransactionAttribute后后续调用，也可如下自定义事务属性源，通过名称匹配的方式。 1234567891011121314151617181920212223@Beanpublic TransactionAttributeSource transactionAttributeSource() &#123; Map&lt;String, TransactionAttribute&gt; txMap = new HashMap&lt;&gt;(); // required事务适用于增删改场景 RuleBasedTransactionAttribute requiredTx = new RuleBasedTransactionAttribute(); requiredTx.setRollbackRules(Collections.singletonList(new RollbackRuleAttribute(RuntimeException.class))); requiredTx.setPropagationBehavior(TransactionDefinition.PROPAGATION_REQUIRED); txMap.put(&quot;add*&quot;, requiredTx); txMap.put(&quot;save*&quot;, requiredTx); txMap.put(&quot;insert*&quot;, requiredTx); txMap.put(&quot;update*&quot;, requiredTx); txMap.put(&quot;delete*&quot;, requiredTx); // 查询 使用只读事务 RuleBasedTransactionAttribute readOnlyTx = new RuleBasedTransactionAttribute(); readOnlyTx.setReadOnly(true); readOnlyTx.setPropagationBehavior(TransactionDefinition.PROPAGATION_NOT_SUPPORTED); txMap.put(&quot;get*&quot;, readOnlyTx); txMap.put(&quot;query*&quot;, readOnlyTx); NameMatchTransactionAttributeSource source = new NameMatchTransactionAttributeSource(); source.setNameMap(txMap); return source;&#125; BeanFactoryTransactionAttributeSourceAdvisor 会在切面解析时第一个被实例化的Bean调用时被 BeanFactoryAdvisorRetrievalHelper 的 findAdvisorBeans 中被解析出来并将其名称放入 cachedAdvisorBeanNames 缓存中。 12345678910111213141516171819public class BeanFactoryTransactionAttributeSourceAdvisor extends AbstractBeanFactoryPointcutAdvisor &#123; @Nullable private TransactionAttributeSource transactionAttributeSource; // 事务属性源切点 private final TransactionAttributeSourcePointcut pointcut = new TransactionAttributeSourcePointcut() &#123; @Override @Nullable protected TransactionAttributeSource getTransactionAttributeSource() &#123; return transactionAttributeSource; &#125; &#125;; public void setTransactionAttributeSource(TransactionAttributeSource transactionAttributeSource) &#123; this.transactionAttributeSource = transactionAttributeSource; // 可手动设置一个事务属性源 &#125; @Override public Pointcut getPointcut() &#123; return this.pointcut; &#125;&#125; 事务切面解析时和AOP的切面相同的逻辑，同样调用的是 canApply 方法经过了初筛和精筛，事务这初筛一般是通过的。初筛时调用 TransactionAttributeSourceClassFilter 的 matches 方法，精筛最终是通过 MethodMatcher 的 matches 方法，实际调用 TransactionAttributeSourcePointcut 的 matches 方法。 1234567891011121314151617181920212223242526abstract class TransactionAttributeSourcePointcut extends StaticMethodMatcherPointcut implements Serializable &#123; @Override public boolean matches(Method method, @Nullable Class&lt;?&gt; targetClass) &#123; if (targetClass != null &amp;&amp; TransactionalProxy.class.isAssignableFrom(targetClass)) &#123; return false; &#125; // 获取我们@EnableTransactionManagement注解为容器中导入的ProxyTransactionManagementConfiguration配置类中的TransactionAttributeSource对象 TransactionAttributeSource tas = getTransactionAttributeSource(); // 通过getTransactionAttribute看是否有@Transactional注解 return (tas == null || tas.getTransactionAttribute(method, targetClass) != null); &#125; @Nullable protected abstract TransactionAttributeSource getTransactionAttributeSource(); private class TransactionAttributeSourceClassFilter implements ClassFilter &#123; @Override public boolean matches(Class&lt;?&gt; clazz) &#123; if (TransactionalProxy.class.isAssignableFrom(clazz) || PlatformTransactionManager.class.isAssignableFrom(clazz) || PersistenceExceptionTranslator.class.isAssignableFrom(clazz)) &#123; return false; &#125; TransactionAttributeSource tas = getTransactionAttributeSource(); return (tas == null || tas.isCandidateClass(clazz)); &#125; &#125;&#125; 最终调用 AnnotationTransactionAttributeSource 的超类 AbstractFallbackTransactionAttributeSource 中的 getTransactionAttribute 方法。若method所在的类是Object则直接返回空，否则先从缓存中获取，若缓存为空说明没有被解析过，则通过 computeTransactionAttribute 去解析，无论是否解析到事务属性都将其放入缓存中。还会把方法描述设置到事务属性descriptor 上去，调用的时候会从事务属性中获取。 1234567891011121314151617181920212223242526272829public abstract class AbstractFallbackTransactionAttributeSource implements TransactionAttributeSource &#123; public TransactionAttribute getTransactionAttribute(Method method, @Nullable Class&lt;?&gt; targetClass) &#123; if (method.getDeclaringClass() == Object.class) &#123; return null; // 判断method所在的class是否为Object类型 &#125; Object cacheKey = getCacheKey(method, targetClass);// 构建缓存key TransactionAttribute cached = this.attributeCache.get(cacheKey);// 先去缓存中获取 if (cached != null) &#123;// 缓存中不为空 if (cached == NULL_TRANSACTION_ATTRIBUTE) &#123;// 判断缓存中的对象是不是空事务属性的对象 return null; &#125; else &#123; return cached;// 若缓存存在则返回 &#125; &#125; else &#123; TransactionAttribute txAttr = computeTransactionAttribute(method, targetClass);// 查找事务注解 if (txAttr == null) &#123;// 若解析出来的事务注解属性为空 this.attributeCache.put(cacheKey, NULL_TRANSACTION_ATTRIBUTE);//往缓存中存放空事务注解属性 &#125; else &#123; // 执行方法的描述符：全类名+方法名 String methodIdentification = ClassUtils.getQualifiedMethodName(method, targetClass); if (txAttr instanceof DefaultTransactionAttribute) &#123;// 把方法描述设置到事务属性上去 ((DefaultTransactionAttribute) txAttr).setDescriptor(methodIdentification); &#125; this.attributeCache.put(cacheKey, txAttr);//加入到缓存 &#125; return txAttr; &#125; &#125;&#125; 首先去目标类的当前方法上去找事务注解，若找到直接解析返回，若找不到再去目标类上去找事务注解，若找不到，再判断若具体方法不是当前的方法说明当前方法是接口方法，再去实现类的接口上的方法去找事务注解，最后再去实现类的接口上去找事务注解。 getMostSpecificMethod 是得到具体的方法，若method是接口方法将从targetClass得到实现类的方法，故无论传的是接口还是实现，都会先解析实现类。可从该代码逻辑看出， @Transactional 注解既可以用在方法上还可以用在类上甚至是接口方法和接口上，但若这些地方都有该注解，则 方法上的该注解会覆盖类上的 。 1234567891011121314151617181920212223242526272829public abstract class AbstractFallbackTransactionAttributeSource implements TransactionAttributeSource &#123; protected TransactionAttribute computeTransactionAttribute(Method method, @Nullable Class&lt;?&gt; targetClass) &#123; if (allowPublicMethodsOnly() &amp;&amp; !Modifier.isPublic(method.getModifiers())) &#123; return null; // 判断事务方法上的修饰符是不是public的 &#125; Method specificMethod = AopUtils.getMostSpecificMethod(method, targetClass); // 去目标class的方法上去找事务注解 TransactionAttribute txAttr = findTransactionAttribute(specificMethod); if (txAttr != null) &#123; return txAttr; &#125; // 去目标类即实现类上找事务注解 txAttr = findTransactionAttribute(specificMethod.getDeclaringClass()); if (txAttr != null &amp;&amp; ClassUtils.isUserLevelMethod(method)) &#123; return txAttr; &#125; if (specificMethod != method) &#123; // 具体方法不是当前的方法说明当前方法是接口方法 txAttr = findTransactionAttribute(method); // 去实现类的接口上的方法去找事务注解 if (txAttr != null) &#123; return txAttr; &#125; txAttr = findTransactionAttribute(method.getDeclaringClass()); // 去实现类的接口上去找事务注解 if (txAttr != null &amp;&amp; ClassUtils.isUserLevelMethod(method)) &#123; return txAttr; &#125; &#125; return null; &#125;&#125; 这里的 findTransactionAttribute 调用是 AnnotationTransactionAttributeSource 的方法，最终会调用 SpringTransactionAnnotationParser 的 parseTransactionAnnotation 。初筛的matches方法实际调用的是该类的 isCandidateClass 。 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class AnnotationTransactionAttributeSource extends AbstractFallbackTransactionAttributeSource implements Serializable &#123; private final Set&lt;TransactionAnnotationParser&gt; annotationParsers; public AnnotationTransactionAttributeSource() &#123; this(true); &#125; public AnnotationTransactionAttributeSource(boolean publicMethodsOnly) &#123; this.publicMethodsOnly = publicMethodsOnly; if (jta12Present || ejb3Present) &#123; // 是否支持 jta和 ejb的事务解析 this.annotationParsers = new LinkedHashSet&lt;&gt;(4); this.annotationParsers.add(new SpringTransactionAnnotationParser()); if (jta12Present) &#123; this.annotationParsers.add(new JtaTransactionAnnotationParser()); &#125; if (ejb3Present) &#123; this.annotationParsers.add(new Ejb3TransactionAnnotationParser()); &#125; &#125; else &#123; this.annotationParsers = Collections.singleton(new SpringTransactionAnnotationParser()); &#125; &#125; protected TransactionAttribute findTransactionAttribute(Class&lt;?&gt; clazz) &#123; return determineTransactionAttribute(clazz); &#125; protected TransactionAttribute findTransactionAttribute(Method method) &#123; return determineTransactionAttribute(method); &#125; protected TransactionAttribute determineTransactionAttribute(AnnotatedElement element) &#123; for (TransactionAnnotationParser annotationParser : this.annotationParsers) &#123; // 获取注解解析器 // 通过注解解析器去解析方法或类上的注解 TransactionAttribute attr = annotationParser.parseTransactionAnnotation(element); if (attr != null) &#123; return attr; &#125; &#125; return null; &#125; public boolean isCandidateClass(Class&lt;?&gt; targetClass) &#123; for (TransactionAnnotationParser parser : this.annotationParsers) &#123; if (parser.isCandidateClass(targetClass)) &#123; return true; &#125; &#125; return false; &#125;&#125; 若在目标元素上找到 @Transactional 注解，则通过 parseTransactionAnnotation 方法对该注解属性进行解析。 123456789101112131415161718192021222324252627282930313233343536373839404142public class SpringTransactionAnnotationParser implements TransactionAnnotationParser, Serializable &#123; public boolean isCandidateClass(Class&lt;?&gt; targetClass) &#123; return AnnotationUtils.isCandidateClass(targetClass, Transactional.class); &#125; public TransactionAttribute parseTransactionAnnotation(AnnotatedElement element) &#123; // 从element对象中获取@Transactional注解，然后把注解属性封装到了AnnotationAttributes AnnotationAttributes attributes = AnnotatedElementUtils.findMergedAnnotationAttributes(element, Transactional.class, false, false); if (attributes != null) &#123;// 解析出真正的事务属性对象 return parseTransactionAnnotation(attributes); &#125; else &#123; return null; &#125; &#125; public TransactionAttribute parseTransactionAnnotation(Transactional ann) &#123; return parseTransactionAnnotation(AnnotationUtils.getAnnotationAttributes(ann, false, false)); &#125; protected TransactionAttribute parseTransactionAnnotation(AnnotationAttributes attributes) &#123; RuleBasedTransactionAttribute rbta = new RuleBasedTransactionAttribute(); // 创建一个基础规则的事务属性对象 Propagation propagation = attributes.getEnum(&quot;propagation&quot;); // 解析@Transactionl上的传播行为 rbta.setPropagationBehavior(propagation.value()); Isolation isolation = attributes.getEnum(&quot;isolation&quot;); // 解析@Transactionl上的隔离级别 rbta.setIsolationLevel(isolation.value()); rbta.setTimeout(attributes.getNumber(&quot;timeout&quot;).intValue()); // 解析@Transactionl上的事务超时事件 rbta.setReadOnly(attributes.getBoolean(&quot;readOnly&quot;)); rbta.setQualifier(attributes.getString(&quot;value&quot;)); // 解析@Transactionl上的事务管理器的名称 List&lt;RollbackRuleAttribute&gt; rollbackRules = new ArrayList&lt;&gt;(); for (Class&lt;?&gt; rbRule : attributes.getClassArray(&quot;rollbackFor&quot;)) &#123; rollbackRules.add(new RollbackRuleAttribute(rbRule)); // 针对哪种异常回滚 &#125; for (String rbRule : attributes.getStringArray(&quot;rollbackForClassName&quot;)) &#123; rollbackRules.add(new RollbackRuleAttribute(rbRule)); // 对哪种异常进行回滚 &#125; for (Class&lt;?&gt; rbRule : attributes.getClassArray(&quot;noRollbackFor&quot;)) &#123; rollbackRules.add(new NoRollbackRuleAttribute(rbRule)); // 对哪种异常不回滚 &#125; for (String rbRule : attributes.getStringArray(&quot;noRollbackForClassName&quot;)) &#123; rollbackRules.add(new NoRollbackRuleAttribute(rbRule)); // 对哪种类型不回滚 &#125; rbta.setRollbackRules(rollbackRules); return rbta; &#125;&#125;","tags":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}]},{"title":"事件监听器","date":"2020-10-21T11:52:21.000Z","path":"blog/Spring/事件监听器/","text":"Spring事件体系包括事件，事件监听器，事件广播器三个组件，实现原理其实就是观察者模式。Spring内置事件由系统内部进行发布，只需要注入监听器即可： ContextRefreshedEvent ：当容器被实例化即所有Bean都已被加载后置处理器都被激活，所有单例bean都已被实例化，所有容器对象都已准备好可使用，如调用refresh()方法。若容器支持热重载，则refresh可以被触发多次， XmlWebApplicatonContext 支持热刷新， GenericApplicationContext 不支持。 ContextStartedEvent ：当容器启动时发布，即调用 start() 方法，即所有Lifecycle Bean都已显式接收到了start信号 ContextStoppedEvent ：当容器停止时发布，即调用 stop() 方法，即所有Lifecycle Bean都已显式接收到了stop信号，关闭的容器可通过start()方法重启 ContextClosedEvent ：当容器关闭时发布，即调用 close() 方法，即所有单例Bean都已被销毁。关闭的容器不能被重启或refresh RequestHandledEvent ：只在使用Spring DispatcherServlet时有效，当一个请求被处理完成时发布 Spring事件机制是观察者模式的一种实现，除了发布者和监听者者两个角色之外，还有一个 EventMultiCaster 的角色负责把事件转发给监听者，发布者调用context.publishEvent(msg)，会将事件发送给了EventMultiCaster， 而EventMultiCaster注册着所有的Listener，然后根据事件类型决定转发给那个Listener。 源码 在 refresh() 中的 prepareRefresh() 方法中创建了一个早期事件监听器对象earlyApplicationListeners ，以及用于保存早期待发布的事件集合earlyApplicationEvents ，事件监听器还没有注册到多播器上的时候都称为早期事件。早期事件不需要手动publishEvent发布，在 registerListeners 中会自动发布，发布完早期事件后会将早期事件置空。 1234567891011121314public abstract class AbstractApplicationContext extends DefaultResourceLoader implements ConfigurableApplicationContext &#123; private Set&lt;ApplicationEvent&gt; earlyApplicationEvents; private ApplicationEventMulticaster applicationEventMulticaster; private Set&lt;ApplicationListener&lt;?&gt;&gt; earlyApplicationListeners; protected void prepareRefresh() &#123; if (this.earlyApplicationListeners == null) &#123; // 创建一个早期事件监听器对象 this.earlyApplicationListeners = new LinkedHashSet&lt;&gt;(this.applicationListeners); &#125; else &#123; this.applicationListeners.clear(); this.applicationListeners.addAll(this.earlyApplicationListeners); &#125; this.earlyApplicationEvents = new LinkedHashSet&lt;&gt;(); &#125;&#125; 事件广播器初始化 applicationEventMulticaster 提供了容器监听器的注册表， refresh() 中的 initApplicationEventMulticaster() 中会对事件广播器进行初始化。 12345678910111213protected void initApplicationEventMulticaster() &#123; ConfigurableListableBeanFactory beanFactory = getBeanFactory(); // 获取Bean工厂对象 // 判断容器中是否有applicationEventMulticaster应用多播器组件 if (beanFactory.containsLocalBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME)) &#123; // 直接显示的调用getBean获取ApplicationEventMulticaster赋值给applicationContext对象 this.applicationEventMulticaster = beanFactory.getBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, ApplicationEventMulticaster.class); &#125; else &#123; // 若容器中没有 // spring ioc显式的new一个SimpleApplicationEventMulticaster对象保存在applicatoinContext对象中 this.applicationEventMulticaster = new SimpleApplicationEventMulticaster(beanFactory); // 并且注入到容器中 beanFactory.registerSingleton(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, this.applicationEventMulticaster); &#125;&#125; 用户可通过实现ApplicationEventMulticaster接口自定义事件广播器，Spring会将其注册成容器的事件广播器，若没有找到配置的外部事件广播器，默认使用 SimpleApplicationEventMulticaster 作为事件广播器。 注册事件监听器refresh()的 registerListeners() 中会获取容器中所有的监听器对象，把监听器挨个的注册到多播器上去，这个时候正常流程是不会有监听器的，在initApplicationEventMulticaster之后，在registerListeners之前，只有一个可能在onRefresh()里面注册了监听器。这里会执行所有的早期发布事件。 1234567891011121314151617181920protected void registerListeners() &#123; // 获取容器中所有的监听器对象，把监听器挨个的注册到多播器上去，这个时候正常流程是不会有监听器的 // 监听器不会在这之前注册，在initApplicationEventMulticaster后在registerListeners之前，只有一个可能在：在onRefresh里面注册了监听器 for (ApplicationListener&lt;?&gt; listener : getApplicationListeners()) &#123; getApplicationEventMulticaster().addApplicationListener(listener); &#125; // 获取Bean定义中的监听器对象 String[] listenerBeanNames = getBeanNamesForType(ApplicationListener.class, true, false); for (String listenerBeanName : listenerBeanNames) &#123; // 把监听器的名称注册到多播器上 getApplicationEventMulticaster().addApplicationListenerBean(listenerBeanName); &#125; // 获取早期事件 Set&lt;ApplicationEvent&gt; earlyEventsToProcess = this.earlyApplicationEvents; this.earlyApplicationEvents = null; // 在这里赋null，也就是自此之后都将没有早期事件了 if (earlyEventsToProcess != null) &#123;// 通过多播器进行播发早期事件 for (ApplicationEvent earlyEvent : earlyEventsToProcess) &#123; getApplicationEventMulticaster().multicastEvent(earlyEvent); &#125; &#125;&#125; 这里只是把监听器的名称注册到多播器上，为了防止懒加载的监听器漏掉，因为懒加载的Bean是不会在容器初始化时加载的，只会在使用时才会去加载，且这里只处理实现了 ApplicationListener 接口的监听器。 123456789101112131415161718192021222324252627282930private class ListenerRetriever &#123; // 存储了所有的Listener，包括实现了ApplicationListener接口和使用了@EventListener的Bean public final Set&lt;ApplicationListener&lt;?&gt;&gt; applicationListeners = new LinkedHashSet&lt;&gt;(); // 只存储实现了ApplicationListener接口的Bean名称 public final Set&lt;String&gt; applicationListenerBeans = new LinkedHashSet&lt;&gt;(); private final boolean preFiltered; public ListenerRetriever(boolean preFiltered) &#123; this.preFiltered = preFiltered; &#125; public Collection&lt;ApplicationListener&lt;?&gt;&gt; getApplicationListeners() &#123; List&lt;ApplicationListener&lt;?&gt;&gt; allListeners = new ArrayList&lt;&gt;(this.applicationListeners.size() + this.applicationListenerBeans.size()); allListeners.addAll(this.applicationListeners); if (!this.applicationListenerBeans.isEmpty()) &#123; BeanFactory beanFactory = getBeanFactory(); for (String listenerBeanName : this.applicationListenerBeans) &#123; try &#123; ApplicationListener&lt;?&gt; listener = beanFactory.getBean(listenerBeanName, ApplicationListener.class); if (this.preFiltered || !allListeners.contains(listener)) &#123; allListeners.add(listener); &#125; &#125; catch (NoSuchBeanDefinitionException ex) &#123; &#125; &#125; &#125; if (!this.preFiltered || !this.applicationListenerBeans.isEmpty()) &#123; AnnotationAwareOrderComparator.sort(allListeners); &#125; return allListeners; &#125;&#125; 发布事件Spring委托 ApplicationEventMulticaster 将事件通知给所有的事件监听器，这里会发布 ContextRefreshedEvent 事件，可实现一个 ContextRefreshedEvent 事件的监听器做一些扩展。 12345678910111213141516171819202122232425262728293031323334353637383940414243protected void finishRefresh() &#123; // 清除上下文级别的资源缓存，如来自扫描的ASM元数据 clearResourceCaches(); // 注册lifecycleProcessor声明周期处理器，作用：当ApplicationContext启动或停止时，它会通过LifecycleProcessor来与所有声明的bean的周期做状态更新 initLifecycleProcessor(); // 为实现了SmartLifecycle并且isAutoStartup 自动启动的Lifecycle调用start()方法 getLifecycleProcessor().onRefresh(); // 发布容器启动完毕事件 publishEvent(new ContextRefreshedEvent(this)); // 注册当前spring容器到LiveBeansView，提供servlet(LiveBeansViewServlet)在线查看所有的bean json 、 为了支持Spring Tool Suite的智能提示 LiveBeansView.registerApplicationContext(this);&#125;public abstract class AbstractApplicationContext extends DefaultResourceLoader implements ConfigurableApplicationContext &#123; public void publishEvent(ApplicationEvent event) &#123; publishEvent(event, null); &#125; protected void publishEvent(Object event, @Nullable ResolvableType eventType) &#123; Assert.notNull(event, &quot;Event must not be null&quot;); ApplicationEvent applicationEvent; if (event instanceof ApplicationEvent) &#123; applicationEvent = (ApplicationEvent) event; &#125; else &#123; applicationEvent = new PayloadApplicationEvent&lt;&gt;(this, event); if (eventType == null) &#123; eventType = ((PayloadApplicationEvent&lt;?&gt;) applicationEvent).getResolvableType(); &#125; &#125; // 这里是唯一添加早期事件的地方，所以一定要发布事件才能添加早期事件 // 只有当执行力refresh--&gt;registerListeners才会将earlyApplicationEvents赋为null，故registerListeners之前发布的事件都是早期事件 if (this.earlyApplicationEvents != null) &#123; this.earlyApplicationEvents.add(applicationEvent); &#125; else &#123; getApplicationEventMulticaster().multicastEvent(applicationEvent, eventType); &#125; if (this.parent != null) &#123; // 若是父容器，也会向父容器里广播一份 if (this.parent instanceof AbstractApplicationContext) &#123; ((AbstractApplicationContext) this.parent).publishEvent(event, eventType); &#125; else &#123; this.parent.publishEvent(event); &#125; &#125; &#125;&#125; Spring默认的事件广播器为 SimpleApplicationEventMulticaster ，这里其实就是挨个去调用事件监听器的 onApplicationEvent 方法。默认getTaskExecutor()获取的线程池为null，故默认是同步执行， applicationContext.publishEvent() 方法需要同步等待各个监听器处理完之后才返回。若想异步可实现 ApplicationEventMulticaster 接口，并将其注册beanName为applicationEventMulticaster 的Bean。 123456789101112131415161718192021222324252627282930313233public class SimpleApplicationEventMulticaster extends AbstractApplicationEventMulticaster &#123; public void multicastEvent(final ApplicationEvent event, @Nullable ResolvableType eventType) &#123; ResolvableType type = (eventType != null ? eventType : resolveDefaultEventType(event)); // 从多播器中获取出所有的监听器 for (final ApplicationListener&lt;?&gt; listener : getApplicationListeners(event, type)) &#123; Executor executor = getTaskExecutor(); // 判断多播器中是否支持异步多播的 if (executor != null) &#123; // 异步播发事件 executor.execute(() -&gt; invokeListener(listener, event)); &#125; else &#123; // 同步播发 invokeListener(listener, event); &#125; &#125; &#125; protected void invokeListener(ApplicationListener&lt;?&gt; listener, ApplicationEvent event) &#123; ErrorHandler errorHandler = getErrorHandler(); if (errorHandler != null) &#123; try &#123; doInvokeListener(listener, event); &#125; catch (Throwable err) &#123; errorHandler.handleError(err); &#125; &#125; else &#123; doInvokeListener(listener, event); &#125; &#125; private void doInvokeListener(ApplicationListener listener, ApplicationEvent event) &#123; try &#123; listener.onApplicationEvent(event); &#125; catch (ClassCastException ex) &#123; throw ex; &#125; &#125;&#125; 遍历注册的每个监听器，并启动来调用每个监听器的 onApplicationEvent 方法。由于 SimpleApplicationEventMulticaster 的 taskExecutor 的实现类是 SyncTaskExecutor ，因此事件监听器对事件的处理是同步进行的。 自定义监听器注册对于用户自定义的监听器的解析是通过 ApplicationListenerDetector 后置处理器来实现的，该Bean后置处理器是在refresh()的 registerBeanPostProcessors(beanFactory) 中注册的，在第八次Bean的后置处理器的调用的地方调用。用于解析实现了ApplicationListener接口的方式的监听器。 12345678910111213class ApplicationListenerDetector implements DestructionAwareBeanPostProcessor, MergedBeanDefinitionPostProcessor &#123; public Object postProcessAfterInitialization(Object bean, String beanName) &#123; if (bean instanceof ApplicationListener) &#123; Boolean flag = this.singletonNames.get(beanName); if (Boolean.TRUE.equals(flag)) &#123; this.applicationContext.addApplicationListener((ApplicationListener&lt;?&gt;) bean); &#125; else if (Boolean.FALSE.equals(flag)) &#123; this.singletonNames.remove(beanName); &#125; &#125; return bean; &#125;&#125; 对于注解方式的自定义监听器的解析与执行是通过在IoC容器启动最开始时在 AnnotatedBeanDefinitionReader 中注册了一系列创世纪的类时，注册了 DefaultEventListenerFactory 事件监听器工厂和处理监听方法的注解 @EventListener 解析器 EventListenerMethodProcessor 。解析是在refresh()的finishBeanFactoryInitialization(beanFactory)的beanFactory.preInstantiateSingletons()中，且是在所有单例Bean都已实例化完成加载到单例池中之后： 12345678910111213141516171819202122public void preInstantiateSingletons() throws BeansException &#123; // 获取容器中所有bean定义的名称 List&lt;String&gt; beanNames = new ArrayList&lt;&gt;(this.beanDefinitionNames); // 所有的单实例的bean已经记载到单实例bean到缓存中 for (String beanName : beanNames) &#123; // 从单例缓存池中获取所有的对象 Object singletonInstance = getSingleton(beanName); // 判断当前的bean是否实现了SmartInitializingSingleton接口 if (singletonInstance instanceof SmartInitializingSingleton) &#123; final SmartInitializingSingleton smartSingleton = (SmartInitializingSingleton) singletonInstance; if (System.getSecurityManager() != null) &#123; AccessController.doPrivileged((PrivilegedAction&lt;Object&gt;) () -&gt; &#123; smartSingleton.afterSingletonsInstantiated(); return null; &#125;, getAccessControlContext()); &#125; else &#123; // 触发实例化之后的方法afterSingletonsInstantiated smartSingleton.afterSingletonsInstantiated(); &#125; &#125; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283public class EventListenerMethodProcessor implements SmartInitializingSingleton, ApplicationContextAware &#123; protected final Log logger = LogFactory.getLog(getClass()); private final EventExpressionEvaluator evaluator = new EventExpressionEvaluator(); // 没有@EventListener的类 private final Set&lt;Class&lt;?&gt;&gt; nonAnnotatedClasses = Collections.newSetFromMap(new ConcurrentHashMap&lt;&gt;(64)); @Nullable private ConfigurableApplicationContext applicationContext; private ConfigurableApplicationContext getApplicationContext() &#123; Assert.state(this.applicationContext != null, &quot;No ApplicationContext set&quot;); return this.applicationContext; &#125; @Override public void setApplicationContext(ApplicationContext applicationContext) &#123; Assert.isTrue(applicationContext instanceof ConfigurableApplicationContext, &quot;ApplicationContext does not implement ConfigurableApplicationContext&quot;); this.applicationContext = (ConfigurableApplicationContext) applicationContext; &#125; @Override public void afterSingletonsInstantiated() &#123; // 从BeanFactory中获取EventListenerFactory的bean默认情况下的两个实现,DefaultEventListenerFactory：spring自己注入的，TransactionalEventListenerFactory：使用配置进去的 List&lt;EventListenerFactory&gt; factories = getEventListenerFactories(); ConfigurableApplicationContext context = getApplicationContext(); String[] beanNames = context.getBeanNamesForType(Object.class); for (String beanName : beanNames) &#123; // 处理所有bean查找当前bean标注了@EventListener的方法 if (!ScopedProxyUtils.isScopedTarget(beanName)) &#123; Class&lt;?&gt; type = null; try &#123; type = AutoProxyUtils.determineTargetClass(context.getBeanFactory(), beanName); &#125; catch (Throwable ex) &#123; &#125; if (type != null) &#123; if (ScopedObject.class.isAssignableFrom(type)) &#123; try &#123; Class&lt;?&gt; targetClass = AutoProxyUtils.determineTargetClass(context.getBeanFactory(), ScopedProxyUtils.getTargetBeanName(beanName)); if (targetClass != null) &#123; type = targetClass; &#125; &#125; catch (Throwable ex) &#123; &#125; &#125; try &#123; processBean(factories, beanName, type); &#125; catch (Throwable ex) &#123; throw new BeanInitializationException(&quot;Failed to process @EventListener &quot; + &quot;annotation on bean with name &#x27;&quot; + beanName + &quot;&#x27;&quot;, ex); &#125; &#125; &#125; &#125; &#125; protected List&lt;EventListenerFactory&gt; getEventListenerFactories() &#123; Map&lt;String, EventListenerFactory&gt; beans = getApplicationContext().getBeansOfType(EventListenerFactory.class); List&lt;EventListenerFactory&gt; factories = new ArrayList&lt;&gt;(beans.values()); AnnotationAwareOrderComparator.sort(factories); return factories; &#125; protected void processBean(final List&lt;EventListenerFactory&gt; factories, final String beanName, final Class&lt;?&gt; targetType) &#123; if (!this.nonAnnotatedClasses.contains(targetType)) &#123; Map&lt;Method, EventListener&gt; annotatedMethods = null; try &#123; // 查找当前bean标注了@EventListener的方法 annotatedMethods = MethodIntrospector.selectMethods(targetType, (MethodIntrospector.MetadataLookup&lt;EventListener&gt;) method -&gt; AnnotatedElementUtils.findMergedAnnotation(method, EventListener.class)); &#125; catch (Throwable ex) &#123; &#125; if (CollectionUtils.isEmpty(annotatedMethods)) &#123; this.nonAnnotatedClasses.add(targetType); &#125; else &#123; ConfigurableApplicationContext context = getApplicationContext(); for (Method method : annotatedMethods.keySet()) &#123; for (EventListenerFactory factory : factories) &#123; if (factory.supportsMethod(method)) &#123; // ①创建事件监听器 Method methodToUse = AopUtils.selectInvocableMethod(method, context.getType(beanName)); ApplicationListener&lt;?&gt; applicationListener = factory.createApplicationListener(beanName, targetType, methodToUse); if (applicationListener instanceof ApplicationListenerMethodAdapter) &#123; ((ApplicationListenerMethodAdapter) applicationListener).init(context, this.evaluator); &#125; context.addApplicationListener(applicationListener); // ②注册事件到Context中 break; &#125; &#125; &#125; &#125; &#125; &#125;&#125; 注解方式的监听器发布事件是 统一 走的 ApplicationListenerMethodAdapter 的 onApplicationEvent 方法，然后通过 反射 来调用。 123456789101112131415161718192021public class ApplicationListenerMethodAdapter implements GenericApplicationListener &#123; public void onApplicationEvent(ApplicationEvent event) &#123; processEvent(event); &#125; public void processEvent(ApplicationEvent event) &#123; Object[] args = resolveArguments(event); if (shouldHandle(event, args)) &#123; Object result = doInvoke(args); if (result != null) &#123; handleResult(result); &#125; &#125; &#125; protected Object doInvoke(Object... args) &#123; Object bean = getTargetBean(); ReflectionUtils.makeAccessible(this.method); try &#123; return this.method.invoke(bean, args); &#125; &#125;&#125; 自定义事件事件类继承ApplicationEvent即可 12345678910public class ElevenEvent extends ApplicationEvent &#123; private String name; public ElevenEvent(Object source, String name) &#123; super(source); this.name = name; &#125; public String getName() &#123; return name; &#125;&#125; 监听器可以基于接口，需实现 ApplicationListener 接口覆写onApplicationEvent方法，也可基于@EventListener注解的方式，同一个事件可有多个监听器 1234567891011121314@Componentpublic class ElevenEventListener implements ApplicationListener&lt;ElevenEvent&gt; &#123; @Override public void onApplicationEvent(ElevenEvent event) &#123; System.out.println(Thread.currentThread().getName() + &quot;, Interface：&quot; + event.getName()); &#125;&#125;@Componentpublic class ElevenEventAnnotationListener &#123; @EventListener(value = ElevenEvent.class) public void onApplicationEvent(ElevenEvent event) &#123; System.out.println(Thread.currentThread().getName() + &quot;, Annotation：&quot; + event.getName()); &#125;&#125; 事件的发布通过 容器 发布即可 12AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(MainConfig.class);context.publishEvent(new ElevenEvent(context, &quot;test&quot;)); 事件监听操作 可异步执行 ， 只 需配置异步线程池 即可 123456@Bean(name = &quot;applicationEventMulticaster&quot;)public ApplicationEventMulticaster simpleApplicationEventMulticaster() &#123; SimpleApplicationEventMulticaster eventMulticaster = new SimpleApplicationEventMulticaster(); eventMulticaster.setTaskExecutor(new SimpleAsyncTaskExecutor()); return eventMulticaster;&#125;","tags":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}]},{"title":"Spring线程池跨线程数据共享","date":"2020-10-21T03:02:20.000Z","path":"blog/Spring/Spring线程池跨线程数据共享/","text":"在Spring Cloud中可能会用到sleuth做链路追踪，以及内部链路中需要用到Header中得一些数据，在单线程是没有问题得，但是在某些场景下就会有问题，比如上层业务系统得一个请求需要同时并发去调用基础服务得多个产品，这样请求到其他服务得链路追踪信息就不一样了等。 为了实现多线程并发情况下主线程和线程池的线程共享ThreadLocal变量，如MDC、RequestAttributes中的数据，需要自定义线程池及线程实现。 自定义线程池继承ThreadPoolTaskExecutor类重写execute和submit方法即可，Spring的ExecutorMethodInterceptor会拦截使用LazyTraceThreadPoolTaskExecutor装饰实际执行的task然后调用当前executor执行。代码如下： 1234567891011121314151617public class CusThreadPoolExecutor extends ThreadPoolTaskExecutor &#123; @Override public void execute(Runnable task) &#123; ServletRequestAttributes servletRequestAttributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes(); Map&lt;String, String&gt; contextOfMDC = MDC.getCopyOfContextMap(); Runnable cusTask = new CusInheritThreadVarRunnable(servletRequestAttributes, contextOfMDC, task); super.execute(cusTask); &#125; @Override public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; ServletRequestAttributes servletRequestAttributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes(); Map&lt;String, String&gt; contextOfMDC = MDC.getCopyOfContextMap(); Callable&lt;T&gt; cusTask = new CusInheritThreadVarCallable&lt;T&gt;(servletRequestAttributes, contextOfMDC, task); return super.submit(cusTask); &#125;&#125; 该线程池的使用和普通的线程池使用是一样。 只是在在提交到真正的线程池之前，会获取主线程中需要共享的ThreadLocal相关变量。然后将任务包装成一个新的Runnable或Callable，在子线程中执行任务之前，将ThreadLocal相关变量设置到子线程的ThreadLocalMap中，执行结束之前清空设置的ThreadLocal相关变量，防止不同线程中串数据。 Callable实现： 12345678910111213141516171819202122232425262728public class CusInheritThreadVarCallable&lt;V&gt; implements Callable&lt;V&gt; &#123; private Callable&lt;V&gt; delegate; private Map&lt;String, String&gt; contextOfMDC; private ServletRequestAttributes servletRequestAttributes; public CusInheritThreadVarCallable(ServletRequestAttributes servletRequestAttributes, Map&lt;String, String&gt; contextOfMDC, Callable&lt;V&gt; delegate) &#123; this.contextOfMDC = contextOfMDC; this.servletRequestAttributes = servletRequestAttributes; this.delegate = delegate; &#125; @Override public V call() throws Exception &#123; RestStrategyContext.clearCurrentContext(); //设置当前线程servletRequestAttributes RequestContextHolder.setRequestAttributes(servletRequestAttributes); //设置当前线程MDC MDC.setContextMap(contextOfMDC); V result; try &#123; result = delegate.call(); &#125; finally &#123; MDC.clear(); RequestContextHolder.resetRequestAttributes(); &#125; return result; &#125;&#125; Runnable实现： 12345678910111213141516171819202122232425262728public class CusInheritThreadVarRunnable implements Runnable &#123; private Runnable delegate; private Map&lt;String, String&gt; contextOfMDC; private ServletRequestAttributes servletRequestAttributes; public CusInheritThreadVarRunnable(ServletRequestAttributes servletRequestAttributes, Map&lt;String, String&gt; contextOfMDC, Runnable delegate) &#123; this.contextOfMDC = contextOfMDC; this.servletRequestAttributes = servletRequestAttributes; this.delegate = delegate; &#125; @Override public void run() &#123; RestStrategyContext.clearCurrentContext(); //设置当前线程servletRequestAttributes RequestContextHolder.setRequestAttributes(servletRequestAttributes); //设置当前线程MDC MDC.setContextMap(contextOfMDC); try &#123; // 执行 delegate.run(); &#125; finally &#123; // 清空 MDC.clear(); RequestContextHolder.resetRequestAttributes(); &#125; &#125;&#125; 线程池的配置如下： 1234567891011121314@Bean(name = &quot;processorExecutor&quot;)public ThreadPoolTaskExecutor taskProcessorExecutor() &#123; CusThreadPoolExecutor executor = new CusThreadPoolExecutor(); executor.setCorePoolSize(taskPoolConfig.getCorePoolSize()); executor.setMaxPoolSize(taskPoolConfig.getMaxPoolSize()); executor.setQueueCapacity(taskPoolConfig.getQueueCapacity()); executor.setKeepAliveSeconds(taskPoolConfig.getKeepAliveSeconds()); executor.setThreadNamePrefix(&quot;CusTask-&quot;); executor.setRejectedExecutionHandler(cusCallerRunsPolicy); executor.setWaitForTasksToCompleteOnShutdown(true); executor.setAwaitTerminationSeconds(taskPoolConfig.getAwaitTerminationSeconds()); executor.initialize(); return executor;&#125; 对于线程池的配置需要注意的是，拒绝策略不要使用CallerRunsPolicy拒绝策略，该拒绝策略会在任务添加到线程池被拒绝时使用主线程执行该任务。在并发较高的情况下，拒绝策略生效，导致很多任务由主线程执行了，从而导致主线程中的MDC数据被清空了，从而导致一些trace信息丢失。可以自定义拒绝策略将任务丢回队列： 123456789101112public class CusCallerRunsPolicy implements RejectedExecutionHandler &#123; @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) &#123; if (!executor.isShutdown()) &#123; try &#123; executor.getQueue().put(r); &#125; catch (InterruptedException e) &#123; log.error(&quot;Reject policy interrupted exception &quot;, e); &#125; &#125; &#125;&#125;","tags":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}]},{"title":"SpringMvc异步原理及实现","date":"2020-10-20T03:08:20.000Z","path":"blog/Spring/SpringMvc异步原理及实现/","text":"在实际的项目中，可能会用到HTTP异步请求方式来提高系统的吞吐量。 同步请求客户端发起 同步HTTP 请求时，线程进入等待状态，直到接受到一个response对象或者请求超时状态 ，往返WEB服务器的过程： HTTP请求在经过DNS服务器的域名解析，到Nginx反向代理转发到我们的WEB服务器（servlet容器，Tomcat），WEB服务器会启动一个请求处理线程来处理请求，完成资源分配处理之后，线程起调后端的处理线程，同时WEB服务器的线程将会进入阻塞状态，直到后端的线程处理完毕，WEB服务器释放请求处理线程的资源，同时返回response对象，客户端接收到response对象，整个请求完成。 若后端处理服务器中进行了大量的IO操作，数据库操作，或者跨网调用等耗时操作，导致请求处理线程进入长时间的阻塞。因为WEB服务器的请求处理线程条个数是有限的，如果同时大量的请求阻塞在WEB服务器中，新的请求将会处于等待状态，甚至服务不可用，connection refused。 异步请求Servlet3的异步web机制的引入，改造接口服务，可以让请求线程(IO线程)和业务处理线程分开，进而对业务进行线程池隔离。 解决tomcat线程池资源消耗，频繁gc，高io，堆内存上升 。还可以根据业务重要性进行业务分级，然后再把线程池分级 。还可以根据这些分级做其它操作比如监控和降级处理。 请求处理线程对后台处理的调用使用了invoke的方式，调invoke方法后直接返回不等待，请求处理线程就释放了，它可以接着去处理别的请求，当后端处理完成后，会钩起一个回调处理线程来处理调用的结果，这个回调处理线程跟请求处理线程也许都是线程池中的某个线程，相互间可以完全没有关系，由这个回调处理线程向浏览器返回内容。 带来的改进是显而易见的，请求处理线程不需要阻塞了，它的能力得到了更充分的使用，带来了服务器吞吐能力的提升。下图是异步请求过程图： Servlet3异步流程 接收到request请求之后，由Tomcat工作线程从HttpServletRequest中获得一个异步上下文AsyncContext对象，然后由Tomcat工作线程把AsyncContext对象传递给业务处理线程，同时Tomcat工作线程归还到工作线程池，这一步就是异步开始。在业务处理线程中完成业务逻辑的处理，生成response返回给客户端。在 Servlet3.0 中虽然处理请求可以实现异步，但是InputStream和OutputStream的IO操作还是阻塞的，当数据量大的request body 或者 response body的时候，就会导致不必要的等待。从Servlet3.1以后增加了非阻塞IO，需要tomcat8.x支持。 Servlet3的异步使用步骤： 声明Servlet，增加asyncSupported属性，开启异步支持。 @WebServlet(urlPatterns = &quot;/simpleAsync&quot;, asyncSupported = true) 通过request获取异步上下文AsyncContext 。 AsyncContext asyncCtx = request.startAsync() ; 开启业务逻辑处理线程，并将AsyncContext 传递给业务线程。 executor.execute(new AsyncRequestProcessor(asyncCtx, secs)); 在异步业务逻辑处理线程中，通过asyncContext获取request和response，处理对应的业务。 业务逻辑处理线程处理完成逻辑之后，调用AsyncContext 的complete方法。asyncContext.complete();从而结束该次异步线程处理。 同步异步对比实际写了一个固定延时10秒的Demo，Tomcat的参数设置如下： 12345tomcat: max-threads: 5 accept-count: 10 max-connections: 1000 在500的并发下分别对同步和异步请求进行了测试，通过 MBean 对Tomcat参数进行监控 同步情况下 currentThreadsBusy 参数始终是与最大线程数一致，说明线程一致未释放，会导致请求一致阻塞 异步情况由于后台是异步处理的线程马上就释放了，故 currentThreadsBusy基本上都是0 。在某些情况下能够极大的提升系统吞吐量。 将Tomcat业务线程池的压力转移到系统自定义线程池中。使得更加可控，即使变更应用服务器系统任然兼容。 Spring异步 Spring MVC 3.2 开始引入了基于Servlet 3的异步请求处理。相比以前，控制器方法已经不一定需要返回一个值，而是可以返回一个 java.util.concurrent.Callable 对象，并通过Spring MVC所管理的线程来产生返回值。 同时Servlet容器的主线程则可以退出并释放其资源了，同时也允许容器去处理其他的请求。通过一个 TaskExecutor ，Spring MVC可以在另外的线程中调用 Callable 。当Callable返回时，请求再携带Callable返回的值，再次被分配到Servlet容器中恢复处理流程。 另一个选择，是让控制器方法返回一个 DeferredResult 实例。该场景下，返回值可由任何一个线程产生，也包括那些不是由Spring MVC管理的线程。 返回值可能是为了响应某些外部事件所产生的，比如一条JMS的消息，一个计划任务 。 Callable异步请求 控制器先返回一个Callable对象 Spring MVC开始进行异步处理，并把该Callable对象提交给另一个独立线程的执行器 TaskExecutor 处理 DispatcherServlet和所有过滤器都退出Servlet容器线程，但此时方法的响应对象仍未返回 Callable对象最终产生一个返回结果，此时Spring MVC会重新把请求分派回Servlet容器，恢复处理 DispatcherServlet再次被调用，恢复对Callable异步处理所返回结果的处理 DeferredResult异步请求 控制器先返回一个 DeferredResult对象，并把它存取在内存（队列或列表等）中以便存取 Spring MVC开始进行异步处理 DispatcherServlet和所有过滤器都退出Servlet容器线程，但此时方法的响应对象仍未返回 由处理该请求的线程对 DeferredResult进行设值，然后Spring MVC会重新把请求分派回Servlet容器，恢复处理 DispatcherServlet再次被调用，恢复对该异步返回结果的处理 SpringMvc异步实现方式一：123456789101112131415161718192021public Callable&lt;String&gt; process(HttpServletResponse response) &#123; return () -&gt; &#123; response.setContentType(&quot;text/plain;charset=utf-8&quot;); response.getWriter().write(&quot;响应内容&quot;); response.getWriter().close(); return null; &#125;;&#125;// taskService是一个@Service注解类public Callable&lt;Map&lt;String, Object&gt;&gt; process() &#123; Callable&lt;Map&lt;String, Object&gt;&gt; callable = taskService::execute; return callable;&#125;// taskService是一个@Service注解类public Callable&lt;Map&lt;String, Object&gt;&gt; process() &#123; Callable&lt;Map&lt;String, Object&gt;&gt; callable = () -&gt; &#123; return taskService.execute(); &#125;; return callable; SpringMvc异步实现方式二：1234567891011// taskService是一个@Service注解类public WebAsyncTask process() &#123; Callable&lt;Map&lt;String, Object&gt;&gt; callable = taskService::execute; return new WebAsyncTask&lt;&gt;(20000, callable);&#125;// taskService是一个@Service注解类public WebAsyncTask process() &#123; Callable&lt;Map&lt;String, Object&gt;&gt; callable = taskService::execute; return new WebAsyncTask&lt;&gt;(callable);&#125; SpringMvc异步实现方式三：123456public DeferredResult&lt;Map&lt;String, Object&gt;&gt; process() &#123; DeferredResult&lt;Map&lt;String, Object&gt;&gt; deferredResult = new DeferredResult&lt;&gt;(); CompletableFuture.supplyAsync(taskService::execute) .whenCompleteAsync((result, throwable) -&gt; deferredResult.setResult(result)); return deferredResult;&#125; 方式一和方式二Spring返回的 Callable 被 RequestMappingHandlerAdapter 拦截，使用 SimpleAsyncTaskExecutor 线程池处理，每当任务被提交到此线程池时，线程池产生一个新的线程去执行Callable中的代码， 每次都产生新的线程而且没有上上限(默认没有上限的，可以设置concurrencyLimit属性来设置线程数的大小) 但： SimpleAsyncTaskExecutor 线程池性能不好，可使用自定义的线程池来代替。 方式三使用的是 CompletableFuture.supplyAsync ，在 completablefuture 的 supplyasync 方法将在 ForkJoinPool 池运行任务。也可以使用任何其他的线程池来执行。 若不自定线程池，MvcAsync线程数会飙涨： 自定义MVC Callable线程池： 123456789101112131415161718192021222324252627282930313233@Bean@ConfigurationProperties(prefix = &quot;spring.task.mvcPool&quot;)public TaskPoolConfig mvcPoolConfig() &#123; return new TaskPoolConfig();&#125;@Beanpublic AsyncTaskExecutor mvcTaskExecutor(TaskPoolConfig mvcPoolConfig) &#123; ThreadPoolTaskExecutor threadPool = new ThreadPoolTaskExecutor(); threadPool.setCorePoolSize(mvcPoolConfig.getCorePoolSize()); threadPool.setMaxPoolSize(mvcPoolConfig.getMaxPoolSize()); threadPool.setQueueCapacity(mvcPoolConfig.getQueueCapacity()); threadPool.setAllowCoreThreadTimeOut(mvcPoolConfig.isAllowCoreThreadTimeOut()); threadPool.setWaitForTasksToCompleteOnShutdown( mvcPoolConfig.isWaitForTasksToCompleteOnShutdown()); threadPool.setKeepAliveSeconds(mvcPoolConfig.getKeepAliveSeconds()); threadPool.setThreadNamePrefix(&quot;Mvc-Thread-&quot;); threadPool.setRejectedExecutionHandler(rejectedExecutionHandler); threadPool.initialize(); return threadPool;&#125;@Beanpublic WebMvcConfigurerAdapter webMvcConfigurerAdapter(AsyncTaskExecutor mvcTaskExecutor) &#123; return new WebMvcConfigurerAdapter() &#123; @Override public void configureAsyncSupport(AsyncSupportConfigurer configurer) &#123; configurer.setTaskExecutor(mvcTaskExecutor); super.configureAsyncSupport(configurer); &#125; &#125;;&#125; 请求由Tomcat业务线程池转移到系统自定义线程池中，从下面的示例中可以明显得看出Tomcat的处理线程非常快的就结束了，而由自定义线程池中的线程去处理任务，等任务结束后再由Tomcat线程响应给用户： 1234567891011121314151617[nio-8011-exec-4] c.i.ent.controller.DashboardController : async start[nio-8011-exec-4] c.i.ent.controller.DashboardController : async end[nio-8011-exec-3] c.i.ent.controller.DashboardController : async start[nio-8011-exec-3] c.i.ent.controller.DashboardController : async end[nio-8011-exec-5] c.i.ent.controller.DashboardController : async start[nio-8011-exec-5] c.i.ent.controller.DashboardController : async end[nio-8011-exec-2] c.i.ent.controller.DashboardController : async start[nio-8011-exec-2] c.i.ent.controller.DashboardController : async end[ Mvc-Thread-4] c.i.ent.service.impl.TaskServiceImpl : Mvc-Thread-4执行进度:task：0/10[ Mvc-Thread-2] c.i.ent.service.impl.TaskServiceImpl : Mvc-Thread-2执行进度:task：0/10[ Mvc-Thread-7] c.i.ent.service.impl.TaskServiceImpl : Mvc-Thread-7执行进度:task：0/10[ Mvc-Thread-5] c.i.ent.service.impl.TaskServiceImpl : Mvc-Thread-5执行进度:task：0/10[ Mvc-Thread-3] c.i.ent.service.impl.TaskServiceImpl : Mvc-Thread-3执行进度:task：0/10[ Mvc-Thread-1] c.i.ent.service.impl.TaskServiceImpl : Mvc-Thread-1执行进度:task：0/10[ Mvc-Thread-6] c.i.ent.service.impl.TaskServiceImpl : Mvc-Thread-6执行进度:task：0/10[ Mvc-Thread-8] c.i.ent.service.impl.TaskServiceImpl : Mvc-Thread-8执行进度:task：0/10[ Mvc-Thread-9] c.i.ent.service.impl.TaskServiceImpl : Mvc-Thread-9执行进度:task：0/10 异步多线程池在实际中可能会用到不同的异步接口使用不同的线程池，以下代码是自定义多个线程池给不同的接口使用的示例代码：多线程池的配置如下，这里做了快、中、慢三个线程池： 1234567891011121314151617181920spring: task: slowMvcPool: corePoolSize: 10 maxPoolSize: 20 queueCapacity: 125 keepAliveSeconds: 60 allowCoreThreadTimeOut: true middleMvcPool: corePoolSize: 20 maxPoolSize: 40 queueCapacity: 250 keepAliveSeconds: 60 allowCoreThreadTimeOut: true fastMvcPool: corePoolSize: 40 maxPoolSize: 80 queueCapacity: 500 keepAliveSeconds: 60 allowCoreThreadTimeOut: true 通过 @Bean 方式将各个线程池的参数注入到Spring中： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768@Bean@ConfigurationProperties(prefix = &quot;spring.task.fastMvcPool&quot;)public TaskPoolConfig fastMvcPoolConfig() &#123; return new TaskPoolConfig();&#125;@Bean@ConfigurationProperties(prefix = &quot;spring.task.middleMvcPool&quot;)public TaskPoolConfig middleMvcPoolConfig() &#123; return new TaskPoolConfig();&#125;@Bean@ConfigurationProperties(prefix = &quot;spring.task.slowMvcPool&quot;)public TaskPoolConfig slowMvcPoolConfig() &#123; return new TaskPoolConfig();&#125;@Beanpublic AsyncTaskExecutor slowMvcTaskExecutor(TaskPoolConfig slowMvcPoolConfig) &#123; ThreadPoolTaskExecutor threadPool = new ThreadPoolTaskExecutor(); threadPool.setCorePoolSize(slowMvcPoolConfig.getCorePoolSize()); threadPool.setMaxPoolSize(slowMvcPoolConfig.getMaxPoolSize()); threadPool.setQueueCapacity(slowMvcPoolConfig.getQueueCapacity()); threadPool.setAllowCoreThreadTimeOut(slowMvcPoolConfig.isAllowCoreThreadTimeOut()); threadPool.setWaitForTasksToCompleteOnShutdown( slowMvcPoolConfig.isWaitForTasksToCompleteOnShutdown()); threadPool.setKeepAliveSeconds(slowMvcPoolConfig.getKeepAliveSeconds()); threadPool.setThreadNamePrefix(&quot;Slow-Mvc-&quot;); threadPool.setRejectedExecutionHandler(rejectedExecutionHandler); threadPool.initialize(); return threadPool;&#125;@Beanpublic AsyncTaskExecutor middleMvcTaskExecutor(TaskPoolConfig middleMvcPoolConfig) &#123; ThreadPoolTaskExecutor threadPool = new ThreadPoolTaskExecutor(); threadPool.setCorePoolSize(middleMvcPoolConfig.getCorePoolSize()); threadPool.setMaxPoolSize(middleMvcPoolConfig.getMaxPoolSize()); threadPool.setQueueCapacity(middleMvcPoolConfig.getQueueCapacity()); threadPool.setAllowCoreThreadTimeOut(middleMvcPoolConfig.isAllowCoreThreadTimeOut()); threadPool.setWaitForTasksToCompleteOnShutdown( middleMvcPoolConfig.isWaitForTasksToCompleteOnShutdown()); threadPool.setKeepAliveSeconds(middleMvcPoolConfig.getKeepAliveSeconds()); threadPool.setThreadNamePrefix(&quot;Middle-Mvc-&quot;); threadPool.setRejectedExecutionHandler(rejectedExecutionHandler); threadPool.initialize(); return threadPool;&#125;@Beanpublic AsyncTaskExecutor fastMvcTaskExecutor(TaskPoolConfig fastMvcPoolConfig) &#123; ThreadPoolTaskExecutor threadPool = new ThreadPoolTaskExecutor(); threadPool.setCorePoolSize(fastMvcPoolConfig.getCorePoolSize()); threadPool.setMaxPoolSize(fastMvcPoolConfig.getMaxPoolSize()); threadPool.setQueueCapacity(fastMvcPoolConfig.getQueueCapacity()); threadPool.setAllowCoreThreadTimeOut(fastMvcPoolConfig.isAllowCoreThreadTimeOut()); threadPool.setWaitForTasksToCompleteOnShutdown( fastMvcPoolConfig.isWaitForTasksToCompleteOnShutdown()); threadPool.setKeepAliveSeconds(fastMvcPoolConfig.getKeepAliveSeconds()); threadPool.setThreadNamePrefix(&quot;Fast-Mvc-&quot;); threadPool.setRejectedExecutionHandler(rejectedExecutionHandler); threadPool.initialize(); return threadPool;&#125; 在Controller层中使用自定义的线程池， WebAsyncTask 支持多种方式的自定义线程池的使用，可以通过下线程池在Spring中的Bean的名称，也可以直接注入线程池Bean，WebAsyncTask可以设置Timeout以及通过onTimeout方法在超时时响应内容，在使用时最好设置，如不设置如果接口超时会抛出 AsyncRequestTimeoutException异常 该异常比较难处理： 1234567891011121314151617181920212223242526@GetMapping(&quot;/slowAsyncTask&quot;)public WebAsyncTask slowAsyncTask(HttpServletResponse response, AsyncTaskExecutor slowMvcTaskExecutor) &#123; logger.info(Thread.currentThread().getName() + &quot; 进入helloController方法&quot;); Callable&lt;Map&lt;String, Object&gt;&gt; callable = taskService::execute; WebAsyncTask asyncTask = new WebAsyncTask( ASYNC_REQUEST_TIME_OUT, slowMvcTaskExecutor, callable); return asyncTask;&#125;@GetMapping(&quot;/middleAsyncTask&quot;)public WebAsyncTask middleAsyncTask(HttpServletResponse response, AsyncTaskExecutor middleMvcTaskExecutor) &#123; logger.info(Thread.currentThread().getName() + &quot; 进入helloController方法&quot;); Callable&lt;Map&lt;String, Object&gt;&gt; callable = taskService::execute; WebAsyncTask asyncTask = new WebAsyncTask( ASYNC_REQUEST_TIME_OUT, middleMvcTaskExecutor, callable); return asyncTask;&#125;@GetMapping(&quot;/fastAsyncTask&quot;)public WebAsyncTask fastAsyncTask(HttpServletResponse response, AsyncTaskExecutor fastMvcTaskExecutor) &#123; logger.info(Thread.currentThread().getName() + &quot; 进入helloController方法&quot;); Callable&lt;Map&lt;String, Object&gt;&gt; callable = taskService::execute; WebAsyncTask asyncTask = new WebAsyncTask( ASYNC_REQUEST_TIME_OUT, fastMvcTaskExecutor, callable); return asyncTask;&#125; Servlet3非阻塞IOServlet3.1以后增加了非阻塞IO实现，需要Tomcat8.x以上支持。 非阻塞 IO 仅对在 Servlet 中的异步处理请求有效，否则当调用 ServletInputStream.setReadListener或ServletOutputStream.setWriteListener方法时将抛出IllegalStateException。Servlet3的非阻塞IO是对Servlet3异步的增强。Servlet3的非阻塞是利用java.util.EventListener的事件驱动机制来实现的。 Servlet3.1的非阻塞IO从下面图中可以看出是面对 InputStream 和 OutPutStream 流的，这里的非阻塞IO跟我们常说的JDK NIO不是一个概念，Servlet3.1的非阻塞是同jdk的事件驱动机制来实现。","tags":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}]},{"title":"SpringMvc处理分发请求原理","date":"2020-10-20T03:02:20.000Z","path":"blog/Spring/SpringMvc处理分发请求原理/","text":"在Spring MVC中是通过 DispatcherServlet前端控制器来完成所有Web请求的转发、匹配、数据处理后，并转由页面进行展示，是MVC实现中最核心的部分。 DispatcherServlet是继承的FrameworkServlet，而FrameworkServlet是HttpServlet的子类， FrameworkServlet 对诸如doGet、doPost等所有放法进行了重写，都调用 processRequest 方法，然后调用子类 DispatcherServlet 中 doService 方法，最终调用 doDispatch 方法处理转发。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101public class DispatcherServlet extends FrameworkServlet &#123; protected void doService(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; logRequest(request); Map&lt;String, Object&gt; attributesSnapshot = null; if (WebUtils.isIncludeRequest(request)) &#123; attributesSnapshot = new HashMap&lt;&gt;(); Enumeration&lt;?&gt; attrNames = request.getAttributeNames(); while (attrNames.hasMoreElements()) &#123; String attrName = (String) attrNames.nextElement(); if (this.cleanupAfterInclude || attrName.startsWith(DEFAULT_STRATEGIES_PREFIX)) &#123; attributesSnapshot.put(attrName, request.getAttribute(attrName)); &#125; &#125; &#125; request.setAttribute(WEB_APPLICATION_CONTEXT_ATTRIBUTE, getWebApplicationContext()); // 把Spring上下文对象存放到Request的attribute中 request.setAttribute(LOCALE_RESOLVER_ATTRIBUTE, this.localeResolver); // 把Spring国际化支持解析器对象存放到Request的attribute中 request.setAttribute(THEME_RESOLVER_ATTRIBUTE, this.themeResolver); // 主题解析器对象 request.setAttribute(THEME_SOURCE_ATTRIBUTE, getThemeSource()); // 主题对象 if (this.flashMapManager != null) &#123; FlashMap inputFlashMap = this.flashMapManager.retrieveAndUpdate(request, response); if (inputFlashMap != null) &#123; request.setAttribute(INPUT_FLASH_MAP_ATTRIBUTE, Collections.unmodifiableMap(inputFlashMap)); &#125; request.setAttribute(OUTPUT_FLASH_MAP_ATTRIBUTE, new FlashMap()); request.setAttribute(FLASH_MAP_MANAGER_ATTRIBUTE, this.flashMapManager); &#125; try &#123; doDispatch(request, response); // 真正的进行处理转发 &#125; finally &#123; if (!WebAsyncUtils.getAsyncManager(request).isConcurrentHandlingStarted()) &#123; if (attributesSnapshot != null) &#123; restoreAttributesAfterInclude(request, attributesSnapshot); &#125; &#125; &#125; &#125; protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; // 声明一个处理器执行链 boolean multipartRequestParsed = false; WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); try &#123; ModelAndView mv = null; Exception dispatchException = null; try &#123; processedRequest = checkMultipart(request); // 检查request对象判断请求是不是文件上传的请求 // 判断是不是文件上传请求，若是则返回的processedRequest是MultipartHttpServletRequest，显然和原始的request对象不是同一个对象 multipartRequestParsed = (processedRequest != request); // 从当前的请求中推断出HandlerExecuteChain处理器执行链对象 mappedHandler = getHandler(processedRequest); if (mappedHandler == null) &#123; noHandlerFound(processedRequest, response); return; &#125; // 根据Handler选择HandlerAdpater对象，默认是@RequestMappingHandlerAdapter对象 HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler()); String method = request.getMethod(); boolean isGet = &quot;GET&quot;.equals(method); if (isGet || &quot;HEAD&quot;.equals(method)) &#123; long lastModified = ha.getLastModified(request, mappedHandler.getHandler()); if (new ServletWebRequest(request, response).checkNotModified(lastModified) &amp;&amp; isGet) &#123; return; &#125; &#125; //触发拦截器的pre方法，返回false，就不进行处理了 if (!mappedHandler.applyPreHandle(processedRequest, response)) &#123; return; &#125; // 通过适配器真正的调用目标方法，RequestMappingHandlerAdapter.handle=&gt;AbstractHandlerMethodAdapter#handle(HttpServletRequest, HttpServletResponse,Object) mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); if (asyncManager.isConcurrentHandlingStarted()) &#123; return; &#125; applyDefaultViewName(processedRequest, mv); // 触发拦截器链的post方法 mappedHandler.applyPostHandle(processedRequest, response, mv); &#125; catch (Exception ex) &#123; dispatchException = ex; &#125; catch (Throwable err) &#123; dispatchException = new NestedServletException(&quot;Handler dispatch failed&quot;, err); &#125; // 处理目标方法返回的结果，主要是渲染视图 processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException); &#125; catch (Exception ex) &#123;// 抛出异常:处理拦截器的afterCompletion方法 triggerAfterCompletion(processedRequest, response, mappedHandler, ex); &#125; catch (Throwable err) &#123;// 抛出异常:处理拦截器的afterCompletion方法 triggerAfterCompletion(processedRequest, response, mappedHandler, new NestedServletException(&quot;Handler processing failed&quot;, err)); &#125; finally &#123; if (asyncManager.isConcurrentHandlingStarted()) &#123; if (mappedHandler != null) &#123; mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response); &#125; &#125; else &#123; if (multipartRequestParsed) &#123; cleanupMultipart(processedRequest); // 清除文件上传时候生成的临时文件 &#125; &#125; &#125; &#125;&#125; 处理器映射器HandlerMapping在初始化完成时，在上下文环境中已定义的所有 HandlerMapping 都已被加载放到一个排好序的List中，存储着HTTP请求对应的映射数据，每个HandlerMapping可持有一系列从URL请求到Controller的映射。对于不同Web请求的映射，Spring MVC提供了不同的 HandlerMapping 的实现，可让应用开发选取不同的映射策略， XML方式通过在 web.xml 中配置的方式注册Bean默认使用 BeanNameUrlHandlerMapping 映射策略，通过 @Controller 、 @RequestMapping 注解的方式使用 RequestMappingHandlerMapping 映射策略。 123456789101112131415161718protected HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception &#123; // Web容器中配置的所有的handlerMapping集合对象在本类中的initHandlerMappings()方法为DispatcherServlet类初始化赋值handlerMappings集合 if (this.handlerMappings != null) &#123; // 循环遍历所有的handlerMappings对象，依次调用handlerMappings的getHandler(request)来获取处理器执行链对象 for (HandlerMapping hm : this.handlerMappings) &#123; if (logger.isTraceEnabled()) &#123; logger.trace(&quot;Testing handler map [&quot; + hm + &quot;] in DispatcherServlet with name &#x27;&quot; + getServletName() + &quot;&#x27;&quot;); &#125; // 依次循环调用HandlerMapping的getHandler方法进行获取HandlerExecutionChain，调用所有的HandlerMapping的父类的AbstractHandlerMapping#getHandler(request) HandlerExecutionChain handler = hm.getHandler(request); if (handler != null) &#123; return handler; &#125; &#125; &#125; // 通过所有的handlerMapping对象 还没有获取到对应的HandlerExecutionChain，则认为该请求无法匹配 return null;&#125; 首先通过 UrlPathHelper 对象解析出request中请求路径，让后通过该路径到RequestMappingHanlderMapping的路径映射注册表 mappingRegistry 中匹配，匹配到后通过 getHandlerExecutionChain 将其封装成一个 HandlerExecutionChain ，然后匹配拦截器规则，将满足条件的拦截器添加到该封装对象中。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091public abstract class AbstractHandlerMapping extends WebApplicationObjectSupport implements HandlerMapping, Ordered &#123; public final HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception &#123; // 找到处理器对象，在本子类的AbstractHandlerMapping的子类RequestMappingHanlderMapping的生命周期回调接口InitializingBean中会把@RequestMapping注解信息和方法映射对象保存到路径映射注册表中 Object handler = getHandlerInternal(request); if (handler == null) &#123; // 判断上一步的handler是否为空 handler = getDefaultHandler(); // 返回默认的handler &#125; if (handler == null) &#123; return null; &#125; if (handler instanceof String) &#123; // 若解析出的handler是String则通过Web容器创建handler对象 String handlerName = (String) handler; handler = obtainApplicationContext().getBean(handlerName); &#125; // 根据处理器来构建处理器执行链对象 HandlerExecutionChain executionChain = getHandlerExecutionChain(handler, request); if (CorsUtils.isCorsRequest(request)) &#123; // 处理跨域 CorsConfiguration globalConfig = this.globalCorsConfigSource.getCorsConfiguration(request); CorsConfiguration handlerConfig = getCorsConfiguration(handler, request); CorsConfiguration config = (globalConfig != null ? globalConfig.combine(handlerConfig) : handlerConfig); executionChain = getCorsHandlerExecutionChain(request, executionChain, config); &#125; return executionChain; &#125; protected HandlerExecutionChain getHandlerExecutionChain(Object handler, HttpServletRequest request) &#123; // 创建处理器执行链对象 HandlerExecutionChain chain = (handler instanceof HandlerExecutionChain ? (HandlerExecutionChain) handler : new HandlerExecutionChain(handler)); // 从请求中获取请求映射路径 String lookupPath = this.urlPathHelper.getLookupPathForRequest(request); // 循环获取所有的拦截器对象 for (HandlerInterceptor interceptor : this.adaptedInterceptors) &#123; // 判断拦截器对象是不是实现HandlerInterceptor if (interceptor instanceof MappedInterceptor) &#123; MappedInterceptor mappedInterceptor = (MappedInterceptor) interceptor; // 通过路径匹配看该拦截器是否会拦截本次请求路径 if (mappedInterceptor.matches(lookupPath, this.pathMatcher)) &#123; chain.addInterceptor(mappedInterceptor.getInterceptor()); &#125; &#125; else &#123; chain.addInterceptor(interceptor); &#125; &#125; return chain; // 返回我们的拦截器链执行器对象 &#125;&#125;public abstract class AbstractHandlerMethodMapping&lt;T&gt; extends AbstractHandlerMapping implements InitializingBean &#123; protected HandlerMethod getHandlerInternal(HttpServletRequest request) throws Exception &#123; // 获取UrlPathHelper对象，用于解析从request中解析出请求映射路径 String lookupPath = getUrlPathHelper().getLookupPathForRequest(request); this.mappingRegistry.acquireReadLock(); // 通过映射注册表获取lock对象 try &#123;// 通过从Request对象中解析出来的lookupPath然后通过lookupPath获取HandlerMethod对象 HandlerMethod handlerMethod = lookupHandlerMethod(lookupPath, request); return (handlerMethod != null ? handlerMethod.createWithResolvedBean() : null); &#125; finally &#123;// 释放锁对象 this.mappingRegistry.releaseReadLock(); &#125; &#125; protected HandlerMethod lookupHandlerMethod(String lookupPath, HttpServletRequest request) throws Exception &#123; List&lt;Match&gt; matches = new ArrayList&lt;&gt;(); // 根据路径去MappingRegistry注册表中的urlLookup的map对象中获取RequestMappingInfo对象，mappingRegistry在RequestMappingHandlerMapping的bean的初始化方法就进行解析保存到注册表中 List&lt;T&gt; directPathMatches = this.mappingRegistry.getMappingsByUrl(lookupPath); // 判断通过解析出来的lookUpPath解析出来的RequestMappingInfo不为空 把RequestMappingInfo封装成为Match保存到集合中 if (directPathMatches != null) &#123; addMatchingMappings(directPathMatches, matches, request); &#125; if (matches.isEmpty()) &#123; addMatchingMappings(this.mappingRegistry.getMappings().keySet(), matches, request); &#125; if (!matches.isEmpty()) &#123; Comparator&lt;Match&gt; comparator = new MatchComparator(getMappingComparator(request)); // 创建Match的匹配器对象 matches.sort(comparator); // 对匹配器进行排序 Match bestMatch = matches.get(0); // 默认选择第一个为最匹配的 if (matches.size() &gt; 1) &#123; if (CorsUtils.isPreFlightRequest(request)) &#123; return PREFLIGHT_AMBIGUOUS_MATCH; &#125; Match secondBestMatch = matches.get(1); // 获取第二最匹配的 if (comparator.compare(bestMatch, secondBestMatch) == 0) &#123; // 若第一个和第二个是一样的则抛出异常 Method m1 = bestMatch.handlerMethod.getMethod(); Method m2 = secondBestMatch.handlerMethod.getMethod(); throw new IllegalStateException(&quot;Ambiguous handler methods mapped for HTTP path &#x27;&quot; + request.getRequestURL() + &quot;&#x27;: &#123;&quot; + m1 + &quot;, &quot; + m2 + &quot;&#125;&quot;); &#125; &#125; request.setAttribute(BEST_MATCHING_HANDLER_ATTRIBUTE, bestMatch.handlerMethod); // 把最匹配的设置到request中 handleMatch(bestMatch.mapping, lookupPath, request); return bestMatch.handlerMethod; // 返回最匹配的 &#125; else &#123; return handleNoMatch(this.mappingRegistry.getMappings().keySet(), lookupPath, request); &#125; &#125;&#125; 处理器适配器HandlerAdapter1234567891011121314151617181920212223public class DispatcherServlet extends FrameworkServlet &#123; protected HandlerAdapter getHandlerAdapter(Object handler) throws ServletException &#123; if (this.handlerAdapters != null) &#123; // 循环系统配置配置的handlerAdapters for (HandlerAdapter ha : this.handlerAdapters) &#123; if (ha.supports(handler)) &#123; return ha; &#125; &#125; &#125; throw new ServletException(&quot;No adapter for handler [&quot; + handler + &quot;]: The DispatcherServlet configuration needs to include a HandlerAdapter that supports this handler&quot;); &#125;&#125;public abstract class AbstractHandlerMethodAdapter extends WebContentGenerator implements HandlerAdapter, Ordered &#123; public final boolean supports(Object handler) &#123; // 判断hanlder是不是HandlerMethod实现类或者子类 &amp;&amp; 默认返回true return (handler instanceof HandlerMethod &amp;&amp; supportsInternal((HandlerMethod) handler)); &#125;&#125;public class RequestMappingHandlerAdapter extends AbstractHandlerMethodAdapter implements BeanFactoryAware, InitializingBean &#123; protected boolean supportsInternal(HandlerMethod handlerMethod) &#123; return true; &#125;&#125; Spring MVC采用适配器模式来适配调用指定Handler，根据Handler的不同种类采用不同的Adapter，其对应关系如下： Handler类别 对应适配器 描述 Controller SimpleControllerHandlerAdapter 标准控制器，返回ModelAndView，实现Controller接口 HttpRequestHandler HttpRequestHandlerAdapter 实现HttpRequestHandler接口 Servlet SimpleServletHandlerAdapter 基于标准的 Servlet 处理，继承HttpServlet HandlerMethod RequestMappingHandlerAdapter 基于 @RequestMapping 对应方法处理 12345678910111213141516171819202122232425262728public class SimpleController implements Controller &#123; @Override public ModelAndView handleRequest(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; return null; &#125;&#125;public class HttpRequestController implements HttpRequestHandler &#123; @Override public void handleRequest(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; &#125;&#125;public class ServletController extends HttpServlet &#123; @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; super.doGet(req, resp); &#125; @Override protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; super.doPost(req, resp); &#125;&#125;@Controllerpublic class RequestController &#123; @RequestMapping(value = &quot;/hello&quot;) public String hello() &#123; return &quot;a&quot;; &#125;&#125; 执行处理器方法过程通过上面获取的具体的HandlerAdapter调用具体的handle方法， RequestMappingHandlerAdapter 是调用超类 AbstractHandlerMethodAdapter 的handle方法从而调用自身的 handleInternal 方法。 1234567891011121314151617181920212223242526272829303132333435public abstract class AbstractHandlerMethodAdapter extends WebContentGenerator implements HandlerAdapter, Ordered &#123; public final ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; return handleInternal(request, response, (HandlerMethod) handler); // 调用到具体子类的方法 &#125;&#125;public class RequestMappingHandlerAdapter extends AbstractHandlerMethodAdapter implements BeanFactoryAware, InitializingBean &#123; protected ModelAndView handleInternal(HttpServletRequest request, HttpServletResponse response, HandlerMethod handlerMethod) throws Exception &#123; ModelAndView mav; checkRequest(request); // 检查请求对象 // 判断当前是否需要支持在同一个session中只能线性地处理请求，synchronized是JVM进程级，故分布式环境下，无法达到同步Session的功能。默认情况下synchronizeOnSession为false if (this.synchronizeOnSession) &#123; HttpSession session = request.getSession(false); // 获取当前请求的session对象 if (session != null) &#123; Object mutex = WebUtils.getSessionMutex(session); // 为当前session生成一个唯一的可用于锁定的key synchronized (mutex) &#123; mav = invokeHandlerMethod(request, response, handlerMethod); // 对HandlerMethod进行参数等的适配处理，并调用目标handler &#125; &#125; else &#123;// 若当前不存在session，则直接对HandlerMethod进行适配 mav = invokeHandlerMethod(request, response, handlerMethod); &#125; &#125; else &#123; // 若当前不需要对session进行同步处理，则直接对HandlerMethod进行适配 mav = invokeHandlerMethod(request, response, handlerMethod); &#125; // 判断当前请求头中是否包含Cache-Control请求头，如果不包含，则对当前response进行处理 if (!response.containsHeader(HEADER_CACHE_CONTROL)) &#123; // 若当前SessionAttribute中存在配置的attributes，则为其设置过期时间。这里SessionAttribute主要是通过@SessionAttribute注解生成的 if (getSessionAttributesHandler(handlerMethod).hasSessionAttributes()) &#123; applyCacheSeconds(response, this.cacheSecondsForSessionAttributeHandlers); &#125; else &#123; // 若当前不存在SessionAttributes，则判断当前是否存在Cache-Control设置，若存在则按照该设置进行response处理，若不存在则设置response中的Cache的过期时间为-1，即立即失效 prepareResponse(response); &#125; &#125; return mav; &#125;&#125; 首先获取容器中全局配置的InitBinder 和当前HandlerMethod所对应的Controller中配置的 InitBinder ，用于参数的绑定，然后获取容器中全局配置的ModelAttribute 和当前HandlerMethod所对应的Controller中配置的 ModelAttribute ，这些配置的方法将会在目标方法调用之前进行调用。 将handlerMethod封装为一个 ServletInvocableHandlerMethod 对象，该对象用于对当前request的整体调用流程进行了封装，设置参数解析器对象，设置返回值解析对象，并将前面创建的WebDataBinderFactory也设置到ServletInvocableHandlerMethod中，然后通过 initModel() 方法调用前面获取到的 @ModelAttribute标注的方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109protected ModelAndView invokeHandlerMethod(HttpServletRequest request, HttpServletResponse response, HandlerMethod handlerMethod) throws Exception &#123; ServletWebRequest webRequest = new ServletWebRequest(request, response); // 把请求req resp包装成ServletWebRequest try &#123; // 获取容器中全局配置的InitBinder和当前HandlerMethod所对应的Controller中配置的InitBinder，用于参数的绑定 WebDataBinderFactory binderFactory = getDataBinderFactory(handlerMethod); // 获取容器中全局配置的ModelAttribute和当前HandlerMethod所对应的Controller中配置的ModelAttribute，这些配置的方法将会在目标方法调用之前进行调用 ModelFactory modelFactory = getModelFactory(handlerMethod, binderFactory); // 将handlerMethod封装为一个ServletInvocableHandlerMethod对象，该对象用于对当前request的整体调用流程进行了封装HanlderMethod：InvocableHandlerMethod:invokeForRequest()，ServletInvocableHandlerMethod:invokeAndHandle() ServletInvocableHandlerMethod invocableMethod = createInvocableHandlerMethod(handlerMethod); // 为invocableMethod(ServletInvocableHandlerMethod)设置参数解析器对象argumentResolvers的初始化就是在RequestMappingHandlerAdapter的生命周期回调afterPropertiesSet()方法进行对argumentResolvers初始化赋值，用于解析参数 if (this.argumentResolvers != null) &#123; invocableMethod.setHandlerMethodArgumentResolvers(this.argumentResolvers); &#125; // 为invocableMethod(ServletInvocableHandlerMethod)设置参数解析器对象argumentResolvers的初始化就是在RequestMappingHandlerAdapter的生命周期回调afterPropertiesSet()方法进行对returnValueHandlers初始化赋值，用于解析返回值 if (this.returnValueHandlers != null) &#123; invocableMethod.setHandlerMethodReturnValueHandlers(this.returnValueHandlers); &#125; // 将前面创建的WebDataBinderFactory设置到ServletInvocableHandlerMethod中 invocableMethod.setDataBinderFactory(binderFactory); // 设置ParameterNameDiscoverer，该对象将按照一定的规则获取当前参数的名称 invocableMethod.setParameterNameDiscoverer(this.parameterNameDiscoverer); // 这里initModel()方法主要作用是调用前面获取到的@ModelAttribute标注的方法，从而达到@ModelAttribute标注的方法能够在目标Handler调用之前调用的目的 ModelAndViewContainer mavContainer = new ModelAndViewContainer(); mavContainer.addAllAttributes(RequestContextUtils.getInputFlashMap(request)); // 调用我们标注了@ModelAttribute的方法,主要是为目标方法预加载 modelFactory.initModel(webRequest, mavContainer, invocableMethod); // 重定向时，忽略model中的数据 mavContainer.setIgnoreDefaultModelOnRedirect(this.ignoreDefaultModelOnRedirect); // 获取当前AsyncWebRequest，主要作用是判断目标handler返回值是否为WebAsyncTask或DefferredResult，若是则说明当前请求的处理应该是异步的。 AsyncWebRequest asyncWebRequest = WebAsyncUtils.createAsyncWebRequest(request, response); asyncWebRequest.setTimeout(this.asyncRequestTimeout); // 封装异步任务的线程池，request和interceptors到WebAsyncManager中 WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); asyncManager.setTaskExecutor(this.taskExecutor); asyncManager.setAsyncWebRequest(asyncWebRequest); asyncManager.registerCallableInterceptors(this.callableInterceptors); asyncManager.registerDeferredResultInterceptors(this.deferredResultInterceptors); // 这里就是用于判断当前请求是否有异步任务结果的，如果存在，则对异步任务结果进行封装 if (asyncManager.hasConcurrentResult()) &#123; Object result = asyncManager.getConcurrentResult(); mavContainer = (ModelAndViewContainer) asyncManager.getConcurrentResultContext()[0]; asyncManager.clearConcurrentResult(); if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Found concurrent result value [&quot; + result + &quot;]&quot;); &#125; invocableMethod = invocableMethod.wrapConcurrentResult(result); &#125; // 对请求参数进行处理，调用目标HandlerMethod，并且将返回值封装为一个ModelAndView对象 invocableMethod.invokeAndHandle(webRequest, mavContainer); if (asyncManager.isConcurrentHandlingStarted()) &#123; return null; &#125; // 对封装的ModelAndView进行处理，主要是判断当前请求是否进行了重定向，如果进行了重定向，还会判断是否需要将FlashAttributes封装到新的请求中 return getModelAndView(mavContainer, modelFactory, webRequest); &#125; finally &#123;// 调用request destruction callbacks和对SessionAttributes进行处理 webRequest.requestCompleted(); &#125;&#125;private WebDataBinderFactory getDataBinderFactory(HandlerMethod handlerMethod) throws Exception &#123; Class&lt;?&gt; handlerType = handlerMethod.getBeanType(); // 获取HandlerMethod的class类型 Set&lt;Method&gt; methods = this.initBinderCache.get(handlerType); // 尝试从缓存中加载Controller中的标注了@InitBinder注解的方法 if (methods == null) &#123; // 缓存中没有，则查找Controller中标注@InitBinder注解的方法 methods = MethodIntrospector.selectMethods(handlerType, INIT_BINDER_METHODS); this.initBinderCache.put(handlerType, methods); // 加入到局部缓存initBinder中 &#125; List&lt;InvocableHandlerMethod&gt; initBinderMethods = new ArrayList&lt;&gt;(); // 定义一个initBinderMethod的集合 // 全局的initBinder注解全局一般是在@ControllerAdvice的类中，initBinderAdviceCache缓存变量在RequestMappingHandlerAdapter类的afterPropertiesSet方法中去加载的 this.initBinderAdviceCache.forEach((clazz, methodSet) -&gt; &#123; if (clazz.isApplicableToBeanType(handlerType)) &#123; // 判断全局的webInitBinder能否作用到当前的controller中 Object bean = clazz.resolveBean(); for (Method method : methodSet) &#123; // 把方法加入到集合中 initBinderMethods.add(createInitBinderMethod(bean, method)); &#125; &#125; &#125;); for (Method method : methods) &#123; // 合并局部的initbinder和全局的initbinder Object bean = handlerMethod.getBean(); initBinderMethods.add(createInitBinderMethod(bean, method)); &#125; return createDataBinderFactory(initBinderMethods); // 创建数据绑定器工厂&#125;private ModelFactory getModelFactory(HandlerMethod handlerMethod, WebDataBinderFactory binderFactory) &#123; // 获取SessionAttributesHandler，解析类上标注的@SessionAttributes注解 // 若类上标注了@SessionAttributes注解，则目标返回模型数据就回被放到session中 SessionAttributesHandler sessionAttrHandler = getSessionAttributesHandler(handlerMethod); Class&lt;?&gt; handlerType = handlerMethod.getBeanType(); // 获取目标controller的class对象 Set&lt;Method&gt; methods = this.modelAttributeCache.get(handlerType); // 尝试从modelAttributeCache缓存中获取对象 if (methods == null) &#123; // 缓存中没有该对象 // 若缓存中没有相关属性，则在当前bean中查找所有使用@ModelAttribute标注，但是没使用@RequestMapping标注的方法，并将这些方法缓存起来 methods = MethodIntrospector.selectMethods(handlerType, MODEL_ATTRIBUTE_METHODS); this.modelAttributeCache.put(handlerType, methods); // 加入到缓存中 &#125; List&lt;InvocableHandlerMethod&gt; attrMethods = new ArrayList&lt;&gt;(); this.modelAttributeAdviceCache.forEach((clazz, methodSet) -&gt; &#123; // 获取全局的标注了@ControllerAdivce中的@ModelAttribute注解的方法 // 判断标注了@ControllerAdivce类型全局@ModelAttribute注解的能否匹配当前的class对象 if (clazz.isApplicableToBeanType(handlerType)) &#123; Object bean = clazz.resolveBean(); for (Method method : methodSet) &#123; // 创建InvocableHandlerMethod加入到缓存中 attrMethods.add(createModelAttributeMethod(binderFactory, bean, method)); &#125; &#125; &#125;); for (Method method : methods) &#123; // 合并全局和局部的@ModelAttribute方法 Object bean = handlerMethod.getBean(); attrMethods.add(createModelAttributeMethod(binderFactory, bean, method)); &#125; return new ModelFactory(attrMethods, binderFactory, sessionAttrHandler);//创建ModelFactory返回&#125; 最终通过invokeAndHandle中调用 invokeForRequest 对 InitBinder 配置的方法和具体的Controller方法进行调用，对于 InitBinder方法的具体调用是在 getMethodArgumentValues 方法中 resolveArgument 调用具体的参数解析器来完成的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public void invokeAndHandle(ServletWebRequest webRequest, ModelAndViewContainer mavContainer, Object... providedArgs) throws Exception &#123; Object returnValue = invokeForRequest(webRequest, mavContainer, providedArgs); // 真正的调用目标对象 setResponseStatus(webRequest); // 设置相关的返回状态 if (returnValue == null) &#123; // 如果请求处理完成，则设置requestHandled属性 if (isRequestNotModified(webRequest) || getResponseStatus() != null || mavContainer.isRequestHandled()) &#123; mavContainer.setRequestHandled(true); return; &#125; &#125; else if (StringUtils.hasText(getResponseStatusReason())) &#123; mavContainer.setRequestHandled(true); return; // 如果请求失败，但是有错误原因，那么也会设置requestHandled属性 &#125; mavContainer.setRequestHandled(false); Assert.state(this.returnValueHandlers != null, &quot;No return value handlers&quot;); try &#123;// 遍历当前容器中所有ReturnValueHandler，判断哪种handler支持当前返回值的处理，若支持，则使用该handler处理该返回值 this.returnValueHandlers.handleReturnValue(returnValue, getReturnValueType(returnValue), mavContainer, webRequest); &#125; catch (Exception ex) &#123; if (logger.isTraceEnabled()) &#123; logger.trace(getReturnValueHandlingErrorMessage(&quot;Error handling return value&quot;, returnValue), ex); &#125; throw ex; &#125;&#125;public Object invokeForRequest(NativeWebRequest request, @Nullable ModelAndViewContainer mavContainer, Object... providedArgs) throws Exception &#123; Object[] args = getMethodArgumentValues(request, mavContainer, providedArgs); // 获取目标方法入参的值 Object returnValue = doInvoke(args); // 真的的调用目标方法 return returnValue;&#125;private Object[] getMethodArgumentValues(NativeWebRequest request, @Nullable ModelAndViewContainer mavContainer, Object... providedArgs) throws Exception &#123; MethodParameter[] parameters = getMethodParameters(); // 获取目标方法参数的描述数组对象 Object[] args = new Object[parameters.length]; // 用来初始化对应参数名称的参数值得数组 for (int i = 0; i &lt; parameters.length; i++) &#123; //循环参数名数组 MethodParameter parameter = parameters[i]; parameter.initParameterNameDiscovery(this.parameterNameDiscoverer); // 为MethodParameter设置参数名称探测器对象 args[i] = resolveProvidedArgument(parameter, providedArgs); if (args[i] != null) &#123; continue; &#125; if (this.argumentResolvers.supportsParameter(parameter)) &#123; // 获取所有的参数解析器，然后筛选出合适的解析器 try &#123;//通过参数解析器来解析参数 args[i] = this.argumentResolvers.resolveArgument(parameter, mavContainer, request, this.dataBinderFactory); continue; &#125; catch (Exception ex) &#123; throw ex; &#125; &#125; if (args[i] == null) &#123; throw new IllegalStateException(&quot;Could not resolve method parameter at index &quot; + parameter.getParameterIndex() + &quot; in &quot; + parameter.getExecutable().toGenericString() + &quot;: &quot; + getArgumentResolutionErrorMessage(&quot;No suitable resolver for&quot;, i)); &#125; &#125; return args;&#125;public Object resolveArgument(MethodParameter parameter, @Nullable ModelAndViewContainer mavContainer, NativeWebRequest webRequest, @Nullable WebDataBinderFactory binderFactory) throws Exception &#123; HandlerMethodArgumentResolver resolver = getArgumentResolver(parameter); // 通过参数筛选出参数解析器对象 if (resolver == null) &#123; throw new IllegalArgumentException(&quot;Unknown parameter type [&quot; + parameter.getParameterType().getName() + &quot;]&quot;); &#125; // 挑选参数解析器来解析真正的参数值 return resolver.resolveArgument(parameter, mavContainer, webRequest, binderFactory);&#125;public void handleReturnValue(@Nullable Object returnValue, MethodParameter returnType, ModelAndViewContainer mavContainer, NativeWebRequest webRequest) throws Exception &#123; // 获取能够处理当前返回值的Handler，比如如果返回值是ModelAndView类型，那么这里的handler就是ModelAndViewMethodReturnValueHandler HandlerMethodReturnValueHandler handler = selectHandler(returnValue, returnType); if (handler == null) &#123; throw new IllegalArgumentException(&quot;Unknown return value type: &quot; + returnType.getParameterType().getName()); &#125; // 通过获取到的handler处理返回值，并将其封装到ModelAndViewContainer中 handler.handleReturnValue(returnValue, returnType, mavContainer, webRequest);&#125; 视图解析器视图解析器ViewResolver负责将处理结果生成View视图，首先根据逻辑视图名解析成物理视图名即具体的页面地址，再生成View视图对象，最后对View进行渲染将处理结果通过页面展示。视图对象是由视图解析器负责实例化。 视图解析器的作用是将逻辑视图转为物理视图，所有的视图解析器都必须实现 ViewResolver 接口。SpringMVC为逻辑视图名的解析提供了不同的策略，可在Spring WEB上下文中配置一种或多种解析策略，并指定他们之间的先后顺序。每一种映射策略对应一个具体的视图解析器实现类。可选择一种视图解析器或混用多种视图解析器。可通过order属性指定解析器的优先顺序，order越小优先级越高，SpringMVC会按视图解析器的优先顺序对逻辑视图名进行解析，直到解析成功并返回视图对象，否则抛出ServletException异常。 分类 解析器类型 说明 解析为Bean的名称 BeanNameViewResolver Bean的id即为逻辑视图名称。 解析为URL文件 InternalResourceViewResolver 将视图名解析成一个 URL 文件。 解析指定XML文件 XmlViewResolver 解析指定位置的XML文件，默认在&#x2F;WEB-INF&#x2F;views.xml 解析指定属性文件 ResourceBundleViewResolver 解析properties文件。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950private void processDispatchResult(HttpServletRequest request, HttpServletResponse response, @Nullable HandlerExecutionChain mappedHandler, @Nullable ModelAndView mv, @Nullable Exception exception) throws Exception &#123; boolean errorView = false; if (exception != null) &#123; // 异常页面处理 if (exception instanceof ModelAndViewDefiningException) &#123; mv = ((ModelAndViewDefiningException) exception).getModelAndView(); &#125; else &#123; Object handler = (mappedHandler != null ? mappedHandler.getHandler() : null); mv = processHandlerException(request, response, handler, exception); errorView = (mv != null); &#125; &#125; if (mv != null &amp;&amp; !mv.wasCleared()) &#123; //渲染视图 render(mv, request, response); if (errorView) &#123; WebUtils.clearErrorRequestAttributes(request); &#125; &#125; if (WebAsyncUtils.getAsyncManager(request).isConcurrentHandlingStarted()) &#123; return; &#125; if (mappedHandler != null) &#123; mappedHandler.triggerAfterCompletion(request, response, null); &#125;&#125;protected void render(ModelAndView mv, HttpServletRequest request, HttpServletResponse response) throws Exception &#123; //获取国际化语言解析器对象 Locale locale = (this.localeResolver != null ? this.localeResolver.resolveLocale(request) : request.getLocale()); response.setLocale(locale); View view; String viewName = mv.getViewName();//获取视图名称 if (viewName != null) &#123;// 根据的视图名称通过视图解析器对象解析成为真正的物理视图 view = resolveViewName(viewName, mv.getModelInternal(), locale, request); if (view == null) &#123; throw new ServletException(&quot;Could not resolve view with name &#x27;&quot; + mv.getViewName() + &quot;&#x27; in servlet with name &#x27;&quot; + getServletName() + &quot;&#x27;&quot;); &#125; &#125; else &#123; view = mv.getView(); if (view == null) &#123; throw new ServletException(&quot;ModelAndView [&quot; + mv + &quot;] neither contains a view name nor a View object in servlet with name &#x27;&quot; + getServletName() + &quot;&#x27;&quot;); &#125; &#125; try &#123; if (mv.getStatus() != null) &#123; response.setStatus(mv.getStatus().value()); &#125; view.render(mv.getModelInternal(), request, response); //渲染模型视图 &#125; catch (Exception ex) &#123; throw ex; &#125;&#125; 根据的视图名称通过视图解析器对象解析成为真正的物理视图，最终调用 AbstractCachingViewResolver 的createView然后调用具体的视图解析器去创建物理视图。 123456789101112131415161718192021222324252627282930313233343536373839404142434445protected View resolveViewName(String viewName, @Nullable Map&lt;String, Object&gt; model, Locale locale, HttpServletRequest request) throws Exception &#123; if (this.viewResolvers != null) &#123; //判断当前的视图解析器集合是否为空 for (ViewResolver viewResolver : this.viewResolvers) &#123; //循环调用的视图解析器对象解析视图 // 一旦有的视图解析器能够解析出视图，后面的视图解析器不在参与解析直接返回 View view = viewResolver.resolveViewName(viewName, locale); if (view != null) &#123; return view; &#125; &#125; &#125; return null;&#125;public View resolveViewName(String viewName, Locale locale) throws Exception &#123; // 是否启用缓存，可通过setCache()方法或setCacheLimit()方法开启缓存，是一个ConcurrentHashMap，默认缓存大小1024，可在配置视图解析器的时候，配置是否启用缓存默认情况下为了提升性能是开启的 if (!isCache()) &#123; return createView(viewName, locale); &#125; else &#123; Object cacheKey = getCacheKey(viewName, locale); // 获取缓存的key:viewName + &#x27;_&#x27; + locale; View view = this.viewAccessCache.get(cacheKey); // 尝试去缓存中加载 if (view == null) &#123; // dcl,防止并发解析 synchronized (this.viewCreationCache) &#123; view = this.viewCreationCache.get(cacheKey); if (view == null) &#123; view = createView(viewName, locale); // 调用子类去创建视图对象 if (view == null &amp;&amp; this.cacheUnresolved) &#123; view = UNRESOLVED_VIEW; &#125; if (view != null) &#123; this.viewAccessCache.put(cacheKey, view); this.viewCreationCache.put(cacheKey, view); if (logger.isTraceEnabled()) &#123; logger.trace(&quot;Cached view [&quot; + cacheKey + &quot;]&quot;); &#125; &#125; &#125; &#125; &#125; return (view != UNRESOLVED_VIEW ? view : null); &#125;&#125;public abstract class AbstractCachingViewResolver extends WebApplicationObjectSupport implements ViewResolver &#123; protected View createView(String viewName, Locale locale) throws Exception &#123; return loadView(viewName, locale); //加载一个视图 &#125;&#125; 分类 视图类型 说明 URL视图 InternalResourceView 将JSP或者其他资源封装成一个视图，InternaleResourceViewResolver默认视图类型。 JstlView 当在页面中使用了JSTL标签库的国际化标签后，需要采用的类型。 文档类视图 AbstractPdfView PDF文档视图的抽象类 AbstarctXlsView 4.2之后加入，Excel文档视图的抽象类，之前使用AbstractExcelView JSON视图 MappingJackson2JsonView 将模型数据封装成Json格式数据输出, 需借助Jackson开源框架。 XML视图 MappingJackson2XmlView 4.1后加入，将模型数据封装成XML格式数据 视图的作用是渲染模型数据，将模型里的数据以某种形式呈现。为了实现视图模型和具体实现技术的解耦，Spring在org.springframework.web.servlet包中定义了一个高度抽象的View接口。通过 renderMergedOutputModel 调用具体的视图类去渲染视图。 123456789public void render(@Nullable Map&lt;String, ?&gt; model, HttpServletRequest request, HttpServletResponse response) throws Exception &#123; if (logger.isTraceEnabled()) &#123; logger.trace(&quot;Rendering view with name &#x27;&quot; + this.beanName + &quot;&#x27; with model &quot; + model + &quot; and static attributes &quot; + this.staticAttributes); &#125; Map&lt;String, Object&gt; mergedModel = createMergedOutputModel(model, request, response); // 获取模型数据 prepareResponse(request, response); // 设置响应头 renderMergedOutputModel(mergedModel, getRequestToExpose(request), response);&#125;","tags":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}]},{"title":"Spring初始化扩展","date":"2020-10-19T08:08:20.000Z","path":"blog/Spring/Spring初始化扩展/","text":"经常需要在容器启动时做一些钩子动作，比如注册消息消费者，监听配置等。 容器刷新完成扩展点监听容器刷新完成扩展点ApplicationListener&lt;ContextRefreshedEvent&gt;容器刷新成功意味着所有的Bean已初始化完成，当容器刷新之后Spring将会调用容器内所有实现了ApplicationListener&lt;ContextRefreshedEvent&gt;的Bean的onApplicationEvent方法，应用程序可以以此达到监听容器初始化完成事件的目的。 1234567@Log4j2public class ApplicationListenerExample implements ApplicationListener&lt;ContextRefreshedEvent&gt; &#123; @Override public void onApplicationEvent(ContextRefreshedEvent event) &#123; log.info(&quot;ApplicationListenerExample Startup&quot;); &#125;&#125; 上面的写法，就会造成onApplicationEvent方法被执行两次。因为在Spring MVC项目中，系统会存在两个容器，一个是root ApplicationContext，一个是作为root ApplicationContext的子容器的WebApplicationContext。 123456789@Log4j2public class ApplicationListenerExample implements ApplicationListener&lt;ContextRefreshedEvent&gt; &#123; @Override public void onApplicationEvent(ContextRefreshedEvent event) &#123; if (event.getApplicationContext().getParent() == null) &#123; log.info(&quot;ApplicationListenerExample Startup&quot;); &#125; &#125;&#125; 自定义事件可以借助Spring以最小成本实现一个观察者模式，首先定义一个事件，然后注册一个监听器，最后发布事件： 1234567891011121314151617181920212223242526public class NotifyEvent extends ApplicationEvent &#123; public NotifyEvent(Object source) &#123; super(source); &#125;&#125;@Log4j2public class NotifyListener implements ApplicationListener&lt;NotifyEvent&gt; &#123; @Override public void onApplicationEvent(NotifyEvent event) &#123; log.info(&quot;NotifyListener Startup&quot;); &#125;&#125;@RunWith(SpringRunner.class)@SpringBootTestpublic class ListenerTest &#123; @Autowired private WebApplicationContext webApplicationContext; @Test public void testListener() &#123; NotifyEvent event = new NotifyEvent(&quot;object&quot;); webApplicationContext.publishEvent(event); &#125;&#125; SpringBoot的CommandLineRunner接口当容器上下文初始化完成之后，SpringBoot也会调用所有实现了CommandLineRunner接口的run方法。 12345678@Log4j2@Componentpublic class CommandLineStartupRunner implements CommandLineRunner &#123; @Override public void run(String... args) throws Exception &#123; log.info(&quot;CommandLineStartupRunner Startup&quot;); &#125;&#125; 多个实现了CommandLineRunner的Bean的执行顺序可以根据Bean上的@Order注解调整。其run方法可以接受从控制台输入的参数，跟ApplicationListener&lt;ContextRefreshedEvent&gt;这种扩展相比更加灵活。 1java -jar CommandLineStartupRunner.jar abc abcd SpringBoot的ApplicationRunner接口与SpringBoot的CommandLineRunner接口扩展类似，只不过接受参数是一个ApplicationArguments类，对控制台输入的参数提供了更好的封装，以--开头的被视为带选项的参数，否则是普通的参数。 12345678@Log4j2@Componentpublic class ApplicationStartupRunner implements ApplicationRunner &#123; @Override public void run(ApplicationArguments args) throws Exception &#123; log.info(&quot;ApplicationStartupRunner Startup: &#123;&#125;&quot;, args.getOptionNames()); &#125;&#125; 控制台输入参数示例： 1java -jar ApplicationStartupRunner.jar abc abcd --autho=mark verbose Bean初始化完成扩展点@PostConstruct注解@PostConstruct注解一般放在Bean的方法上，被@PostConstruct修饰的方法会在Bean初始化后马上调用： 1234567891011@Log4j2@Componentpublic class PostConstructExample &#123; @Autowired private Environment environment; @PostConstruct public void init() &#123; log.info(Arrays.asList(environment.getDefaultProfiles())); &#125;&#125; InitializingBean接口InitializingBean的用法基本上与@PostConstruct一致，只不过相应的Bean需要实现afterPropertiesSet方法。 1234567891011@Log4j2@Componentpublic class InitializingBeanExample implements InitializingBean &#123; @Autowired private Environment environment; @Override public void afterPropertiesSet() throws Exception &#123; log.info(Arrays.asList(environment.getDefaultProfiles())); &#125;&#125; @Bean注解的初始化方法通过@Bean注入Bean的时候可以指定初始化方法： 123456789101112131415@Log4j2@Componentpublic class InitMethodExampleBean &#123; @Autowired private Environment environment; public void init() &#123; log.info(Arrays.asList(environment.getDefaultProfiles())); &#125;&#125;@Bean(initMethod=&quot;init&quot;)public InitMethodExampleBean initMethodExampleBean() &#123; return new InitMethodExampleBean();&#125; 通过构造函数注入Spring也支持通过构造函数注入，我们可以把搞事情的代码写在构造函数中，同样能达到目的 1234567891011@Log4j2@Componentpublic class ConstructorExampleBean &#123; private final Environment environment; @Autowired public ConstructorExampleBean(Environment environment) &#123; this.environment = environment; log.info(Arrays.asList(environment.getDefaultProfiles())); &#125;&#125; Bean初始化完成扩展点执行顺序是：构造函数注入， @PostConstruct注解 ， InitializingBean接口 ， @Bean注解的初始化方法 。","tags":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}]},{"title":"SpringMvc加载机制","date":"2020-10-19T07:08:20.000Z","path":"blog/Spring/SpringMvc加载机制/","text":"Web容器启动时会调用 ServletContainerInitializer 的 onStartup 方法，以Tomcat容器为例，其调用实际是在 StandardContext 容器的 startInternal() 方法中被调用的，且可在该接口的实现类上标注 @HandlesTypes 注解，该注解配置的接口的实现类都会被传递到onStartup方法的入参中，并通过反射调用生成对象，Spring MVC中通过 SpringServletContainerInitializer 实现了 ServletContainerInitializer 接口，并在该类上通过 @HandlesTypes 注解导入了 WebApplicationInitializer 。 1234567891011121314151617181920212223242526272829@HandlesTypes(WebApplicationInitializer.class)public class SpringServletContainerInitializer implements ServletContainerInitializer &#123; // 容器启动的时会调用该方法，且传入@HandlesTypes(WebApplicationInitializer.class) public void onStartup(@Nullable Set&lt;Class&lt;?&gt;&gt; webAppInitializerClasses, ServletContext servletContext) throws ServletException &#123; List&lt;WebApplicationInitializer&gt; initializers = new LinkedList&lt;&gt;(); if (webAppInitializerClasses != null) &#123; // 传入的webAppInitializerClasses类的所有子类 for (Class&lt;?&gt; waiClass : webAppInitializerClasses) &#123; //进行循环敢兴趣的类 // 判断类不是接口，不是抽象类 if (!waiClass.isInterface() &amp;&amp; !Modifier.isAbstract(waiClass.getModifiers()) &amp;&amp; WebApplicationInitializer.class.isAssignableFrom(waiClass)) &#123; try &#123;// 通过反射调用创建类的实例，然后加入到initializers initializers.add((WebApplicationInitializer) ReflectionUtils.accessibleConstructor(waiClass).newInstance()); &#125; catch (Throwable ex) &#123; throw new ServletException(&quot;Failed to instantiate WebApplicationInitializer class&quot;, ex); &#125; &#125; &#125; &#125; if (initializers.isEmpty()) &#123; servletContext.log(&quot;No Spring WebApplicationInitializer types detected on classpath&quot;); return; &#125; servletContext.log(initializers.size() + &quot; Spring WebApplicationInitializers detected on classpath&quot;); // 若WebApplicationInitializer的实现类实现了Orderd接口或者是标注了@Order注解，会进行排序 AnnotationAwareOrderComparator.sort(initializers); for (WebApplicationInitializer initializer : initializers) &#123; initializer.onStartup(servletContext); // 依次循环调用类的实例的onStartup方法 &#125; &#125;&#125; 最终会调用 AbstractDispatcherServletInitializer 抽象类的 onStartup 方法，该方法会先调用超类的onStartup方法创建rootAppContext ，且将rootAppContext设置到ContextLoaderListener ，并将创建的 ContextLoaderListener 设置到 ServletContext 中，在Tomcat的 StandardContext 容器调用 listenerStart() 方法中调用 ContextLoaderListener 的 contextInitialized 方法；然后创建webAppContext ，并将其设置到新创建的 DispatcherServlet 中。 创建 AnnotationConfigWebApplicationContext 上下文仅仅调用 register 方法将创世纪的类和自定义的配置的注册到容器中，并没有启动容器。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public abstract class AbstractDispatcherServletInitializer extends AbstractContextLoaderInitializer &#123; public void onStartup(ServletContext servletContext) throws ServletException &#123; super.onStartup(servletContext); registerDispatcherServlet(servletContext); &#125; protected void registerDispatcherServlet(ServletContext servletContext) &#123; String servletName = getServletName(); Assert.hasLength(servletName, &quot;getServletName() must not return null or empty&quot;); WebApplicationContext servletAppContext = createServletApplicationContext(); Assert.notNull(servletAppContext, &quot;createServletApplicationContext() must not return null&quot;); FrameworkServlet dispatcherServlet = createDispatcherServlet(servletAppContext); Assert.notNull(dispatcherServlet, &quot;createDispatcherServlet(WebApplicationContext) must not return null&quot;); dispatcherServlet.setContextInitializers(getServletApplicationContextInitializers()); ServletRegistration.Dynamic registration = servletContext.addServlet(servletName, dispatcherServlet); if (registration == null) &#123; throw new IllegalStateException(&quot;Failed to register servlet with name &#x27;&quot; + servletName + &quot;&#x27;. &quot; + &quot;Check if there is another servlet registered under the same name.&quot;); &#125; registration.setLoadOnStartup(1); registration.addMapping(getServletMappings()); registration.setAsyncSupported(isAsyncSupported()); Filter[] filters = getServletFilters(); if (!ObjectUtils.isEmpty(filters)) &#123; for (Filter filter : filters) &#123; registerServletFilter(servletContext, filter); &#125; &#125; customizeRegistration(registration); &#125;&#125;public abstract class AbstractContextLoaderInitializer implements WebApplicationInitializer &#123; public void onStartup(ServletContext servletContext) throws ServletException &#123; registerContextLoaderListener(servletContext); &#125; protected void registerContextLoaderListener(ServletContext servletContext) &#123; WebApplicationContext rootAppContext = createRootApplicationContext(); if (rootAppContext != null) &#123; ContextLoaderListener listener = new ContextLoaderListener(rootAppContext); listener.setContextInitializers(getRootApplicationContextInitializers()); servletContext.addListener(listener); &#125; &#125;&#125;public abstract class AbstractAnnotationConfigDispatcherServletInitializer extends AbstractDispatcherServletInitializer &#123; protected WebApplicationContext createRootApplicationContext() &#123; Class&lt;?&gt;[] configClasses = getRootConfigClasses(); if (!ObjectUtils.isEmpty(configClasses)) &#123; AnnotationConfigWebApplicationContext context = new AnnotationConfigWebApplicationContext(); context.register(configClasses); return context; &#125; else &#123; return null; &#125; &#125; protected WebApplicationContext createServletApplicationContext() &#123; AnnotationConfigWebApplicationContext context = new AnnotationConfigWebApplicationContext(); Class&lt;?&gt;[] configClasses = getServletConfigClasses(); if (!ObjectUtils.isEmpty(configClasses)) &#123; context.register(configClasses); &#125; return context; &#125;&#125; 故可通过继承 AbstractAnnotationConfigDispatcherServletInitializer 重写 getRootConfigClasses 、 getServletConfigClasses 方法来自定义设置Root容器的配置类和Web容器的配置类。 1234567891011121314public class ElevenStarterInitializer extends AbstractAnnotationConfigDispatcherServletInitializer &#123; @Override protected Class&lt;?&gt;[] getRootConfigClasses() &#123; return new Class[]&#123;RootConfig.class&#125;; &#125; @Override protected Class&lt;?&gt;[] getServletConfigClasses() &#123; return new Class[]&#123;WebAppConfig.class&#125;; &#125; @Override protected String[] getServletMappings() &#123; return new String[]&#123;&quot;/&quot;&#125;; &#125;&#125; 1234567@Configuration@ComponentScan(basePackages = &quot;com.eleven.icode.imvc&quot;, excludeFilters = &#123; @ComponentScan.Filter(type = FilterType.ANNOTATION, value = &#123;RestController.class, Controller.class&#125;), @ComponentScan.Filter(type = ASSIGNABLE_TYPE, value = WebAppConfig.class),&#125;)public class RootConfig &#123;&#125; 12345678910111213141516171819202122@Configuration@ComponentScan(basePackages = &#123;&quot;com.eleven.icode.imvc&quot;&#125;, includeFilters = &#123; @ComponentScan.Filter(type = FilterType.ANNOTATION, value = &#123;RestController.class, Controller.class&#125;)&#125;, useDefaultFilters = false)@EnableWebMvcpublic class WebAppConfig implements WebMvcConfigurer &#123; @Bean public ElevenInterceptor tulingInterceptor() &#123; return new ElevenInterceptor(); &#125; @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(tulingInterceptor()).addPathPatterns(&quot;/*&quot;); &#125; @Bean public InternalResourceViewResolver internalResourceViewResolver() &#123; InternalResourceViewResolver viewResolver = new InternalResourceViewResolver(); viewResolver.setSuffix(&quot;.jsp&quot;); viewResolver.setPrefix(&quot;/&quot;); return viewResolver; &#125;&#125; ContextLoaderListener 实现了 ServletContextListener 接口，该接口是在Servlet API中定义的，提供了与Servlet生命周期结合的回调 contextInitialized 和 contextDestroyed 。这里只是去启动Root容器。通过注解方式在创建ContextLoaderListener就已将context传递进来了，这里不需要再创建了，只有通过xml方式的context才为空，需要在这里创建根容器对象。 当Root容器初始化完成后会将其保存到 ServletContext 应用上下文对象中，方便在Web容器实例化过程从ServletContext取出来设置为父容器。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public class ContextLoaderListener extends ContextLoader implements ServletContextListener &#123; public void contextInitialized(ServletContextEvent event) &#123; initWebApplicationContext(event.getServletContext()); &#125;&#125;public class ContextLoader &#123; public WebApplicationContext initWebApplicationContext(ServletContext servletContext) &#123; if (servletContext.getAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE) != null) &#123; throw new IllegalStateException(&quot;Cannot initialize context because there is already a root application context present - check whether you have multiple ContextLoader* definitions in your web.xml!&quot;); &#125; try &#123; if (this.context == null) &#123; // 通过注解方式在外面就已经传递进来了，通过xml方式context为空，需要在这里创建根容器对象 this.context = createWebApplicationContext(servletContext); &#125; if (this.context instanceof ConfigurableWebApplicationContext) &#123; // 强制转化成ConfigurableWebApplicationContext ConfigurableWebApplicationContext cwac = (ConfigurableWebApplicationContext) this.context; // 判断ConfigurableWebApplicationContext配置上下文版本的是不是激活了 if (!cwac.isActive()) &#123; // 没有激活 if (cwac.getParent() == null) &#123; // 若此时ConfigurableWebApplicationContext对象的父容器为空 ApplicationContext parent = loadParentContext(servletContext); // 为Root Context加载我们的父容器 cwac.setParent(parent); // parent == null &#125; configureAndRefreshWebApplicationContext(cwac, servletContext); // 配置和刷新根容器对象 &#125; &#125; // 把Spring上下文保存到应用上下文对象中，方便在Spring web上下文对象实例化过程会从servletContext取出来 servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, this.context); ClassLoader ccl = Thread.currentThread().getContextClassLoader(); if (ccl == ContextLoader.class.getClassLoader()) &#123; currentContext = this.context; &#125; else if (ccl != null) &#123; currentContextPerThread.put(ccl, this.context); &#125; return this.context; &#125; catch (RuntimeException ex) &#123; servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, ex); throw ex; &#125; catch (Error err) &#123; servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, err); throw err; &#125; &#125; protected void configureAndRefreshWebApplicationContext(ConfigurableWebApplicationContext wac, ServletContext sc) &#123; if (ObjectUtils.identityToString(wac).equals(wac.getId())) &#123; String idParam = sc.getInitParameter(CONTEXT_ID_PARAM); // 去ServletContext获取contextId if (idParam != null) &#123; wac.setId(idParam); // 若web.xml配置了该参数就设置到容器中 &#125; else &#123; //若没有配置，就使用默认的 wac.setId(ConfigurableWebApplicationContext.APPLICATION_CONTEXT_ID_PREFIX + ObjectUtils.getDisplayString(sc.getContextPath())); &#125; &#125; wac.setServletContext(sc); // 把当前工程的应用上下文设置到spring上下文中 String configLocationParam = sc.getInitParameter(CONFIG_LOCATION_PARAM); if (configLocationParam != null) &#123; // 把配置文件的路径保存到上下文中 wac.setConfigLocation(configLocationParam); &#125; ConfigurableEnvironment env = wac.getEnvironment(); if (env instanceof ConfigurableWebEnvironment) &#123; ((ConfigurableWebEnvironment) env).initPropertySources(sc, null); &#125; customizeContext(sc, wac); // 定制spring上下文对象 wac.refresh(); // 会触发IOC根容器的刷新 &#125;&#125; 对于Web容器的初始化工作是在 DispatcherServlet 的超类 FrameworkServlet 中的 initServletBean() 方法中完成的，该方法是Servlet的init方法中被调用。首先将之前初始化好的Root容器设置到当前Web容器中，然后将Web容器进行初始化。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public abstract class FrameworkServlet extends HttpServletBean implements ApplicationContextAware &#123; protected final void initServletBean() throws ServletException &#123; try &#123; this.webApplicationContext = initWebApplicationContext(); initFrameworkServlet(); &#125; catch (ServletException | RuntimeException ex) &#123; throw ex; &#125; &#125; protected WebApplicationContext initWebApplicationContext() &#123; // 从ServletContext对象中获取到Spring Root上下文对象，在Spring根容器上下文创建成功后放入到ServletContext对象中 WebApplicationContext rootContext = WebApplicationContextUtils.getWebApplicationContext(getServletContext()); WebApplicationContext wac = null; if (this.webApplicationContext != null) &#123; // webApplicationContext对象是在创建DispatcherServlet对象时，存放进来的一个springmvc web的上下文对象 wac = this.webApplicationContext; if (wac instanceof ConfigurableWebApplicationContext) &#123; ConfigurableWebApplicationContext cwac = (ConfigurableWebApplicationContext) wac; if (!cwac.isActive()) &#123; // 判断是否激活 if (cwac.getParent() == null) &#123; // 设置父的上下文对象 cwac.setParent(rootContext); &#125; configureAndRefreshWebApplicationContext(cwac); // 作为SpringMvc上下文刷新 &#125; &#125; &#125; if (wac == null) &#123; wac = findWebApplicationContext(); &#125; if (wac == null) &#123; wac = createWebApplicationContext(rootContext); &#125; if (!this.refreshEventReceived) &#123; synchronized (this.onRefreshMonitor) &#123; onRefresh(wac); &#125; &#125; if (this.publishContext) &#123; String attrName = getServletContextAttributeName(); getServletContext().setAttribute(attrName, wac); &#125; return wac; &#125; protected void configureAndRefreshWebApplicationContext(ConfigurableWebApplicationContext wac) &#123; if (ObjectUtils.identityToString(wac).equals(wac.getId())) &#123; if (this.contextId != null) &#123; wac.setId(this.contextId); &#125; else &#123; wac.setId(ConfigurableWebApplicationContext.APPLICATION_CONTEXT_ID_PREFIX + ObjectUtils.getDisplayString(getServletContext().getContextPath()) + &#x27;/&#x27; + getServletName()); &#125; &#125; wac.setServletContext(getServletContext()); wac.setServletConfig(getServletConfig()); wac.setNamespace(getNamespace()); wac.addApplicationListener(new SourceFilteringListener(wac, new ContextRefreshListener())); ConfigurableEnvironment env = wac.getEnvironment(); if (env instanceof ConfigurableWebEnvironment) &#123; ((ConfigurableWebEnvironment) env).initPropertySources(getServletContext(), getServletConfig()); &#125; postProcessWebApplicationContext(wac); applyInitializers(wac); wac.refresh(); &#125;&#125; 启动Web容器与启动Root容器基本类似，唯一比较大的区别是在Web容器启动前添加了一个 ContextRefreshListener 监听器，在容器启动完成时会进行调用，初始化Spring MVC九大组件。 123456789101112131415161718192021222324252627282930private class ContextRefreshListener implements ApplicationListener&lt;ContextRefreshedEvent&gt; &#123; @Override public void onApplicationEvent(ContextRefreshedEvent event) &#123; FrameworkServlet.this.onApplicationEvent(event); &#125;&#125;public abstract class FrameworkServlet extends HttpServletBean implements ApplicationContextAware &#123; public void onApplicationEvent(ContextRefreshedEvent event) &#123; this.refreshEventReceived = true; synchronized (this.onRefreshMonitor) &#123; onRefresh(event.getApplicationContext()); &#125; &#125;&#125;public class DispatcherServlet extends FrameworkServlet &#123; protected void onRefresh(ApplicationContext context) &#123; initStrategies(context); &#125; protected void initStrategies(ApplicationContext context) &#123; initMultipartResolver(context); // 初始化用于文件上传下载的解析器对象 initLocaleResolver(context); // 初始化用于处理国际化资源的解析器对象 initThemeResolver(context); // 主题解析器对象初始化 initHandlerMappings(context); // 初始化HandlerMapping initHandlerAdapters(context); // 初始化HandlerAdapters initHandlerExceptionResolvers(context); // 初始化处理器异常解析器对象 initRequestToViewNameTranslator(context); initViewResolvers(context); // 初始化给DispatcherSerlvet的ViewResolvers处理器 initFlashMapManager(context); &#125;&#125; 在 @EnableWebMvc 注解中导入了 DelegatingWebMvcConfiguration 配置类，该类的超类 WebMvcConfigurationSupport 中导入了很多Mvc请求处理相关的Bean。这里会导入一系列处理器映射器其中比较常用和重要的是 RequestMappingHandlerMapping 和 BeanNameUrlHandlerMapping ，前者是使用注解@Controller和@RequestMapping时默认映射策略，后者是 XML方式通过在 web.xml 中配置的方式注册Bean默认映射策略。且 RequestMappingHandlerMapping 的Order为0，而 BeanNameUrlHandlerMapping 的Order为1。 123456789101112131415161718192021222324252627282930313233343536373839404142public class WebMvcConfigurationSupport implements ApplicationContextAware, ServletContextAware &#123; @Bean public RequestMappingHandlerMapping requestMappingHandlerMapping() &#123; RequestMappingHandlerMapping mapping = createRequestMappingHandlerMapping(); mapping.setOrder(0); mapping.setInterceptors(getInterceptors()); mapping.setContentNegotiationManager(mvcContentNegotiationManager()); mapping.setCorsConfigurations(getCorsConfigurations()); PathMatchConfigurer configurer = getPathMatchConfigurer(); Boolean useSuffixPatternMatch = configurer.isUseSuffixPatternMatch(); if (useSuffixPatternMatch != null) &#123; mapping.setUseSuffixPatternMatch(useSuffixPatternMatch); &#125; Boolean useRegisteredSuffixPatternMatch = configurer.isUseRegisteredSuffixPatternMatch(); if (useRegisteredSuffixPatternMatch != null) &#123; mapping.setUseRegisteredSuffixPatternMatch(useRegisteredSuffixPatternMatch); &#125; Boolean useTrailingSlashMatch = configurer.isUseTrailingSlashMatch(); if (useTrailingSlashMatch != null) &#123; mapping.setUseTrailingSlashMatch(useTrailingSlashMatch); &#125; UrlPathHelper pathHelper = configurer.getUrlPathHelper(); if (pathHelper != null) &#123; mapping.setUrlPathHelper(pathHelper); &#125; PathMatcher pathMatcher = configurer.getPathMatcher(); if (pathMatcher != null) &#123; mapping.setPathMatcher(pathMatcher); &#125; return mapping; &#125; public BeanNameUrlHandlerMapping beanNameHandlerMapping() &#123; BeanNameUrlHandlerMapping mapping = new BeanNameUrlHandlerMapping(); mapping.setOrder(2); mapping.setInterceptors(getInterceptors()); mapping.setCorsConfigurations(getCorsConfigurations()); return mapping; &#125;&#125; RequestMappingHandlerMapping 实现了 InitializingBean 接口，在初始化时会调用 afterPropertiesSet 方法来进行初始化操作，该方法会调用父类 AbstractHandlerMethodMapping 的 afterPropertiesSet 方法来把 Controller 中的 RequestMapping 注解的路径和方法进行一一映射保存。 1234567891011121314151617181920212223242526272829303132333435363738394041public class RequestMappingHandlerMapping extends RequestMappingInfoHandlerMapping implements MatchableHandlerMapping, EmbeddedValueResolverAware &#123; public void afterPropertiesSet() &#123; // 构建RequestMappingInfo.BuilderConfiguration静态类部类对象 this.config = new RequestMappingInfo.BuilderConfiguration(); // 调用当前父类AbstractHandlerMapping.getUrlPathHelper()获取UrlPathHelper对象 this.config.setUrlPathHelper(getUrlPathHelper()); // 调用父类的AbstractHandlerMapping.getPathMatcher()的ant匹配器对象 this.config.setPathMatcher(getPathMatcher()); this.config.setSuffixPatternMatch(this.useSuffixPatternMatch); // 设置前缀匹配 this.config.setTrailingSlashMatch(this.useTrailingSlashMatch); // 末尾不带/的匹配 this.config.setRegisteredSuffixPatternMatch(this.useRegisteredSuffixPatternMatch); // 设置内容协商管理器，一个请求路径返回多种数据格式 this.config.setContentNegotiationManager(getContentNegotiationManager()); // 调用父类AbstractHandlerMethodMapping#afterPropertiesSet()方法来处理器路径和控制器映射 super.afterPropertiesSet(); &#125; protected boolean isHandler(Class&lt;?&gt; beanType) &#123; return (AnnotatedElementUtils.hasAnnotation(beanType, Controller.class) || AnnotatedElementUtils.hasAnnotation(beanType, RequestMapping.class)); &#125;&#125;public abstract class AbstractHandlerMethodMapping&lt;T&gt; extends AbstractHandlerMapping implements InitializingBean &#123; public void afterPropertiesSet() &#123; initHandlerMethods(); &#125; protected void initHandlerMethods() &#123; // 去web容器中获取出所有组件的beanNames获取出来 String[] beanNames = (this.detectHandlerMethodsInAncestorContexts ? BeanFactoryUtils.beanNamesForTypeIncludingAncestors(obtainApplicationContext(), Object.class) : obtainApplicationContext().getBeanNamesForType(Object.class)); for (String beanName : beanNames) &#123; if (!beanName.startsWith(SCOPED_TARGET_NAME_PREFIX)) &#123; Class&lt;?&gt; beanType = null; try &#123; // 通过beanName去web容器中获取beanType即class对象 beanType = obtainApplicationContext().getType(beanName); &#125; // 通过Class对象判断是不是一个controller对象判断类上面有没有@Controller||@RequestMapping注解 if (beanType != null &amp;&amp; isHandler(beanType)) &#123; detectHandlerMethods(beanName); // 探测我们的处理器方法对象 &#125; &#125; &#125; handlerMethodsInitialized(getHandlerMethods()); // 空方法 &#125;&#125; 把 Controller 中标注的 @RequestMapping 的方法对象做为key，配置的路径作为value设置到Map对象中，最终将把method和path的映射关系保存到 MappingRegistry 对象中。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697public abstract class AbstractHandlerMethodMapping&lt;T&gt; extends AbstractHandlerMapping implements InitializingBean &#123; protected void detectHandlerMethods(Object handler) &#123; // 判断传入handler是不是beanName，若是则通过beanName从web容器中获取beanName对应的bean的class对象，否则直接获取handler的class对象 Class&lt;?&gt; handlerType = (handler instanceof String ? obtainApplicationContext().getType((String) handler) : handler.getClass()); if (handlerType != null) &#123; // 获取目标的class对象，防止class对象被cglib增强的 Class&lt;?&gt; userType = ClassUtils.getUserClass(handlerType); // 把Controller中标注的@RequestMapping的方法对象做为key，配置的路径作为value设置到Map对象中 // 使用lambda表达式，把getMappingForMethod(method,userType)方法注入到MethodIntrospector.MetadataLookup接口中的inspect方法中，真正调用inspect()方法时会调用getMappingForMethod方法 Map&lt;Method, T&gt; methods = MethodIntrospector.selectMethods(userType, (MethodIntrospector.MetadataLookup&lt;T&gt;) method -&gt; &#123; try &#123; return getMappingForMethod(method, userType); &#125; catch (Throwable ex) &#123; throw new IllegalStateException(&quot;Invalid mapping on handler class [&quot; + userType.getName() + &quot;]: &quot; + method, ex); &#125; &#125;); // 循环上一步解析的map,把method---path 的映射关系保存到MappingRegistry对象中 methods.forEach((method, mapping) -&gt; &#123; // 解析map中的key（method）对象，获取method对象是不是一个可执行的method对象 Method invocableMethod = AopUtils.selectInvocableMethod(method, userType); // 把映射关系保存到MappingRegistry中 registerHandlerMethod(handler, invocableMethod, mapping); &#125;); &#125; &#125; protected void registerHandlerMethod(Object handler, Method method, T mapping) &#123; this.mappingRegistry.register(mapping, handler, method); &#125; class MappingRegistry &#123; public void register(T mapping, Object handler, Method method) &#123; this.readWriteLock.writeLock().lock(); // 加写锁，写操作有且只有一个线程能操作 try &#123; // 根据controller对象和被调用的method对象来创建HandlerMethod HandlerMethod handlerMethod = createHandlerMethod(handler, method); assertUniqueMethodMapping(handlerMethod, mapping); // 判断处理器映射是否唯一 // 把url，和handlerMethod保存到mappingLookup map中mappingLookup&lt;RequestMappingInfo,HandlerMethod&gt; this.mappingLookup.put(mapping, handlerMethod); // 从RequestMappingInfo中解析出直接的url，@RequestMapping(value = &#123;&quot;/tuling&quot;,&quot;/angle&quot;&#125;) urlLookUp(tuling,RequestMappingInfo) urlLookUp(angle,RequestMappingInfo) List&lt;String&gt; directUrls = getDirectUrls(mapping); for (String url : directUrls) &#123; this.urlLookup.add(url, mapping); &#125; String name = null; // 策略模式：生成name&#123;ElevenController&#125;TC#方法名===&gt;TC#testEleven Map&lt;String, List&lt;HandlerMethod&gt;&gt; if (getNamingStrategy() != null) &#123; name = getNamingStrategy().getName(handlerMethod, mapping); addMappingName(name, handlerMethod); &#125; CorsConfiguration corsConfig = initCorsConfiguration(handler, method, mapping); if (corsConfig != null) &#123; this.corsLookup.put(handlerMethod, corsConfig); &#125; // 映射表注册MappingRegistration对象 this.registry.put(mapping, new MappingRegistration&lt;&gt;(mapping, handlerMethod, directUrls, name)); &#125; finally &#123; this.readWriteLock.writeLock().unlock(); // 释放锁对象 &#125; &#125; &#125;&#125;public class RequestMappingHandlerMapping extends RequestMappingInfoHandlerMapping implements MatchableHandlerMapping, EmbeddedValueResolverAware &#123; protected RequestMappingInfo getMappingForMethod(Method method, Class&lt;?&gt; handlerType) &#123; //解析method方法上的@ReuqestMapping注解，解析出对应的RequestMappingInfo对象 RequestMappingInfo info = createRequestMappingInfo(method); //方法级别上的RequestMapping注解不为空 if (info != null) &#123; // 创建类级别的RequestMappingInfo对象 RequestMappingInfo typeInfo = createRequestMappingInfo(handlerType); if (typeInfo != null) &#123; // 若Controller类上也标注了@RequestMapping info = typeInfo.combine(info); // 把类级别的RequestMappingInfo和方法级别的RequestMappingInfo连接起来 &#125; &#125; return info; &#125; private RequestMappingInfo createRequestMappingInfo(AnnotatedElement element) &#123; // 从element对象上找出request注解 RequestMapping requestMapping = AnnotatedElementUtils.findMergedAnnotation(element, RequestMapping.class); // 获取@RequestMapping注解上的各个条件 RequestCondition&lt;?&gt; condition = (element instanceof Class ? getCustomTypeCondition((Class&lt;?&gt;) element) : getCustomMethodCondition((Method) element)); // 判断requestMapping注解是否为空，不为空则真正的创建createRequestMappingInfo(requestMapping,condition) return (requestMapping != null ? createRequestMappingInfo(requestMapping, condition) : null); &#125; protected RequestMappingInfo createRequestMappingInfo(RequestMapping requestMapping, @Nullable RequestCondition&lt;?&gt; customCondition) &#123; RequestMappingInfo.Builder builder = RequestMappingInfo .paths(resolveEmbeddedValuesInPatterns(requestMapping.path())) //构建路径 .methods(requestMapping.method()) //构建方法(get还是post等) .params(requestMapping.params())//参数 对应http request parameter .headers(requestMapping.headers())//头部 .consumes(requestMapping.consumes())//request的提交内容类型content type,如application/json, text/html .produces(requestMapping.produces())//指定返回的内容类型的content type，仅当request请求头中的(Accept)类型中包含该指定类型才返回 .mappingName(requestMapping.name()); if (customCondition != null) &#123; builder.customCondition(customCondition); &#125; return builder.options(this.config).build(); // 真正的构建RequestMappingInfo对象 &#125;&#125; BeanNameUrlHandlerMapping 是 ApplicationContextAware 的子类，对于映射关系的解析是在其加载完毕后通过调用Aware接口的 setApplicationContext 方法触发调用 initApplicationContext() 方法从而进行映射关系的解析。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class BeanNameUrlHandlerMapping extends AbstractDetectingUrlHandlerMapping &#123; protected String[] determineUrlsForHandler(String beanName) &#123; List&lt;String&gt; urls = new ArrayList&lt;&gt;(); if (beanName.startsWith(&quot;/&quot;)) &#123; urls.add(beanName); &#125; String[] aliases = obtainApplicationContext().getAliases(beanName); for (String alias : aliases) &#123; if (alias.startsWith(&quot;/&quot;)) &#123; urls.add(alias); &#125; &#125; return StringUtils.toStringArray(urls); &#125;&#125;public abstract class AbstractDetectingUrlHandlerMapping extends AbstractUrlHandlerMapping &#123; public void initApplicationContext() throws ApplicationContextException &#123; super.initApplicationContext(); detectHandlers(); &#125; protected void detectHandlers() throws BeansException &#123; ApplicationContext applicationContext = obtainApplicationContext(); String[] beanNames = (this.detectHandlersInAncestorContexts ? BeanFactoryUtils.beanNamesForTypeIncludingAncestors(applicationContext, Object.class) : applicationContext.getBeanNamesForType(Object.class)); for (String beanName : beanNames) &#123; String[] urls = determineUrlsForHandler(beanName); if (!ObjectUtils.isEmpty(urls)) &#123; registerHandler(urls, beanName); &#125; &#125; &#125; protected void registerHandler(String[] urlPaths, String beanName) throws BeansException, IllegalStateException &#123; for (String urlPath : urlPaths) &#123; registerHandler(urlPath, beanName); &#125; &#125; protected void registerHandler(String urlPath, Object handler) throws BeansException, IllegalStateException &#123; Object resolvedHandler = handler; if (!this.lazyInitHandlers &amp;&amp; handler instanceof String) &#123; String handlerName = (String) handler; ApplicationContext applicationContext = obtainApplicationContext(); if (applicationContext.isSingleton(handlerName)) &#123; resolvedHandler = applicationContext.getBean(handlerName); &#125; &#125; Object mappedHandler = this.handlerMap.get(urlPath); if (mappedHandler != null) &#123; if (mappedHandler != resolvedHandler) &#123; throw new IllegalStateException(&quot;Cannot map &quot; + getHandlerDescription(handler) + &quot; to URL path [&quot; + urlPath + &quot;]: There is already &quot; + getHandlerDescription(mappedHandler) + &quot; mapped.&quot;); &#125; &#125; else &#123; if (urlPath.equals(&quot;/&quot;)) &#123; setRootHandler(resolvedHandler); &#125; else if (urlPath.equals(&quot;/*&quot;)) &#123; setDefaultHandler(resolvedHandler); &#125; else &#123; this.handlerMap.put(urlPath, resolvedHandler); &#125; &#125; &#125;&#125; 在 WebMvcConfigurationSupport 中也会导入一系列处理器适配器 RequestMappingHandlerAdapter 、 HttpRequestHandlerAdapter 、 SimpleControllerHandlerAdapter 123456789101112131415161718192021222324252627282930313233343536public class WebMvcConfigurationSupport implements ApplicationContextAware, ServletContextAware &#123; @Bean public RequestMappingHandlerAdapter requestMappingHandlerAdapter() &#123; RequestMappingHandlerAdapter adapter = createRequestMappingHandlerAdapter(); adapter.setContentNegotiationManager(mvcContentNegotiationManager()); adapter.setMessageConverters(getMessageConverters()); adapter.setWebBindingInitializer(getConfigurableWebBindingInitializer()); adapter.setCustomArgumentResolvers(getArgumentResolvers()); adapter.setCustomReturnValueHandlers(getReturnValueHandlers()); if (jackson2Present) &#123; adapter.setRequestBodyAdvice(Collections.singletonList(new JsonViewRequestBodyAdvice())); adapter.setResponseBodyAdvice(Collections.singletonList(new JsonViewResponseBodyAdvice())); &#125; AsyncSupportConfigurer configurer = new AsyncSupportConfigurer(); configureAsyncSupport(configurer); if (configurer.getTaskExecutor() != null) &#123; adapter.setTaskExecutor(configurer.getTaskExecutor()); &#125; if (configurer.getTimeout() != null) &#123; adapter.setAsyncRequestTimeout(configurer.getTimeout()); &#125; adapter.setCallableInterceptors(configurer.getCallableInterceptors()); adapter.setDeferredResultInterceptors(configurer.getDeferredResultInterceptors()); return adapter; &#125; @Bean public HttpRequestHandlerAdapter httpRequestHandlerAdapter() &#123; return new HttpRequestHandlerAdapter(); &#125; @Bean public SimpleControllerHandlerAdapter simpleControllerHandlerAdapter() &#123; return new SimpleControllerHandlerAdapter(); &#125;&#125; RequestMappingHandlerAdapter 实现了 InitializingBean 接口，在初始化时会调用 afterPropertiesSet 方法来进行初始化操作，主要是解析标注了 @ControllerAdvice 、 @InitBinder 、 @ModelAttribute 等注解的类和方法，并将解析后的数据放入缓存中。以及添加一系列的参数解析器、标注@InitBinder注解方法的参数解析器、返回值解析器。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public class RequestMappingHandlerAdapter extends AbstractHandlerMethodAdapter implements BeanFactoryAware, InitializingBean &#123; public static final MethodFilter INIT_BINDER_METHODS = method -&gt; (AnnotationUtils.findAnnotation(method, InitBinder.class) != null); public static final MethodFilter MODEL_ATTRIBUTE_METHODS = method -&gt; (AnnotationUtils.findAnnotation(method, RequestMapping.class) == null &amp;&amp; AnnotationUtils.findAnnotation(method, ModelAttribute.class) != null); public void afterPropertiesSet() &#123; initControllerAdviceCache(); // 实例化标注了@ControllerAdvice等组件 if (this.argumentResolvers == null) &#123; // 加入容器中各种参数解析器对象 List&lt;HandlerMethodArgumentResolver&gt; resolvers = getDefaultArgumentResolvers(); this.argumentResolvers = new HandlerMethodArgumentResolverComposite().addResolvers(resolvers); &#125; if (this.initBinderArgumentResolvers == null) &#123; // 解析@InitBinder注解标注的方法的参数解析器对象 List&lt;HandlerMethodArgumentResolver&gt; resolvers = getDefaultInitBinderArgumentResolvers(); this.initBinderArgumentResolvers = new HandlerMethodArgumentResolverComposite().addResolvers(resolvers); &#125; if (this.returnValueHandlers == null) &#123; // 返回值解析器对象 List&lt;HandlerMethodReturnValueHandler&gt; handlers = getDefaultReturnValueHandlers(); this.returnValueHandlers = new HandlerMethodReturnValueHandlerComposite().addHandlers(handlers); &#125; &#125; private void initControllerAdviceCache() &#123; if (getApplicationContext() == null) &#123; return; &#125; // 传入web上下文对象，查找容器中标注了@ControllerAdvice组件的bean List&lt;ControllerAdviceBean&gt; adviceBeans = ControllerAdviceBean.findAnnotatedBeans(getApplicationContext()); AnnotationAwareOrderComparator.sort(adviceBeans); // 排序 List&lt;Object&gt; requestResponseBodyAdviceBeans = new ArrayList&lt;&gt;(); for (ControllerAdviceBean adviceBean : adviceBeans) &#123; // 循环所有的@ControllerAdvice的集合 Class&lt;?&gt; beanType = adviceBean.getBeanType(); // 获取bean的class类型 if (beanType == null) &#123; throw new IllegalStateException(&quot;Unresolvable type for ControllerAdviceBean: &quot; + adviceBean); &#125; // 获取class类中所有标注了@ModelAttribute注解 Set&lt;Method&gt; attrMethods = MethodIntrospector.selectMethods(beanType, MODEL_ATTRIBUTE_METHODS); if (!attrMethods.isEmpty()) &#123; // 标注了@ModelAttribute标注的方法不为空 this.modelAttributeAdviceCache.put(adviceBean, attrMethods); // 加入到缓存中 &#125; // 查找全局的@InitBinder注解标标注的方法 Set&lt;Method&gt; binderMethods = MethodIntrospector.selectMethods(beanType, INIT_BINDER_METHODS); if (!binderMethods.isEmpty()) &#123; // 不为空加入到缓存中 this.initBinderAdviceCache.put(adviceBean, binderMethods); &#125; boolean isRequestBodyAdvice = RequestBodyAdvice.class.isAssignableFrom(beanType); boolean isResponseBodyAdvice = ResponseBodyAdvice.class.isAssignableFrom(beanType); if (isRequestBodyAdvice || isResponseBodyAdvice) &#123; requestResponseBodyAdviceBeans.add(adviceBean); &#125; &#125; if (!requestResponseBodyAdviceBeans.isEmpty()) &#123; this.requestResponseBodyAdvice.addAll(0, requestResponseBodyAdviceBeans); &#125; &#125;&#125;public class ControllerAdviceBean implements Ordered &#123; public static List&lt;ControllerAdviceBean&gt; findAnnotatedBeans(ApplicationContext applicationContext) &#123; List&lt;ControllerAdviceBean&gt; beans = new ArrayList&lt;&gt;(); for (String name : BeanFactoryUtils.beanNamesForTypeIncludingAncestors(applicationContext, Object.class)) &#123; if (applicationContext.findAnnotationOnBean(name, ControllerAdvice.class) != null) &#123; // 若组件上标注了@ControllerAdvice，则加入到集合中返回 beans.add(new ControllerAdviceBean(name, applicationContext)); &#125; &#125; return beans; &#125;&#125;","tags":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}]},{"title":"Spring Gzip压缩","date":"2020-10-19T03:08:20.000Z","path":"blog/Spring/Spring Gzip压缩/","text":"输出Gzip压缩在SpringBoot项目中启用输出Gzip压缩，需要添加如下配置。 123456789101112server: compression: enabled: true min-response-size: 2048 mime-types: - application/json - application/x-www-form-urlencoded - application/xml - text/html - text/xml - text/plain - application/javascript 是否压缩取决于数据大小是否达到 min-response-size 配置的值且请求方在request header中是否添加 Accept-Encoding:gzip,deflate , 一般浏览器会在请求头中默认添加该header。 若提供接口给外部服务，若有使用Nginx，可以通过Nginx反向代理转发到我们的WEB服务器时在请求头中添加Accept-Encoding:gzip,deflate。 验证GZIP是否生效 通过HttpClient的方法验证12345678910111213141516HttpClient httpClient = new DefaultHttpClient();HttpGet get = new HttpGet(uri);ResponseHandler&lt;String&gt; responseHandler = new BasicResponseHandler();try &#123; get.setHeader(&quot;Accept-Encoding&quot;, &quot;gzip,deflate&quot;); String content = httpClient.execute(get, responseHandler); System.out.println(content); // 如果gzip生效，会打印出乱码 HttpResponse response = httpClient.execute(get); long cLen = response.getEntity().getContentLength(); System.out.println(cLen); // 如果gzip生效，长度值为-1或比原始大小小很多的值&#125; catch(Exception e) &#123; // ignore ...&#125; finally &#123; httpClient.getConnectionManager().shutdown();&#125; 通过浏览器调试工具对比Network中请求的Size 输入Gzip压缩对于请求体比较大的接口，通常会采用压缩的方式进行传输。这里对Gzip踩坑进行一下总结。 对于即支持 Gzip 压缩调用，也支持非压缩调用的接口，通常做法是在请求头中放入一个字段来判断该字段的值来确定所走流程。通常做法可能很多人会采用标准的请求头参数 Content-Encoding ，在直接调用不仅过 zuul 的服务中是没有问题的。但是在有zuul的服务中， zuul 默认会将请求头中的 Content-Encoding 移除，从而导致获取不到 Content-Encoding 该字段，从而走非Gzip的流程导致bug，在该种情况下最好使用自定义的请求头代替标准的请求头。StackOverFlow参考 12345678910public static String compress(String param) throws IOException &#123; if (null == param || param.length() &lt;= 0) &#123; return param; &#125; ByteArrayOutputStream out = new ByteArrayOutputStream(); GZIPOutputStream gzip = new GZIPOutputStream(out); gzip.write(param.getBytes(&quot;utf-8&quot;)); gzip.close(); return out.toString(&quot;ISO-8859-1&quot;);&#125; 在服务端将通过 @RequestBody 获取到的请求体通过如下方式解压出来使用。 1234567891011121314public static String unCompress(String paramGzip) throws IOException &#123; if (null == paramGzip || paramGzip.length() &lt;= 0) &#123; return paramGzip; &#125; ByteArrayOutputStream out = new ByteArrayOutputStream(); ByteArrayInputStream in = new ByteArrayInputStream(paramGzip.getBytes(&quot;ISO-8859-1&quot;)); GZIPInputStream gzip = new GZIPInputStream(in); byte[] buffer = new byte[256]; int n = 0; while ((n = gzip.read(buffer)) &gt;= 0)&#123; out.write(buffer, 0, n); &#125; return out.toString(&quot;utf-8&quot;);&#125; 以上方式的问题在于不通用，如果说使用Python或者其他语言来，或者说如JMeter和LoadRunner之类的工具请求，基本上百分之百会乱码导致请求失败。 优化方案，直接从 HttpServletRequest 中获取 InputStream 从而获取到字节数组。并将字节数组解压缩，最后将解压缩后的字节数组转成字符串进行处理。 123456789101112131415public static byte[] unCompressBytes(byte[] bytes) throws IOException &#123; if (null == bytes || bytes.length &lt;= 0) &#123; return bytes; &#125; ByteArrayOutputStream out = new ByteArrayOutputStream(); ByteArrayInputStream in = new ByteArrayInputStream(bytes); GZIPInputStream gzip = new GZIPInputStream(in); byte[] buffer = new byte[256]; int n = 0; while ((n = gzip.read(buffer)) &gt;= 0) &#123; out.write(buffer, 0, n); &#125; gzip.close(); return out.toByteArray();&#125; 对于Java客户端的请求，可以直接使用 GzipCompressingEntity 标准的请求方式来调用： 12345678HttpPost httpPost = new HttpPost(url);httpPost.setHeader(&quot;Content-Type&quot;, &quot;application/json;charset=UTF-8&quot;);httpPost.setHeader(&quot;AA-Content-Encoding&quot;, &quot;gzip&quot;);StringEntity entity = new StringEntity(param, &quot;UTF-8&quot;);httpPost.setEntity(new GzipCompressingEntity(entity));HttpResponse httpResponse = httpClient.execute(httpPost); 当然也可以自己来压缩调用，通过 compressByte 方法将数据压缩成字节流，再将字节流直接放入到 HttpPost 的请求体中，中间不要做任何转码： 1234567891011121314151617181920public static byte[] compressByte(String param) throws IOException &#123; if (null == param || param.length() &lt;= 0) &#123; return new byte[0]; &#125; ByteArrayOutputStream out = new ByteArrayOutputStream(); GZIPOutputStream gzip = new GZIPOutputStream(out); gzip.write(param.getBytes(StandardCharsets.UTF_8)); gzip.close(); return out.toByteArray();&#125;HttpPost httpPost = new HttpPost(url);httpPost.setHeader(&quot;Content-Type&quot;, &quot;application/json;charset=UTF-8&quot;);httpPost.setHeader(&quot;AA-Content-Encoding&quot;, &quot;gzip&quot;);ByteArrayEntity entity = new ByteArrayEntity(bytes);httpPost.setEntity(new GzipCompressingEntity(entity));HttpResponse httpResponse = httpClient.execute(httpPost); 对于Python的调用也很简单： 12345678headers = &#123; &quot;Content-Type&quot;: &quot;application/json;charset=utf-8&quot;, &quot;AA-Content-Encoding&quot;: &quot;gzip&quot;&#125;dataGzip = gzip.compress(json.dumps(data).encode(&quot;utf-8&quot;))response = requests.post(url=url, headers=headers, data=dataGzip, params=params)","tags":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}]},{"title":"IoC容器加载过程","date":"2020-10-18T09:08:20.000Z","path":"blog/Spring/IoC容器加载过程/","text":"现在用的比较多的注解的方式，这里仅对于注解的容器即 AnnotationConfigApplicationContext 的加过程的总结。使用时启动一个容器仅一行或几行代码，看着相当简单，但内部做了非常复杂的处理。这里的MainConfig是一个配置类，带上 @Configuration 注解的配置类是传统意义上的配置类Spring内部称为 Full配置类；还有一种是没有带上@Configuration ，但是带有@Component，@Import，@ImportResouce，@Service，@ComponentScan等注解的配置类Spring内部称之为 Lite配置类。在解析这些配置类时，会给其加上Full或Lite属性。 1AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(MainConfig.class); 1234// 或者通过下面的方式启动容器AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext();context.register(MainStarter.class);context.refresh(); 实例化 AnnotationConfigApplicationContext 容器的时，首先会隐式调用父类 GenericApplicationContext 的无参构造函数去实例化Bean工厂 DefaultListableBeanFactory 。然后调用无参构造方法对读取器 AnnotatedBeanDefinitionReader 和扫描器 ClassPathBeanDefinitionScanner 进行了实例化，然后通过 register 注册自己的配置类为 BeanDefinition ，最后调用 refresh ()方法。 12345678910111213141516171819202122232425262728293031323334353637public class AnnotationConfigApplicationContext extends GenericApplicationContext implements AnnotationConfigRegistry &#123; // 注解的bean定义读取器 private final AnnotatedBeanDefinitionReader reader; // 类路径下的bean定义扫描器 private final ClassPathBeanDefinitionScanner scanner; public AnnotationConfigApplicationContext() &#123; // 创建一个读取注解的BeanDefinition读取器，完成spring内部BeanDefinition的注册（主要是后置处理器） this.reader = new AnnotatedBeanDefinitionReader(this); /** * 创建BeanDefinition扫描器，可以用来扫描包或者类，继而转换为BeanDefinition * spring默认的扫描包不是该scanner对象，而是在执行工程后置处理器ConfigurationClassPostProcessor时，去扫描包时会new一个ClassPathBeanDefinitionScanner * 这里的scanner仅仅是为了程序员可以手动调用AnnotationConfigApplicationContext对象的scan方法 */ this.scanner = new ClassPathBeanDefinitionScanner(this); &#125; public AnnotationConfigApplicationContext(DefaultListableBeanFactory beanFactory) &#123; super(beanFactory); this.reader = new AnnotatedBeanDefinitionReader(this); this.scanner = new ClassPathBeanDefinitionScanner(this); &#125; public AnnotationConfigApplicationContext(Class&lt;?&gt;... annotatedClasses) &#123; this(); // 调用构造函数 register(annotatedClasses); //注册我们的配置类 refresh(); // IOC容器刷新接口 &#125; public AnnotationConfigApplicationContext(String... basePackages) &#123; this(); scan(basePackages); refresh(); &#125;&#125;public class GenericApplicationContext extends AbstractApplicationContext implements BeanDefinitionRegistry &#123; private final DefaultListableBeanFactory beanFactory; public GenericApplicationContext() &#123; this.beanFactory = new DefaultListableBeanFactory(); &#125;&#125; 实例化DefaultListableBeanFactory工厂 DefaultListableBeanFactory 是最底层的实现，其中定义很多重要的属性，在后续的容器加载过程会频繁用到： 123456789101112131415161718192021222324252627282930313233public class DefaultListableBeanFactory extends AbstractAutowireCapableBeanFactory implements ConfigurableListableBeanFactory, BeanDefinitionRegistry, Serializable &#123; /** Map from serialized id to factory instance */ private static final Map&lt;String, Reference&lt;DefaultListableBeanFactory&gt;&gt; serializableFactories = new ConcurrentHashMap&lt;&gt;(8); /** Optional id for this factory, for serialization purposes */ @Nullable private String serializationId; /** Whether to allow re-registration of a different definition with the same name */ private boolean allowBeanDefinitionOverriding = true; /** Whether to allow eager class loading even for lazy-init beans */ private boolean allowEagerClassLoading = true; /** Optional OrderComparator for dependency Lists and arrays */ @Nullable private Comparator&lt;Object&gt; dependencyComparator; /** Resolver to use for checking if a bean definition is an autowire candidate */ private AutowireCandidateResolver autowireCandidateResolver = new SimpleAutowireCandidateResolver(); /** Map from dependency type to corresponding autowired value */ private final Map&lt;Class&lt;?&gt;, Object&gt; resolvableDependencies = new ConcurrentHashMap&lt;&gt;(16); /** 用于保存原始的bean定义信息(没有被mearged) */ private final Map&lt;String, BeanDefinition&gt; beanDefinitionMap = new ConcurrentHashMap&lt;&gt;(256); /** Map of singleton and non-singleton bean names, keyed by dependency type */ private final Map&lt;Class&lt;?&gt;, String[]&gt; allBeanNamesByType = new ConcurrentHashMap&lt;&gt;(64); /** Map of singleton-only bean names, keyed by dependency type */ private final Map&lt;Class&lt;?&gt;, String[]&gt; singletonBeanNamesByType = new ConcurrentHashMap&lt;&gt;(64); /** List of bean definition names, in registration order */ private volatile List&lt;String&gt; beanDefinitionNames = new ArrayList&lt;&gt;(256); /** List of names of manually registered singletons, in registration order */ private volatile Set&lt;String&gt; manualSingletonNames = new LinkedHashSet&lt;&gt;(16); /** Cached array of bean definition names in case of frozen configuration */ @Nullable private volatile String[] frozenBeanDefinitionNames; /** Whether bean definition metadata may be cached for all beans */ private volatile boolean configurationFrozen = false;&#125; 实例化BeanDefinition读取器 AnnotatedBeanDefinitionReader 主要是注册内置的BeanPostProcessor 以及注册相关的BeanDefinition ，主要是注册系统内部的一些基础的配置类如：解析配置类的后置处理器ConfigurationClassPostProcessor 、处理@Autowired注解的处理器AutowiredAnnotationBeanPostProcessor 、处理 @Required 属性的注解处理器 RequiredAnnotationBeanPostProcessor 、处理JSR规范的注解处理器CommonAnnotationBeanPostProcessor、处理jpa注解的处理器PersistenceAnnotationBeanPostProcessor、处理监听方法的注解 @EventListener 解析器 EventListenerMethodProcessor 、注册事件监听器工厂 DefaultEventListenerFactory 。 ConfigurationClassPostProcessor 是最重要的Bean其实现了 BeanDefinitionRegistryPostProcessor和BeanFactoryPostProcessor接口，其作用分别为注册BeanDefinition 和修改BeanDefinition ， BeanFactoryPostProcessor是Spring扩展点之一。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889public class AnnotatedBeanDefinitionReader &#123; private final BeanDefinitionRegistry registry; private BeanNameGenerator beanNameGenerator = new AnnotationBeanNameGenerator(); private ScopeMetadataResolver scopeMetadataResolver = new AnnotationScopeMetadataResolver(); private ConditionEvaluator conditionEvaluator; public AnnotatedBeanDefinitionReader(BeanDefinitionRegistry registry) &#123; this(registry, getOrCreateEnvironment(registry)); &#125; public AnnotatedBeanDefinitionReader(BeanDefinitionRegistry registry, Environment environment) &#123; Assert.notNull(registry, &quot;BeanDefinitionRegistry must not be null&quot;); Assert.notNull(environment, &quot;Environment must not be null&quot;); // 把ApplicationContext对象赋值给AnnotatedBeanDefinitionReader this.registry = registry; // 用户处理条件注解 @Conditional os.name this.conditionEvaluator = new ConditionEvaluator(registry, environment, null); // 注册一些内置的后置处理器 AnnotationConfigUtils.registerAnnotationConfigProcessors(this.registry); &#125;&#125;public class AnnotationConfigUtils &#123; public static void registerAnnotationConfigProcessors(BeanDefinitionRegistry registry) &#123; registerAnnotationConfigProcessors(registry, null); &#125; public static Set&lt;BeanDefinitionHolder&gt; registerAnnotationConfigProcessors( BeanDefinitionRegistry registry, @Nullable Object source) &#123; DefaultListableBeanFactory beanFactory = unwrapDefaultListableBeanFactory(registry); if (beanFactory != null) &#123; if (!(beanFactory.getDependencyComparator() instanceof AnnotationAwareOrderComparator)) &#123; //注册了实现Order接口的排序器 beanFactory.setDependencyComparator(AnnotationAwareOrderComparator.INSTANCE); &#125; //设置@AutoWired的候选的解析器：ContextAnnotationAutowireCandidateResolver // getLazyResolutionProxyIfNecessary方法，它也是唯一实现。 //如果字段上带有@Lazy注解，表示进行懒加载 Spring不会立即创建注入属性的实例，而是生成代理对象，来代替实例 if (!(beanFactory.getAutowireCandidateResolver() instanceof ContextAnnotationAutowireCandidateResolver)) &#123; beanFactory.setAutowireCandidateResolver(new ContextAnnotationAutowireCandidateResolver()); &#125; &#125; Set&lt;BeanDefinitionHolder&gt; beanDefs = new LinkedHashSet&lt;&gt;(8); // 为我们容器中注册了解析配置类的后置处理器ConfigurationClassPostProcessor:org.springframework.context.annotation.internalConfigurationAnnotationProcessor if (!registry.containsBeanDefinition(CONFIGURATION_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(ConfigurationClassPostProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, CONFIGURATION_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; // 为容器中注册了处理@Autowired 注解的处理器AutowiredAnnotationBeanPostProcessor:org.springframework.context.annotation.internalAutowiredAnnotationProcessor if (!registry.containsBeanDefinition(AUTOWIRED_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(AutowiredAnnotationBeanPostProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, AUTOWIRED_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; // 为容器中注册处理@Required属性的注解处理器RequiredAnnotationBeanPostProcessor:org.springframework.context.annotation.internalRequiredAnnotationProcessor if (!registry.containsBeanDefinition(REQUIRED_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(RequiredAnnotationBeanPostProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, REQUIRED_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; // 为我们容器注册处理JSR规范的注解处理器CommonAnnotationBeanPostProcessor：org.springframework.context.annotation.internalCommonAnnotationProcessor if (jsr250Present &amp;&amp; !registry.containsBeanDefinition(COMMON_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(CommonAnnotationBeanPostProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, COMMON_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; // 处理jpa注解的处理器org.springframework.orm.jpa.support.PersistenceAnnotationBeanPostProcessor if (jpaPresent &amp;&amp; !registry.containsBeanDefinition(PERSISTENCE_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(); try &#123; def.setBeanClass(ClassUtils.forName(PERSISTENCE_ANNOTATION_PROCESSOR_CLASS_NAME, AnnotationConfigUtils.class.getClassLoader())); &#125; catch (ClassNotFoundException ex) &#123; throw new IllegalStateException(&quot;Cannot load optional framework class: &quot; + PERSISTENCE_ANNOTATION_PROCESSOR_CLASS_NAME, ex); &#125; def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, PERSISTENCE_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; // 处理监听方法的注解@EventListener解析器EventListenerMethodProcessor if (!registry.containsBeanDefinition(EVENT_LISTENER_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(EventListenerMethodProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, EVENT_LISTENER_PROCESSOR_BEAN_NAME)); &#125; // 注册事件监听器工厂 if (!registry.containsBeanDefinition(EVENT_LISTENER_FACTORY_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(DefaultEventListenerFactory.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, EVENT_LISTENER_FACTORY_BEAN_NAME)); &#125; return beanDefs; &#125;&#125; 最终是通过 registerPostProcessor 注册这些BeanDefinition，最终是调用的DefaultListableBeanFactory的registerBeanDefinition将这些BeanDefinition放入保存原始的BeanDefinition信息的beanDefinitionMap及beanDefinitionNames中。这里仅仅是注册，并没有对这些Bean实例化。 创建BeanDefinition扫描器常规使用方式是不会用到 AnnotationConfigApplicationContext 中的scanner的，这里的scanner仅仅是为了手动调用 AnnotationConfigApplicationContext 对象的scan方法。 register注册自定义配置类 register 传入的是一个数组，最终会循环调用 doRegisterBean 注册传入的配置到 DefaultListableBeanFactory 中的 beanDefinitionMap 和 beanDefinitionNames 中。注意这里是使用 AnnotatedGenericBeanDefinition 来获得配置类的BeanDefinition而前面注册系统内部的一些基础的配置类时是通过 RootBeanDefinition 来获得配置类BeanDefinition的。 12345678910111213141516171819202122232425262728293031323334353637&lt;T&gt; void doRegisterBean(Class&lt;T&gt; annotatedClass, @Nullable Supplier&lt;T&gt; instanceSupplier, @Nullable String name, @Nullable Class&lt;? extends Annotation&gt;[] qualifiers, BeanDefinitionCustomizer... definitionCustomizers) &#123; //存储@Configuration注解注释的类 AnnotatedGenericBeanDefinition abd = new AnnotatedGenericBeanDefinition(annotatedClass); //判断是否需要跳过注解，spring中有一个@Condition注解，当不满足条件，这个bean就不会被解析 if (this.conditionEvaluator.shouldSkip(abd.getMetadata())) &#123; return; &#125; abd.setInstanceSupplier(instanceSupplier); //解析bean的作用域和scopedProxyMode，如果没有设置的话，默认为单例，默认scopedProxyMode=ScopedProxyMode.NO ScopeMetadata scopeMetadata = this.scopeMetadataResolver.resolveScopeMetadata(abd); abd.setScope(scopeMetadata.getScopeName()); //获得beanName String beanName = (name != null ? name : this.beanNameGenerator.generateBeanName(abd, this.registry)); //解析通用注解，填充到AnnotatedGenericBeanDefinition，解析的注解为Lazy，Primary，DependsOn，Role，Description AnnotationConfigUtils.processCommonDefinitionAnnotations(abd); if (qualifiers != null) &#123; for (Class&lt;? extends Annotation&gt; qualifier : qualifiers) &#123; if (Primary.class == qualifier) &#123; abd.setPrimary(true); &#125; else if (Lazy.class == qualifier) &#123; abd.setLazyInit(true); &#125; else &#123; abd.addQualifier(new AutowireCandidateQualifier(qualifier)); &#125; &#125; &#125; for (BeanDefinitionCustomizer customizer : definitionCustomizers) &#123; customizer.customize(abd); &#125; BeanDefinitionHolder definitionHolder = new BeanDefinitionHolder(abd, beanName); definitionHolder = AnnotationConfigUtils.applyScopedProxyMode(scopeMetadata, definitionHolder, this.registry); //注册，最终会调用DefaultListableBeanFactory中的registerBeanDefinition方法去注册， DefaultListableBeanFactory维护着一系列信息，比如beanDefinitionNames，beanDefinitionMap //beanDefinitionNames是一个List&lt;String&gt;,用来保存beanName，beanDefinitionMap是一个Map,用来保存beanName和beanDefinition BeanDefinitionReaderUtils.registerBeanDefinition(definitionHolder, this.registry);&#125; refresh刷新容器到这里Spring还没有进行扫描，只是实例化了一个工厂，注册了一些内置的Bean和我们传进去的配置类。refresh是一个模板方法。 123456789101112131415161718192021222324252627282930public abstract class AbstractApplicationContext extends DefaultResourceLoader implements ConfigurableApplicationContext &#123; public void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; prepareRefresh(); // 刷新预处理，和主流程关系不大，就是保存了容器的启动时间，启动标志等 ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // 获取告诉子类初始化Bean工厂，不同工厂不同实现 prepareBeanFactory(beanFactory); // 对bean工厂进行填充属性，添加了两个后置处理器：ApplicationContextAwareProcessor，ApplicationListenerDetector，还设置了忽略自动装配和允许自动装配的接口，若不存在某个bean的时候，spring就自动注册singleton bean，还设置了bean表达式解析器等 try &#123; postProcessBeanFactory(beanFactory); // 留个子类去实现该接口 invokeBeanFactoryPostProcessors(beanFactory); // 调用我们的bean工厂的后置处理器，会在此将class扫描成beanDefinition，bean工厂的后置处理器调用 registerBeanPostProcessors(beanFactory); // 注册bean的后置处理器 initMessageSource(); // 初始化国际化资源处理器 initApplicationEventMulticaster();// 创建事件多播器 onRefresh();// 该方法同样也是留给子类实现的，springboot也是从该方法进行启动tomcat的 registerListeners(); // 把事件监听器注册到多播器上 finishBeanFactoryInitialization(beanFactory); // 实例化我们剩余的单实例bean finishRefresh(); // 最后容器刷新 发布刷新事件(Spring cloud也是从这里启动的) &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(&quot;Exception encountered during context initialization - &quot; + &quot;cancelling refresh attempt: &quot; + ex); &#125; // Destroy already created singletons to avoid dangling resources. destroyBeans(); cancelRefresh(ex); throw ex; &#125; finally &#123; resetCommonCaches(); &#125; &#125; &#125;&#125; prepareRefresh主要做了一些刷新前的准备工作，和主流程关系不大，主要是保存了容器的启动时间，启动标志等； 123456789101112131415161718192021222324protected void prepareRefresh() &#123; this.startupDate = System.currentTimeMillis(); this.closed.set(false); this.active.set(true); /** * 相传该方法在网上很多人说该方法没有用,因为这个方法是留个子类实现的,由于是对spring源码的核心 设计理念没有弄清楚,正式由于spring提供了大量的可扩展的接口提供给我们自己来实现 * 比如我们自己写一个类重写了initPropertySources方法，在该方法中设置了一个环境变量的值为A 启动的时候，我的环境变量中没有该值就会启动抛出异常 */ initPropertySources(); // 用来校验我们容器启动必须依赖的环境变量的值 getEnvironment().validateRequiredProperties(); // 创建一个早期事件监听器对象 if (this.earlyApplicationListeners == null) &#123; this.earlyApplicationListeners = new LinkedHashSet&lt;&gt;(this.applicationListeners); &#125; else &#123; this.applicationListeners.clear(); this.applicationListeners.addAll(this.earlyApplicationListeners); &#125; /** * 创建一个容器用于保存早期待发布的事件集合，就是我们的事件监听器还没有注册到多播器上的时候都称为早期事件 * 早期事件不需要手动publishEvent发布， 在registerListeners中会自动发布， 发布完早期事件就不存在了。 */ this.earlyApplicationEvents = new LinkedHashSet&lt;&gt;();&#125; obtainFreshBeanFactory和主流程关系也不是很大，可简单认为就是把beanFactory取出来而已，XML模式下会在这里读取BeanDefinition； 1234567protected ConfigurableListableBeanFactory obtainFreshBeanFactory() &#123; // xml加载spring会在这里加载beanDefinition，javaconfig只是刷新了beanFactory refreshBeanFactory(); //返回我们的bean工厂 ConfigurableListableBeanFactory beanFactory = getBeanFactory(); return beanFactory;&#125; prepareBeanFactory做一些准备工作主要是为Bean工厂填充内部属性，添加了 ApplicationContextAwareProcessor 和 ApplicationListenerDetector 后置处理器，还设置了忽略自动装配和允许自动装配的接口，若不存在某个Bean时，Spring则自动注册Singleton Bean，还设置了bean表达式解析器等； 1234567891011121314151617181920212223242526272829303132333435363738394041protected void prepareBeanFactory(ConfigurableListableBeanFactory beanFactory) &#123; //设置bean工厂的类加载器为当前application应用的加载器 beanFactory.setBeanClassLoader(getClassLoader()); //为bean工厂设置我们标准的SPEL表达式解析器对象StandardBeanExpressionResolver beanFactory.setBeanExpressionResolver(new StandardBeanExpressionResolver(beanFactory.getBeanClassLoader())); //为我们的bean工厂设置了一个propertityEditor 属性资源编辑器对象(用于后面的给bean对象赋值使用) beanFactory.addPropertyEditorRegistrar(new ResourceEditorRegistrar(this, getEnvironment())); // 注册了一个完整的ApplicationContextAwareProcessor 后置处理器用来处理ApplicationContextAware接口的回调方法 beanFactory.addBeanPostProcessor(new ApplicationContextAwareProcessor(this)); // 忽略以下接口的bean的接口函数方法，在populateBean时以下接口都有setXXX方法，这些方法不特殊处理将会自动注入容器中的bean beanFactory.ignoreDependencyInterface(EnvironmentAware.class); beanFactory.ignoreDependencyInterface(EmbeddedValueResolverAware.class); beanFactory.ignoreDependencyInterface(ResourceLoaderAware.class); beanFactory.ignoreDependencyInterface(ApplicationEventPublisherAware.class); beanFactory.ignoreDependencyInterface(MessageSourceAware.class); beanFactory.ignoreDependencyInterface(ApplicationContextAware.class); /** * 当注册了依赖解析后，例如当注册了对BeanFactory.class的解析依赖后，，当bean的属性注入时，一旦检测到属性为BeanFactory 类型便会将beanFactory的实例注入进去。 * 知道为什么可以@Autowired， ApplicationContext applicationContext 就是因为这里设置了 */ beanFactory.registerResolvableDependency(BeanFactory.class, beanFactory); beanFactory.registerResolvableDependency(ResourceLoader.class, this); beanFactory.registerResolvableDependency(ApplicationEventPublisher.class, this); beanFactory.registerResolvableDependency(ApplicationContext.class, this); // 注册了一个事件监听器探测器后置处理器接口 beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(this)); if (beanFactory.containsBean(LOAD_TIME_WEAVER_BEAN_NAME)) &#123; // 处理aspectj的 beanFactory.addBeanPostProcessor(new LoadTimeWeaverAwareProcessor(beanFactory)); beanFactory.setTempClassLoader(new ContextTypeMatchClassLoader(beanFactory.getBeanClassLoader())); &#125; // 注册了bean工厂的内部的bean if (!beanFactory.containsLocalBean(ENVIRONMENT_BEAN_NAME)) &#123; // 环境 beanFactory.registerSingleton(ENVIRONMENT_BEAN_NAME, getEnvironment()); &#125; if (!beanFactory.containsLocalBean(SYSTEM_PROPERTIES_BEAN_NAME)) &#123; //环境系统属性 beanFactory.registerSingleton(SYSTEM_PROPERTIES_BEAN_NAME, getEnvironment().getSystemProperties()); &#125; if (!beanFactory.containsLocalBean(SYSTEM_ENVIRONMENT_BEAN_NAME)) &#123; //系统环境 beanFactory.registerSingleton(SYSTEM_ENVIRONMENT_BEAN_NAME, getEnvironment().getSystemEnvironment()); &#125;&#125; postProcessBeanFactory一个空方法留给子类去实现该接口。 invokeBeanFactoryPostProcessors是目前为止最重要的方法，会在此将Class扫描成BeanDefinition 以及Bean工厂后置处理器调用对IoC容器加载BeanDefinition前后进行处理。 123456789protected void invokeBeanFactoryPostProcessors(ConfigurableListableBeanFactory beanFactory) &#123; // 参数分别是当前Bean工厂，自己调用annotationConfigApplicationContext.addBeanFactoryPostProcessor添加的 PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(beanFactory, getBeanFactoryPostProcessors()); if (beanFactory.getTempClassLoader() == null &amp;&amp; beanFactory.containsBean(LOAD_TIME_WEAVER_BEAN_NAME)) &#123; beanFactory.addBeanPostProcessor(new LoadTimeWeaverAwareProcessor(beanFactory)); beanFactory.setTempClassLoader(new ContextTypeMatchClassLoader(beanFactory.getBeanClassLoader())); &#125;&#125; BeanDefinitionRegistryPostProcessor是BeanDefinition解析前调用，执行的顺序依次是：实现了PriorityOrdered接口的，实现了Ordered接口的，没有实现任何的优先级接口的， BeanDefinitionRegistryPostProcessor是BeanFactoryPostProcessor的子接口。 BeanFactoryPostProcessor是BeanDefinition解析后调用，其执行顺序和 BeanDefinitionRegistryPostProcessor 是一样的。但是Bean实例还没有被初始化。 很明显当前的beanFactory即 AnnotationConfigApplicationContext 从前面的类结构图可知明显是BeanDefinitionRegistry的实例，这里一般情况beanFactoryPostProcessors是空的。processedBeans变量是用于将已经处理过的后置处理器过滤掉，防止重复执行。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134public static void invokeBeanFactoryPostProcessors(ConfigurableListableBeanFactory beanFactory, List&lt;BeanFactoryPostProcessor&gt; beanFactoryPostProcessors) &#123; Set&lt;String&gt; processedBeans = new HashSet&lt;&gt;(); // 定义已处理的后置处理器 // 判断beanFactory是否实现了BeanDefinitionRegistry，实现了该结构就有注册和获取Bean定义的能力 if (beanFactory instanceof BeanDefinitionRegistry) &#123; //强行把我们的bean工厂转为BeanDefinitionRegistry，因为待会需要注册Bean定义 BeanDefinitionRegistry registry = (BeanDefinitionRegistry) beanFactory; //保存BeanFactoryPostProcessor类型的后置，BeanFactoryPostProcessor提供修改 List&lt;BeanFactoryPostProcessor&gt; regularPostProcessors = new ArrayList&lt;&gt;(); //保存BeanDefinitionRegistryPostProcessor类型的后置处理器，BeanDefinitionRegistryPostProcessor提供注册 List&lt;BeanDefinitionRegistryPostProcessor&gt; registryProcessors = new ArrayList&lt;&gt;(); //循环我们传递进来的beanFactoryPostProcessors for (BeanFactoryPostProcessor postProcessor : beanFactoryPostProcessors) &#123; // 判断后置处理器是不是BeanDefinitionRegistryPostProcessor if (postProcessor instanceof BeanDefinitionRegistryPostProcessor) &#123; // 进行强制转化 BeanDefinitionRegistryPostProcessor registryProcessor = (BeanDefinitionRegistryPostProcessor) postProcessor; // 调用其作为BeanDefinitionRegistryPostProcessor的处理器的后置方法 registryProcessor.postProcessBeanDefinitionRegistry(registry); // 添加到我们用于保存的BeanDefinitionRegistryPostProcessor的集合中 registryProcessors.add(registryProcessor); &#125; else &#123; // 若没实现BeanDefinitionRegistryPostProcessor接口，其就是BeanFactoryPostProcessor其加入到regularPostProcessors中 regularPostProcessors.add(postProcessor); &#125; &#125; // 定义一个集合用户保存当前准备创建的BeanDefinitionRegistryPostProcessor List&lt;BeanDefinitionRegistryPostProcessor&gt; currentRegistryProcessors = new ArrayList&lt;&gt;(); // 第一步：去当前容器中获取BeanDefinitionRegistryPostProcessor的bean的处理器名称 String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false); // 循环筛选出来的匹配BeanDefinitionRegistryPostProcessor的类型名称 for (String ppName : postProcessorNames) &#123; // 判断是否实现了PriorityOrdered接口的 if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123; // 显示的调用getBean()的方式获取出该对象然后加入到currentRegistryProcessors集合中去，即实例化 currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class)); // 同时也加入到processedBeans集合中去 processedBeans.add(ppName); &#125; &#125; // 对currentRegistryProcessors集合中BeanDefinitionRegistryPostProcessor进行排序 sortPostProcessors(currentRegistryProcessors, beanFactory); // 把当前的加入到总的里面去，因为一开始spring只会执行BeanDefinitionRegistryPostProcessor独有的方法，而不会执行BeanDefinitionRegistryPostProcessor父类的方法 // 即BeanFactoryProcessor接口中的方法，所以需要把这些后置处理器放入一个集合中，后续统一执行BeanFactoryProcessor接口中的方法 registryProcessors.addAll(currentRegistryProcessors); // 在这里典型的BeanDefinitionRegistryPostProcessor就是ConfigurationClassPostProcessor，用于进行bean定义的加载，如包扫描，@import等等 invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry); currentRegistryProcessors.clear(); // 调用完之后，马上clear掉 // 去容器中获取BeanDefinitionRegistryPostProcessor的bean的处理器名称（内置的和上面注册的） postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false); // 循环上一步获取的BeanDefinitionRegistryPostProcessor的类型名称 for (String ppName : postProcessorNames) &#123; // 表示没有被处理过，且实现了Ordered接口的 if (!processedBeans.contains(ppName) &amp;&amp; beanFactory.isTypeMatch(ppName, Ordered.class)) &#123; // 显示的调用getBean()的方式获取出该对象然后加入到currentRegistryProcessors集合中去 currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class)); // 同时也加入到processedBeans集合中去 processedBeans.add(ppName); &#125; &#125; // 对currentRegistryProcessors集合中BeanDefinitionRegistryPostProcessor进行排序 sortPostProcessors(currentRegistryProcessors, beanFactory); // 把他加入到用于保存到registryProcessors中 registryProcessors.addAll(currentRegistryProcessors); invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry); // 调用他的后置处理方法 currentRegistryProcessors.clear(); // 调用完之后，马上clear掉 // 调用没有实现任何优先级接口的BeanDefinitionRegistryPostProcessor，定义一个重复处理的开关变量 默认值为true boolean reiterate = true; while (reiterate) &#123; // 第一次就可以进来 reiterate = false; // 进入循环马上把开关变量给改为false // 去容器中获取BeanDefinitionRegistryPostProcessor的bean的处理器名称 postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false); for (String ppName : postProcessorNames) &#123; // 循环上一步获取的BeanDefinitionRegistryPostProcessor的类型名称 if (!processedBeans.contains(ppName)) &#123; //没有被处理过的 //显示的调用getBean()的方式获取出该对象然后加入到currentRegistryProcessors集合中去 currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class)); processedBeans.add(ppName); // 同时也加入到processedBeans集合中去 reiterate = true; //再次设置为true &#125; &#125; sortPostProcessors(currentRegistryProcessors, beanFactory); registryProcessors.addAll(currentRegistryProcessors); invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry); currentRegistryProcessors.clear(); // 调用完之后，马上clear掉 &#125; // 调用BeanDefinitionRegistryPostProcessor.postProcessBeanFactory方法 invokeBeanFactoryPostProcessors(registryProcessors, beanFactory); // 调用BeanFactoryPostProcessor自设的 invokeBeanFactoryPostProcessors(regularPostProcessors, beanFactory); &#125; else &#123; // 若当前的beanFactory没有实现BeanDefinitionRegistry说明没有注册Bean定义的能力 // 则直接调用BeanDefinitionRegistryPostProcessor.postProcessBeanFactory方法 invokeBeanFactoryPostProcessors(beanFactoryPostProcessors, beanFactory); &#125; // 上面是所有BeanDefinitionRegistryPostProcessor调用完毕，接下来处理BeanFactoryPostProcessor //获取容器中所有的 BeanFactoryPostProcessor String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanFactoryPostProcessor.class, true, false); // 保存BeanFactoryPostProcessor类型实现了priorityOrdered List&lt;BeanFactoryPostProcessor&gt; priorityOrderedPostProcessors = new ArrayList&lt;&gt;(); // 保存BeanFactoryPostProcessor类型实现了Ordered接口的 List&lt;String&gt; orderedPostProcessorNames = new ArrayList&lt;&gt;(); // 保存BeanFactoryPostProcessor没有实现任何优先级接口的 List&lt;String&gt; nonOrderedPostProcessorNames = new ArrayList&lt;&gt;(); for (String ppName : postProcessorNames) &#123; // processedBeans包含的话，表示在上面处理BeanDefinitionRegistryPostProcessor的时候处理过了 if (processedBeans.contains(ppName)) &#123; // skip - already processed in first phase above &#125; else if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123; // 判断是否实现了PriorityOrdered 优先级最高 priorityOrderedPostProcessors.add(beanFactory.getBean(ppName, BeanFactoryPostProcessor.class)); &#125; else if (beanFactory.isTypeMatch(ppName, Ordered.class)) &#123; // 判断是否实现了Ordered 优先级其次 orderedPostProcessorNames.add(ppName); &#125; else &#123; // 没有实现任何的优先级接口的 最后调用 nonOrderedPostProcessorNames.add(ppName); &#125; &#125; sortPostProcessors(priorityOrderedPostProcessors, beanFactory); // 排序 // 先调用BeanFactoryPostProcessor实现了PriorityOrdered接口的 invokeBeanFactoryPostProcessors(priorityOrderedPostProcessors, beanFactory); // 再调用BeanFactoryPostProcessor实现了Ordered接口的 List&lt;BeanFactoryPostProcessor&gt; orderedPostProcessors = new ArrayList&lt;&gt;(); for (String postProcessorName : orderedPostProcessorNames) &#123; orderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class)); &#125; sortPostProcessors(orderedPostProcessors, beanFactory); invokeBeanFactoryPostProcessors(orderedPostProcessors, beanFactory); // 调用没有实现任何方法接口的 List&lt;BeanFactoryPostProcessor&gt; nonOrderedPostProcessors = new ArrayList&lt;&gt;(); for (String postProcessorName : nonOrderedPostProcessorNames) &#123; nonOrderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class)); &#125; invokeBeanFactoryPostProcessors(nonOrderedPostProcessors, beanFactory); beanFactory.clearMetadataCache();&#125; invokeBeanDefinitionRegistryPostProcessors执行了三次，执行currentRegistryProcessors变量中装载的BeanDefinitionRegistryPostProcessor，第一次执行currentRegistryProcessors中只有解析配置类的后置处理器ConfigurationClassPostProcessor ，这里调用的 beanFactory.getBean ，将会解析出系统中通过配置类配置的扫描包，扫描出所有Bean，第二次执行currentRegistryProcessors为空，为空的前提是扫描出的Bean中无 BeanDefinitionRegistryPostProcessor ，第三次执行和第二次执行一样。如下所示若定义一个自定义的 BeanDefinitionRegistryPostProcessor ，由于这里没有实现 PriorityOrdered 和 Ordered 接口，则第三次执行时会执行该 BeanDefinitionRegistryPostProcessor 的 postProcessBeanDefinitionRegistry 方法。 12345678910111213@Componentpublic class MyBeanDefinitionRegistryPostProcessor implements BeanDefinitionRegistryPostProcessor &#123; @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException &#123; RootBeanDefinition car = (RootBeanDefinition) beanFactory.getBeanDefinition(&quot;car&quot;); &#125; @Override public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) throws BeansException &#123; RootBeanDefinition beanDefinition = new RootBeanDefinition(); beanDefinition.setBeanClass(Tank.class); registry.registerBeanDefinition(&quot;car&quot;, beanDefinition); &#125;&#125; 当 BeanDefinitionRegistryPostProcessor 处理完毕后会将其与registryProcessors合并，因为一开始只会执行BeanDefinitionRegistryPostProcessor独有方法，不会执行其父类方法，即BeanFactoryProcessor接口中的方法，故需要把这些后置处理器放入一个集合中，后续统一执行BeanFactoryProcessor接口中的方法。 可理解为执行currentRegistryProcessors中的ConfigurationClassPostProcessor中的postProcessBeanDefinitionRegistry方法，这就是Spring设计思想的体现了，在这里体现的就是其中的热插拔，插件化开发的思想。Spring中很多东西都是交给插件去处理的，该后置处理器就相当于一个插件。 当通过invokeBeanDefinitionRegistryPostProcessors方法执行过ConfigurationClassPostProcessor后，后续就能获取到项目中自定义的打上@Component注解的后置处理器。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556private static void invokeBeanFactoryPostProcessors(Collection&lt;? extends BeanFactoryPostProcessor&gt; postProcessors, ConfigurableListableBeanFactory beanFactory) &#123; for (BeanFactoryPostProcessor postProcessor : postProcessors) &#123; postProcessor.postProcessBeanFactory(beanFactory); &#125;&#125;public class ConfigurationClassPostProcessor implements BeanDefinitionRegistryPostProcessor, PriorityOrdered, ResourceLoaderAware, BeanClassLoaderAware, EnvironmentAware &#123; public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) &#123; int factoryId = System.identityHashCode(beanFactory); if (this.factoriesPostProcessed.contains(factoryId)) &#123; throw new IllegalStateException( &quot;postProcessBeanFactory already called on this post-processor against &quot; + beanFactory); &#125; this.factoriesPostProcessed.add(factoryId); if (!this.registriesPostProcessed.contains(factoryId)) &#123; processConfigBeanDefinitions((BeanDefinitionRegistry) beanFactory); &#125; // 使用cglib对配置类进行代理，因为@Bean方法到时候要进行创建Bean的实例 enhanceConfigurationClasses(beanFactory); beanFactory.addBeanPostProcessor(new ImportAwareBeanPostProcessor(beanFactory)); &#125; public void enhanceConfigurationClasses(ConfigurableListableBeanFactory beanFactory) &#123; Map&lt;String, AbstractBeanDefinition&gt; configBeanDefs = new LinkedHashMap&lt;&gt;(); for (String beanName : beanFactory.getBeanDefinitionNames()) &#123; BeanDefinition beanDef = beanFactory.getBeanDefinition(beanName); // 只有full版配置类才会创建cglib代理 if (ConfigurationClassUtils.isFullConfigurationClass(beanDef)) &#123; if (!(beanDef instanceof AbstractBeanDefinition)) &#123; throw new BeanDefinitionStoreException(&quot;Cannot enhance @Configuration bean definition &#x27;&quot; + beanName + &quot;&#x27; since it is not stored in an AbstractBeanDefinition subclass&quot;); &#125; configBeanDefs.put(beanName, (AbstractBeanDefinition) beanDef); &#125; &#125; if (configBeanDefs.isEmpty()) &#123; return; // nothing to enhance -&gt; return immediately &#125; ConfigurationClassEnhancer enhancer = new ConfigurationClassEnhancer(); for (Map.Entry&lt;String, AbstractBeanDefinition&gt; entry : configBeanDefs.entrySet()) &#123; AbstractBeanDefinition beanDef = entry.getValue(); // If a @Configuration class gets proxied, always proxy the target class beanDef.setAttribute(AutoProxyUtils.PRESERVE_TARGET_CLASS_ATTRIBUTE, Boolean.TRUE); try &#123; // Set enhanced subclass of the user-specified bean class Class&lt;?&gt; configClass = beanDef.resolveBeanClass(this.beanClassLoader); if (configClass != null) &#123; Class&lt;?&gt; enhancedClass = enhancer.enhance(configClass, this.beanClassLoader); if (configClass != enhancedClass) &#123; // 重新修改Bean定义的Class，在创建Bean的实例时将会实例cglib的类 beanDef.setBeanClass(enhancedClass); &#125; &#125; &#125; catch (Throwable ex) &#123; &#125; &#125; &#125;&#125; 只有full版配置类才会创建cglib代理，虽然在指定配置时不标注 @Configuration 也行，所以加不加注解的区别就在这里，当在配置类中一个 @Bean 使用方法的方式引用另一个 Bean 若不加注解就会重复加载Bean ，若加了 @Configuration 则会在这里创建cglib代理，当调用@Bean方法时会先检测容器中是否存在。 1234567@Componentpublic class MyBeanFactoryPostProcessor implements BeanFactoryPostProcessor &#123; @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException &#123; System.out.println(&quot;MyBeanFactoryPostProcessorNew&quot;); &#125;&#125; 同样invokeBeanFactoryPostProcessors方法会执行自定义的BeanFactoryPostProcessor的postProcessBeanFactory方法。 registerBeanPostProcessors给容器中注册bean的后置处理器，bean的后置处理器在bean的各个生命周期中都会进行调用。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960protected void registerBeanPostProcessors(ConfigurableListableBeanFactory beanFactory) &#123; PostProcessorRegistrationDelegate.registerBeanPostProcessors(beanFactory, this);&#125;public static void registerBeanPostProcessors(ConfigurableListableBeanFactory beanFactory, AbstractApplicationContext applicationContext) &#123; // 去容器中获取所有的BeanPostProcessor 的名称(还是bean定义) String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanPostProcessor.class, true, false); // 之前refresh--&gt;prepareBeanFactory()中注册的postProcessorNames.length // bean后置处理器个数beanFactory.getBeanPostProcessorCount()成品个数 beanFactory工厂中bean定义的个数+1在后面又马上注册了BeanPostProcessorChecker的后置处理器 int beanProcessorTargetCount = beanFactory.getBeanPostProcessorCount() + 1 + postProcessorNames.length; beanFactory.addBeanPostProcessor(new BeanPostProcessorChecker(beanFactory, beanProcessorTargetCount)); //按照BeanPostProcessor实现的优先级接口来分离我们的后置处理器 List&lt;BeanPostProcessor&gt; priorityOrderedPostProcessors = new ArrayList&lt;&gt;();// 保存实现了priorityOrdered接口的 List&lt;BeanPostProcessor&gt; internalPostProcessors = new ArrayList&lt;&gt;(); // 系统内部的 List&lt;String&gt; orderedPostProcessorNames = new ArrayList&lt;&gt;(); // 实现了ordered接口的 List&lt;String&gt; nonOrderedPostProcessorNames = new ArrayList&lt;&gt;(); // 没有优先级的 for (String ppName : postProcessorNames) &#123; // 循环bean定义(BeanPostProcessor) if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123; //若实现了PriorityOrdered接口的 BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); // 显示的调用getBean流程创建bean的后置处理器 priorityOrderedPostProcessors.add(pp); // 加入到集合中 if (pp instanceof MergedBeanDefinitionPostProcessor) &#123; // 判断是否实现了MergedBeanDefinitionPostProcessor internalPostProcessors.add(pp); // 加入到集合中 &#125; &#125; else if (beanFactory.isTypeMatch(ppName, Ordered.class)) &#123; // 判断是否实现了Ordered orderedPostProcessorNames.add(ppName); &#125; else &#123; // 没有任何拍下接口的 nonOrderedPostProcessorNames.add(ppName); &#125; &#125; // 把实现了priorityOrdered注册到容器中 sortPostProcessors(priorityOrderedPostProcessors, beanFactory); registerBeanPostProcessors(beanFactory, priorityOrderedPostProcessors); // 处理实现Ordered的bean定义 List&lt;BeanPostProcessor&gt; orderedPostProcessors = new ArrayList&lt;&gt;(); for (String ppName : orderedPostProcessorNames) &#123; BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); //显示调用getBean方法 orderedPostProcessors.add(pp); //加入到集合中 if (pp instanceof MergedBeanDefinitionPostProcessor) &#123; //判断是否实现了MergedBeanDefinitionPostProcessor internalPostProcessors.add(pp); //加入到集合中 &#125; &#125; //排序并且注册我们实现了Order接口的后置处理器 sortPostProcessors(orderedPostProcessors, beanFactory); registerBeanPostProcessors(beanFactory, orderedPostProcessors); List&lt;BeanPostProcessor&gt; nonOrderedPostProcessors = new ArrayList&lt;&gt;(); for (String ppName : nonOrderedPostProcessorNames) &#123; BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); nonOrderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) &#123; internalPostProcessors.add(pp); &#125; &#125; //注册我们普通的没有实现任何排序接口的 registerBeanPostProcessors(beanFactory, nonOrderedPostProcessors); //注册MergedBeanDefinitionPostProcessor类型的后置处理器bean合并后的处理，Autowired注解正是通过此方法实现诸如类型的预解析。 sortPostProcessors(internalPostProcessors, beanFactory); registerBeanPostProcessors(beanFactory, internalPostProcessors); //注册ApplicationListenerDetector 应用监听器探测器的后置处理器 beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(applicationContext));&#125;","tags":[{"name":"Spring, IOC","slug":"Spring-IOC","permalink":"http://example.com/tags/Spring-IOC/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}]},{"title":"Hystrix总结","date":"2020-10-18T07:08:20.000Z","path":"blog/Spring/Hystrix总结/","text":"在项目中需要对某些接口进行限流和熔断处理，防止由于某些接口资源消耗过大影响到整个的所有接口，防止单独的依赖耗尽资源；对一些依赖服务进行隔离，防止当依赖服务不可用或者响应非常缓慢导致整个应用不可用，阻止故障的连锁反应。过载立即切断并快速失败防止排队。 Hystrix 有4种参数配置，优先级由低到高分别为：内置全局默认值、动态全局默认属性、内置实例默认值、动态配置实例属性。 基于编程式基于编程式使用 Hystrix ，只需继承 HystrixCommand 或 HystrixObservableCommand ，区别在于 HystrixCommand 命令逻辑写在 run() 方法中，且由新创建线程执行，一个实例只能向调用程序发送单条数据。 HystrixObservableCommand 命令逻辑写在 construct() 方法中，由调用程序线程执行，一个实例可以顺序发送多条数据。 HystrixCommand 命令有 execute() 、 queue() 、 observe() 、t oObservable() 4个方法来触发执行 run() 方法。 HystrixObservableCommand 命令只有 observe() 、t oObservable() 2个方法来触发执行 construct() 方法。 execute() 以同步堵塞方式执行 queue() 以异步非堵塞方式执行，通过 Future.get() 获取 run() 返回结果 observe() 事件注册前执行 run() 或 construct() 方法 toObservable() 事件注册后执行 run() 或 construct() 方法 继承 HystrixCommand 实现自己的 Command ，在构造方法中配置需要的参数，后续章节对具体配置进行详细描述。 123456789101112131415161718192021222324252627282930313233public class HelloWorldCommand extends HystrixCommand&lt;JSONObject&gt; &#123; private DataRequest request; protected HelloWorldCommand(DataRequest request) &#123; HystrixCommandProperties.Setter propertiesSetter = HystrixCommandProperties.Setter() .withCircuitBreakerEnabled(true) .withRequestCacheEnabled(false) .withRequestLogEnabled(false) .withExecutionIsolationStrategy() .withExecutionIsolationSemaphoreMaxConcurrentRequests(80) .withFallbackIsolationSemaphoreMaxConcurrentRequests(80) .withCircuitBreakerRequestVolumeThreshold(30) .withCircuitBreakerSleepWindowInMilliseconds(5000) .withExecutionTimeoutInMilliseconds(timeOut); HystrixCommandGroupKey groupKey = HystrixCommandGroupKey.Factory.asKey(&quot;requestData&quot;); HystrixCommand.Setter setter = HystrixCommand.Setter.withGroupKey(groupKey) .andCommandKey(HystrixCommandKey.Factory.asKey(&quot;data-&quot;+ Id)) .andCommandPropertiesDefaults(propertiesSetter) .andThreadPoolKey(HystrixThreadPoolKey.Factory.asKey(&quot;requestData&quot;)); super(setter); this.request = request; &#125; @Override protected JSONObject run() &#123; return request.executeRequest(); &#125; @Override protected JSONObject getFallback() &#123;&#125;&#125; 调用 HystrixCommand 的执行方法发起实际请求， execute() 方法同步调用： 12HelloWorldCommand command = new HelloWorldCommand(request);JSONObject result = command.execute(); queue() 方法异步调用： 123HelloWorldCommand command = new HelloWorldCommand(request);Future&lt;JSONObject&gt; future = command.queue();JSONObject result = future.get(10000, TimeUnit.MILLISECONDS); observe() 方法，注册观察者事件订阅，事件注册前执行： 12Observable&lt;JSONObject&gt; observable = new HelloWorldCommand(request).observe();observable.subscribe(result1 -&gt; System.out.println(&quot;Observable call--&gt; &quot; + result1)); observe() 方法，注册完整执行生命周期事件，事件注册前执行： 1234567891011121314Observable&lt;JSONObject&gt; observable = new HelloWorldCommand(request).observe();observable.subscribe(new Observer&lt;JSONObject&gt;() &#123; //onNext/onError完成之后最后回调 @Override public void onCompleted() &#123;&#125; // 当产生异常时回调 @Override public void onError(Throwable throwable) &#123;&#125; // 获取结果后回调 @Override public void onNext(JSONObject s) &#123;&#125;&#125;); toObservable() 方法，注册观察者事件订阅，事件注册后执行： 1234567891011121314Observable&lt;JSONObject&gt; toObservable = new HelloWorldCommand(request).toObservable();toObservable.subscribe(new Observer&lt;JSONObject&gt;() &#123; //onNext/onError完成之后最后回调 @Override public void onCompleted() &#123;&#125; // 当产生异常时回调 @Override public void onError(Throwable throwable) &#123;&#125; // 获取结果后回调 @Override public void onNext(JSONObject s) &#123;&#125;&#125;); 基于注解式注解使用方式和编程式大致相同，只是属性参数配置都注解化了。三个核心注解分别为 @HystrixCommand 、 @HystrixProperty 和 @HystrixCollapser 。注解同步执行： 123456789101112131415public class HelloWorldHystrixAnnotation &#123; @Autowired private DataClient dataClient; @HystrixCommand(groupKey = &quot;helloWorldHystrixAnnotation&quot;, commandKey = &quot;helloWorldHystrixAnnotationSync&quot;, fallbackMethod = &quot;fallback&quot;) public JSONObject executeRequest(String param) &#123; return dataClient.retrieveData(param); &#125; public JSONObject fallback() &#123; return new JSONObject(); &#125;&#125; 注解异步执行： 1234567891011121314151617181920public class HelloWorldHystrixAnnotationAsync &#123; @Autowired private DataClient dataClient; @HystrixCommand(groupKey = &quot;helloWorldHystrixAnnotation&quot;, commandKey = &quot;helloWorldHystrixAnnotationAsync&quot;, fallbackMethod = &quot;fallback&quot;) public Future&lt;JSONObject&gt; run(String param) &#123; return new AsyncResult&lt;JSONObject&gt;() &#123; @Override public JSONObject invoke() &#123; return dataClient.retrieveData(param); &#125; &#125;; &#125; public JSONObject fallback() &#123; return new JSONObject(); &#125;&#125; 注解订阅执行： 123456789101112131415161718192021222324public class HelloWorldHystrixAnnotationObervable &#123; @Autowired private DataClient dataClient; @HystrixCommand(groupKey = &quot;helloWorldHystrixAnnotation&quot;, commandKey = &quot;helloWorldHystrixAnnotationObervable&quot;, fallbackMethod = &quot;fallback&quot;) public Observable&lt;JSONObject&gt; run(String param) &#123; return Observable.create(subscriber -&gt; &#123; try &#123; if (!subscriber.isUnsubscribed()) &#123; subscriber.onNext(dataClient.retrieveData(param)); subscriber.onCompleted(); &#125; &#125; catch (Exception e) &#123; subscriber.onError(e); &#125; &#125;); &#125; public JSONObject fallback() &#123; return new JSONObject(); &#125;&#125; 触发fallback方法的情况 执行抛出异常 执行超时 断路器打开，不尝试执行 线程池拒绝，不尝试执行 信号量拒绝，不尝试执行 Hystrix监控界面参数基础属性配置 CommandGroup ：每个命令最少配置的必选参数，不指定 ThreadPoolKey 的情况下，用于指定线程池的隔离。 实例配置： HystrixCommand.Setter().withGroupKey(HystrixCommandGroupKey.Factory.asKey(&quot;groupKey&quot;)); 注解配置： @HystrixCommand(groupKey = &quot;groupKey&quot;） CommandKey ：依赖命名，一般每个 CommandKey 代表一个依赖抽象，相同依赖使用相同 CommandKey 名称，依赖隔离的根本就是对相同CommandKey 的依赖做隔离，不同的依赖隔离最好使用不同的线程池。 实例配置： HystrixCommand.Setter().andCommandKey(HystrixCommandKey.Factory.asKey(&quot;commandKey&quot;)); 注解配置： @HystrixCommand(commandKey = &quot;commandKey&quot;) ThreadPoolKey ：依赖隔离使用的线程池的键值，对同一业务依赖隔离用 CommandGroup 做区分，对同一依赖的不同远程调用，使用 ThreadPoolKey 做隔离区分，业务相同的组，需要在资源上做隔离时，使用 ThreadPoolKey 区分。不同的 ThreadPoolKey 建议使用不同的 CommandKey 。 实例配置： HystrixCommand.Setter().andThreadPoolKey(HystrixThreadPoolKey.Factory.asKey(&quot;threadPoolKey&quot;)) 注解配置： @HystrixCommand(threadPoolKey = &quot;threadPoolKey&quot;) 命令属性配置 execution.isolation.strategy ：用于设置 HystrixCommand 执行的隔离策略，支持 THREAD线程池隔离单独线程执行并发数受限于线程池大小和 SEMAPHORE信号量隔离在调用线程中执行通过信号量来限制并发数。 实例配置： HystrixCommandProperties.Setter().withExecutionIsolationStrategy(ExecutionIsolationStrategy.THREAD) 注解配置： @HystrixCommand(commandProperties = &#123;@HystrixProperty(name = &quot;execution.isolation.strategy&quot;,value = &quot;SEMAPHORE&quot;)&#125;) 默认值： THREAD execution.timeout.enabled ：是否启用超时限制。 实例配置： HystrixCommandProperties.Setter().withExecutionTimeoutEnabled(true) 注解配置： @HystrixCommand(commandProperties = &#123;@HystrixProperty(name = &quot;execution.timeout.enabled&quot;, value = &quot;true&quot;)&#125;) 默认值： true execution.isolation.thread.timeoutInMilliseconds ：执行超时时间，超时会作用在 HystrixCommand.queue() ，即使没有调用 get() 获得 Future 对象。 实例配置： HystrixCommandProperties.Setter().withExecutionTimeoutInMilliseconds(2000) 注解配置： @HystrixCommand(commandProperties = &#123;@HystrixProperty(name = &quot;execution.isolation.thread.timeoutInMilliseconds&quot;, value = &quot;2000&quot;)&#125;) 默认值： 1000ms execution.isolation.thread.interruptOnTimeout ：使用线程隔离时，对执行超时的线程是否被中断。 实例配置： HystrixCommandProperties.Setter().withExecutionIsolationThreadInterruptOnTimeout(true) 注解配置： @HystrixCommand(commandProperties = &#123;@HystrixProperty(name = &quot;execution.isolation.thread.interruptOnTimeout&quot;, value = &quot;true&quot;)&#125;) 默认值： true （ THREAD 模式有效） execution.isolation.semaphore.maxConcurrentRequests ：使用信号量策略时，允许的最大并发请求数。 实例配置： HystrixCommandProperties.Setter().withExecutionIsolationSemaphoreMaxConcurrentRequests(50) 注解配置： @HystrixCommand(commandProperties = &#123;@HystrixProperty(name = &quot;execution.isolation.semaphore.maxConcurrentRequests&quot;, value = &quot;50&quot;)&#125;) 默认值： 10 （ SEMAPHORE 模式有效） Fallback fallback.enabled ：当接口异常或者拒绝时，是否调用 Fallback 方法处理，线程池和信号量策略都支持。 实例配置： HystrixCommandProperties.Setter().withFallbackEnabled(true) 注解配置： @HystrixCommand(commandProperties = &#123;@HystrixProperty(name = &quot;fallback.enabled&quot;, value = &quot;true&quot;)&#125;) 默认值： true fallback.isolation.semaphore.maxConcurrentRequests ： Fallback 方法最大并发数。超过该配置的请求将被拒绝，若没有实现回退，则抛出异常。线程池和信号量策略都支持。 实例配置： HystrixCommandProperties.Setter().withFallbackIsolationSemaphoreMaxConcurrentRequests(20) 注解配置： @HystrixCommand(commandProperties = &#123;@HystrixProperty(name = &quot;fallback.isolation.semaphore.maxConcurrentRequests&quot;, value = &quot;20&quot;)&#125;) 默认值： 10 （ SEMAPHORE 模式有效） circuitBreaker.enabled ：断路器是否生效。 实例配置： HystrixCommandProperties.Setter().withCircuitBreakerEnabled(true) 注解配置： @HystrixCommand(commandProperties = &#123;@HystrixProperty(name = &quot;circuitBreaker.enabled&quot;, value = &quot;true&quot;)&#125;) 默认值： true 断路器 circuitBreaker.requestVolumeThreshold ：滚动窗口中，打开断路器的最少请求数。 实例配置： HystrixCommandProperties.Setter().withCircuitBreakerRequestVolumeThreshold(20) 注解配置： @HystrixCommand(commandProperties = &#123;@HystrixProperty(name = &quot;circuitBreaker.requestVolumeThreshold&quot;,value = &quot;20&quot;)&#125;) 默认值： 20 circuitBreaker.sleepWindowInMilliseconds ：拒绝请求到再次不被拒绝的请求时间间隔。 实例配置： HystrixCommandProperties.Setter().withCircuitBreakerSleepWindowInMilliseconds(10) 注解配置： @HystrixCommand(commandProperties = &#123;@HystrixProperty(name = &quot;circuitBreaker.sleepWindowInMilliseconds&quot;, value = &quot;5000&quot;)&#125;) 默认值： 5000ms circuitBreaker.errorThresholdPercentage ：断路器启动回退逻辑的错误比率。 实例配置： HystrixCommandProperties.Setter().withCircuitBreakerErrorThresholdPercentage(50) 注解配置： @HystrixCommand(commandProperties = &#123;@HystrixProperty(name = &quot;circuitBreaker.errorThresholdPercentage&quot;, value = &quot;50&quot;)&#125;) 默认值： 50 circuitBreaker.forceClosed ：强制断路器进入关闭状态，将允许所有的请求，无视错误率。 实例配置： HystrixCommandProperties.Setter().withCircuitBreakerForceClosed(false) 注解配置： @HystrixCommand(commandProperties = &#123;@HystrixProperty(name = &quot;circuitBreaker.forceClosed&quot;, value = &quot;false&quot;)&#125;) 默认值： false circuitBreaker.forceOpen ：强制断路器进入打开状态，将会拒绝所有的请求。优先级比 circuitBreaker.forceClosed 高。 实例配置： HystrixCommandProperties.Setter().withCircuitBreakerForceOpen(false) 注解配置： @HystrixCommand(commandProperties = &#123;@HystrixProperty(name = &quot;circuitBreaker.forceOpen&quot;, value = &quot;false&quot;)&#125;) 默认值： false 线程池 hystrix.threadpool.default.coreSize ：设置核心线程池大小，与 ThreadPoolExecutor 的 coreSize 的含义不一样 实例配置： HystrixThreadPoolProperties.Setter().withCoreSize(10) 注解配置： @HystrixCommand(threadPoolProperties = &#123;@HystrixProperty(name = &quot;coreSize&quot;, value = &quot;10&quot;)&#125;) 默认值： 10 hystrix.threadpool.default.maximumSize ：设置线程池最大值，不开始拒绝 HystrixCommand 的情况下支持的最大并发数，设置 allowMaximumSizeToDrivergeFromCoreSize 后生效。 实例配置： HystrixThreadPoolProperties.Setter().withMaximumSize(10) 注解配置： @HystrixCommand(threadPoolProperties = &#123;@HystrixProperty(name = &quot;maximumSize&quot;, value = &quot;10&quot;)&#125;) 默认值： 10 hystrix.threadpool.default.maxQueueSize ：最大的队列值，若设置为 -1 使用 SynchronousQueue ，否则使用 LinkedBlockingQueue 。 实例配置： HystrixThreadPoolProperties.Setter().withMaxQueueSize(10) 注解配置： @HystrixCommand(threadPoolProperties = &#123;@HystrixProperty(name = &quot;maxQueueSize&quot;, value = &quot;10&quot;)&#125;) 默认值： -1 hystrix.threadpool.default.queueSizeRejectionThreshold ：设置队列拒绝的阈值， maxQueueSize 值为 -1 时，该属性不生效。 实例配置： HystrixThreadPoolProperties.Setter().withQueueSizeRejectionThreshold(5) 注解配置： @HystrixCommand(threadPoolProperties = &#123;@HystrixProperty(name = &quot;queueSizeRejectionThreshold&quot;, value = &quot;5&quot;)&#125;) 默认值： 5 hystrix.threadpool.default.keepAliveTimeMinutes ：设置存活时间，单位分钟，如果 coreSize 小于 maximumSize ，则该属性控制一个线程从使用完成到被释放的时间。 实例配置： HystrixThreadPoolProperties.Setter().withKeepAliveTimeMinutes(1) 注解配置： @HystrixCommand(threadPoolProperties = &#123;@HystrixProperty(name = &quot;keepAliveTimeMinutes&quot;, value = &quot;1&quot;)&#125;) 默认值： 1 hystrix.threadpool.default.allowMaximumSizeToDivergeFromCoreSize ：允许 maximumSize 起作用。 实例配置： HystrixThreadPoolProperties.Setter().withAllowMaximumSizeToDivergeFromCoreSize(false) 注解配置： @HystrixCommand(threadPoolProperties = &#123;@HystrixProperty(name = &quot;allowMaximumSizeToDivergeFromCoreSize&quot;, value = &quot;false&quot;)&#125;) 默认值： false","tags":[{"name":"SpringBoot, 限流, 熔断","slug":"SpringBoot-限流-熔断","permalink":"http://example.com/tags/SpringBoot-%E9%99%90%E6%B5%81-%E7%86%94%E6%96%AD/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}]},{"title":"IoC容器","date":"2020-10-18T07:08:20.000Z","path":"blog/Spring/IoC容器/","text":"IoC容器概述依赖反转的概念：依赖对象的获得被反转了，基于该结论为控制反转创造了一个更好听的名字：依赖注入。依赖控制反转的实现方式有很多种，Spring中IoC容器是实现该模式的载体，它可以在对象生成或初始化时直接将数据注入到对象中，也可以通过将对象引用注入到对象数据域中的方式来注入对方法调用的依赖。这种依赖注入是可以递归的，对象被逐层注入。 应用控制反转后，当对象被创建时，由一个调用系统内的所有对象的外界实体将其所依赖的对象的引用传递给它，控制反转是关于一个对象如何获取它所依赖的对象的引用，反转指的是责任的反转。 通过使用IoC容器，对象的依赖关系的管理被反转了或者说是把资源的获取方式反转了，对象之间的相互依赖关系由IoC容器进行管理，并由IoC容器完成对象的注入。注入的主要实现方式有：接口注入、 setter注入、构造器注入。Spring中setter注入和构造器注入是主要的注入方式，使用Spring时setter注入是常见的注入方式。且Spring还提供了对特定依赖的检查。 Spring IoC提供了一个基本的JavaBean容器，通过IoC容器管理依赖关系，并通过依赖注入和AOP切面增强了为JavaBean这样的POJO对象赋予事务管理、生命周期管理等基本功能。 IoC容器的设计与实现Spring IoC容器的设计中，实现了BeanFactory接口的简单容器系列，该系列容器只实现了容器的最基本的功能；和容器的高级形态ApplicationContext应用上下文，两个主要的容器系列。BeanFactory是IoC容器具体实现的基本功能规范的设计表现。 对于使用者来说，可将BeanFactory和ApplicationContext看成容器的具体表现形式。通常所说的IoC容器实际上代表的是一系列功能各异的容器产品。Spring中有各种各样的IoC容器的实现。 在Spring提供的基本的IoC容器的接口定义和实现的基础上，Spring通过定义BeanDefinition来管理基本的Spring的应用中的各种对象以及它们之间的相互依赖关系。 BeanDefinition抽象了对Bean的定义，是让容器起作用的主要数据类型。对于IoC容器来说，BeanDefinition就是对依赖反转模式中管理的对象依赖关系的数据抽象，也是容器实现依赖反转功能的核心数据结构，依赖反转功能都是围绕对BeanDefinition的处理来完成的。 BeanFactory接口定义了基本的IoC容器规范，从接口BeanFactory到HierarchicalBeanFactory再到ConfigurableBeanFactory是一条主要的BeanFactory设计路径。HierarchicalBeanFactory接口增加了getParentBeanFactory()的接口功能，使BeanFactory具备了双亲IoC容器的管理功能。ConfigurableBeanFactory接口主要定义了一些对BeanFactory的配置功能。可设置双亲IoC容器，配置Bean后置处理器等。","tags":[{"name":"Spring, IOC","slug":"Spring-IOC","permalink":"http://example.com/tags/Spring-IOC/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}]},{"title":"Bean的加载过程","date":"2020-10-17T07:58:20.000Z","path":"blog/Spring/Bean的加载过程/","text":"容器启动去实例化剩余未被加载的非懒加载的单例Bean。在invokeBeanFactoryPostProcessors方法中根据各种注解解析出来的类，在这都会被初始化，实例化的过程各种BeanPostProcessor开始起作用。 12345678910111213141516171819public abstract class AbstractApplicationContext extends DefaultResourceLoader implements ConfigurableApplicationContext &#123; protected void finishBeanFactoryInitialization(ConfigurableListableBeanFactory beanFactory) &#123; // 为我们的bean工厂创建类型转化器Convert if (beanFactory.containsBean(CONVERSION_SERVICE_BEAN_NAME) &amp;&amp; beanFactory.isTypeMatch(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)) &#123; beanFactory.setConversionService(beanFactory.getBean(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)); &#125; if (!beanFactory.hasEmbeddedValueResolver()) &#123; beanFactory.addEmbeddedValueResolver(strVal -&gt; getEnvironment().resolvePlaceholders(strVal)); &#125; // 处理关于aspectj String[] weaverAwareNames = beanFactory.getBeanNamesForType(LoadTimeWeaverAware.class, false, false); for (String weaverAwareName : weaverAwareNames) &#123; getBean(weaverAwareName); &#125; beanFactory.setTempClassLoader(null); beanFactory.freezeConfiguration(); // 冻结所有bean定义，说明注册的bean定义将不被修改或任何进一步的处理 beanFactory.preInstantiateSingletons(); // 实例化剩余的单实例bean &#125;&#125; 对于 FactoryBean 可以通过&amp;beanName获取到原始的FactoryBean ，若不加&amp;符号是获取的FactoryBean中 getObject方法返回的对象作为Bean。不论是普通Bean还是 FactoryBean 最终都是通过 getBean方法加载的。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class DefaultListableBeanFactory extends AbstractAutowireCapableBeanFactory implements ConfigurableListableBeanFactory, BeanDefinitionRegistry, Serializable &#123; public void preInstantiateSingletons() throws BeansException &#123; List&lt;String&gt; beanNames = new ArrayList&lt;&gt;(this.beanDefinitionNames); // 获取容器中所有bean定义的名称 for (String beanName : beanNames) &#123; // 循环所有的bean定义名称 // 合并的bean定义，转换为统一的RootBeanDefinition类型， 方便后续处理 RootBeanDefinition bd = getMergedLocalBeanDefinition(beanName); // 根据bean定义判断，不是抽象的&amp;&amp;是单例的&amp;&amp;不是懒加载的，才会去生成 if (!bd.isAbstract() &amp;&amp; bd.isSingleton() &amp;&amp; !bd.isLazyInit()) &#123; if (isFactoryBean(beanName)) &#123; // 是不是工厂bean // 是factoryBean会先生成实际的bean &amp;beanName是用来获取实际bean的 Object bean = getBean(FACTORY_BEAN_PREFIX + beanName); if (bean instanceof FactoryBean) &#123; final FactoryBean&lt;?&gt; factory = (FactoryBean&lt;?&gt;) bean; boolean isEagerInit; if (System.getSecurityManager() != null &amp;&amp; factory instanceof SmartFactoryBean) &#123; isEagerInit = AccessController.doPrivileged((PrivilegedAction&lt;Boolean&gt;)((SmartFactoryBean&lt;?&gt;) factory)::isEagerInit, getAccessControlContext()); &#125; else &#123; isEagerInit = (factory instanceof SmartFactoryBean &amp;&amp; ((SmartFactoryBean&lt;?&gt;) factory).isEagerInit()); &#125; if (isEagerInit) &#123; // 调用真正的getBean的流程 getBean(beanName); &#125; &#125; &#125; else &#123; // 非工厂Bean，就是普通的bean getBean(beanName); &#125; &#125; &#125; //或有的bean的名称，到这里所有的单实例的bean已经记载到单实例bean到缓存中 for (String beanName : beanNames) &#123; Object singletonInstance = getSingleton(beanName); // 从单例缓存池中获取所有的对象 // 判断当前的bean是否实现了SmartInitializingSingleton接口 if (singletonInstance instanceof SmartInitializingSingleton) &#123; final SmartInitializingSingleton smartSingleton = (SmartInitializingSingleton) singletonInstance; if (System.getSecurityManager() != null) &#123; AccessController.doPrivileged((PrivilegedAction&lt;Object&gt;) () -&gt; &#123; smartSingleton.afterSingletonsInstantiated(); return null; &#125;, getAccessControlContext()); &#125; else &#123; // 触发实例化之后的方法afterSingletonsInstantiated smartSingleton.afterSingletonsInstantiated(); &#125; &#125; &#125; &#125;&#125; 首先尝试去缓存中获取对象，若获取的是普通单例Bean 对象，则 getObjectForBeanInstance 会直接返回。但若 sharedInstance 是 FactoryBean 类型，则需调用getObject工厂方法获取真正的bean实例。若用户想获取FactoryBean本身，这里也不会做特别的处理，直接返回即可。毕竟FactoryBean的实现类本身也是一种Bean，只不过具有一点特殊的功能而已。 Spring不能解决单例对象构造器注入和原型模式创建Bean产生的循环依赖问题， isPrototypeCurrentlyInCreation(beanName) 判断会直接抛出异常。 判断 AbstractBeanFacotry 工厂是否有父工厂，一般情况下是没有父工厂因为 abstractBeanFactory 直接是抽象类，不存在父工厂，一般情况下，只有Spring和Spring MVC整合时才会有父子容器的概念，如Controller中注入Service时，发现依赖的是一个引用对象，则会调用getBean去把service找出来，但当前所在的容器是web子容器，则会在这里的先去父容器找。 若想类A在类B前被加载可以在类B上使用 @DependsOn(value = &#123;&quot;dependsA&quot;&#125;) 注解处理 dependsOn 的依赖，这不是所谓的循环依赖，而是bean创建前后的依赖。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117public abstract class AbstractBeanFactory extends FactoryBeanRegistrySupport implements ConfigurableBeanFactory &#123; public Object getBean(String name) throws BeansException &#123; return doGetBean(name, null, null, false); // 真正的获取bean的逻辑 &#125; protected &lt;T&gt; T doGetBean(final String name, @Nullable final Class&lt;T&gt; requiredType, @Nullable final Object[] args, boolean typeCheckOnly) throws BeansException &#123; // 这里传入进来的name可能是别名, 也有可能是工厂bean的name，所以在这里需要转换 final String beanName = transformedBeanName(name); Object bean; Object sharedInstance = getSingleton(beanName); // 尝试去缓存中获取对象 if (sharedInstance != null &amp;&amp; args == null) &#123; // 若sharedInstance是普通的单例bean，下面的方法会直接返回。但若sharedInstance是FactoryBean类型，则需调用getObject工厂方法获取真正的bean实例。 // 若用户想获取FactoryBean本身，这里也不会做特别的处理，直接返回即可。毕竟FactoryBean的实现类本身也是一种bean，只不过具有一点特殊的功能而已。 bean = getObjectForBeanInstance(sharedInstance, name, beanName, null); &#125; else &#123; // spring只能解决单例对象的setter注入的循环依赖，不能解决构造器注入和原型模式创建Bean产生的循环依赖问题 if (isPrototypeCurrentlyInCreation(beanName)) &#123; throw new BeanCurrentlyInCreationException(beanName); &#125; // 判断AbstractBeanFacotry工厂是否有父工厂(一般情况下是没有父工厂因为abstractBeanFactory直接是抽象类,不存在父工厂),一般情况下,只有Spring和SpringMvc整合时才会有父子容器的概念 // 如Controller中注入Service时，发现依赖的是一个引用对象，则会调用getBean去把service找出来，但当前所在的容器是web子容器，则会在这里的先去父容器找 BeanFactory parentBeanFactory = getParentBeanFactory(); // 若存在父工厂，且当前bean工厂不存在当前的bean定义，则bean定义是存在于父beanFacotry中 if (parentBeanFactory != null &amp;&amp; !containsBeanDefinition(beanName)) &#123; String nameToLookup = originalBeanName(name); // 获取bean的原始名称 // 若为AbstractBeanFactory类型，委托父类处理 if (parentBeanFactory instanceof AbstractBeanFactory) &#123; return ((AbstractBeanFactory) parentBeanFactory).doGetBean(nameToLookup, requiredType, args, typeCheckOnly); &#125; else if (args != null) &#123; // 委托给构造函数getBean()处理 return (T) parentBeanFactory.getBean(nameToLookup, args); &#125; else &#123; // 没有args，委托给标准的getBean()处理 return parentBeanFactory.getBean(nameToLookup, requiredType); &#125; &#125; // 方法参数typeCheckOnly，用来判断调用#getBean(...)方法时，表示是否仅仅进行类型检查获取Bean对象 if (!typeCheckOnly) &#123; // 若不是仅仅做类型检查，而是创建Bean对象，则需要调用#markBeanAsCreated(String beanName)方法，进行记录 markBeanAsCreated(beanName); &#125; try &#123; // 从容器中获取beanName相应的GenericBeanDefinition对象，并将其转换为RootBeanDefinition对象 final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName); checkMergedBeanDefinition(mbd, beanName, args); // 检查当前创建的bean定义是不是抽象的bean定义 // 处理dependsOn的依赖，这个不是所谓的循环依赖，而是bean创建前后的依赖，依赖bean的名称 String[] dependsOn = mbd.getDependsOn(); if (dependsOn != null) &#123; // 若给定的依赖bean已经注册为依赖给定的bean，即循环依赖的情况，抛出BeanCreationException异常 for (String dep : dependsOn) &#123; // beanName是当前正在创建的bean,dep是正在创建的bean的依赖的bean的名称 if (isDependent(beanName, dep)) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, &quot;Circular depends-on relationship between &#x27;&quot; + beanName + &quot;&#x27; and &#x27;&quot; + dep + &quot;&#x27;&quot;); &#125; registerDependentBean(dep, beanName); // 保存的是依赖beanName之间的映射关系：依赖beanName -&gt; beanName的集合 try &#123; getBean(dep); // 获取depentceOn的bean &#125; catch (NoSuchBeanDefinitionException ex) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, &quot;&#x27;&quot; + beanName + &quot;&#x27; depends on missing bean &#x27;&quot; + dep + &quot;&#x27;&quot;, ex); &#125; &#125; &#125; if (mbd.isSingleton()) &#123; // 创建单例bean，把beanName和singletonFactory传入一个回调对象用于回调 sharedInstance = getSingleton(beanName, () -&gt; &#123; try &#123; return createBean(beanName, mbd, args); // 进入创建bean的逻辑 &#125; catch (BeansException ex) &#123; // 创建bean的过程中发生异常，需要销毁关于当前bean的所有信息 destroySingleton(beanName); throw ex; &#125; &#125;); bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd); &#125; else if (mbd.isPrototype()) &#123; Object prototypeInstance = null; try &#123; beforePrototypeCreation(beanName); prototypeInstance = createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd); &#125; else &#123; String scopeName = mbd.getScope(); final Scope scope = this.scopes.get(scopeName); if (scope == null) &#123; throw new IllegalStateException(&quot;No Scope registered for scope name &#x27;&quot; + scopeName + &quot;&#x27;&quot;); &#125; try &#123; Object scopedInstance = scope.get(beanName, () -&gt; &#123; beforePrototypeCreation(beanName); try &#123; return createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; &#125;); bean = getObjectForBeanInstance(scopedInstance, name, beanName, mbd); &#125; catch (IllegalStateException ex) &#123; throw new BeanCreationException(beanName, &quot;Scope &#x27;&quot; + scopeName + &quot;&#x27; is not active for the current thread; consider &quot; + &quot;defining a scoped proxy for this bean if you intend to refer to it from a singleton&quot;, ex); &#125; &#125; &#125; catch (BeansException ex) &#123; cleanupAfterBeanCreationFailure(beanName); throw ex; &#125; &#125; // Check if required type matches the type of the actual bean instance. if (requiredType != null &amp;&amp; !requiredType.isInstance(bean)) &#123; try &#123; T convertedBean = getTypeConverter().convertIfNecessary(bean, requiredType); if (convertedBean == null) &#123; throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass()); &#125; return convertedBean; &#125; catch (TypeMismatchException ex) &#123; throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass()); &#125; &#125; return (T) bean; &#125;&#125; 注意上面两次调用的getSingleton方法不是同一个方法，上面第一次调用的 getSingleton 方法： 1234567891011121314151617181920212223242526272829public class DefaultSingletonBeanRegistry extends SimpleAliasRegistry implements SingletonBeanRegistry &#123; public Object getSingleton(String beanName) &#123; // 系统一般是允许早期对象引用的allowEarlyReference通过这个参数可以控制解决循环依赖 return getSingleton(beanName, true); &#125; protected Object getSingleton(String beanName, boolean allowEarlyReference) &#123; // 先尝试去一级缓存单例缓存池中去获取对象，一般情况从该map中获取的对象是直接可使用的，IOC容器初始化加载单实例bean时第一次进来时该map中一般返回空 Object singletonObject = this.singletonObjects.get(beanName); // 若一级缓存中没有获取到对象,且singletonsCurrentlyInCreation这个list包含该beanName，IOC容器初始化加载单实例bean时第一次进来时，该list中一般返回空，但循环依赖时可以满足该条件 if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) &#123; synchronized (this.singletonObjects) &#123; // 尝试去二级缓存中获取对象，二级缓存中的对象是一个早期对象，就是bean刚刚调用了构造方法，还来不及给bean的属性进行赋值的对象，即纯净态就是早期对象 singletonObject = this.earlySingletonObjects.get(beanName); // 二级缓存中也没有获取到对象,allowEarlyReference为true(参数是有上一个方法传递进来的true) if (singletonObject == null &amp;&amp; allowEarlyReference) &#123; // 直接从三级缓存中获取ObjectFactory对象 这个对接就是用来解决循环依赖的关键所在，在ioc后期过程中,当bean调用了构造方法时,把早期对象包裹成一个ObjectFactory暴露到三级缓存中 ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName); if (singletonFactory != null) &#123;// 从三级缓存中获取到对象不为空 // 在这里通过暴露的ObjectFactory包装对象中,通过调用他的getObject()来获取早期对象在这个环节中会调用到getEarlyBeanReference()来进行后置处理 singletonObject = singletonFactory.getObject(); this.earlySingletonObjects.put(beanName, singletonObject); //把早期对象放置在二级缓存 this.singletonFactories.remove(beanName); // ObjectFactory包装对象从三级缓存中删除掉 &#125; &#125; &#125; &#125; return singletonObject; &#125;&#125; 上面第二次调用的 getSingleton 方法，该放法的第二个参数传入的是一个函数式接口，不会立刻执行，而是在下面调用 ObjectFactory 的 getObject 才会执行 createBean 。 beforeSingletonCreation 方法会将beanName加入到 singletonsCurrentlyInCreation 集合，即标记当前bean马上就要被创建了，当Bean创建完成会在 afterSingletonCreation 方法中将beanName从 singletonsCurrentlyInCreation 集合中移除。 12345678910111213141516171819202122232425262728293031323334353637383940public class DefaultSingletonBeanRegistry extends SimpleAliasRegistry implements SingletonBeanRegistry &#123; public Object getSingleton(String beanName, ObjectFactory&lt;?&gt; singletonFactory) &#123; Assert.notNull(beanName, &quot;Bean name must not be null&quot;); synchronized (this.singletonObjects) &#123; // 加锁 Object singletonObject = this.singletonObjects.get(beanName); // 尝试从单例缓存池中获取对象 if (singletonObject == null) &#123; if (this.singletonsCurrentlyInDestruction) &#123; throw new BeanCreationNotAllowedException(beanName, &quot;Singleton bean creation not allowed while singletons of this factory are in destruction &quot; + &quot;(Do not request a bean from a BeanFactory in a destroy method implementation!)&quot;); &#125; // 标记当前bean马上就要被创建了，singletonsCurrentlyInCreation在这里会把beanName加入进来，若第二次循环依赖，构造器注入会抛出异常 beforeSingletonCreation(beanName); boolean newSingleton = false; boolean recordSuppressedExceptions = (this.suppressedExceptions == null); if (recordSuppressedExceptions) &#123; this.suppressedExceptions = new LinkedHashSet&lt;&gt;(); &#125; try &#123; // 初始化bean，这个过程其实是调用上面写的createBean()方法 singletonObject = singletonFactory.getObject(); newSingleton = true; &#125; catch (IllegalStateException ex) &#123; //回调我们singletonObjects的get方法,进行正在的创建bean的逻辑 singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null) &#123; throw ex; &#125; &#125; catch (BeanCreationException ex) &#123; throw ex; &#125; finally &#123; // 后置处理，主要做是把singletonsCurrentlyInCreation标记正在创建的bean从集合中移除 afterSingletonCreation(beanName); &#125; if (newSingleton) &#123; addSingleton(beanName, singletonObject); // 加入缓存中 &#125; &#125; return singletonObject; &#125; &#125;&#125; resolveBeforeInstantiation(beanName, mbdToUse) 是第一次调用bean后置处理器的地方，主要通过调用 AbstractAutoProxyCreator 后置处理器来进行后置处理生成代理对象，一般在此处不会生成代理对象，因为真实的对象没有生成，故在这里不会生成代理对象，这一步是 AOP 和事务的关键，在这里解析AOP切面信息进行缓存。 doCreateBean才是真正创建bean实例对象。 12345678910111213141516171819202122232425262728293031323334public abstract class AbstractAutowireCapableBeanFactory extends AbstractBeanFactory implements AutowireCapableBeanFactory &#123; protected Object createBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException &#123; RootBeanDefinition mbdToUse = mbd; Class&lt;?&gt; resolvedClass = resolveBeanClass(mbd, beanName); // 确保此时的bean已经被解析了 if (resolvedClass != null &amp;&amp; !mbd.hasBeanClass() &amp;&amp; mbd.getBeanClassName() != null) &#123; mbdToUse = new RootBeanDefinition(mbd); mbdToUse.setBeanClass(resolvedClass); &#125; try &#123; // 验证和准备覆盖方法，仅在XML方式中，lookup-method和replace-method，这两个配置存放在BeanDefinition中的 methodOverrides(仅在XML方式中） // 在XML方式中bean实例化的过程中如果检测到存在methodOverrides，则会动态地为当前bean生成代理并使用对应的拦截器为bean做增强处理。 mbdToUse.prepareMethodOverrides(); &#125; catch (BeanDefinitionValidationException ex) &#123; throw new BeanDefinitionStoreException(mbdToUse.getResourceDescription(), beanName, &quot;Validation of method overrides failed&quot;, ex); &#125; try &#123; // 第1个bean后置处理器，通过bean的后置处理器来进行后置处理生成代理对象，一般在此处不会生成代理对象，因为真实的对象没有生成，故在这里不会生成代理对象，这一步是我们aop和事务的关键，因为在这里解析aop切面信息进行缓存 Object bean = resolveBeforeInstantiation(beanName, mbdToUse); if (bean != null) &#123; return bean; &#125; &#125; catch (Throwable ex) &#123; throw new BeanCreationException(mbdToUse.getResourceDescription(), beanName, &quot;BeanPostProcessor before instantiation of bean failed&quot;, ex); &#125; try &#123; // 该步骤是真正创建bean实例对象的地方 Object beanInstance = doCreateBean(beanName, mbdToUse, args); return beanInstance; &#125; catch (BeanCreationException | ImplicitlyAppearedSingletonException ex) &#123; throw ex; &#125; catch (Throwable ex) &#123; throw new BeanCreationException(mbdToUse.getResourceDescription(), beanName, &quot;Unexpected exception during bean creation&quot;, ex); &#125; &#125;&#125; 上面的 resolveBeforeInstantiation 中调用的是 applyBeanPostProcessorsBeforeInstantiation 方法，而该方法中是第一次调用Bean的后置处理器的地方，该方法会执行所有实现了 InstantiationAwareBeanPostProcessor 接口的后置处理器，对于Spring内部有好几个实现了该接口的后置处理器，但只有 AbstractAutoProxyCreator 复写了这里调用的 postProcessBeforeInstantiation 方法。在这里通过该Bean后置处理器主要做的是解析AOP切面信息进行缓存，从上面和下面的代码结合来看若自定义一个Bean后置处理器且实现InstantiationAwareBeanPostProcessor接口复写postProcessBeforeInstantiation方法返回一个对象，可直接停止Bean的后续创建直接返回当前自定义后置处理器中返回的对象。 若返回Bean不为空，则调用所有实现 InstantiationAwareBeanPostProcessor 接口的后置处理器的 postProcessAfterInitialization 方法，这里主要是对初始化完成后的Bean进行 AOP代理的创建，这也是Bean创建过程第八次调用Bean后置处理器的地方。正常情况上面的resolveBeforeInstantiation方法是不会调用applyBeanPostProcessorsAfterInitialization的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public abstract class AbstractAutowireCapableBeanFactory extends AbstractBeanFactory implements AutowireCapableBeanFactory &#123; protected Object resolveBeforeInstantiation(String beanName, RootBeanDefinition mbd) &#123; Object bean = null; if (!Boolean.FALSE.equals(mbd.beforeInstantiationResolved)) &#123; // 判断容器中是否有InstantiationAwareBeanPostProcessors if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123; Class&lt;?&gt; targetType = determineTargetType(beanName, mbd); // 获取当前bean的class对象 if (targetType != null) &#123; // 后置处理器的第一次调用，共有九处调用，事务在这里不会被调用，aop的才会被调用，因为在此处需要解析出对应的切面报错到缓存中 bean = applyBeanPostProcessorsBeforeInstantiation(targetType, beanName); // 若InstantiationAwareBeanPostProcessors后置处理器的postProcessBeforeInstantiation返回不为null，说明生成了代理对象 if (bean != null) &#123; // 后置处理器的第二处调用，该后置处理器若被调用的话，则第一处的处理器肯定返回的不是null，InstantiationAwareBeanPostProcessors后置处理器postProcessAfterInitialization bean = applyBeanPostProcessorsAfterInitialization(bean, beanName); &#125; &#125; &#125; mbd.beforeInstantiationResolved = (bean != null); &#125; return bean; &#125; protected Object applyBeanPostProcessorsBeforeInstantiation(Class&lt;?&gt; beanClass, String beanName) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; // 获取容器中的所有后置处理器 if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; // 判断后置处理器是不是InstantiationAwareBeanPostProcessor // 把BeanPostProcessor强制转为InstantiationAwareBeanPostProcessor InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; // AOP的@EnableAspectJAutoProxy为容器中导入了AnnotationAwareAspectJAutoProxyCreator，事务注解@EnableTransactionManagement为容器导入了InfrastructureAdvisorAutoProxyCreator // 都是实现了BeanPostProcessor接口，InstantiationAwareBeanPostProcessor进行后置处理解析切面 Object result = ibp.postProcessBeforeInstantiation(beanClass, beanName); if (result != null) &#123; return result; &#125; &#125; &#125; return null; &#125; public Object applyBeanPostProcessorsAfterInitialization(Object existingBean, String beanName) throws BeansException &#123; Object result = existingBean; for (BeanPostProcessor processor : getBeanPostProcessors()) &#123; // 获取容器中的所有的bean的后置处理器 // 在这里是后置处理器的第九次调用，aop和事务都会在这里生存代理对象 // AOP的@EnableAspectJAutoProxy为容器中导入了AnnotationAwareAspectJAutoProxyCreator，事务注解@EnableTransactionManagement为容器导入了InfrastructureAdvisorAutoProxyCreator // 都是实现了我们的BeanPostProcessor接口，InstantiationAwareBeanPostProcessor，在这里实现的是BeanPostProcessor接口的postProcessAfterInitialization来生成我们的代理对象 Object current = processor.postProcessAfterInitialization(result, beanName); if (current == null) &#123; // 若只要有一个返回null，则直接返回原始的 return result; &#125; result = current; &#125; return result; &#125;&#125; doCreateBean主要完成的内容是，通过createBeanInstance对Bean进行实例化，通过populateBean对属性进行赋值，通过initializeBean对Bean进行初始化操作。且这三大步中又调用了很多次的Bean的后置处理器，以及一些Aware接口的调用等。 实例化完成后，判断当前Bean是否单例、是否允许循环依赖、是否正在创建，若满足条件则缓存单例到第三级缓存singletonFactories 中，以防循环依赖。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374protected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final @Nullable Object[] args) throws BeanCreationException &#123; // BeanWrapper是对Bean的包装，其接口中所定义的功能很简单包括设置获取被包装的对象，获取被包装bean的属性描述器 BeanWrapper instanceWrapper = null; if (mbd.isSingleton()) &#123; // 从没有完成的FactoryBean中移除 instanceWrapper = this.factoryBeanInstanceCache.remove(beanName); &#125; if (instanceWrapper == null) &#123; // 创建bean实例化，使用合适的实例化策略来创建新的实例：工厂方法、构造函数自动注入、简单初始化，该方法很复杂也很重要 instanceWrapper = createBeanInstance(beanName, mbd, args); &#125; // 从beanWrapper中获取早期对象 final Object bean = instanceWrapper.getWrappedInstance(); Class&lt;?&gt; beanType = instanceWrapper.getWrappedClass(); if (beanType != NullBean.class) &#123; mbd.resolvedTargetType = beanType; &#125; // Allow post-processors to modify the merged bean definition. synchronized (mbd.postProcessingLock) &#123; if (!mbd.postProcessed) &#123; try &#123; //进行后置处理@AutoWired、@Value的注解的预解析 applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName); &#125; catch (Throwable ex) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, &quot;Post-processing of merged bean definition failed&quot;, ex); &#125; mbd.postProcessed = true; &#125; &#125; // 缓存单例到三级缓存中，以防循环依赖，判断是否为早期引用的Bean，若是则允许提前暴露引用 // 判断是否能够暴露早期对象的条件：是否单例、是否允许循环依赖、是否正在创建的Bean boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp; isSingletonCurrentlyInCreation(beanName)); if (earlySingletonExposure) &#123; // 上述条件满足，允许中期暴露对象 // 把早期对象包装成一个singletonFactory对象，该对象提供了一个getObject方法，该方法内部调用getEarlyBeanReference方法 addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean)); &#125; // Initialize the bean instance. Object exposedObject = bean; try &#123; populateBean(beanName, mbd, instanceWrapper); // 属性赋值，给属性进行赋值，调用set方法进行赋值 exposedObject = initializeBean(beanName, exposedObject, mbd); // 进行对象初始化操作，在这里可能生成代理对象 &#125; catch (Throwable ex) &#123; if (ex instanceof BeanCreationException &amp;&amp; beanName.equals(((BeanCreationException) ex).getBeanName())) &#123; throw (BeanCreationException) ex; &#125; else &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, &quot;Initialization of bean failed&quot;, ex); &#125; &#125; if (earlySingletonExposure) &#123; // 是早期对象暴露 // 去缓存中获取对象，由于传递的allowEarlyReference是false，要求只能在一级二级缓存中去获取，不存在循环依赖的bean创建过程中，压根不会把三级缓存提升到二级缓存中 Object earlySingletonReference = getSingleton(beanName, false); if (earlySingletonReference != null) &#123; // 能够获取到 if (exposedObject == bean) &#123; // 经过后置处理的bean和早期的bean引用还相等的话，表示当前的bean没有被代理过 exposedObject = earlySingletonReference; &#125; else if (!this.allowRawInjectionDespiteWrapping &amp;&amp; hasDependentBean(beanName)) &#123; // 处理依赖的bean String[] dependentBeans = getDependentBeans(beanName); Set&lt;String&gt; actualDependentBeans = new LinkedHashSet&lt;&gt;(dependentBeans.length); for (String dependentBean : dependentBeans) &#123; if (!removeSingletonIfCreatedForTypeCheckOnly(dependentBean)) &#123; actualDependentBeans.add(dependentBean); &#125; &#125; if (!actualDependentBeans.isEmpty()) &#123; throw new BeanCurrentlyInCreationException(beanName, &quot;Bean with name &#x27;&quot; + beanName + &quot;&#x27; has been injected into other beans [&quot; + StringUtils.collectionToCommaDelimitedString(actualDependentBeans) + &quot;] in its raw version as part of a circular reference, but has eventually been &quot; + &quot;wrapped. This means that said other beans do not use the final version of the &quot; + &quot;bean. This is often the result of over-eager type matching - consider using &quot; + &quot;&#x27;getBeanNamesOfType&#x27; with the &#x27;allowEagerInit&#x27; flag turned off, for example.&quot;); &#125; &#125; &#125; &#125; try &#123; //注册销毁的bean的销毁接口 registerDisposableBeanIfNecessary(beanName, bean, mbd); &#125; catch (BeanDefinitionValidationException ex) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, &quot;Invalid destruction signature&quot;, ex); &#125; return exposedObject;&#125; 若使用 @Bean方式配置的Bean实例化时直接通过 instantiateUsingFactoryMethod 工程方法进行实例化，方法名称就是就是工厂方法的名称。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546protected BeanWrapper createBeanInstance(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) &#123; Class&lt;?&gt; beanClass = resolveBeanClass(mbd, beanName); // 从bean定义中解析出当前bean的class对象 // 检测类的访问权限。默认情况下非public的类是允许访问的。Bean定义默认情况nonPublicAccessAllowed为true，即使不是public的也ok // beanClass不为null且访问修饰符如果不是public且Bean定义的nonPublicAccessAllowed为false，若满足则抛出异常 if (beanClass != null &amp;&amp; !Modifier.isPublic(beanClass.getModifiers()) &amp;&amp; !mbd.isNonPublicAccessAllowed()) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, &quot;Bean class isn&#x27;t public, and non-public access not allowed: &quot; + beanClass.getName()); &#125; // 该方法是spring5.0 新增加的 如果存在 Supplier 回调，则使用给定的回调方法初始化策略 Supplier&lt;?&gt; instanceSupplier = mbd.getInstanceSupplier(); if (instanceSupplier != null) &#123; return obtainFromSupplier(instanceSupplier, beanName); &#125; // @Bean会在这创建实例，工厂方法，通过配置类来进行配置的话，采用的就是工厂方法，方法名称就是就是工厂方法的名称 if (mbd.getFactoryMethodName() != null) &#123; return instantiateUsingFactoryMethod(beanName, mbd, args); &#125; // 当多次构建同一个bean时，可使用此处的快捷路径，即无需再次推断应该使用哪种方式构造实例，以提高效率。 // 在多次构建同一个prototype类型的bean时，就可以走此处的捷径，这里的resolved和mbd.constructorArgumentsResolved将会在bean第一次实例化的过程中被设置。 //判断当前构造函数是否被解析过 boolean resolved = false; //有没有必须进行依赖注入 boolean autowireNecessary = false; // 通过getBean传入进来的构造函数是否来指定需要推断构造函数，若传递进来的args不为空，则可直接选出对应的构造函数 if (args == null) &#123; synchronized (mbd.constructorArgumentLock) &#123; // 判断bean定义信息中的resolvedConstructorOrFactoryMethod用来缓存已解析的构造函数或者工厂方法 if (mbd.resolvedConstructorOrFactoryMethod != null) &#123; resolved = true; // 修改已经解析过的构造函数的标志 autowireNecessary = mbd.constructorArgumentsResolved; // 修改标记为true标识构造函数或者工厂方法已解析过 &#125; &#125; &#125; if (resolved) &#123; // 若被解析过 if (autowireNecessary) &#123; // 通过有参的构造函数进行反射调用 return autowireConstructor(beanName, mbd, null, null); &#125; else &#123; //调用无参数的构造函数进行创建对象 return instantiateBean(beanName, mbd); &#125; &#125; // 通过bean的后置处理器进行选举出合适的构造函数对象 Constructor&lt;?&gt;[] ctors = determineConstructorsFromBeanPostProcessors(beanClass, beanName); // 自定义了BeanPostProcessor返回了构造器或使用构造器自动装配模式或设置了BeanDefinition构造器参数或有参数:即getBean(String name,Object... args) if (ctors != null || mbd.getResolvedAutowireMode() == AUTOWIRE_CONSTRUCTOR || mbd.hasConstructorArgumentValues() || !ObjectUtils.isEmpty(args)) &#123; return autowireConstructor(beanName, mbd, ctors, args); // 使用自定义的构造器初始化 &#125; return instantiateBean(beanName, mbd); // 使用无参数的构造函数调用创建对象&#125; 第二次Bean后置处理器的调用，其作用就是指定实例化的构造函数，主要调用的是 AutowiredAnnotationBeanPostProcessor 后置处理器 determineCandidateConstructors 方法。 1234567891011121314151617public abstract class AbstractAutowireCapableBeanFactory extends AbstractBeanFactory implements AutowireCapableBeanFactory &#123; protected Constructor&lt;?&gt;[] determineConstructorsFromBeanPostProcessors(@Nullable Class&lt;?&gt; beanClass, String beanName) throws BeansException &#123; if (beanClass != null &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; // 获取到容器中所有的后置处理器BeanPostProcessors if (bp instanceof SmartInstantiationAwareBeanPostProcessor) &#123; // 判断后置处理器是否为SmartInstantiationAwareBeanPostProcessor SmartInstantiationAwareBeanPostProcessor ibp = (SmartInstantiationAwareBeanPostProcessor) bp; // 调用后置处理器的determineCandidateConstructors来决定构造方法 Constructor&lt;?&gt;[] ctors = ibp.determineCandidateConstructors(beanClass, beanName); if (ctors != null) &#123; return ctors; &#125; &#125; &#125; &#125; return null; &#125;&#125; Bean实例化完成后，调用applyMergedBeanDefinitionPostProcessors从而第三次调用Bean的后置处理器，完成 @Autowired、@Value、@PostConstruct等注解以及自定义的初始化方法等预解析 。调用 AutowiredAnnotationBeanPostProcessor 将 @Autowired 、 @Value 注入信息预解析存入 externallyManagedConfigMembers 中，调用 CommonAnnotationBeanPostProcessor 从而调用 InitDestroyAnnotationBeanPostProcessor 将自定义的初始化方法信息即 @Bean(initMethod = &quot;initMethod&quot;) 中指定的初始化方法预解析存入 externallyManagedInitMethods 中。 12345678910public abstract class AbstractAutowireCapableBeanFactory extends AbstractBeanFactory implements AutowireCapableBeanFactory &#123; protected void applyMergedBeanDefinitionPostProcessors(RootBeanDefinition mbd, Class&lt;?&gt; beanType, String beanName) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof MergedBeanDefinitionPostProcessor) &#123; MergedBeanDefinitionPostProcessor bdp = (MergedBeanDefinitionPostProcessor) bp; bdp.postProcessMergedBeanDefinition(mbd, beanType, beanName); &#125; &#125; &#125;&#125; getEarlyBeanReference中是第四次调用Bean的后置处理器，调用实现了 SmartInstantiationAwareBeanPostProcessor 接口的 getEarlyBeanReference 方法的后置处理器，这里是调用 AbstractAutoProxyCreator 后置处理器，主要作用是给有AOP代理的且产生循环依赖的对象创建AOP代理，若该Bean有AOP代理，但不存在循环依赖，则AOP代理是在第八次调用后置处理器时，给该Bean创建动态代理的。若已经设置了动态代理会将beanName加入到 earlyProxyReferences 集合中，防止重复添加动态代理。 123456789101112131415public abstract class AbstractAutowireCapableBeanFactory extends AbstractBeanFactory implements AutowireCapableBeanFactory &#123; protected Object getEarlyBeanReference(String beanName, RootBeanDefinition mbd, Object bean) &#123; Object exposedObject = bean; // 判读容器中是否有InstantiationAwareBeanPostProcessors类型的后置处理器 if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; // 获取所有的后置处理器 if (bp instanceof SmartInstantiationAwareBeanPostProcessor) &#123; // 判断后置处理器是否实现了SmartInstantiationAwareBeanPostProcessor接口 SmartInstantiationAwareBeanPostProcessor ibp = (SmartInstantiationAwareBeanPostProcessor) bp; // 进行强制转换 exposedObject = ibp.getEarlyBeanReference(exposedObject, beanName); // 挨个调用SmartInstantiationAwareBeanPostProcessor的getEarlyBeanReference &#125; &#125; &#125; return exposedObject; &#125;&#125; 属性进行赋值前第五次调用后置处理器，Spring自身没有做相应的事情，调用实现了 InstantiationAwareBeanPostProcessor 接口 postProcessAfterInstantiation 的后置处理器，其作用是让用户可以自定义属性，其还可以设置跳过后续的赋值操作。 紧接着调用第六次后置处理器，调用实现了 InstantiationAwareBeanPostProcessor 接口 postProcessProperties 的后置处理器，主要是注入PropertyValues 对属性进行赋值操作，@Autowired、@Value注解是通过 AutowiredAnnotationBeanPostProcessor 中postProcessProperties方法调用 InjectionMetadata.inject 方法，若发现@Autowired注入的Bean未被创建，最终会调用 DependencyDescriptor 的 resolveCandidate 方法，通过getBean 去创建该Bean。若存在循环依赖，给依赖的Bean进行属性赋值时会再次通过getBean调用当前Bean，从而通过getSingleton方法中对三级缓存中函数式接口的调用，即调用 getEarlyBeanReference 方法将三级缓存转换为二级缓存，返回给依赖的Bean进行赋值操作。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980protected void populateBean(String beanName, RootBeanDefinition mbd, @Nullable BeanWrapper bw) &#123; if (bw == null) &#123; // 若bw为null的话，说明对象没有实例化 if (mbd.hasPropertyValues()) &#123; // 进入if说明对象有属性，bw为空，不能为他设置属性，那就在下面就执行抛出异常 throw new BeanCreationException(mbd.getResourceDescription(), beanName, &quot;Cannot apply property values to null instance&quot;); &#125; else &#123; return; // Skip property population phase for null instance. &#125; &#125; /** * 在属性被填充前，给InstantiationAwareBeanPostProcessor类型的后置处理器一个修改bean状态的机会。官方的解释是：让用户可以自定义属性注入。 * 若用户实现一个InstantiationAwareBeanPostProcessor类型的后置处理器，并通过postProcessAfterInstantiation方法向bean的成员变量注入自定义的信息。 * 当时发现系统中的InstantiationAwareBeanPostProcessor.postProcessAfterInstantiation没有进行任何处理，若自己实现了该接口，可以自定义处理，直接使用配置中的信息注入即可。 */ boolean continueWithPropertyPopulation = true; if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123; // 是否持有InstantiationAwareBeanPostProcessor for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; // 获取容器中的所有的BeanPostProcessor if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; // 判断后置处理器是不是InstantiationAwareBeanPostProcessor InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; // 进行强制转化 // 若存在后置处理器给属性赋值了，则返回false可来修改开关变量，就不会走下面的逻辑了 if (!ibp.postProcessAfterInstantiation(bw.getWrappedInstance(), beanName)) &#123; // 返回值为是否继续填充bean // postProcessAfterInstantiation：若应该在bean上面设置属性则返回true，否则返回false，一般情况下返回true // 返回false，将会阻止在此Bean实例上调用任何后续的InstantiationAwareBeanPostProcessor continueWithPropertyPopulation = false; break; &#125; &#125; &#125; &#125; if (!continueWithPropertyPopulation) &#123; // 若后续处理器发出停止填充命令，则终止后续操作 return; &#125; PropertyValues pvs = (mbd.hasPropertyValues() ? mbd.getPropertyValues() : null); // 获取bean定义的属性 // 判断的bean的属性注入模型AUTOWIRE_BY_NAME根据名称注入，AUTOWIRE_BY_TYPE 根据类型注入 if (mbd.getResolvedAutowireMode() == AUTOWIRE_BY_NAME || mbd.getResolvedAutowireMode() == AUTOWIRE_BY_TYPE) &#123; MutablePropertyValues newPvs = new MutablePropertyValues(pvs); // 把PropertyValues封装成为MutablePropertyValues if (mbd.getResolvedAutowireMode() == AUTOWIRE_BY_NAME) &#123; // 根据bean的属性名称注入 autowireByName(beanName, mbd, bw, newPvs); &#125; if (mbd.getResolvedAutowireMode() == AUTOWIRE_BY_TYPE) &#123; // 根据bean的类型进行注入 autowireByType(beanName, mbd, bw, newPvs); &#125; pvs = newPvs; // 把处理过的属性覆盖原来的 &#125; // 用于在Spring填充属性到bean对象前，对属性的值进行相应的处理，可修改某些属性的值。这时注入到bean中的值就不是配置文件中的内容了，而是经过后置处理器修改后的内容 boolean hasInstAwareBpps = hasInstantiationAwareBeanPostProcessors(); // 判断是否需要检查依赖 boolean needsDepCheck = (mbd.getDependencyCheck() != AbstractBeanDefinition.DEPENDENCY_CHECK_NONE); if (hasInstAwareBpps || needsDepCheck) &#123; if (pvs == null) &#123; pvs = mbd.getPropertyValues(); &#125; // 提出当前正在创建的beanWrapper依赖的对象 PropertyDescriptor[] filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching); if (hasInstAwareBpps) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; // 获取所有的后置处理器 if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; PropertyValues pvsToUse = ibp.postProcessProperties(pvs, bw.getWrappedInstance(), beanName); if (pvsToUse == null) &#123; if (filteredPds == null) &#123; filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching); &#125; pvsToUse = ibp.postProcessPropertyValues(pvs, filteredPds, bw.getWrappedInstance(), beanName); if (pvsToUse == null) &#123; return; &#125; &#125; pvs = pvsToUse; &#125; &#125; &#125; if (needsDepCheck) &#123; // 判断是否检查依赖 checkDependencies(beanName, mbd, filteredPds, pvs); &#125; &#125; // 上面只是完成了所有注入属性的获取，将获取的属性封装在PropertyValues的实例对象pvs中，并没有应用到已经实例化的bean中，applyPropertyValues则是完成这一步骤的 if (pvs != null) &#123; applyPropertyValues(beanName, mbd, bw, pvs); &#125;&#125; 这里对Bean进行初始化，首先会调用 invokeAwareMethods 方法从而调用Bean的 BeanNameAware 、 BeanClassLoaderAware 、 BeanFactoryAware 三个Aware接口。 1234567891011121314151617181920212223protected Object initializeBean(final String beanName, final Object bean, @Nullable RootBeanDefinition mbd) &#123; if (System.getSecurityManager() != null) &#123; AccessController.doPrivileged((PrivilegedAction&lt;Object&gt;) () -&gt; &#123; invokeAwareMethods(beanName, bean); return null; &#125;, getAccessControlContext()); &#125; else &#123; invokeAwareMethods(beanName, bean); // 若bean实现了XXXAware接口进行方法的回调 &#125; Object wrappedBean = bean; if (mbd == null || !mbd.isSynthetic()) &#123; // 调用bean的后置处理器的postProcessorsBeforeInitialization方法，@PostCust注解的方法 wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); &#125; try &#123; invokeInitMethods(beanName, wrappedBean, mbd); // 调用初始化方法 &#125; catch (Throwable ex) &#123; throw new BeanCreationException((mbd != null ? mbd.getResourceDescription() : null), beanName, &quot;Invocation of init method failed&quot;, ex); &#125; if (mbd == null || !mbd.isSynthetic()) &#123; // 调用bean的后置处理器的PostProcessorsAfterInitialization方法 wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); &#125; return wrappedBean;&#125; 第七次Bean的后置处理器调用，通过 InitDestroyAnnotationBeanPostProcessor 接口中调用 LifecycleMetadata.invokeInitMethods 方法来实现初始化前 @PostConstruct注解的方法的调用 ，以及调用 ApplicationContextAwareProcessor 后置处理器的 postProcessBeforeInitialization 方法，完成 EnvironmentAware 、 EmbeddedValueResolverAware 、 ResourceLoaderAware 、 ApplicationEventPublisherAware 、 MessageSourceAware 、 ApplicationContextAware 、 ImportAware 等Aware接口的调用。 1234567891011public Object applyBeanPostProcessorsBeforeInitialization(Object existingBean, String beanName) throws BeansException &#123; Object result = existingBean; for (BeanPostProcessor processor : getBeanPostProcessors()) &#123; // 获取容器中的所有的bean的后置处理器 Object current = processor.postProcessBeforeInitialization(result, beanName); // 挨个调用bean的后置处理器的postProcessBeforeInitialization if (current == null) &#123; // 若只有有一个返回null 那么直接返回原始的 return result; &#125; result = current; &#125; return result;&#125; invokeInitMethods方法中若实现了InitializingBean接口，则调用InitializingBean接口的afterPropertiesSet方法，以及自定义的初始化方法的调用即 @Bean(initMethod = &quot;initMethod&quot;) 中指定的初始化方法。 123456789101112131415161718192021222324252627protected void invokeInitMethods(String beanName, final Object bean, @Nullable RootBeanDefinition mbd) throws Throwable &#123; boolean isInitializingBean = (bean instanceof InitializingBean); // 判断容器中是否实现了InitializingBean接口 if (isInitializingBean &amp;&amp; (mbd == null || !mbd.isExternallyManagedInitMethod(&quot;afterPropertiesSet&quot;))) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Invoking afterPropertiesSet() on bean with name &#x27;&quot; + beanName + &quot;&#x27;&quot;); &#125; if (System.getSecurityManager() != null) &#123; try &#123; AccessController.doPrivileged((PrivilegedExceptionAction&lt;Object&gt;) () -&gt; &#123; ((InitializingBean) bean).afterPropertiesSet(); return null; &#125;, getAccessControlContext()); &#125; catch (PrivilegedActionException pae) &#123; throw pae.getException(); &#125; &#125; else &#123; // 回调InitializingBean的afterPropertiesSet()方法 ((InitializingBean) bean).afterPropertiesSet(); &#125; &#125; if (mbd != null &amp;&amp; bean.getClass() != NullBean.class) &#123; // 调用initMethod String initMethodName = mbd.getInitMethodName(); // beanclass中是否有自定义的init方法 // 判断自定义的init方法名称不叫afterPropertiesSet if (StringUtils.hasLength(initMethodName) &amp;&amp; !(isInitializingBean &amp;&amp; &quot;afterPropertiesSet&quot;.equals(initMethodName)) &amp;&amp; !mbd.isExternallyManagedInitMethod(initMethodName)) &#123; invokeCustomInitMethod(beanName, bean, mbd); // 调用自定义的初始化方法 &#125; &#125;&#125; 在applyBeanPostProcessorsAfterInitialization方法中完成了第八次后置处理器的调用，主要是对初始化完成后的Bean进行 AOP代理的创建以及 ApplicationListener 的添加。最终Bean销毁的时候会调用第九次Bean的后置处理器，即调用 InitDestroyAnnotationBeanPostProcessor 后置处理器的 postProcessBeforeDestruction 方法。","tags":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}]},{"title":"Bean的生命周期","date":"2020-10-17T07:08:20.000Z","path":"blog/Spring/Bean的生命周期/","text":"生命周期首先Bean是通过 ConfigurationClassPostProcessor解析配置类的后置处理器，将Bean从类中注册到BeanFactory中，然后通过getBean方法加载Bean。 首先调用 getSingleton 方法从三级缓存中获取，若获取不到，再通过函数式接口调用 createBean 创建Bean的流程。通过 resolveBeforeInstantiation 方法去第一次调用Bean的后置处理器，这里调用的是实现了 InstantiationAwareBeanPostProcessor 接口 postProcessBeforeInstantiation 方法的后置处理器，这里主要调用 AbstractAutoProxyCreator 对AOP切面类进行解析，并将解析后的数据缓存，即通过 @EnableAspectJAutoProxy 开启了AOP代理，且该类为 Advice 、 Pointcut 、 Advisor 、 AopInfrastructureBean 等接口的子类，或该类上有 @Aspect注解且不是一个被 AspectJ编译过的类；在这里还可以自定义一个后置处理器返回一个对象来阻断后续流程的执行。 接着调用 doCreateBean 真正去创建Bean，首先回去创建Bean的简单实例，在创建实例的过程中可能会第二次调用Bean的后置处理器，这里调用的是实现了 SmartInstantiationAwareBeanPostProcessor 接口 determineCandidateConstructors 方法的后置处理器，这里主要调用 AutowiredAnnotationBeanPostProcessor 来指定实例化的的构造函数，通过 @Bean注入的对象会跳过该后置处理器。 简单实例化完成后，调用 applyMergedBeanDefinitionPostProcessors 从而第三次调用Bean的后置处理器，完成 @Autowired、@Value、@PostConstruct等注解以及自定义的初始化方法等预解析。调用 AutowiredAnnotationBeanPostProcessor 将 @Autowired 、 @Value 注入信息预解析存入 externallyManagedConfigMembers 中，调用 CommonAnnotationBeanPostProcessor 从而调用 InitDestroyAnnotationBeanPostProcessor 将自定义的初始化方法信息即 @Bean(initMethod = &quot;initMethod&quot;) 中指定的初始化方法预解析存入 externallyManagedInitMethods 中。 然后将早期对象通过函数式接口getEarlyBeanReference 存入第三级缓存singletonFactories 中，这里主要是为了解决循环依赖，若不存在循环依赖，该函数接口不会被调用，故三级缓存不会被升级为二级缓存。在该函数式接口中第四次调用了Bean的后置处理器，调用实现了 SmartInstantiationAwareBeanPostProcessor 接口的 getEarlyBeanReference 方法的后置处理器，这里是调用 AbstractAutoProxyCreator 后置处理器，主要作用是给有AOP代理的且产生循环依赖且先被加载的对象创建AOP代理，若该Bean有AOP代理，但不存在循环依赖或存在循环依赖但后被加载，则AOP代理是在第八次调用后置处理器时，给该Bean创建动态代理的。若在该处已经设置了动态代理会将 beanName 加入到 earlyProxyReferences 集合中，防止第八次调用后置处理器时重复添加动态代理。 紧接着调用 populateBean 方法为Bean的属性进行赋值，在属性设置前第五次调用实现了 InstantiationAwareBeanPostProcessor 接口 postProcessAfterInstantiation 的后置处理器，其作用是让用户可以自定义属性，其还可以设置跳过后续的赋值操作。 紧接着调用第六次后置处理器，调用实现了 InstantiationAwareBeanPostProcessor 接口 postProcessProperties 的后置处理器，主要是注入PropertyValues对属性进行赋值操作，@Autowired、@Value注解是通过 AutowiredAnnotationBeanPostProcessor 中 postProcessProperties 方法调用 InjectionMetadata.inject 方法，若发现 @Autowired注入的Bean未被创建 ，最终会调用 DependencyDescriptor 的 resolveCandidate 方法，通过getBean 去创建该Bean。若存在循环依赖，给依赖的Bean进行属性赋值时会再次通过getBean调用当前Bean，从而通过 getSingleton 方法中对三级缓存中函数式接口的调用，即调用 getEarlyBeanReference 方法将三级缓存转换为二级缓存，返回给依赖的Bean进行赋值操作。 完成了属性的赋值，接下来就是通过 initializeBean 对Bean的初始化方法的调用，初始化调用前首先通过 invokeAwareMethods 方法对 BeanNameAware 、 BeanClassLoaderAware 、 BeanFactoryAware 三个Aware接口的调用。 第七次Bean的后置处理器调用，通过 InitDestroyAnnotationBeanPostProcessor 接口中调用 LifecycleMetadata.invokeInitMethods 方法来实现初始化前 @PostConstruct注解的方法的调用 ，以及调用 ApplicationContextAwareProcessor 后置处理器的 postProcessBeforeInitialization 方法，完成 EnvironmentAware 、 EmbeddedValueResolverAware 、 ResourceLoaderAware 、 ApplicationEventPublisherAware 、 MessageSourceAware 、 ApplicationContextAware 、 ImportAware 等Aware接口的调用。 接着调用 invokeInitMethods 方法，若Bean实现了 InitializingBean 接口，则调用InitializingBean接口的afterPropertiesSet方法，以及自定义的初始化方法的调用即 @Bean(initMethod = &quot;initMethod&quot;) 中指定的初始化方法。 在 applyBeanPostProcessorsAfterInitialization 方法中完成了第八次后置处理器的调用，通过调用实现了 BeanPostProcessor 接口 postProcessAfterInitialization 方法的后置处理器，调用 AbstractAutoProxyCreator 、 AbstractAdvisingBeanPostProcessor 、 AdvisorAdapterRegistrationManager 等后置处理器的调用来对初始化完成后的Bean进行 AOP代理的创建，调用 ApplicationListenerDetector 调用来对 ApplicationListener 的添加。 最终Bean销毁时会调用第九次Bean的后置处理器，即调用 InitDestroyAnnotationBeanPostProcessor 后置处理器的 postProcessBeforeDestruction 方法。 循环依赖所谓的循环依赖是指，A依赖B，B又依赖A，它们之间形成了循环依赖。或者A依赖B，B依赖C，C又依赖A： Spring中Bean创建过程中，需要对Bean的属性进行赋值，当发现其属性B是一个Bean时，会先通过 getBean(B) 去获取依赖的Bean，若B未被穿件会先创建，最终将生成好的依赖的Bean赋值给当前属性。若在通过getBean(B)创建依赖Bean时，给依赖的Bean的属性A赋值时，发现其属性是前一个Bean，这是又通过getBean(A)去获取Bean，但这时A并没有创建完成，这时就会产生死循环。Spring中是通过三级缓存来解决单例Bean的循环依赖问题的。 1234567891011121314public class DefaultSingletonBeanRegistry extends SimpleAliasRegistry implements SingletonBeanRegistry &#123; // 一级缓存，也是单例缓存池 用于保存所有的单实例bean private final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;&gt;(256); // 二级缓存，缓存的key为beanName，value为早期对象，即还没进行属性赋值的对象 private final Map&lt;String, Object&gt; earlySingletonObjects = new HashMap&lt;&gt;(16); // 三级缓存，缓存key为beanName，value为函数式接口ObjectFactory private final Map&lt;String, ObjectFactory&lt;?&gt;&gt; singletonFactories = new HashMap&lt;&gt;(16); // 已注册的单例名称set private final Set&lt;String&gt; registeredSingletons = new LinkedHashSet&lt;&gt;(256); // 该集合用户缓存当前正在创建bean的名称 private final Set&lt;String&gt; singletonsCurrentlyInCreation = Collections.newSetFromMap(new ConcurrentHashMap&lt;&gt;(16)); // 排除当前创建检查的 private final Set&lt;String&gt; inCreationCheckExclusions = Collections.newSetFromMap(new ConcurrentHashMap&lt;&gt;(16));&#125; 一级缓存singletonObjects 保存所有生成完全的单实例Bean，二级缓存earlySingletonObjects 保存还没进行属性赋值的Bean的早期对象，三级缓存singletonFactories 中保存是封装了早期对象的函数式接口。 1addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean)); 123456789101112protected Object getEarlyBeanReference(String beanName, RootBeanDefinition mbd, Object bean) &#123; Object exposedObject = bean; if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof SmartInstantiationAwareBeanPostProcessor) &#123; SmartInstantiationAwareBeanPostProcessor ibp = (SmartInstantiationAwareBeanPostProcessor) bp; exposedObject = ibp.getEarlyBeanReference(exposedObject, beanName); &#125; &#125; &#125; return exposedObject;&#125; 当Bean实例化完成即早期对象生成完成后，会将早期对象通过函数式接口getEarlyBeanReference 存入第三级缓存singletonFactories 中，主要就是为了解决循环依赖，若不存在循环依赖，该函数接口不会被调用，故三级缓存不会被升级为二级缓存。若存在循环引用就会在getBean(A)时调用 getSingleton 方法，从而将三级缓存中的函数式接口 getEarlyBeanReference 执行，给有AOP代理的且产生循环依赖的对象创建AOP代理，并将代理后的对象放入二级缓存中。 1234567891011121314151617protected Object getSingleton(String beanName, boolean allowEarlyReference) &#123; Object singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) &#123; synchronized (this.singletonObjects) &#123; singletonObject = this.earlySingletonObjects.get(beanName); if (singletonObject == null &amp;&amp; allowEarlyReference) &#123; ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName); if (singletonFactory != null) &#123; singletonObject = singletonFactory.getObject(); this.earlySingletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); &#125; &#125; &#125; &#125; return singletonObject;&#125; B的属性赋值中就能通过getBean(A)拿到A了，然后B就能完成赋值从而完成Bean的生成，最终A的属性赋值getBean(B)就能获取到B从而A完成属性赋值。 从源码来看其实二级缓存完全可以解决循环依赖的问题，若不使用第三级缓存，那 getEarlyBeanReference 方法要么在Bean实例化后就立即调用，要么将 getEarlyBeanReference 放入 getSingleton 中调用，前者会导致不论是否有循环依赖的Bean创建都会被调用，从而导致大量重复的调用，后者导致 getSingleton 方法职责不单一，故用到第三级缓存可能主要是为了解耦、方法职责单一、提高阅读性便于维护。 对于循环依赖中先被加载的类A才会用到二级缓存 earlySingletonObjects ，后被加载的类B其实跟普通Bean加载过程一样，不会调用三级缓存中的函数式接口 getEarlyBeanReference 。若A存在AOP代理，则B中赋值的A是经过AOP代理过后的对象，但给A属性赋值的时候依旧是赋值给未被代理的A，但是A和代理对象的中的A是同一个，故代理对象中的A属性被赋值了。若不存在AOP代理，这里的bean、earlySingletonReference、exposedObject其实是同一个对象，若存在AOP代理earlySingletonReference与bean、exposedObject不是同一个对象。 12345678if (earlySingletonExposure) &#123; Object earlySingletonReference = getSingleton(beanName, false); // 若存在AOP代理，则返回被代理后的对象 if (earlySingletonReference != null) &#123; if (exposedObject == bean) &#123; exposedObject = earlySingletonReference; // 将代理后的对象返回 &#125; &#125;&#125; 只有单实例Bean才会放入三级缓存，对于原型模式创建的对象不会放入三级缓存中，而Spring又是通过三级缓存来解决循环依赖的，故原型Bean的循环依赖无法利用缓存，则无法解决循环依赖的问题。 对于构造方法注入的Bean的循环依赖问题，源码中可以很明看到Bean是先通过构造方法实例化后，才会将其放入三级缓存中，故构造方法注入Bean无法利用三级缓存，故也无法解决循环依赖问题。","tags":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}]},{"title":"BeanDefinition解析注册","date":"2020-10-17T04:08:20.000Z","path":"blog/Spring/BeanDefinition解析注册/","text":"自定义的Bean解析与注册是通过 refresh() 中 invokeBeanFactoryPostProcessors() 方法最终调用 PostProcessorRegistrationDelegate 的 invokeBeanFactoryPostProcessors 方法，通过 invokeBeanDefinitionRegistryPostProcessors 调用 ConfigurationClassPostProcessor 的 postProcessBeanDefinitionRegistry 方法，对项目的包扫描，然后将所有的Bean解析成BeanDefinition然后注册到IoC容器中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104private static void invokeBeanDefinitionRegistryPostProcessors(Collection&lt;? extends BeanDefinitionRegistryPostProcessor&gt; postProcessors, BeanDefinitionRegistry registry) &#123; // 获取容器中ConfigurationClassPostProcessor后置处理器进行bean定义的扫描 for (BeanDefinitionRegistryPostProcessor postProcessor : postProcessors) &#123; postProcessor.postProcessBeanDefinitionRegistry(registry); &#125;&#125;public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) &#123; int registryId = System.identityHashCode(registry); if (this.registriesPostProcessed.contains(registryId)) &#123; throw new IllegalStateException(&quot;postProcessBeanDefinitionRegistry already called on this post-processor against &quot; + registry); &#125; if (this.factoriesPostProcessed.contains(registryId)) &#123; throw new IllegalStateException(&quot;postProcessBeanFactory already called on this post-processor against &quot; + registry); &#125; this.registriesPostProcessed.add(registryId); processConfigBeanDefinitions(registry); // 真正的解析BeanDefinition&#125;public void processConfigBeanDefinitions(BeanDefinitionRegistry registry) &#123; List&lt;BeanDefinitionHolder&gt; configCandidates = new ArrayList&lt;&gt;(); // 获取IOC容器中目前所有BeanDefinition名称，仅包括之前内置的Bean和传入的配置类 String[] candidateNames = registry.getBeanDefinitionNames(); for (String beanName : candidateNames) &#123; // 循环我们的上一步获取的所有BeanDefinition信息 BeanDefinition beanDef = registry.getBeanDefinition(beanName); // 通过bean的名称来获取我们的bean定义对象 // 判断是否有没有解析过 if (ConfigurationClassUtils.isFullConfigurationClass(beanDef) || ConfigurationClassUtils.isLiteConfigurationClass(beanDef)) &#123; &#125; else if (ConfigurationClassUtils.checkConfigurationClassCandidate(beanDef, this.metadataReaderFactory)) &#123; // 进行正在的解析判断是不是完全的配置类，还是一个非正式的配置类，这里是有我们传入的配置类MainConfig进入到改else中 configCandidates.add(new BeanDefinitionHolder(beanDef, beanName)); // 加入到候选的配置类集合中 &#125; &#125; if (configCandidates.isEmpty()) &#123; // 若没有找到配置类 直接返回 return; &#125; configCandidates.sort((bd1, bd2) -&gt; &#123; // 对配置类进行Order排序 int i1 = ConfigurationClassUtils.getOrder(bd1.getBeanDefinition()); int i2 = ConfigurationClassUtils.getOrder(bd2.getBeanDefinition()); return Integer.compare(i1, i2); &#125;); // 创建通过@CompentScan导入进来的bean name的生成器，创建通过@Import导入进来的bean的名称 SingletonBeanRegistry sbr = null; if (registry instanceof SingletonBeanRegistry) &#123; sbr = (SingletonBeanRegistry) registry; if (!this.localBeanNameGeneratorSet) &#123; BeanNameGenerator generator = (BeanNameGenerator) sbr.getSingleton(CONFIGURATION_BEAN_NAME_GENERATOR); if (generator != null) &#123; // 设置@CompentScan导入进来的bean的名称生成器(默认类首字母小写）也可自己定义，一般不会 this.componentScanBeanNameGenerator = generator; // 设置@Import导入进来的bean的名称生成器(默认类首字母小写）也可自己定义，一般不会 this.importBeanNameGenerator = generator; &#125; &#125; &#125; if (this.environment == null) &#123; this.environment = new StandardEnvironment(); &#125; //创建一个配置类解析器对象 ConfigurationClassParser parser = new ConfigurationClassParser(this.metadataReaderFactory, this.problemReporter, this.environment, this.resourceLoader, this.componentScanBeanNameGenerator, registry); // 用于保存配置类BeanDefinitionHolder放入上面筛选出来的配置类 Set&lt;BeanDefinitionHolder&gt; candidates = new LinkedHashSet&lt;&gt;(configCandidates); // 用于保存已解析的配置类，长度默认为解析出来默认的配置类的集合长度 Set&lt;ConfigurationClass&gt; alreadyParsed = new HashSet&lt;&gt;(configCandidates.size()); do &#123; //do while 会进行第一次解析 parser.parse(candidates); //真正的解析我们的配置类 parser.validate(); // 解析出来的配置类 Set&lt;ConfigurationClass&gt; configClasses = new LinkedHashSet&lt;&gt;(parser.getConfigurationClasses()); configClasses.removeAll(alreadyParsed); // Read the model and create bean definitions based on its content if (this.reader == null) &#123; this.reader = new ConfigurationClassBeanDefinitionReader(registry, this.sourceExtractor, this.resourceLoader, this.environment, this.importBeanNameGenerator, parser.getImportRegistry()); &#125; // 此处才把@Bean的方法和@Import 注册到BeanDefinitionMap中 this.reader.loadBeanDefinitions(configClasses); alreadyParsed.addAll(configClasses); // 加入到已经解析的集合中 candidates.clear(); // 判断ioc容器中的BeanDefinition是否大于候选原始的BeanDefinition个数 if (registry.getBeanDefinitionCount() &gt; candidateNames.length) &#123; String[] newCandidateNames = registry.getBeanDefinitionNames(); // 获取所有的bean定义 Set&lt;String&gt; oldCandidateNames = new HashSet&lt;&gt;(Arrays.asList(candidateNames)); //原始候选bean定义 Set&lt;String&gt; alreadyParsedClasses = new HashSet&lt;&gt;(); for (ConfigurationClass configurationClass : alreadyParsed) &#123; // 赋值已经解析的 alreadyParsedClasses.add(configurationClass.getMetadata().getClassName()); &#125; for (String candidateName : newCandidateNames) &#123; if (!oldCandidateNames.contains(candidateName)) &#123; // 表示当前循环的还没有被解析过 BeanDefinition bd = registry.getBeanDefinition(candidateName); // 判断有没有被解析过，则放入candidates集合，进行新一轮解析 if (ConfigurationClassUtils.checkConfigurationClassCandidate(bd, this.metadataReaderFactory) &amp;&amp; !alreadyParsedClasses.contains(bd.getBeanClassName())) &#123; candidates.add(new BeanDefinitionHolder(bd, candidateName)); &#125; &#125; &#125; candidateNames = newCandidateNames; &#125; &#125; while (!candidates.isEmpty()); //存在没有解析过的 需要循环解析 // Register the ImportRegistry as a bean in order to support ImportAware @Configuration classes if (sbr != null &amp;&amp; !sbr.containsSingleton(IMPORT_REGISTRY_BEAN_NAME)) &#123; sbr.registerSingleton(IMPORT_REGISTRY_BEAN_NAME, parser.getImportRegistry()); &#125; if (this.metadataReaderFactory instanceof CachingMetadataReaderFactory) &#123; // Clear cache in externally provided MetadataReaderFactory; this is a no-op for a shared cache since it&#x27;ll be cleared by the ApplicationContext. ((CachingMetadataReaderFactory) this.metadataReaderFactory).clearCache(); &#125;&#125; this.reader.loadBeanDefinitions(configClasses) 这里才把 @Bean 方法和 @Import 注解中的类注册到 BeanDefinitionMap 中，典型的是对AOP的支持将 AspectJAutoProxyRegistrar 注册到 BeanDefinitionMap 中。 1234567891011121314151617181920212223242526public void loadBeanDefinitions(Set&lt;ConfigurationClass&gt; configurationModel) &#123; TrackedConditionEvaluator trackedConditionEvaluator = new TrackedConditionEvaluator(); for (ConfigurationClass configClass : configurationModel) &#123; // 注册配置类到容器中 loadBeanDefinitionsForConfigurationClass(configClass, trackedConditionEvaluator); &#125;&#125;private void loadBeanDefinitionsForConfigurationClass(ConfigurationClass configClass, TrackedConditionEvaluator trackedConditionEvaluator) &#123; if (trackedConditionEvaluator.shouldSkip(configClass)) &#123; String beanName = configClass.getBeanName(); if (StringUtils.hasLength(beanName) &amp;&amp; this.registry.containsBeanDefinition(beanName)) &#123; this.registry.removeBeanDefinition(beanName); &#125; this.importRegistry.removeImportingClass(configClass.getMetadata().getClassName()); return; &#125; if (configClass.isImported()) &#123; // 通过@Import导入进来的配置类的处理即@Configuration注解的类 registerBeanDefinitionForImportedConfigurationClass(configClass); &#125; for (BeanMethod beanMethod : configClass.getBeanMethods()) &#123; // 通过@bean导入进来的组件 loadBeanDefinitionsForBeanMethod(beanMethod); &#125; // 通过@ImportResources导入进来 loadBeanDefinitionsFromImportedResources(configClass.getImportedResources()); // 通过ImportBeanDefinitionRegistrar注解导入进来 loadBeanDefinitionsFromRegistrars(configClass.getImportBeanDefinitionRegistrars());&#125; 上面通过 ConfigurationClassUtils 工具类对注册的Bean进行标记，标记配置类是属于Full配置类，还是Lite配置类，当注册配置类时，若加了 @Configuration注解 ，就称之为Full配置类，若直接使用 @Component 、 @ComponentScan 、 @Import 、 @ImportResource 等注解，Spring把这种配置类称之为Lite配置类。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061abstract class ConfigurationClassUtils &#123; private static final String CONFIGURATION_CLASS_FULL = &quot;full&quot;; private static final String CONFIGURATION_CLASS_LITE = &quot;lite&quot;; private static final Set&lt;String&gt; candidateIndicators = new HashSet&lt;&gt;(8); static &#123; candidateIndicators.add(Component.class.getName()); candidateIndicators.add(ComponentScan.class.getName()); candidateIndicators.add(Import.class.getName()); candidateIndicators.add(ImportResource.class.getName()); &#125; // 该方法通过传入的bean定义字段来判断当前bean是完全的配置类(标注了@Configuration注解) public static boolean isFullConfigurationClass(BeanDefinition beanDef) &#123; /** * 最终会通过方法checkConfigurationClassCandidate来设置CONFIGURATION_CLASS_ATTRIBUTE的属性是完全的配置类还是非正式的配置类 * 第一次进来的时候逻辑CONFIGURATION_CLASS_ATTRIBUTE属性CONFIGURATION_CLASS_ATTRIBUTE是为Null的 */ return CONFIGURATION_CLASS_FULL.equals(beanDef.getAttribute(CONFIGURATION_CLASS_ATTRIBUTE)); &#125; // 该方法通过传入bean定义的字段来判断当前bean是非正式的配置类(没有标注了@Configuration注解,但该类配置了@Bean的配置类) public static boolean isLiteConfigurationClass(BeanDefinition beanDef) &#123; return CONFIGURATION_CLASS_LITE.equals(beanDef.getAttribute(CONFIGURATION_CLASS_ATTRIBUTE)); &#125; public static boolean checkConfigurationClassCandidate(BeanDefinition beanDef, MetadataReaderFactory metadataReaderFactory) &#123; String className = beanDef.getBeanClassName(); if (className == null || beanDef.getFactoryMethodName() != null) &#123; return false; &#125; AnnotationMetadata metadata; if (beanDef instanceof AnnotatedBeanDefinition &amp;&amp; className.equals(((AnnotatedBeanDefinition) beanDef).getMetadata().getClassName())) &#123; metadata = ((AnnotatedBeanDefinition) beanDef).getMetadata(); &#125; else if (beanDef instanceof AbstractBeanDefinition &amp;&amp; ((AbstractBeanDefinition) beanDef).hasBeanClass()) &#123; Class&lt;?&gt; beanClass = ((AbstractBeanDefinition) beanDef).getBeanClass(); metadata = new StandardAnnotationMetadata(beanClass, true); &#125; else &#123; try &#123; MetadataReader metadataReader = metadataReaderFactory.getMetadataReader(className); metadata = metadataReader.getAnnotationMetadata(); &#125; catch (IOException ex) &#123; return false; &#125; &#125; // 判断是不是真正的配置类 就是判断当前的bean的class上有没有标注了@Configuration注解 if (isFullConfigurationCandidate(metadata)) &#123; // 设置标记 beanDef.setAttribute(CONFIGURATION_CLASS_ATTRIBUTE, CONFIGURATION_CLASS_FULL); &#125; // 这里判断该配置类是一个非正式的配置类(Component ComponentScan Import ImportResource) else if (isLiteConfigurationCandidate(metadata)) &#123; beanDef.setAttribute(CONFIGURATION_CLASS_ATTRIBUTE, CONFIGURATION_CLASS_LITE); &#125; else &#123; return false; &#125; //解析配置类上是否标注了@Order注解 Integer order = getOrder(metadata); if (order != null) &#123; beanDef.setAttribute(ORDER_ATTRIBUTE, order); &#125; return true; &#125;&#125; Full配置类在getBean创建时会被被CGLib代理，而Lite配置类getBean创建时不会被代理。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110class ConfigurationClassParser &#123; // 具体的解析过程 public void parse(Set&lt;BeanDefinitionHolder&gt; configCandidates) &#123; // 用于保存延时的ImportSelectors，最著名的代表SpringBoot自动装配的的类AutoConfigurationImportSelector this.deferredImportSelectors = new LinkedList&lt;&gt;(); for (BeanDefinitionHolder holder : configCandidates) &#123; // 循环配置类 BeanDefinition bd = holder.getBeanDefinition(); try &#123; if (bd instanceof AnnotatedBeanDefinition) &#123; // 真正的解析bean定义，通过注解元数据解析 parse(((AnnotatedBeanDefinition) bd).getMetadata(), holder.getBeanName()); &#125; else if (bd instanceof AbstractBeanDefinition &amp;&amp; ((AbstractBeanDefinition) bd).hasBeanClass()) &#123; parse(((AbstractBeanDefinition) bd).getBeanClass(), holder.getBeanName()); &#125; else &#123; parse(bd.getBeanClassName(), holder.getBeanName()); &#125; &#125; catch (BeanDefinitionStoreException ex) &#123; throw ex; &#125; catch (Throwable ex) &#123; throw new BeanDefinitionStoreException(&quot;Failed to parse configuration class [&quot; + bd.getBeanClassName() + &quot;]&quot;, ex); &#125; &#125; // 处理延时的DeferredImportSelectors，springboot就是通过这进行记载spring.factories文件中的自定装配的对象 processDeferredImportSelectors(); &#125; // 第一步：把配置类源信息和beanName包装成一个ConfigurationClass对象 protected final void parse(AnnotationMetadata metadata, String beanName) throws IOException &#123; processConfigurationClass(new ConfigurationClass(metadata, beanName)); &#125; protected void processConfigurationClass(ConfigurationClass configClass) throws IOException &#123; if (this.conditionEvaluator.shouldSkip(configClass.getMetadata(), ConfigurationPhase.PARSE_CONFIGURATION)) &#123; return; &#125; //获取处我们的配置类对象 ConfigurationClass existingClass = this.configurationClasses.get(configClass); if (existingClass != null) &#123; if (configClass.isImported()) &#123; // 传入进来的配置类是通过其他配置类的Import导入进来的 if (existingClass.isImported()) &#123; // 需要合并配置 existingClass.mergeImportedBy(configClass); &#125; return; // 故若通过@Import导入一个已存在的配置类 是不允许的，会忽略。 &#125; else &#123; this.configurationClasses.remove(configClass); this.knownSuperclasses.values().removeIf(configClass::equals); &#125; &#125; // 递归处理配置类及其超类层次结构。 SourceClass sourceClass = asSourceClass(configClass); do &#123; // 真正的进行配置类的解析 sourceClass = doProcessConfigurationClass(configClass, sourceClass); &#125; while (sourceClass != null); this.configurationClasses.put(configClass, configClass); &#125; protected final SourceClass doProcessConfigurationClass(ConfigurationClass configClass, SourceClass sourceClass) throws IOException &#123; // Recursively process any member (nested) classes first processMemberClasses(configClass, sourceClass); // 处理@propertySource注解 for (AnnotationAttributes propertySource : AnnotationConfigUtils.attributesForRepeatable(sourceClass.getMetadata(), PropertySources.class, org.springframework.context.annotation.PropertySource.class)) &#123; if (this.environment instanceof ConfigurableEnvironment) &#123; processPropertySource(propertySource); &#125; &#125; // 从配置类上解析出ComponentScans的对象集合属性 Set&lt;AnnotationAttributes&gt; componentScans = AnnotationConfigUtils.attributesForRepeatable(sourceClass.getMetadata(), ComponentScans.class, ComponentScan.class); if (!componentScans.isEmpty() &amp;&amp; !this.conditionEvaluator.shouldSkip(sourceClass.getMetadata(), ConfigurationPhase.REGISTER_BEAN)) &#123; // 循环解析出AnnotationAttributes for (AnnotationAttributes componentScan : componentScans) &#123; // 把我们扫描出来的类变为bean定义的集合，真正的解析 Set&lt;BeanDefinitionHolder&gt; scannedBeanDefinitions = this.componentScanParser.parse(componentScan, sourceClass.getMetadata().getClassName()); //循环处理我们包扫描出来的bean定义 for (BeanDefinitionHolder holder : scannedBeanDefinitions) &#123; BeanDefinition bdCand = holder.getBeanDefinition().getOriginatingBeanDefinition(); if (bdCand == null) &#123; bdCand = holder.getBeanDefinition(); &#125; // 判断当前扫描出来的bean定义是不是一个配置类,若是的话直接进行递归解析 if (ConfigurationClassUtils.checkConfigurationClassCandidate(bdCand, this.metadataReaderFactory)) &#123; // 递归解析，因为@Component算是lite配置类 parse(bdCand.getBeanClassName(), holder.getBeanName()); &#125; &#125; &#125; &#125; // 处理@Import，@Import三种类：Import普通类、ImportSelector、ImportBeanDefinitionRegistrar processImports(configClass, sourceClass, getImports(sourceClass), true); // 处理 @ImportResource annotations AnnotationAttributes importResource = AnnotationConfigUtils.attributesFor(sourceClass.getMetadata(), ImportResource.class); if (importResource != null) &#123; String[] resources = importResource.getStringArray(&quot;locations&quot;); Class&lt;? extends BeanDefinitionReader&gt; readerClass = importResource.getClass(&quot;reader&quot;); for (String resource : resources) &#123; String resolvedResource = this.environment.resolveRequiredPlaceholders(resource); configClass.addImportedResource(resolvedResource, readerClass); &#125; &#125; // 处理@Bean方法获取配置类中所有标注了@Bean的方法，不是马上转换成BeanDefinition，而是先用一个set接收 Set&lt;MethodMetadata&gt; beanMethods = retrieveBeanMethodMetadata(sourceClass); for (MethodMetadata methodMetadata : beanMethods) &#123; configClass.addBeanMethod(new BeanMethod(methodMetadata, configClass)); &#125; processInterfaces(configClass, sourceClass); // 处理配置类接口 默认方法的@Bean if (sourceClass.getMetadata().hasSuperClass()) &#123; // 处理配置类的父类的 ，循环再解析 String superclass = sourceClass.getMetadata().getSuperClassName(); if (superclass != null &amp;&amp; !superclass.startsWith(&quot;java&quot;) &amp;&amp; !this.knownSuperclasses.containsKey(superclass)) &#123; this.knownSuperclasses.put(superclass, configClass); // Superclass found, return its annotation metadata and recurse return sourceClass.getSuperClass(); &#125; &#125; return null; // 没有父类解析完成 &#125;&#125; 真正进行扫描和解析的地方，可以明显看到这里并没有使用AnnotationConfigApplicationContext中的scanner 而是重新new了一个ClassPathBeanDefinitionScanner 。且会创建和添加默认的includeFilters 。 123456789101112131415161718192021public ClassPathBeanDefinitionScanner(BeanDefinitionRegistry registry, boolean useDefaultFilters, Environment environment, @Nullable ResourceLoader resourceLoader) &#123; Assert.notNull(registry, &quot;BeanDefinitionRegistry must not be null&quot;); this.registry = registry; // 设置默认的扫描规则为true的话 默认是扫描所有的 若使用 includeFilters 来表示只包含需要设置为false if (useDefaultFilters) &#123; registerDefaultFilters(); &#125; setEnvironment(environment); // 设置环境对象 setResourceLoader(resourceLoader); //设置资源加载器&#125;protected void registerDefaultFilters() &#123; // 加入扫描@Component的TypeFilter this.includeFilters.add(new AnnotationTypeFilter(Component.class)); ClassLoader cl = ClassPathScanningCandidateComponentProvider.class.getClassLoader(); try &#123; // 加入扫描的JSR250规范的TypeFilter this.includeFilters.add(new AnnotationTypeFilter(((Class&lt;? extends Annotation&gt;) ClassUtils.forName(&quot;javax.annotation.ManagedBean&quot;, cl)), false)); &#125; catch (ClassNotFoundException ex) &#123;&#125; try &#123; // 加入扫描JSR330规范的TypeFilter this.includeFilters.add(new AnnotationTypeFilter(((Class&lt;? extends Annotation&gt;) ClassUtils.forName(&quot;javax.inject.Named&quot;, cl)), false)); &#125; catch (ClassNotFoundException ex) &#123;&#125;&#125; ComponentScans指定扫描目标，除了最常用的 basePackages ，还可以指定 basePackageClasses ，就是指定多个类，只要是与这几个类同级的，或者在这几个类下级的都可以被扫描到，这种方式Spring比较推荐的，指定 basePackages 没有IDE的检查容易出错，但指定一个类有IDE的检查了，不容易出错，经常会用一个空的类来作为 basePackageClasses ，还可以直接不指定，默认会把与配置类同级，或者在配置类下级的作为扫描目标。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657class ComponentScanAnnotationParser &#123; public Set&lt;BeanDefinitionHolder&gt; parse(AnnotationAttributes componentScan, final String declaringClass) &#123; ClassPathBeanDefinitionScanner scanner = new ClassPathBeanDefinitionScanner(this.registry, componentScan.getBoolean(&quot;useDefaultFilters&quot;), this.environment, this.resourceLoader); // 为扫描器设置beanName的生成器对象 Class&lt;? extends BeanNameGenerator&gt; generatorClass = componentScan.getClass(&quot;nameGenerator&quot;); boolean useInheritedGenerator = (BeanNameGenerator.class == generatorClass); scanner.setBeanNameGenerator(useInheritedGenerator ? this.beanNameGenerator : BeanUtils.instantiateClass(generatorClass)); // 解析@Scope的ProxyMode属性，该属性可以将Bean创建问jdk代理或cglib代理 ScopedProxyMode scopedProxyMode = componentScan.getEnum(&quot;scopedProxy&quot;); if (scopedProxyMode != ScopedProxyMode.DEFAULT) &#123; scanner.setScopedProxyMode(scopedProxyMode); &#125; else &#123; Class&lt;? extends ScopeMetadataResolver&gt; resolverClass = componentScan.getClass(&quot;scopeResolver&quot;); scanner.setScopeMetadataResolver(BeanUtils.instantiateClass(resolverClass)); &#125; scanner.setResourcePattern(componentScan.getString(&quot;resourcePattern&quot;)); // 设置CompentScan对象的includeFilters 包含的属性 for (AnnotationAttributes filter : componentScan.getAnnotationArray(&quot;includeFilters&quot;)) &#123; for (TypeFilter typeFilter : typeFiltersFor(filter)) &#123; scanner.addIncludeFilter(typeFilter); &#125; &#125; // 设置CompentScan对象的excludeFilters 包含的属性 for (AnnotationAttributes filter : componentScan.getAnnotationArray(&quot;excludeFilters&quot;)) &#123; for (TypeFilter typeFilter : typeFiltersFor(filter)) &#123; scanner.addExcludeFilter(typeFilter); &#125; &#125; // 是否懒加载，此懒加载为componentScan延迟加载所有类 boolean lazyInit = componentScan.getBoolean(&quot;lazyInit&quot;); if (lazyInit) &#123; scanner.getBeanDefinitionDefaults().setLazyInit(true); &#125; // 包路径配置类中componentScan设置的路径 Set&lt;String&gt; basePackages = new LinkedHashSet&lt;&gt;(); String[] basePackagesArray = componentScan.getStringArray(&quot;basePackages&quot;); for (String pkg : basePackagesArray) &#123; String[] tokenized = StringUtils.tokenizeToStringArray(this.environment.resolvePlaceholders(pkg), ConfigurableApplicationContext.CONFIG_LOCATION_DELIMITERS); Collections.addAll(basePackages, tokenized); &#125; for (Class&lt;?&gt; clazz : componentScan.getClassArray(&quot;basePackageClasses&quot;)) &#123; basePackages.add(ClassUtils.getPackageName(clazz)); &#125; if (basePackages.isEmpty()) &#123; basePackages.add(ClassUtils.getPackageName(declaringClass)); &#125; scanner.addExcludeFilter(new AbstractTypeHierarchyTraversingFilter(false, false) &#123; @Override protected boolean matchClassName(String className) &#123; return declaringClass.equals(className); &#125; &#125;); return scanner.doScan(StringUtils.toStringArray(basePackages)); // 真正的进行扫描解析 &#125;&#125; 12345678910111213141516171819202122232425262728293031323334public class ClassPathBeanDefinitionScanner extends ClassPathScanningCandidateComponentProvider &#123; protected Set&lt;BeanDefinitionHolder&gt; doScan(String... basePackages) &#123; Assert.notEmpty(basePackages, &quot;At least one base package must be specified&quot;); // 创建bean定义的holder对象用于保存扫描后生成的bean定义对象 Set&lt;BeanDefinitionHolder&gt; beanDefinitions = new LinkedHashSet&lt;&gt;(); for (String basePackage : basePackages) &#123; // 循环包路径集合 // 到候选的Components Set&lt;BeanDefinition&gt; candidates = findCandidateComponents(basePackage); for (BeanDefinition candidate : candidates) &#123; ScopeMetadata scopeMetadata = this.scopeMetadataResolver.resolveScopeMetadata(candidate); candidate.setScope(scopeMetadata.getScopeName()); // 设置beanName String beanName = this.beanNameGenerator.generateBeanName(candidate, this.registry); //这是默认配置 autowire-candidate if (candidate instanceof AbstractBeanDefinition) &#123; postProcessBeanDefinition((AbstractBeanDefinition) candidate, beanName); &#125; // 取@Lazy @DependsOn等注解的数据设置到BeanDefinition中 if (candidate instanceof AnnotatedBeanDefinition) &#123; AnnotationConfigUtils.processCommonDefinitionAnnotations((AnnotatedBeanDefinition) candidate); &#125; // 解析出来的组件bean定义注册到我们的IOC容器中（容器中没有才注册） if (checkCandidate(beanName, candidate)) &#123; BeanDefinitionHolder definitionHolder = new BeanDefinitionHolder(candidate, beanName); definitionHolder = AnnotationConfigUtils.applyScopedProxyMode(scopeMetadata, definitionHolder, this.registry); beanDefinitions.add(definitionHolder); registerBeanDefinition(definitionHolder, this.registry); &#125; &#125; &#125; return beanDefinitions; &#125;&#125; 1234567public Set&lt;BeanDefinition&gt; findCandidateComponents(String basePackage) &#123; if (this.componentsIndex != null &amp;&amp; indexSupportsIncludeFilters()) &#123; return addCandidateComponentsFromIndex(this.componentsIndex, basePackage); &#125; else &#123; return scanCandidateComponents(basePackage); &#125;&#125; Spring支持 component索引技术，需要引入一个组件，大部分项目没有引入这个组件，所以会进入 scanCandidateComponents 方法。注意这里的Bean是包装成一个 ScannedGenericBeanDefinition ，与内置的和配置类的都是区别开的。 123456789101112131415161718192021222324252627282930313233private Set&lt;BeanDefinition&gt; scanCandidateComponents(String basePackage) &#123; Set&lt;BeanDefinition&gt; candidates = new LinkedHashSet&lt;&gt;(); try &#123; // 把包路径转为资源路径 cn/test/MainConfig String packageSearchPath = ResourcePatternResolver.CLASSPATH_ALL_URL_PREFIX + resolveBasePackage(basePackage) + &#x27;/&#x27; + this.resourcePattern; // 扫描指定包路径下面的所有.class文件 Resource[] resources = getResourcePatternResolver().getResources(packageSearchPath); boolean traceEnabled = logger.isTraceEnabled(); boolean debugEnabled = logger.isDebugEnabled(); for (Resource resource : resources) &#123; // 需要resources集合 //判断当的是不是可读的 if (resource.isReadable()) &#123; try &#123; MetadataReader metadataReader = getMetadataReaderFactory().getMetadataReader(resource); if (isCandidateComponent(metadataReader)) &#123; // 是不是候选的组件 // 包装成为一个ScannedGenericBeanDefinition ScannedGenericBeanDefinition sbd = new ScannedGenericBeanDefinition(metadataReader); sbd.setResource(resource); // 并且设置class资源 sbd.setSource(resource); if (isCandidateComponent(sbd)) &#123; candidates.add(sbd); // 加入到集合中 &#125; &#125; &#125; catch (Throwable ex) &#123; throw new BeanDefinitionStoreException(&quot;Failed to read candidate component class: &quot; + resource, ex); &#125; &#125; &#125; &#125; catch (IOException ex) &#123; throw new BeanDefinitionStoreException(&quot;I/O failure during classpath scanning&quot;, ex); &#125; return candidates; //返回&#125; @Import解析这里会将@Import注解中的信息解析出来，然后根据类型分别进行处理，Spring AOP的支持就是在该处解析出来的，在 @EnableAspectJAutoProxy 注解上有 @Import(AspectJAutoProxyRegistrar.class) 注解，这里的 AspectJAutoProxyRegistrar 实现了ImportBeanDefinitionRegistrar接口，但这里不会直接调用ImportBeanDefinitionRegistrar 的 registerBeanDefinitions 方法，而是等数据都解析完了才会去调用。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950private void processImports(ConfigurationClass configClass, SourceClass currentSourceClass, Collection&lt;SourceClass&gt; importCandidates, boolean checkForCircularImports) &#123; if (importCandidates.isEmpty()) &#123; return; &#125; if (checkForCircularImports &amp;&amp; isChainedImportOnStack(configClass)) &#123; this.problemReporter.error(new CircularImportProblem(configClass, this.importStack)); &#125; else &#123; this.importStack.push(configClass); try &#123; for (SourceClass candidate : importCandidates) &#123; // 获取我们Import导入进来的所有组件 if (candidate.isAssignable(ImportSelector.class)) &#123; // 判断该组件是不是实现了ImportSelector // Candidate class is an ImportSelector -&gt; delegate to it to determine imports Class&lt;?&gt; candidateClass = candidate.loadClass(); // 实例化我们的SelectImport组件 ImportSelector selector = BeanUtils.instantiateClass(candidateClass, ImportSelector.class); // 调用相关的aware方法 ParserStrategyUtils.invokeAwareMethods(selector, this.environment, this.resourceLoader, this.registry); // 判断是不是延时的DeferredImportSelectors，是这个类型 不进行处理 if (this.deferredImportSelectors != null &amp;&amp; selector instanceof DeferredImportSelector) &#123; this.deferredImportSelectors.add(new DeferredImportSelectorHolder(configClass, (DeferredImportSelector) selector)); &#125; else &#123; // 不是延时的， 调用selector的selectImports String[] importClassNames = selector.selectImports(currentSourceClass.getMetadata()); // 所以递归解析-- 直到成普通组件 Collection&lt;SourceClass&gt; importSourceClasses = asSourceClasses(importClassNames); processImports(configClass, currentSourceClass, importSourceClasses, false); &#125; &#125; // 判断导入的组件是不是ImportBeanDefinitionRegistrar，这里不直接调用，只是解析 else if (candidate.isAssignable(ImportBeanDefinitionRegistrar.class)) &#123; Class&lt;?&gt; candidateClass = candidate.loadClass(); // 实例化ImportBeanDefinitionRegistrar对象 ImportBeanDefinitionRegistrar registrar = BeanUtils.instantiateClass(candidateClass, ImportBeanDefinitionRegistrar.class); ParserStrategyUtils.invokeAwareMethods(registrar, this.environment, this.resourceLoader, this.registry); // 保存ImportBeanDefinitionRegistrar对象currentSourceClass=所在配置类 configClass.addImportBeanDefinitionRegistrar(registrar, currentSourceClass.getMetadata()); &#125; else &#123; // 当做配置类再解析，注意这里会标记：importedBy，表示这是Import的配置的类，再执行之前的processConfigurationClass()方法 ， this.importStack.registerImport(currentSourceClass.getMetadata(), candidate.getMetadata().getClassName()); processConfigurationClass(candidate.asConfigClass(configClass)); &#125; &#125; &#125; catch (BeanDefinitionStoreException ex) &#123; throw ex; &#125; catch (Throwable ex) &#123; throw new BeanDefinitionStoreException(&quot;Failed to process import candidates for configuration class [&quot; + configClass.getMetadata().getClassName() + &quot;]&quot;, ex); &#125; finally &#123; this.importStack.pop(); &#125; &#125;&#125;","tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://example.com/tags/SpringBoot/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}]},{"title":"AOP创建代理与调用","date":"2020-10-16T11:08:20.000Z","path":"blog/Spring/AOP创建代理与调用/","text":"创建代理给Bean创建代理的地方有两个，存在循环依赖的Bean会调用实现了 SmartInstantiationAwareBeanPostProcessor 接口的 getEarlyBeanReference 方法，即Bean的生命周期中第四次调用后置处理器的地方，给有AOP代理的且产生循环依赖且先被加载的对象创建AOP代理。若在该处已经设置了动态代理会将 beanName 加入到 earlyProxyReferences 集合中，防止第八次调用后置处理器时重复添加动态代理。 1234567public abstract class AbstractAutoProxyCreator extends ProxyProcessorSupport implements SmartInstantiationAwareBeanPostProcessor, BeanFactoryAware &#123; public Object getEarlyBeanReference(Object bean, String beanName) throws BeansException &#123; Object cacheKey = getCacheKey(bean.getClass(), beanName); this.earlyProxyReferences.put(cacheKey, bean); return wrapIfNecessary(bean, beanName, cacheKey); &#125;&#125; 若Bean有AOP代理，但不存在循环依赖或存在循环依赖但后被加载，则AOP代理是在第八次调用后置处理器时，给该Bean创建动态代理的。 1234567891011public abstract class AbstractAutoProxyCreator extends ProxyProcessorSupport implements SmartInstantiationAwareBeanPostProcessor, BeanFactoryAware &#123; public Object postProcessAfterInitialization(@Nullable Object bean, String beanName) throws BeansException &#123; if (bean != null) &#123; Object cacheKey = getCacheKey(bean.getClass(), beanName);// 获取缓存key if (this.earlyProxyReferences.remove(cacheKey) != bean) &#123;// 若之前循环依赖已创建的动态代理则不再创建且移除 return wrapIfNecessary(bean, beanName, cacheKey);// 若存在动态代理将返回创建动态代理后实例 &#125; &#125; return bean; &#125;&#125; 这两个地方其实都是调用的 wrapIfNecessary 方法为加载的Bean创建动态代理的， advisedBeans 中对于AOP基础类或被标记跳过的类会直接返回原始对象。 shouldSkip 在 切面解析 时就已经对所有切面类进行了解析，这里会走缓存。接着找到当前Bean的所有匹配切点规则的advisor，然后对当前Bean创建代理对象，不管是否创建代理对象都将其缓存到 advisedBeans 中。 12345678910111213141516171819202122232425protected Object wrapIfNecessary(Object bean, String beanName, Object cacheKey) &#123; // 已被处理过即解析切面时targetSourcedBeans出现过，则是自实现创建动态代理逻辑 if (StringUtils.hasLength(beanName) &amp;&amp; this.targetSourcedBeans.contains(beanName)) &#123; return bean; &#125; if (Boolean.FALSE.equals(this.advisedBeans.get(cacheKey))) &#123; // 不需要增强直接返回 return bean; &#125; // 是否基础的Bean、是否需要跳过的重复判断，因为循环依赖是可以改变bean的，若把bean改成了advisor if (isInfrastructureClass(bean.getClass()) || shouldSkip(bean.getClass(), beanName)) &#123; this.advisedBeans.put(cacheKey, Boolean.FALSE); return bean; &#125; // 根据当前Bean找到匹配的advisor列表 Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(bean.getClass(), beanName, null); if (specificInterceptors != DO_NOT_PROXY) &#123; // 当前Bean匹配到了advisor this.advisedBeans.put(cacheKey, Boolean.TRUE); // 标记为已处理 // 真正创建代理对象 Object proxy = createProxy(bean.getClass(), beanName, specificInterceptors, new SingletonTargetSource(bean)); this.proxyTypes.put(cacheKey, proxy.getClass()); // 加入到缓存 return proxy; &#125; this.advisedBeans.put(cacheKey, Boolean.FALSE); return bean;&#125; 从候选通知器中找到当前Bean关联的 Advisor 列表，然后对Advisor进行一个排序，按照 AfterThrowing 、 AfterReturning 、 After 、 Around 、 Before 的顺序排列，若有多个切面每个切面内还是按照前面的排序，然后再进行切面之间的排序。因为实际调用的时候是方法递归调用，所以排在前面的方法会后执行。 12345678910111213141516171819202122232425262728public abstract class AbstractAdvisorAutoProxyCreator extends AbstractAutoProxyCreator &#123; protected Object[] getAdvicesAndAdvisorsForBean(Class&lt;?&gt; beanClass, String beanName, @Nullable TargetSource targetSource) &#123; List&lt;Advisor&gt; advisors = findEligibleAdvisors(beanClass, beanName); // 找到和当前Bean匹配的advisor if (advisors.isEmpty()) &#123; return DO_NOT_PROXY; // 若没找到则不创建代理 &#125; return advisors.toArray(); &#125; protected List&lt;Advisor&gt; findEligibleAdvisors(Class&lt;?&gt; beanClass, String beanName) &#123; List&lt;Advisor&gt; candidateAdvisors = findCandidateAdvisors(); // 获取所有切面的所有Advisor，这里是从缓存获取 // 切点是否命中当前Bean List&lt;Advisor&gt; eligibleAdvisors = findAdvisorsThatCanApply(candidateAdvisors, beanClass, beanName); extendAdvisors(eligibleAdvisors); if (!eligibleAdvisors.isEmpty()) &#123; // 对advisor进行排序 eligibleAdvisors = sortAdvisors(eligibleAdvisors); &#125; return eligibleAdvisors; &#125; protected List&lt;Advisor&gt; findAdvisorsThatCanApply(List&lt;Advisor&gt; candidateAdvisors, Class&lt;?&gt; beanClass, String beanName) &#123; // 记录当前正在创建的被代理对象的名称 ProxyCreationContext.setCurrentProxiedBeanName(beanName); try &#123;// 从候选通知器中找到当前Bean关联的advisors return AopUtils.findAdvisorsThatCanApply(candidateAdvisors, beanClass); &#125; finally &#123;//从线程局部变量中清除当前正在创建的beanName的代理对象名称 ProxyCreationContext.setCurrentProxiedBeanName(null); &#125; &#125;&#125; 首先通过AspectJ进行类级别的过滤即初筛，若不匹配则直接返回，若 Pointcut 的 getMethodMatcher() 为 TrueMethodMatcher 则匹配所有方法。这里其实就是将Advisor中的切点表达式与Bean进行匹配。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public abstract class AopUtils &#123; public static boolean canApply(Advisor advisor, Class&lt;?&gt; targetClass, boolean hasIntroductions) &#123; if (advisor instanceof IntroductionAdvisor) &#123;// 判断advisor是否为IntroductionAdvisor return ((IntroductionAdvisor) advisor).getClassFilter().matches(targetClass); &#125; else if (advisor instanceof PointcutAdvisor) &#123; // 判断advisor是否实现了PointcutAdvisor PointcutAdvisor pca = (PointcutAdvisor) advisor; return canApply(pca.getPointcut(), targetClass, hasIntroductions); // 找到真正能用的增强器 &#125; else &#123; return true; &#125; &#125; public static boolean canApply(Pointcut pc, Class&lt;?&gt; targetClass, boolean hasIntroductions) &#123; Assert.notNull(pc, &quot;Pointcut must not be null&quot;); if (!pc.getClassFilter().matches(targetClass)) &#123; // 通过AspectJ进行类级别过滤（初筛） return false; &#125; // 进行方法级别过滤（精筛），若pc.getMethodMatcher()返回TrueMethodMatcher则匹配所有方法 MethodMatcher methodMatcher = pc.getMethodMatcher(); if (methodMatcher == MethodMatcher.TRUE) &#123; return true; &#125; // 判断匹配器是否为IntroductionAwareMethodMatcher，只有AspectJExpressionPointCut才会实现这个接口 IntroductionAwareMethodMatcher introductionAwareMethodMatcher = null; if (methodMatcher instanceof IntroductionAwareMethodMatcher) &#123; introductionAwareMethodMatcher = (IntroductionAwareMethodMatcher) methodMatcher; &#125; Set&lt;Class&lt;?&gt;&gt; classes = new LinkedHashSet&lt;&gt;(); // 用于保存targetClass的class对象 if (!Proxy.isProxyClass(targetClass)) &#123; // 判断当前class是不是代理的class对象 classes.add(ClassUtils.getUserClass(targetClass)); // 加入到集合中去 &#125; // 获取到targetClass所实现的接口的class对象，然后加入到集合中 classes.addAll(ClassUtils.getAllInterfacesForClassAsSet(targetClass)); for (Class&lt;?&gt; clazz : classes) &#123; // 循环所有的class对象 Method[] methods = ReflectionUtils.getAllDeclaredMethods(clazz); // 通过class获取到所有的方法 for (Method method : methods) &#123; // 遍历方法挨个匹配 // 通过methodMatcher.matches来匹配方法 if (introductionAwareMethodMatcher != null ? // 通过切点表达式进行匹配 AspectJ方式 introductionAwareMethodMatcher.matches(method, targetClass, hasIntroductions) : // 通过方法匹配器进行匹配 内置aop接口方式 methodMatcher.matches(method, targetClass)) &#123; // 只要有1个方法匹配上了就创建代理 return true; &#125; &#125; &#125; return false; &#125;&#125; 通过 @Before 、 @Around 、 @After 、 @AfterReturning 、 @AfterThrowing 等注解的方法配置的切点，最终的初筛和精筛都是调用的 AspectJExpressionPointcut 的 matches 方法，其匹配实现是AspectJ来完成的。初筛是通过 couldMatchJoinPointsInType 方法，精筛是通过 matchesMethodExecution 方法，通过切点表达式与类和方法进行匹配。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class AspectJExpressionPointcut extends AbstractExpressionPointcut implements ClassFilter, IntroductionAwareMethodMatcher, BeanFactoryAware &#123; public boolean matches(Class&lt;?&gt; targetClass) &#123; // 初筛 PointcutExpression pointcutExpression = obtainPointcutExpression(); try &#123; try &#123; return pointcutExpression.couldMatchJoinPointsInType(targetClass); &#125; catch (ReflectionWorldException ex) &#123; PointcutExpression fallbackExpression = getFallbackPointcutExpression(targetClass); if (fallbackExpression != null) &#123; return fallbackExpression.couldMatchJoinPointsInType(targetClass); &#125; &#125; &#125; catch (Throwable ex) &#123;&#125; return false; &#125; private PointcutExpression obtainPointcutExpression() &#123; if (getExpression() == null) &#123; throw new IllegalStateException(&quot;Must set property &#x27;expression&#x27; before attempting to match&quot;); &#125; if (this.pointcutExpression == null) &#123; this.pointcutClassLoader = determinePointcutClassLoader(); this.pointcutExpression = buildPointcutExpression(this.pointcutClassLoader); &#125; return this.pointcutExpression; &#125; private PointcutExpression buildPointcutExpression(@Nullable ClassLoader classLoader) &#123; PointcutParser parser = initializePointcutParser(classLoader); PointcutParameter[] pointcutParameters = new PointcutParameter[this.pointcutParameterNames.length]; for (int i = 0; i &lt; pointcutParameters.length; i++) &#123; pointcutParameters[i] = parser.createPointcutParameter(this.pointcutParameterNames[i], this.pointcutParameterTypes[i]); &#125; return parser.parsePointcutExpression(replaceBooleanOperators(resolveExpression()),this.pointcutDeclarationScope, pointcutParameters); &#125; public boolean matches(Method method, Class&lt;?&gt; targetClass, boolean hasIntroductions) &#123; // 精筛 obtainPointcutExpression(); ShadowMatch shadowMatch = getTargetShadowMatch(method, targetClass); if (shadowMatch.alwaysMatches()) &#123; return true; &#125; else if (shadowMatch.neverMatches()) &#123; return false; &#125; else &#123; if (hasIntroductions) &#123; return true; &#125; RuntimeTestWalker walker = getRuntimeTestWalker(shadowMatch); return (!walker.testsSubtypeSensitiveVars() || walker.testTargetInstanceOfResidue(targetClass)); &#125; &#125;&#125; 完成该Bean的所有方法和所有的切点匹配工作后，做存在匹配的切点，则通过 ProxyFactory 代理工厂来为该Bean创建动态代理。若 @EnableAspectJAutoProxy(proxyTargetClass = true) 则表示无论该Bean是否实现接口都通过 Cglib 的方式来创建代理。若未设置该属性，则判断该Bean是否继承接口，若继承接口则使用JDK动态代理，否则使用Cglib动态代理。 12345678910111213141516171819202122232425262728public abstract class AbstractAutoProxyCreator extends ProxyProcessorSupport implements SmartInstantiationAwareBeanPostProcessor, BeanFactoryAware &#123; protected Object createProxy(Class&lt;?&gt; beanClass, @Nullable String beanName, @Nullable Object[] specificInterceptors, TargetSource targetSource) &#123; if (this.beanFactory instanceof ConfigurableListableBeanFactory) &#123; AutoProxyUtils.exposeTargetClass((ConfigurableListableBeanFactory) this.beanFactory, beanName, beanClass); &#125; ProxyFactory proxyFactory = new ProxyFactory(); //创建一个代理对象工厂 proxyFactory.copyFrom(this); // 为proxyFactory设置创建jdk代理还是cglib代理，若设置了&lt;aop:aspectj-autoproxy proxy-target-class=&quot;true&quot;/&gt;不会进if，说明强制使用cglib if (!proxyFactory.isProxyTargetClass()) &#123; if (shouldProxyTargetClass(beanClass, beanName)) &#123; proxyFactory.setProxyTargetClass(true); // 内部设置的，配置类就会设置这个属性 &#125; else &#123; // 检查有没有接口 evaluateProxyInterfaces(beanClass, proxyFactory); &#125; &#125; // 把specificInterceptors数组中的Advisor转化为数组形式的 Advisor[] advisors = buildAdvisors(beanName, specificInterceptors); proxyFactory.addAdvisors(advisors); // 为代理工厂加入通知器， proxyFactory.setTargetSource(targetSource); // 设置targetSource对象 customizeProxyFactory(proxyFactory); proxyFactory.setFrozen(this.freezeProxy); // 代表之前是否筛选advise，因为继承了AbstractAdvisorAutoProxyCreator，且之前调用了findEligibleAdvisors进行筛选，所以是true if (advisorsPreFiltered()) &#123; proxyFactory.setPreFiltered(true); &#125; return proxyFactory.getProxy(getProxyClassLoader()); //真正的创建代理对象 &#125;&#125; 这里创建动态代理会根据是否指定 ProxyTargetClass=true 以及有没有接口来决定使用 JDK动态代理还是 Cglib动态代理。 12345678910111213141516171819202122232425262728293031public class ProxyFactory extends ProxyCreatorSupport &#123; public Object getProxy(@Nullable ClassLoader classLoader) &#123; return createAopProxy().getProxy(classLoader); // createAopProxy()用来获取代理工厂 &#125;&#125;public class ProxyCreatorSupport extends AdvisedSupport &#123; protected final synchronized AopProxy createAopProxy() &#123; if (!this.active) &#123; activate(); &#125; return getAopProxyFactory().createAopProxy(this); &#125;&#125;public class DefaultAopProxyFactory implements AopProxyFactory, Serializable &#123; public AopProxy createAopProxy(AdvisedSupport config) throws AopConfigException &#123; // 判断是否前置指定使用cglib代理ProxyTargetClass=true或者没有接口 if (config.isOptimize() || config.isProxyTargetClass() || hasNoUserSuppliedProxyInterfaces(config)) &#123; Class&lt;?&gt; targetClass = config.getTargetClass(); if (targetClass == null) &#123; throw new AopConfigException(&quot;TargetSource cannot determine target class: &quot; + &quot;Either an interface or a target is required for proxy creation.&quot;); &#125; // 所targetClass是接口则使用jdk代理 if (targetClass.isInterface() || Proxy.isProxyClass(targetClass)) &#123; return new JdkDynamicAopProxy(config); &#125; return new ObjenesisCglibAopProxy(config); // cglib代理 &#125; else &#123; return new JdkDynamicAopProxy(config); // 动态代理 &#125; &#125;&#125; 代理类调用在代理创建时已经将增强器Advisors赋予了代理类，在执行时只需将这些增强器应用到被代理的类上即可，对于被JDK动态代理的类来说，当执行具体方法时，会调用 JdkDynamicAopProxy 的 invoke 方法，对于被Cglib动态代理的类来说，当执行具体方法时，会调用 CglibAopProxy 中 DynamicAdvisedInterceptor 的 intercept 方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354final class JdkDynamicAopProxy implements AopProxy, InvocationHandler, Serializable &#123; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; Object oldProxy = null; boolean setProxyContext = false; TargetSource targetSource = this.advised.targetSource;// 获取到目标对象 Object target = null; try &#123; if (!this.equalsDefined &amp;&amp; AopUtils.isEqualsMethod(method)) &#123;// 若执行代理对象的equals方法不需要代理 return equals(args[0]); &#125; else if (!this.hashCodeDefined &amp;&amp; AopUtils.isHashCodeMethod(method)) &#123;// 若执行的是hashCode方法不需要代理 return hashCode(); &#125; // 若执行的class对象是DecoratingProxy则不会对其应用切面进行方法的增强，返回源目标类型 else if (method.getDeclaringClass() == DecoratingProxy.class) &#123; return AopProxyUtils.ultimateTargetClass(this.advised); &#125; // 若目标对象实现的Advised接口，则不会对其应用切面进行方法的增强，直接执行方法 else if (!this.advised.opaque &amp;&amp; method.getDeclaringClass().isInterface() &amp;&amp; method.getDeclaringClass().isAssignableFrom(Advised.class)) &#123; return AopUtils.invokeJoinpointUsingReflection(this.advised, method, args); &#125; Object retVal; if (this.advised.exposeProxy) &#123; // 暴露代理对象到线程变量中 oldProxy = AopContext.setCurrentProxy(proxy); // 把代理对象暴露到线程变量中 setProxyContext = true; &#125; target = targetSource.getTarget(); // 获取目标对象 Class&lt;?&gt; targetClass = (target != null ? target.getClass() : null); // 获取目标对象的class // 把AOP的advisor全部转化为拦截器，通过责任链模式依次调用 List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass); if (chain.isEmpty()) &#123; // 若拦截器链为空，通过反射直接调用执行 Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args); retVal = AopUtils.invokeJoinpointUsingReflection(target, method, argsToUse); &#125; else &#123; // 创建一个方法调用对象 MethodInvocation invocation = new ReflectiveMethodInvocation(proxy, target, method, args, targetClass, chain); retVal = invocation.proceed(); // 调用执行 &#125; Class&lt;?&gt; returnType = method.getReturnType(); if (retVal != null &amp;&amp; retVal == target &amp;&amp; returnType != Object.class &amp;&amp; returnType.isInstance(proxy) &amp;&amp; !RawTargetAccess.class.isAssignableFrom(method.getDeclaringClass())) &#123; retVal = proxy; &#125; else if (retVal == null &amp;&amp; returnType != Void.TYPE &amp;&amp; returnType.isPrimitive()) &#123; throw new AopInvocationException(&quot;Null return value from advice does not match primitive return type for: &quot; + method); &#125; return retVal; &#125; finally &#123; if (target != null &amp;&amp; !targetSource.isStatic()) &#123; targetSource.releaseTarget(target); &#125; if (setProxyContext) &#123; AopContext.setCurrentProxy(oldProxy); &#125; &#125; &#125;&#125; Cglib动态代理后续调用逻辑与JDK动态代理是一样的 1234567891011121314151617181920212223242526272829303132333435class CglibAopProxy implements AopProxy, Serializable &#123; private static class DynamicAdvisedInterceptor implements MethodInterceptor, Serializable &#123; public Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) throws Throwable &#123; Object oldProxy = null; boolean setProxyContext = false; Object target = null; TargetSource targetSource = this.advised.getTargetSource(); try &#123; if (this.advised.exposeProxy) &#123; oldProxy = AopContext.setCurrentProxy(proxy); setProxyContext = true; &#125; target = targetSource.getTarget(); Class&lt;?&gt; targetClass = (target != null ? target.getClass() : null); List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass); Object retVal; if (chain.isEmpty() &amp;&amp; Modifier.isPublic(method.getModifiers())) &#123; Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args); retVal = methodProxy.invoke(target, argsToUse); &#125; else &#123; retVal = new CglibMethodInvocation(proxy, target, method, args, targetClass, chain, methodProxy).proceed(); &#125; retVal = processReturnType(proxy, target, method, retVal); return retVal; &#125; finally &#123; if (target != null &amp;&amp; !targetSource.isStatic()) &#123; targetSource.releaseTarget(target); &#125; if (setProxyContext) &#123; AopContext.setCurrentProxy(oldProxy); &#125; &#125; &#125; &#125;&#125; 其中的 this.advised.exposeProxy 判断是暴露代理对象到线程本地变量中，需搭配 @EnableAspectJAutoProxy(exposeProxy = true) 一起使用，若有两个方法init、transfer都被设置了代理，但在代理方法中通过 this 来调用另一个代理方法时，该方法不会被代理执行，这时就需要通过 AopContext.currentProxy() 来配合使用才能是该方法被代理执行，事务方法调用事务方法时就是这样来设置的。 1234567891011@Component@EnableAspectJAutoProxy(exposeProxy = true)public class Car implements CarSuper &#123; public void init() &#123; System.out.println(&quot;car init ...&quot;); ((CarSuper)AopContext.currentProxy()).transfer(); &#125; public void transfer() &#123; System.out.println(&quot;Car transfer...&quot;); &#125;&#125; 第一次调用代理方法时会将该方法与该类上的Advisor列表一一匹配，并将匹配到的Advisor转换成拦截器MethodInterceptor ，然后放入缓存，再次调用时直接从缓存中获取。 1234567891011public class AdvisedSupport extends ProxyConfig implements Advised &#123; public List&lt;Object&gt; getInterceptorsAndDynamicInterceptionAdvice(Method method, @Nullable Class&lt;?&gt; targetClass) &#123; MethodCacheKey cacheKey = new MethodCacheKey(method); List&lt;Object&gt; cached = this.methodCache.get(cacheKey); if (cached == null) &#123; cached = this.advisorChainFactory.getInterceptorsAndDynamicInterceptionAdvice(this, method, targetClass); this.methodCache.put(cacheKey, cached); &#125; return cached; &#125;&#125; Advisor中封装的Advice实现了 MethodInterceptor 拦截器，则直接强制类型转换，否则通过 AdvisorAdapter 进行转换。内置了 MethodBeforeAdviceAdapter 、 AfterReturningAdviceAdapter 、 ThrowsAdviceAdapter 三个适配器。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class DefaultAdvisorChainFactory implements AdvisorChainFactory, Serializable &#123; private final List&lt;AdvisorAdapter&gt; adapters = new ArrayList&lt;&gt;(3); public DefaultAdvisorAdapterRegistry() &#123; registerAdvisorAdapter(new MethodBeforeAdviceAdapter()); registerAdvisorAdapter(new AfterReturningAdviceAdapter()); registerAdvisorAdapter(new ThrowsAdviceAdapter()); &#125; public List&lt;Object&gt; getInterceptorsAndDynamicInterceptionAdvice(Advised config, Method method, @Nullable Class&lt;?&gt; targetClass) &#123; List&lt;Object&gt; interceptorList = new ArrayList&lt;Object&gt;(config.getAdvisors().length); Class&lt;?&gt; actualClass = (targetClass != null ? targetClass : method.getDeclaringClass()); boolean hasIntroductions = hasMatchingIntroductions(config, actualClass); AdvisorAdapterRegistry registry = GlobalAdvisorAdapterRegistry.getInstance(); for (Advisor advisor : config.getAdvisors()) &#123; if (advisor instanceof PointcutAdvisor) &#123; PointcutAdvisor pointcutAdvisor = (PointcutAdvisor) advisor; if (config.isPreFiltered() || pointcutAdvisor.getPointcut().getClassFilter().matches(actualClass)) &#123; MethodMatcher mm = pointcutAdvisor.getPointcut().getMethodMatcher(); if (MethodMatchers.matches(mm, method, actualClass, hasIntroductions)) &#123; MethodInterceptor[] interceptors = registry.getInterceptors(advisor); if (mm.isRuntime()) &#123; for (MethodInterceptor interceptor : interceptors) &#123; interceptorList.add(new InterceptorAndDynamicMethodMatcher(interceptor, mm)); &#125; &#125; else &#123; interceptorList.addAll(Arrays.asList(interceptors)); &#125; &#125; &#125; &#125; else if (advisor instanceof IntroductionAdvisor) &#123; IntroductionAdvisor ia = (IntroductionAdvisor) advisor; if (config.isPreFiltered() || ia.getClassFilter().matches(actualClass)) &#123; Interceptor[] interceptors = registry.getInterceptors(advisor); interceptorList.addAll(Arrays.asList(interceptors)); &#125; &#125; else &#123; Interceptor[] interceptors = registry.getInterceptors(advisor); interceptorList.addAll(Arrays.asList(interceptors)); &#125; &#125; return interceptorList; &#125; public MethodInterceptor[] getInterceptors(Advisor advisor) throws UnknownAdviceTypeException &#123; List&lt;MethodInterceptor&gt; interceptors = new ArrayList&lt;&gt;(3); Advice advice = advisor.getAdvice(); if (advice instanceof MethodInterceptor) &#123; interceptors.add((MethodInterceptor) advice); &#125; for (AdvisorAdapter adapter : this.adapters) &#123; if (adapter.supportsAdvice(advice)) &#123; interceptors.add(adapter.getInterceptor(advisor)); &#125; &#125; if (interceptors.isEmpty()) &#123; throw new UnknownAdviceTypeException(advisor.getAdvice()); &#125; return interceptors.toArray(new MethodInterceptor[0]); &#125;&#125; 内置的三个适配器实现都很简单，就是获取到具体的advice然后再转换成具体的拦截器。 1234567891011121314151617181920212223242526272829303132class AfterReturningAdviceAdapter implements AdvisorAdapter, Serializable &#123; @Override public boolean supportsAdvice(Advice advice) &#123; return (advice instanceof AfterReturningAdvice); &#125; @Override public MethodInterceptor getInterceptor(Advisor advisor) &#123; AfterReturningAdvice advice = (AfterReturningAdvice) advisor.getAdvice(); return new AfterReturningAdviceInterceptor(advice); &#125;&#125;class MethodBeforeAdviceAdapter implements AdvisorAdapter, Serializable &#123; @Override public boolean supportsAdvice(Advice advice) &#123; return (advice instanceof MethodBeforeAdvice); &#125; @Override public MethodInterceptor getInterceptor(Advisor advisor) &#123; MethodBeforeAdvice advice = (MethodBeforeAdvice) advisor.getAdvice(); return new MethodBeforeAdviceInterceptor(advice); &#125;&#125;class ThrowsAdviceAdapter implements AdvisorAdapter, Serializable &#123; @Override public boolean supportsAdvice(Advice advice) &#123; return (advice instanceof ThrowsAdvice); &#125; @Override public MethodInterceptor getInterceptor(Advisor advisor) &#123; return new ThrowsAdviceInterceptor(advisor.getAdvice()); &#125;&#125; 最终将匹配到的拦截器链以及目标方法等信息包装为 ReflectiveMethodInvocation 执行它的 proceed 方法，这里的 invokeJoinpoint() 就是调用连接点即被代理的方法本身。 1234567891011121314151617181920212223public class ReflectiveMethodInvocation implements ProxyMethodInvocation, Cloneable &#123; public Object proceed() throws Throwable &#123; // 从-1开始，结束条件执行目标方法是下标=拦截器的长度-1，即执行到最后一个拦截器时 if (this.currentInterceptorIndex == this.interceptorsAndDynamicMethodMatchers.size() - 1) &#123; return invokeJoinpoint(); // 当执行到最后一个拦截器的时候才会进入 &#125; // 获取集合当前需要运行的拦截器 Object interceptorOrInterceptionAdvice = this.interceptorsAndDynamicMethodMatchers.get(++this.currentInterceptorIndex); if (interceptorOrInterceptionAdvice instanceof InterceptorAndDynamicMethodMatcher) &#123; InterceptorAndDynamicMethodMatcher dm = (InterceptorAndDynamicMethodMatcher) interceptorOrInterceptionAdvice; if (dm.methodMatcher.matches(this.method, this.targetClass, this.arguments)) &#123; return dm.interceptor.invoke(this); &#125; else &#123; return proceed(); &#125; &#125; else &#123;// 执行拦截器方法 return ((MethodInterceptor) interceptorOrInterceptionAdvice).invoke(this); &#125; &#125; protected Object invokeJoinpoint() throws Throwable &#123; return AopUtils.invokeJoinpointUsingReflection(this.target, this.method, this.arguments); &#125;&#125; 首先调用 ExposeInvocationInterceptor ，一般AOP代理时都会创建一个，然后加入到列表头部， mi.proceed() 又回到了 ReflectiveMethodInvocation 中。 1234567891011public class ExposeInvocationInterceptor implements MethodInterceptor, PriorityOrdered, Serializable &#123; public Object invoke(MethodInvocation mi) throws Throwable &#123; MethodInvocation oldInvocation = invocation.get(); invocation.set(mi); // 记录当前正在执行的拦截器 try &#123; return mi.proceed(); &#125; finally &#123; invocation.set(oldInvocation); &#125; &#125;&#125; 异常通知 AspectJAfterThrowingAdvice 12345678910111213public class AspectJAfterThrowingAdvice extends AbstractAspectJAdvice implements MethodInterceptor, AfterAdvice, Serializable &#123; public Object invoke(MethodInvocation mi) throws Throwable &#123; try &#123; return mi.proceed(); &#125; catch (Throwable ex) &#123; Method handlerMethod = getExceptionHandler(ex); if (handlerMethod != null) &#123; invokeHandlerMethod(mi, ex, handlerMethod); &#125; throw ex; &#125; &#125;&#125; 前置通知 MethodBeforeAdviceInterceptor 123456public class MethodBeforeAdviceInterceptor implements MethodInterceptor, BeforeAdvice, Serializable &#123; public Object invoke(MethodInvocation mi) throws Throwable &#123; this.advice.before(mi.getMethod(), mi.getArguments(), mi.getThis()); return mi.proceed(); &#125;&#125; 返回通知 AfterReturningAdviceInterceptor 1234567public class AfterReturningAdviceInterceptor implements MethodInterceptor, AfterAdvice, Serializable &#123; public Object invoke(MethodInvocation mi) throws Throwable &#123; Object retVal = mi.proceed(); this.advice.afterReturning(retVal, mi.getMethod(), mi.getArguments(), mi.getThis()); return retVal; &#125;&#125; 后置 AspectJAfterAdvice 123456789public class AspectJAfterAdvice extends AbstractAspectJAdvice implements MethodInterceptor, AfterAdvice, Serializable &#123; public Object invoke(MethodInvocation mi) throws Throwable &#123; try &#123; return mi.proceed(); &#125; finally &#123; invokeAdviceMethod(getJoinPointMatch(), null, null); &#125; &#125;&#125; 环绕通知 AspectJAroundAdvice 1234567891011public class AspectJAroundAdvice extends AbstractAspectJAdvice implements MethodInterceptor, Serializable &#123; public Object invoke(MethodInvocation mi) throws Throwable &#123; if (!(mi instanceof ProxyMethodInvocation)) &#123; throw new IllegalStateException(&quot;MethodInvocation is not a Spring ProxyMethodInvocation: &quot; + mi); &#125; ProxyMethodInvocation pmi = (ProxyMethodInvocation) mi; ProceedingJoinPoint pjp = lazyGetProceedingJoinPoint(pmi); JoinPointMatch jpm = getJoinPointMatch(pmi); return invokeAdviceMethod(pjp, jpm, null, null); &#125;&#125;","tags":[{"name":"Spring, AOP","slug":"Spring-AOP","permalink":"http://example.com/tags/Spring-AOP/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}]},{"title":"AOP切面类解析","date":"2020-10-16T03:08:20.000Z","path":"blog/Spring/AOP切面类解析/","text":"Spring AOP是通过给一个类加上 @Aspect注解来定义一个切面类，定义一个 Pointcut 方法，最后定义一系列的增强方法，这样就完成一个对象的切面操作。 通过 @EnableAspectJAutoProxy注解开启AOP切面，该注解类上 @Import(AspectJAutoProxyRegistrar.class) 注解中 AspectJAutoProxyRegistrar 实现了 ImportBeanDefinitionRegistrar ，其会通过 registerBeanDefinitions 方法为容器导入为Bean创建代理 beanName 为 internalAutoProxyCreator 的关键 beanDefinition 。type为 AnnotationAwareAspectJAutoProxyCreator 。 @Import 中 ImportBeanDefinitionRegistrar 接口 registerBeanDefinitions 方法调用时机是在 invokeBeanFactoryPostProcessors 的 invokeBeanFactoryPostProcessors 中解析完配置类后调用 ConfigurationClassBeanDefinitionReader 的 loadBeanDefinitions 方法，即在Bean实例化之前。 123456789101112131415161718class AspectJAutoProxyRegistrar implements ImportBeanDefinitionRegistrar &#123; @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; // 注册名字internalAutoProxyCreator的AnnotationAwareAspectJAutoProxyCreator AopConfigUtils.registerAspectJAnnotationAutoProxyCreatorIfNecessary(registry); // 获得注解的属性 AnnotationAttributes enableAspectJAutoProxy = AnnotationConfigUtils.attributesFor(importingClassMetadata, EnableAspectJAutoProxy.class); // 根据其中的proxyTargetClass/exposeProxy设置beanDefinition属性 if (enableAspectJAutoProxy != null) &#123; if (enableAspectJAutoProxy.getBoolean(&quot;proxyTargetClass&quot;)) &#123; AopConfigUtils.forceAutoProxyCreatorToUseClassProxying(registry); &#125; if (enableAspectJAutoProxy.getBoolean(&quot;exposeProxy&quot;)) &#123; AopConfigUtils.forceAutoProxyCreatorToExposeProxy(registry); &#125; &#125; &#125;&#125; 12345678910111213141516171819202122232425262728public abstract class AopConfigUtils &#123; public static BeanDefinition registerAspectJAnnotationAutoProxyCreatorIfNecessary(BeanDefinitionRegistry registry) &#123; return registerAspectJAnnotationAutoProxyCreatorIfNecessary(registry, null); &#125; public static BeanDefinition registerAspectJAnnotationAutoProxyCreatorIfNecessary(BeanDefinitionRegistry registry, @Nullable Object source) &#123; return registerOrEscalateApcAsRequired(AnnotationAwareAspectJAutoProxyCreator.class, registry, source); &#125; private static BeanDefinition registerOrEscalateApcAsRequired(Class&lt;?&gt; cls, BeanDefinitionRegistry registry, @Nullable Object source) &#123; Assert.notNull(registry, &quot;BeanDefinitionRegistry must not be null&quot;); if (registry.containsBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME)) &#123; BeanDefinition apcDefinition = registry.getBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME); if (!cls.getName().equals(apcDefinition.getBeanClassName())) &#123; int currentPriority = findPriorityForClass(apcDefinition.getBeanClassName()); int requiredPriority = findPriorityForClass(cls); if (currentPriority &lt; requiredPriority) &#123; apcDefinition.setBeanClassName(cls.getName()); &#125; &#125; return null; &#125; RootBeanDefinition beanDefinition = new RootBeanDefinition(cls); beanDefinition.setSource(source); beanDefinition.getPropertyValues().add(&quot;order&quot;, Ordered.HIGHEST_PRECEDENCE); beanDefinition.setRole(BeanDefinition.ROLE_INFRASTRUCTURE); registry.registerBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME, beanDefinition); return beanDefinition; &#125;&#125; 在 finishBeanFactoryInitialization第一个Bean创建时通过 resolveBeforeInstantiation第一次调用后置处理器时，调用 AnnotationAwareAspectJAutoProxyCreator 超类 AbstractAutoProxyCreator 中的 postProcessBeforeInstantiation 方法时，对所有的AOP切面类进行解析并将解析后的 Advisors列表缓存。 12345678910111213141516171819202122232425262728public abstract class AbstractAutoProxyCreator extends ProxyProcessorSupport implements SmartInstantiationAwareBeanPostProcessor, BeanFactoryAware &#123; public Object postProcessBeforeInstantiation(Class&lt;?&gt; beanClass, String beanName) throws BeansException &#123; Object cacheKey = getCacheKey(beanClass, beanName); // 构建缓存key // 没有beanName或没有包含在targetSourcedBeans中，一般都不会包含，因为targetSource需要手动设置，一般情况不会设置 if (!StringUtils.hasLength(beanName) || !this.targetSourcedBeans.contains(beanName)) &#123; if (this.advisedBeans.containsKey(cacheKey)) &#123; // 被解析过 直接返回 return null; &#125; // 判断是不是基础的bean即是不是切面类、通知、切点等，判断是不是应该跳过 默认false，切面解析也在其中 if (isInfrastructureClass(beanClass) || shouldSkip(beanClass, beanName)) &#123; this.advisedBeans.put(cacheKey, Boolean.FALSE); return null; &#125; &#125; // TargetSource代理逻辑的实现，在创建代理时默认是SingletonTargetSource，故若指定了TargetSource说明有自己的代理逻辑实现，在这就直接创建代理 TargetSource targetSource = getCustomTargetSource(beanClass, beanName); if (targetSource != null) &#123; if (StringUtils.hasLength(beanName)) &#123; this.targetSourcedBeans.add(beanName); &#125; Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(beanClass, beanName, targetSource); Object proxy = createProxy(beanClass, beanName, specificInterceptors, targetSource); this.proxyTypes.put(cacheKey, proxy.getClass()); return proxy; &#125; return null; &#125;&#125; 通过 isInfrastructureClass 判断该类是否是切面类、通知、切点等，判断逻辑就是判断当前正在创建的类是否为 Advice 、 Pointcut 、 Advisor 、 AopInfrastructureBean 的子类，若是则直接跳过解析。或若该类上有 @Aspect注解且不是一个被 AspectJ编译过的类也跳过解析。 123456789101112131415161718192021222324252627public class AnnotationAwareAspectJAutoProxyCreator extends AspectJAwareAdvisorAutoProxyCreator &#123; protected boolean isInfrastructureClass(Class&lt;?&gt; beanClass) &#123; return (super.isInfrastructureClass(beanClass) || (this.aspectJAdvisorFactory != null &amp;&amp; this.aspectJAdvisorFactory.isAspect(beanClass))); &#125;&#125;public abstract class AbstractAutoProxyCreator extends ProxyProcessorSupport implements SmartInstantiationAwareBeanPostProcessor, BeanFactoryAware &#123; private static final String AJC_MAGIC = &quot;ajc$&quot;; protected boolean isInfrastructureClass(Class&lt;?&gt; beanClass) &#123; // 若当前正在创建的Bean的class是Advice PointCut Advisor AopInfrastructureBean，直接跳过不需要解析 boolean retVal = Advice.class.isAssignableFrom(beanClass) || Pointcut.class.isAssignableFrom(beanClass) || Advisor.class.isAssignableFrom(beanClass) || AopInfrastructureBean.class.isAssignableFrom(beanClass); return retVal; &#125; public boolean isAspect(Class&lt;?&gt; clazz) &#123; // 有没有切面注解 &amp;&amp; 没有被AspectJ编译过 return (hasAspectAnnotation(clazz) &amp;&amp; !compiledByAjc(clazz)); &#125; private boolean hasAspectAnnotation(Class&lt;?&gt; clazz) &#123; return (AnnotationUtils.findAnnotation(clazz, Aspect.class) != null); &#125; private boolean compiledByAjc(Class&lt;?&gt; clazz) &#123; for (Field field : clazz.getDeclaredFields()) &#123; if (field.getName().startsWith(AJC_MAGIC)) &#123; return true; // 至少一个属性前缀为&quot;ajc$&quot; &#125; &#125; return false; &#125;&#125; shouldSkip 中的 findCandidateAdvisors() 会解析出所有的 Advisor ，这里的 AspectJPointcutAdvisor 是 xml 中advisor解析的对象，若aspect是当前beanName就说明当前bean是切面类则跳过。 123456789101112public class AspectJAwareAdvisorAutoProxyCreator extends AbstractAdvisorAutoProxyCreator &#123; protected boolean shouldSkip(Class&lt;?&gt; beanClass, String beanName) &#123; List&lt;Advisor&gt; candidateAdvisors = findCandidateAdvisors(); // 找到所有定义的候选Advisors for (Advisor advisor : candidateAdvisors) &#123; // AspectJPointcutAdvisor是xml&lt;aop:advisor解析的对象，若&lt;aop:aspect ref=&quot;beanName&quot;&gt;是当前beanName就说明当前bean是切面类则跳过。 if (advisor instanceof AspectJPointcutAdvisor &amp;&amp; ((AspectJPointcutAdvisor) advisor).getAspectName().equals(beanName)) &#123; return true; &#125; &#125; return super.shouldSkip(beanClass, beanName); &#125;&#125; 通过 buildAspectJAdvisors 去容器中获取所有切面信息保存到缓存中。 12345678910public class AnnotationAwareAspectJAutoProxyCreator extends AspectJAwareAdvisorAutoProxyCreator &#123; protected List&lt;Advisor&gt; findCandidateAdvisors() &#123; // 找出xml配置的Advisor、原生接口的AOP的Advisor、事务相关的advisor List&lt;Advisor&gt; advisors = super.findCandidateAdvisors(); if (this.aspectJAdvisorsBuilder != null) &#123; // 找出Aspect相关的信息之后封装为一个advisor advisors.addAll(this.aspectJAdvisorsBuilder.buildAspectJAdvisors()); &#125; return advisors; // 返回所有的通知 &#125;&#125; 关于 advisorRetrievalHelper 的初始化， AbstractAdvisorAutoProxyCreator 的父类 AbstractAutoProxyCreator 实现了 BeanFactoryAware 接口，而 AbstractAutoProxyCreator 是事务和 AOP 导入进来的后置处理器的顶级父类，在实例化AOP 和事务导入组件时会调用setBeanFactory的方法来注入Bean工厂，调用setBeanFactory会触发 initBeanFactory 的调用来实例化通知查找探测器。 1234567891011121314151617public abstract class AbstractAdvisorAutoProxyCreator extends AbstractAutoProxyCreator &#123; private BeanFactoryAdvisorRetrievalHelper advisorRetrievalHelper; protected List&lt;Advisor&gt; findCandidateAdvisors() &#123; // 通过通知者探测器帮助找到通知 Assert.state(this.advisorRetrievalHelper != null, &quot;No BeanFactoryAdvisorRetrievalHelper available&quot;); return this.advisorRetrievalHelper.findAdvisorBeans(); &#125; public void setBeanFactory(BeanFactory beanFactory) &#123; super.setBeanFactory(beanFactory); if (!(beanFactory instanceof ConfigurableListableBeanFactory)) &#123; throw new IllegalArgumentException(&quot;AdvisorAutoProxyCreator requires a ConfigurableListableBeanFactory: &quot; + beanFactory); &#125; initBeanFactory((ConfigurableListableBeanFactory) beanFactory); &#125; protected void initBeanFactory(ConfigurableListableBeanFactory beanFactory) &#123; this.advisorRetrievalHelper = new BeanFactoryAdvisorRetrievalHelperAdapter(beanFactory); &#125;&#125; 探测器字段 cachedAdvisorBeanNames 是用来缓存Advisor全类名，在第一个单实例bean实例化过程中把所有的advisor名称解析出来，若 cachedAdvisorBeanNames 为空则先获取容器中所有实现了Advisor接口的实现类，典型为事务注解@EnableTransactionManagement 导入 ProxyTransactionManagementConfiguration 配置类。 1234567891011121314151617181920212223242526272829303132333435public class BeanFactoryAdvisorRetrievalHelper &#123; public List&lt;Advisor&gt; findAdvisorBeans() &#123; // 探测器字段cachedAdvisorBeanNames是用来缓存Advisor全类名，在第一个单实例bean实例化过程中把该advisor名称解析出来 String[] advisorNames = this.cachedAdvisorBeanNames; if (advisorNames == null) &#123; advisorNames = BeanFactoryUtils.beanNamesForTypeIncludingAncestors(this.beanFactory, Advisor.class, true, false); this.cachedAdvisorBeanNames = advisorNames; &#125; if (advisorNames.length == 0) &#123; // 若在容器中没有找到，直接返回一个空的集合 return new ArrayList&lt;&gt;(); &#125; List&lt;Advisor&gt; advisors = new ArrayList&lt;&gt;(); for (String name : advisorNames) &#123; // 容器中找到了配置的BeanFactoryTransactionAttributeSourceAdvisor if (isEligibleBean(name)) &#123; // 判断其是不是一个合适的 if (this.beanFactory.isCurrentlyInCreation(name)) &#123; // BeanFactoryTransactionAttributeSourceAdvisor是不是正在创建的bean &#125; else &#123; // 不是的话 try &#123; //显示的调用getBean方法方法创建BeanFactoryTransactionAttributeSourceAdvisor返回去 advisors.add(this.beanFactory.getBean(name, Advisor.class)); &#125; catch (BeanCreationException ex) &#123; Throwable rootCause = ex.getMostSpecificCause(); if (rootCause instanceof BeanCurrentlyInCreationException) &#123; BeanCreationException bce = (BeanCreationException) rootCause; String bceBeanName = bce.getBeanName(); if (bceBeanName != null &amp;&amp; this.beanFactory.isCurrentlyInCreation(bceBeanName)) &#123; continue; &#125; &#125; throw ex; &#125; &#125; &#125; &#125; return advisors; &#125;&#125; 缓存字段 aspectNames 没有值，会在 AnnotationAwareAspectJAutoProxyCreator 注册之后，第一个单例执行后置处理器时触发解析切面的操作。这里获取的是Object类型的Bean的名称即获取所有的Bean。遍历解析Advisor的过程十分耗性能，解析后会加入了保存切面信息的缓存，事务模块的功能是直接去容器中获取Advisor类型的，选择范围小，且不消耗性能，故事务模块中没有加入缓存来保存事务相关的advisor。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public List&lt;Advisor&gt; buildAspectJAdvisors() &#123; // 用于保存切面的名称，该aspectNames是类级别的缓存，缓存已解析出的切面信息 List&lt;String&gt; aspectNames = this.aspectBeanNames; if (aspectNames == null) &#123; synchronized (this) &#123; // 加上同步锁， 防止多线程同时加载Aspect aspectNames = this.aspectBeanNames; if (aspectNames == null) &#123; // 双重检查加锁 List&lt;Advisor&gt; advisors = new ArrayList&lt;&gt;(); // 保存所有通知的集合 aspectNames = new ArrayList&lt;&gt;(); // 保存切面的名称的集合 // 从容器中获取所有Bean，再遍历，该过程十分耗性能，解析后会加入了保存切面信息的缓存 String[] beanNames = BeanFactoryUtils.beanNamesForTypeIncludingAncestors(this.beanFactory, Object.class, true, false); for (String beanName : beanNames) &#123; // 遍历从IOC容器中获取的所有bean的名称 if (!isEligibleBean(beanName)) continue; Class&lt;?&gt; beanType = this.beanFactory.getType(beanName); // 通过beanName去容器中获取到对应class对象 if (beanType == null) continue; if (this.advisorFactory.isAspect(beanType)) &#123; // 根据class对象判断是不是切面 aspectNames.add(beanName); // 是切面类，加入到缓存中 // 把beanName和class对象构建成为一个AspectMetadata AspectMetadata amd = new AspectMetadata(beanType, beanName); if (amd.getAjType().getPerClause().getKind() == PerClauseKind.SINGLETON) &#123; //构建切面注解的实例工厂 MetadataAwareAspectInstanceFactory factory = new BeanFactoryAspectInstanceFactory(this.beanFactory, beanName); // 真正的去获取通知对象 List&lt;Advisor&gt; classAdvisors = this.advisorFactory.getAdvisors(factory); if (this.beanFactory.isSingleton(beanName)) &#123; // 加入到缓存中 this.advisorsCache.put(beanName, classAdvisors); &#125; else &#123; this.aspectFactoryCache.put(beanName, factory); &#125; advisors.addAll(classAdvisors); &#125; else &#123; if (this.beanFactory.isSingleton(beanName)) &#123; throw new IllegalArgumentException(&quot;Bean with name &#x27;&quot; + beanName + &quot;&#x27; is a singleton, but aspect instantiation model is not singleton&quot;); &#125; MetadataAwareAspectInstanceFactory factory = new PrototypeAspectInstanceFactory(this.beanFactory, beanName); this.aspectFactoryCache.put(beanName, factory); advisors.addAll(this.advisorFactory.getAdvisors(factory)); &#125; &#125; &#125; this.aspectBeanNames = aspectNames; return advisors; &#125; &#125; &#125; if (aspectNames.isEmpty()) &#123; return Collections.emptyList(); &#125; // 真正的创建切面的时候，我们不需要去解析了而是直接去缓存中获取处 List&lt;Advisor&gt; advisors = new ArrayList&lt;&gt;(); for (String aspectName : aspectNames) &#123; List&lt;Advisor&gt; cachedAdvisors = this.advisorsCache.get(aspectName); if (cachedAdvisors != null) &#123; advisors.addAll(cachedAdvisors); &#125; else &#123; MetadataAwareAspectInstanceFactory factory = this.aspectFactoryCache.get(aspectName); advisors.addAll(this.advisorFactory.getAdvisors(factory)); &#125; &#125; return advisors;&#125; 遍历切面类中的所有除了被 @Pointcut 注解标注的方法，并将满足条件的每个方法都封装成一个Advisor 。这里 getAdvisorMethods 方法中对所有获取到的切面方法按照 Around 、 Before 、 After 、 AfterReturning 、 AfterThrowing 的顺序进行了排序。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public class ReflectiveAspectJAdvisorFactory extends AbstractAspectJAdvisorFactory implements Serializable &#123; public List&lt;Advisor&gt; getAdvisors(MetadataAwareAspectInstanceFactory aspectInstanceFactory) &#123; Class&lt;?&gt; aspectClass = aspectInstanceFactory.getAspectMetadata().getAspectClass(); // 获取标记为Aspect的类 String aspectName = aspectInstanceFactory.getAspectMetadata().getAspectName(); // 获取切面类的名称 validate(aspectClass); // 校验切面类 // 使用包装模式来包装MetadataAwareAspectInstanceFactory构建为MetadataAwareAspectInstanceFactory MetadataAwareAspectInstanceFactory lazySingletonAspectInstanceFactory = new LazySingletonAspectInstanceFactoryDecorator(aspectInstanceFactory); List&lt;Advisor&gt; advisors = new ArrayList&lt;&gt;(); // 获取到切面类中的所有方法，但是该方法不会解析标注了@PointCut注解的方法 for (Method method : getAdvisorMethods(aspectClass)) &#123; // 挨个去解析切面中的方法 Advisor advisor = getAdvisor(method, lazySingletonAspectInstanceFactory, advisors.size(), aspectName); if (advisor != null) &#123; advisors.add(advisor); &#125; &#125; if (!advisors.isEmpty() &amp;&amp; lazySingletonAspectInstanceFactory.getAspectMetadata().isLazilyInstantiated()) &#123; Advisor instantiationAdvisor = new SyntheticInstantiationAdvisor(lazySingletonAspectInstanceFactory); advisors.add(0, instantiationAdvisor); &#125; for (Field field : aspectClass.getDeclaredFields()) &#123; Advisor advisor = getDeclareParentsAdvisor(field); if (advisor != null) &#123; advisors.add(advisor); &#125; &#125; return advisors; &#125; public Advisor getAdvisor(Method candidateAdviceMethod, MetadataAwareAspectInstanceFactory aspectInstanceFactory, int declarationOrderInAspect, String aspectName) &#123; validate(aspectInstanceFactory.getAspectMetadata().getAspectClass()); // 获得当前通知的切点表达式 AspectJExpressionPointcut expressionPointcut = getPointcut(candidateAdviceMethod, aspectInstanceFactory.getAspectMetadata().getAspectClass()); if (expressionPointcut == null) &#123; return null; &#125; // 将切点表达式和通知封装到InstantiationModelAwarePointcutAdvisorImpl对象中 return new InstantiationModelAwarePointcutAdvisorImpl(expressionPointcut, candidateAdviceMethod, this, aspectInstanceFactory, declarationOrderInAspect, aspectName); &#125; private AspectJExpressionPointcut getPointcut(Method candidateAdviceMethod, Class&lt;?&gt; candidateAspectClass) &#123; // 找到aspectJ的注解：@Pointcut、@Around、@Before、@After、@AfterReturning、@AfterThrowing AspectJAnnotation&lt;?&gt; aspectJAnnotation = AbstractAspectJAdvisorFactory.findAspectJAnnotationOnMethod(candidateAdviceMethod); if (aspectJAnnotation == null) &#123; // 没有注解直接忽略 return null; &#125; AspectJExpressionPointcut ajexp = new AspectJExpressionPointcut(candidateAspectClass, new String[0], new Class&lt;?&gt;[0]); ajexp.setExpression(aspectJAnnotation.getPointcutExpression()); if (this.beanFactory != null) &#123; ajexp.setBeanFactory(this.beanFactory); &#125; return ajexp; &#125; private List&lt;Method&gt; getAdvisorMethods(Class&lt;?&gt; aspectClass) &#123; final List&lt;Method&gt; methods = new ArrayList&lt;&gt;(); ReflectionUtils.doWithMethods(aspectClass, method -&gt; &#123; if (AnnotationUtils.getAnnotation(method, Pointcut.class) == null) &#123; methods.add(method); &#125; &#125;); methods.sort(METHOD_COMPARATOR); return methods; &#125; private static final Comparator&lt;Method&gt; METHOD_COMPARATOR; static &#123; Comparator&lt;Method&gt; adviceKindComparator = new ConvertingComparator&lt;&gt;( new InstanceComparator&lt;&gt;(Around.class, Before.class, After.class, AfterReturning.class, AfterThrowing.class), (Converter&lt;Method, Annotation&gt;) method -&gt; &#123; AspectJAnnotation&lt;?&gt; annotation = AbstractAspectJAdvisorFactory.findAspectJAnnotationOnMethod(method); return (annotation != null ? annotation.getAnnotation() : null); &#125;); Comparator&lt;Method&gt; methodNameComparator = new ConvertingComparator&lt;&gt;(Method::getName); METHOD_COMPARATOR = adviceKindComparator.thenComparing(methodNameComparator); &#125;&#125; 找到方法上是否有 @Pointcut 、 @Around 、 @Before 、 @After 、 @AfterReturning 、 @AfterThrowing 等注解，并获取到注解上切面表达式。 123456789101112public abstract class AbstractAspectJAdvisorFactory implements AspectJAdvisorFactory &#123; private static final Class&lt;?&gt;[] ASPECTJ_ANNOTATION_CLASSES = new Class&lt;?&gt;[] &#123;Pointcut.class, Around.class, Before.class, After.class, AfterReturning.class, AfterThrowing.class&#125;; protected static AspectJAnnotation&lt;?&gt; findAspectJAnnotationOnMethod(Method method) &#123; for (Class&lt;?&gt; clazz : ASPECTJ_ANNOTATION_CLASSES) &#123; AspectJAnnotation&lt;?&gt; foundAnnotation = findAnnotation(method, (Class&lt;Annotation&gt;) clazz); if (foundAnnotation != null) &#123; return foundAnnotation; &#125; &#125; return null; &#125;&#125; 通过 InstantiationModelAwarePointcutAdvisorImpl 的 instantiateAdvice 方法将不同类型的注解方法解析成对应的Advice。 12345678910111213141516171819202122232425262728class InstantiationModelAwarePointcutAdvisorImpl implements InstantiationModelAwarePointcutAdvisor, AspectJPrecedenceInformation, Serializable &#123; public InstantiationModelAwarePointcutAdvisorImpl(AspectJExpressionPointcut declaredPointcut, Method aspectJAdviceMethod, AspectJAdvisorFactory aspectJAdvisorFactory, MetadataAwareAspectInstanceFactory aspectInstanceFactory, int declarationOrder, String aspectName) &#123; this.declaredPointcut = declaredPointcut;// 当前的切点 this.declaringClass = aspectJAdviceMethod.getDeclaringClass();// 切面的class对象 this.methodName = aspectJAdviceMethod.getName();// 切面方法的名称 this.parameterTypes = aspectJAdviceMethod.getParameterTypes();// 切面方法的参数类型 this.aspectJAdviceMethod = aspectJAdviceMethod;// 切面方法对象 this.aspectJAdvisorFactory = aspectJAdvisorFactory;// aspectj的通知工厂 this.aspectInstanceFactory = aspectInstanceFactory;// aspect的实例工厂 this.declarationOrder = declarationOrder;// 切面的顺序 this.aspectName = aspectName;// 切面的名称 // 判断当前的切面对象是否需要延时加载 if (aspectInstanceFactory.getAspectMetadata().isLazilyInstantiated()) &#123; Pointcut preInstantiationPointcut = Pointcuts.union(aspectInstanceFactory.getAspectMetadata().getPerClausePointcut(), this.declaredPointcut); this.pointcut = new PerTargetInstantiationModelPointcut(this.declaredPointcut, preInstantiationPointcut, aspectInstanceFactory); this.lazy = true; &#125; else &#123; this.pointcut = this.declaredPointcut; this.lazy = false; // 把切面中的通知构造为一个一个的advice通知对象 this.instantiatedAdvice = instantiateAdvice(this.declaredPointcut); &#125; &#125; private Advice instantiateAdvice(AspectJExpressionPointcut pointcut) &#123; Advice advice = this.aspectJAdvisorFactory.getAdvice(this.aspectJAdviceMethod, pointcut, this.aspectInstanceFactory, this.declarationOrder, this.aspectName); return (advice != null ? advice : EMPTY_ADVICE); &#125;&#125; 在 instantiateAdvice 方法中调用 getAdvice 方法根据不同类型的注解生成对应的 Advice 。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class ReflectiveAspectJAdvisorFactory extends AbstractAspectJAdvisorFactory implements Serializable &#123; public Advice getAdvice(Method candidateAdviceMethod, AspectJExpressionPointcut expressionPointcut, MetadataAwareAspectInstanceFactory aspectInstanceFactory, int declarationOrder, String aspectName) &#123; // 获取切面类的class对象 Class&lt;?&gt; candidateAspectClass = aspectInstanceFactory.getAspectMetadata().getAspectClass(); validate(candidateAspectClass); // 获取切面方法上的注解 AspectJAnnotation&lt;?&gt; aspectJAnnotation = AbstractAspectJAdvisorFactory.findAspectJAnnotationOnMethod(candidateAdviceMethod); if (aspectJAnnotation == null) &#123; // 解析出来的注解信息是否为null return null; &#125; if (!isAspect(candidateAspectClass)) &#123; // 判断这里的class对象是不是切面信息对象 throw new AopConfigException(&quot;Advice must be declared inside an aspect type: Offending method &#x27;&quot; + candidateAdviceMethod + &quot;&#x27; in class [&quot; + candidateAspectClass.getName() + &quot;]&quot;); &#125; AbstractAspectJAdvice springAdvice; switch (aspectJAnnotation.getAnnotationType()) &#123; // 判断标注在方法上的注解类型 case AtPointcut: // 是PointCut注解则抛出异常，在外面传递进来的方法已经排除了pointcut的方法 return null; case AtAround: //环绕通知 构建AspectJAroundAdvice springAdvice = new AspectJAroundAdvice(candidateAdviceMethod, expressionPointcut, aspectInstanceFactory); break; case AtBefore: //前置通知 构建AspectJMethodBeforeAdvice springAdvice = new AspectJMethodBeforeAdvice(candidateAdviceMethod, expressionPointcut, aspectInstanceFactory); break; case AtAfter: //后置通知 AspectJAfterAdvice springAdvice = new AspectJAfterAdvice(candidateAdviceMethod, expressionPointcut, aspectInstanceFactory); break; case AtAfterReturning: //返回通知 AspectJAfterReturningAdvice springAdvice = new AspectJAfterReturningAdvice(candidateAdviceMethod, expressionPointcut, aspectInstanceFactory); AfterReturning afterReturningAnnotation = (AfterReturning) aspectJAnnotation.getAnnotation(); if (StringUtils.hasText(afterReturningAnnotation.returning())) &#123; springAdvice.setReturningName(afterReturningAnnotation.returning()); &#125; break; case AtAfterThrowing: //异常通知 AspectJAfterThrowingAdvice springAdvice = new AspectJAfterThrowingAdvice(candidateAdviceMethod, expressionPointcut, aspectInstanceFactory); AfterThrowing afterThrowingAnnotation = (AfterThrowing) aspectJAnnotation.getAnnotation(); if (StringUtils.hasText(afterThrowingAnnotation.throwing())) &#123; springAdvice.setThrowingName(afterThrowingAnnotation.throwing()); &#125; break; default: throw new UnsupportedOperationException(&quot;Unsupported advice type on method: &quot; + candidateAdviceMethod); &#125; springAdvice.setAspectName(aspectName); // 配置构建出来的通知对象 springAdvice.setDeclarationOrder(declarationOrder); String[] argNames = this.parameterNameDiscoverer.getParameterNames(candidateAdviceMethod); if (argNames != null) &#123; springAdvice.setArgumentNamesFromStringArray(argNames); &#125; springAdvice.calculateArgumentBindings(); return springAdvice; &#125;&#125;","tags":[{"name":"Spring, AOP","slug":"Spring-AOP","permalink":"http://example.com/tags/Spring-AOP/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}]},{"title":"Spring整体架构","date":"2020-10-15T07:08:20.000Z","path":"blog/Spring/Spring整体架构/","text":"Spring子项目Spring Framework（core）包含一系列Ioc容器的设计，提供了依赖反转的实现，集成了AOP，还包含了MVC、JDBC、事务处理模块的实现。 Spring Web Flow定义了一种特定的语言来描述工作流，同时高级的工作流控制引擎可以管理会话状态，支持AJAX来构建丰富的客户端体验，并提供JSF支持。其实际上是构建在Spring MVC的基础上的，相对于Spring Framework（core）独立发展的。 Spring BlazeDS Integration提供Spring于Adobe Flex技术集成的模块。 Spring Security基于Spring的认证和安全工具。 Spring Security OAuth为OAuth在Spring上集成提供支持，OAuth是一个第三方模块，提供一个开放协议的实现，通过改协议，前端桌面应用可以对Web应用进行简单而标准的安全调用。 Spring Dynamic Modules可以让Spring运行在OSGi平台上。 Spring Batch提供构建批处理应用和自动化操作的框架。 Spring Integration为企业数据集成提供了各种适配器，通过这些适配器来转换各种消息格式，并帮助Spring应用完成与企业应用系统的集成。 Spring AMQP为Spring应用更好地使用基于AMQP（高级消息队列协议）的消息服务而开发。 Spring Data为Spring应用提供使用关系型数据的能力。 Spring设计目标​ 为开发者提供的是一个一站式的轻量级应用开发框架。其抽象了许多应用开发中遇到的共性问题。支持POJO和使用JavaBean的开发方式，使应用面向接口开发，充分支持OO（面向对象）的设计方法，使开发的入门、测试、应用部署都得到简化。 ​ 通过使用Spring的IoC容器，可以对应用开发中复杂的对象耦合关系实现一个文本化、外部化的工作，即通过一个或几个XML文件，可以方便地对应用的耦合关系进行浏览、修改和维护，很大程度上简化应用开发。通过Ioc容器实现的依赖反转，把依赖关系的管理从Java对象中解放出来，交给IoC容器来完成，从而完成了对象之间的解耦，将原来的对象—对象的关系，转化为对象—IoC容器—对象的关系。 ​ Spring即作为用户和机器之间的平台，同时也为用户使用底层的机器资源提供了应用开发环境。Spring关系的是一些企业应用资源的使用，如数据持久化、数据集成、事务管理、消息中间件、Web2.0应用、分布式计算等对高效可靠处理企业数据方法的技术抽象。 ​ Spring一方面通过IoC容器来管理POJO对象，以及它们相互之间的耦合关系，使企业的信息、数据、资源可以用简单得Java语言来抽象和描述；另一方面可通过AOP以动态和非侵入式的方式来增强服务的功能。 ​ IoC容器和AOP模块是平台实现的核心，代表了最为基础的底层抽象，同时也是Spring其他模块实现的基础。 Spring整体架构Spring IoC​ 包含了最基本的IoC容器BeanFactory接口的实现，也提供了一系列这个接口的实现。如：XmlBeanFactory、SimpleJndiBeanFactory、StaticListableBeanFactory等，为了让应用更方便得使用IoC容器，还在IoC容器的外围提供如Resource访问资源的抽象和定位等支持。Spring还设计了IoC容器的高级形态ApplicationContext应用上下文提供用户使用。 Spring AOP​ Spring核心模块，围绕AOP增强功能，Spring集成了AspectJ作为AOP的一个特定实现，还在JVM动态代理&#x2F;CGLIB的基础上实现了一个AOP框架。 Spring MVC​ 以DispatcherServlet为核心的模块，实现了MVC模式，包括怎样与Web容器环境集成、Web请求的拦截、分发、处理、和ModelAndView数据的返回，以及如何集成各种UI视图展现和数据表现。 Spring JDBC&#x2F;ORM​ Spring JDBC包提供了JdbcTemplate作为模板类，封装了基本的数据库操作方法，如数据查询、更新等。 ​ Spring还提供许多对ORM工具的封装。如Hibernate、iBatis等。可以把对这些工具的使用和Spring声明式事务处理结合起来。同时Spring还提供许多模板对象，如HibernateTemplate来实现对Hibernate的驱动。 Spring事务处理​ Spring事务处理是一个通过Spring AOP实现的自身功能增强的典型模块。通过AOP增强实现了声明式事务处理的功能，使应用只需要在IoC容器中对事务属性进行配置即可完成，同时这些事务处理的基本过程和具体的事务处理器实现是无关的，应用可以选择不同的具体的事务处理机制，使用了声明式事务处理，这些具体的事务处理机制会被纳入Spring事务处理的统一框架中完成，并完成与具体业务代码的解耦。 Spring远端调用​ 通过Spring的封装，为应用屏蔽了各种通信和调用细节的实现，通过这一层的封装，使应用可以通过选择各种不同的远端调用来实现。如HTTP调用器、第三方二进制实现Hessian&#x2F;Burlap、RMI调用。 Spring应用场景​ 在Spring这个一站式应用平台或框架中，其中各个模块除了依赖IoC容器和AOP之外，相互之间没有很强的耦合性；Spring最重目标是简化应用开发的编程模型。其所提供的服务可贯穿应用道整个软件中，从最上层Web UI到底层数据操作，到其他企业信息数据集成，再到各种J2EE服务的使用。 ​ 可把Spring作为一个整体使用，也可以把Spring各个模块拿出来单独使用，因其本身是非常模块化的。Spring的价值： 非侵入性框架，其目标是使应用程序代码对框架的依赖最小化。 提供了一个一致的编程模型，使应用直接使用POJO开发，从而可以与运行环境隔离开。 推动应用的设计风格向面向对象及面向接口编程转变，提高代码的重用性和可测性。 改进了体系结构的选择，Spring可以帮助我们选择不同的技术实现。","tags":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}]},{"title":"SpringBoot启动原理","date":"2020-10-15T07:08:20.000Z","path":"blog/Spring/SpringBoot/SpringBoot启动原理/","text":"SpringBoot的启动是 SpringApplication.run(ElevenApplication.class, args) 来完成的，首先在实例化SpringApplication时会去加载项目中所有的 spring.factories 配置文件数据到缓存中，并将所有的 ApplicationContextInitializer 和 ApplicationListener 筛选出来并实例化，其作用是对外扩张，以及对内的解耦，全局配置文件以及热部署插件就是通过这两个Initializer和Listener来完成的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public class SpringApplication &#123; private List&lt;ApplicationContextInitializer&lt;?&gt;&gt; initializers; private List&lt;ApplicationListener&lt;?&gt;&gt; listeners; public SpringApplication(Class&lt;?&gt;... primarySources) &#123; this(null, primarySources); &#125; public SpringApplication(ResourceLoader resourceLoader, Class&lt;?&gt;... primarySources) &#123; this.resourceLoader = resourceLoader; Assert.notNull(primarySources, &quot;PrimarySources must not be null&quot;); this.primarySources = new LinkedHashSet&lt;&gt;(Arrays.asList(primarySources));/ 将启动类放入primarySources this.webApplicationType = WebApplicationType.deduceFromClasspath(); // 根据classpath下的类确定Web类型NONE、SERVLET、REACTIVE this.bootstrapRegistryInitializers = getBootstrapRegistryInitializersFromSpringFactories(); // 去spring.factories中去获取所有key:org.springframework.context.ApplicationContextInitializer setInitializers((Collection) getSpringFactoriesInstances(ApplicationContextInitializer.class)); // 去spring.factories中去获取所有key: org.springframework.context.ApplicationListener setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); this.mainApplicationClass = deduceMainApplicationClass(); // 根据main方法推算出mainApplicationClass &#125; private &lt;T&gt; Collection&lt;T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type) &#123; return getSpringFactoriesInstances(type, new Class&lt;?&gt;[] &#123;&#125;); &#125; private &lt;T&gt; Collection&lt;T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type, Class&lt;?&gt;[] parameterTypes, Object... args) &#123; ClassLoader classLoader = getClassLoader(); // 根据类型筛选出spring.factories中配置的满足条件的类名列表 Set&lt;String&gt; names = new LinkedHashSet&lt;&gt;(SpringFactoriesLoader.loadFactoryNames(type, classLoader)); // 将满足条件的类实例化 List&lt;T&gt; instances = createSpringFactoriesInstances(type, parameterTypes, classLoader, args, names); AnnotationAwareOrderComparator.sort(instances); return instances; &#125;&#125;public final class SpringFactoriesLoader &#123; // 加载Jar包中所有的spring.factories文件中配置的数据到缓存中 public static final String FACTORIES_RESOURCE_LOCATION = &quot;META-INF/spring.factories&quot;; public static List&lt;String&gt; loadFactoryNames(Class&lt;?&gt; factoryType, @Nullable ClassLoader classLoader) &#123; ClassLoader classLoaderToUse = classLoader; if (classLoaderToUse == null) &#123; classLoaderToUse = SpringFactoriesLoader.class.getClassLoader(); &#125; String factoryTypeName = factoryType.getName(); return loadSpringFactories(classLoaderToUse).getOrDefault(factoryTypeName, Collections.emptyList()); &#125; private static Map&lt;String, List&lt;String&gt;&gt; loadSpringFactories(ClassLoader classLoader) &#123; Map&lt;String, List&lt;String&gt;&gt; result = cache.get(classLoader); if (result != null) &#123; // 若已加载过直接跳过 return result; &#125; result = new HashMap&lt;&gt;(); try &#123; Enumeration&lt;URL&gt; urls = classLoader.getResources(FACTORIES_RESOURCE_LOCATION); while (urls.hasMoreElements()) &#123; URL url = urls.nextElement(); UrlResource resource = new UrlResource(url); Properties properties = PropertiesLoaderUtils.loadProperties(resource); for (Map.Entry&lt;?, ?&gt; entry : properties.entrySet()) &#123; String factoryTypeName = ((String) entry.getKey()).trim(); String[] factoryImplementationNames = StringUtils.commaDelimitedListToStringArray((String) entry.getValue()); for (String factoryImplementationName : factoryImplementationNames) &#123; result.computeIfAbsent(factoryTypeName, key -&gt; new ArrayList&lt;&gt;()).add(factoryImplementationName.trim()); &#125; &#125; &#125; result.replaceAll((factoryType, implementations) -&gt; implementations.stream().distinct().collect(Collectors.collectingAndThen(Collectors.toList(), Collections::unmodifiableList))); cache.put(classLoader, result); &#125; catch (IOException ex) &#123; throw new IllegalArgumentException(&quot;Unable to load factories from location [&quot; + FACTORIES_RESOURCE_LOCATION + &quot;]&quot;, ex); &#125; return result; &#125;&#125; 通过run方法完成SpringBoot的启动 123456789101112131415161718192021222324252627282930313233343536373839public ConfigurableApplicationContext run(String... args) &#123; StopWatch stopWatch = new StopWatch(); // 用来记录当前springboot启动耗时 stopWatch.start(); // 记录启动开始时间 DefaultBootstrapContext bootstrapContext = createBootstrapContext(); ConfigurableApplicationContext context = null; // // 它是任何spring上下文的接口，可接收任何ApplicationContext实现 configureHeadlessProperty(); // 开启了Headless模式 SpringApplicationRunListeners listeners = getRunListeners(args); // 去spring.factroies中读取SpringApplicationRunListener组件，用来发布事件或者运行监听器 listeners.starting(bootstrapContext, this.mainApplicationClass); // ApplicationStartingEvent事件，在运行开始时发送 try &#123; // 根据命令行参数实例化一个ApplicationArguments ApplicationArguments applicationArguments = new DefaultApplicationArguments(args); // 基于监听器预初始化环境：读取环境变量，读取配置文件信息 ConfigurableEnvironment environment = prepareEnvironment(listeners, bootstrapContext, applicationArguments); configureIgnoreBeanInfo(environment); // 忽略beaninfo的bean Banner printedBanner = printBanner(environment); // 打印Banner横幅 context = createApplicationContext(); context.setApplicationStartup(this.applicationStartup); // 预初始化spring上下文 prepareContext(bootstrapContext, context, environment, listeners, applicationArguments, printedBanner); refreshContext(context); // 加载spring ioc容器 afterRefresh(context, applicationArguments); stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass).logStarted(getApplicationLog(), stopWatch); &#125; listeners.started(context); callRunners(context, applicationArguments); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, listeners); throw new IllegalStateException(ex); &#125; try &#123; listeners.running(context); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, null); throw new IllegalStateException(ex); &#125; return context;&#125; 预初始化环境是基于监听器来读取环境变量和读取配置文件信息，首先根据 webApplicationType 创建 Environment ，创建就会读取Java环境变量和系统环境变量。然后将命令行参数读取环境变量中，通过发布 ApplicationEnvironmentPreparedEvent 监听器读取全局配置文件。 12345678910111213141516171819private ConfigurableEnvironment prepareEnvironment(SpringApplicationRunListeners listeners, DefaultBootstrapContext bootstrapContext, ApplicationArguments applicationArguments) &#123; // 根据webApplicationType创建Environment，创建就会读取：java环境变量和系统环境变量 ConfigurableEnvironment environment = getOrCreateEnvironment(); // 将命令行参数读取环境变量中 configureEnvironment(environment, applicationArguments.getSourceArgs()); // 将@PropertieSource的配置信息放在第一位，读取配置文件@PropertieSource优先级是最低的 ConfigurationPropertySources.attach(environment); // 发布了ApplicationEnvironmentPreparedEvent的监听器读取全局配置文件 listeners.environmentPrepared(bootstrapContext, environment); // 将所有spring.main开头的配置信息绑定SpringApplication DefaultPropertiesPropertySource.moveToEnd(environment); Assert.state(!environment.containsProperty(&quot;spring.main.environment-prefix&quot;), &quot;Environment prefix cannot be set via properties.&quot;); bindToSpringApplication(environment); if (!this.isCustomEnvironment) &#123; environment = new EnvironmentConverter(getClassLoader()).convertEnvironmentIfNecessary(environment, deduceEnvironmentClass()); &#125; ConfigurationPropertySources.attach(environment); // 更新PropertySources return environment;&#125; 根据应用类型创建Spring IOC上下文 1234567891011121314151617181920protected ConfigurableApplicationContext createApplicationContext() &#123; return this.applicationContextFactory.create(this.webApplicationType);&#125;public interface ApplicationContextFactory &#123; ApplicationContextFactory DEFAULT = (webApplicationType) -&gt; &#123; try &#123; switch (webApplicationType) &#123; case SERVLET: return new AnnotationConfigServletWebServerApplicationContext(); case REACTIVE: return new AnnotationConfigReactiveWebServerApplicationContext(); default: return new AnnotationConfigApplicationContext(); &#125; &#125; catch (Exception ex) &#123; throw new IllegalStateException(&quot;Unable create a default ApplicationContext instance, &quot; + &quot;you may need a custom ApplicationContextFactory&quot;, ex); &#125; &#125;; ConfigurableApplicationContext create(WebApplicationType webApplicationType);&#125; 预初始化上下文，这里会发布 ApplicationContextInitializedEvent 事件，且设置重名的Bean不允许覆盖直接抛出异常，设置当前Spring容器是否要将所有bean设置为懒加载，然后通过 AnnotatedBeanDefinitionReader 的 register 方法将 SpringApplication#run 中传入的类注册到IoC容器中，读取完配置类后发布 ApplicationPreparedEvent 事件。 12345678910111213141516171819202122232425262728293031private void prepareContext(DefaultBootstrapContext bootstrapContext, ConfigurableApplicationContext context, ConfigurableEnvironment environment, SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments, Banner printedBanner) &#123; context.setEnvironment(environment); postProcessApplicationContext(context); applyInitializers(context); // 拿到之前读取到所有ApplicationContextInitializer的组件， 循环调用initialize方法 listeners.contextPrepared(context); // 发布了ApplicationContextInitializedEvent bootstrapContext.close(context); if (this.logStartupInfo) &#123; logStartupInfo(context.getParent() == null); logStartupProfileInfo(context); &#125; // 获取当前spring上下文beanFactory，负责创建bean ConfigurableListableBeanFactory beanFactory = context.getBeanFactory(); beanFactory.registerSingleton(&quot;springApplicationArguments&quot;, applicationArguments); if (printedBanner != null) &#123; beanFactory.registerSingleton(&quot;springBootBanner&quot;, printedBanner); &#125; // 若Spring下出现2个重名的bean, 则后读取到的会覆盖前面，SpringBoot在这里设置了不允许覆盖，当出现2个重名的bean会抛出异常 if (beanFactory instanceof DefaultListableBeanFactory) &#123; ((DefaultListableBeanFactory) beanFactory).setAllowBeanDefinitionOverriding(this.allowBeanDefinitionOverriding); &#125; // 设置当前spring容器是不是要将所有的bean设置为懒加载 if (this.lazyInitialization) &#123; context.addBeanFactoryPostProcessor(new LazyInitializationBeanFactoryPostProcessor()); &#125; // 即传入的ElevenApplication Set&lt;Object&gt; sources = getAllSources(); Assert.notEmpty(sources, &quot;Sources must not be empty&quot;); // 读取主启动类将它注册为BD、就和以前register启动类一个意思，因为后续要根据配置类解析配置的所有bean load(context, sources.toArray(new Object[0])); listeners.contextLoaded(context); // 读取完配置类后发送ApplicationPreparedEvent&#125; 最后调用容器启动最重要的 refresh() 方法来完成Bean的扫描注册和实例化等工作。 123456789private void refreshContext(ConfigurableApplicationContext context) &#123; if (this.registerShutdownHook) &#123; shutdownHook.registerApplicationContext(context); &#125; refresh(context);&#125;protected void refresh(ConfigurableApplicationContext applicationContext) &#123; applicationContext.refresh();&#125; 内嵌Web容器启动内嵌Web容器的启动是在 refresh() 中的 onRefresh() 中完成的，最终调用子容器 ServletWebServerApplicationContext 的 onRefresh() 方法，从而调用 createWebServer() 创建Web容器。 12345678910111213141516171819202122232425262728293031public class ServletWebServerApplicationContext extends GenericWebApplicationContext implements ConfigurableWebServerApplicationContext &#123; protected void onRefresh() &#123; super.onRefresh(); try &#123; createWebServer(); &#125; catch (Throwable ex) &#123; throw new ApplicationContextException(&quot;Unable to start web server&quot;, ex); &#125; &#125; private void createWebServer() &#123; WebServer webServer = this.webServer; ServletContext servletContext = getServletContext(); if (webServer == null &amp;&amp; servletContext == null) &#123; StartupStep createWebServer = this.getApplicationStartup().start(&quot;spring.boot.webserver.create&quot;); ServletWebServerFactory factory = getWebServerFactory(); createWebServer.tag(&quot;factory&quot;, factory.getClass().toString()); this.webServer = factory.getWebServer(getSelfInitializer()); createWebServer.end(); getBeanFactory().registerSingleton(&quot;webServerGracefulShutdown&quot;, new WebServerGracefulShutdownLifecycle(this.webServer)); getBeanFactory().registerSingleton(&quot;webServerStartStop&quot;, new WebServerStartStopLifecycle(this, this.webServer)); &#125; else if (servletContext != null) &#123; try &#123; getSelfInitializer().onStartup(servletContext); &#125; catch (ServletException ex) &#123; throw new ApplicationContextException(&quot;Cannot initialize servlet context&quot;, ex); &#125; &#125; initPropertySources(); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public class TomcatServletWebServerFactory extends AbstractServletWebServerFactory implements ConfigurableTomcatWebServerFactory, ResourceLoaderAware &#123; public WebServer getWebServer(ServletContextInitializer... initializers) &#123; if (this.disableMBeanRegistry) &#123; Registry.disableRegistry(); &#125; Tomcat tomcat = new Tomcat(); File baseDir = (this.baseDirectory != null) ? this.baseDirectory : createTempDir(&quot;tomcat&quot;); tomcat.setBaseDir(baseDir.getAbsolutePath()); Connector connector = new Connector(this.protocol); connector.setThrowOnFailure(true); tomcat.getService().addConnector(connector); customizeConnector(connector); tomcat.setConnector(connector); tomcat.getHost().setAutoDeploy(false); configureEngine(tomcat.getEngine()); for (Connector additionalConnector : this.additionalTomcatConnectors) &#123; tomcat.getService().addConnector(additionalConnector); &#125; prepareContext(tomcat.getHost(), initializers); return getTomcatWebServer(tomcat); &#125; protected TomcatWebServer getTomcatWebServer(Tomcat tomcat) &#123; return new TomcatWebServer(tomcat, getPort() &gt;= 0, getShutdown()); &#125;&#125;public class TomcatWebServer implements WebServer &#123; public TomcatWebServer(Tomcat tomcat, boolean autoStart, Shutdown shutdown) &#123; Assert.notNull(tomcat, &quot;Tomcat Server must not be null&quot;); this.tomcat = tomcat; this.autoStart = autoStart; this.gracefulShutdown = (shutdown == Shutdown.GRACEFUL) ? new GracefulShutdown(tomcat) : null; initialize(); &#125; private void initialize() throws WebServerException &#123; synchronized (this.monitor) &#123; try &#123; addInstanceIdToEngineName(); Context context = findContext(); context.addLifecycleListener((event) -&gt; &#123; if (context.equals(event.getSource()) &amp;&amp; Lifecycle.START_EVENT.equals(event.getType())) &#123; removeServiceConnectors(); &#125; &#125;); this.tomcat.start(); rethrowDeferredStartupExceptions(); try &#123; ContextBindings.bindClassLoader(context, context.getNamingToken(), getClass().getClassLoader()); &#125; catch (NamingException ex) &#123; &#125; startDaemonAwaitThread(); &#125; catch (Exception ex) &#123; stopSilently(); destroySilently(); throw new WebServerException(&quot;Unable to start embedded Tomcat&quot;, ex); &#125; &#125; &#125; private void startDaemonAwaitThread() &#123; Thread awaitThread = new Thread(&quot;container-&quot; + (containerCounter.get())) &#123; @Override public void run() &#123; TomcatWebServer.this.tomcat.getServer().await(); &#125; &#125;; awaitThread.setContextClassLoader(getClass().getClassLoader()); awaitThread.setDaemon(false); awaitThread.start(); &#125;&#125; 外部Servlet容器启动外部Servlet容器启动是通过war包以及 SPI机制来完成的， SPI是一种服务发现机制，它通过在ClassPath路径下的 META-INF/services 文件夹查找文件，自动加载文件里所定义的类。需要将打包方式改成war包，然后将POM中Tomcat的依赖设置为不参与打包。 12345&lt;dependency&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 当 Servlet 启动时回去 META-INF/services 文件夹中找到 javax.servlet.ServletContainerInitializer ，当Servlet容器启动时会去找到ServletContainerInitializer的实现类，从而创建它的实例调用 onStartup 方法。在Spring中ServletContainerInitializer 的实现类为 SpringServletContainerInitializer ，且通过 @HandlesTypes(WebApplicationInitializer.class)注解将 ServletContainerInitializer 感兴趣的类 WebApplicationInitializer 传入到 onStartup 方法的参数中。 123456789101112131415161718192021222324252627282930313233343536public abstract class SpringBootServletInitializer implements WebApplicationInitializer &#123; protected WebApplicationContext createRootApplicationContext(ServletContext servletContext) &#123; SpringApplicationBuilder builder = createSpringApplicationBuilder(); builder.main(getClass()); ApplicationContext parent = getExistingRootWebApplicationContext(servletContext); if (parent != null) &#123; servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, null); builder.initializers(new ParentContextApplicationContextInitializer(parent)); &#125; builder.initializers(new ServletContextApplicationContextInitializer(servletContext)); builder.contextFactory((webApplicationType) -&gt; new AnnotationConfigServletWebServerApplicationContext()); builder = configure(builder); builder.listeners(new WebEnvironmentPropertySourceInitializer(servletContext)); SpringApplication application = builder.build(); if (application.getAllSources().isEmpty() &amp;&amp; MergedAnnotations.from(getClass(), SearchStrategy.TYPE_HIERARCHY).isPresent(Configuration.class)) &#123; application.addPrimarySources(Collections.singleton(getClass())); &#125; Assert.state(!application.getAllSources().isEmpty(), &quot;No SpringApplication sources have been defined. Either override the &quot; + &quot;configure method or add an @Configuration annotation&quot;); if (this.registerErrorPageFilter) &#123; application.addPrimarySources(Collections.singleton(ErrorPageFilterConfiguration.class)); &#125; application.setRegisterShutdownHook(false); return run(application); &#125; protected SpringApplicationBuilder createSpringApplicationBuilder() &#123; return new SpringApplicationBuilder(); &#125;&#125;public class SpringApplicationBuilder &#123; public SpringApplicationBuilder(Class&lt;?&gt;... sources) &#123; this.application = createSpringApplication(sources); &#125; protected SpringApplication createSpringApplication(Class&lt;?&gt;... sources) &#123; return new SpringApplication(sources); &#125;&#125; 由代码可以明显看到Tomcat不会主动去启动SpringBoot应用，而默认创建SpringApplication时什么都没有传入，故需要通过继承 SpringBootServletInitializer 重写 configure 来指定SpringBoot启动类。 123456public class TomcatStartSpringBoot extends SpringBootServletInitializer &#123; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder builder) &#123; return builder.sources(ElevenSpringbootApplication.class); &#125;&#125;","tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://example.com/tags/SpringBoot/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"},{"name":"SpringBoot","slug":"Spring/SpringBoot","permalink":"http://example.com/categories/Spring/SpringBoot/"}]},{"title":"SpringBoot自动装配原理","date":"2020-10-15T06:08:20.000Z","path":"blog/Spring/SpringBoot/SpringBoot自动装配原理/","text":"SpringBoot容器启动时最终会调用 refresh() 方法来扫描项目中的Bean注册为BeanDefinition然后将其加载到容器中。扫描注册过程还是在 invokeBeanFactoryPostProcessors 中来完成的。首先通过启动类上 @SpringBootApplication 中的 @ComponentScan 来确定扫描的包来扫描包下所有的类，然后通过条件筛选出符合的Bean。 12345678910111213141516171819202122@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan(excludeFilters = &#123; @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) &#125;)public @interface SpringBootApplication &#123; @AliasFor(annotation = EnableAutoConfiguration.class) Class&lt;?&gt;[] exclude() default &#123;&#125;; @AliasFor(annotation = EnableAutoConfiguration.class) String[] excludeName() default &#123;&#125;; @AliasFor(annotation = ComponentScan.class, attribute = &quot;basePackages&quot;) String[] scanBasePackages() default &#123;&#125;; @AliasFor(annotation = ComponentScan.class, attribute = &quot;basePackageClasses&quot;) Class&lt;?&gt;[] scanBasePackageClasses() default &#123;&#125;; @AliasFor(annotation = ComponentScan.class, attribute = &quot;nameGenerator&quot;) Class&lt;? extends BeanNameGenerator&gt; nameGenerator() default BeanNameGenerator.class; @AliasFor(annotation = Configuration.class) boolean proxyBeanMethods() default true;&#125; 在 @ComponentScan 中配置了一个两个 excludeFilters ，TypeExcludeFilter适用于提供的扩展点，AutoConfigurationExcludeFilter的作用是排除被 @Configuration 注解标注的且在所有 META-INF/spring.factories 文件中的KEY为 org.springframework.boot.autoconfigure.EnableAutoConfiguration 的自动配置类。 1234567891011121314151617181920public class AutoConfigurationExcludeFilter implements TypeFilter, BeanClassLoaderAware &#123; public boolean match(MetadataReader metadataReader, MetadataReaderFactory metadataReaderFactory) throws IOException &#123; return isConfiguration(metadataReader) &amp;&amp; isAutoConfiguration(metadataReader); &#125; private boolean isConfiguration(MetadataReader metadataReader) &#123; return metadataReader.getAnnotationMetadata().isAnnotated(Configuration.class.getName()); &#125; private boolean isAutoConfiguration(MetadataReader metadataReader) &#123; return getAutoConfigurations().contains(metadataReader.getClassMetadata().getClassName()); &#125; protected List&lt;String&gt; getAutoConfigurations() &#123; if (this.autoConfigurations == null) &#123; this.autoConfigurations = SpringFactoriesLoader.loadFactoryNames(EnableAutoConfiguration.class, this.beanClassLoader); &#125; return this.autoConfigurations; &#125;&#125; 若 @ComponentScan 未指定 basePackages 和 basePackageClasses ，则默认使用当前配置类所在的包。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162class ComponentScanAnnotationParser &#123; public Set&lt;BeanDefinitionHolder&gt; parse(AnnotationAttributes componentScan, final String declaringClass) &#123; ClassPathBeanDefinitionScanner scanner = new ClassPathBeanDefinitionScanner(this.registry, componentScan.getBoolean(&quot;useDefaultFilters&quot;), this.environment, this.resourceLoader); // 为扫描器设置beanName的生成器对象 Class&lt;? extends BeanNameGenerator&gt; generatorClass = componentScan.getClass(&quot;nameGenerator&quot;); boolean useInheritedGenerator = (BeanNameGenerator.class == generatorClass); scanner.setBeanNameGenerator(useInheritedGenerator ? this.beanNameGenerator : BeanUtils.instantiateClass(generatorClass)); // 解析@Scope的ProxyMode属性，该属性可以将Bean创建为jdk代理或cglib代理 ScopedProxyMode scopedProxyMode = componentScan.getEnum(&quot;scopedProxy&quot;); if (scopedProxyMode != ScopedProxyMode.DEFAULT) &#123; scanner.setScopedProxyMode(scopedProxyMode); &#125; else &#123; Class&lt;? extends ScopeMetadataResolver&gt; resolverClass = componentScan.getClass(&quot;scopeResolver&quot;); scanner.setScopeMetadataResolver(BeanUtils.instantiateClass(resolverClass)); &#125; scanner.setResourcePattern(componentScan.getString(&quot;resourcePattern&quot;)); // 设置CompentScan对象的includeFilters 包含的属性 for (AnnotationAttributes filter : componentScan.getAnnotationArray(&quot;includeFilters&quot;)) &#123; for (TypeFilter typeFilter : typeFiltersFor(filter)) &#123; scanner.addIncludeFilter(typeFilter); &#125; &#125; // 设置CompentScan对象的excludeFilters 包含的属性 for (AnnotationAttributes filter : componentScan.getAnnotationArray(&quot;excludeFilters&quot;)) &#123; for (TypeFilter typeFilter : typeFiltersFor(filter)) &#123; scanner.addExcludeFilter(typeFilter); &#125; &#125; // 是否懒加载，此懒加载为componentScan延迟加载所有类 boolean lazyInit = componentScan.getBoolean(&quot;lazyInit&quot;); if (lazyInit) &#123; scanner.getBeanDefinitionDefaults().setLazyInit(true); &#125; // 包路径配置类中componentScan设置的路径 Set&lt;String&gt; basePackages = new LinkedHashSet&lt;&gt;(); String[] basePackagesArray = componentScan.getStringArray(&quot;basePackages&quot;); for (String pkg : basePackagesArray) &#123; String[] tokenized = StringUtils.tokenizeToStringArray(this.environment.resolvePlaceholders(pkg), ConfigurableApplicationContext.CONFIG_LOCATION_DELIMITERS); Collections.addAll(basePackages, tokenized); &#125; for (Class&lt;?&gt; clazz : componentScan.getClassArray(&quot;basePackageClasses&quot;)) &#123; basePackages.add(ClassUtils.getPackageName(clazz)); &#125; if (basePackages.isEmpty()) &#123; // 若未指定则使用当前配置所在的包 basePackages.add(ClassUtils.getPackageName(declaringClass)); &#125; scanner.addExcludeFilter(new AbstractTypeHierarchyTraversingFilter(false, false) &#123; @Override protected boolean matchClassName(String className) &#123; return declaringClass.equals(className); &#125; &#125;); return scanner.doScan(StringUtils.toStringArray(basePackages)); // 真正的进行扫描解析 &#125;&#125;public static String getPackageName(String fqClassName) &#123; // 截取出当前类所在的文件夹 Assert.notNull(fqClassName, &quot;Class name must not be null&quot;); int lastDotIndex = fqClassName.lastIndexOf(PACKAGE_SEPARATOR); return (lastDotIndex != -1 ? fqClassName.substring(0, lastDotIndex) : &quot;&quot;);&#125; 将所有的@Component注解标注的类扫描出来，将其注册到容器中，对于 @Import注解导入的类，总的来说分为三种，第一种是普通的类，第二种是实现了 ImportSelector 接口，这里面有两种类型，若是一个延时的 DeferredImportSelector 则只将该类添加到 deferredImportSelectors 后续解析后统一处理。否则调用 selectImports 递归调用 processImports ，第三中是实现了 ImportBeanDefinitionRegistrar 接口，这种会将其添加到当前 ConfigurationClass 的 importBeanDefinitionRegistrars 列表中后续统一处理。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950private void processImports(ConfigurationClass configClass, SourceClass currentSourceClass, Collection&lt;SourceClass&gt; importCandidates, boolean checkForCircularImports) &#123; if (importCandidates.isEmpty()) &#123; return; &#125; if (checkForCircularImports &amp;&amp; isChainedImportOnStack(configClass)) &#123; this.problemReporter.error(new CircularImportProblem(configClass, this.importStack)); &#125; else &#123; this.importStack.push(configClass); try &#123; for (SourceClass candidate : importCandidates) &#123; // 获取我们Import导入进来的所有组件 if (candidate.isAssignable(ImportSelector.class)) &#123; // 判断该组件是不是实现了ImportSelector // Candidate class is an ImportSelector -&gt; delegate to it to determine imports Class&lt;?&gt; candidateClass = candidate.loadClass(); // 实例化我们的SelectImport组件 ImportSelector selector = BeanUtils.instantiateClass(candidateClass, ImportSelector.class); // 调用相关的aware方法 ParserStrategyUtils.invokeAwareMethods(selector, this.environment, this.resourceLoader, this.registry); // 判断是不是延时的DeferredImportSelectors，是这个类型不进行处理 if (this.deferredImportSelectors != null &amp;&amp; selector instanceof DeferredImportSelector) &#123; this.deferredImportSelectors.add(new DeferredImportSelectorHolder(configClass, (DeferredImportSelector) selector)); &#125; else &#123; // 不是延时的， 调用selector的selectImports String[] importClassNames = selector.selectImports(currentSourceClass.getMetadata()); // 所以递归解析-- 直到成普通组件 Collection&lt;SourceClass&gt; importSourceClasses = asSourceClasses(importClassNames); processImports(configClass, currentSourceClass, importSourceClasses, false); &#125; &#125; // 判断导入的组件是不是ImportBeanDefinitionRegistrar，这里不直接调用，只是解析 else if (candidate.isAssignable(ImportBeanDefinitionRegistrar.class)) &#123; Class&lt;?&gt; candidateClass = candidate.loadClass(); // 实例化ImportBeanDefinitionRegistrar对象 ImportBeanDefinitionRegistrar registrar = BeanUtils.instantiateClass(candidateClass, ImportBeanDefinitionRegistrar.class); ParserStrategyUtils.invokeAwareMethods(registrar, this.environment, this.resourceLoader, this.registry); // 保存ImportBeanDefinitionRegistrar对象currentSourceClass=所在配置类 configClass.addImportBeanDefinitionRegistrar(registrar, currentSourceClass.getMetadata()); &#125; else &#123; // 当做配置类再解析，注意这里会标记：importedBy，表示这是Import的配置的类，再执行之前的processConfigurationClass()方法 ， this.importStack.registerImport(currentSourceClass.getMetadata(), candidate.getMetadata().getClassName()); processConfigurationClass(candidate.asConfigClass(configClass)); &#125; &#125; &#125; catch (BeanDefinitionStoreException ex) &#123; throw ex; &#125; catch (Throwable ex) &#123; throw new BeanDefinitionStoreException(&quot;Failed to process import candidates for configuration class [&quot; + configClass.getMetadata().getClassName() + &quot;]&quot;, ex); &#125; finally &#123; this.importStack.pop(); &#125; &#125;&#125; 对于 DeferredImportSelector 的处理在 processImports 中会通过handle方法将其添加到 ConfigurationClassParser 的 deferredImportSelectors 列表中。在parse解析完所有Bean后调用 process 方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849class ConfigurationClassParser &#123; public void parse(Set&lt;BeanDefinitionHolder&gt; configCandidates) &#123; for (BeanDefinitionHolder holder : configCandidates) &#123; BeanDefinition bd = holder.getBeanDefinition(); try &#123; if (bd instanceof AnnotatedBeanDefinition) &#123; parse(((AnnotatedBeanDefinition) bd).getMetadata(), holder.getBeanName()); &#125; else if (bd instanceof AbstractBeanDefinition &amp;&amp; ((AbstractBeanDefinition) bd).hasBeanClass()) &#123; parse(((AbstractBeanDefinition) bd).getBeanClass(), holder.getBeanName()); &#125; else &#123; parse(bd.getBeanClassName(), holder.getBeanName()); &#125; &#125; catch (BeanDefinitionStoreException ex) &#123; throw ex; &#125; catch (Throwable ex) &#123; throw new BeanDefinitionStoreException(&quot;Failed to parse configuration class [&quot; + bd.getBeanClassName() + &quot;]&quot;, ex); &#125; &#125; this.deferredImportSelectorHandler.process(); &#125;&#125;private class DeferredImportSelectorHandler &#123; private List&lt;DeferredImportSelectorHolder&gt; deferredImportSelectors = new ArrayList&lt;&gt;(); public void handle(ConfigurationClass configClass, DeferredImportSelector importSelector) &#123; DeferredImportSelectorHolder holder = new DeferredImportSelectorHolder(configClass, importSelector); if (this.deferredImportSelectors == null) &#123; DeferredImportSelectorGroupingHandler handler = new DeferredImportSelectorGroupingHandler(); handler.register(holder); handler.processGroupImports(); &#125; else &#123; this.deferredImportSelectors.add(holder); &#125; &#125; public void process() &#123; List&lt;DeferredImportSelectorHolder&gt; deferredImports = this.deferredImportSelectors; this.deferredImportSelectors = null; try &#123; if (deferredImports != null) &#123; DeferredImportSelectorGroupingHandler handler = new DeferredImportSelectorGroupingHandler(); deferredImports.sort(DEFERRED_IMPORT_COMPARATOR); deferredImports.forEach(handler::register); handler.processGroupImports(); &#125; &#125; finally &#123; this.deferredImportSelectors = new ArrayList&lt;&gt;(); &#125; &#125;&#125; 通过 DeferredImportSelectorGroupingHandler 的 register 方法遍历，首先调用其 getImportGroup 获取Group，然后再将其封装添加到 grouping ，最后通过 processGroupImports 遍历 getImports() 再遍历每个导入的类执行 processImports 。 123456789101112131415161718192021222324252627282930313233private class DeferredImportSelectorGroupingHandler &#123; private final Map&lt;Object, DeferredImportSelectorGrouping&gt; groupings = new LinkedHashMap&lt;&gt;(); private final Map&lt;AnnotationMetadata, ConfigurationClass&gt; configurationClasses = new HashMap&lt;&gt;(); public void register(DeferredImportSelectorHolder deferredImport) &#123; Class&lt;? extends Group&gt; group = deferredImport.getImportSelector().getImportGroup(); DeferredImportSelectorGrouping grouping = this.groupings.computeIfAbsent( (group != null ? group : deferredImport), key -&gt; new DeferredImportSelectorGrouping(createGroup(group))); grouping.add(deferredImport); this.configurationClasses.put(deferredImport.getConfigurationClass().getMetadata(), deferredImport.getConfigurationClass()); &#125; public void processGroupImports() &#123; for (DeferredImportSelectorGrouping grouping : this.groupings.values()) &#123; Predicate&lt;String&gt; exclusionFilter = grouping.getCandidateFilter(); grouping.getImports().forEach(entry -&gt; &#123; ConfigurationClass configurationClass = this.configurationClasses.get(entry.getMetadata()); try &#123; processImports(configurationClass, asSourceClass(configurationClass, exclusionFilter), Collections.singleton(asSourceClass(entry.getImportClassName(), exclusionFilter)), exclusionFilter, false); &#125; catch (BeanDefinitionStoreException ex) &#123; throw ex; &#125; catch (Throwable ex) &#123; throw new BeanDefinitionStoreException(&quot;Failed to process import candidates for configuration class [&quot; + configurationClass.getMetadata().getClassName() + &quot;]&quot;, ex); &#125; &#125;); &#125; &#125; private Group createGroup(@Nullable Class&lt;? extends Group&gt; type) &#123; Class&lt;? extends Group&gt; effectiveType = (type != null ? type : DefaultDeferredImportSelectorGroup.class); return ParserStrategyUtils.instantiateClass(effectiveType, Group.class, ConfigurationClassParser.this.environment, ConfigurationClassParser.this.resourceLoader, ConfigurationClassParser.this.registry); &#125;&#125; 当处理完所有的Bean后通过调用 ConfigurationClassBeanDefinitionReader 的 loadBeanDefinitions 方法，按照解析Bean的顺序再次解析Bean中用@Bean注解标注的方法，以及对 @Import 中导入的实现了 ImportBeanDefinitionRegistrar 接口的类。 123456789101112131415161718private void loadBeanDefinitionsForConfigurationClass(ConfigurationClass configClass, TrackedConditionEvaluator trackedConditionEvaluator) &#123; if (trackedConditionEvaluator.shouldSkip(configClass)) &#123; String beanName = configClass.getBeanName(); if (StringUtils.hasLength(beanName) &amp;&amp; this.registry.containsBeanDefinition(beanName)) &#123; this.registry.removeBeanDefinition(beanName); &#125; this.importRegistry.removeImportingClass(configClass.getMetadata().getClassName()); return; &#125; if (configClass.isImported()) &#123; registerBeanDefinitionForImportedConfigurationClass(configClass); &#125; for (BeanMethod beanMethod : configClass.getBeanMethods()) &#123; loadBeanDefinitionsForBeanMethod(beanMethod); &#125; loadBeanDefinitionsFromImportedResources(configClass.getImportedResources()); loadBeanDefinitionsFromRegistrars(configClass.getImportBeanDefinitionRegistrars());&#125; SpringBoot的自动装配主要体现在 @EnableAutoConfiguration 中。在该注解上导入了 AutoConfigurationImportSelector ，该类实现了延时的 DeferredImportSelector ，从而延时加载自动配置的类，达到自动配置的效果。 1234567891011@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@AutoConfigurationPackage@Import(AutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration &#123; String ENABLED_OVERRIDE_PROPERTY = &quot;spring.boot.enableautoconfiguration&quot;; Class&lt;?&gt;[] exclude() default &#123;&#125;; String[] excludeName() default &#123;&#125;;&#125; 对于 @AutoConfigurationPackages 注解的作用是保存当前配置类所在的包路径作为扫描路径，提供给 spring-data-jpa 需要扫描 @Entity 。 123456789101112131415161718192021222324252627282930public abstract class AutoConfigurationPackages &#123; static class Registrar implements ImportBeanDefinitionRegistrar, DeterminableImports &#123; @Override public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry) &#123; register(registry, new PackageImports(metadata).getPackageNames().toArray(new String[0])); &#125; @Override public Set&lt;Object&gt; determineImports(AnnotationMetadata metadata) &#123; return Collections.singleton(new PackageImports(metadata)); &#125; &#125;&#125;private static final class PackageImports &#123; private final List&lt;String&gt; packageNames; PackageImports(AnnotationMetadata metadata) &#123; AnnotationAttributes attributes = AnnotationAttributes.fromMap(metadata.getAnnotationAttributes(AutoConfigurationPackage.class.getName(), false)); List&lt;String&gt; packageNames = new ArrayList&lt;&gt;(Arrays.asList(attributes.getStringArray(&quot;basePackages&quot;))); for (Class&lt;?&gt; basePackageClass : attributes.getClassArray(&quot;basePackageClasses&quot;)) &#123; packageNames.add(basePackageClass.getPackage().getName()); &#125; if (packageNames.isEmpty()) &#123; packageNames.add(ClassUtils.getPackageName(metadata.getClassName())); &#125; this.packageNames = Collections.unmodifiableList(packageNames); &#125; List&lt;String&gt; getPackageNames() &#123; return this.packageNames; &#125;&#125; 通过调用 AutoConfigurationImportSelector 的 getImportGroup() 获取到 AutoConfigurationGroup ，在解析完成所有Bean后调用 AutoConfigurationGroup 的process方法，最终调用 getAutoConfigurationEntry 去加载系统中所有 META-INF/spring.factories 文件中的KEY为 org.springframework.boot.autoconfigure.EnableAutoConfiguration 的自动配置类列表。 加载自动配置类的过程中会排除掉 @EnableAutoConfiguration注解中 exclude 和 excludeName 配置的类，以及 spring.autoconfigure.exclude 配置的类过滤掉，还会根据配置类上的 @Conditional派生注解进行配置类的过滤；在加载Bean方法时通过 ConditionEvaluator 的 shouldSkip 根据Bean上的 @Conditional派生注解来判断是否加载该Bean。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public class AutoConfigurationImportSelector implements DeferredImportSelector, BeanClassLoaderAware, ResourceLoaderAware, BeanFactoryAware, EnvironmentAware, Ordered &#123; public Class&lt;? extends Group&gt; getImportGroup() &#123; return AutoConfigurationGroup.class; &#125; protected AutoConfigurationEntry getAutoConfigurationEntry(AnnotationMetadata annotationMetadata) &#123; if (!isEnabled(annotationMetadata)) &#123; return EMPTY_ENTRY; &#125; AnnotationAttributes attributes = getAttributes(annotationMetadata); // 从META-INF/spring.factories中获得候选的自动配置类 List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata, attributes); configurations = removeDuplicates(configurations);// 排重 //根据EnableAutoConfiguration注解中属性，获取不需要自动装配的类名单 Set&lt;String&gt; exclusions = getExclusions(annotationMetadata, attributes); // 根据:@EnableAutoConfiguration.exclude，@EnableAutoConfiguration.excludeName，spring.autoconfigure.exclude进行排除 checkExcludedClasses(configurations, exclusions); configurations.removeAll(exclusions); // exclusions 也排除 // 通过读取spring.factories中的OnBeanCondition\\OnClassCondition\\OnWebApplicationCondition进行配置类的过滤 configurations = getConfigurationClassFilter().filter(configurations); fireAutoConfigurationImportEvents(configurations, exclusions); return new AutoConfigurationEntry(configurations, exclusions); &#125; protected boolean isEnabled(AnnotationMetadata metadata) &#123; if (getClass() == AutoConfigurationImportSelector.class) &#123; return getEnvironment().getProperty(EnableAutoConfiguration.ENABLED_OVERRIDE_PROPERTY, Boolean.class, true); &#125; return true; &#125; protected Class&lt;?&gt; getAnnotationClass() &#123; return EnableAutoConfiguration.class; &#125; protected List&lt;String&gt; getCandidateConfigurations(AnnotationMetadata metadata, AnnotationAttributes attributes) &#123; List&lt;String&gt; configurations = SpringFactoriesLoader.loadFactoryNames(getSpringFactoriesLoaderFactoryClass(), getBeanClassLoader()); Assert.notEmpty(configurations, &quot;No auto configuration classes found in META-INF/spring.factories. If you &quot; + &quot;are using a custom packaging, make sure that file is correct.&quot;); return configurations; &#125; protected Class&lt;?&gt; getSpringFactoriesLoaderFactoryClass() &#123; return EnableAutoConfiguration.class; &#125;&#125;private static class AutoConfigurationGroup implements DeferredImportSelector.Group, BeanClassLoaderAware, BeanFactoryAware, ResourceLoaderAware &#123; public void process(AnnotationMetadata annotationMetadata, DeferredImportSelector deferredImportSelector) &#123; Assert.state(deferredImportSelector instanceof AutoConfigurationImportSelector, () -&gt; String.format(&quot;Only %s implementations are supported, got %s&quot;, AutoConfigurationImportSelector.class.getSimpleName(), deferredImportSelector.getClass().getName())); AutoConfigurationEntry autoConfigurationEntry = ((AutoConfigurationImportSelector) deferredImportSelector).getAutoConfigurationEntry(annotationMetadata); this.autoConfigurationEntries.add(autoConfigurationEntry); for (String importClassName : autoConfigurationEntry.getConfigurations()) &#123; this.entries.putIfAbsent(importClassName, annotationMetadata); &#125; &#125; @Override public Iterable&lt;Entry&gt; selectImports() &#123; if (this.autoConfigurationEntries.isEmpty()) &#123; return Collections.emptyList(); &#125; Set&lt;String&gt; allExclusions = this.autoConfigurationEntries.stream() .map(AutoConfigurationEntry::getExclusions).flatMap(Collection::stream).collect(Collectors.toSet()); Set&lt;String&gt; processedConfigurations = this.autoConfigurationEntries.stream() .map(AutoConfigurationEntry::getConfigurations).flatMap(Collection::stream) .collect(Collectors.toCollection(LinkedHashSet::new)); processedConfigurations.removeAll(allExclusions); return sortAutoConfigurations(processedConfigurations, getAutoConfigurationMetadata()).stream() .map((importClassName) -&gt; new Entry(this.entries.get(importClassName), importClassName)) .collect(Collectors.toList()); &#125;&#125; @Conditional有很多扩展注解，最终这些扩展注解是通过 @Conditional中指定的类来处理具体的逻辑的。最终都是通过 SpringBootCondition 的 matches 方法。 @Conditional扩展注解 判断件 具体处理类 @ConditionalOnJava 系统的java版本是否符合要求 OnJavaCondition @ConditionalOnBean 容器中存在指定Bean OnBeanCondition @ConditionalOnMissingBean 容器中不存在指定Bean OnBeanCondition @ConditionalOnExpression 满足SpEL表达式指定 OnExpressionCondition @ConditionalOnClass 系统中有指定的类 OnClassCondition @ConditionalOnMissingClass 系统中没有指定的类 OnClassCondition @ConditionalOnSingleCandidate 容器中只有一个指定的Bean或者该Bean是首选Bean OnBeanCondition @ConditionalOnProperty 系统中指定的属性是否有指定的值 OnPropertyCondition @ConditionalOnResource 类路径下是否存在指定资源文件 OnResourceCondition @ConditionalOnNotWebApplication 不是Web应用 OnWebApplicationCondition @ConditionalOnWebApplication 是Web应用 OnWebApplicationCondition getMatchOutcome 方法是提供给具体的处理类去实现的。 12345678910111213141516171819202122232425262728293031323334353637383940414243public abstract class SpringBootCondition implements Condition &#123; public final boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) &#123; String classOrMethodName = getClassOrMethodName(metadata); try &#123; ConditionOutcome outcome = getMatchOutcome(context, metadata); logOutcome(classOrMethodName, outcome); recordEvaluation(context, classOrMethodName, outcome); return outcome.isMatch(); &#125; catch (NoClassDefFoundError ex) &#123; throw new IllegalStateException(ex.getMessage(), ex); &#125; catch (RuntimeException ex) &#123; throw new IllegalStateException(&quot;Error processing condition on &quot; + getName(metadata), ex); &#125; &#125; public abstract ConditionOutcome getMatchOutcome(ConditionContext context, AnnotatedTypeMetadata metadata);&#125;class OnClassCondition extends FilteringSpringBootCondition &#123; public ConditionOutcome getMatchOutcome(ConditionContext context, AnnotatedTypeMetadata metadata) &#123; ClassLoader classLoader = context.getClassLoader(); ConditionMessage matchMessage = ConditionMessage.empty(); List&lt;String&gt; onClasses = getCandidates(metadata, ConditionalOnClass.class); if (onClasses != null) &#123; List&lt;String&gt; missing = filter(onClasses, ClassNameFilter.MISSING, classLoader); if (!missing.isEmpty()) &#123; return ConditionOutcome.noMatch(ConditionMessage.forCondition(ConditionalOnClass.class) .didNotFind(&quot;required class&quot;, &quot;required classes&quot;).items(Style.QUOTE, missing)); &#125; matchMessage = matchMessage.andCondition(ConditionalOnClass.class) .found(&quot;required class&quot;, &quot;required classes&quot;) .items(Style.QUOTE, filter(onClasses, ClassNameFilter.PRESENT, classLoader)); &#125; List&lt;String&gt; onMissingClasses = getCandidates(metadata, ConditionalOnMissingClass.class); if (onMissingClasses != null) &#123; List&lt;String&gt; present = filter(onMissingClasses, ClassNameFilter.PRESENT, classLoader); if (!present.isEmpty()) &#123; return ConditionOutcome.noMatch(ConditionMessage.forCondition(ConditionalOnMissingClass.class).found(&quot;unwanted class&quot;, &quot;unwanted classes&quot;).items(Style.QUOTE, present)); &#125; matchMessage = matchMessage.andCondition(ConditionalOnMissingClass.class) .didNotFind(&quot;unwanted class&quot;, &quot;unwanted classes&quot;) .items(Style.QUOTE, filter(onMissingClasses, ClassNameFilter.MISSING, classLoader)); &#125; return ConditionOutcome.match(matchMessage); &#125;&#125;","tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://example.com/tags/SpringBoot/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"},{"name":"SpringBoot","slug":"Spring/SpringBoot","permalink":"http://example.com/categories/Spring/SpringBoot/"}]},{"title":"SpringBoot资源加载","date":"2020-10-15T05:08:20.000Z","path":"blog/Spring/SpringBoot/SpringBoot资源加载/","text":"@ConfigurationProperties被 @ConfigurationProperties 注解修饰的类的属性注入，可通过 @ConfigurationPropertiesScan 和 @EnableConfigurationProperties 注解将 @ConfigurationProperties 修饰的类注册到Spring容器中，且注册处理属性注入的 BeanPostProcessor 后置处理器及相关的类。 @EnableConfigurationProperties 注解通过 @Import 注解导入 EnableConfigurationPropertiesRegistrar 。能讲该注解 value属性中配置的加了 @ConfigurationProperties 注解的类注册到Spring容器中。 12345678@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(EnableConfigurationPropertiesRegistrar.class)public @interface EnableConfigurationProperties &#123; String VALIDATOR_BEAN_NAME = &quot;configurationPropertiesValidator&quot;; Class&lt;?&gt;[] value() default &#123;&#125;;&#125; EnableConfigurationPropertiesRegistrar 实现了 ImportBeanDefinitionRegistrar 接口，在扫描 BeanDefinition 时被调用 registerBeanDefinitions 方法，从而完成 ConfigurationPropertiesBindingPostProcessor 、 BoundConfigurationProperties 、 ConfigurationPropertiesBinder 等处理属性注入的Bean的注册。 通过 getTypes 方法获取 @EnableConfigurationProperties 注解中 value属性配置的类，遍历这些类通过 ConfigurationPropertiesBeanRegistrar#register 将这些类注册到Spring容器中。 1234567891011121314151617class EnableConfigurationPropertiesRegistrar implements ImportBeanDefinitionRegistrar &#123; public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry) &#123; registerInfrastructureBeans(registry); ConfigurationPropertiesBeanRegistrar beanRegistrar = new ConfigurationPropertiesBeanRegistrar(registry); getTypes(metadata).forEach(beanRegistrar::register); &#125; static void registerInfrastructureBeans(BeanDefinitionRegistry registry) &#123; ConfigurationPropertiesBindingPostProcessor.register(registry); BoundConfigurationProperties.register(registry); ConfigurationBeanFactoryMetadata.register(registry); &#125; private Set&lt;Class&lt;?&gt;&gt; getTypes(AnnotationMetadata metadata) &#123; return metadata.getAnnotations().stream(EnableConfigurationProperties.class) .flatMap((annotation) -&gt; Arrays.stream(annotation.getClassArray(MergedAnnotation.VALUE))) .filter((type) -&gt; void.class != type).collect(Collectors.toSet()); &#125;&#125; 再通过 ConfigurationPropertiesBeanRegistrar 将其注册到Spring容器前会检查该类上是否存在 @ConfigurationProperties 注解，且通过该方式生成Bean的名称和通过 @Component 等注解生成Bean不一样。这里会将 @ConfigurationProperties 注解 prefix 属性配置的值加上 - 再加上类的全限定名。 12345678910111213141516171819202122232425262728final class ConfigurationPropertiesBeanRegistrar &#123; void register(Class&lt;?&gt; type) &#123; MergedAnnotation&lt;ConfigurationProperties&gt; annotation = MergedAnnotations .from(type, SearchStrategy.TYPE_HIERARCHY).get(ConfigurationProperties.class); register(type, annotation); &#125; void register(Class&lt;?&gt; type, MergedAnnotation&lt;ConfigurationProperties&gt; annotation) &#123; String name = getName(type, annotation); // 特殊化Bean的名称 if (!containsBeanDefinition(name)) &#123;// 判断该Bean是否注册到容器中 registerBeanDefinition(name, type, annotation); // 注册BeanDefinition到容器中 &#125; &#125; private String getName(Class&lt;?&gt; type, MergedAnnotation&lt;ConfigurationProperties&gt; annotation) &#123; String prefix = annotation.isPresent() ? annotation.getString(&quot;prefix&quot;) : &quot;&quot;; return (StringUtils.hasText(prefix) ? prefix + &quot;-&quot; + type.getName() : type.getName()); &#125; private void registerBeanDefinition(String beanName, Class&lt;?&gt; type, MergedAnnotation&lt;ConfigurationProperties&gt; annotation) &#123; this.registry.registerBeanDefinition(beanName, createBeanDefinition(beanName, type)); &#125; private BeanDefinition createBeanDefinition(String beanName, Class&lt;?&gt; type) &#123; if (BindMethod.forType(type) == BindMethod.VALUE_OBJECT) &#123; // 根据该类是否有构造函数，且构造函数上是否有ConstructorBinding注解 return new ConfigurationPropertiesValueObjectBeanDefinition(this.beanFactory, beanName, type); &#125; GenericBeanDefinition definition = new GenericBeanDefinition(); definition.setBeanClass(type); return definition; &#125;&#125; ConfigurationPropertiesBindingPostProcessor 实现了 BeanPostProcessor 后置处理器，在Bean创建过程中会调用该Bean的后置处理器的 postProcessBeforeInitialization 最终通过 ConfigurationPropertiesBinder 完成属性的注入。 12345678910111213141516171819202122232425262728293031public class ConfigurationPropertiesBindingPostProcessor implements BeanPostProcessor, PriorityOrdered, ApplicationContextAware, InitializingBean &#123; public static void register(BeanDefinitionRegistry registry) &#123; Assert.notNull(registry, &quot;Registry must not be null&quot;); if (!registry.containsBeanDefinition(BEAN_NAME)) &#123; GenericBeanDefinition definition = new GenericBeanDefinition(); definition.setBeanClass(ConfigurationPropertiesBindingPostProcessor.class); definition.setRole(BeanDefinition.ROLE_INFRASTRUCTURE); registry.registerBeanDefinition(BEAN_NAME, definition); &#125; ConfigurationPropertiesBinder.register(registry); &#125; public void afterPropertiesSet() throws Exception &#123; this.registry = (BeanDefinitionRegistry) this.applicationContext.getAutowireCapableBeanFactory(); this.binder = ConfigurationPropertiesBinder.get(this.applicationContext); &#125; public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; bind(ConfigurationPropertiesBean.get(this.applicationContext, bean, beanName)); return bean; &#125; private void bind(ConfigurationPropertiesBean bean) &#123; if (bean == null || hasBoundValueObject(bean.getName())) &#123; return; &#125; Assert.state(bean.getBindMethod() == BindMethod.JAVA_BEAN, &quot;Cannot bind @ConfigurationProperties for bean &#x27;&quot; + bean.getName() + &quot;&#x27;. Ensure that @ConstructorBinding has not been applied to regular bean&quot;); try &#123; this.binder.bind(bean); &#125; catch (Exception ex) &#123; throw new ConfigurationPropertiesBindException(bean, ex); &#125; &#125;&#125; 最终通过层层调用将从 PropertySources 匹配到的属性值通过set方法将属性赋值。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102class ConfigurationPropertiesBinder &#123; BindResult&lt;?&gt; bind(ConfigurationPropertiesBean propertiesBean) &#123; Bindable&lt;?&gt; target = propertiesBean.asBindTarget(); ConfigurationProperties annotation = propertiesBean.getAnnotation(); BindHandler bindHandler = getBindHandler(target, annotation); return getBinder().bind(annotation.prefix(), target, bindHandler); &#125; private Binder getBinder() &#123; if (this.binder == null) &#123; this.binder = new Binder(getConfigurationPropertySources(), getPropertySourcesPlaceholdersResolver(), getConversionService(), getPropertyEditorInitializer(), null, ConfigurationPropertiesBindConstructorProvider.INSTANCE); &#125; return this.binder; &#125;&#125;public class Binder &#123; public &lt;T&gt; BindResult&lt;T&gt; bind(ConfigurationPropertyName name, Bindable&lt;T&gt; target, BindHandler handler) &#123; T bound = bind(name, target, handler, false); return BindResult.of(bound); &#125; private &lt;T&gt; T bind(ConfigurationPropertyName name, Bindable&lt;T&gt; target, BindHandler handler, Context context, boolean allowRecursiveBinding, boolean create) &#123; try &#123; Bindable&lt;T&gt; replacementTarget = handler.onStart(name, target, context); if (replacementTarget == null) &#123; return handleBindResult(name, target, handler, context, null, create); &#125; target = replacementTarget; Object bound = bindObject(name, target, handler, context, allowRecursiveBinding); return handleBindResult(name, target, handler, context, bound, create); &#125; catch (Exception ex) &#123; return handleBindError(name, target, handler, context, ex); &#125; &#125; private Object bindDataObject(ConfigurationPropertyName name, Bindable&lt;?&gt; target, BindHandler handler, Context context, boolean allowRecursiveBinding) &#123; if (isUnbindableBean(name, target, context)) &#123; return null; &#125; Class&lt;?&gt; type = target.getType().resolve(Object.class); if (!allowRecursiveBinding &amp;&amp; context.isBindingDataObject(type)) &#123; return null; &#125; DataObjectPropertyBinder propertyBinder = (propertyName, propertyTarget) -&gt; bind(name.append(propertyName), propertyTarget, handler, context, false, false); return context.withDataObject(type, () -&gt; &#123; for (DataObjectBinder dataObjectBinder : this.dataObjectBinders) &#123; Object instance = dataObjectBinder.bind(name, target, context, propertyBinder); if (instance != null) &#123; return instance; &#125; &#125; return null; &#125;); &#125;&#125;class JavaBeanBinder implements DataObjectBinder &#123; public &lt;T&gt; T bind(ConfigurationPropertyName name, Bindable&lt;T&gt; target, Context context, DataObjectPropertyBinder propertyBinder) &#123; boolean hasKnownBindableProperties = target.getValue() != null &amp;&amp; hasKnownBindableProperties(name, context); Bean&lt;T&gt; bean = Bean.get(target, hasKnownBindableProperties); if (bean == null) &#123; return null; &#125; BeanSupplier&lt;T&gt; beanSupplier = bean.getSupplier(target); boolean bound = bind(propertyBinder, bean, beanSupplier, context); return (bound ? beanSupplier.get() : null); &#125; private &lt;T&gt; boolean bind(DataObjectPropertyBinder propertyBinder, Bean&lt;T&gt; bean, BeanSupplier&lt;T&gt; beanSupplier, Context context) &#123; boolean bound = false; for (BeanProperty beanProperty : bean.getProperties().values()) &#123; bound |= bind(beanSupplier, propertyBinder, beanProperty); context.clearConfigurationProperty(); &#125; return bound; &#125; private &lt;T&gt; boolean bind(BeanSupplier&lt;T&gt; beanSupplier, DataObjectPropertyBinder propertyBinder, BeanProperty property) &#123; String propertyName = property.getName(); ResolvableType type = property.getType(); Supplier&lt;Object&gt; value = property.getValue(beanSupplier); Annotation[] annotations = property.getAnnotations(); Object bound = propertyBinder.bindProperty(propertyName, Bindable.of(type).withSuppliedValue(value).withAnnotations(annotations)); if (bound == null) &#123; return false; &#125; if (property.isSettable()) &#123; property.setValue(beanSupplier, bound); &#125; else if (value == null || !bound.equals(value.get())) &#123; throw new IllegalStateException(&quot;No setter found for property: &quot; + property.getName()); &#125; return true; &#125;&#125;static class BeanProperty &#123; private Method getter; private Method setter; private Field field; void setValue(Supplier&lt;?&gt; instance, Object value) &#123; try &#123; this.setter.setAccessible(true); this.setter.invoke(instance.get(), value); &#125; catch (Exception ex) &#123; throw new IllegalStateException(&quot;Unable to set value for property &quot; + this.name, ex); &#125; &#125;&#125; @ConfigurationPropertiesScan 注解的作用是扫描所有带有 @ConfigurationProperties 注解的类将其注册到Spring容器中。且该注解上被 @EnableConfigurationProperties 注解标记。 123456789101112@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(ConfigurationPropertiesScanRegistrar.class)@EnableConfigurationPropertiespublic @interface ConfigurationPropertiesScan &#123; @AliasFor(&quot;basePackages&quot;) String[] value() default &#123;&#125;; @AliasFor(&quot;value&quot;) String[] basePackages() default &#123;&#125;; Class&lt;?&gt;[] basePackageClasses() default &#123;&#125;;&#125; ConfigurationPropertiesScanRegistrar 同样实现了 ImportBeanDefinitionRegistrar 接口，首先获取需要扫描的包，若未指定则以当前注解所在类所在的包作为扫描包，通过 ClassPathScanningCandidateComponentProvider 遍历扫描所有的包，扫描出包中被 @ConfigurationProperties 注解标注，但是未被 @Component 注解及其派生注解标注的类，注册到Spring容器中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253class ConfigurationPropertiesScanRegistrar implements ImportBeanDefinitionRegistrar &#123; public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; Set&lt;String&gt; packagesToScan = getPackagesToScan(importingClassMetadata); // 获取扫描的包 scan(registry, packagesToScan); // 扫描出包中所有带有@ConfigurationProperties注解的类，注册到Spring容器中 &#125; private Set&lt;String&gt; getPackagesToScan(AnnotationMetadata metadata) &#123; AnnotationAttributes attributes = AnnotationAttributes.fromMap(metadata.getAnnotationAttributes(ConfigurationPropertiesScan.class.getName())); String[] basePackages = attributes.getStringArray(&quot;basePackages&quot;); Class&lt;?&gt;[] basePackageClasses = attributes.getClassArray(&quot;basePackageClasses&quot;); Set&lt;String&gt; packagesToScan = new LinkedHashSet&lt;&gt;(Arrays.asList(basePackages)); for (Class&lt;?&gt; basePackageClass : basePackageClasses) &#123; packagesToScan.add(ClassUtils.getPackageName(basePackageClass)); &#125; if (packagesToScan.isEmpty()) &#123; // 若未指定则以当前注解所在类所在的包作为扫描包 packagesToScan.add(ClassUtils.getPackageName(metadata.getClassName())); &#125; packagesToScan.removeIf((candidate) -&gt; !StringUtils.hasText(candidate)); return packagesToScan; &#125; private void scan(BeanDefinitionRegistry registry, Set&lt;String&gt; packages) &#123; ConfigurationPropertiesBeanRegistrar registrar = new ConfigurationPropertiesBeanRegistrar(registry); ClassPathScanningCandidateComponentProvider scanner = getScanner(registry); for (String basePackage : packages) &#123; for (BeanDefinition candidate : scanner.findCandidateComponents(basePackage)) &#123; register(registrar, candidate.getBeanClassName()); &#125; &#125; &#125; private ClassPathScanningCandidateComponentProvider getScanner(BeanDefinitionRegistry registry) &#123; ClassPathScanningCandidateComponentProvider scanner = new ClassPathScanningCandidateComponentProvider(false); scanner.setEnvironment(this.environment); scanner.setResourceLoader(this.resourceLoader); scanner.addIncludeFilter(new AnnotationTypeFilter(ConfigurationProperties.class)); // 添加过滤器，过滤出带有@ConfigurationProperties注解的类 TypeExcludeFilter typeExcludeFilter = new TypeExcludeFilter(); typeExcludeFilter.setBeanFactory((BeanFactory) registry); scanner.addExcludeFilter(typeExcludeFilter); return scanner; &#125; private void register(ConfigurationPropertiesBeanRegistrar registrar, String className) throws LinkageError &#123; try &#123; register(registrar, ClassUtils.forName(className, null)); &#125; catch (ClassNotFoundException ex) &#123; &#125; &#125; private void register(ConfigurationPropertiesBeanRegistrar registrar, Class&lt;?&gt; type) &#123; if (!isComponent(type)) &#123; // 该类没有被@Component注解修饰 registrar.register(type); // 注册过程和上面一样 &#125; &#125; private boolean isComponent(Class&lt;?&gt; type) &#123; return MergedAnnotations.from(type, SearchStrategy.TYPE_HIERARCHY).isPresent(Component.class); &#125;&#125; Enviroment Enviroment 是Spring为运行环境提供的高度抽象接口，项目运行中的所有相关配置都基于此接口，在 SpringApplication 的 prepareEnvironment 方法中完成了配置文件的加载。通过发布环境准备就绪事件 ApplicationEnvironmentPreparedEvent ，从而加载项目中的配置文件。 123456789101112131415private ConfigurableEnvironment prepareEnvironment(SpringApplicationRunListeners listeners, DefaultBootstrapContext bootstrapContext, ApplicationArguments applicationArguments) &#123; // Create and configure the environment ConfigurableEnvironment environment = getOrCreateEnvironment(); // 获取或创建ConfigurableEnvironment，会调用超类AbstractEnvironment的无参构造方法 configureEnvironment(environment, applicationArguments.getSourceArgs()); // 加载默认配置 ConfigurationPropertySources.attach(environment); listeners.environmentPrepared(bootstrapContext, environment); // 发布环境准备就绪事件ApplicationEnvironmentPreparedEvent，从而加载项目中的配置文件 DefaultPropertiesPropertySource.moveToEnd(environment); // 将defaultProperties移到列表最后，即将其优先级降到最低 Assert.state(!environment.containsProperty(&quot;spring.main.environment-prefix&quot;), &quot;Environment prefix cannot be set via properties.&quot;); bindToSpringApplication(environment); if (!this.isCustomEnvironment) &#123; environment = new EnvironmentConverter(getClassLoader()).convertEnvironmentIfNecessary(environment, deduceEnvironmentClass()); &#125; ConfigurationPropertySources.attach(environment); return environment;&#125; 在 getOrCreateEnvironment 方法中对 Environment 初始化，以 ApplicationServletEnvironment 为例，其初始化时会调用超类 AbstractEnvironment 的无参构造函数，然后调用子类 StandardServletEnvironment 实现的 customizePropertySources 方法，添加类型为 StubPropertySource 的 servletConfigInitParams 和 servletContextInitParams ，然后再调用其父类 StandardEnvironment 的 customizePropertySources 方法，将 systemProperties 和 systemEnvironment 加载到 Environment 中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class SpringApplication &#123; private ConfigurableEnvironment getOrCreateEnvironment() &#123; if (this.environment != null) &#123; return this.environment; &#125; switch (this.webApplicationType) &#123; case SERVLET: return new ApplicationServletEnvironment(); case REACTIVE: return new ApplicationReactiveWebEnvironment(); default: return new ApplicationEnvironment(); &#125; &#125;&#125;class ApplicationServletEnvironment extends StandardServletEnvironment &#123; protected ConfigurablePropertyResolver createPropertyResolver(MutablePropertySources propertySources) &#123; return ConfigurationPropertySources.createPropertyResolver(propertySources); &#125;&#125;public class StandardServletEnvironment extends StandardEnvironment implements ConfigurableWebEnvironment &#123; public static final String SERVLET_CONTEXT_PROPERTY_SOURCE_NAME = &quot;servletContextInitParams&quot;; public static final String SERVLET_CONFIG_PROPERTY_SOURCE_NAME = &quot;servletConfigInitParams&quot;; public static final String JNDI_PROPERTY_SOURCE_NAME = &quot;jndiProperties&quot;; protected void customizePropertySources(MutablePropertySources propertySources) &#123; propertySources.addLast(new StubPropertySource(SERVLET_CONFIG_PROPERTY_SOURCE_NAME)); propertySources.addLast(new StubPropertySource(SERVLET_CONTEXT_PROPERTY_SOURCE_NAME)); if (JndiLocatorDelegate.isDefaultJndiEnvironmentAvailable()) &#123; propertySources.addLast(new JndiPropertySource(JNDI_PROPERTY_SOURCE_NAME)); &#125; super.customizePropertySources(propertySources); &#125;&#125;public class StandardEnvironment extends AbstractEnvironment &#123; public static final String SYSTEM_ENVIRONMENT_PROPERTY_SOURCE_NAME = &quot;systemEnvironment&quot;; public static final String SYSTEM_PROPERTIES_PROPERTY_SOURCE_NAME = &quot;systemProperties&quot;; protected void customizePropertySources(MutablePropertySources propertySources) &#123; propertySources.addLast(new PropertiesPropertySource(SYSTEM_PROPERTIES_PROPERTY_SOURCE_NAME, getSystemProperties())); propertySources.addLast(new SystemEnvironmentPropertySource(SYSTEM_ENVIRONMENT_PROPERTY_SOURCE_NAME, getSystemEnvironment())); &#125;&#125;public abstract class AbstractEnvironment implements ConfigurableEnvironment &#123; public AbstractEnvironment() &#123; this(new MutablePropertySources()); &#125; protected AbstractEnvironment(MutablePropertySources propertySources) &#123; this.propertySources = propertySources; this.propertyResolver = createPropertyResolver(propertySources); customizePropertySources(propertySources); &#125; protected void customizePropertySources(MutablePropertySources propertySources) &#123; &#125;&#125; 发布环境准备就绪事件 ApplicationEnvironmentPreparedEvent 是通过 getRunListeners 中从 spring.factories 配置文件加载的 EventPublishingRunListener 来完成的。 123# Run Listenersorg.springframework.boot.SpringApplicationRunListener=\\org.springframework.boot.context.event.EventPublishingRunListener 123456public class SpringApplication &#123; private SpringApplicationRunListeners getRunListeners(String[] args) &#123; Class&lt;?&gt;[] types = new Class&lt;?&gt;[] &#123; SpringApplication.class, String[].class &#125;; return new SpringApplicationRunListeners(logger, getSpringFactoriesInstances(SpringApplicationRunListener.class, types, this, args)); &#125;&#125; 故最终会调用 EventPublishingRunListener 的 environmentPrepared 方法来发布 ApplicationEnvironmentPreparedEvent 事件。 12345678910class SpringApplicationRunListeners &#123; void environmentPrepared(ConfigurableBootstrapContext bootstrapContext, ConfigurableEnvironment environment) &#123; doWithListeners(&quot;spring.boot.application.environment-prepared&quot;, (listener) -&gt; listener.environmentPrepared(bootstrapContext, environment)); &#125;&#125;public class EventPublishingRunListener implements SpringApplicationRunListener, Ordered &#123; public void environmentPrepared(ConfigurableBootstrapContext bootstrapContext, ConfigurableEnvironment environment) &#123; this.initialMulticaster.multicastEvent(new ApplicationEnvironmentPreparedEvent(bootstrapContext, this.application, this.args, environment)); &#125;&#125; 监听了 ApplicationEnvironmentPreparedEvent 事件的类很多个，旧版本中是通过 ConfigFileApplicationListener 来加载配置文件，该监听器的加载是通过 SpringApplication构造方法中通过 getSpringFactoriesInstances 方法从 spring.factories 配置文件中加载 ApplicationListener 时加载的。新版本是通过 ConfigDataEnvironmentPostProcessor 来加载的配置文件，其是通过加载 ApplicationListener 时加载的 EnvironmentPostProcessorApplicationListener 监听器时该类的构造方法中又加载了一系列 EnvironmentPostProcessor 后置处理器中的一个。这里 DEFAULT_SEARCH_LOCATIONS 体现了配置文件加载顺序。 1234567891011121314151617181920212223242526272829303132public class ConfigFileApplicationListener implements EnvironmentPostProcessor, SmartApplicationListener, Ordered &#123; private static final String DEFAULT_SEARCH_LOCATIONS = &quot;classpath:/,classpath:/config/,file:./,file:./config/*/,file:./config/&quot;; private static final String DEFAULT_PROPERTIES = &quot;defaultProperties&quot;; private static final String DEFAULT_NAMES = &quot;application&quot;; public void onApplicationEvent(ApplicationEvent event) &#123; if (event instanceof ApplicationEnvironmentPreparedEvent) &#123; onApplicationEnvironmentPreparedEvent((ApplicationEnvironmentPreparedEvent) event); &#125; if (event instanceof ApplicationPreparedEvent) &#123; onApplicationPreparedEvent(event); &#125; &#125; private void onApplicationEnvironmentPreparedEvent(ApplicationEnvironmentPreparedEvent event) &#123; List&lt;EnvironmentPostProcessor&gt; postProcessors = loadPostProcessors(); postProcessors.add(this); AnnotationAwareOrderComparator.sort(postProcessors); for (EnvironmentPostProcessor postProcessor : postProcessors) &#123; postProcessor.postProcessEnvironment(event.getEnvironment(), event.getSpringApplication()); &#125; &#125; List&lt;EnvironmentPostProcessor&gt; loadPostProcessors() &#123; // 加载spring.factories配置文件中以EnvironmentPostProcessor为key配置的类 return SpringFactoriesLoader.loadFactories(EnvironmentPostProcessor.class, getClass().getClassLoader()); &#125; public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application) &#123; addPropertySources(environment, application.getResourceLoader()); &#125; protected void addPropertySources(ConfigurableEnvironment environment, ResourceLoader resourceLoader) &#123; RandomValuePropertySource.addToEnvironment(environment); new Loader(environment, resourceLoader).load(); // 最终通过该处去加载配置文件 &#125;&#125; ConfigFileApplicationListener 也实现了 EnvironmentPostProcessor 故最终会执行其 postProcessEnvironment 方法最终通过 Loader 类来加载配置文件。构造方法中会加载 PropertySourceLoader ，主要是 PropertiesPropertySourceLoader 和 YamlPropertySourceLoader 12345678private class Loader &#123; Loader(ConfigurableEnvironment environment, ResourceLoader resourceLoader) &#123; this.environment = environment; this.placeholdersResolver = new PropertySourcesPlaceholdersResolver(this.environment); this.resourceLoader = (resourceLoader != null) ? resourceLoader : new DefaultResourceLoader(null); this.propertySourceLoaders = SpringFactoriesLoader.loadFactories(PropertySourceLoader.class, getClass().getClassLoader()); &#125;&#125; 1234# PropertySource Loadersorg.springframework.boot.env.PropertySourceLoader=\\org.springframework.boot.env.PropertiesPropertySourceLoader,\\org.springframework.boot.env.YamlPropertySourceLoader 最终调用load方法来加载配置文件，首先获取需要遍历的目录，其实就是将 DEFAULT_SEARCH_LOCATIONS 中的目录拆分成数组，并进行反序，若为Cloud项目会在 BootstrapApplicationListener 中添加 MapPropertySource 配置，从而会获取 spring.config.name 设置的值，默认是 bootstrap ，故默认会先加载各个目录下的 bootstrap 配置文件。然后再加载 application 配置文件。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061void load() &#123; FilteredPropertySource.apply(this.environment, DEFAULT_PROPERTIES, LOAD_FILTERED_PROPERTY, (defaultProperties) -&gt; &#123; this.profiles = new LinkedList&lt;&gt;(); this.processedProfiles = new LinkedList&lt;&gt;(); this.activatedProfiles = false; this.loaded = new LinkedHashMap&lt;&gt;(); initializeProfiles(); while (!this.profiles.isEmpty()) &#123; Profile profile = this.profiles.poll(); if (isDefaultProfile(profile)) &#123; addProfileToEnvironment(profile.getName()); &#125; load(profile, this::getPositiveProfileFilter, addToLoaded(MutablePropertySources::addLast, false)); this.processedProfiles.add(profile); &#125; load(null, this::getNegativeProfileFilter, addToLoaded(MutablePropertySources::addFirst, true)); addLoadedPropertySources(); applyActiveProfiles(defaultProperties); &#125;);&#125;class FilteredPropertySource extends PropertySource&lt;PropertySource&lt;?&gt;&gt; &#123; static void apply(ConfigurableEnvironment environment, String propertySourceName, Set&lt;String&gt; filteredProperties, Consumer&lt;PropertySource&lt;?&gt;&gt; operation) &#123; MutablePropertySources propertySources = environment.getPropertySources(); PropertySource&lt;?&gt; original = propertySources.get(propertySourceName); if (original == null) &#123; operation.accept(null); return; &#125; propertySources.replace(propertySourceName, new FilteredPropertySource(original, filteredProperties)); try &#123; operation.accept(original); &#125; finally &#123; propertySources.replace(propertySourceName, original); &#125; &#125;&#125;private void load(Profile profile, DocumentFilterFactory filterFactory, DocumentConsumer consumer) &#123; getSearchLocations().forEach((location) -&gt; &#123; boolean isDirectory = location.endsWith(&quot;/&quot;); Set&lt;String&gt; names = isDirectory ? getSearchNames() : NO_SEARCH_NAMES; names.forEach((name) -&gt; load(location, name, profile, filterFactory, consumer)); &#125;);&#125;private Set&lt;String&gt; getSearchLocations() &#123; Set&lt;String&gt; locations = getSearchLocations(CONFIG_ADDITIONAL_LOCATION_PROPERTY); if (this.environment.containsProperty(CONFIG_LOCATION_PROPERTY)) &#123; locations.addAll(getSearchLocations(CONFIG_LOCATION_PROPERTY)); &#125; else &#123; // 将DEFAULT_SEARCH_LOCATIONS中的目录拆分成数组，并进行反序 locations.addAll(asResolvedSet(ConfigFileApplicationListener.this.searchLocations, DEFAULT_SEARCH_LOCATIONS)); &#125; return locations;&#125;private Set&lt;String&gt; getSearchNames() &#123; if (this.environment.containsProperty(CONFIG_NAME_PROPERTY)) &#123; String property = this.environment.getProperty(CONFIG_NAME_PROPERTY); Set&lt;String&gt; names = asResolvedSet(property, null); names.forEach(this::assertValidConfigName); return names; &#125; return asResolvedSet(ConfigFileApplicationListener.this.names, DEFAULT_NAMES);&#125; 遍历 propertySourceLoaders 依次通过 PropertiesPropertySourceLoader 和 YamlPropertySourceLoader 去加载解析配置文件。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879private void load(String location, String name, Profile profile, DocumentFilterFactory filterFactory, DocumentConsumer consumer) &#123; if (!StringUtils.hasText(name)) &#123; for (PropertySourceLoader loader : this.propertySourceLoaders) &#123; if (canLoadFileExtension(loader, location)) &#123; load(loader, location, profile, filterFactory.getDocumentFilter(profile), consumer); return; &#125; &#125; throw new IllegalStateException(&quot;File extension of config file location &#x27;&quot; + location + &quot;&#x27; is not known to any PropertySourceLoader. If the location is meant to reference &quot; + &quot;a directory, it must end in &#x27;/&#x27;&quot;); &#125; Set&lt;String&gt; processed = new HashSet&lt;&gt;(); for (PropertySourceLoader loader : this.propertySourceLoaders) &#123; for (String fileExtension : loader.getFileExtensions()) &#123; if (processed.add(fileExtension)) &#123; loadForFileExtension(loader, location + name, &quot;.&quot; + fileExtension, profile, filterFactory, consumer); &#125; &#125; &#125;&#125;private void loadForFileExtension(PropertySourceLoader loader, String prefix, String fileExtension, Profile profile, DocumentFilterFactory filterFactory, DocumentConsumer consumer) &#123; DocumentFilter defaultFilter = filterFactory.getDocumentFilter(null); DocumentFilter profileFilter = filterFactory.getDocumentFilter(profile); if (profile != null) &#123; // 若设置了环境则加载对应环境的配置文件 String profileSpecificFile = prefix + &quot;-&quot; + profile + fileExtension; load(loader, profileSpecificFile, profile, defaultFilter, consumer); load(loader, profileSpecificFile, profile, profileFilter, consumer); for (Profile processedProfile : this.processedProfiles) &#123; if (processedProfile != null) &#123; String previouslyLoaded = prefix + &quot;-&quot; + processedProfile + fileExtension; load(loader, previouslyLoaded, profile, profileFilter, consumer); &#125; &#125; &#125; load(loader, prefix + fileExtension, profile, profileFilter, consumer);&#125;private void load(PropertySourceLoader loader, String location, Profile profile, DocumentFilter filter, DocumentConsumer consumer) &#123; Resource[] resources = getResources(location); for (Resource resource : resources) &#123; try &#123; if (resource == null || !resource.exists()) &#123; continue; &#125; if (!StringUtils.hasText(StringUtils.getFilenameExtension(resource.getFilename()))) &#123; continue; &#125; String name = &quot;applicationConfig: [&quot; + getLocationName(location, resource) + &quot;]&quot;; List&lt;Document&gt; documents = loadDocuments(loader, name, resource); if (CollectionUtils.isEmpty(documents)) &#123; continue; &#125; List&lt;Document&gt; loaded = new ArrayList&lt;&gt;(); for (Document document : documents) &#123; if (filter.match(document)) &#123; addActiveProfiles(document.getActiveProfiles()); addIncludedProfiles(document.getIncludeProfiles()); loaded.add(document); &#125; &#125; Collections.reverse(loaded); if (!loaded.isEmpty()) &#123; loaded.forEach((document) -&gt; consumer.accept(profile, document)); &#125; &#125; catch (Exception ex) &#123; StringBuilder description = getDescription(&quot;Failed to load property source from &quot;, location, resource, profile); throw new IllegalStateException(description.toString(), ex); &#125; &#125;&#125;private List&lt;Document&gt; loadDocuments(PropertySourceLoader loader, String name, Resource resource) throws IOException &#123; DocumentsCacheKey cacheKey = new DocumentsCacheKey(loader, resource); List&lt;Document&gt; documents = this.loadDocumentsCache.get(cacheKey); if (documents == null) &#123; // 调用具体的PropertySourceLoader去加载解析配置文件 List&lt;PropertySource&lt;?&gt;&gt; loaded = loader.load(name, resource); documents = asDocuments(loaded); this.loadDocumentsCache.put(cacheKey, documents); &#125; return documents;&#125; 若是在 Spring Cloud 项目中会通过ApplicationListener加载 BootstrapApplicationListener ，在该监听器中的 bootstrapServiceContext 方法中添加了 MapPropertySource 配置，将 spring.config.name 值设置为 configName ， configName 默认值为 bootstrap 。 1234org.springframework.context.ApplicationListener=\\org.springframework.cloud.bootstrap.BootstrapApplicationListener,\\org.springframework.cloud.bootstrap.LoggingSystemShutdownListener,\\org.springframework.cloud.context.restart.RestartListener 12345678910111213141516171819202122232425public class BootstrapApplicationListener implements ApplicationListener&lt;ApplicationEnvironmentPreparedEvent&gt;, Ordered &#123; public static final String BOOTSTRAP_PROPERTY_SOURCE_NAME = &quot;bootstrap&quot;; public void onApplicationEvent(ApplicationEnvironmentPreparedEvent event) &#123; ConfigurableEnvironment environment = event.getEnvironment(); if (!environment.getProperty(&quot;spring.cloud.bootstrap.enabled&quot;, Boolean.class, true)) &#123; return; &#125; if (environment.getPropertySources().contains(BOOTSTRAP_PROPERTY_SOURCE_NAME)) &#123; return; &#125; ConfigurableApplicationContext context = null; // 很明显configName默认值为bootstrap String configName = environment.resolvePlaceholders(&quot;$&#123;spring.cloud.bootstrap.name:bootstrap&#125;&quot;); for (ApplicationContextInitializer&lt;?&gt; initializer : event.getSpringApplication().getInitializers()) &#123; if (initializer instanceof ParentContextApplicationContextInitializer) &#123; context = findBootstrapContext((ParentContextApplicationContextInitializer) initializer, configName); &#125; &#125; if (context == null) &#123; context = bootstrapServiceContext(environment, event.getSpringApplication(), configName); event.getSpringApplication().addListeners(new CloseContextOnFailureApplicationListener(context)); &#125; apply(context, event.getSpringApplication(), environment); &#125;&#125;","tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://example.com/tags/SpringBoot/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"},{"name":"SpringBoot","slug":"Spring/SpringBoot","permalink":"http://example.com/categories/Spring/SpringBoot/"}]},{"title":"SpringBoot Jar包启动原理","date":"2020-10-15T03:08:20.000Z","path":"blog/Spring/SpringBoot/SpringBoot Jar包启动原理/","text":"在执行 java -jar 命令时会在Jar包中找到 META-INF/MANIFEST.MF 文件，在该文件中通过 Main-Class 指定了应用的 启动类 ，在SpringBoot的Jar包中 Main-Class 指定的是 JarLauncher 而非是正在的启动类，因为在Java中 没有 提供任何 标准方式 来 加载jar文件中的jar文件 ，故SpringBoot通过 JarLauncher 来执行启动类，同时加载jar包中依赖的jar文件。 123456789101112Manifest-Version: 1.0Spring-Boot-Classpath-Index: BOOT-INF/classpath.idxImplementation-Title: eleven-springbootImplementation-Version: 0.0.1-SNAPSHOTSpring-Boot-Layers-Index: BOOT-INF/layers.idxStart-Class: com.icode.eleven.elevenspringboot.ElevenSpringbootApplicationSpring-Boot-Classes: BOOT-INF/classes/Spring-Boot-Lib: BOOT-INF/lib/Build-Jdk-Spec: 1.8Spring-Boot-Version: 2.5.5Created-By: Maven Jar Plugin 3.2.0Main-Class: org.springframework.boot.loader.JarLauncher Spring-Boot-Classes 指定的 BOOT-INF/classes/ 中是应用程序类， Spring-Boot-Lib 指定的 BOOT-INF/lib/ 是第三方依赖jar路径。在Jar包中的 org/springframework/boot/loader 是SpringBoot的启动程序， JarLauncher 就在该目录下。JarLauncher可以加载内部 /BOOT-INF/lib 下的jar及 /BOOT-INF/classes 下的应用 class 。 1234567891011public class JarLauncher extends ExecutableArchiveLauncher &#123; static final EntryFilter NESTED_ARCHIVE_ENTRY_FILTER = (entry) -&gt; &#123; if (entry.isDirectory()) &#123; return entry.getName().equals(&quot;BOOT-INF/classes/&quot;); &#125; return entry.getName().startsWith(&quot;BOOT-INF/lib/&quot;); &#125;; public static void main(String[] args) throws Exception &#123; new JarLauncher().launch(args); &#125;&#125; 实例化 JarLauncher 时会先调用父类 ExecutableArchiveLauncher 的构造方法，最终调用超类Launcher中的 createArchive() 创建一个 归档文件Archive 。通过获取当前执行类所在的的磁盘路径，然后通过该路径打开一个文件，判断文件是否为目录来决定创建 ExplodedArchive 还是 JarFileArchive 。若是Jar文件这里的 classPathIndex 为 null 。 123456789101112131415161718192021222324252627282930public abstract class ExecutableArchiveLauncher extends Launcher &#123; private static final String START_CLASS_ATTRIBUTE = &quot;Start-Class&quot;; private final Archive archive; private final ClassPathIndexFile classPathIndex; public ExecutableArchiveLauncher() &#123; try &#123; this.archive = createArchive(); this.classPathIndex = getClassPathIndex(this.archive); &#125; catch (Exception ex) &#123; throw new IllegalStateException(ex); &#125; &#125;&#125;public abstract class Launcher &#123; protected final Archive createArchive() throws Exception &#123; ProtectionDomain protectionDomain = getClass().getProtectionDomain(); CodeSource codeSource = protectionDomain.getCodeSource(); URI location = (codeSource != null) ? codeSource.getLocation().toURI() : null; String path = (location != null) ? location.getSchemeSpecificPart() : null; if (path == null) &#123; throw new IllegalStateException(&quot;Unable to determine code source archive&quot;); &#125; File root = new File(path); if (!root.exists()) &#123; throw new IllegalStateException(&quot;Unable to determine code source archive from &quot; + root); &#125; return (root.isDirectory() ? new ExplodedArchive(root) : new JarFileArchive(root)); &#125;&#125; Archive有处理文件目录资源的 ExplodedArchive 和处理Jar包资源的 JarFileArchive 两个实现类。对Jar包的封装每个 JarFileArchive 都会对应一个 JarFile ， JarFile被构造时会解析内部结构去获取jar包里的各个文件或文件夹 ，这些文件或文件夹会被封装到Entry中，也存储在JarFileArchive中。若Entry是个jar会解析成JarFileArchive。 1234567public interface Archive extends Iterable&lt;Archive.Entry&gt;, AutoCloseable &#123; URL getUrl() throws MalformedURLException; // 获取该归档的url // 获取jar!/META-INF/MANIFEST.MF或[ArchiveDir]/META-INF/MANIFEST.MF Manifest getManifest() throws IOException; // 获取jar!/BOOT-INF/lib/*.jar或[ArchiveDir]/BOOT-INF/lib/*.jar List&lt;Archive&gt; getNestedArchives(EntryFilter filter) throws IOException;&#125; 执行launch方法最终调用超类Launcher中的launch方法。createClassLoader方法会遍历出满足条件的jar包，并通过其创建一个 LaunchedURLClassLoader 。 12345678910111213141516171819202122232425262728public abstract class Launcher &#123; protected void launch(String[] args) throws Exception &#123; if (!isExploded()) &#123; JarFile.registerUrlProtocolHandler(); &#125; ClassLoader classLoader = createClassLoader(getClassPathArchivesIterator()); String jarMode = System.getProperty(&quot;jarmode&quot;); String launchClass = (jarMode != null &amp;&amp; !jarMode.isEmpty()) ? JAR_MODE_LAUNCHER : getMainClass(); launch(args, launchClass, classLoader); &#125;&#125;public abstract class ExecutableArchiveLauncher extends Launcher &#123; protected ClassLoader createClassLoader(Iterator&lt;Archive&gt; archives) throws Exception &#123; List&lt;URL&gt; urls = new ArrayList&lt;&gt;(guessClassPathSize()); while (archives.hasNext()) &#123; urls.add(archives.next().getUrl()); &#125; if (this.classPathIndex != null) &#123; urls.addAll(this.classPathIndex.getUrls()); &#125; return createClassLoader(urls.toArray(new URL[0])); &#125;&#125;public abstract class Launcher &#123; protected ClassLoader createClassLoader(URL[] urls) throws Exception &#123; return new LaunchedURLClassLoader(isExploded(), getArchive(), urls, getClass().getClassLoader()); &#125;&#125; 会将 BOOT-INF/lib/ 目录下的所有文件过滤出来。 12345678910111213141516171819202122232425262728293031323334353637public abstract class ExecutableArchiveLauncher extends Launcher &#123; protected Iterator&lt;Archive&gt; getClassPathArchivesIterator() throws Exception &#123; Archive.EntryFilter searchFilter = this::isSearchCandidate; Iterator&lt;Archive&gt; archives = this.archive.getNestedArchives(searchFilter, (entry) -&gt; isNestedArchive(entry) &amp;&amp; !isEntryIndexed(entry)); if (isPostProcessingClassPathArchives()) &#123; archives = applyClassPathArchivePostProcessing(archives); &#125; return archives; &#125; protected ClassLoader createClassLoader(Iterator&lt;Archive&gt; archives) throws Exception &#123; List&lt;URL&gt; urls = new ArrayList&lt;&gt;(guessClassPathSize()); while (archives.hasNext()) &#123; urls.add(archives.next().getUrl()); &#125; if (this.classPathIndex != null) &#123; urls.addAll(this.classPathIndex.getUrls()); &#125; return createClassLoader(urls.toArray(new URL[0])); &#125;&#125;public class JarLauncher extends ExecutableArchiveLauncher &#123; static final EntryFilter NESTED_ARCHIVE_ENTRY_FILTER = (entry) -&gt; &#123; if (entry.isDirectory()) &#123; return entry.getName().equals(&quot;BOOT-INF/classes/&quot;); &#125; return entry.getName().startsWith(&quot;BOOT-INF/lib/&quot;); &#125;; protected boolean isSearchCandidate(Archive.Entry entry) &#123; return entry.getName().startsWith(&quot;BOOT-INF/&quot;); &#125; protected boolean isNestedArchive(Archive.Entry entry) &#123; return NESTED_ARCHIVE_ENTRY_FILTER.matches(entry); &#125; protected boolean isPostProcessingClassPathArchives() &#123; return false; &#125;&#125; 创建一个 NestedArchiveIterator 迭代器，迭代时调用超类AbstractIterator的next方法会回调 adapt 方法，最终调用 getNestedArchive 对于comment为 UNPACK: 开头的文件，会进行解压。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class JarFileArchive implements Archive &#123; private static final String UNPACK_MARKER = &quot;UNPACK:&quot;; public Iterator&lt;Archive&gt; getNestedArchives(EntryFilter searchFilter, EntryFilter includeFilter) throws IOException &#123; return new NestedArchiveIterator(this.jarFile.iterator(), searchFilter, includeFilter); &#125; protected Archive getNestedArchive(Entry entry) throws IOException &#123; JarEntry jarEntry = ((JarFileEntry) entry).getJarEntry(); if (jarEntry.getComment().startsWith(UNPACK_MARKER)) &#123; return getUnpackedNestedArchive(jarEntry); &#125; try &#123; JarFile jarFile = this.jarFile.getNestedJarFile(jarEntry); return new JarFileArchive(jarFile); &#125; catch (Exception ex) &#123; throw new IllegalStateException(&quot;Failed to get nested archive for entry &quot; + entry.getName(), ex); &#125; &#125; private Archive getUnpackedNestedArchive(JarEntry jarEntry) throws IOException &#123; String name = jarEntry.getName(); if (name.lastIndexOf(&#x27;/&#x27;) != -1) &#123; name = name.substring(name.lastIndexOf(&#x27;/&#x27;) + 1); &#125; Path path = getTempUnpackDirectory().resolve(name); if (!Files.exists(path) || Files.size(path) != jarEntry.getSize()) &#123; unpack(jarEntry, path); &#125; return new JarFileArchive(path.toFile(), path.toUri().toURL()); &#125;&#125;private class NestedArchiveIterator extends AbstractIterator&lt;Archive&gt; &#123; NestedArchiveIterator(Iterator&lt;JarEntry&gt; iterator, EntryFilter searchFilter, EntryFilter includeFilter) &#123; super(iterator, searchFilter, includeFilter); &#125; @Override protected Archive adapt(Entry entry) &#123; try &#123; return getNestedArchive(entry); &#125; catch (IOException ex) &#123; throw new IllegalStateException(ex); &#125; &#125;&#125;private abstract static class AbstractIterator&lt;T&gt; implements Iterator&lt;T&gt; &#123; public T next() &#123; T result = adapt(this.current); this.current = poll(); return result; &#125;&#125; 然后调用 ExecutableArchiveLauncher 的 getMainClass 或者正在的 启动类 ，即 META-INF/MANIFEST.MF 文件中配置的- Start-Class 。Manifest就是用来接收解析 META-INF/MANIFEST.MF 出来的数据。 1234567891011121314public abstract class ExecutableArchiveLauncher extends Launcher &#123; private static final String START_CLASS_ATTRIBUTE = &quot;Start-Class&quot;; protected String getMainClass() throws Exception &#123; Manifest manifest = this.archive.getManifest(); String mainClass = null; if (manifest != null) &#123; mainClass = manifest.getMainAttributes().getValue(START_CLASS_ATTRIBUTE); &#125; if (mainClass == null) &#123; throw new IllegalStateException(&quot;No &#x27;Start-Class&#x27; manifest entry specified in &quot; + this); &#125; return mainClass; &#125;&#125; 获取到启动类后通过反射调用启动类的main方法，即最终调用ElevenSpringbootApplication的main方法，从而去完成SpringBoot的启动。 1234567891011121314151617181920212223public abstract class Launcher &#123; protected void launch(String[] args, String launchClass, ClassLoader classLoader) throws Exception &#123; Thread.currentThread().setContextClassLoader(classLoader); createMainMethodRunner(launchClass, args, classLoader).run(); &#125; protected MainMethodRunner createMainMethodRunner(String mainClass, String[] args, ClassLoader classLoader) &#123; return new MainMethodRunner(mainClass, args); &#125;&#125;public class MainMethodRunner &#123; private final String mainClassName; private final String[] args; public MainMethodRunner(String mainClass, String[] args) &#123; this.mainClassName = mainClass; this.args = (args != null) ? args.clone() : null; &#125; public void run() throws Exception &#123; Class&lt;?&gt; mainClass = Class.forName(this.mainClassName, false, Thread.currentThread().getContextClassLoader()); Method mainMethod = mainClass.getDeclaredMethod(&quot;main&quot;, String[].class); mainMethod.setAccessible(true); mainMethod.invoke(null, new Object[] &#123; this.args &#125;); &#125;&#125;","tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://example.com/tags/SpringBoot/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"},{"name":"SpringBoot","slug":"Spring/SpringBoot","permalink":"http://example.com/categories/Spring/SpringBoot/"}]},{"title":"LoadRunner日常总结","date":"2019-10-06T03:50:20.000Z","path":"blog/Test/LoadRunner日常总结/","text":"HTTPS请求LoadRunner对HTTPS接口进行测试时，最好加上web_set_sockets_option(&quot;SSL_VERSION&quot;,&quot;TLS&quot;)。 LoadRunner在对HTTPS接口进行请求时，可能出现Error -27778: SSL protocol error when attempting to connect with host &quot;XXX&quot; [MsgId: MERR-27778]错误。 设置Vuser -&gt; Run-time Setting找到Internet Protocol -&gt; Preferences -&gt; Advanced勾选winlnet replay instead of sockets(windows only)选项。 日志中文打印通常在请求时想看到请求参数、返回结果等数据，可以在 Vuser -&gt; run-time setting -&gt; general -&gt; log 勾选 extended log 且勾选其下的三个选项。但是这种方式不能解决中文乱码问题。 可以将中文数据通过 web_reg_save_param 单独提取出来 lr_convert_string_encoding 转码后通过 lr_output_message 或 lr_log_message 打印： 1234web_reg_save_param(&quot;result&quot;, &quot;LB=message\\&quot;:\\&quot;&quot;, &quot;RB=\\&quot;&quot;, LAST);// web_custom_request请求lr_convert_string_encoding(lr_eval_string(&quot;&#123;result&#125;&quot;), &quot;utf-8&quot;, NULL, &quot;msg&quot;);lr_output_message(&quot;message--------%s&quot;,lr_eval_string(&quot;&#123;msg&#125;&quot;)); 中文参数乱码通常在通过 LoadRunner 请求接口时，若 请求参数中存在中文参数 ，虽然在 Replay Log 中打印的内容可能并没有乱码，但是请求到服务器可能就乱码了，从而导致接口请求失败。 为了解决中文参数导致的中文乱码，可以将中文参数提取出来通过 lr_convert_string_encoding 进行 转码 后使用。首先通过通过 lr_save_string 将中文参数参数化，也可以到 Parameter List 进行设置。然后将参数转成 UTF-8 ，最后将参数转成 URL编码 。 123456lr_save_string(&quot;奚姝&quot;,&quot;name&quot;);lr_convert_string_encoding(lr_eval_string(&quot;&#123;name&#125;&quot;), LR_ENC_SYSTEM_LOCALE, LR_ENC_UTF8, &quot;encode_name&quot;);lr_save_string(lr_eval_string(&quot;&#123;encode_name&#125;&quot;),&quot;name&quot;);web_convert_param(&quot;name&quot;, &quot;SourceEncoding=PLAIN&quot;, &quot;TargetEncoding=URL&quot;, LAST);lr_log_message(&quot;参数化结果name：%s&quot;, lr_eval_string(&quot;&#123;name&#125;&quot;)); Web请求LR可以通过 web_custom_request 函数发送 POST 或者 GET 请求。对于普通POST请求，未将请求参数放到 RequestBody 中的，可以将参数在 Body 中通过 &amp; 符号进行拼接。 12345web_custom_request(&quot;web_custom_request&quot;,&quot;URL=&#123;url&#125;&quot;,&quot;Method=POST&quot;, &quot;Resource=0&quot;,&quot;RecContentType=Application/json&quot;,&quot;Referer=&quot;,&quot;Mode=HTML&quot;, &quot;EncType=application/x-www-form-urlencoded;charset=UTF-8&quot;, //&quot;EncType=application/json;charset=UTF-8&quot;, &quot;Body=name=&#123;name&#125;&amp;phone=&#123;phone&#125;&quot;,LAST); 对于请求参数放到 RequestBody 中的，可以直接将请求参数转成字符串放到 Body 中。或者放到 RAW_BODY_START 和 RAW_BODY_END 之间，其中 200 指代参数长度。 123456789web_custom_request(&quot;web_custom_request&quot;,&quot;URL=&#123;url&#125;&quot;,&quot;Method=POST&quot;,&quot;Resource=0&quot;, &quot;RecContentType=application/json&quot;,&quot;Referer=&quot;,&quot;Mode=HTTP&quot;, &quot;EncType=application/json;charset=UTF-8&quot;, //RAW_BODY_START, //&quot;&#123;\\&quot;id\\&quot;:\\&quot;&#123;id&#125;\\&quot;,\\&quot;name\\&quot;:\\&quot;&#123;name&#125;\\&quot;,\\&quot;mobile\\&quot;:\\&quot;&#123;mobile&#125;\\&quot;&#125;&quot;, //200, //RAW_BODY_END, &quot;Body=&#123;\\&quot;id\\&quot;:\\&quot;&#123;id&#125;\\&quot;,\\&quot;name\\&quot;:\\&quot;&#123;name&#125;\\&quot;,\\&quot;mobile\\&quot;:\\&quot;&#123;mobile&#125;\\&quot;&#125;&quot;, LAST); 对于响应结果的提取通过 web_reg_save_param(&quot;code&quot;,&quot;LB=response_code\\&quot;:\\&quot;&quot;,&quot;RB=\\&quot;&quot;,LAST); 提取出来，用来进行事务成功与否判断。 12345678910111213lr_start_transaction (&quot;接口A&quot;);web_reg_save_param(&quot;code&quot;,&quot;LB=response_code\\&quot;:\\&quot;&quot;,&quot;RB=\\&quot;,\\&quot;&quot;,LAST);web_custom_request(&quot;web_custom_request&quot;,&quot;URL=&#123;url&#125;&quot;,&quot;Method=POST&quot;,&quot;Resource=0&quot;, &quot;RecContentType=application/json&quot;,&quot;Referer=&quot;,&quot;Mode=HTTP&quot;, &quot;EncType=application/json;charset=UTF-8&quot;, &quot;Body=&#123;\\&quot;id\\&quot;:\\&quot;&#123;id&#125;\\&quot;,\\&quot;name\\&quot;:\\&quot;&#123;name&#125;\\&quot;&#125;&quot;,LAST);if (strcmp(lr_eval_string(&quot;&#123;coke&#125;&quot;), &quot;00&quot;) == 0)&#123; lr_end_transaction(&quot;接口A&quot;, LR_PASS);&#125;else&#123; lr_end_transaction(&quot;接口A&quot;, LR_FAIL);&#125;","tags":[{"name":"Test","slug":"Test","permalink":"http://example.com/tags/Test/"}],"categories":[{"name":"Test","slug":"Test","permalink":"http://example.com/categories/Test/"}]},{"title":"JMeter日常总结","date":"2019-10-06T03:28:20.000Z","path":"blog/Test/JMeter日常总结/","text":"断言在对接口进行测试时，通常需要对接口调用结果进行断言，以确定接口调用是否达到预期，同时也可以在结果数中看到接口是否调用成功。响应断言 和 jp@gc - JSON Path Assertion 是比较简单和常用的两个断言器。 在HTTP请求下添加 断言 -&gt; 响应断言 ，可以通过不同的模式匹配规则进行匹配断言。 在HTTP请求下添加 断言 -&gt; jp@gc - JSON Path Assertion 。目前看来该断言器只能断言其中一个字段。 一般来说以上两种断言器已经基本够用了，如果遇到比较复杂的可以使用 BeanShell断言 来通过脚本进行断言。 变量提取使用通常在测试时接口需要进行鉴权，这是通过调用登录接口获取到token_id然后在调用具体接口时将token_id作为参数或者放在header中传入。这里就需要将 token_id 从鉴权接口的响应中提取出来，然后再使用时传入。 对于鉴权接口在 JMeter 中可以通过在测试计划中添加 setUp Thread Group ，并将 线程数 和 循环次数 设置成 1 ，并在该线程组中添加鉴权接口的HTTP请求。可以添加常规的 断言 和 察看结果树 。也可以在线程组中添加 逻辑控制器 -&gt; 仅一次控制器 将鉴权接口相关类容添加至该逻辑控制器下。 目前我用到的变量提取有 JSON Extractor 和 正则表达式提取器 两种。当然还有其他的提取器，目前这两种提取器基本够用了。 JSON Extractor 其实是通过 XPath 从JSON串中取出目标值。 正则表达式提取器 当然是通过正则表达式的方式从字符串中提取目标值。 虽然将变量从响应结果中提取出来了，但是并不能直接使用。可以通过 BeanShell PostProcessor 将参数设置为全局变量，也可以将其存储到本地文件中使用时通过 CSV Data Set Config 来读取并使用。 设置成全局变量 相对简单，只需要在 BeanShell PostProcessor 中配置 $&#123;__setProperty(token_id, $&#123;token_id&#125;,)&#125; 脚本即可。这里的print会将提取到的变量打印到 cmd 窗口中。在使用变量时通过 $&#123;__property(token_id)&#125; 进行获取。 将变量存储到本地文件中，也是通过 BeanShell PostProcessor 脚本实现的，只是相对于设置全局变量复杂得多。 1234567891011121314151617181920212223242526272829import java.util.regex.Matcher; import java.util.regex.Pattern; //JMeter的内置API：prev.getResponseData()获取请求的响应内容 byte[] responseData = prev.getResponseData();//定义正则表达式需要匹配的模式提取相关变量Pattern pattern = Pattern.compile(&quot;\\&quot;token_id\\&quot;:\\&quot;(.+?)\\&quot;&quot;); Matcher result = pattern.matcher(new String(responseData)); //boolean java.util.regex.Matcher.find()只要找到符合条件的就返回trueif(result.find())&#123; String tokenId += result.group(1)+&quot;\\r\\n&quot;; //导出的csv存放位置 String filePath = &quot;D:/test/token.txt&quot;; BufferedOutputStream bos = null; FileOutputStream fos = null; try &#123; File file = new File(filePath); fos = new FileOutputStream(file); bos = new BufferedOutputStream(fos); bos.write(tokenId.getBytes()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; if (bos != null) &#123; bos.close(); &#125; if (fos != null) &#123; fos.close(); &#125; &#125;&#125; 使用时通过 CSV Data Set Config 来读取到配置中。 JMeter压测的坑在JMeter中通过线程组的方式进行并发压测，但是实际测试中发现，JMeter其实实际上是一个同步的方式去发送请求的，当我们同时压测几个接口时，通过聚合报告很明显的看出JMeter会等到前一个接口结束后才会请求下一个接口。 在单个接口做并发测试时，当我们的并发设置为150时，JMeter的并发请求数确实是150，但是JMeter会等到其中某个请求结束然后再补充一个请求，通俗的将若你的接口延时1分钟，JMeter在这1分钟内只会发150个请求，当其中有请求结束再往里面补充一致维持150个请求。并不能完全模拟真实场景下的高并发。 通过MBean监控Tomcat的collectionCount参数也可以明显的看出这一点： JMeter BindExecption：Address already in use：connect在Windows10环境下，通过JMeter对接口进行压测时，在100的并发下聚合报告中会出现百分之三点几的错误率，在150的并发下出现了百分之三十几的错误率，当然在不同的环境和接口响应速率下这个错误率可能会不一样。 具体原因是由于端口被占用，Windows提供给TCP&#x2F;IP连接的端口为1024-5000，并且要四分钟来循环回收他们。就导致我们在短时间内跑大量的请求时将端口占满了。解决方案： cmd中，用regedit打开注册表 在 HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\Tcpip\\Parameters下: 右击parameters，添加一个新的DWORD，名字为MaxUserPort 然后双击MaxUserPort，输入数值数据为65534，基数选择十进制。 然后重启电脑！重启电脑！重启电脑！ Gzip压缩请求对于Gzip压缩请求，通常做法是添加JSR223 PreProcessor预处理程序，将请求内容进行压缩。 123456789101112import org.apache.commons.io.IOUtils;import java.util.zip.GZIPOutputStream;String bodyString = sampler.getArguments().getArgument(0).getValue();byte [] requestBody = bodyString.getBytes(&quot;utf-8&quot;);ByteArrayOutputStream out = new ByteArrayOutputStream(requestBody.length);GZIPOutputStream gzip = new GZIPOutputStream(out);gzip.write(requestBody);gzip.close();sampler.getArguments().getArgument(0).setValue(out.toString(0)); 在上述代码中的 getBytes(&quot;utf-8&quot;) 最好加上 utf-8 的编码格式，否则日志可能乱码。 值得注意的是，在 HTTP Request 中的 Content encoding 中的编码方式一定不要填，否则很有可能导致乱码，从而导致请求失败。","tags":[{"name":"Test","slug":"Test","permalink":"http://example.com/tags/Test/"}],"categories":[{"name":"Test","slug":"Test","permalink":"http://example.com/categories/Test/"}]},{"title":"UT测试总结","date":"2019-10-06T02:28:20.000Z","path":"blog/Test/UT测试总结/","text":"UT测试主要测试单元内部的数据结构、逻辑控制、异常处理等。单元测试实现容易、运行速度快、能完全控制被测试的单元不包含外部依赖、测试用例相互独立无依赖关系。能够帮助发现代码缺陷、修改或者重构代码时确保没有影响现有功能。 对于一些对 Bean 没有依赖的类的测试（例如一些工具类），仅使用 JUnit 即可完成单元测试。 对于一些依赖 Bean 的类进行测试，若其复杂度低，在上层一两个IT测试即可覆盖掉，可以使用IT测试；若其复杂度比较高，可以使用 JUnit 加 Mockito 来完成单元测试，通过使用 Mock 技术测试可以 无视代码依赖关系 去测试代码的有效性，mock技术的目的和作用就是 模拟一些在应用中不容易构造或者比较复杂的对象，从而把测试与测试边界以外的对象隔离开，对于依赖的Bean进行Mock处理，模拟构造各种 Bean的输出 来以及 待测试方法的输入 来覆盖当前方法的所有分支。 Mockito基础必须使用 @RunWith(MockitoJUnitRunner.class) 注解，否则Mock的依赖Bean将为空。 @Mock 将创建一个Mock， @InjectMocks 创建一个实例且自动实例化， mockito 会自动注入 mock 或 spy 成员。 UserBaseServiceImpl 中通过 @Autowired 注解或者构造方法等方式注入了 IUserBaseDao ，就可以通过如下方式使用。 12345678@RunWith(MockitoJUnitRunner.class)public class UserBaseServiceTest &#123; @Mock private IUserBaseDao userBaseDao; @InjectMocks private UserBaseServiceImpl userBaseService;&#125; @Mock与@Spy的区别使用 @Mock 生成的类，所有方法都不是真实的方法，而且返回值都是NULL。通常在设置测试桩时通过如下方式设置，对于多次调用返回不同值，可以通过多次设置 thenReturn ： 123456LinkedList mockedList = mock(LinkedList.class);mockedList.add(11);assertEquals(null, mockedList.get(0));when(mockedList.get(0)).thenReturn(&quot;first&quot;).thenReturn(&quot;second&quot;);assertEquals(&quot;first&quot;, mockedList.get(0)); 使用 @Spy 生成的类，所有方法都是真实方法，返回值都是和真实方法一样的。测试桩设置与 @Mock 方式有所区别： 123456LinkedList mockedList = spy(LinkedList.class);mockedList.add(11);assertEquals(11, mockedList.get(0));doReturn(&quot;foo&quot;).when(spy).get(0);assertEquals(&quot;foo&quot;, mockedList.get(0)); Redis测试有时在进行Mock测试时会遇到 redisTemplate ，通常在应用中会使用 redisTemplate.boundValueOps 或者 redisTemplate.boundHashOps 生成一个 BoundValueOperations 或者 BoundHashOperations 对象，再来继续调用具体的处理方法。在设置测试桩时，需要进行两次设置。 12when(redisTemplate.boundValueOps(redisKey)).thenReturn(mock(BoundValueOperations.class));when(redisTemplate.boundValueOps(redisKey).increment(anyLong())).thenReturn(10L); 参数捕捉有时会出现一大串复杂的逻辑处理后生成一个或几个参数，用于调用其他的依赖Bean，这时可以通过参数捕捉来验证逻辑中各种情况下生产的参数是否满足预期。若简单参数也可以通过 verify 直接验证。 123456789BoundHashOperations boundHashOperations = mock(BoundHashOperations.class);when(redisTemplate.boundHashOps(anyString())).thenReturn(boundHashOperations);ArgumentCaptor&lt;Map&gt; argument = ArgumentCaptor.forClass(Map.class); verify(boundHashOperations, times(2)).putAll(argument.capture());Map&lt;String, CaseFlow&gt; map = new HashMap&lt;&gt;();assertEquals(map, argument.getValue()); 方法调用次数验证当验证的方法中存在循环、或者复杂度比较高等，导致方法在不同条件下可能存在多次调用的情况，最好验证一下方法的调用次数。或者是用于验证某个逻辑没有被执行或方法没有别调用。 12345verify(mock, times(1)).someMethod();// 至少调用2次verify(mock, atLeast(2)).someMethod();// 至多调用5次verify(mock, atMost(5)).someMethod(); 异常处理在进行一些会抛出异常的测试时，可以通过捕获异常在进行后续校验，可以使用 @Test(expected = Exception.class) ，若有多个地方抛出相同异常但异常信息不同时，该测试方法就不适用了，可以通过如下方式进行异常捕获后进行相关的验证。 1234567891011doThrow(new RuntimeException()).when(mockedList).clear();when(redisTemplate.boundValueOps(any())).thenThrow(new RuntimeException());Exception error = null;try &#123; baselineModelHandler.output(segment, modelData);&#125; catch (Exception e) &#123; error = e;&#125;assertNotNull(error);assertEquals(&quot;&quot;, error.getMessage()); 验证调用顺序12345678910111213List firstMock = mock(List.class);List secondMock = mock(List.class);firstMock.add(&quot;was called first&quot;);secondMock.add(&quot;was called second&quot;);//创建多个mock对象的inOrderInOrder inOrder = inOrder(firstMock, secondMock);//验证firstMock先于secondMock调用inOrder.verify(firstMock).add(&quot;was called first&quot;);inOrder.verify(secondMock).add(&quot;was called second&quot;); 实现ApplicationContextAware接口的类测试1234Map&lt;String, Object&gt; map = new HashMap&lt;&gt;();map.put(&quot;outputServiceImpl&quot;, new OutputServiceImpl(requestService, updateCache, mock(ICache.class)));when(applicationContext.getBeansWithAnnotation(InvokeListener.class)).thenReturn(map);dataInvokeService.setApplicationContext(applicationContext);","tags":[{"name":"Test","slug":"Test","permalink":"http://example.com/tags/Test/"}],"categories":[{"name":"Test","slug":"Test","permalink":"http://example.com/categories/Test/"}]},{"title":"IT测试总结","date":"2019-10-06T02:08:20.000Z","path":"blog/Test/IT测试总结/","text":"IT测试主要测试模块之间的接口和接口数据传递关系，以及模块组合后的整体功能。 在做集成测试时，若涉及到数据库的数据变更的，最好在测试过后将数据还原，可以先构建一条新的数据测试完成后删除，防止印象到数据库中原有的数据。 Controller层测试对于 SpringBoot 项目，Controller层的IT测试可以通过在类上加 @AutoConfigureMockMvc 注解并直接注入 MockMvc 的方式进行测试。 若对于一些特殊的测试，需要使用不同的配置的, 可使用 @TestPropertySource(locations=&quot;classpath:test.application.properties&quot;) 注解指定特定的配置文件。 123456789101112131415161718@RunWith(SpringRunner.class)@SpringBootTest@AutoConfigureMockMvcpublic class DashboardControllerTest &#123; @Autowired private MockMvc mockMvc; @Test public void get_method_test() throws Exception &#123; this.mockMvc.perform(get(&quot;/test//v1&quot;) .param(&quot;param1&quot;, &quot;value1&quot;) .param(&quot;param2&quot;, &quot;value2&quot;) .header(&quot;uid&quot;, &quot;123456&quot;)) .andExpect(status().isOk()) .andExpect(content().string(containsString(&quot;&#123;\\&quot;response_code\\&quot;:\\&quot;00\\&quot;&quot;))); &#125;&#125; 对于 MockMvc 的使用还可以通过如下方式，这样可以不用在类上添加 @AutoConfigureMockMvc 注解： 12345678910@Autowiredprivate WebApplicationContext context;private MockMvc mvc;@Beforepublic void setUp() throws Exception &#123; mvc = MockMvcBuilders.webAppContextSetup(context) .addFilter(new BaseParamCheckFilter()).build();&#125; mockMvc.perform 需要传入的是一个 RequestBuilder ，可以将其封装好了再传入，需要放入 RequestBody 中的参数可以通过 content 进行参数构造： 12345678910HttpHeaders httpHeaders = new HttpHeaders();httpHeaders.add(&quot;uuid&quot;, &quot;68A&quot;);httpHeaders.add(&quot;Content-Type&quot;, &quot;application/json&quot;);RequestBuilder request = post(&quot;/test/v1&quot;) .headers(httpHeaders) .content(&quot;&#123;\\&quot;uuid\\&quot;: \\&quot;68A\\&quot;,\\&quot;param1\\&quot;:\\&quot;aa\\&quot;&#125;&quot;) .accept(MediaType.APPLICATION_JSON);mockMvc.perform(request).andExpect(status().isOk()).andDo(print()).andExpect( content().string(containsString(&quot;&#123;\\&quot;response_code\\&quot;:\\&quot;02\\&quot;,\\&quot;message\\&quot;:\\&quot;请求参数缺失\\&quot;&quot;))); 对于返回结果的严重可以使用上面的示例通过 MockMvcResultMatchers 结合 Matchers 中的方法进行验证，也可以通过以下方式获取到具体结果后进行验证。 123String responseString = mvc.perform(request) .andExpect(status().isOk()) .andReturn().getResponse().getContentAsString(); perform ：执行一个 RequestBuilder 请求，会自动执行 SpringMVC 的流程并映射到相应的控制器执行处理； andExpect ：添加 ResultMatcher 验证规则，验证控制器执行完成后结果是否正确； andDo ：添加 ResultHandler 结果处理器，比如调试时打印结果到控制台； andReturn ：最后返回相应的 MvcResult ；然后进行自定义验证&#x2F;进行下一步的异步处理； 测试文件上传对于文件大小限制的测试可以直接构建一个指定大小的byte数组。 1234567MockMultipartFile xmlFile = new MockMultipartFile(&quot;xmlFile&quot;, &quot;emptyModel.xml&quot;, &quot;text/plain&quot;, new byte[1024 * 1024 * 200 + 1]);this.mockMvc.perform(MockMvcRequestBuilders.fileUpload(&quot;/test/config/add&quot;) .file(xmlFile).param(&quot;mid&quot;, mid).param(&quot;status&quot;, &quot;1&quot;)) .andExpect(status().isOk()) .andExpect(content().string(containsString(&quot;&#123;\\&quot;message\\&quot;:\\&quot;上传文件异常\\&quot;&quot;))); 如果对于真实的文件上传测试可以读取真实的文件传输： 12345678910111213141516171819URL url = this.getClass().getClassLoader().getResource(&quot;test/errorFileType.txt&quot;);File file = new File(url.getPath());MockMultipartFile xmlFile = new MockMultipartFile(&quot;xmlFile&quot;, &quot;errorFileType.txt&quot;, &quot;text/plain&quot;, getByte(file));private byte[] getByte(File file) throws IOException &#123; FileInputStream fis = new FileInputStream(file); ByteArrayOutputStream bos = new ByteArrayOutputStream(); byte[] b = new byte[1000]; int n; while ((n = fis.read(b)) != -1) &#123; bos.write(b, 0, n); &#125; fis.close(); bos.close(); return bos.toByteArray(); &#125;&#125; 使用TestRestTemplate 对象测试12345678910@Autowiredprivate TestRestTemplate template;@Testpublic void testController()&#123; // template.getForObject() 会得到 controller 返回的 json 值 String content = template.getForObject(&quot;/show/100&quot;, String.class); // 使用断言测试，使用正确的断言 Assert.assertEquals(&quot;show100&quot;, content);&#125; 非Controller层测试对于非Controller测试一般更简单一些，只需要注入相关的类构造入参进行具体的方法调用测试，输出结果进行验证即可。 123456789101112131415161718192021@RunWith(SpringRunner.class)@SpringBootTest(webEnvironment = NONE)public class ITConfigServiceTest &#123; @Autowired private TestBusiConfigMapper testBuisConfigMapper; @Autowired private otherConfigService otherConfigService; @Test public void getConfigTest() &#123; List&lt;Config&gt; configList = testBuisConfigMapper.getAllConfigs(); assertNotNull(configList); assertEquals(true, configList.size() &gt; 0); for (Config config : configList) &#123; Config config = otherConfigService.getConfig(config.getId()); assertNotNull(config); &#125; &#125;&#125;","tags":[{"name":"Test","slug":"Test","permalink":"http://example.com/tags/Test/"}],"categories":[{"name":"Test","slug":"Test","permalink":"http://example.com/categories/Test/"}]},{"title":"RocketMQ-Spring集成","date":"2019-05-01T02:08:20.000Z","path":"blog/工具和中间件/消息队列/RocketMQ/RocketMQ-Spring集成/","text":"SpringBoot集成SpringBoot集成RocketMQ的starter依赖是由Spring社区提供的,目前正在快速迭代的过程当中,不同版本之间的差距非常大,故需特别注意版本.通过内置的 RocketMQTemplate 来与RocketMQ交互. 123456789101112131415161718192021222324&lt;dependency&gt; &lt;groupId&gt;org.apache.rocketmq&lt;/groupId&gt; &lt;artifactId&gt;rocketmq-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.1.1&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;version&gt;2.1.6.RELEASE&lt;/version&gt;&lt;/dependency&gt; 1234# NameServer地址rocketmq.name-server=localhost:9876# 默认的消息生产者组rocketmq.producer.group=springBootGroup SpringBoot集成RocketMQ,消费者部分核心功能都集成到 @RocketMQMessageListener 注解.消息过滤可以由里面的 selectorType 属性和 selectorExpression 来定制,由 consumeMode 来有序消费还是并发消费等； 1234567891011121314151617181920@Componentpublic class SpringProducer &#123; @Resource private RocketMQTemplate rocketMQTemplate; public void sendMessage(String topic, String msg) &#123; String[] tags = new String[]&#123;&quot;TagA&quot;, &quot;TagB&quot;, &quot;TagC&quot;, &quot;TagD&quot;, &quot;TagE&quot;&#125;; for (String tag : tags) &#123; String destination = topic + &quot;:&quot; + tag; this.rocketMQTemplate.convertAndSend(destination, msg); &#125; &#125;&#125;@Component@RocketMQMessageListener(consumerGroup = &quot;MyConsumerGroup&quot;, messageModel = MessageModel.CLUSTERING, topic = &quot;TestTopic&quot;, consumeMode = ConsumeMode.CONCURRENTLY, selectorExpression = &quot;TagA&quot;)public class SpringConsumer implements RocketMQListener&lt;String&gt; &#123; @Override public void onMessage(String message) &#123; System.out.println(&quot;Received message1 : &quot; + message); &#125;&#125; 对于事务消息需要添加一个 事务消息监听器 ,对于消息TAG的使用,需要通过将TAG拼接到Topic后面.SpringBoot依赖中的 Message 对象和RocketMQ中的 Message 对象是两个不同的对象,SpringBoot中的Message中就没有TAG属性,Tag属性被移到了发送目标中,以 Topic:Tag 的方式指定. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465@ExtRocketMQTemplateConfigurationpublic class ExtRocketMQTemplate extends RocketMQTemplate &#123;&#125;@RocketMQTransactionListener(rocketMQTemplateBeanName = &quot;extRocketMQTemplate&quot;)public class MyTransactionImpl implements RocketMQLocalTransactionListener &#123; private ConcurrentHashMap&lt;Object, Message&gt; localTrans = new ConcurrentHashMap&lt;&gt;(); @Override public RocketMQLocalTransactionState executeLocalTransaction(Message msg, Object arg) &#123; Object transId = msg.getHeaders().get(RocketMQHeaders.PREFIX + RocketMQHeaders.TRANSACTION_ID); String destination = arg.toString(); localTrans.put(transId, msg); //这个msg的实现类是GenericMessage,里面实现了toString方法 //在Header中自定义的RocketMQHeaders.TAGS属性,到这里就没了.但是RocketMQHeaders.TRANSACTION_ID这个属性就还在. //而message的Header里面会默认保存RocketMQHeaders里的属性,但是都会加上一个RocketMQHeaders.PREFIX前缀 System.out.println(&quot;executeLocalTransaction msg = &quot; + msg); //转成RocketMQ的Message对象 org.apache.rocketmq.common.message.Message message = RocketMQUtil.convertToRocketMessage(new StringMessageConverter(), &quot;UTF-8&quot;, destination, msg); String tags = message.getTags(); if (StringUtils.contains(tags, &quot;TagA&quot;)) &#123; return RocketMQLocalTransactionState.COMMIT; &#125; else if (StringUtils.contains(tags, &quot;TagB&quot;)) &#123; return RocketMQLocalTransactionState.ROLLBACK; &#125; else &#123; return RocketMQLocalTransactionState.UNKNOWN; &#125; &#125; @Override public RocketMQLocalTransactionState checkLocalTransaction(Message msg) &#123; String transId = msg.getHeaders().get(RocketMQHeaders.PREFIX + RocketMQHeaders.TRANSACTION_ID).toString(); Message originalMessage = localTrans.get(transId); // 这里能够获取到自定义的transaction_id属性 System.out.println(&quot;checkLocalTransaction msg = &quot; + originalMessage); // 获取标签时,自定义的RocketMQHeaders.TAGS拿不到,但是框架会封装成一个带RocketMQHeaders.PREFIX的属性 String tags = msg.getHeaders().get(RocketMQHeaders.PREFIX + RocketMQHeaders.TAGS).toString(); if (StringUtils.contains(tags, &quot;TagC&quot;)) &#123; return RocketMQLocalTransactionState.COMMIT; &#125; else if (StringUtils.contains(tags, &quot;TagD&quot;)) &#123; return RocketMQLocalTransactionState.ROLLBACK; &#125; else &#123; return RocketMQLocalTransactionState.UNKNOWN; &#125; &#125;&#125;@Componentpublic class SpringProducer &#123; @Resource private RocketMQTemplate extRocketMQTemplate; public void sendMessageInTransaction(String topic, String msg) throws InterruptedException &#123; String[] tags = new String[]&#123;&quot;TagA&quot;, &quot;TagB&quot;, &quot;TagC&quot;, &quot;TagD&quot;, &quot;TagE&quot;&#125;; for (int i = 0; i &lt; 10; i++) &#123; //尝试在Header中加入一些自定义的属性. Message&lt;String&gt; message = MessageBuilder.withPayload(msg) .setHeader(RocketMQHeaders.TRANSACTION_ID, &quot;TransID_&quot; + i) //发到事务监听器里后,这个自己设定的TAGS属性会丢失.但是上面那个属性不会丢失. .setHeader(RocketMQHeaders.TAGS, tags[i % tags.length]) //MyProp在事务监听器里也能拿到,为什么就单单这个RocketMQHeaders.TAGS拿不到？这只能去调源码了. .setHeader(&quot;MyProp&quot;, &quot;MyProp_&quot; + i) .build(); String destination = topic + &quot;:&quot; + tags[i % tags.length]; //这里发送事务消息时,还是会转换成RocketMQ的Message对象,再调用RocketMQ的API完成事务消息机制. SendResult sendResult = extRocketMQTemplate.sendMessageInTransaction(destination, message, destination); System.out.printf(&quot;%s%n&quot;, sendResult); Thread.sleep(10); &#125; &#125;&#125;","tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"http://example.com/tags/RocketMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RocketMQ","slug":"工具和中间件/消息队列/RocketMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RocketMQ/"}]},{"title":"RocketMQ-高级特性","date":"2019-04-24T02:08:20.000Z","path":"blog/工具和中间件/消息队列/RocketMQ/RocketMQ-高级特性/","text":"消息模型RocketMQ主要由 Producer 、 Broker 、 Consumer 三部分组成, Producer负责生产消息, Consumer负责消费消息, Broker负责存储消息. Broker在实际部署过程中对应一台服务器, 每个Broker可存储多个Topic消息, 每个Topic消息也可分片存储于不同的Broker. MessageQueue用于存储消息的物理地址, 每个Topic中的消息地址存储于多个MessageQueue中. ConsumerGroup由多个Consumer 实例构成. 每个Broker下都会生成对应的Topic的文件夹, 每个Topic文件夹下会为每个队列生成一个以队列id作为文件名的文件夹, 在文件夹内才是对应的MessageQueue文件. 消息生产者RocketMQ提供多种发送方式, 同步发送、异步发送、顺序发送、单向发送. 同步和异步方式均需要Broker返回确认信息, 单向发送不需要； 生产者中会把同一类Producer组成一个集合, 叫做生产者组, 这类Producer发送同一类消息且发送逻辑一致. 若发送的是事务消息且原始生产者在发送之后崩溃, 则Broker服务器会联系同一生产者组的其他生产者实例以提交或回溯消费. 消息消费者一个消息消费者会从 Broker 服务器拉取消息, 从用户应用的角度而言提供了两种消费形式：拉取式消费、推动式消费. 拉取式消费的应用通常主动调用Consumer的拉消息方法从Broker服务器拉消息、主动权由应用控制. 一旦获取了批量消息, 应用就会启动消费过程. 推动式消费模式下Broker收到数据后会主动推送给消费端, 该消费模式一般实时性较高, 底层也是通过拉取模式来实现的, 与Broker建立长连接达到消息实时接收的效果. 消费者同样会把同一类Consumer组成一个集合, 叫做消费者组, 这类Consumer通常消费同一类消息且消费逻辑一致. 消费者组使得在消息消费方面, 实现负载均衡和容错的目标变得非常容易. 消费者组的消费者实例必须订阅完全相同的Topic . RocketMQ支持两种消息模式：集群消费Clustering 和广播消费Broadcasting . 集群消费模式：相同Consumer Group的每个Consumer实例平均分摊消息. 不同的Consumer Group全量接收消息. 广播消费模式：相同Consumer Group的每个Consumer实例都接收全量的消息. Topic Topic 表示一类消息的集合, 每个Topic包含若干条消息, 每条消息只能属于一个主题, 是RocketMQ进行消息订阅的基本单位. 同一个Topic下的数据, 会分片保存到不同的Broker上, 而每一个分片单位为 MessageQueue . MessageQueue 是生产者发送消息与消费者消费消息的最小单位. Broker Server消息中转角色, 负责存储消息、转发消息. 代理服务器在RocketMQ系统中负责接收从生产者发送来的消息并存储、同时为消费者的拉取请求作准备. 代理服务器也存储消息相关元数据, 包括消费者组、消费进度偏移和主题和队列消息等. Broker Server要保证高可用需要搭建主从集群架构. RocketMQ中有普通集群和Dledger高可用集群两种Broker架构模式. 普通集群该集群模式下会给每个节点分配一个固定角色, Master 负责响应客户端的请求并存储消息. Slave 则只负责对 Master 的消息进行同步保存, 并响应部分客户端的读请求, 消息同步方式分为同步同步和异步同步. 该集群模式下各节点角色无法进行切换, 即Master节点挂了, 则这一组Broker就不可用了, Slave 不会顶上去成为Master. Dledger高可用集群Dledger是 RocketMQ 4.5 引入的实现高可用集群的一项技术. 该模式下集群会随机选出一个节点作为Master, 当Master节点挂了后, 会从Slave中自动选出一个节点升级成为Master. Dledger会从集群中选举出Master节点, 完成Master节点往Slave节点的消息同步, 且接管Broker的 CommitLog消息存储. Dledger是使用 Raft算法来进行节点选举的. 每个节点有 Leader 、 Follower 、 Candidate 三个状态, 正常运行情况下, 集群中会有一个leader, 其他都是Follower且只响应Leader和Candidate的请求, 而客户端的请求全部由Leader处理, 即使有客户端请求到了一个Follower也会将请求转发到Leader . 集群刚启动时每个节点都是Follower状态, 之后集群内部会发送一个timeout信号, 所有Follower转成Candidate去拉取选票, 获得大多数选票的节点选为Leader, 其他候选人转为Follower. 若一个timeout信号发出时, 没有选出Leader, 将会重新开始一次新的选举. Leader节点会往其他节点发送心跳信号, 确认其Leader状态. 然后启动定时器, 若指定时间内未收到Leader心跳, 则转为Candidate状态, 然后向其他成员发起投票请求, 若收到半数以上成员的投票, 则Candidate会晋升为Leader, 然后Leader也有可能会退化成Follower. 在Raft协议中会将时间分为一些任意时间长度的时间片段叫做 term . term会使用一个全局唯一, 连续递增的编号作为标识, 起到一个逻辑时钟的作用. 在每个term时间片里都会进行新的选举, 每个 Candidate 都会努力争取成为Leader. Leader节点在一个term时间片里会保持Leader状态, 同一时间段内, 集群中只会有一个Leader. 某些情况下形成不了多数派, 那该term可能直到结束都没有leader, 直到下一个term再重新发起选举, 也就没有了Zookeeper中的脑裂问题. 而在每次重新选举的过程中, Leader也有可能会退化成为Follower. 在该集群中Leader节点会不断变化. 每次选举的过程中, 每个节点都会存储当前term编号, 并在节点之间进行交流时带上自己的term编号. 若一个节点发现他的编号比另外一个小, 则会将自己的编号更新为较大的那一个. 若Leader或Candidate发现自己的编号不是最新的, 则会自动转成Follower . 若接收到的请求term编号小于自己的编号term将会拒绝执行. 在选举过程中, Raft协议会通过心跳机制发起Leader选举. 节点都是从Follower状态开始, 若收到了来自Leader或Candidate的心跳RPC请求, 则会保持Follower状态, 避免争抢成为Candidate. 而Leader会往其他节点发送心跳信号, 来确认自己的地位. 若 Follower两个timeout信号内没有收到Leader的心跳信号, 则会认为Leader挂了, 发起新一轮选举. 选举开始后, 每个Follower会增加自己当前的term, 并将自己转为Candidate. 然后向其他节点发起投票请求, 请求时默认投自己一票. 之后Candidate状态可能会发生以下三种变化： 赢得选举成为Leader ：若在一个term内收到了大多数的选票, 将会在接下的剩余term时间内称为Leader, 然后就可通过发送心跳确立自己的地位. 每一个Server在一个term内只能投一张选票, 并且按先到先得的原则投出 其他节点成为Leader：在等待投票时, 可能会收到其他Server发出心跳信号, 说明Leader已产生. 这时通过比较自己的term编号和RPC过来的term编号, 若比对方大说明Leader的term过期, 则拒绝该RPC并继续保持候选人身份, 若对方编号不比自己小则承认对方的地位,转为follower. 选票被瓜分选举失败：若无Candidate获取大多数选票, 则无Leader产生, Candidate们等待超时后发起另一轮选举, 为防止下一次选票还被瓜分, Raft采用随机Election Timeout即随机休眠时间机制防止选票被持续瓜分. 通过将timeout随机设为一段区间上的某个值, 因此很大概率会有某个Candidate率先超时然后赢得大部分选票. 以三个节点的集群为例, 集群启动时三个节点都是Follower, 发起投票后三个节点都会给自己投票, 一轮投票下来三个节点的term都是1, 选举不出Leader；三个节点会进入随机休眠, 然后开始新一轮投票； Dledger还会采用Raft协议进行多副本消息同步, 数据同步会通过 uncommitted阶段和 commited阶段两个阶段来完成. Leader Broker上的Dledger收到一条数据后, 会标记为 uncommitted状态, 然后他通过自己的DledgerServer组件把该uncommitted数据发给Follower Broker的 DledgerServer 组件. Follower Broker的 DledgerServer 收到uncommitted消息后, 必须返回一个Ack 给Leader Broker的Dledger. 若Leader Broker收到超过半数的Follower Broker返回的 Ack 之后, 就会把消息标记为committed状态. Leader Broker上的 DledgerServer 就会发送committed消息给Follower Broker上的DledgerServer, 让他们把消息也标记为committed状态. 消息存储分布式队列因为有高可靠性的要求, 所以数据要进行持久化存储. RocketMQ采用的是类似于Kafka的文件存储机制, 即直接用磁盘文件来保存消息, 而不需要借助MySQL这一类索引工具. MQ收到一条消息后, 需要向生产者返回一个ACK响应, 并将消息存储起来. MQ Push一条消息给消费者后, 等待消费者的ACK响应, 需要将消息标记为已消费. 若没有标记为消费, MQ会不断尝试往消费者推送这条消息. MQ需要定期删除一些过期的消息, 这样才能保证服务一直可用. 目前的高性能磁盘, 顺序写速度可以达到 600MB/s , 超过一般网卡传输速度. 但是磁盘随机写速度只有大概 100KB/s , RocketMQ的消息用顺序写保证了消息存储的速度. Linux操作系统分为用户态和内核态, 文件操作、网络操作需要涉及这两种形态的切换, 免不了进行数据复制. 一台服务器把本机磁盘文件的内容发送到客户端, 一般分为读取本地文件内容、将读取的内容通过网络发送出去两个步骤. 看似简单的操作, 实际进行了 4 次数据复制： 从磁盘复制数据到内核态内存 从内核态内存复制到用户态内存 然后从用户态内存复制到网络驱动的内核态内存 最后从网络驱动的内核态内存复制到网卡中进行传输 通过使用 mmap 方式, 可省去向用户态内存复制, 提高速度. 这种机制在Java中是通过 NIO 包中的 MappedByteBuffer 实现的. RocketMQ充分利用该特性, 也就是所谓的零拷贝技术, 提高消息存盘和网络发送速度. 采用 MappedByteBuffer 这种内存映射的方式有几个限制：一次只能映射1.5~2G的文件至用户态的虚拟内存, 这也是为何RocketMQ默认设置单个CommitLog日志数据文件为1G的原因. 零拷贝在Java NIO中提供了 mmap 和 sendfile 两种实现方式, mmap适合比较小的文件, sendfile适合传递比较大的文件. RocketMQ消息的存储分为三个部分： CommitLog ：存储消息的元数据, 所有消息都会顺序存入到 CommitLog 文件当中. CommitLog 由多个文件组成, 每个文件固定大小1G , 以第一条消息的偏移量为文件名. ConsumerQueue ：存储消息在CommitLog的索引, 一个 MessageQueue 一个文件, 记录当前 MessageQueue 被哪些消费者组消费到了哪一条 CommitLog . 每个Broker下都会生成对应的Topic的文件夹, 每个Topic文件夹下会为每个队列生成一个以队列id作为文件名的文件夹, 在文件夹内才是对应的MessageQueue文件. IndexFile ：为了消息查询提供了一种通过key或时间区间来查询消息的方法, 这种通过 IndexFile 来查找消息的方法不影响发送与消费消息的主流程 abort ：该文件是RocketMQ用来判断程序是否正常关闭的一个标识文件. 正常情况下在启动时创建关闭服务时删除. 若遇到服务器宕机或 kill -9 等一些非正常关闭服务的情况, 该abort文件不会删除, RocketMQ就可判断上一次服务是非正常关闭, 做一些数据恢复的操作. checkpoint ：数据存盘检查点. config/*.json ：将 Topic配置、消费者组配置、消费者组消息偏移量Offset等关键配置信息进行存盘保存. 刷盘机制RocketMQ需要将消息存储到磁盘上才能保证断电后消息不丢失, 才可以让存储的消息量超出内存的限制. 为了提高性能, 会尽量保证磁盘的顺序写. 消息在写入磁盘时有 SYNC_FLUSH同步刷盘和 ASYNC_FLUSH异步刷盘两种写磁盘的方式. 通过Broker配置文件中 flushDiskType 参数设置. 同步刷盘：返回写成功状态时, 消息已经被写入磁盘. 消息写入内存的 PAGECACHE 后, 立刻通知刷盘线程刷盘, 等待刷盘完成, 刷盘线程执行完成后唤醒等待的线程, 返回消息写成功的状态. 异步刷盘：返回写成功状态时, 消息可能只是被写入了内存的PAGECACHE , 写操作的返回快吞吐量大；当内存里的消息量积累到一定程度时, 统一触发写磁盘动作快速写入. 主从复制若Broker以集群方式部署, 会有一个Master节点和多个Slave节点, 消息需要从Master复制到Slave上. 而消息复制的方式分为同步复制和异步复制. 通过Broker配置文件里的 brokerRole 参数进行设置, 该参数可以被设置成 ASYNC_MASTER 、 SYNC_MASTER 、 SLAVE 三个值中的一个. 同步复制：等Master和Slave都写入消息成功后才反馈给客户端写入成功的状态. 若Master故障Slave上有全部数据备份, 很容易恢复数据. 同步复制会增大数据写入延迟降低系统的吞吐量. 异步复制：Master写入消息成功就反馈给客户端写入成功的状态, 再异步将消息复制给Slave节点. 系统拥有较低延迟和较高吞吐量. 但若Master故障而有些数据没有完成复制就会造成数据丢失 负载均衡Producer负载均衡Producer发送消息时, 默认会轮询目标Topic下的所有MessageQueue , 并采用递增取模方式往不同的 MessageQueue 上发送消息, 让消息平均落在不同的Queue上. 由于 MessageQueue 是分布在不同的Broker上, 故消息也会发送到不同的Broker上. 生产者在发送消息时, 可指定一个 MessageQueueSelector , 通过该对象来将消息发送到指定的MessageQueue上, 可通过该方式保证消息局部有序. Consumer负载均衡Consumer也是以 MessageQueue 为单位来进行负载均衡, 分为集群模式和广播模式.广播模式下每条消息都会投递给订阅了Topic的所有消费者实例, 在Consumer分配Queue时, 所有Consumer都分到所有的Queue. 集群消费模式每条消息只需要投递到订阅该Topic的Consumer Group下的一个实例, RocketMQ采用主动拉取方式拉取并消费消息, 在拉取时需明确指定拉取哪一条MessageQueue . 每当实例的数量有变更, 都会触发一次所有实例的负载均衡, 这时会按照 Queue的数量和实例的数量平均分配Queue给每个实例. 每次分配时都会将 MessageQueue 和消费者ID进行排序, 再用不同的分配算法进行分配. 内置的分配的算法共有六种, 分别对应 AllocateMessageQueueStrategy下的六种实现类, 可在Consumer中直接指定. 默认情况下使用的是最简单的平均分配策略. AllocateMachineRoomNearby ：将同机房的Consumer和Broker优先分配在一起. 该策略可通过一个 machineRoomResolver 对象来定制Consumer和Broker的机房解析规则. 还需要引入另外一个分配策略来对同机房的Broker和Consumer进行分配. 一般用平均分配策略或轮询分配策略. AllocateMessageQueueAveragely ：平均分配, 将所有MessageQueue平均分给每一个消费者 AllocateMessageQueueAveragelyByCircle ： 轮询分配, 轮流的给一个消费者分配一个MessageQueue. AllocateMessageQueueByConfig ： 直接指定一个messageQueue列表, 类似于广播模式, 直接指定所有队列. AllocateMessageQueueByMachineRoom ：按逻辑机房的概念进行分配. 对BrokerName和ConsumerIdc有定制化的配置. AllocateMessageQueueConsistentHash ：一致性哈希策略只需要指定一个虚拟节点数, 用一个哈希环算法, 虚拟节点是为了让Hash数据在环上分布更为均匀. 消息重试广播模式的消息是不存在消息重试机制, 消息消费失败后不会再重新进行发送, 继续消费新的消息. 对于普通消息, 当消费者消费消息失败后, 可通过设置返回状态达到消息重试的结果. 集群消费方式下, 消息消费失败后期望消息重试, 需要在消息监听器接口的实现中明确进行配置, 有返回Action.ReconsumeLater 、返回NULL 、抛出异常三种配置方式. 重试消息会进入一个 %RETRY%+ConsumeGroup 队列中, 默认允许每条消息最多重试16次, 重试时间跟延迟消息的延迟级别是对应的, 不过取的是延迟级别的后16级别. 若消息重试16次后仍然失败, 消息将不再投递转为进入死信队列, 可通过 consumer.setMaxReconsumeTimes(20) 自定义重试次数, 当定制的重试次数超过16次后, 消息重试时间间隔均为2小时. 消息最大重试次数的设置对相同GroupID下的所有Consumer实例有效. 且最后启动的Consumer会覆盖之前启动的Consumer的配置. 死信队列当一条消息消费失败会自动进行消息重试, 若消息超过最大重试次数, RocketMQ认为该消息有问题, 但不会立刻将该消息丢弃, 而是将其发送到这个消费者组对应的一种特殊队列死信队列. 死信队列名称 %DLQ%+ConsumGroup . 一个死信队列对应一个ConsumGroup , 而不是对应某个消费者实例. 若一个 ConsumeGroup没有产生死信队列, RocketMQ就不会为其创建相应的死信队列. 一个死信队列包含了该ConsumeGroup里的所有死信消息, 而不区分该消息Topic . 死信队列中的消息不会再被消费者正常消费. 死信队列的有效期跟正常消息相同, 默认3天, 对应broker.conf中的 fileReservedTime 属性. 超过该最长时间的消息都会被删除, 而不管消息是否消费过. 通常一条消息进入了死信队列, 意味着消息在消费处理的过程中出现了比较严重的错误, 且无法自行恢复. 此时, 一般需要人工去查看死信队列中的消息, 对错误原因进行排查. 然后对死信消息进行处理, 比如转发到正常的Topic重新进行消费或者丢弃. 消息幂等 发送时消息重复：当一条消息已被成功发送到服务端并完成持久化, 此时出现了网络闪断或者客户端宕机, 导致服务端对客户端应答失败. 若此时生产者意识到消息发送失败并尝试再次发送消息, 消费者后续会收到两条内容相同且 MessageID也相同的消息. 投递时消息重复：消息已投递到消费者并完成业务处理, 当客户端给服务端反馈应答的时候网络闪断. 为了保证消息至少被消费一次, RocketMQ服务端将在网络恢复后再次尝试投递之前已被处理过的消息, 消费者后续会收到两条内容相同并且 MessageID也相同的消息. 负载均衡时消息重复：包括但不限于网络抖动、Broker重启以及订阅方应用重启, 当RocketMQ的Broker或客户端重启、扩容或缩容时, 会触发Rebalance , 此时消费者可能会收到重复消息. 在RocketMQ中, 无法保证每个消息只被投递一次, 所以要在业务上自行来保证消息消费的幂等性. RocketMQ的每条消息都有一个唯一的MessageId , 该参数在多次投递的过程中是不会改变, 业务上可用MessageId来作为判断幂等的关键依据. MessageId无法保证全局唯一, 也会有冲突的情况. 所以在一些对幂等性要求严格的场景, 最好是使用业务上唯一的一个标识如订单ID. 而该业务标识可使用 Message的Key来进行传递. 消息零丢失 生产者使用事务消息机制. Broker配置同步刷盘+Dledger主从架构 消费者不要使用异步消费. 整个MQ挂了之后准备降级方案 消息积压处理若Topic下的MessageQueue配置得是足够多的, 每个Consumer实际上会分配多个MessageQueue来进行消费. 可通过增加Consumer服务节点数量来加快消息的消费, 等积压消息消费完了, 再恢复成正常情况. 最极限的情况是把Consumer的节点个数设置成跟MessageQueue的个数相同. 此时再继续增加Consumer的服务节点就没有用了. 若Topic下的MessageQueue配置不够多, 就不能用上面这种增加Consumer节点个数的方法. 若要快速处理积压的消息, 可创建一个新的Topic , 配置足够多的MessageQueue , 把所有消费者节点的目标Topic转向新的Topic, 并紧急上线一组新的消费者, 只负责消费旧Topic中的消息, 并转储到新的Topic中, 在新的Topic上就可以通过增加消费者个数来提高消费速度了. 若RocketMQ原本是采用的普通方式搭建主从架构, 而现在想要中途改为使用Dledger高可用集群, 这时若不想历史消息丢失, 就需要先将消息进行对齐, 也就是要消费者把所有的消息都消费完, 再来切换主从架构. 因为Dledger集群会接管RocketMQ原有的CommitLog日志, 切换主从架构时, 若有消息没有消费完, 这些消息是存在旧的CommitLog中的, 就无法再进行消费了. 该场景下也是需要尽快的处理掉积压的消息.","tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"http://example.com/tags/RocketMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RocketMQ","slug":"工具和中间件/消息队列/RocketMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RocketMQ/"}]},{"title":"RocketMQ-消息存储源码","date":"2019-04-23T05:08:20.000Z","path":"blog/工具和中间件/消息队列/RocketMQ/RocketMQ-消息存储源码/","text":"RocketMQ的存储文件包括消息文件Commitlog 、消息消费队列文件ConsumerQueue 、Hash索引文件IndexFile 、监测点文件checkPoint 、 abort关闭异常文件. 单个消息存储文件、消息消费队列文件、Hash索引文件长度固定以便使用内存映射机制进行文件的读写操作. RocketMQ组织文件以文件起始偏移量来命令文件, 根据偏移量能快速定位到真实物理文件. 基于内存映射文件机制提供了同步刷盘和异步刷盘两种机制, 异步刷盘是指在消息存储时先追加到内存映射文件, 然后启动专门的刷盘线程定时将内存中的文件数据刷写到磁盘. 为了保证消息发送的高吞吐量, 采用单一文件存储所有主题消息, 保证消息存储是完全的顺序写, 但这样给文件读取带来了不便, 为了方便消息消费构建了消息消费队列文件, 基于主题与队列进行组织, 同时为消息实现了Hash索引, 可以为消息设置索引键, 故能快速从 CommitLog 文件中检索消息. 当消息达到 CommitLog 后, 会通过 ReputMessageService 线程接近实时地将消息转发给消息消费队列文件与索引文件. 为了安全起见引入 abort文件, 记录Broker停机是否是正常关闭, 在重启Broker时为了保证CommitLog文件、消息消费队列文件与Hash索引文件的正确性, 分别采用不同策略来恢复文件. RocketMQ不会永久存储消息文件、消息消费队列文件, 而是启动文件过期机制并在磁盘空间不足或默认4点删除过期文件, 文件保存72小时并且在删除文件时并不会判断该消息文件上的消息是否被消费. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class DefaultMessageStore implements MessageStore &#123; public void start() throws Exception &#123; lock = lockFile.getChannel().tryLock(0, 1, false); if (lock == null || lock.isShared() || !lock.isValid()) &#123; throw new RuntimeException(&quot;Lock failed,MQ already started&quot;); &#125; lockFile.getChannel().write(ByteBuffer.wrap(&quot;lock&quot;.getBytes())); lockFile.getChannel().force(true); &#123; long maxPhysicalPosInLogicQueue = commitLog.getMinOffset(); for (ConcurrentMap&lt;Integer, ConsumeQueue&gt; maps : this.consumeQueueTable.values()) &#123; for (ConsumeQueue logic : maps.values()) &#123; if (logic.getMaxPhysicOffset() &gt; maxPhysicalPosInLogicQueue) &#123; maxPhysicalPosInLogicQueue = logic.getMaxPhysicOffset(); &#125; &#125; &#125; if (maxPhysicalPosInLogicQueue &lt; 0) &#123; maxPhysicalPosInLogicQueue = 0; &#125; if (maxPhysicalPosInLogicQueue &lt; this.commitLog.getMinOffset()) &#123; maxPhysicalPosInLogicQueue = this.commitLog.getMinOffset(); &#125; // Broker启动时会启动一个线程来更新ConsumerQueue索引文件. this.reputMessageService.setReputFromOffset(maxPhysicalPosInLogicQueue); this.reputMessageService.start(); while (true) &#123; if (dispatchBehindBytes() &lt;= 0) &#123; break; &#125; Thread.sleep(1000); &#125; this.recoverTopicQueueTable(); &#125; if (!messageStoreConfig.isEnableDLegerCommitLog()) &#123; this.haService.start(); this.handleScheduleMessageService(messageStoreConfig.getBrokerRole()); &#125; this.flushConsumeQueueService.start(); this.commitLog.start(); this.storeStatsService.start(); this.createTempFile(); this.addScheduleTask(); // Broker启动删除过期文件的定时任务 this.shutdown = false; &#125;&#125; 消息存储对于消息的存储是通过 DefaultMessageStore 的 putMessage 方法最终调用 CommitLog 的 putMessage 方法从而使用 mmap零拷贝来完成数据的存储. 对于延迟消息会将实际的Topic替换为SCHEDULE_TOPIC_XXXX , 通过异步任务当到达时间点时再从该队列中取出再放入原来实际的Topic中. 对于 CommitLog 文件的写同一时间只能有一个线程, 首先会获取当前要写的 MappedFile , 若该文件已满或不存在则创建一个 MappedFile , 通过 MappedFile 的 appendMessage 方法将数据写入缓存中. 然后执行 handleDiskFlush 方法将缓存中的数据刷到磁盘中, 以及通过 handleHA 方法进行主从同步. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113public interface MessageStore &#123; default CompletableFuture&lt;PutMessageResult&gt; asyncPutMessage(final MessageExtBrokerInner msg) &#123; return CompletableFuture.completedFuture(putMessage(msg)); &#125;&#125;public class DefaultMessageStore implements MessageStore &#123; public PutMessageResult putMessage(MessageExtBrokerInner msg) &#123; PutMessageStatus checkStoreStatus = this.checkStoreStatus(); if (checkStoreStatus != PutMessageStatus.PUT_OK) &#123; return new PutMessageResult(checkStoreStatus, null); &#125; PutMessageStatus msgCheckStatus = this.checkMessage(msg); if (msgCheckStatus == PutMessageStatus.MESSAGE_ILLEGAL) &#123; return new PutMessageResult(msgCheckStatus, null); &#125; long beginTime = this.getSystemClock().now(); //我们跟踪下这个最典型的消息写入commitlog的方法 PutMessageResult result = this.commitLog.putMessage(msg); long elapsedTime = this.getSystemClock().now() - beginTime; this.storeStatsService.setPutMessageEntireTimeMax(elapsedTime); if (null == result || !result.isOk()) &#123; this.storeStatsService.getPutMessageFailedTimes().incrementAndGet(); &#125; return result; &#125;&#125;public class CommitLog &#123; public PutMessageResult putMessage(final MessageExtBrokerInner msg) &#123; msg.setStoreTimestamp(System.currentTimeMillis()); // Set the storage time msg.setBodyCRC(UtilAll.crc32(msg.getBody())); AppendMessageResult result = null; StoreStatsService storeStatsService = this.defaultMessageStore.getStoreStatsService(); String topic = msg.getTopic(); int queueId = msg.getQueueId(); final int tranType = MessageSysFlag.getTransactionValue(msg.getSysFlag()); if (tranType == MessageSysFlag.TRANSACTION_NOT_TYPE || tranType == MessageSysFlag.TRANSACTION_COMMIT_TYPE) &#123; if (msg.getDelayTimeLevel() &gt; 0) &#123; // Delay Delivery if (msg.getDelayTimeLevel() &gt; this.defaultMessageStore.getScheduleMessageService().getMaxDelayLevel()) &#123; msg.setDelayTimeLevel(this.defaultMessageStore.getScheduleMessageService().getMaxDelayLevel()); &#125; topic = TopicValidator.RMQ_SYS_SCHEDULE_TOPIC; // 将消息的Topic替换为SCHEDULE_TOPIC_XXXX queueId = ScheduleMessageService.delayLevel2QueueId(msg.getDelayTimeLevel()); MessageAccessor.putProperty(msg, MessageConst.PROPERTY_REAL_TOPIC, msg.getTopic()); MessageAccessor.putProperty(msg, MessageConst.PROPERTY_REAL_QUEUE_ID, String.valueOf(msg.getQueueId())); msg.setPropertiesString(MessageDecoder.messageProperties2String(msg.getProperties())); msg.setTopic(topic); msg.setQueueId(queueId); &#125; &#125; InetSocketAddress bornSocketAddress = (InetSocketAddress) msg.getBornHost(); if (bornSocketAddress.getAddress() instanceof Inet6Address) &#123; msg.setBornHostV6Flag(); &#125; InetSocketAddress storeSocketAddress = (InetSocketAddress) msg.getStoreHost(); if (storeSocketAddress.getAddress() instanceof Inet6Address) &#123; msg.setStoreHostAddressV6Flag(); &#125; long elapsedTimeInLock = 0; MappedFile unlockMappedFile = null; MappedFile mappedFile = this.mappedFileQueue.getLastMappedFile(); //mappedFile 零拷贝实现 putMessageLock.lock(); // 线程锁 注意使用锁的这种方式 try &#123; long beginLockTimestamp = this.defaultMessageStore.getSystemClock().now(); this.beginTimeInLock = beginLockTimestamp; msg.setStoreTimestamp(beginLockTimestamp); if (null == mappedFile || mappedFile.isFull()) &#123; mappedFile = this.mappedFileQueue.getLastMappedFile(0); // Mark: NewFile may be cause noise &#125; if (null == mappedFile) &#123; beginTimeInLock = 0; return new PutMessageResult(PutMessageStatus.CREATE_MAPEDFILE_FAILED, null); &#125; // 直接以Append的方式写入文件 result = mappedFile.appendMessage(msg, this.appendMessageCallback); switch (result.getStatus()) &#123; // 文件写入的结果 case PUT_OK: break; case END_OF_FILE: //文件写满了, 就创建一个新文件, 重写消息 unlockMappedFile = mappedFile; mappedFile = this.mappedFileQueue.getLastMappedFile(0); if (null == mappedFile) &#123; beginTimeInLock = 0; return new PutMessageResult(PutMessageStatus.CREATE_MAPEDFILE_FAILED, result); &#125; result = mappedFile.appendMessage(msg, this.appendMessageCallback); break; case MESSAGE_SIZE_EXCEEDED: case PROPERTIES_SIZE_EXCEEDED: beginTimeInLock = 0; return new PutMessageResult(PutMessageStatus.MESSAGE_ILLEGAL, result); case UNKNOWN_ERROR: beginTimeInLock = 0; return new PutMessageResult(PutMessageStatus.UNKNOWN_ERROR, result); default: beginTimeInLock = 0; return new PutMessageResult(PutMessageStatus.UNKNOWN_ERROR, result); &#125; elapsedTimeInLock = this.defaultMessageStore.getSystemClock().now() - beginLockTimestamp; beginTimeInLock = 0; &#125; finally &#123; putMessageLock.unlock(); &#125; if (null != unlockMappedFile &amp;&amp; this.defaultMessageStore.getMessageStoreConfig().isWarmMapedFileEnable()) &#123; this.defaultMessageStore.unlockMappedFile(unlockMappedFile); &#125; PutMessageResult putMessageResult = new PutMessageResult(PutMessageStatus.PUT_OK, result); storeStatsService.getSinglePutMessageTopicTimesTotal(msg.getTopic()).incrementAndGet(); storeStatsService.getSinglePutMessageTopicSizeTotal(topic).addAndGet(result.getWroteBytes()); handleDiskFlush(result, putMessageResult, msg); //文件刷盘 handleHA(result, putMessageResult, msg); //主从同步 return putMessageResult; &#125;&#125; MappedFileQueue 对应 CommitLog 目录下的文件, 文件名称为第一个数据的偏移量加个上文件的固定大小, 最终会通过 AllocateMappedFileService 的 putRequestAndReturnMappedFile 方法创建一个 MappedFile 对象. 123456789101112131415161718192021222324252627282930313233343536public class MappedFileQueue &#123; // MappedFileQueue对应CommitLog目录下的文件 public MappedFile getLastMappedFile(final long startOffset) &#123; return getLastMappedFile(startOffset, true); &#125; public MappedFile getLastMappedFile(final long startOffset, boolean needCreate) &#123; long createOffset = -1; MappedFile mappedFileLast = getLastMappedFile(); if (mappedFileLast == null) &#123; createOffset = startOffset - (startOffset % this.mappedFileSize); &#125; if (mappedFileLast != null &amp;&amp; mappedFileLast.isFull()) &#123; createOffset = mappedFileLast.getFileFromOffset() + this.mappedFileSize; &#125; if (createOffset != -1 &amp;&amp; needCreate) &#123; String nextFilePath = this.storePath + File.separator + UtilAll.offset2FileName(createOffset); String nextNextFilePath = this.storePath + File.separator + UtilAll.offset2FileName(createOffset + this.mappedFileSize); MappedFile mappedFile = null; if (this.allocateMappedFileService != null) &#123; mappedFile = this.allocateMappedFileService.putRequestAndReturnMappedFile(nextFilePath, nextNextFilePath, this.mappedFileSize); &#125; else &#123; try &#123; mappedFile = new MappedFile(nextFilePath, this.mappedFileSize); &#125; catch (IOException e) &#123; &#125; &#125; if (mappedFile != null) &#123; if (this.mappedFiles.isEmpty()) &#123; mappedFile.setFirstCreateInQueue(true); &#125; this.mappedFiles.add(mappedFile); &#125; return mappedFile; &#125; return mappedFileLast; &#125;&#125; AllocateMappedFileService 是一个线程类, putRequestAndReturnMappedFile 中会把任务放入队列中, 然后在run方法中取处理任务, 该线程是在 DefaultMessageStore 的构造方法中创建启动. 这里会将写满的文件刷到磁盘中. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131public class AllocateMappedFileService extends ServiceThread &#123; private ConcurrentMap&lt;String, AllocateRequest&gt; requestTable = new ConcurrentHashMap&lt;String, AllocateRequest&gt;(); private PriorityBlockingQueue&lt;AllocateRequest&gt; requestQueue = new PriorityBlockingQueue&lt;AllocateRequest&gt;(); public MappedFile putRequestAndReturnMappedFile(String nextFilePath, String nextNextFilePath, int fileSize) &#123; int canSubmitRequests = 2; if (this.messageStore.getMessageStoreConfig().isTransientStorePoolEnable()) &#123; if (this.messageStore.getMessageStoreConfig().isFastFailIfNoBufferInStorePool() &amp;&amp; BrokerRole.SLAVE != this.messageStore.getMessageStoreConfig().getBrokerRole()) &#123; //if broker is slave, don&#x27;t fast fail even no buffer in pool canSubmitRequests = this.messageStore.getTransientStorePool().availableBufferNums() - this.requestQueue.size(); &#125; &#125; AllocateRequest nextReq = new AllocateRequest(nextFilePath, fileSize); boolean nextPutOK = this.requestTable.putIfAbsent(nextFilePath, nextReq) == null; if (nextPutOK) &#123; if (canSubmitRequests &lt;= 0) &#123; this.requestTable.remove(nextFilePath); return null; &#125; boolean offerOK = this.requestQueue.offer(nextReq); canSubmitRequests--; &#125; AllocateRequest nextNextReq = new AllocateRequest(nextNextFilePath, fileSize); boolean nextNextPutOK = this.requestTable.putIfAbsent(nextNextFilePath, nextNextReq) == null; if (nextNextPutOK) &#123; if (canSubmitRequests &lt;= 0) &#123; this.requestTable.remove(nextNextFilePath); &#125; else &#123; boolean offerOK = this.requestQueue.offer(nextNextReq); &#125; &#125; if (hasException) &#123; return null; &#125; AllocateRequest result = this.requestTable.get(nextFilePath); try &#123; if (result != null) &#123; boolean waitOK = result.getCountDownLatch().await(waitTimeOut, TimeUnit.MILLISECONDS); if (!waitOK) &#123; return null; &#125; else &#123; this.requestTable.remove(nextFilePath); return result.getMappedFile(); &#125; &#125; &#125; return null; &#125; public void run() &#123; while (!this.isStopped() &amp;&amp; this.mmapOperation()) &#123; &#125; &#125; private boolean mmapOperation() &#123; boolean isSuccess = false; AllocateRequest req = null; try &#123; req = this.requestQueue.take(); AllocateRequest expectedRequest = this.requestTable.get(req.getFilePath()); if (null == expectedRequest) &#123; return true; &#125; if (expectedRequest != req) &#123; return true; &#125; if (req.getMappedFile() == null) &#123; long beginTime = System.currentTimeMillis(); MappedFile mappedFile; if (messageStore.getMessageStoreConfig().isTransientStorePoolEnable()) &#123; try &#123; mappedFile = ServiceLoader.load(MappedFile.class).iterator().next(); mappedFile.init(req.getFilePath(), req.getFileSize(), messageStore.getTransientStorePool()); &#125; catch (RuntimeException e) &#123; mappedFile = new MappedFile(req.getFilePath(), req.getFileSize(), messageStore.getTransientStorePool()); &#125; &#125; else &#123; mappedFile = new MappedFile(req.getFilePath(), req.getFileSize()); &#125; long elapsedTime = UtilAll.computeElapsedTimeMilliseconds(beginTime); if (elapsedTime &gt; 10) &#123; int queueSize = this.requestQueue.size(); &#125; if (mappedFile.getFileSize() &gt;= this.messageStore.getMessageStoreConfig().getMappedFileSizeCommitLog() &amp;&amp; this.messageStore.getMessageStoreConfig().isWarmMapedFileEnable()) &#123; mappedFile.warmMappedFile(this.messageStore.getMessageStoreConfig().getFlushDiskType(), this.messageStore.getMessageStoreConfig().getFlushLeastPagesWhenWarmMapedFile()); &#125; req.setMappedFile(mappedFile); this.hasException = false; isSuccess = true; &#125; &#125; catch (InterruptedException e) &#123; this.hasException = true; return false; &#125; catch (IOException e) &#123; this.hasException = true; if (null != req) &#123; requestQueue.offer(req); try &#123; Thread.sleep(1); &#125; catch (InterruptedException ignored) &#123; &#125; &#125; &#125; finally &#123; if (req != null &amp;&amp; isSuccess) req.getCountDownLatch().countDown(); &#125; return true; &#125;&#125;public class MappedFile extends ReferenceResource &#123; public void warmMappedFile(FlushDiskType type, int pages) &#123; long beginTime = System.currentTimeMillis(); ByteBuffer byteBuffer = this.mappedByteBuffer.slice(); int flush = 0; long time = System.currentTimeMillis(); for (int i = 0, j = 0; i &lt; this.fileSize; i += MappedFile.OS_PAGE_SIZE, j++) &#123; byteBuffer.put(i, (byte) 0); if (type == FlushDiskType.SYNC_FLUSH) &#123; if ((i / OS_PAGE_SIZE) - (flush / OS_PAGE_SIZE) &gt;= pages) &#123; flush = i; mappedByteBuffer.force(); // force flush when flush disk type is sync &#125; &#125; if (j % 1000 == 0) &#123; // prevent gc try &#123; Thread.sleep(0); &#125; &#125; &#125; if (type == FlushDiskType.SYNC_FLUSH) &#123; mappedByteBuffer.force(); // force flush when prepare load finished &#125; this.mlock(); &#125;&#125; 消息是通过 MappedFile 的 appendMessage 方法以Append的方式写入文件缓存中. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899public class MappedFile extends ReferenceResource &#123; public AppendMessageResult appendMessage(final MessageExtBrokerInner msg, final AppendMessageCallback cb) &#123; return appendMessagesInner(msg, cb); &#125; public AppendMessageResult appendMessagesInner(final MessageExt messageExt, final AppendMessageCallback cb) &#123; assert messageExt != null; assert cb != null; int currentPos = this.wrotePosition.get(); if (currentPos &lt; this.fileSize) &#123; ByteBuffer byteBuffer = writeBuffer != null ? writeBuffer.slice() : this.mappedByteBuffer.slice(); byteBuffer.position(currentPos); AppendMessageResult result; if (messageExt instanceof MessageExtBrokerInner) &#123; result = cb.doAppend(this.getFileFromOffset(), byteBuffer, this.fileSize - currentPos, (MessageExtBrokerInner) messageExt); &#125; else if (messageExt instanceof MessageExtBatch) &#123; result = cb.doAppend(this.getFileFromOffset(), byteBuffer, this.fileSize - currentPos, (MessageExtBatch) messageExt); &#125; else &#123; return new AppendMessageResult(AppendMessageStatus.UNKNOWN_ERROR); &#125; this.wrotePosition.addAndGet(result.getWroteBytes()); this.storeTimestamp = result.getStoreTimestamp(); return result; &#125; return new AppendMessageResult(AppendMessageStatus.UNKNOWN_ERROR); &#125;&#125;public class CommitLog &#123; public AppendMessageResult doAppend(final long fileFromOffset, final ByteBuffer byteBuffer, final int maxBlank, final MessageExtBatch messageExtBatch) &#123; byteBuffer.mark(); long wroteOffset = fileFromOffset + byteBuffer.position(); //physical offset keyBuilder.setLength(0); // Record ConsumeQueue information keyBuilder.append(messageExtBatch.getTopic()); keyBuilder.append(&#x27;-&#x27;); keyBuilder.append(messageExtBatch.getQueueId()); String key = keyBuilder.toString(); Long queueOffset = CommitLog.this.topicQueueTable.get(key); if (null == queueOffset) &#123; queueOffset = 0L; CommitLog.this.topicQueueTable.put(key, queueOffset); &#125; long beginQueueOffset = queueOffset; int totalMsgLen = 0; int msgNum = 0; msgIdBuilder.setLength(0); final long beginTimeMills = CommitLog.this.defaultMessageStore.now(); ByteBuffer messagesByteBuff = messageExtBatch.getEncodedBuff(); int sysFlag = messageExtBatch.getSysFlag(); int storeHostLength = (sysFlag &amp; MessageSysFlag.STOREHOSTADDRESS_V6_FLAG) == 0 ? 4 + 4 : 16 + 4; ByteBuffer storeHostHolder = ByteBuffer.allocate(storeHostLength); this.resetByteBuffer(storeHostHolder, storeHostLength); ByteBuffer storeHostBytes = messageExtBatch.getStoreHostBytes(storeHostHolder); messagesByteBuff.mark(); while (messagesByteBuff.hasRemaining()) &#123; final int msgPos = messagesByteBuff.position(); // 1 TOTALSIZE final int msgLen = messagesByteBuff.getInt(); final int bodyLen = msgLen - 40; //only for log, just estimate it if (msgLen &gt; this.maxMessageSize) &#123; // Exceeds the maximum message CommitLog.log.warn(&quot;message size exceeded, msg total size: &quot; + msgLen + &quot;, msg body size: &quot; + bodyLen + &quot;, maxMessageSize: &quot; + this.maxMessageSize); return new AppendMessageResult(AppendMessageStatus.MESSAGE_SIZE_EXCEEDED); &#125; totalMsgLen += msgLen; if ((totalMsgLen + END_FILE_MIN_BLANK_LENGTH) &gt; maxBlank) &#123; // Determines whether there is sufficient free space this.resetByteBuffer(this.msgStoreItemMemory, 8); this.msgStoreItemMemory.putInt(maxBlank); // 1 TOTALSIZE this.msgStoreItemMemory.putInt(CommitLog.BLANK_MAGIC_CODE); // 2 MAGICCODE messagesByteBuff.reset(); // 3 The remaining space may be any value ignore previous read byteBuffer.reset(); //Here the length of the specially set maxBlank ignore the previous appended messages byteBuffer.put(this.msgStoreItemMemory.array(), 0, 8); return new AppendMessageResult(AppendMessageStatus.END_OF_FILE, wroteOffset, maxBlank, msgIdBuilder.toString(), messageExtBatch.getStoreTimestamp(), beginQueueOffset, CommitLog.this.defaultMessageStore.now() - beginTimeMills); &#125; messagesByteBuff.position(msgPos + 20); //move to add queue offset and commitlog offset messagesByteBuff.putLong(queueOffset); messagesByteBuff.putLong(wroteOffset + totalMsgLen - msgLen); storeHostBytes.rewind(); String msgId; if ((sysFlag &amp; MessageSysFlag.STOREHOSTADDRESS_V6_FLAG) == 0) &#123; msgId = MessageDecoder.createMessageId(this.msgIdMemory, storeHostBytes, wroteOffset + totalMsgLen - msgLen); &#125; else &#123; msgId = MessageDecoder.createMessageId(this.msgIdV6Memory, storeHostBytes, wroteOffset + totalMsgLen - msgLen); &#125; if (msgIdBuilder.length() &gt; 0) &#123; msgIdBuilder.append(&#x27;,&#x27;).append(msgId); &#125; else &#123; msgIdBuilder.append(msgId); &#125; queueOffset++; msgNum++; messagesByteBuff.position(msgPos + msgLen); &#125; messagesByteBuff.position(0); messagesByteBuff.limit(totalMsgLen); byteBuffer.put(messagesByteBuff); messageExtBatch.setEncodedBuff(null); AppendMessageResult result = new AppendMessageResult(AppendMessageStatus.PUT_OK, wroteOffset, totalMsgLen, msgIdBuilder.toString(), messageExtBatch.getStoreTimestamp(), beginQueueOffset, CommitLog.this.defaultMessageStore.now() - beginTimeMills); result.setMsgNum(msgNum); CommitLog.this.topicQueueTable.put(key, queueOffset); return result; &#125;&#125; 同步数据刷盘是通过 CommitLog 的 handleDiskFlush 方法来完成的, 最终将耍盘任务通过 putRequest 方法提交到 GroupCommitService 中, 异步消息刷盘任务也是调用的 putRequest 方法, GroupCommitService 是一个线程在 CommitLog 的start方法中被启动, 从run方法中可知该刷盘任务每10ms执行一次. 最终调用 MappedFileQueue 的 flush 方法强迫把写入内存的数据刷入到磁盘文件中. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133public class CommitLog &#123; public CompletableFuture&lt;PutMessageStatus&gt; submitFlushRequest(AppendMessageResult result, PutMessageResult putMessageResult, MessageExt messageExt) &#123; if (FlushDiskType.SYNC_FLUSH == this.defaultMessageStore.getMessageStoreConfig().getFlushDiskType()) &#123; final GroupCommitService service = (GroupCommitService) this.flushCommitLogService; if (messageExt.isWaitStoreMsgOK()) &#123; GroupCommitRequest request = new GroupCommitRequest(result.getWroteOffset() + result.getWroteBytes(), this.defaultMessageStore.getMessageStoreConfig().getSyncFlushTimeout()); service.putRequest(request); return request.future(); // 直接返回future不会同步等待 &#125; else &#123; service.wakeup(); return CompletableFuture.completedFuture(PutMessageStatus.PUT_OK); &#125; &#125; else &#123; // 若打开了对外内存, 就需要先将对外内存写入到文件映射中, 再存盘 if (!this.defaultMessageStore.getMessageStoreConfig().isTransientStorePoolEnable()) &#123; flushCommitLogService.wakeup(); &#125; else &#123; commitLogService.wakeup(); &#125; return CompletableFuture.completedFuture(PutMessageStatus.PUT_OK); &#125; &#125; public void handleDiskFlush(AppendMessageResult result, PutMessageResult putMessageResult, MessageExt messageExt) &#123; if (FlushDiskType.SYNC_FLUSH == this.defaultMessageStore.getMessageStoreConfig().getFlushDiskType()) &#123; // Synchronization flush 同步刷盘 final GroupCommitService service = (GroupCommitService) this.flushCommitLogService; if (messageExt.isWaitStoreMsgOK()) &#123;//构建一个GroupCommitRequest, 交给GroupCommitService处理. GroupCommitRequest request = new GroupCommitRequest(result.getWroteOffset() + result.getWroteBytes()); service.putRequest(request); CompletableFuture&lt;PutMessageStatus&gt; flushOkFuture = request.future(); PutMessageStatus flushStatus = null; try &#123; //同步等待文件刷新 flushStatus = flushOkFuture.get(this.defaultMessageStore.getMessageStoreConfig().getSyncFlushTimeout(), TimeUnit.MILLISECONDS); &#125; catch (InterruptedException | ExecutionException | TimeoutException e) &#123; &#125; if (flushStatus != PutMessageStatus.PUT_OK) &#123; putMessageResult.setPutMessageStatus(PutMessageStatus.FLUSH_DISK_TIMEOUT); &#125; &#125; else &#123; service.wakeup(); &#125; &#125; else &#123; // Asynchronous flush 异步刷盘, 异步刷盘是把消息映射到MappedFile后, 单独唤醒一个服务来进行刷盘 if (!this.defaultMessageStore.getMessageStoreConfig().isTransientStorePoolEnable()) &#123; flushCommitLogService.wakeup(); &#125; else &#123; commitLogService.wakeup(); &#125; &#125; &#125;&#125;class GroupCommitService extends FlushCommitLogService &#123; private volatile List&lt;GroupCommitRequest&gt; requestsWrite = new ArrayList&lt;GroupCommitRequest&gt;(); private volatile List&lt;GroupCommitRequest&gt; requestsRead = new ArrayList&lt;GroupCommitRequest&gt;(); public synchronized void putRequest(final GroupCommitRequest request) &#123; synchronized (this.requestsWrite) &#123; this.requestsWrite.add(request); &#125; this.wakeup(); &#125; public void run() &#123; while (!this.isStopped()) &#123; try &#123; this.waitForRunning(10); this.doCommit(); &#125; &#125; try &#123;// Under normal circumstances shutdown, wait for the arrival of the request, and then flush Thread.sleep(10); &#125; synchronized (this) &#123; this.swapRequests(); &#125; this.doCommit(); &#125; private void doCommit() &#123; synchronized (this.requestsRead) &#123; if (!this.requestsRead.isEmpty()) &#123; for (GroupCommitRequest req : this.requestsRead) &#123; // 消息刷盘 // There may be a message in the next file, so a maximum of two times the flush boolean flushOK = false; for (int i = 0; i &lt; 2 &amp;&amp; !flushOK; i++) &#123; flushOK = CommitLog.this.mappedFileQueue.getFlushedWhere() &gt;= req.getNextOffset(); if (!flushOK) &#123; // 当前索引位置小于请求数据的位置执行刷盘 CommitLog.this.mappedFileQueue.flush(0); &#125; &#125; req.wakeupCustomer(flushOK ? PutMessageStatus.PUT_OK : PutMessageStatus.FLUSH_DISK_TIMEOUT); &#125; long storeTimestamp = CommitLog.this.mappedFileQueue.getStoreTimestamp(); if (storeTimestamp &gt; 0) &#123; CommitLog.this.defaultMessageStore.getStoreCheckpoint().setPhysicMsgTimestamp(storeTimestamp); &#125; this.requestsRead.clear(); &#125; else &#123; // Because of individual messages is set to not sync flush, it will come to this process CommitLog.this.mappedFileQueue.flush(0); &#125; &#125; &#125;&#125;public class MappedFileQueue &#123; public boolean flush(final int flushLeastPages) &#123; boolean result = true; MappedFile mappedFile = this.findMappedFileByOffset(this.flushedWhere, this.flushedWhere == 0); if (mappedFile != null) &#123; long tmpTimeStamp = mappedFile.getStoreTimestamp(); int offset = mappedFile.flush(flushLeastPages); long where = mappedFile.getFileFromOffset() + offset; result = where == this.flushedWhere; this.flushedWhere = where; if (0 == flushLeastPages) &#123; this.storeTimestamp = tmpTimeStamp; &#125; &#125; return result; &#125;&#125;public int flush(final int flushLeastPages) &#123; if (this.isAbleToFlush(flushLeastPages)) &#123; if (this.hold()) &#123; int value = getReadPosition(); try &#123; // force方法就是强迫把写入内存的数据刷入到磁盘文件里去 if (writeBuffer != null || this.fileChannel.position() != 0) &#123; this.fileChannel.force(false); &#125; else &#123; this.mappedByteBuffer.force(); &#125; &#125; this.flushedPosition.set(value); this.release(); &#125; else &#123; this.flushedPosition.set(getReadPosition()); &#125; &#125; return this.getFlushedPosition();&#125; 消息分发当 CommitLog 写入一条消息后, 会有一个后台线程 ReputMessageService 每隔1ms 就会去拉取 CommitLog 中最新更新的一批消息, 然后分别转发到 ComsumeQueue 和 IndexFile 中. 若服务异常宕机, 会造成 CommitLog 和 ConsumeQueue 、 IndexFile 文件不一致, 有消息写入CommitLog后, 没有分发到索引文件, 这样消息就丢失了. DefaultMappedStore 的 load 方法提供了恢复索引文件的方法. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970class ReputMessageService extends ServiceThread &#123; public void run() &#123; while (!this.isStopped()) &#123; try &#123; // 每隔1毫秒, 往ConsumeQueue和IndexFile中转发一次CommitLog写入的消息 Thread.sleep(1); this.doReput(); &#125; catch (Exception e) &#123; &#125; &#125; &#125; private void doReput() &#123; if (this.reputFromOffset &lt; DefaultMessageStore.this.commitLog.getMinOffset()) &#123; this.reputFromOffset = DefaultMessageStore.this.commitLog.getMinOffset(); &#125; for (boolean doNext = true; this.isCommitLogAvailable() &amp;&amp; doNext; ) &#123; if (DefaultMessageStore.this.getMessageStoreConfig().isDuplicationEnable() &amp;&amp; this.reputFromOffset &gt;= DefaultMessageStore.this.getConfirmOffset()) &#123; break; &#125; SelectMappedBufferResult result = DefaultMessageStore.this.commitLog.getData(reputFromOffset); // 获取CommitLog中的消息 if (result != null) &#123; try &#123; this.reputFromOffset = result.getStartOffset(); for (int readSize = 0; readSize &lt; result.getSize() &amp;&amp; doNext; ) &#123; //从CommitLog中获取一个DispatchRequest,拿到一份需要进行转发的消息, 也就是从commitlog中读取的. DispatchRequest dispatchRequest = DefaultMessageStore.this.commitLog.checkMessageAndReturnSize(result.getByteBuffer(), false, false); int size = dispatchRequest.getBufferSize() == -1 ? dispatchRequest.getMsgSize() : dispatchRequest.getBufferSize(); if (dispatchRequest.isSuccess()) &#123; if (size &gt; 0) &#123; DefaultMessageStore.this.doDispatch(dispatchRequest); //分发CommitLog写入消息 // 长轮询： 如果有消息到了主节点, 并且开启了长轮询. if (BrokerRole.SLAVE != DefaultMessageStore.this.getMessageStoreConfig().getBrokerRole() &amp;&amp; DefaultMessageStore.this.brokerConfig.isLongPollingEnable()) &#123; //唤醒NotifyMessageArrivingListener的arriving方法, 进行一次请求线程的检查 DefaultMessageStore.this.messageArrivingListener.arriving(dispatchRequest.getTopic(), dispatchRequest.getQueueId(), dispatchRequest.getConsumeQueueOffset() + 1, dispatchRequest.getTagsCode(), dispatchRequest.getStoreTimestamp(), dispatchRequest.getBitMap(), dispatchRequest.getPropertiesMap()); &#125; this.reputFromOffset += size; readSize += size; if (DefaultMessageStore.this.getMessageStoreConfig().getBrokerRole() == BrokerRole.SLAVE) &#123; DefaultMessageStore.this.storeStatsService.getSinglePutMessageTopicTimesTotal(dispatchRequest.getTopic()).incrementAndGet(); DefaultMessageStore.this.storeStatsService.getSinglePutMessageTopicSizeTotal(dispatchRequest.getTopic()).addAndGet(dispatchRequest.getMsgSize()); &#125; &#125; else if (size == 0) &#123; this.reputFromOffset = DefaultMessageStore.this.commitLog.rollNextFile(this.reputFromOffset); readSize = result.getSize(); &#125; &#125; else if (!dispatchRequest.isSuccess()) &#123; if (size &gt; 0) &#123; this.reputFromOffset += size; &#125; else &#123; doNext = false; if (DefaultMessageStore.this.getMessageStoreConfig().isEnableDLegerCommitLog() || DefaultMessageStore.this.brokerConfig.getBrokerId() == MixAll.MASTER_ID) &#123; this.reputFromOffset += result.getSize() - readSize; &#125; &#125; &#125; &#125; &#125; finally &#123; result.release(); &#125; &#125; else &#123; doNext = false; &#125; &#125; &#125; public void doDispatch(DispatchRequest req) &#123; for (CommitLogDispatcher dispatcher : this.dispatcherList) &#123; dispatcher.dispatch(req); // 将commitLog写入的事件转发到ComsumeQueue和IndexFile &#125; &#125;&#125; 对于 ConsumeQueue 文件的写入是通过调用 CommitLogDispatcherBuildConsumeQueue 的 dispatch 方法, 在分发时首先通过 DefaultMessageStore 的 findConsumeQueue 方法按消息 Topic 和 queueId 找到对应的消息队列, 然后调用 ConsumeQueue 的 putMessagePositionInfoWrapper 正则去完成写入到对应的缓存以及刷盘工作. 最终调用的 MappedFile 的 appendMessage 来完成数据的持久化. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108class CommitLogDispatcherBuildConsumeQueue implements CommitLogDispatcher &#123; @Override public void dispatch(DispatchRequest request) &#123; // Consumequeue文件分发的构建器 final int tranType = MessageSysFlag.getTransactionValue(request.getSysFlag()); switch (tranType) &#123; case MessageSysFlag.TRANSACTION_NOT_TYPE: case MessageSysFlag.TRANSACTION_COMMIT_TYPE: DefaultMessageStore.this.putMessagePositionInfo(request); break; case MessageSysFlag.TRANSACTION_PREPARED_TYPE: case MessageSysFlag.TRANSACTION_ROLLBACK_TYPE: break; &#125; &#125;&#125;public class DefaultMessageStore implements MessageStore &#123; private final ConcurrentMap&lt;String, ConcurrentMap&lt;Integer, ConsumeQueue&gt;&gt; consumeQueueTable; public void putMessagePositionInfo(DispatchRequest dispatchRequest) &#123; ConsumeQueue cq = this.findConsumeQueue(dispatchRequest.getTopic(), dispatchRequest.getQueueId()); cq.putMessagePositionInfoWrapper(dispatchRequest); &#125; public ConsumeQueue findConsumeQueue(String topic, int queueId) &#123; // 获取具体的队列 ConcurrentMap&lt;Integer, ConsumeQueue&gt; map = consumeQueueTable.get(topic); if (null == map) &#123; ConcurrentMap&lt;Integer, ConsumeQueue&gt; newMap = new ConcurrentHashMap&lt;Integer, ConsumeQueue&gt;(128); ConcurrentMap&lt;Integer, ConsumeQueue&gt; oldMap = consumeQueueTable.putIfAbsent(topic, newMap); if (oldMap != null) &#123; map = oldMap; &#125; else &#123; map = newMap; &#125; &#125; ConsumeQueue logic = map.get(queueId); if (null == logic) &#123; ConsumeQueue newLogic = new ConsumeQueue(topic, queueId, StorePathConfigHelper.getStorePathConsumeQueue(this.messageStoreConfig.getStorePathRootDir()), this.getMessageStoreConfig().getMappedFileSizeConsumeQueue(), this); ConsumeQueue oldLogic = map.putIfAbsent(queueId, newLogic); if (oldLogic != null) &#123; logic = oldLogic; &#125; else &#123; logic = newLogic; &#125; &#125; return logic; &#125;&#125;public class ConsumeQueue &#123; public void putMessagePositionInfoWrapper(DispatchRequest request) &#123; final int maxRetries = 30; boolean canWrite = this.defaultMessageStore.getRunningFlags().isCQWriteable(); for (int i = 0; i &lt; maxRetries &amp;&amp; canWrite; i++) &#123; long tagsCode = request.getTagsCode(); if (isExtWriteEnable()) &#123; ConsumeQueueExt.CqExtUnit cqExtUnit = new ConsumeQueueExt.CqExtUnit(); cqExtUnit.setFilterBitMap(request.getBitMap()); cqExtUnit.setMsgStoreTime(request.getStoreTimestamp()); cqExtUnit.setTagsCode(request.getTagsCode()); long extAddr = this.consumeQueueExt.put(cqExtUnit); if (isExtAddr(extAddr)) &#123; tagsCode = extAddr; &#125; &#125; // ConsumeQueue数据分发 boolean result = this.putMessagePositionInfo(request.getCommitLogOffset(), request.getMsgSize(), tagsCode, request.getConsumeQueueOffset()); if (result) &#123; if (this.defaultMessageStore.getMessageStoreConfig().getBrokerRole() == BrokerRole.SLAVE || this.defaultMessageStore.getMessageStoreConfig().isEnableDLegerCommitLog()) &#123; this.defaultMessageStore.getStoreCheckpoint().setPhysicMsgTimestamp(request.getStoreTimestamp()); &#125; this.defaultMessageStore.getStoreCheckpoint().setLogicsMsgTimestamp(request.getStoreTimestamp()); return; &#125; else &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; &#125; &#125; &#125; this.defaultMessageStore.getRunningFlags().makeLogicsQueueError(); &#125; private boolean putMessagePositionInfo(final long offset, final int size, final long tagsCode, final long cqOffset) &#123; if (offset + size &lt;= this.maxPhysicOffset) &#123; return true; &#125; this.byteBufferIndex.flip(); this.byteBufferIndex.limit(CQ_STORE_UNIT_SIZE); this.byteBufferIndex.putLong(offset); this.byteBufferIndex.putInt(size); this.byteBufferIndex.putLong(tagsCode); final long expectLogicOffset = cqOffset * CQ_STORE_UNIT_SIZE; MappedFile mappedFile = this.mappedFileQueue.getLastMappedFile(expectLogicOffset); if (mappedFile != null) &#123; if (mappedFile.isFirstCreateInQueue() &amp;&amp; cqOffset != 0 &amp;&amp; mappedFile.getWrotePosition() == 0) &#123; this.minLogicOffset = expectLogicOffset; this.mappedFileQueue.setFlushedWhere(expectLogicOffset); this.mappedFileQueue.setCommittedWhere(expectLogicOffset); this.fillPreBlank(mappedFile, expectLogicOffset); &#125; if (cqOffset != 0) &#123; long currentLogicOffset = mappedFile.getWrotePosition() + mappedFile.getFileFromOffset(); if (expectLogicOffset &lt; currentLogicOffset) &#123; return true; &#125; &#125; this.maxPhysicOffset = offset + size; return mappedFile.appendMessage(this.byteBufferIndex.array()); &#125; return false; &#125;&#125; 对于Index文件的分发是通过 CommitLogDispatcherBuildIndex 中最终调用 IndexService 的 buildIndex 方法完成的, 首先先通过 retryGetAndCreateIndexFile 获取 IndexFile , 若不存在则创建, 让后通过 IndexFile 的 putKey 方法将数据写入磁盘. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169class CommitLogDispatcherBuildIndex implements CommitLogDispatcher &#123; @Override public void dispatch(DispatchRequest request) &#123; if (DefaultMessageStore.this.messageStoreConfig.isMessageIndexEnable()) &#123; DefaultMessageStore.this.indexService.buildIndex(request); &#125; &#125;&#125;public class IndexService &#123; public void buildIndex(DispatchRequest req) &#123; IndexFile indexFile = retryGetAndCreateIndexFile(); if (indexFile != null) &#123; long endPhyOffset = indexFile.getEndPhyOffset(); DispatchRequest msg = req; String topic = msg.getTopic(); String keys = msg.getKeys(); if (msg.getCommitLogOffset() &lt; endPhyOffset) &#123; //重复消息直接返回 return; &#125; final int tranType = MessageSysFlag.getTransactionValue(msg.getSysFlag()); switch (tranType) &#123; case MessageSysFlag.TRANSACTION_NOT_TYPE: case MessageSysFlag.TRANSACTION_PREPARED_TYPE: case MessageSysFlag.TRANSACTION_COMMIT_TYPE: break; case MessageSysFlag.TRANSACTION_ROLLBACK_TYPE: return; // 回退消息直接返回 &#125; // indexFile索引文件构建的核心步骤 if (req.getUniqKey() != null) &#123; // 若存在唯一键 indexFile = putKey(indexFile, msg, buildKey(topic, req.getUniqKey())); if (indexFile == null) &#123; return; &#125; &#125; if (keys != null &amp;&amp; keys.length() &gt; 0) &#123; // 若存在过滤的keys String[] keyset = keys.split(MessageConst.KEY_SEPARATOR); for (int i = 0; i &lt; keyset.length; i++) &#123; String key = keyset[i]; if (key.length() &gt; 0) &#123; indexFile = putKey(indexFile, msg, buildKey(topic, key)); if (indexFile == null) &#123; return; &#125; &#125; &#125; &#125; &#125; &#125; public IndexFile retryGetAndCreateIndexFile() &#123; IndexFile indexFile = null; for (int times = 0; null == indexFile &amp;&amp; times &lt; MAX_TRY_IDX_CREATE; times++) &#123; indexFile = this.getAndCreateLastIndexFile(); if (null != indexFile) break; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; &#125; &#125; if (null == indexFile) &#123; this.defaultMessageStore.getAccessRights().makeIndexFileError(); &#125; return indexFile; &#125; public IndexFile getAndCreateLastIndexFile() &#123; IndexFile indexFile = null; IndexFile prevIndexFile = null; long lastUpdateEndPhyOffset = 0; long lastUpdateIndexTimestamp = 0; &#123; this.readWriteLock.readLock().lock(); if (!this.indexFileList.isEmpty()) &#123; IndexFile tmp = this.indexFileList.get(this.indexFileList.size() - 1); if (!tmp.isWriteFull()) &#123; indexFile = tmp; &#125; else &#123; lastUpdateEndPhyOffset = tmp.getEndPhyOffset(); lastUpdateIndexTimestamp = tmp.getEndTimestamp(); prevIndexFile = tmp; &#125; &#125; this.readWriteLock.readLock().unlock(); &#125; if (indexFile == null) &#123; try &#123; // 按照时间生成Index文件名称 String fileName = this.storePath + File.separator + UtilAll.timeMillisToHumanString(System.currentTimeMillis()); indexFile = new IndexFile(fileName, this.hashSlotNum, this.indexNum, lastUpdateEndPhyOffset, lastUpdateIndexTimestamp); this.readWriteLock.writeLock().lock(); this.indexFileList.add(indexFile); &#125; catch (Exception e) &#123; &#125; finally &#123; this.readWriteLock.writeLock().unlock(); &#125; if (indexFile != null) &#123; // 开启线程将之前的IndexFile缓存中的数据刷到磁盘中 final IndexFile flushThisFile = prevIndexFile; Thread flushThread = new Thread(new Runnable() &#123; @Override public void run() &#123; IndexService.this.flush(flushThisFile); &#125; &#125;, &quot;FlushIndexFileThread&quot;); flushThread.setDaemon(true); flushThread.start(); &#125; &#125; return indexFile; &#125; private IndexFile putKey(IndexFile indexFile, DispatchRequest msg, String idxKey) &#123; for (boolean ok = indexFile.putKey(idxKey, msg.getCommitLogOffset(), msg.getStoreTimestamp()); !ok; ) &#123; indexFile = retryGetAndCreateIndexFile(); if (null == indexFile) &#123; return null; &#125; ok = indexFile.putKey(idxKey, msg.getCommitLogOffset(), msg.getStoreTimestamp()); &#125; return indexFile; &#125;&#125;public class IndexFile &#123; public boolean putKey(final String key, final long phyOffset, final long storeTimestamp) &#123; if (this.indexHeader.getIndexCount() &lt; this.indexNum) &#123; int keyHash = indexKeyHashMethod(key); int slotPos = keyHash % this.hashSlotNum; int absSlotPos = IndexHeader.INDEX_HEADER_SIZE + slotPos * hashSlotSize; FileLock fileLock = null; try &#123;// fileLock = this.fileChannel.lock(absSlotPos, hashSlotSize, false); int slotValue = this.mappedByteBuffer.getInt(absSlotPos); if (slotValue &lt;= invalidIndex || slotValue &gt; this.indexHeader.getIndexCount()) &#123; slotValue = invalidIndex; &#125; long timeDiff = storeTimestamp - this.indexHeader.getBeginTimestamp(); timeDiff = timeDiff / 1000; if (this.indexHeader.getBeginTimestamp() &lt;= 0) &#123; timeDiff = 0; &#125; else if (timeDiff &gt; Integer.MAX_VALUE) &#123; timeDiff = Integer.MAX_VALUE; &#125; else if (timeDiff &lt; 0) &#123; timeDiff = 0; &#125; int absIndexPos = IndexHeader.INDEX_HEADER_SIZE + this.hashSlotNum * hashSlotSize + this.indexHeader.getIndexCount() * indexSize; this.mappedByteBuffer.putInt(absIndexPos, keyHash); this.mappedByteBuffer.putLong(absIndexPos + 4, phyOffset); this.mappedByteBuffer.putInt(absIndexPos + 4 + 8, (int) timeDiff); this.mappedByteBuffer.putInt(absIndexPos + 4 + 8 + 4, slotValue); this.mappedByteBuffer.putInt(absSlotPos, this.indexHeader.getIndexCount()); if (this.indexHeader.getIndexCount() &lt;= 1) &#123; this.indexHeader.setBeginPhyOffset(phyOffset); this.indexHeader.setBeginTimestamp(storeTimestamp); &#125; if (invalidIndex == slotValue) &#123; this.indexHeader.incHashSlotCount(); &#125; this.indexHeader.incIndexCount(); this.indexHeader.setEndPhyOffset(phyOffset); this.indexHeader.setEndTimestamp(storeTimestamp); return true; &#125; catch (Exception e) &#123; &#125; finally &#123; if (fileLock != null) &#123; try &#123; fileLock.release(); &#125; &#125; &#125; &#125; return false; &#125;&#125;","tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"http://example.com/tags/RocketMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RocketMQ","slug":"工具和中间件/消息队列/RocketMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RocketMQ/"}]},{"title":"RocketMQ-消费者源码","date":"2019-04-23T04:08:20.000Z","path":"blog/工具和中间件/消息队列/RocketMQ/RocketMQ-消费者源码/","text":"消费者以消费者组的模式开展.消费者组之间有集群模式和广播模式两种消费模式.消费模式有推模式和拉模式.推模式是由拉模式封装组成. 集群模式下,一个消费队列同一时间只能被一个消费者消费,而一个消费者可以同时消费多个队列.RocketMQ只支持一个队列上的局部消息顺序,不保证全局消息顺序. 在 DefaultMQPushConsumer 中的 start 方法中,通过调用 MQClientManager 的 getOrCreateMQClientInstance 方法实例化关键类 MQClientInstance ,在 MQClientInstance 中实例化了 PullMessageService 和 RebalanceService 两个线程类. MQClientInstance 的start方法中会启动 PullMessageService 和 RebalanceService 线程. RebalanceService 线程默认每 20s 执行一次,调用 MQClientInstance 的 doRebalance 方法遍历当前客户端所有消费者组的所有消费者,再通过 RebalanceImpl 的 doRebalance 方法遍历消费者对应的所有Topic,然后通过 rebalanceByTopic 对集群模式和广播模式进行处理,然后通过 updateProcessQueueTableInRebalance 方法遍历Topic下所有的队列将未消费的消息封装成 PullRequest列表最终通过 PullMessageService 的 executePullRequestImmediately 方法将 PullRequest 任务添加阻塞队列中. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149public class RebalanceService extends ServiceThread &#123; public void run() &#123; log.info(this.getServiceName() + &quot; service started&quot;); while (!this.isStopped()) &#123; this.waitForRunning(waitInterval); this.mqClientFactory.doRebalance(); &#125; log.info(this.getServiceName() + &quot; service end&quot;); &#125;&#125;public class MQClientInstance &#123; public void doRebalance() &#123; // 客户端负载均衡 针对当前消费者所属的每一个消费者组 for (Map.Entry&lt;String, MQConsumerInner&gt; entry : this.consumerTable.entrySet()) &#123; MQConsumerInner impl = entry.getValue(); if (impl != null) &#123; try &#123; impl.doRebalance(); &#125; &#125; &#125; &#125;&#125;public abstract class RebalanceImpl &#123; public void doRebalance(final boolean isOrder) &#123; Map&lt;String, SubscriptionData&gt; subTable = this.getSubscriptionInner(); if (subTable != null) &#123; for (final Map.Entry&lt;String, SubscriptionData&gt; entry : subTable.entrySet()) &#123; final String topic = entry.getKey(); try &#123; // 客户端负载：真正进行负载都是根据主题来进行的. this.rebalanceByTopic(topic, isOrder); &#125; catch (Throwable e) &#123; &#125; &#125; &#125; this.truncateMessageQueueNotMyTopic(); &#125; private void rebalanceByTopic(final String topic, final boolean isOrder) &#123; switch (messageModel) &#123; case BROADCASTING: &#123; //广播模式,不需要进行负载.每个消费者都要消费.只需要更新负载信息. Set&lt;MessageQueue&gt; mqSet = this.topicSubscribeInfoTable.get(topic); if (mqSet != null) &#123; boolean changed = this.updateProcessQueueTableInRebalance(topic, mqSet, isOrder); // 关键代码 if (changed) &#123; this.messageQueueChanged(topic, mqSet, mqSet); &#125; &#125; break; &#125; case CLUSTERING: &#123; // 客户端负载：集群模式负载方法 Set&lt;MessageQueue&gt; mqSet = this.topicSubscribeInfoTable.get(topic); //订阅的主题 List&lt;String&gt; cidAll = this.mQClientFactory.findConsumerIdList(topic, consumerGroup); //客户端ID if (mqSet != null &amp;&amp; cidAll != null) &#123; List&lt;MessageQueue&gt; mqAll = new ArrayList&lt;MessageQueue&gt;(); mqAll.addAll(mqSet); Collections.sort(mqAll); //排序后才能保证消费者负载策略相对稳定. Collections.sort(cidAll); AllocateMessageQueueStrategy strategy = this.allocateMessageQueueStrategy; //MessageQueue的负载策略,有五种实现类 List&lt;MessageQueue&gt; allocateResult = null; try &#123;//按负载策略进行分配,返回当前消费者实际订阅的MessageQueue集合. allocateResult = strategy.allocate(this.consumerGroup, this.mQClientFactory.getClientId(), mqAll, cidAll); &#125; catch (Throwable e) &#123; return; &#125; Set&lt;MessageQueue&gt; allocateResultSet = new HashSet&lt;MessageQueue&gt;(); if (allocateResult != null) &#123; allocateResultSet.addAll(allocateResult); &#125; boolean changed = this.updateProcessQueueTableInRebalance(topic, allocateResultSet, isOrder); // 关键代码 if (changed) &#123; this.messageQueueChanged(topic, mqSet, allocateResultSet); &#125; &#125; break; &#125; default: break; &#125; &#125; private boolean updateProcessQueueTableInRebalance(final String topic, final Set&lt;MessageQueue&gt; mqSet, final boolean isOrder) &#123; boolean changed = false; Iterator&lt;Entry&lt;MessageQueue, ProcessQueue&gt;&gt; it = this.processQueueTable.entrySet().iterator(); while (it.hasNext()) &#123; Entry&lt;MessageQueue, ProcessQueue&gt; next = it.next(); MessageQueue mq = next.getKey(); ProcessQueue pq = next.getValue(); if (mq.getTopic().equals(topic)) &#123; if (!mqSet.contains(mq)) &#123; pq.setDropped(true); if (this.removeUnnecessaryMessageQueue(mq, pq)) &#123; it.remove(); changed = true; &#125; &#125; else if (pq.isPullExpired()) &#123; switch (this.consumeType()) &#123; case CONSUME_ACTIVELY: break; case CONSUME_PASSIVELY: pq.setDropped(true); if (this.removeUnnecessaryMessageQueue(mq, pq)) &#123; it.remove(); changed = true; &#125; break; default: break; &#125; &#125; &#125; &#125; List&lt;PullRequest&gt; pullRequestList = new ArrayList&lt;PullRequest&gt;(); for (MessageQueue mq : mqSet) &#123; if (!this.processQueueTable.containsKey(mq)) &#123; if (isOrder &amp;&amp; !this.lock(mq)) &#123; continue; &#125; this.removeDirtyOffset(mq); ProcessQueue pq = new ProcessQueue(); long nextOffset = this.computePullFromWhere(mq); if (nextOffset &gt;= 0) &#123; ProcessQueue pre = this.processQueueTable.putIfAbsent(mq, pq); if (pre != null) &#123; &#125; else &#123; PullRequest pullRequest = new PullRequest(); pullRequest.setConsumerGroup(consumerGroup); pullRequest.setNextOffset(nextOffset); pullRequest.setMessageQueue(mq); pullRequest.setProcessQueue(pq); pullRequestList.add(pullRequest); changed = true; &#125; &#125; &#125; &#125; this.dispatchPullRequest(pullRequestList); return changed; &#125;&#125;public class RebalancePushImpl extends RebalanceImpl &#123; public void dispatchPullRequest(List&lt;PullRequest&gt; pullRequestList) &#123; for (PullRequest pullRequest : pullRequestList) &#123; this.defaultMQPushConsumerImpl.executePullRequestImmediately(pullRequest); &#125; &#125;&#125;public class DefaultMQPushConsumerImpl implements MQConsumerInner &#123; public void executePullRequestImmediately(final PullRequest pullRequest) &#123; this.mQClientFactory.getPullMessageService().executePullRequestImmediately(pullRequest); &#125;&#125; PullMessageService 线程的 run 方法中消费 PullRequest 请求,最终调用 DefaultMQPushConsumerImpl 的 pullMessage 方法,首先会对消息进行流量和消息大小限流,若不满足限流条线丢到线程池中延迟处理,定义了一个拉取消息的回调函数PullCallback ,若拉取消息失败则调用 onException 将其丢到线程池中延迟处理下次继续重试处理,若成功则调用 onSuccess 方法,在该方法中若拉取到数据后会调用 executePullRequestLater 或 executePullRequestImmediately 方法再次将拉取请求放入任务队列中,若有数据则会一直拉取直到数据被消费完则 PullStatus 会变为非 FOUND 状态.不论获取消息成功还是失败都会将请求再次放回队列,便于长轮训的方式拉取消息. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157public class PullMessageService extends ServiceThread &#123; public void run() &#123; while (!this.isStopped()) &#123; try &#123; //拉取消息的请求队列 PullRequest pullRequest = this.pullRequestQueue.take(); this.pullMessage(pullRequest); //处理请求 &#125; &#125; &#125; private void pullMessage(final PullRequest pullRequest) &#123; final MQConsumerInner consumer = this.mQClientFactory.selectConsumer(pullRequest.getConsumerGroup()); if (consumer != null) &#123; DefaultMQPushConsumerImpl impl = (DefaultMQPushConsumerImpl) consumer; impl.pullMessage(pullRequest); // 推模式的消费者最终还是会使用拉消息的方式 &#125; &#125;&#125;public class DefaultMQPushConsumerImpl implements MQConsumerInner &#123; public void pullMessage(final PullRequest pullRequest) &#123; // 拉取消息的核心流程 final ProcessQueue processQueue = pullRequest.getProcessQueue(); //获取要处理的消息：ProcessQueue if (processQueue.isDropped()) &#123; //如果队列被抛弃,直接返回 return; &#125; pullRequest.getProcessQueue().setLastPullTimestamp(System.currentTimeMillis()); //先更新时间戳 try &#123; this.makeSureStateOK(); &#125; catch (MQClientException e) &#123; this.executePullRequestLater(pullRequest, pullTimeDelayMillsWhenException); return; &#125; if (this.isPause()) &#123; //如果处理队列被挂起,延迟1S后再执行. this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_SUSPEND); return; &#125; long cachedMessageCount = processQueue.getMsgCount().get(); //获得最大待处理消息数量 long cachedMessageSizeInMiB = processQueue.getMsgSize().get() / (1024 * 1024); //获得最大待处理消息大小 if (cachedMessageCount &gt; this.defaultMQPushConsumer.getPullThresholdForQueue()) &#123; //从数量进行流控 this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL); return; &#125; if (cachedMessageSizeInMiB &gt; this.defaultMQPushConsumer.getPullThresholdSizeForQueue()) &#123; //从消息大小进行流控 this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL); return; &#125; if (!this.consumeOrderly) &#123; // 若是有序消息 if (processQueue.getMaxSpan() &gt; this.defaultMQPushConsumer.getConsumeConcurrentlyMaxSpan()) &#123; this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL); return; &#125; &#125; else &#123; if (processQueue.isLocked()) &#123; if (!pullRequest.isLockedFirst()) &#123; final long offset = this.rebalanceImpl.computePullFromWhere(pullRequest.getMessageQueue()); boolean brokerBusy = offset &lt; pullRequest.getNextOffset(); pullRequest.setLockedFirst(true); pullRequest.setNextOffset(offset); &#125; &#125; else &#123; this.executePullRequestLater(pullRequest, pullTimeDelayMillsWhenException); return; &#125; &#125; // 获取订阅信息 final SubscriptionData subscriptionData = this.rebalanceImpl.getSubscriptionInner().get(pullRequest.getMessageQueue().getTopic()); if (null == subscriptionData) &#123; this.executePullRequestLater(pullRequest, pullTimeDelayMillsWhenException); return; &#125; final long beginTimestamp = System.currentTimeMillis(); PullCallback pullCallback = new PullCallback() &#123; // 客户端默认的拉取的回调函数,在拉取到消息后会进入这个方法处理. @Override public void onSuccess(PullResult pullResult) &#123; if (pullResult != null) &#123; pullResult = DefaultMQPushConsumerImpl.this.pullAPIWrapper.processPullResult(pullRequest.getMessageQueue(), pullResult, subscriptionData); switch (pullResult.getPullStatus()) &#123; case FOUND: long prevRequestOffset = pullRequest.getNextOffset(); pullRequest.setNextOffset(pullResult.getNextBeginOffset()); long pullRT = System.currentTimeMillis() - beginTimestamp; DefaultMQPushConsumerImpl.this.getConsumerStatsManager().incPullRT(pullRequest.getConsumerGroup(), pullRequest.getMessageQueue().getTopic(), pullRT); long firstMsgOffset = Long.MAX_VALUE; if (pullResult.getMsgFoundList() == null || pullResult.getMsgFoundList().isEmpty()) &#123; DefaultMQPushConsumerImpl.this.executePullRequestImmediately(pullRequest); &#125; else &#123; firstMsgOffset = pullResult.getMsgFoundList().get(0).getQueueOffset(); DefaultMQPushConsumerImpl.this.getConsumerStatsManager().incPullTPS(pullRequest.getConsumerGroup(), pullRequest.getMessageQueue().getTopic(), pullResult.getMsgFoundList().size()); boolean dispatchToConsume = processQueue.putMessage(pullResult.getMsgFoundList()); // 消费者消息服务处理消费到的消息 DefaultMQPushConsumerImpl.this.consumeMessageService.submitConsumeRequest(pullResult.getMsgFoundList(), processQueue, pullRequest.getMessageQueue(), dispatchToConsume); if (DefaultMQPushConsumerImpl.this.defaultMQPushConsumer.getPullInterval() &gt; 0) &#123; // 退模式下任务间隔时间 DefaultMQPushConsumerImpl.this.executePullRequestLater(pullRequest, DefaultMQPushConsumerImpl.this.defaultMQPushConsumer.getPullInterval()); &#125; else &#123; DefaultMQPushConsumerImpl.this.executePullRequestImmediately(pullRequest); &#125; &#125; break; case NO_NEW_MSG: pullRequest.setNextOffset(pullResult.getNextBeginOffset()); DefaultMQPushConsumerImpl.this.correctTagsOffset(pullRequest); DefaultMQPushConsumerImpl.this.executePullRequestImmediately(pullRequest); break; case NO_MATCHED_MSG: pullRequest.setNextOffset(pullResult.getNextBeginOffset()); DefaultMQPushConsumerImpl.this.correctTagsOffset(pullRequest); DefaultMQPushConsumerImpl.this.executePullRequestImmediately(pullRequest); break; case OFFSET_ILLEGAL: pullRequest.setNextOffset(pullResult.getNextBeginOffset()); pullRequest.getProcessQueue().setDropped(true); DefaultMQPushConsumerImpl.this.executeTaskLater(new Runnable() &#123; @Override public void run() &#123; try &#123; DefaultMQPushConsumerImpl.this.offsetStore.updateOffset(pullRequest.getMessageQueue(), pullRequest.getNextOffset(), false); DefaultMQPushConsumerImpl.this.offsetStore.persist(pullRequest.getMessageQueue()); DefaultMQPushConsumerImpl.this.rebalanceImpl.removeProcessQueue(pullRequest.getMessageQueue()); &#125; &#125; &#125;, 10000); break; default: break; &#125; &#125; &#125; @Override public void onException(Throwable e) &#123; DefaultMQPushConsumerImpl.this.executePullRequestLater(pullRequest, pullTimeDelayMillsWhenException); &#125; &#125;; boolean commitOffsetEnable = false; long commitOffsetValue = 0L; if (MessageModel.CLUSTERING == this.defaultMQPushConsumer.getMessageModel()) &#123; commitOffsetValue = this.offsetStore.readOffset(pullRequest.getMessageQueue(), ReadOffsetType.READ_FROM_MEMORY); if (commitOffsetValue &gt; 0) &#123; commitOffsetEnable = true; &#125; &#125; String subExpression = null; boolean classFilter = false; SubscriptionData sd = this.rebalanceImpl.getSubscriptionInner().get(pullRequest.getMessageQueue().getTopic()); if (sd != null) &#123; if (this.defaultMQPushConsumer.isPostSubscriptionWhenPull() &amp;&amp; !sd.isClassFilterMode()) &#123; subExpression = sd.getSubString(); &#125; classFilter = sd.isClassFilterMode(); &#125; int sysFlag = PullSysFlag.buildSysFlag(commitOffsetEnable, true, subExpression != null, classFilter); try &#123;// 客户端实际与服务器交互,拉取消息的地方,拉取成功后回调PullCallback this.pullAPIWrapper.pullKernelImpl(pullRequest.getMessageQueue(), subExpression, subscriptionData.getExpressionType(), subscriptionData.getSubVersion(), pullRequest.getNextOffset(), this.defaultMQPushConsumer.getPullBatchSize(), sysFlag, commitOffsetValue, BROKER_SUSPEND_MAX_TIME_MILLIS, CONSUMER_TIMEOUT_MILLIS_WHEN_SUSPEND, CommunicationMode.ASYNC, pullCallback); &#125; catch (Exception e) &#123; this.executePullRequestLater(pullRequest, pullTimeDelayMillsWhenException); &#125; &#125;&#125; 在拉取消息成功 PullCallback回调方法中,普通消息和顺序消息分别调用 ConsumeMessageConcurrentlyService 和 ConsumeMessageOrderlyService 的 submitConsumeRequest 方法.最终通过 ConsumeRequest 线程来处理,在该线程中具体消费者的 consumeMessage 方法. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135public class ConsumeMessageConcurrentlyService implements ConsumeMessageService &#123; public void submitConsumeRequest(final List&lt;MessageExt&gt; msgs, final ProcessQueue processQueue, final MessageQueue messageQueue, final boolean dispatchToConsume) &#123; final int consumeBatchSize = this.defaultMQPushConsumer.getConsumeMessageBatchMaxSize(); if (msgs.size() &lt;= consumeBatchSize) &#123; //一次只拉取32条数据,不足32直接处理 ConsumeRequest consumeRequest = new ConsumeRequest(msgs, processQueue, messageQueue); try &#123; this.consumeExecutor.submit(consumeRequest); &#125; catch (RejectedExecutionException e) &#123; this.submitConsumeRequestLater(consumeRequest); &#125; &#125; else &#123;//超过32条,就进行分页处理. for (int total = 0; total &lt; msgs.size(); ) &#123; List&lt;MessageExt&gt; msgThis = new ArrayList&lt;MessageExt&gt;(consumeBatchSize); for (int i = 0; i &lt; consumeBatchSize; i++, total++) &#123; if (total &lt; msgs.size()) &#123; msgThis.add(msgs.get(total)); &#125; else &#123; break; &#125; &#125; ConsumeRequest consumeRequest = new ConsumeRequest(msgThis, processQueue, messageQueue); //消费请求处理线程 try &#123; this.consumeExecutor.submit(consumeRequest); &#125; catch (RejectedExecutionException e) &#123; for (; total &lt; msgs.size(); total++) &#123; msgThis.add(msgs.get(total)); &#125; this.submitConsumeRequestLater(consumeRequest); &#125; &#125; &#125; &#125;&#125;public class ConsumeMessageOrderlyService implements ConsumeMessageService &#123; public void submitConsumeRequest(final List&lt;MessageExt&gt; msgs, final ProcessQueue processQueue, final MessageQueue messageQueue, final boolean dispathToConsume) &#123; if (dispathToConsume) &#123; ConsumeRequest consumeRequest = new ConsumeRequest(processQueue, messageQueue); this.consumeExecutor.submit(consumeRequest); &#125; &#125;&#125;class ConsumeRequest implements Runnable &#123; public void run() &#123; if (this.processQueue.isDropped()) &#123; return; &#125; final Object objLock = messageQueueLock.fetchLockObject(this.messageQueue); synchronized (objLock) &#123;//通过加锁,将并发的消息顺序进行消费.消息处理的方式没什么特别. if (MessageModel.BROADCASTING.equals(ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.messageModel()) || (this.processQueue.isLocked() &amp;&amp; !this.processQueue.isLockExpired())) &#123; final long beginTime = System.currentTimeMillis(); for (boolean continueConsume = true; continueConsume; ) &#123; if (this.processQueue.isDropped()) &#123; break; &#125; if (MessageModel.CLUSTERING.equals(ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.messageModel()) &amp;&amp; !this.processQueue.isLocked()) &#123; ConsumeMessageOrderlyService.this.tryLockLaterAndReconsume(this.messageQueue, this.processQueue, 10); break; &#125; if (MessageModel.CLUSTERING.equals(ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.messageModel()) &amp;&amp; this.processQueue.isLockExpired()) &#123; ConsumeMessageOrderlyService.this.tryLockLaterAndReconsume(this.messageQueue, this.processQueue, 10); break; &#125; long interval = System.currentTimeMillis() - beginTime; if (interval &gt; MAX_TIME_CONSUME_CONTINUOUSLY) &#123; ConsumeMessageOrderlyService.this.submitConsumeRequestLater(processQueue, messageQueue, 10); break; &#125; final int consumeBatchSize = ConsumeMessageOrderlyService.this.defaultMQPushConsumer.getConsumeMessageBatchMaxSize(); List&lt;MessageExt&gt; msgs = this.processQueue.takeMessages(consumeBatchSize); defaultMQPushConsumerImpl.resetRetryAndNamespace(msgs, defaultMQPushConsumer.getConsumerGroup()); if (!msgs.isEmpty()) &#123; final ConsumeOrderlyContext context = new ConsumeOrderlyContext(this.messageQueue); ConsumeOrderlyStatus status = null; ConsumeMessageContext consumeMessageContext = null; if (ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.hasHook()) &#123; consumeMessageContext = new ConsumeMessageContext(); consumeMessageContext.setConsumerGroup(ConsumeMessageOrderlyService.this.defaultMQPushConsumer.getConsumerGroup()); consumeMessageContext.setNamespace(defaultMQPushConsumer.getNamespace()); consumeMessageContext.setMq(messageQueue); consumeMessageContext.setMsgList(msgs); consumeMessageContext.setSuccess(false); consumeMessageContext.setProps(new HashMap&lt;String, String&gt;()); // init the consume context type ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.executeHookBefore(consumeMessageContext); &#125; long beginTimestamp = System.currentTimeMillis(); ConsumeReturnType returnType = ConsumeReturnType.SUCCESS; boolean hasException = false; try &#123; this.processQueue.getLockConsume().lock(); status = messageListener.consumeMessage(Collections.unmodifiableList(msgs), context); // 调用消费者具体的消费方法 &#125; catch (Throwable e) &#123; hasException = true; &#125; finally &#123; this.processQueue.getLockConsume().unlock(); &#125; long consumeRT = System.currentTimeMillis() - beginTimestamp; if (null == status) &#123; if (hasException) &#123; returnType = ConsumeReturnType.EXCEPTION; &#125; else &#123; returnType = ConsumeReturnType.RETURNNULL; &#125; &#125; else if (consumeRT &gt;= defaultMQPushConsumer.getConsumeTimeout() * 60 * 1000) &#123; returnType = ConsumeReturnType.TIME_OUT; &#125; else if (ConsumeOrderlyStatus.SUSPEND_CURRENT_QUEUE_A_MOMENT == status) &#123; returnType = ConsumeReturnType.FAILED; &#125; else if (ConsumeOrderlyStatus.SUCCESS == status) &#123; returnType = ConsumeReturnType.SUCCESS; &#125; if (ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.hasHook()) &#123; consumeMessageContext.getProps().put(MixAll.CONSUME_CONTEXT_TYPE, returnType.name()); &#125; if (null == status) &#123; status = ConsumeOrderlyStatus.SUSPEND_CURRENT_QUEUE_A_MOMENT; &#125; if (ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.hasHook()) &#123; consumeMessageContext.setStatus(status.toString()); consumeMessageContext.setSuccess(ConsumeOrderlyStatus.SUCCESS == status || ConsumeOrderlyStatus.COMMIT == status); ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.executeHookAfter(consumeMessageContext); &#125; ConsumeMessageOrderlyService.this.getConsumerStatsManager().incConsumeRT(ConsumeMessageOrderlyService.this.consumerGroup, messageQueue.getTopic(), consumeRT); continueConsume = ConsumeMessageOrderlyService.this.processConsumeResult(msgs, status, context, this); &#125; else &#123; continueConsume = false; &#125; &#125; &#125; else &#123; if (this.processQueue.isDropped()) &#123; return; &#125; ConsumeMessageOrderlyService.this.tryLockLaterAndReconsume(this.messageQueue, this.processQueue, 100); &#125; &#125; &#125;&#125; 消息的拉取最终调用的是 PullAPIWrapper 的 pullKernelImpl 方法,拉取模式固定为 ASYNC ,最终调用 MQClientAPIImpl 的 pullMessageAsync 方法想 Broker 发送 RequestCode.PULL_MESSAGE 命令拉取消息,在 operationComplete 方法中完成 PullCallback回调. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788public class PullAPIWrapper &#123; public PullResult pullKernelImpl(final MessageQueue mq, final String subExpression, final String expressionType, final long subVersion, final long offset, final int maxNums, final int sysFlag, final long commitOffset, final long brokerSuspendMaxTimeMillis, final long timeoutMillis, final CommunicationMode communicationMode, final PullCallback pullCallback) throws MQClientException, RemotingException, MQBrokerException, InterruptedException &#123; //找到Broker FindBrokerResult findBrokerResult = this.mQClientFactory.findBrokerAddressInSubscribe(mq.getBrokerName(), this.recalculatePullFromWhichNode(mq), false); if (null == findBrokerResult) &#123; this.mQClientFactory.updateTopicRouteInfoFromNameServer(mq.getTopic()); findBrokerResult = this.mQClientFactory.findBrokerAddressInSubscribe(mq.getBrokerName(), this.recalculatePullFromWhichNode(mq), false); &#125; if (findBrokerResult != null) &#123; &#123;// check version 版本检查 if (!ExpressionType.isTagType(expressionType) &amp;&amp; findBrokerResult.getBrokerVersion() &lt; MQVersion.Version.V4_1_0_SNAPSHOT.ordinal()) &#123; throw new MQClientException(&quot;The broker[&quot; + mq.getBrokerName() + &quot;, &quot; + findBrokerResult.getBrokerVersion() + &quot;] does not upgrade to support for filter message by &quot; + expressionType, null); &#125; &#125; int sysFlagInner = sysFlag; if (findBrokerResult.isSlave()) &#123; sysFlagInner = PullSysFlag.clearCommitOffsetFlag(sysFlagInner); &#125; //构建请求 PullMessageRequestHeader requestHeader = new PullMessageRequestHeader(); requestHeader.setConsumerGroup(this.consumerGroup); requestHeader.setTopic(mq.getTopic()); requestHeader.setQueueId(mq.getQueueId()); requestHeader.setQueueOffset(offset); requestHeader.setMaxMsgNums(maxNums); requestHeader.setSysFlag(sysFlagInner); requestHeader.setCommitOffset(commitOffset); requestHeader.setSuspendTimeoutMillis(brokerSuspendMaxTimeMillis); requestHeader.setSubscription(subExpression); requestHeader.setSubVersion(subVersion); requestHeader.setExpressionType(expressionType); String brokerAddr = findBrokerResult.getBrokerAddr(); if (PullSysFlag.hasClassFilterFlag(sysFlagInner)) &#123; brokerAddr = computPullFromWhichFilterServer(mq.getTopic(), brokerAddr); &#125; //拉取消息 PullResult pullResult = this.mQClientFactory.getMQClientAPIImpl().pullMessage(brokerAddr, requestHeader, timeoutMillis, communicationMode, pullCallback); return pullResult; &#125; throw new MQClientException(&quot;The broker[&quot; + mq.getBrokerName() + &quot;] not exist&quot;, null); &#125;&#125;public class MQClientAPIImpl &#123; public PullResult pullMessage(final String addr, final PullMessageRequestHeader requestHeader, final long timeoutMillis, final CommunicationMode communicationMode, final PullCallback pullCallback) throws RemotingException, MQBrokerException, InterruptedException &#123; RemotingCommand request = RemotingCommand.createRequestCommand(RequestCode.PULL_MESSAGE, requestHeader); //几种拉取方式 switch (communicationMode) &#123; case ONEWAY: assert false; return null; case ASYNC: this.pullMessageAsync(addr, request, timeoutMillis, pullCallback); return null; case SYNC: return this.pullMessageSync(addr, request, timeoutMillis); default: assert false; break; &#125; return null; &#125; private void pullMessageAsync(final String addr, final RemotingCommand request, final long timeoutMillis, final PullCallback pullCallback) throws RemotingException, InterruptedException &#123; this.remotingClient.invokeAsync(addr, request, timeoutMillis, new InvokeCallback() &#123; //异步拉取 @Override public void operationComplete(ResponseFuture responseFuture) &#123; RemotingCommand response = responseFuture.getResponseCommand(); //处理拉取消息的结果 if (response != null) &#123; //有响应 try &#123; PullResult pullResult = MQClientAPIImpl.this.processPullResponse(response); assert pullResult != null; pullCallback.onSuccess(pullResult); &#125; catch (Exception e) &#123; pullCallback.onException(e); &#125; &#125; else &#123;//没响应 if (!responseFuture.isSendRequestOK()) &#123; pullCallback.onException(new MQClientException(&quot;send request failed to &quot; + addr + &quot;. Request: &quot; + request, responseFuture.getCause())); &#125; else if (responseFuture.isTimeout()) &#123; pullCallback.onException(new MQClientException(&quot;wait response from &quot; + addr + &quot; timeout :&quot; + responseFuture.getTimeoutMillis() + &quot;ms&quot; + &quot;. Request: &quot; + request, responseFuture.getCause())); &#125; else &#123; pullCallback.onException(new MQClientException(&quot;unknown reason. addr: &quot; + addr + &quot;, timeoutMillis: &quot; + timeoutMillis + &quot;. Request: &quot; + request, responseFuture.getCause())); &#125; &#125; &#125; &#125;); &#125;&#125; 在Broker通过 PullMessageProcessor 方法的 processRequest 方法处理 RequestCode.PULL_MESSAGE 请求.首先端构建消息过滤器,然后在 DefaultMessageStore 的 getMessage 查询消息中调用 MessageFilter 的 isMatchedByConsumeQueue 方法.若 ResponseCode.PULL_NOT_FOUND 未拉取到数据,则再创建一个拉取请求且通过 PullRequestHoldService 的 suspendPullRequest 将该请求放入 ManyPullRequest 请求拉取队列,从而实现长连接. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109private RemotingCommand processRequest(final Channel channel, RemotingCommand request, boolean brokerAllowSuspend) throws RemotingCommandException &#123; RemotingCommand response = RemotingCommand.createResponseCommand(PullMessageResponseHeader.class); final PullMessageResponseHeader responseHeader = (PullMessageResponseHeader) response.readCustomHeader(); final PullMessageRequestHeader requestHeader = (PullMessageRequestHeader) request.decodeCommandCustomHeader(PullMessageRequestHeader.class); response.setOpaque(request.getOpaque()); SubscriptionGroupConfig subscriptionGroupConfig = this.brokerController.getSubscriptionGroupManager().findSubscriptionGroupConfig(requestHeader.getConsumerGroup()); final boolean hasSuspendFlag = PullSysFlag.hasSuspendFlag(requestHeader.getSysFlag()); final boolean hasCommitOffsetFlag = PullSysFlag.hasCommitOffsetFlag(requestHeader.getSysFlag()); final boolean hasSubscriptionFlag = PullSysFlag.hasSubscriptionFlag(requestHeader.getSysFlag()); final long suspendTimeoutMillisLong = hasSuspendFlag ? requestHeader.getSuspendTimeoutMillis() : 0; TopicConfig topicConfig = this.brokerController.getTopicConfigManager().selectTopicConfig(requestHeader.getTopic()); SubscriptionData subscriptionData = null; ConsumerFilterData consumerFilterData = null; if (hasSubscriptionFlag) &#123; try &#123; subscriptionData = FilterAPI.build(requestHeader.getTopic(), requestHeader.getSubscription(), requestHeader.getExpressionType()); if (!ExpressionType.isTagType(subscriptionData.getExpressionType())) &#123; consumerFilterData = ConsumerFilterManager.build(requestHeader.getTopic(), requestHeader.getConsumerGroup(), requestHeader.getSubscription(), requestHeader.getExpressionType(), requestHeader.getSubVersion()); assert consumerFilterData != null; &#125; &#125; &#125; else &#123; ConsumerGroupInfo consumerGroupInfo = this.brokerController.getConsumerManager().getConsumerGroupInfo(requestHeader.getConsumerGroup()); subscriptionData = consumerGroupInfo.findSubscriptionData(requestHeader.getTopic()); if (!ExpressionType.isTagType(subscriptionData.getExpressionType())) &#123; consumerFilterData = this.brokerController.getConsumerFilterManager().get(requestHeader.getTopic(), requestHeader.getConsumerGroup()); &#125; &#125; //在Broker端构建消息过滤器 MessageFilter messageFilter; if (this.brokerController.getBrokerConfig().isFilterSupportRetry()) &#123; messageFilter = new ExpressionForRetryMessageFilter(subscriptionData, consumerFilterData, this.brokerController.getConsumerFilterManager()); &#125; else &#123; messageFilter = new ExpressionMessageFilter(subscriptionData, consumerFilterData, this.brokerController.getConsumerFilterManager()); &#125; // 获取消息 final GetMessageResult getMessageResult = this.brokerController.getMessageStore().getMessage(requestHeader.getConsumerGroup(), requestHeader.getTopic(), requestHeader.getQueueId(), requestHeader.getQueueOffset(), requestHeader.getMaxMsgNums(), messageFilter); if (getMessageResult != null) &#123; response.setRemark(getMessageResult.getStatus().name()); responseHeader.setNextBeginOffset(getMessageResult.getNextBeginOffset()); responseHeader.setMinOffset(getMessageResult.getMinOffset()); responseHeader.setMaxOffset(getMessageResult.getMaxOffset()); if (getMessageResult.isSuggestPullingFromSlave()) &#123; responseHeader.setSuggestWhichBrokerId(subscriptionGroupConfig.getWhichBrokerWhenConsumeSlowly()); &#125; else &#123; responseHeader.setSuggestWhichBrokerId(MixAll.MASTER_ID); &#125; //消息拉取结果 switch (getMessageResult.getStatus()) &#123; case FOUND: response.setCode(ResponseCode.SUCCESS); break; case MESSAGE_WAS_REMOVING: response.setCode(ResponseCode.PULL_RETRY_IMMEDIATELY); break; case NO_MATCHED_LOGIC_QUEUE: case NO_MESSAGE_IN_QUEUE: break; case NO_MATCHED_MESSAGE: response.setCode(ResponseCode.PULL_RETRY_IMMEDIATELY); break; case OFFSET_FOUND_NULL: response.setCode(ResponseCode.PULL_NOT_FOUND); break; case OFFSET_OVERFLOW_BADLY: response.setCode(ResponseCode.PULL_OFFSET_MOVED); break; case OFFSET_OVERFLOW_ONE: response.setCode(ResponseCode.PULL_NOT_FOUND); break; case OFFSET_TOO_SMALL: response.setCode(ResponseCode.PULL_OFFSET_MOVED); break; default: assert false; break; &#125; switch (response.getCode()) &#123; case ResponseCode.SUCCESS: this.brokerController.getBrokerStatsManager().incGroupGetNums(requestHeader.getConsumerGroup(), requestHeader.getTopic(), getMessageResult.getMessageCount()); this.brokerController.getBrokerStatsManager().incGroupGetSize(requestHeader.getConsumerGroup(), requestHeader.getTopic(), getMessageResult.getBufferTotalSize()); this.brokerController.getBrokerStatsManager().incBrokerGetNums(getMessageResult.getMessageCount()); break; case ResponseCode.PULL_NOT_FOUND: if (brokerAllowSuspend &amp;&amp; hasSuspendFlag) &#123; long pollingTimeMills = suspendTimeoutMillisLong; if (!this.brokerController.getBrokerConfig().isLongPollingEnable()) &#123;// 消息长轮询 pollingTimeMills = this.brokerController.getBrokerConfig().getShortPollingTimeMills(); &#125; String topic = requestHeader.getTopic(); long offset = requestHeader.getQueueOffset(); int queueId = requestHeader.getQueueId(); //没有拉取到消息,就再创建一个拉取请求 PullRequest pullRequest = new PullRequest(request, channel, pollingTimeMills, this.brokerController.getMessageStore().now(), offset, subscriptionData, messageFilter); //将请求放入ManyRequestPull请求队列,为了配合长连接处理 this.brokerController.getPullRequestHoldService().suspendPullRequest(topic, queueId, pullRequest); response = null; break; &#125; &#125; &#125; boolean storeOffsetEnable = brokerAllowSuspend; storeOffsetEnable = storeOffsetEnable &amp;&amp; hasCommitOffsetFlag; storeOffsetEnable = storeOffsetEnable &amp;&amp; this.brokerController.getMessageStoreConfig().getBrokerRole() != BrokerRole.SLAVE; if (storeOffsetEnable) &#123; this.brokerController.getConsumerOffsetManager().commitOffset(RemotingHelper.parseChannelRemoteAddr(channel), requestHeader.getConsumerGroup(), requestHeader.getTopic(), requestHeader.getQueueId(), requestHeader.getCommitOffset()); &#125; return response;&#125; 长轮询对于消息的发送基本能达到实时的效果,是通过 PullRequestHoldService 类中长轮训来实现的,该类是一个线程类,在 Broker 中的 BrokerController 中被实例化和启动.客户端拉取数时未拉取到数据就会将请求通过 suspendPullRequest 方法放入 pullRequestTable 中.在run方法中一直循环若没有消息就 waitForRunning 方法等待 5s ,若有数据则会被提前唤醒.然后通过 checkHoldRequest 方法检查请求对象,若有数据则将数据返回给客户端. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117public class PullRequestHoldService extends ServiceThread &#123; private ConcurrentMap&lt;String, ManyPullRequest&gt; pullRequestTable = new ConcurrentHashMap&lt;String, ManyPullRequest&gt;(1024); public void suspendPullRequest(final String topic, final int queueId, final PullRequest pullRequest) &#123; String key = this.buildKey(topic, queueId); ManyPullRequest mpr = this.pullRequestTable.get(key); if (null == mpr) &#123; mpr = new ManyPullRequest(); ManyPullRequest prev = this.pullRequestTable.putIfAbsent(key, mpr); if (prev != null) &#123; mpr = prev; &#125; &#125; mpr.addPullRequest(pullRequest); &#125; public void run() &#123; // 处理ManyPullRequest线程 while (!this.isStopped()) &#123; try &#123;// 如果开启了长轮询,等待5秒后再去查 if (this.brokerController.getBrokerConfig().isLongPollingEnable()) &#123; this.waitForRunning(5 * 1000); &#125; else &#123;//没有开启长轮询,等待1秒后再去查. this.waitForRunning(this.brokerController.getBrokerConfig().getShortPollingTimeMills()); &#125; long beginLockTimestamp = this.systemClock.now(); this.checkHoldRequest(); //检查请求对象 long costTime = this.systemClock.now() - beginLockTimestamp; &#125; catch (Throwable e) &#123; &#125; &#125; &#125; private void checkHoldRequest() &#123; for (String key : this.pullRequestTable.keySet()) &#123; String[] kArray = key.split(TOPIC_QUEUEID_SEPARATOR); if (2 == kArray.length) &#123; String topic = kArray[0]; int queueId = Integer.parseInt(kArray[1]); //从CommitLog中检查是否有新的消息. final long offset = this.brokerController.getMessageStore().getMaxOffsetInQueue(topic, queueId); try &#123;//通知消息到达 this.notifyMessageArriving(topic, queueId, offset); &#125; catch (Throwable e) &#123; &#125; &#125; &#125; &#125; public void notifyMessageArriving(final String topic, final int queueId, final long maxOffset) &#123; notifyMessageArriving(topic, queueId, maxOffset, null, 0, null, null); &#125; public void notifyMessageArriving(final String topic, final int queueId, final long maxOffset, final Long tagsCode, long msgStoreTime, byte[] filterBitMap, Map&lt;String, String&gt; properties) &#123; String key = this.buildKey(topic, queueId); //CommitLog消息到达通知 ManyPullRequest mpr = this.pullRequestTable.get(key); if (mpr != null) &#123; List&lt;PullRequest&gt; requestList = mpr.cloneListAndClear(); if (requestList != null) &#123; List&lt;PullRequest&gt; replayList = new ArrayList&lt;PullRequest&gt;(); for (PullRequest request : requestList) &#123; long newestOffset = maxOffset; if (newestOffset &lt;= request.getPullFromThisOffset()) &#123; newestOffset = this.brokerController.getMessageStore().getMaxOffsetInQueue(topic, queueId); &#125; if (newestOffset &gt; request.getPullFromThisOffset()) &#123; //判断是否有新的消息 //检查新的消息是否是ConsumeQueue感兴趣的消息 boolean match = request.getMessageFilter().isMatchedByConsumeQueue(tagsCode, new ConsumeQueueExt.CqExtUnit(tagsCode, msgStoreTime, filterBitMap)); if (match &amp;&amp; properties != null) &#123; match = request.getMessageFilter().isMatchedByCommitLog(null, properties); &#125; if (match) &#123; //如果是感兴趣的消息,就等待线程唤醒后执行消息推送. try &#123; this.brokerController.getPullMessageProcessor().executeRequestWhenWakeup(request.getClientChannel(), request.getRequestCommand()); &#125; catch (Throwable e) &#123; &#125; continue; &#125; &#125; if (System.currentTimeMillis() &gt;= (request.getSuspendTimestamp() + request.getTimeoutMillis())) &#123; try &#123; //请求超时后也给客户端响应. this.brokerController.getPullMessageProcessor().executeRequestWhenWakeup(request.getClientChannel(), request.getRequestCommand()); &#125; catch (Throwable e) &#123; &#125; continue; &#125; replayList.add(request); &#125; if (!replayList.isEmpty()) &#123; mpr.addPullRequest(replayList); &#125; &#125; &#125; &#125;&#125;public class PullMessageProcessor extends AsyncNettyRequestProcessor implements NettyRequestProcessor &#123; public void executeRequestWhenWakeup(final Channel channel, final RemotingCommand request) throws RemotingCommandException &#123; Runnable run = new Runnable() &#123; @Override public void run() &#123; try &#123; final RemotingCommand response = PullMessageProcessor.this.processRequest(channel, request, false); if (response != null) &#123; response.setOpaque(request.getOpaque()); response.markResponseType(); try &#123; channel.writeAndFlush(response).addListener(new ChannelFutureListener() &#123; @Override public void operationComplete(ChannelFuture future) throws Exception &#123; if (!future.isSuccess()) &#123; &#125; &#125; &#125;); &#125; catch (Throwable e) &#123; &#125; &#125; &#125; catch (RemotingCommandException e1) &#123; &#125; &#125; &#125;; this.brokerController.getPullMessageExecutor().submit(new RequestTask(run, channel, request)); &#125;&#125; 还有一种方式在 DefaultMessageStore 的 ReputMessageService 线程类的 run 方法中执行分发请求时,执行完分发请求后通过调用 NotifyMessageArrivingListener 的 arriving 方法从而调用 PullRequestHoldService 的 notifyMessageArriving 方法进行一起请求线程的检查从而通知到客户端. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667class ReputMessageService extends ServiceThread &#123; @Override public void run() &#123; while (!this.isStopped()) &#123; try &#123; // 每隔1毫秒,往ConsumeQueue和IndexFile中转发一次CommitLog写入的消息 Thread.sleep(1); this.doReput(); &#125; catch (Exception e) &#123; &#125; &#125; &#125; private void doReput() &#123; if (this.reputFromOffset &lt; DefaultMessageStore.this.commitLog.getMinOffset()) &#123; log.warn(&quot;The reputFromOffset=&#123;&#125; is smaller than minPyOffset=&#123;&#125;, this usually indicate that the dispatch behind too much and the commitlog has expired.&quot;, this.reputFromOffset, DefaultMessageStore.this.commitLog.getMinOffset()); this.reputFromOffset = DefaultMessageStore.this.commitLog.getMinOffset(); &#125; for (boolean doNext = true; this.isCommitLogAvailable() &amp;&amp; doNext; ) &#123; if (DefaultMessageStore.this.getMessageStoreConfig().isDuplicationEnable() &amp;&amp; this.reputFromOffset &gt;= DefaultMessageStore.this.getConfirmOffset()) &#123; break; &#125; SelectMappedBufferResult result = DefaultMessageStore.this.commitLog.getData(reputFromOffset); // 获取CommitLog中的消息 if (result != null) &#123; try &#123; this.reputFromOffset = result.getStartOffset(); for (int readSize = 0; readSize &lt; result.getSize() &amp;&amp; doNext; ) &#123; //从CommitLog中获取一个DispatchRequest,拿到一份需要进行转发的消息,也就是从commitlog中读取的. DispatchRequest dispatchRequest = DefaultMessageStore.this.commitLog.checkMessageAndReturnSize(result.getByteBuffer(), false, false); int size = dispatchRequest.getBufferSize() == -1 ? dispatchRequest.getMsgSize() : dispatchRequest.getBufferSize(); if (dispatchRequest.isSuccess()) &#123; if (size &gt; 0) &#123; DefaultMessageStore.this.doDispatch(dispatchRequest); //分发CommitLog写入消息 // 长轮询： 如果有消息到了主节点,并且开启了长轮询. if (BrokerRole.SLAVE != DefaultMessageStore.this.getMessageStoreConfig().getBrokerRole() &amp;&amp; DefaultMessageStore.this.brokerConfig.isLongPollingEnable()) &#123; //唤醒NotifyMessageArrivingListener的arriving方法,进行一次请求线程的检查 DefaultMessageStore.this.messageArrivingListener.arriving(dispatchRequest.getTopic(), dispatchRequest.getQueueId(), dispatchRequest.getConsumeQueueOffset() + 1, dispatchRequest.getTagsCode(), dispatchRequest.getStoreTimestamp(), dispatchRequest.getBitMap(), dispatchRequest.getPropertiesMap()); &#125; this.reputFromOffset += size; readSize += size; if (DefaultMessageStore.this.getMessageStoreConfig().getBrokerRole() == BrokerRole.SLAVE) &#123; // 从节点 DefaultMessageStore.this.storeStatsService.getSinglePutMessageTopicTimesTotal(dispatchRequest.getTopic()).incrementAndGet(); DefaultMessageStore.this.storeStatsService.getSinglePutMessageTopicSizeTotal(dispatchRequest.getTopic()).addAndGet(dispatchRequest.getMsgSize()); &#125; &#125; else if (size == 0) &#123; this.reputFromOffset = DefaultMessageStore.this.commitLog.rollNextFile(this.reputFromOffset); readSize = result.getSize(); &#125; &#125; else if (!dispatchRequest.isSuccess()) &#123; if (size &gt; 0) &#123; this.reputFromOffset += size; &#125; else &#123; doNext = false; if (DefaultMessageStore.this.getMessageStoreConfig().isEnableDLegerCommitLog() || DefaultMessageStore.this.brokerConfig.getBrokerId() == MixAll.MASTER_ID) &#123; this.reputFromOffset += result.getSize() - readSize; &#125; &#125; &#125; &#125; &#125; finally &#123; result.release(); &#125; &#125; else &#123; doNext = false; &#125; &#125; &#125;&#125; 集群模式下消费者策略Consumer也是以 MessageQueue 为单位来进行负载均衡,分为集群模式和广播模式.广播模式下每条消息都会投递给订阅了Topic的所有消费者实例,在Consumer分配Queue时,所有Consumer都分到所有的Queue.集群消费模式每条消息只需要投递到订阅该Topic的Consumer Group下的一个实例,RocketMQ采用主动拉取方式拉取并消费消息,在拉取时需明确指定拉取哪一条MessageQueue . 每当实例的数量有变更,都会触发一次所有实例的负载均衡,这时会按照 Queue的数量和实例的数量平均分配Queue给每个实例.每次分配时都会将 MessageQueue 和消费者ID进行排序,再用不同的分配算法进行分配.内置的分配的算法共有六种,分别对应 AllocateMessageQueueStrategy下的六种实现类,可在Consumer中直接指定.默认情况下使用的是最简单的平均分配策略. AllocateMachineRoomNearby ：将同机房的Consumer和Broker优先分配在一起.该策略可通过一个 machineRoomResolver 对象来定制Consumer和Broker的机房解析规则.还需要引入另外一个分配策略来对同机房的Broker和Consumer进行分配.一般用平均分配策略或轮询分配策略. AllocateMessageQueueAveragely ：平均分配,将所有MessageQueue平均分给每一个消费者 AllocateMessageQueueAveragelyByCircle ： 轮询分配,轮流的给一个消费者分配一个MessageQueue. AllocateMessageQueueByConfig ： 直接指定一个messageQueue列表,类似于广播模式,直接指定所有队列. AllocateMessageQueueByMachineRoom ：按逻辑机房的概念进行分配.对BrokerName和ConsumerIdc有定制化的配置. AllocateMessageQueueConsistentHash ：一致性哈希策略只需要指定一个虚拟节点数,用一个哈希环算法,虚拟节点是为了让Hash数据在环上分布更为均匀. 对于消费者策略可以通过 DefaultMQPushConsumer 构造方法设置,默认是使用 AllocateMessageQueueAveragely平均分配策略.且该负载均衡策略在 RebalanceImpl 的 rebalanceByTopic 方法中被调用. 123456789101112131415161718192021222324252627public class AllocateMessageQueueAveragely implements AllocateMessageQueueStrategy &#123; public List&lt;MessageQueue&gt; allocate(String consumerGroup, String currentCID, List&lt;MessageQueue&gt; mqAll, List&lt;String&gt; cidAll) &#123; if (currentCID == null || currentCID.length() &lt; 1) &#123; throw new IllegalArgumentException(&quot;currentCID is empty&quot;); &#125; if (mqAll == null || mqAll.isEmpty()) &#123; throw new IllegalArgumentException(&quot;mqAll is null or mqAll empty&quot;); &#125; if (cidAll == null || cidAll.isEmpty()) &#123; throw new IllegalArgumentException(&quot;cidAll is null or cidAll empty&quot;); &#125; List&lt;MessageQueue&gt; result = new ArrayList&lt;MessageQueue&gt;(); if (!cidAll.contains(currentCID)) &#123; log.info(&quot;[BUG] ConsumerGroup: &#123;&#125; The consumerId: &#123;&#125; not in cidAll: &#123;&#125;&quot;, consumerGroup, currentCID, cidAll); return result; &#125; int index = cidAll.indexOf(currentCID); int mod = mqAll.size() % cidAll.size(); int averageSize = mqAll.size() &lt;= cidAll.size() ? 1 : (mod &gt; 0 &amp;&amp; index &lt; mod ? mqAll.size() / cidAll.size() + 1 : mqAll.size() / cidAll.size()); int startIndex = (mod &gt; 0 &amp;&amp; index &lt; mod) ? index * averageSize : index * averageSize + mod; int range = Math.min(averageSize, mqAll.size() - startIndex); for (int i = 0; i &lt; range; i++) &#123; result.add(mqAll.get((startIndex + i) % mqAll.size())); &#125; return result; &#125;&#125; 顺序消息12345678910111213141516171819DefaultMQProducer producer = new DefaultMQProducer(&quot;please_rename_unique_group_name&quot;);producer.setNamesrvAddr(&quot;localhost:9876&quot;);producer.start();for (int i = 0; i &lt; 10; i++) &#123; int orderId = i; for (int j = 0; j &lt;= 5; j++) &#123; Message msg = new Message(&quot;OrderTopicTest&quot;, &quot;order_&quot; + orderId, &quot;KEY&quot; + orderId, (&quot;order_&quot; + orderId + &quot; step &quot; + j).getBytes(RemotingHelper.DEFAULT_CHARSET)); SendResult sendResult = producer.send(msg, new MessageQueueSelector() &#123; @Override public MessageQueue select(List&lt;MessageQueue&gt; mqs, Message msg, Object arg) &#123; Integer id = (Integer) arg; // 实际就是传入的orderId int index = id % mqs.size(); return mqs.get(index); &#125; &#125;, orderId); System.out.printf(&quot;%s%n&quot;, sendResult); &#125;&#125;producer.shutdown(); 顺序消息,对于生产者发送消息需要将消息发送到同一个 MessageQueue 中,可通过 MessageQueueSelector ,对于需要保持顺序的消息传入同一个业务参数orderId,通过orderId对消息队列的取模得到一个固定的 MessageQueue ,在发送消息时就能将数据发送到同一个消息队列中了.但不能100%保证消息的顺序,若发生宕机可能导致发送到不同的 MessageQueue 中. 12345678910111213141516171819202122232425262728293031323334353637public class DefaultMQProducer extends ClientConfig implements MQProducer &#123; public SendResult send(Message msg, MessageQueueSelector selector, Object arg) throws MQClientException, RemotingException, MQBrokerException, InterruptedException &#123; msg.setTopic(withNamespace(msg.getTopic())); return this.defaultMQProducerImpl.send(msg, selector, arg); &#125; private SendResult sendSelectImpl(Message msg, MessageQueueSelector selector, Object arg, final CommunicationMode communicationMode, final SendCallback sendCallback, final long timeout) throws MQClientException, RemotingException, MQBrokerException, InterruptedException &#123; long beginStartTime = System.currentTimeMillis(); this.makeSureStateOK(); Validators.checkMessage(msg, this.defaultMQProducer); TopicPublishInfo topicPublishInfo = this.tryToFindTopicPublishInfo(msg.getTopic()); if (topicPublishInfo != null &amp;&amp; topicPublishInfo.ok()) &#123; MessageQueue mq = null; try &#123; List&lt;MessageQueue&gt; messageQueueList = mQClientFactory.getMQAdminImpl().parsePublishMessageQueues(topicPublishInfo.getMessageQueueList()); Message userMessage = MessageAccessor.cloneMessage(msg); String userTopic = NamespaceUtil.withoutNamespace(userMessage.getTopic(), mQClientFactory.getClientConfig().getNamespace()); userMessage.setTopic(userTopic); // 这里回调上面示例中MessageQueueSelector的select方法,这里的arg就是传入的orderId mq = mQClientFactory.getClientConfig().queueWithNamespace(selector.select(messageQueueList, userMessage, arg)); &#125; catch (Throwable e) &#123; throw new MQClientException(&quot;select message queue throwed exception.&quot;, e); &#125; long costTime = System.currentTimeMillis() - beginStartTime; if (timeout &lt; costTime) &#123; throw new RemotingTooMuchRequestException(&quot;sendSelectImpl call timeout&quot;); &#125; if (mq != null) &#123; return this.sendKernelImpl(msg, mq, communicationMode, sendCallback, null, timeout - costTime); &#125; else &#123; throw new MQClientException(&quot;select message queue return null.&quot;, null); &#125; &#125; validateNameServerSetting(); throw new MQClientException(&quot;No route info for this topic, &quot; + msg.getTopic(), null); &#125;&#125; 对于每个消费端在创建 DefaultMQPushConsumer 时指定 consumerGroup ,在 DefaultMQPushConsumer 的start方法中调用 DefaultMQPushConsumerImpl 的 start 方法从而将 consumerGroup 设置到 RebalancePushImpl 中.且通过 registerMessageListener 方法设置的 MessageListenerOrderly 会被赋值给 DefaultMQPushConsumerImpl 的 messageListenerInner ,在DefaultMQPushConsumerImpl的start方法中判断messageListenerInner类型最终调用 ConsumeMessageOrderlyService 的 start 方法启动异步线程. 1234567891011121314DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;please_rename_unique_group_name_3&quot;);consumer.setNamesrvAddr(&quot;localhost:9876&quot;);consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_LAST_OFFSET);consumer.subscribe(&quot;OrderTopicTest&quot;, &quot;*&quot;);consumer.registerMessageListener(new MessageListenerOrderly() &#123; @Override public ConsumeOrderlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeOrderlyContext context) &#123; context.setAutoCommit(true); for (MessageExt msg : msgs) &#123; System.out.println(&quot;收到消息内容 &quot; + new String(msg.getBody())); &#125; return ConsumeOrderlyStatus.SUCCESS; &#125;&#125;); 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100public class DefaultMQPushConsumer extends ClientConfig implements MQPushConsumer &#123; private String consumerGroup; public DefaultMQPushConsumer(final String consumerGroup) &#123; this(null, consumerGroup, null, new AllocateMessageQueueAveragely()); &#125; public DefaultMQPushConsumer(final String namespace, final String consumerGroup, RPCHook rpcHook, AllocateMessageQueueStrategy allocateMessageQueueStrategy) &#123; this.consumerGroup = consumerGroup; this.namespace = namespace; this.allocateMessageQueueStrategy = allocateMessageQueueStrategy; defaultMQPushConsumerImpl = new DefaultMQPushConsumerImpl(this, rpcHook); &#125; public void registerMessageListener(MessageListenerOrderly messageListener) &#123; this.messageListener = messageListener; this.defaultMQPushConsumerImpl.registerMessageListener(messageListener); &#125; public void start() throws MQClientException &#123; setConsumerGroup(NamespaceUtil.wrapNamespace(this.getNamespace(), this.consumerGroup)); this.defaultMQPushConsumerImpl.start(); if (null != traceDispatcher) &#123; try &#123; traceDispatcher.start(this.getNamesrvAddr(), this.getAccessChannel()); &#125; catch (MQClientException e) &#123; &#125; &#125; &#125;&#125;public class DefaultMQPushConsumerImpl implements MQConsumerInner &#123; public void registerMessageListener(MessageListener messageListener) &#123; this.messageListenerInner = messageListener; &#125; public MessageListener getMessageListenerInner() &#123; return messageListenerInner; &#125; public synchronized void start() throws MQClientException &#123; switch (this.serviceState) &#123; case CREATE_JUST: this.serviceState = ServiceState.START_FAILED; this.checkConfig(); // 检查配置 this.copySubscription(); if (this.defaultMQPushConsumer.getMessageModel() == MessageModel.CLUSTERING) &#123; this.defaultMQPushConsumer.changeInstanceNameToPID(); &#125; //K2 客户端创建工厂,这个是核心对象 this.mQClientFactory = MQClientManager.getInstance().getOrCreateMQClientInstance(this.defaultMQPushConsumer, this.rpcHook); this.rebalanceImpl.setConsumerGroup(this.defaultMQPushConsumer.getConsumerGroup()); this.rebalanceImpl.setMessageModel(this.defaultMQPushConsumer.getMessageModel()); // 集群模式下消费者策略 this.rebalanceImpl.setAllocateMessageQueueStrategy(this.defaultMQPushConsumer.getAllocateMessageQueueStrategy()); this.rebalanceImpl.setmQClientFactory(this.mQClientFactory); this.pullAPIWrapper = new PullAPIWrapper(mQClientFactory, this.defaultMQPushConsumer.getConsumerGroup(), isUnitMode()); this.pullAPIWrapper.registerFilterMessageHook(filterMessageHookList); if (this.defaultMQPushConsumer.getOffsetStore() != null) &#123; this.offsetStore = this.defaultMQPushConsumer.getOffsetStore(); &#125; else &#123; switch (this.defaultMQPushConsumer.getMessageModel()) &#123; case BROADCASTING: this.offsetStore = new LocalFileOffsetStore(this.mQClientFactory, this.defaultMQPushConsumer.getConsumerGroup()); break; case CLUSTERING: this.offsetStore = new RemoteBrokerOffsetStore(this.mQClientFactory, this.defaultMQPushConsumer.getConsumerGroup()); break; default: break; &#125; this.defaultMQPushConsumer.setOffsetStore(this.offsetStore); &#125; this.offsetStore.load(); //根据客户端配置实例化不同的consumeMessageService if (this.getMessageListenerInner() instanceof MessageListenerOrderly) &#123; // 顺序消息 this.consumeOrderly = true; this.consumeMessageService = new ConsumeMessageOrderlyService(this, (MessageListenerOrderly) this.getMessageListenerInner()); &#125; else if (this.getMessageListenerInner() instanceof MessageListenerConcurrently) &#123; // 非顺序消息 this.consumeOrderly = false; this.consumeMessageService = new ConsumeMessageConcurrentlyService(this, (MessageListenerConcurrently) this.getMessageListenerInner()); &#125; this.consumeMessageService.start(); //注册本地的消费者组缓存. boolean registerOK = mQClientFactory.registerConsumer(this.defaultMQPushConsumer.getConsumerGroup(), this); if (!registerOK) &#123; this.serviceState = ServiceState.CREATE_JUST; this.consumeMessageService.shutdown(defaultMQPushConsumer.getAwaitTerminationMillisWhenShutdown()); throw new MQClientException(&quot;The consumer group[&quot; + this.defaultMQPushConsumer.getConsumerGroup() + &quot;] has been created before, specify another name please.&quot; + FAQUrl.suggestTodo(FAQUrl.GROUP_NAME_DUPLICATE_URL), null); &#125; mQClientFactory.start(); this.serviceState = ServiceState.RUNNING; break; case RUNNING: case START_FAILED: case SHUTDOWN_ALREADY: throw new MQClientException(&quot;The PushConsumer service state not OK, maybe started once, &quot; + this.serviceState + FAQUrl.suggestTodo(FAQUrl.CLIENT_SERVICE_NOT_OK), null); default: break; &#125; this.updateTopicSubscribeInfoWhenSubscriptionChanged(); this.mQClientFactory.checkClientInBroker(); this.mQClientFactory.sendHeartbeatToAllBrokerWithLock(); this.mQClientFactory.rebalanceImmediately(); &#125;&#125; ConsumeMessageOrderlyService 线程会每隔 20s 执行一次,最终调用 RebalancePushImpl 超类 RebalanceImpl 的 lock 方法,通过 LockBatchRequestBody 设置前面设置到 RebalancePushImpl 中的 consumerGroup ,向Broker获取队列锁,且将锁定的队列缓存到 processQueueTable 中. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203public class ConsumeMessageOrderlyService implements ConsumeMessageService &#123; public void start() &#123; if (MessageModel.CLUSTERING.equals(ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.messageModel())) &#123; this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() &#123; @Override public void run() &#123; // 每20s执行一次 ConsumeMessageOrderlyService.this.lockMQPeriodically(); &#125; &#125;, 1000 * 1, ProcessQueue.REBALANCE_LOCK_INTERVAL, TimeUnit.MILLISECONDS); &#125; &#125; public synchronized void lockMQPeriodically() &#123; if (!this.stopped) &#123; this.defaultMQPushConsumerImpl.getRebalanceImpl().lockAll(); &#125; &#125;&#125;public abstract class RebalanceImpl &#123; private boolean updateProcessQueueTableInRebalance(final String topic, final Set&lt;MessageQueue&gt; mqSet, final boolean isOrder) &#123; boolean changed = false; Iterator&lt;Entry&lt;MessageQueue, ProcessQueue&gt;&gt; it = this.processQueueTable.entrySet().iterator(); while (it.hasNext()) &#123; Entry&lt;MessageQueue, ProcessQueue&gt; next = it.next(); MessageQueue mq = next.getKey(); ProcessQueue pq = next.getValue(); if (mq.getTopic().equals(topic)) &#123; if (!mqSet.contains(mq)) &#123; pq.setDropped(true); if (this.removeUnnecessaryMessageQueue(mq, pq)) &#123; it.remove(); changed = true; &#125; &#125; else if (pq.isPullExpired()) &#123; switch (this.consumeType()) &#123; case CONSUME_ACTIVELY: break; case CONSUME_PASSIVELY: pq.setDropped(true); if (this.removeUnnecessaryMessageQueue(mq, pq)) &#123; it.remove(); changed = true; &#125; break; default: break; &#125; &#125; &#125; &#125; List&lt;PullRequest&gt; pullRequestList = new ArrayList&lt;PullRequest&gt;(); for (MessageQueue mq : mqSet) &#123; if (!this.processQueueTable.containsKey(mq)) &#123; if (isOrder &amp;&amp; !this.lock(mq)) &#123; continue; &#125; this.removeDirtyOffset(mq); ProcessQueue pq = new ProcessQueue(); long nextOffset = this.computePullFromWhere(mq); if (nextOffset &gt;= 0) &#123; ProcessQueue pre = this.processQueueTable.putIfAbsent(mq, pq); if (pre != null) &#123; &#125; else &#123; PullRequest pullRequest = new PullRequest(); pullRequest.setConsumerGroup(consumerGroup); pullRequest.setNextOffset(nextOffset); pullRequest.setMessageQueue(mq); pullRequest.setProcessQueue(pq); pullRequestList.add(pullRequest); changed = true; &#125; &#125; &#125; &#125; this.dispatchPullRequest(pullRequestList); return changed; &#125; public boolean lock(final MessageQueue mq) &#123; FindBrokerResult findBrokerResult = this.mQClientFactory.findBrokerAddressInSubscribe(mq.getBrokerName(), MixAll.MASTER_ID, true); if (findBrokerResult != null) &#123; LockBatchRequestBody requestBody = new LockBatchRequestBody(); requestBody.setConsumerGroup(this.consumerGroup); requestBody.setClientId(this.mQClientFactory.getClientId()); requestBody.getMqSet().add(mq); try &#123; Set&lt;MessageQueue&gt; lockedMq = this.mQClientFactory.getMQClientAPIImpl().lockBatchMQ(findBrokerResult.getBrokerAddr(), requestBody, 1000); for (MessageQueue mmqq : lockedMq) &#123; ProcessQueue processQueue = this.processQueueTable.get(mmqq); if (processQueue != null) &#123; processQueue.setLocked(true); processQueue.setLastLockTimestamp(System.currentTimeMillis()); &#125; &#125; boolean lockOK = lockedMq.contains(mq); return lockOK; &#125; catch (Exception e) &#123; &#125; &#125; return false; &#125;&#125;public class ConsumeMessageOrderlyService implements ConsumeMessageService &#123; class ConsumeRequest implements Runnable &#123; private final ProcessQueue processQueue; private final MessageQueue messageQueue; @Override public void run() &#123; // 每一个ConsumeRequest消费任务不是以消费消息条数来计算,而是根据消费时间,默认当消费时长大于MAX_TIME_CONSUME_CONTINUOUSLY,默认60s后,本次消费任务结束,由消费组内其他线程继续消费 if (this.processQueue.isDropped()) &#123; return; &#125; final Object objLock = messageQueueLock.fetchLockObject(this.messageQueue); synchronized (objLock) &#123; // 通过加锁,将并发的消息顺序进行消费.消息处理的方式没什么特别. // 广播模式直接进入消费,无需锁定处理对列因为相互直接无竞争,集群模式proceessQueue被锁定并且锁未超时 if (MessageModel.BROADCASTING.equals(ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.messageModel()) || (this.processQueue.isLocked() &amp;&amp; !this.processQueue.isLockExpired())) &#123; final long beginTime = System.currentTimeMillis(); for (boolean continueConsume = true; continueConsume; ) &#123; if (this.processQueue.isDropped()) &#123; break; &#125; if (MessageModel.CLUSTERING.equals(ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.messageModel()) &amp;&amp; !this.processQueue.isLocked()) &#123; ConsumeMessageOrderlyService.this.tryLockLaterAndReconsume(this.messageQueue, this.processQueue, 10); break; &#125; if (MessageModel.CLUSTERING.equals(ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.messageModel()) &amp;&amp; this.processQueue.isLockExpired()) &#123; ConsumeMessageOrderlyService.this.tryLockLaterAndReconsume(this.messageQueue, this.processQueue, 10); break; &#125; long interval = System.currentTimeMillis() - beginTime; if (interval &gt; MAX_TIME_CONSUME_CONTINUOUSLY) &#123; ConsumeMessageOrderlyService.this.submitConsumeRequestLater(processQueue, messageQueue, 10); break; &#125; final int consumeBatchSize = ConsumeMessageOrderlyService.this.defaultMQPushConsumer.getConsumeMessageBatchMaxSize(); List&lt;MessageExt&gt; msgs = this.processQueue.takeMessages(consumeBatchSize); defaultMQPushConsumerImpl.resetRetryAndNamespace(msgs, defaultMQPushConsumer.getConsumerGroup()); if (!msgs.isEmpty()) &#123; final ConsumeOrderlyContext context = new ConsumeOrderlyContext(this.messageQueue); ConsumeOrderlyStatus status = null; ConsumeMessageContext consumeMessageContext = null; if (ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.hasHook()) &#123; consumeMessageContext = new ConsumeMessageContext(); consumeMessageContext.setConsumerGroup(ConsumeMessageOrderlyService.this.defaultMQPushConsumer.getConsumerGroup()); consumeMessageContext.setNamespace(defaultMQPushConsumer.getNamespace()); consumeMessageContext.setMq(messageQueue); consumeMessageContext.setMsgList(msgs); consumeMessageContext.setSuccess(false); consumeMessageContext.setProps(new HashMap&lt;String, String&gt;()); // init the consume context type ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.executeHookBefore(consumeMessageContext); &#125; long beginTimestamp = System.currentTimeMillis(); ConsumeReturnType returnType = ConsumeReturnType.SUCCESS; boolean hasException = false; try &#123; this.processQueue.getLockConsume().lock(); if (this.processQueue.isDropped()) &#123; break; &#125; status = messageListener.consumeMessage(Collections.unmodifiableList(msgs), context); // 调用消费者具体的消费方法 &#125; catch (Throwable e) &#123; hasException = true; &#125; finally &#123; this.processQueue.getLockConsume().unlock(); &#125; long consumeRT = System.currentTimeMillis() - beginTimestamp; if (null == status) &#123; if (hasException) &#123; returnType = ConsumeReturnType.EXCEPTION; &#125; else &#123; returnType = ConsumeReturnType.RETURNNULL; &#125; &#125; else if (consumeRT &gt;= defaultMQPushConsumer.getConsumeTimeout() * 60 * 1000) &#123; returnType = ConsumeReturnType.TIME_OUT; &#125; else if (ConsumeOrderlyStatus.SUSPEND_CURRENT_QUEUE_A_MOMENT == status) &#123; returnType = ConsumeReturnType.FAILED; &#125; else if (ConsumeOrderlyStatus.SUCCESS == status) &#123; returnType = ConsumeReturnType.SUCCESS; &#125; if (ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.hasHook()) &#123; consumeMessageContext.getProps().put(MixAll.CONSUME_CONTEXT_TYPE, returnType.name()); &#125; if (null == status) &#123; status = ConsumeOrderlyStatus.SUSPEND_CURRENT_QUEUE_A_MOMENT; &#125; if (ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.hasHook()) &#123; consumeMessageContext.setStatus(status.toString()); consumeMessageContext.setSuccess(ConsumeOrderlyStatus.SUCCESS == status || ConsumeOrderlyStatus.COMMIT == status); ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.executeHookAfter(consumeMessageContext); &#125; ConsumeMessageOrderlyService.this.getConsumerStatsManager().incConsumeRT(ConsumeMessageOrderlyService.this.consumerGroup, messageQueue.getTopic(), consumeRT); continueConsume = ConsumeMessageOrderlyService.this.processConsumeResult(msgs, status, context, this); &#125; else &#123; continueConsume = false; &#125; &#125; &#125; else &#123; if (this.processQueue.isDropped()) &#123; return; &#125; ConsumeMessageOrderlyService.this.tryLockLaterAndReconsume(this.messageQueue, this.processQueue, 100); &#125; &#125; &#125; &#125;&#125;","tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"http://example.com/tags/RocketMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RocketMQ","slug":"工具和中间件/消息队列/RocketMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RocketMQ/"}]},{"title":"RocketMQ-生产者源码","date":"2019-04-23T03:08:20.000Z","path":"blog/工具和中间件/消息队列/RocketMQ/RocketMQ-生产者源码/","text":"普通消息不论同步请求还是异步请求最终都是调用 DefaultMQProducerImpl 的 sendDefaultImpl 方法,首先通过 tryToFindTopicPublishInfo 方法获取Topic信息,先从本地缓存找,若本地缓存没有则调用 MQClientAPIImpl 的 getTopicRouteInfoFromNameServer 方法通过 RequestCode.GET_ROUTEINFO_BY_TOPIC 关联调用NameServer的 DefaultRequestProcessor 的 getRouteInfoByTopic 方法获取Topic信息； Topic 信息在 Producter 启动时就注册到 NameServer 了,且每 30s 发送心跳也会发送 Topic 相关的信息. 然后通过 MQFaultStrategy 的 selectOneMessageQueue 获取具体的具体要将消息发送到哪一个队列中,Producer选择 MessageQueue 方法是消息数自增对队列数取模,可通过 sendLatencyFaultEnable 参数开启Broker故障延迟机制,发送消息失败后一定时间内不在往同一个Queue重复发送的机制,在 LatencyFaultToleranceImpl 中维护了曾经发送失败的Broker列表到faultItemTable 中. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189public class DefaultMQProducer extends ClientConfig implements MQProducer &#123; public SendResult send(Message msg) throws MQClientException, RemotingException, MQBrokerException, InterruptedException &#123; Validators.checkMessage(msg, this); msg.setTopic(withNamespace(msg.getTopic())); return this.defaultMQProducerImpl.send(msg); &#125; public void send(Message msg, SendCallback sendCallback) throws MQClientException, RemotingException, InterruptedException &#123; msg.setTopic(withNamespace(msg.getTopic())); this.defaultMQProducerImpl.send(msg, sendCallback); &#125;&#125;public class DefaultMQProducerImpl implements MQProducerInner &#123; public void send(final Message msg, final SendCallback sendCallback, final long timeout) throws MQClientException, RemotingException, InterruptedException &#123; final long beginStartTime = System.currentTimeMillis(); ExecutorService executor = this.getAsyncSenderExecutor(); try &#123; executor.submit(new Runnable() &#123; @Override public void run() &#123; long costTime = System.currentTimeMillis() - beginStartTime; if (timeout &gt; costTime) &#123; try &#123; sendDefaultImpl(msg, CommunicationMode.ASYNC, sendCallback, timeout - costTime); &#125; catch (Exception e) &#123; sendCallback.onException(e); // 调用回调方法 &#125; &#125; else &#123; // 调用回调方法 sendCallback.onException(new RemotingTooMuchRequestException(&quot;DEFAULT ASYNC send call timeout&quot;)); &#125; &#125; &#125;); &#125; catch (RejectedExecutionException e) &#123; throw new MQClientException(&quot;executor rejected &quot;, e); &#125; &#125; private SendResult sendDefaultImpl(Message msg, final CommunicationMode communicationMode, final SendCallback sendCallback, final long timeout) throws MQClientException, RemotingException, MQBrokerException, InterruptedException &#123; this.makeSureStateOK(); Validators.checkMessage(msg, this.defaultMQProducer); final long invokeID = random.nextLong(); long beginTimestampFirst = System.currentTimeMillis(); long beginTimestampPrev = beginTimestampFirst; long endTimestamp = beginTimestampFirst; // 生产者获取Topic的公开信息 TopicPublishInfo topicPublishInfo = this.tryToFindTopicPublishInfo(msg.getTopic()); if (topicPublishInfo != null &amp;&amp; topicPublishInfo.ok()) &#123; boolean callTimeout = false; MessageQueue mq = null; Exception exception = null; SendResult sendResult = null; int timesTotal = communicationMode == CommunicationMode.SYNC ? 1 + this.defaultMQProducer.getRetryTimesWhenSendFailed() : 1; int times = 0; String[] brokersSent = new String[timesTotal]; for (; times &lt; timesTotal; times++) &#123; // 重试次数,异步默认重试2次共3次,同步不重试共1次 String lastBrokerName = null == mq ? null : mq.getBrokerName(); // Producer计算把消息发到哪个MessageQueue中,自增然后取模 MessageQueue mqSelected = this.selectOneMessageQueue(topicPublishInfo, lastBrokerName); if (mqSelected != null) &#123; mq = mqSelected; brokersSent[times] = mq.getBrokerName(); // 根据MessageQueue去获取目标节点的信息. try &#123; beginTimestampPrev = System.currentTimeMillis(); if (times &gt; 0) &#123; // 重新发送期间使用命名空间重置主题 msg.setTopic(this.defaultMQProducer.withNamespace(msg.getTopic())); &#125; long costTime = beginTimestampPrev - beginTimestampFirst; if (timeout &lt; costTime) &#123; // 判断是否超时,默认3s callTimeout = true; break; // 若超时 &#125; // 实际发送消息的方法 sendResult = this.sendKernelImpl(msg, mq, communicationMode, sendCallback, topicPublishInfo, timeout - costTime); endTimestamp = System.currentTimeMillis(); this.updateFaultItem(mq.getBrokerName(), endTimestamp - beginTimestampPrev, false); switch (communicationMode) &#123; case ASYNC: return null; // 异步发送返回null case ONEWAY: return null; // 单向发送返回null case SYNC: if (sendResult.getSendStatus() != SendStatus.SEND_OK) &#123; if (this.defaultMQProducer.isRetryAnotherBrokerWhenNotStoreOK()) &#123; continue; // 若重试则继续,否则直接返回结果 &#125; &#125; return sendResult; default: break; &#125; &#125; &#125; else &#123; break; &#125; &#125; if (sendResult != null) &#123; return sendResult; &#125; info += FAQUrl.suggestTodo(FAQUrl.SEND_MSG_FAILED); MQClientException mqClientException = new MQClientException(info, exception); if (callTimeout) &#123; throw new RemotingTooMuchRequestException(&quot;sendDefaultImpl call timeout&quot;); &#125; throw mqClientException; &#125; validateNameServerSetting(); throw new MQClientException(&quot;No route info of this topic: &quot; + msg.getTopic() + FAQUrl.suggestTodo(FAQUrl.NO_TOPIC_ROUTE_INFO), null).setResponseCode(ClientErrorCode.NOT_FOUND_TOPIC_EXCEPTION); &#125; public MessageQueue selectOneMessageQueue(final TopicPublishInfo tpInfo, final String lastBrokerName) &#123; return this.mqFaultStrategy.selectOneMessageQueue(tpInfo, lastBrokerName); &#125; // 找路由表的过程都是先从本地缓存找,本地缓存没有,就去NameServer上申请. private TopicPublishInfo tryToFindTopicPublishInfo(final String topic) &#123; TopicPublishInfo topicPublishInfo = this.topicPublishInfoTable.get(topic); if (null == topicPublishInfo || !topicPublishInfo.ok()) &#123; this.topicPublishInfoTable.putIfAbsent(topic, new TopicPublishInfo()); // Producer向NameServer获取更新Topic的路由信息. this.mQClientFactory.updateTopicRouteInfoFromNameServer(topic); // 还是从本地缓存中寻找Topic路由信息. topicPublishInfo = this.topicPublishInfoTable.get(topic); &#125; if (topicPublishInfo.isHaveTopicRouterInfo() || topicPublishInfo.ok()) &#123; return topicPublishInfo; &#125; else &#123; this.mQClientFactory.updateTopicRouteInfoFromNameServer(topic, true, this.defaultMQProducer); topicPublishInfo = this.topicPublishInfoTable.get(topic); return topicPublishInfo; &#125; &#125;&#125;public class MQFaultStrategy &#123; public MessageQueue selectOneMessageQueue(final TopicPublishInfo tpInfo, final String lastBrokerName) &#123; // sendLatencyFaultEnable默认关闭,Broker故障延迟机制,表示一种发送消息失败后一定时间内不在往同一个Queue重复发送的机制 if (this.sendLatencyFaultEnable) &#123; try &#123; // Producer选择MessageQueue的方法是自增然后取模. int index = tpInfo.getSendWhichQueue().getAndIncrement(); for (int i = 0; i &lt; tpInfo.getMessageQueueList().size(); i++) &#123; int pos = Math.abs(index++) % tpInfo.getMessageQueueList().size(); if (pos &lt; 0) pos = 0; MessageQueue mq = tpInfo.getMessageQueueList().get(pos); // Broker轮询,尽量将请求平均分配给不同的Broker if (latencyFaultTolerance.isAvailable(mq.getBrokerName())) &#123; if (null == lastBrokerName || mq.getBrokerName().equals(lastBrokerName)) return mq; &#125; &#125; final String notBestBroker = latencyFaultTolerance.pickOneAtLeast(); int writeQueueNums = tpInfo.getQueueIdByBroker(notBestBroker); if (writeQueueNums &gt; 0) &#123; final MessageQueue mq = tpInfo.selectOneMessageQueue();// 自增取模计算 if (notBestBroker != null) &#123; mq.setBrokerName(notBestBroker); mq.setQueueId(tpInfo.getSendWhichQueue().getAndIncrement() % writeQueueNums); &#125; return mq; &#125; else &#123; latencyFaultTolerance.remove(notBestBroker); &#125; &#125; return tpInfo.selectOneMessageQueue(); // 自增取模计算 &#125; return tpInfo.selectOneMessageQueue(lastBrokerName); // 自增取模计算 &#125;&#125;public class TopicPublishInfo &#123; //选择MessageQueue的方式：递增取模 public MessageQueue selectOneMessageQueue() &#123; int index = this.sendWhichQueue.getAndIncrement(); int pos = Math.abs(index) % this.messageQueueList.size(); if (pos &lt; 0) pos = 0; return this.messageQueueList.get(pos); &#125; public MessageQueue selectOneMessageQueue(final String lastBrokerName) &#123; if (lastBrokerName == null) &#123; return selectOneMessageQueue(); &#125; else &#123; int index = this.sendWhichQueue.getAndIncrement(); for (int i = 0; i &lt; this.messageQueueList.size(); i++) &#123; int pos = Math.abs(index++) % this.messageQueueList.size(); if (pos &lt; 0) pos = 0; MessageQueue mq = this.messageQueueList.get(pos); if (!mq.getBrokerName().equals(lastBrokerName)) &#123; return mq; &#125; &#125; return selectOneMessageQueue(); &#125; &#125;&#125; 不论是同步还是异步或是单向消息最终都会调用 MQClientAPIImpl 的 sendMessage 方法,不同的是同步方法没有 SendCallback 回调. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152public class DefaultMQProducerImpl implements MQProducerInner &#123; private SendResult sendKernelImpl(final Message msg, final MessageQueue mq, final CommunicationMode communicationMode, final SendCallback sendCallback, final TopicPublishInfo topicPublishInfo, final long timeout) throws MQClientException, RemotingException, MQBrokerException, InterruptedException &#123; long beginStartTime = System.currentTimeMillis(); String brokerAddr = this.mQClientFactory.findBrokerAddressInPublish(mq.getBrokerName()); // 找到Master节点地址 if (null == brokerAddr) &#123;// 通过Broker名称获取Broker地址,若获取不到则去NameServer上获取. tryToFindTopicPublishInfo(mq.getTopic()); brokerAddr = this.mQClientFactory.findBrokerAddressInPublish(mq.getBrokerName()); &#125; SendMessageContext context = null; if (brokerAddr != null) &#123; brokerAddr = MixAll.brokerVIPChannel(this.defaultMQProducer.isSendMessageWithVIPChannel(), brokerAddr); byte[] prevBody = msg.getBody(); try &#123; if (!(msg instanceof MessageBatch)) &#123; //for MessageBatch,ID has been set in the generating process MessageClientIDSetter.setUniqID(msg); // 批量消息 &#125; boolean topicWithNamespace = false; if (null != this.mQClientFactory.getClientConfig().getNamespace()) &#123; msg.setInstanceId(this.mQClientFactory.getClientConfig().getNamespace()); topicWithNamespace = true; &#125; int sysFlag = 0; boolean msgBodyCompressed = false; if (this.tryToCompressMessage(msg)) &#123; // 消息体大于4K将默认压缩 sysFlag |= MessageSysFlag.COMPRESSED_FLAG; msgBodyCompressed = true; &#125; final String tranMsg = msg.getProperty(MessageConst.PROPERTY_TRANSACTION_PREPARED); if (tranMsg != null &amp;&amp; Boolean.parseBoolean(tranMsg)) &#123; sysFlag |= MessageSysFlag.TRANSACTION_PREPARED_TYPE; &#125; SendMessageRequestHeader requestHeader = new SendMessageRequestHeader(); requestHeader.setProducerGroup(this.defaultMQProducer.getProducerGroup()); requestHeader.setTopic(msg.getTopic()); requestHeader.setDefaultTopic(this.defaultMQProducer.getCreateTopicKey()); requestHeader.setDefaultTopicQueueNums(this.defaultMQProducer.getDefaultTopicQueueNums()); requestHeader.setQueueId(mq.getQueueId()); requestHeader.setSysFlag(sysFlag); requestHeader.setBornTimestamp(System.currentTimeMillis()); requestHeader.setFlag(msg.getFlag()); requestHeader.setProperties(MessageDecoder.messageProperties2String(msg.getProperties())); requestHeader.setReconsumeTimes(0); requestHeader.setUnitMode(this.isUnitMode()); requestHeader.setBatch(msg instanceof MessageBatch); if (requestHeader.getTopic().startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)) &#123; // 重试消息 String reconsumeTimes = MessageAccessor.getReconsumeTime(msg); if (reconsumeTimes != null) &#123; requestHeader.setReconsumeTimes(Integer.valueOf(reconsumeTimes)); MessageAccessor.clearProperty(msg, MessageConst.PROPERTY_RECONSUME_TIME); &#125; String maxReconsumeTimes = MessageAccessor.getMaxReconsumeTimes(msg); if (maxReconsumeTimes != null) &#123; requestHeader.setMaxReconsumeTimes(Integer.valueOf(maxReconsumeTimes)); MessageAccessor.clearProperty(msg, MessageConst.PROPERTY_MAX_RECONSUME_TIMES); &#125; &#125; SendResult sendResult = null; switch (communicationMode) &#123; case ASYNC: Message tmpMessage = msg; boolean messageCloned = false; if (msgBodyCompressed) &#123; tmpMessage = MessageAccessor.cloneMessage(msg); messageCloned = true; msg.setBody(prevBody); &#125; if (topicWithNamespace) &#123; if (!messageCloned) &#123; tmpMessage = MessageAccessor.cloneMessage(msg); messageCloned = true; &#125; msg.setTopic(NamespaceUtil.withoutNamespace(msg.getTopic(), this.defaultMQProducer.getNamespace())); &#125; long costTimeAsync = System.currentTimeMillis() - beginStartTime; if (timeout &lt; costTimeAsync) &#123; throw new RemotingTooMuchRequestException(&quot;sendKernelImpl call timeout&quot;); &#125; // 真正向Broker发送消息,异步要传入回调函数 sendResult = this.mQClientFactory.getMQClientAPIImpl().sendMessage(brokerAddr, mq.getBrokerName(), tmpMessage, requestHeader, timeout - costTimeAsync, communicationMode, sendCallback, topicPublishInfo, this.mQClientFactory, this.defaultMQProducer.getRetryTimesWhenSendAsyncFailed(), context, this); break; case ONEWAY: case SYNC: long costTimeSync = System.currentTimeMillis() - beginStartTime; if (timeout &lt; costTimeSync) &#123; throw new RemotingTooMuchRequestException(&quot;sendKernelImpl call timeout&quot;); &#125; // 真正向Broker发送消息,同步不需要传入回调函数 sendResult = this.mQClientFactory.getMQClientAPIImpl().sendMessage(brokerAddr, mq.getBrokerName(), msg, requestHeader, timeout - costTimeSync, communicationMode, context, this); break; default: assert false; break; &#125; if (this.hasSendMessageHook()) &#123;//消息发送完成后执行钩子程序. context.setSendResult(sendResult); this.executeSendMessageHookAfter(context); &#125; return sendResult; &#125; &#125; throw new MQClientException(&quot;The broker[&quot; + mq.getBrokerName() + &quot;] not exist&quot;, null); &#125;&#125;public class MQClientAPIImpl &#123; // 不论同步还是异步最终都会调用该方法 public SendResult sendMessage(final String addr, final String brokerName, final Message msg, final SendMessageRequestHeader requestHeader, final long timeoutMillis, final CommunicationMode communicationMode, final SendCallback sendCallback, final TopicPublishInfo topicPublishInfo, final MQClientInstance instance, final int retryTimesWhenSendFailed, final SendMessageContext context, final DefaultMQProducerImpl producer) throws RemotingException, MQBrokerException, InterruptedException &#123; long beginStartTime = System.currentTimeMillis(); RemotingCommand request = null; String msgType = msg.getProperty(MessageConst.PROPERTY_MESSAGE_TYPE); boolean isReply = msgType != null &amp;&amp; msgType.equals(MixAll.REPLY_MESSAGE_FLAG); if (isReply) &#123; if (sendSmartMsg) &#123; SendMessageRequestHeaderV2 requestHeaderV2 = SendMessageRequestHeaderV2.createSendMessageRequestHeaderV2(requestHeader); request = RemotingCommand.createRequestCommand(RequestCode.SEND_REPLY_MESSAGE_V2, requestHeaderV2); &#125; else &#123; request = RemotingCommand.createRequestCommand(RequestCode.SEND_REPLY_MESSAGE, requestHeader); &#125; &#125; else &#123; if (sendSmartMsg || msg instanceof MessageBatch) &#123; SendMessageRequestHeaderV2 requestHeaderV2 = SendMessageRequestHeaderV2.createSendMessageRequestHeaderV2(requestHeader); request = RemotingCommand.createRequestCommand(msg instanceof MessageBatch ? RequestCode.SEND_BATCH_MESSAGE : RequestCode.SEND_MESSAGE_V2, requestHeaderV2); &#125; else &#123; request = RemotingCommand.createRequestCommand(RequestCode.SEND_MESSAGE, requestHeader); &#125; &#125; request.setBody(msg.getBody()); switch (communicationMode) &#123; case ONEWAY: this.remotingClient.invokeOneway(addr, request, timeoutMillis); return null; case ASYNC: final AtomicInteger times = new AtomicInteger(); long costTimeAsync = System.currentTimeMillis() - beginStartTime; if (timeoutMillis &lt; costTimeAsync) &#123; throw new RemotingTooMuchRequestException(&quot;sendMessage call timeout&quot;); &#125; this.sendMessageAsync(addr, brokerName, msg, timeoutMillis - costTimeAsync, request, sendCallback, topicPublishInfo, instance, retryTimesWhenSendFailed, times, context, producer); return null; case SYNC: long costTimeSync = System.currentTimeMillis() - beginStartTime; if (timeoutMillis &lt; costTimeSync) &#123; throw new RemotingTooMuchRequestException(&quot;sendMessage call timeout&quot;); &#125; return this.sendMessageSync(addr, brokerName, msg, timeoutMillis - costTimeSync, request); default: assert false; break; &#125; return null; &#125; &#125; 对于同步消息最终用通过 RequestCode.SEND_MESSAGE 编号最终在 Broker 中执行 SendMessageProcessor 的 processRequest 方法,异步消息最终调用的是 SendMessageProcessor 的 asyncProcessRequest 方法,最终都是调用的 asyncProcessRequest 方法,不同点在于同步消息的 processRequest 中获取到异步 CompletableFuture 直接调用get方法等待结果,不论是同步还是异步方法最终都是在 handlePutMessageResultFuture 方法中调用 CompletableFuture 的 thenApply 方法,在响应后最终在 handlePutMessageResult 中调用 doResponse 方法将结果写回给客户端. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109public class MQClientAPIImpl &#123; private SendResult sendMessageSync(final String addr, final String brokerName, final Message msg, final long timeoutMillis, final RemotingCommand request) throws RemotingException, MQBrokerException, InterruptedException &#123; RemotingCommand response = this.remotingClient.invokeSync(addr, request, timeoutMillis); assert response != null; return this.processSendResponse(brokerName, msg, response); &#125;&#125;public class NettyRemotingClient extends NettyRemotingAbstract implements RemotingClient &#123; public RemotingCommand invokeSync(String addr, final RemotingCommand request, long timeoutMillis) throws InterruptedException, RemotingConnectException, RemotingSendRequestException, RemotingTimeoutException &#123; long beginStartTime = System.currentTimeMillis(); // channel是和Nameserver之间建立的一个连接. final Channel channel = this.getAndCreateChannel(addr); if (channel != null &amp;&amp; channel.isActive()) &#123; // 网络连接ok则发送请求 try &#123; doBeforeRpcHooks(addr, request); //计算时间 long costTime = System.currentTimeMillis() - beginStartTime; if (timeoutMillis &lt; costTime) &#123; throw new RemotingTimeoutException(&quot;invokeSync call timeout&quot;); &#125; RemotingCommand response = this.invokeSyncImpl(channel, request, timeoutMillis - costTime); // 真正发网络请求的地方 doAfterRpcHooks(RemotingHelper.parseChannelRemoteAddr(channel), request, response); return response; &#125; catch (RemotingSendRequestException e) &#123; this.closeChannel(addr, channel); throw e; &#125; catch (RemotingTimeoutException e) &#123; if (nettyClientConfig.isClientCloseSocketIfTimeout()) &#123; this.closeChannel(addr, channel); &#125; throw e; &#125; &#125; else &#123; this.closeChannel(addr, channel); throw new RemotingConnectException(addr); &#125; &#125;&#125;public class SendMessageProcessor extends AbstractSendMessageProcessor implements NettyRequestProcessor &#123; public RemotingCommand processRequest(ChannelHandlerContext ctx, RemotingCommand request) throws RemotingCommandException &#123; RemotingCommand response = null; try &#123; response = asyncProcessRequest(ctx, request).get(); &#125; return response; &#125; public CompletableFuture&lt;RemotingCommand&gt; asyncProcessRequest(ChannelHandlerContext ctx, RemotingCommand request) throws RemotingCommandException &#123; final SendMessageContext mqtraceContext; switch (request.getCode()) &#123; case RequestCode.CONSUMER_SEND_MSG_BACK: return this.asyncConsumerSendMsgBack(ctx, request); default: SendMessageRequestHeader requestHeader = parseRequestHeader(request); if (requestHeader == null) &#123; return CompletableFuture.completedFuture(null); &#125; mqtraceContext = buildMsgContext(ctx, requestHeader); this.executeSendMessageHookBefore(ctx, request, mqtraceContext); if (requestHeader.isBatch()) &#123; return this.asyncSendBatchMessage(ctx, request, mqtraceContext, requestHeader); &#125; else &#123; return this.asyncSendMessage(ctx, request, mqtraceContext, requestHeader); &#125; &#125; &#125; private CompletableFuture&lt;RemotingCommand&gt; asyncSendMessage(ChannelHandlerContext ctx, RemotingCommand request, SendMessageContext mqtraceContext, SendMessageRequestHeader requestHeader) &#123; final RemotingCommand response = preSend(ctx, request, requestHeader); final SendMessageResponseHeader responseHeader = (SendMessageResponseHeader)response.readCustomHeader(); if (response.getCode() != -1) &#123; return CompletableFuture.completedFuture(response); &#125; final byte[] body = request.getBody(); int queueIdInt = requestHeader.getQueueId(); TopicConfig topicConfig = this.brokerController.getTopicConfigManager().selectTopicConfig(requestHeader.getTopic()); if (queueIdInt &lt; 0) &#123; queueIdInt = randomQueueId(topicConfig.getWriteQueueNums()); &#125; MessageExtBrokerInner msgInner = new MessageExtBrokerInner(); msgInner.setTopic(requestHeader.getTopic()); msgInner.setQueueId(queueIdInt); if (!handleRetryAndDLQ(requestHeader, response, request, msgInner, topicConfig)) &#123; return CompletableFuture.completedFuture(response); &#125; msgInner.setBody(body); msgInner.setFlag(requestHeader.getFlag()); MessageAccessor.setProperties(msgInner, MessageDecoder.string2messageProperties(requestHeader.getProperties())); msgInner.setPropertiesString(requestHeader.getProperties()); msgInner.setBornTimestamp(requestHeader.getBornTimestamp()); msgInner.setBornHost(ctx.channel().remoteAddress()); msgInner.setStoreHost(this.getStoreHost()); msgInner.setReconsumeTimes(requestHeader.getReconsumeTimes() == null ? 0 : requestHeader.getReconsumeTimes()); String clusterName = this.brokerController.getBrokerConfig().getBrokerClusterName(); MessageAccessor.putProperty(msgInner, MessageConst.PROPERTY_CLUSTER, clusterName); msgInner.setPropertiesString(MessageDecoder.messageProperties2String(msgInner.getProperties())); CompletableFuture&lt;PutMessageResult&gt; putMessageResult = null; Map&lt;String, String&gt; origProps = MessageDecoder.string2messageProperties(requestHeader.getProperties()); String transFlag = origProps.get(MessageConst.PROPERTY_TRANSACTION_PREPARED); if (transFlag != null &amp;&amp; Boolean.parseBoolean(transFlag)) &#123; if (this.brokerController.getBrokerConfig().isRejectTransactionMessage()) &#123; response.setCode(ResponseCode.NO_PERMISSION); response.setRemark(&quot;the broker[&quot; + this.brokerController.getBrokerConfig().getBrokerIP1() + &quot;] sending transaction message is forbidden&quot;); return CompletableFuture.completedFuture(response); &#125; putMessageResult = this.brokerController.getTransactionalMessageService().asyncPrepareMessage(msgInner); // 事务消息持久化 &#125; else &#123; putMessageResult = this.brokerController.getMessageStore().asyncPutMessage(msgInner); // 普通消息持久化 &#125; return handlePutMessageResultFuture(putMessageResult, response, request, msgInner, responseHeader, mqtraceContext, ctx, queueIdInt); &#125;&#125; 对于异步方法当获取到响应后会回调 InvokeCallback 中的 operationComplete 方法,在该方法中若成功则回调用 SendCallback 的 onSuccess 方法.若失败则走重试逻辑若中还是失败则回调用 SendCallback 的 onException 方法. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class MQClientAPIImpl &#123; private void sendMessageAsync(final String addr, final String brokerName, final Message msg, final long timeoutMillis, final RemotingCommand request, final SendCallback sendCallback, final TopicPublishInfo topicPublishInfo, final MQClientInstance instance, final int retryTimesWhenSendFailed, final AtomicInteger times, final SendMessageContext context, final DefaultMQProducerImpl producer) throws InterruptedException, RemotingException &#123; final long beginStartTime = System.currentTimeMillis(); this.remotingClient.invokeAsync(addr, request, timeoutMillis, new InvokeCallback() &#123; @Override public void operationComplete(ResponseFuture responseFuture) &#123; long cost = System.currentTimeMillis() - beginStartTime; RemotingCommand response = responseFuture.getResponseCommand(); if (null == sendCallback &amp;&amp; response != null) &#123; try &#123; SendResult sendResult = MQClientAPIImpl.this.processSendResponse(brokerName, msg, response); if (context != null &amp;&amp; sendResult != null) &#123; context.setSendResult(sendResult); context.getProducer().executeSendMessageHookAfter(context); &#125; &#125; catch (Throwable e) &#123; &#125; producer.updateFaultItem(brokerName, System.currentTimeMillis() - responseFuture.getBeginTimestamp(), false); return; &#125; if (response != null) &#123; try &#123; SendResult sendResult = MQClientAPIImpl.this.processSendResponse(brokerName, msg, response); assert sendResult != null; if (context != null) &#123; context.setSendResult(sendResult); context.getProducer().executeSendMessageHookAfter(context); &#125; try &#123; sendCallback.onSuccess(sendResult); // 回调用SendCallback的onSuccess方法 &#125; catch (Throwable e) &#123; &#125; producer.updateFaultItem(brokerName, System.currentTimeMillis() - responseFuture.getBeginTimestamp(), false); &#125; catch (Exception e) &#123; producer.updateFaultItem(brokerName, System.currentTimeMillis() - responseFuture.getBeginTimestamp(), true); onExceptionImpl(brokerName, msg, timeoutMillis - cost, request, sendCallback, topicPublishInfo, instance, retryTimesWhenSendFailed, times, e, context, false, producer); &#125; &#125; else &#123; producer.updateFaultItem(brokerName, System.currentTimeMillis() - responseFuture.getBeginTimestamp(), true); if (!responseFuture.isSendRequestOK()) &#123; MQClientException ex = new MQClientException(&quot;send request failed&quot;, responseFuture.getCause()); onExceptionImpl(brokerName, msg, timeoutMillis - cost, request, sendCallback, topicPublishInfo, instance, retryTimesWhenSendFailed, times, ex, context, true, producer); &#125; else if (responseFuture.isTimeout()) &#123; MQClientException ex = new MQClientException(&quot;wait response timeout &quot; + responseFuture.getTimeoutMillis() + &quot;ms&quot;, responseFuture.getCause()); onExceptionImpl(brokerName, msg, timeoutMillis - cost, request, sendCallback, topicPublishInfo, instance, retryTimesWhenSendFailed, times, ex, context, true, producer); &#125; else &#123; MQClientException ex = new MQClientException(&quot;unknow reseaon&quot;, responseFuture.getCause()); onExceptionImpl(brokerName, msg, timeoutMillis - cost, request, sendCallback, topicPublishInfo, instance, retryTimesWhenSendFailed, times, ex, context, true, producer); &#125; &#125; &#125; &#125;); &#125;&#125; 事务消息对于事务消息的发送是通过 TransactionMQProducer 类的 sendMessageInTransaction 方法来完成的,若事务消息设置了延迟参数则将会被清除,会设置 TRAN_MSG 属性为 true ,然后调用send方法发送消费到 Broker ,send方法中和普通的发送消息调用的一个方法,但普通消息是走的 DefaultMessageStore 的 asyncPutMessage 方法,事务消息是走的 TransactionalMessageServiceImpl 的 asyncPrepareMessage 方法.若发送成功则调用设置的 TransactionListener 的 executeLocalTransaction 方法,然后调用 MQClientAPIImpl 的 endTransactionOneway 方法. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111public class TransactionMQProducer extends DefaultMQProducer &#123; public TransactionSendResult sendMessageInTransaction(final Message msg, final Object arg) throws MQClientException &#123; if (null == this.transactionListener) &#123; throw new MQClientException(&quot;TransactionListener is null&quot;, null); &#125; msg.setTopic(NamespaceUtil.wrapNamespace(this.getNamespace(), msg.getTopic())); return this.defaultMQProducerImpl.sendMessageInTransaction(msg, null, arg); &#125;&#125;public class DefaultMQProducerImpl implements MQProducerInner &#123; public TransactionSendResult sendMessageInTransaction(final Message msg, final LocalTransactionExecuter localTransactionExecuter, final Object arg) throws MQClientException &#123; TransactionListener transactionListener = getCheckListener(); if (null == localTransactionExecuter &amp;&amp; null == transactionListener) &#123; throw new MQClientException(&quot;tranExecutor is null&quot;, null); &#125; if (msg.getDelayTimeLevel() != 0) &#123; // 不支持延迟消息 MessageAccessor.clearProperty(msg, MessageConst.PROPERTY_DELAY_TIME_LEVEL); &#125; Validators.checkMessage(msg, this.defaultMQProducer); SendResult sendResult = null; MessageAccessor.putProperty(msg, MessageConst.PROPERTY_TRANSACTION_PREPARED, &quot;true&quot;); MessageAccessor.putProperty(msg, MessageConst.PROPERTY_PRODUCER_GROUP, this.defaultMQProducer.getProducerGroup()); try &#123; sendResult = this.send(msg); &#125; catch (Exception e) &#123; throw new MQClientException(&quot;send message Exception&quot;, e); &#125; LocalTransactionState localTransactionState = LocalTransactionState.UNKNOW; // 默认本地事务状态为UNKNOW Throwable localException = null; switch (sendResult.getSendStatus()) &#123; case SEND_OK: &#123; try &#123; if (sendResult.getTransactionId() != null) &#123; msg.putUserProperty(&quot;__transactionId__&quot;, sendResult.getTransactionId()); &#125; String transactionId = msg.getProperty(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX); if (null != transactionId &amp;&amp; !&quot;&quot;.equals(transactionId)) &#123; msg.setTransactionId(transactionId); &#125; if (null != localTransactionExecuter) &#123; // 默认localTransactionExecuter为null localTransactionState = localTransactionExecuter.executeLocalTransactionBranch(msg, arg); &#125; else if (transactionListener != null) &#123; // transactionListener是调用时设置的 localTransactionState = transactionListener.executeLocalTransaction(msg, arg); &#125; if (null == localTransactionState) &#123; localTransactionState = LocalTransactionState.UNKNOW; &#125; &#125; catch (Throwable e) &#123; localException = e; &#125; &#125; break; case FLUSH_DISK_TIMEOUT: case FLUSH_SLAVE_TIMEOUT: case SLAVE_NOT_AVAILABLE: localTransactionState = LocalTransactionState.ROLLBACK_MESSAGE; break; default: break; &#125; try &#123; this.endTransaction(sendResult, localTransactionState, localException); &#125; TransactionSendResult transactionSendResult = new TransactionSendResult(); transactionSendResult.setSendStatus(sendResult.getSendStatus()); transactionSendResult.setMessageQueue(sendResult.getMessageQueue()); transactionSendResult.setMsgId(sendResult.getMsgId()); transactionSendResult.setQueueOffset(sendResult.getQueueOffset()); transactionSendResult.setTransactionId(sendResult.getTransactionId()); transactionSendResult.setLocalTransactionState(localTransactionState); return transactionSendResult; &#125; public void endTransaction(final SendResult sendResult, final LocalTransactionState localTransactionState, final Throwable localException) throws RemotingException, MQBrokerException, InterruptedException, UnknownHostException &#123; final MessageId id; if (sendResult.getOffsetMsgId() != null) &#123; id = MessageDecoder.decodeMessageId(sendResult.getOffsetMsgId()); &#125; else &#123; id = MessageDecoder.decodeMessageId(sendResult.getMsgId()); &#125; String transactionId = sendResult.getTransactionId(); final String brokerAddr = this.mQClientFactory.findBrokerAddressInPublish(sendResult.getMessageQueue().getBrokerName()); EndTransactionRequestHeader requestHeader = new EndTransactionRequestHeader(); requestHeader.setTransactionId(transactionId); requestHeader.setCommitLogOffset(id.getOffset()); switch (localTransactionState) &#123; case COMMIT_MESSAGE: requestHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_COMMIT_TYPE); break; case ROLLBACK_MESSAGE: requestHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_ROLLBACK_TYPE); break; case UNKNOW: requestHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_NOT_TYPE); break; default: break; &#125; requestHeader.setProducerGroup(this.defaultMQProducer.getProducerGroup()); requestHeader.setTranStateTableOffset(sendResult.getQueueOffset()); requestHeader.setMsgId(sendResult.getMsgId()); String remark = localException != null ? (&quot;executeLocalTransactionBranch exception: &quot; + localException.toString()) : null; this.mQClientFactory.getMQClientAPIImpl().endTransactionOneway(brokerAddr, requestHeader, remark, this.defaultMQProducer.getSendMsgTimeout()); &#125;&#125;public class MQClientAPIImpl &#123; public void endTransactionOneway(final String addr, final EndTransactionRequestHeader requestHeader, final String remark, final long timeoutMillis) throws RemotingException, MQBrokerException, InterruptedException &#123; RemotingCommand request = RemotingCommand.createRequestCommand(RequestCode.END_TRANSACTION, requestHeader); request.setRemark(remark); this.remotingClient.invokeOneway(addr, request, timeoutMillis); &#125;&#125; 首先会将将真正的事务 Topic 存储到 REAL_TOPIC 属性中,然后将 Topic 换成 RMQ_SYS_TRANS_HALF_TOPIC ,然后将替换了Topic的事务消息通过 DefaultMessageStore 的 asyncPutMessage 方法最终存储到 CommitLog 中. 1234567891011121314151617public class TransactionalMessageServiceImpl implements TransactionalMessageService &#123; public CompletableFuture&lt;PutMessageResult&gt; asyncPrepareMessage(MessageExtBrokerInner messageInner) &#123; return transactionalMessageBridge.asyncPutHalfMessage(messageInner); &#125; public CompletableFuture&lt;PutMessageResult&gt; asyncPutHalfMessage(MessageExtBrokerInner messageInner) &#123; return store.asyncPutMessage(parseHalfMessageInner(messageInner)); &#125; private MessageExtBrokerInner parseHalfMessageInner(MessageExtBrokerInner msgInner) &#123; MessageAccessor.putProperty(msgInner, MessageConst.PROPERTY_REAL_TOPIC, msgInner.getTopic()); // 将真正的事务Topic存储到REAL_TOPIC属性中 MessageAccessor.putProperty(msgInner, MessageConst.PROPERTY_REAL_QUEUE_ID, String.valueOf(msgInner.getQueueId())); msgInner.setSysFlag(MessageSysFlag.resetTransactionValue(msgInner.getSysFlag(), MessageSysFlag.TRANSACTION_NOT_TYPE)); msgInner.setTopic(TransactionalMessageUtil.buildHalfTopic()); // Topic换成RMQ_SYS_TRANS_HALF_TOPIC msgInner.setQueueId(0); msgInner.setPropertiesString(MessageDecoder.messageProperties2String(msgInner.getProperties())); return msgInner; &#125;&#125; 最终通过 RequestCode.END_TRANSACTION 编码关联调用 EndTransactionProcessor 的 processRequest 方法,不论是是 COMMIT 还是 ROLLBACK 都将消息从 RMQ_SYS_TRANS_HALF_TOPIC 队列中查询出,若是 COMMIT 则将从 RMQ_SYS_TRANS_HALF_TOPIC 队列中查询的消息真正存储到其真实的Topic队列中,然后成功则再在 RMQ_SYS_TRANS_OP_HALF_TOPIC 队列中添加一条对应的消息标识该Half消息被删除.若为 ROLLBACK 则直接在 RMQ_SYS_TRANS_OP_HALF_TOPIC 队列中添加一条对应的消标识事务结束.开源版本进行了阉割,不会走回查逻辑. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class EndTransactionProcessor extends AsyncNettyRequestProcessor implements NettyRequestProcessor &#123; public RemotingCommand processRequest(ChannelHandlerContext ctx, RemotingCommand request) throws RemotingCommandException &#123; final RemotingCommand response = RemotingCommand.createResponseCommand(null); final EndTransactionRequestHeader requestHeader = (EndTransactionRequestHeader)request.decodeCommandCustomHeader(EndTransactionRequestHeader.class); if (BrokerRole.SLAVE == brokerController.getMessageStoreConfig().getBrokerRole()) &#123; response.setCode(ResponseCode.SLAVE_NOT_AVAILABLE); return response; // 若当前节点是从节点 &#125; OperationResult result = new OperationResult(); if (MessageSysFlag.TRANSACTION_COMMIT_TYPE == requestHeader.getCommitOrRollback()) &#123; result = this.brokerController.getTransactionalMessageService().commitMessage(requestHeader); if (result.getResponseCode() == ResponseCode.SUCCESS) &#123; RemotingCommand res = checkPrepareMessage(result.getPrepareMessage(), requestHeader); if (res.getCode() == ResponseCode.SUCCESS) &#123; MessageExtBrokerInner msgInner = endMessageTransaction(result.getPrepareMessage()); msgInner.setSysFlag(MessageSysFlag.resetTransactionValue(msgInner.getSysFlag(), requestHeader.getCommitOrRollback())); msgInner.setQueueOffset(requestHeader.getTranStateTableOffset()); msgInner.setPreparedTransactionOffset(requestHeader.getCommitLogOffset()); msgInner.setStoreTimestamp(result.getPrepareMessage().getStoreTimestamp()); MessageAccessor.clearProperty(msgInner, MessageConst.PROPERTY_TRANSACTION_PREPARED); // 将事务消息TRAN_MSG标记移除 RemotingCommand sendResult = sendFinalMessage(msgInner);// 将从RMQ_SYS_TRANS_HALF_TOPIC队列中查询的消息真正存储到其真实的Topic队列中 if (sendResult.getCode() == ResponseCode.SUCCESS) &#123;// 存储成功则在RMQ_SYS_TRANS_OP_HALF_TOPIC队列中添加对应的消息 this.brokerController.getTransactionalMessageService().deletePrepareMessage(result.getPrepareMessage()); &#125; return sendResult; &#125; return res; &#125; &#125; else if (MessageSysFlag.TRANSACTION_ROLLBACK_TYPE == requestHeader.getCommitOrRollback()) &#123; result = this.brokerController.getTransactionalMessageService().rollbackMessage(requestHeader); if (result.getResponseCode() == ResponseCode.SUCCESS) &#123; RemotingCommand res = checkPrepareMessage(result.getPrepareMessage(), requestHeader); if (res.getCode() == ResponseCode.SUCCESS) &#123;// 成功则在RMQ_SYS_TRANS_OP_HALF_TOPIC队列中添加对应的消息 this.brokerController.getTransactionalMessageService().deletePrepareMessage(result.getPrepareMessage()); &#125; return res; &#125; &#125; response.setCode(result.getResponseCode()); response.setRemark(result.getResponseRemark()); return response; &#125;&#125;public class TransactionalMessageServiceImpl implements TransactionalMessageService &#123; public OperationResult commitMessage(EndTransactionRequestHeader requestHeader) &#123; return getHalfMessageByOffset(requestHeader.getCommitLogOffset()); &#125; public OperationResult rollbackMessage(EndTransactionRequestHeader requestHeader) &#123; return getHalfMessageByOffset(requestHeader.getCommitLogOffset()); &#125; private OperationResult getHalfMessageByOffset(long commitLogOffset) &#123; OperationResult response = new OperationResult(); MessageExt messageExt = this.transactionalMessageBridge.lookMessageByOffset(commitLogOffset); if (messageExt != null) &#123; response.setPrepareMessage(messageExt); response.setResponseCode(ResponseCode.SUCCESS); &#125; else &#123; response.setResponseCode(ResponseCode.SYSTEM_ERROR); response.setResponseRemark(&quot;Find prepared transaction message failed&quot;); &#125; return response; &#125;&#125; 在 BrokerController 的 initialTransaction() 方法中会初始化事务消息检查类TransactionalMessageCheckService ,该类是一个线程类,在 BrokerController 的 start 方法中通过 startProcessorByHa 方法开启事务消息检查线程.若已经超过最大回查次数,则将消息添加到 TRANS_CHECK_MAXTIME_TOPIC 队列中,若需要检查则将消息写回 RMQ_SYS_TRANS_HALF_TOPIC 队列中防止再次失败,然后调用 AbstractTransactionalMessageCheckListener 的 resolveHalfMsg 方法检查消息. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130public class TransactionalMessageCheckService extends ServiceThread &#123; public void run() &#123; // 默认60s long checkInterval = brokerController.getBrokerConfig().getTransactionCheckInterval(); while (!this.isStopped()) &#123; this.waitForRunning(checkInterval); &#125; &#125; protected void waitForRunning(long interval) &#123; if (hasNotified.compareAndSet(true, false)) &#123; this.onWaitEnd(); return; &#125; waitPoint.reset(); try &#123; waitPoint.await(interval, TimeUnit.MILLISECONDS); &#125; catch (InterruptedException e) &#123; &#125; finally &#123; hasNotified.set(false); this.onWaitEnd(); &#125; &#125; protected void onWaitEnd() &#123; long timeout = brokerController.getBrokerConfig().getTransactionTimeOut(); // 获取超时时间6s int checkMax = brokerController.getBrokerConfig().getTransactionCheckMax(); // 获取最大回查次数15 long begin = System.currentTimeMillis(); this.brokerController.getTransactionalMessageService().check(timeout, checkMax, this.brokerController.getTransactionalMessageCheckListener()); &#125;&#125;public class TransactionalMessageServiceImpl implements TransactionalMessageService &#123; public void check(long transactionTimeout, int transactionCheckMax, AbstractTransactionalMessageCheckListener listener) &#123; try &#123; String topic = TopicValidator.RMQ_SYS_TRANS_HALF_TOPIC; // RMQ_SYS_TRANS_HALF_TOPIC Set&lt;MessageQueue&gt; msgQueues = transactionalMessageBridge.fetchMessageQueues(topic); if (msgQueues == null || msgQueues.size() == 0) &#123; return; &#125; for (MessageQueue messageQueue : msgQueues) &#123; long startTime = System.currentTimeMillis(); MessageQueue opQueue = getOpQueue(messageQueue); long halfOffset = transactionalMessageBridge.fetchConsumeOffset(messageQueue); long opOffset = transactionalMessageBridge.fetchConsumeOffset(opQueue); if (halfOffset &lt; 0 || opOffset &lt; 0) &#123; continue; &#125; List&lt;Long&gt; doneOpOffset = new ArrayList&lt;&gt;(); HashMap&lt;Long, Long&gt; removeMap = new HashMap&lt;&gt;(); PullResult pullResult = fillOpRemoveMap(removeMap, opQueue, opOffset, halfOffset, doneOpOffset); if (null == pullResult) &#123; continue; &#125; int getMessageNullCount = 1; long newOffset = halfOffset; long i = halfOffset; while (true) &#123; if (System.currentTimeMillis() - startTime &gt; MAX_PROCESS_TIME_LIMIT) &#123; break; &#125; if (removeMap.containsKey(i)) &#123; Long removedOpOffset = removeMap.remove(i); doneOpOffset.add(removedOpOffset); &#125; else &#123; GetResult getResult = getHalfMsg(messageQueue, i); // 消费RMQ_SYS_TRANS_HALF_TOPIC队列中的事务消息 MessageExt msgExt = getResult.getMsg(); if (msgExt == null) &#123; if (getMessageNullCount++ &gt; MAX_RETRY_COUNT_WHEN_HALF_NULL) &#123; break; &#125; if (getResult.getPullResult().getPullStatus() == PullStatus.NO_NEW_MSG) &#123; break; &#125; else &#123; i = getResult.getPullResult().getNextBeginOffset(); newOffset = i; continue; &#125; &#125; if (needDiscard(msgExt, transactionCheckMax) || needSkip(msgExt)) &#123;// 若已经超过最大回查次数了 listener.resolveDiscardMsg(msgExt); // 将消息添加到TRANS_CHECK_MAXTIME_TOPIC队列中 newOffset = i + 1; i++; continue; &#125; if (msgExt.getStoreTimestamp() &gt;= startTime) &#123; break; &#125; long valueOfCurrentMinusBorn = System.currentTimeMillis() - msgExt.getBornTimestamp(); long checkImmunityTime = transactionTimeout; String checkImmunityTimeStr = msgExt.getUserProperty(MessageConst.PROPERTY_CHECK_IMMUNITY_TIME_IN_SECONDS); if (null != checkImmunityTimeStr) &#123; checkImmunityTime = getImmunityTime(checkImmunityTimeStr, transactionTimeout); if (valueOfCurrentMinusBorn &lt; checkImmunityTime) &#123; if (checkPrepareQueueOffset(removeMap, doneOpOffset, msgExt)) &#123; newOffset = i + 1; i++; continue; &#125; &#125; &#125; else &#123; if ((0 &lt;= valueOfCurrentMinusBorn) &amp;&amp; (valueOfCurrentMinusBorn &lt; checkImmunityTime)) &#123; break; &#125; &#125; List&lt;MessageExt&gt; opMsg = pullResult.getMsgFoundList(); boolean isNeedCheck = (opMsg == null &amp;&amp; valueOfCurrentMinusBorn &gt; checkImmunityTime) || (opMsg != null &amp;&amp; (opMsg.get(opMsg.size() - 1).getBornTimestamp() - startTime &gt; transactionTimeout)) || (valueOfCurrentMinusBorn &lt;= -1); if (isNeedCheck) &#123; if (!putBackHalfMsgQueue(msgExt, i)) &#123; // 写回RMQ_SYS_TRANS_HALF_TOPIC队列中 continue; &#125; listener.resolveHalfMsg(msgExt); // 真正检查消息的地方,回调客户端checkLocalTransaction方法 &#125; else &#123; pullResult = fillOpRemoveMap(removeMap, opQueue, pullResult.getNextBeginOffset(), halfOffset, doneOpOffset); continue; &#125; &#125; newOffset = i + 1; i++; &#125; if (newOffset != halfOffset) &#123; transactionalMessageBridge.updateConsumeOffset(messageQueue, newOffset); &#125; long newOpOffset = calculateOpOffset(doneOpOffset, opOffset); if (newOpOffset != opOffset) &#123; transactionalMessageBridge.updateConsumeOffset(opQueue, newOpOffset); &#125; &#125; &#125; &#125;&#125; 检查消息是异步执行的,首先还原当前消息真正的Topic,然后通过 Broker2Client 的 checkProducerTransactionState 方法中通过 RequestCode.CHECK_TRANSACTION_STATE 关联调用 ClientRemotingProcessor 的 ClientRemotingProcessor 方法. 123456789101112131415161718192021222324252627282930313233343536373839public abstract class AbstractTransactionalMessageCheckListener &#123; public void resolveHalfMsg(final MessageExt msgExt) &#123; executorService.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; sendCheckMessage(msgExt); &#125; catch (Exception e) &#123; &#125; &#125; &#125;); &#125; public void sendCheckMessage(MessageExt msgExt) throws Exception &#123; CheckTransactionStateRequestHeader checkTransactionStateRequestHeader = new CheckTransactionStateRequestHeader(); checkTransactionStateRequestHeader.setCommitLogOffset(msgExt.getCommitLogOffset()); checkTransactionStateRequestHeader.setOffsetMsgId(msgExt.getMsgId()); checkTransactionStateRequestHeader.setMsgId(msgExt.getUserProperty(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX)); checkTransactionStateRequestHeader.setTransactionId(checkTransactionStateRequestHeader.getMsgId()); checkTransactionStateRequestHeader.setTranStateTableOffset(msgExt.getQueueOffset()); msgExt.setTopic(msgExt.getUserProperty(MessageConst.PROPERTY_REAL_TOPIC)); // 真正的Topic msgExt.setQueueId(Integer.parseInt(msgExt.getUserProperty(MessageConst.PROPERTY_REAL_QUEUE_ID))); msgExt.setStoreSize(0); String groupId = msgExt.getProperty(MessageConst.PROPERTY_PRODUCER_GROUP); Channel channel = brokerController.getProducerManager().getAvaliableChannel(groupId); if (channel != null) &#123; brokerController.getBroker2Client().checkProducerTransactionState(groupId, channel, checkTransactionStateRequestHeader, msgExt); &#125; &#125;&#125;public class Broker2Client &#123; public void checkProducerTransactionState(final String group, final Channel channel, final CheckTransactionStateRequestHeader requestHeader, final MessageExt messageExt) throws Exception &#123; RemotingCommand request = RemotingCommand.createRequestCommand(RequestCode.CHECK_TRANSACTION_STATE, requestHeader); request.setBody(MessageDecoder.encode(messageExt, false)); try &#123; this.brokerController.getRemotingServer().invokeOneway(channel, request, 10); &#125; catch (Exception e) &#123; &#125; &#125;&#125; 首先调用自定义 TransactionListener 的 checkLocalTransaction 方法,然后调用 MQClientAPIImpl 的 endTransactionOneway 方法.最终又调用 EndTransactionProcessor 的 processRequest 方法. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596public class ClientRemotingProcessor extends AsyncNettyRequestProcessor implements NettyRequestProcessor &#123; public class ClientRemotingProcessor extends AsyncNettyRequestProcessor implements NettyRequestProcessor &#123; public RemotingCommand checkTransactionState(ChannelHandlerContext ctx, RemotingCommand request) throws RemotingCommandException &#123; final CheckTransactionStateRequestHeader requestHeader = (CheckTransactionStateRequestHeader) request.decodeCommandCustomHeader(CheckTransactionStateRequestHeader.class); final ByteBuffer byteBuffer = ByteBuffer.wrap(request.getBody()); final MessageExt messageExt = MessageDecoder.decode(byteBuffer); if (messageExt != null) &#123; if (StringUtils.isNotEmpty(this.mqClientFactory.getClientConfig().getNamespace())) &#123; messageExt.setTopic(NamespaceUtil.withoutNamespace(messageExt.getTopic(), this.mqClientFactory.getClientConfig().getNamespace())); &#125; String transactionId = messageExt.getProperty(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX); if (null != transactionId &amp;&amp; !&quot;&quot;.equals(transactionId)) &#123; messageExt.setTransactionId(transactionId); &#125; final String group = messageExt.getProperty(MessageConst.PROPERTY_PRODUCER_GROUP); if (group != null) &#123; MQProducerInner producer = this.mqClientFactory.selectProducer(group); if (producer != null) &#123; final String addr = RemotingHelper.parseChannelRemoteAddr(ctx.channel()); producer.checkTransactionState(addr, messageExt, requestHeader); &#125; &#125; &#125; return null; &#125; &#125;&#125;public class DefaultMQProducerImpl implements MQProducerInner &#123; public void checkTransactionState(final String addr, final MessageExt msg, final CheckTransactionStateRequestHeader header) &#123; Runnable request = new Runnable() &#123; private final String brokerAddr = addr; private final MessageExt message = msg; private final CheckTransactionStateRequestHeader checkRequestHeader = header; private final String group = DefaultMQProducerImpl.this.defaultMQProducer.getProducerGroup(); @Override public void run() &#123; TransactionCheckListener transactionCheckListener = DefaultMQProducerImpl.this.checkListener(); TransactionListener transactionListener = getCheckListener(); if (transactionCheckListener != null || transactionListener != null) &#123; LocalTransactionState localTransactionState = LocalTransactionState.UNKNOW; Throwable exception = null; try &#123; if (transactionCheckListener != null) &#123; localTransactionState = transactionCheckListener.checkLocalTransactionState(message); &#125; else if (transactionListener != null) &#123; localTransactionState = transactionListener.checkLocalTransaction(message); &#125; &#125; catch (Throwable e) &#123; exception = e; &#125; this.processTransactionState(localTransactionState, group, exception); &#125; &#125; private void processTransactionState(final LocalTransactionState localTransactionState, final String producerGroup, final Throwable exception) &#123; final EndTransactionRequestHeader thisHeader = new EndTransactionRequestHeader(); thisHeader.setCommitLogOffset(checkRequestHeader.getCommitLogOffset()); thisHeader.setProducerGroup(producerGroup); thisHeader.setTranStateTableOffset(checkRequestHeader.getTranStateTableOffset()); thisHeader.setFromTransactionCheck(true); String uniqueKey = message.getProperties().get(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX); if (uniqueKey == null) &#123; uniqueKey = message.getMsgId(); &#125; thisHeader.setMsgId(uniqueKey); thisHeader.setTransactionId(checkRequestHeader.getTransactionId()); switch (localTransactionState) &#123; case COMMIT_MESSAGE: thisHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_COMMIT_TYPE); break; case ROLLBACK_MESSAGE: thisHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_ROLLBACK_TYPE); break; case UNKNOW: thisHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_NOT_TYPE); break; default: break; &#125; String remark = null; if (exception != null) &#123; remark = &quot;checkLocalTransactionState Exception: &quot; + RemotingHelper.exceptionSimpleDesc(exception); &#125; try &#123; DefaultMQProducerImpl.this.mQClientFactory.getMQClientAPIImpl().endTransactionOneway(brokerAddr, thisHeader, remark, 3000); &#125; catch (Exception e) &#123; &#125; &#125; &#125;; this.checkExecutor.submit(request); &#125;&#125;public void endTransactionOneway(final String addr, final EndTransactionRequestHeader requestHeader, final String remark, final long timeoutMillis) throws RemotingException, MQBrokerException, InterruptedException &#123; RemotingCommand request = RemotingCommand.createRequestCommand(RequestCode.END_TRANSACTION, requestHeader); request.setRemark(remark); this.remotingClient.invokeOneway(addr, request, timeoutMillis);&#125; 延迟消息 延迟消息写入时会将延迟消息转为写入到SCHEDULE_TOPIC_XXXX的Topic中,系统内置的该Topic有 18 个队列,对应18个延迟级别. ScheduleMessageService 会每隔1s 执行一次 DeliverDelayedMessageTimerTask.executeOnTimeup 任务,将消息从延迟队列中写入正常Topic中. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107public class ScheduleMessageService extends ConfigManager &#123; private static final long FIRST_DELAY_TIME = 1000L; private static final long DELAY_FOR_A_WHILE = 100L; private static final long DELAY_FOR_A_PERIOD = 10000L; public void start() &#123; // 延迟消息服务的启动方法 if (started.compareAndSet(false, true)) &#123; this.timer = new Timer(&quot;ScheduleMessageTimerThread&quot;, true); for (Map.Entry&lt;Integer, Long&gt; entry : this.delayLevelTable.entrySet()) &#123; Integer level = entry.getKey(); Long timeDelay = entry.getValue(); Long offset = this.offsetTable.get(level); if (null == offset) &#123; offset = 0L; &#125; if (timeDelay != null) &#123;//定时执行延迟消息处理任务 this.timer.schedule(new DeliverDelayedMessageTimerTask(level, offset), FIRST_DELAY_TIME); &#125; &#125; this.timer.scheduleAtFixedRate(new TimerTask() &#123; //每隔10秒,将延迟消息持久化到硬盘中. @Override public void run() &#123; try &#123; if (started.get()) ScheduleMessageService.this.persist(); &#125; catch (Throwable e) &#123; &#125; &#125; &#125;, 10000, this.defaultMessageStore.getMessageStoreConfig().getFlushDelayOffsetInterval()); &#125; &#125;&#125;class DeliverDelayedMessageTimerTask extends TimerTask &#123; public void run() &#123; try &#123; if (isStarted()) &#123; this.executeOnTimeup(); &#125; &#125; catch (Exception e) &#123; ScheduleMessageService.this.timer.schedule(new DeliverDelayedMessageTimerTask(this.delayLevel, this.offset), DELAY_FOR_A_PERIOD); &#125; &#125; public void executeOnTimeup() &#123; // 拿到延迟级别对应的队列 ConsumeQueue cq = ScheduleMessageService.this.defaultMessageStore.findConsumeQueue(TopicValidator.RMQ_SYS_SCHEDULE_TOPIC, delayLevel2QueueId(delayLevel)); long failScheduleOffset = offset; if (cq != null) &#123; SelectMappedBufferResult bufferCQ = cq.getIndexBuffer(this.offset); if (bufferCQ != null) &#123; try &#123; long nextOffset = offset; int i = 0; ConsumeQueueExt.CqExtUnit cqExtUnit = new ConsumeQueueExt.CqExtUnit(); // 遍历每个延迟队列的消息 for (; i &lt; bufferCQ.getSize(); i += ConsumeQueue.CQ_STORE_UNIT_SIZE) &#123; long offsetPy = bufferCQ.getByteBuffer().getLong(); int sizePy = bufferCQ.getByteBuffer().getInt(); long tagsCode = bufferCQ.getByteBuffer().getLong(); if (cq.isExtAddr(tagsCode)) &#123; if (cq.getExt(tagsCode, cqExtUnit)) &#123; tagsCode = cqExtUnit.getTagsCode(); &#125; &#125; long now = System.currentTimeMillis(); long deliverTimestamp = this.correctDeliverTimestamp(now, tagsCode); nextOffset = offset + (i / ConsumeQueue.CQ_STORE_UNIT_SIZE); long countdown = deliverTimestamp - now; if (countdown &lt;= 0) &#123; //把每个延迟消息封装成一个MessageExt MessageExt msgExt = ScheduleMessageService.this.defaultMessageStore.lookMessageByOffset(offsetPy, sizePy); if (msgExt != null) &#123; try &#123; MessageExtBrokerInner msgInner = this.messageTimeup(msgExt); if (TopicValidator.RMQ_SYS_TRANS_HALF_TOPIC.equals(msgInner.getTopic())) &#123; continue; &#125; //将延迟消息写入正常消息队列,这样就能被消费者正常消费了. PutMessageResult putMessageResult = ScheduleMessageService.this.writeMessageStore.putMessage(msgInner); if (putMessageResult != null &amp;&amp; putMessageResult.getPutMessageStatus() == PutMessageStatus.PUT_OK) &#123; continue; &#125; else &#123; ScheduleMessageService.this.timer.schedule(new DeliverDelayedMessageTimerTask(this.delayLevel, nextOffset), DELAY_FOR_A_PERIOD); ScheduleMessageService.this.updateOffset(this.delayLevel, nextOffset); return; &#125; &#125; catch (Exception e) &#123; &#125; &#125; &#125; else &#123; ScheduleMessageService.this.timer.schedule(new DeliverDelayedMessageTimerTask(this.delayLevel, nextOffset), countdown); ScheduleMessageService.this.updateOffset(this.delayLevel, nextOffset); return; &#125; &#125; // end of for nextOffset = offset + (i / ConsumeQueue.CQ_STORE_UNIT_SIZE); ScheduleMessageService.this.timer.schedule(new DeliverDelayedMessageTimerTask(this.delayLevel, nextOffset), DELAY_FOR_A_WHILE); ScheduleMessageService.this.updateOffset(this.delayLevel, nextOffset); return; &#125; finally &#123; bufferCQ.release(); &#125; &#125; else &#123; // end of if (bufferCQ != null) long cqMinOffset = cq.getMinOffsetInQueue(); if (offset &lt; cqMinOffset) &#123; failScheduleOffset = cqMinOffset; &#125; &#125; &#125; // end of if (cq != null) ScheduleMessageService.this.timer.schedule(new DeliverDelayedMessageTimerTask(this.delayLevel, failScheduleOffset), DELAY_FOR_A_WHILE); &#125;&#125;","tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"http://example.com/tags/RocketMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RocketMQ","slug":"工具和中间件/消息队列/RocketMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RocketMQ/"}]},{"title":"RocketMQ-基础","date":"2019-04-23T02:08:20.000Z","path":"blog/工具和中间件/消息队列/RocketMQ/RocketMQ-基础/","text":"介绍Apache RocketMQ作为阿里开源的一款高性能、高吞吐量的分布式消息中间件. RocketMQ架构 生产者-Producer消息发布的角色,支持分布式集群方式部署.Producer 通过MQ的负载均衡模块 选择相应的 Broker集群队列 进行消息投递,投递的过程支持 快速失败 并且 低延迟. Producer启动后会 随机选择 NameServer集群中 其中一个节点建立长连接,定期从NameServer获取 Topic路由信息,并判断 当前订阅Topic存在哪些Broker上, 轮询从队列列表中选择一个队列,并向 提供Topic服务的队列所在的Master建立长连接,且 定时向Master发送心跳. Producer 完全无状态,可集群部署. 消费者-Consumer消息消费的角色,支持分布式集群方式部署.支持以 Push推,Pull拉两种模式对消息进行消费.同时支持集群方式和广播方式消费,提供实时消息订阅机制. Consumer启动后会随机选择NameServer集群中其中一个节点建立长连接,定期从NameServer获取 Topic路由信息,并判断当前订阅Topic存在哪些Broker上,并向提供Topic服务的Master、Slave建立长连接,且定时向Master、Slave发送心跳.Consumer既可从Master订阅消息,也可从Slave订阅消息,消费者在向Master拉取消息时,Master服务器会根据拉取偏移量与最大偏移量的距离,判断是否读老消息产生读I&#x2F;O,以及从服务器是否可读等因素建议下一次是从Master还是Slave拉取. NameServerNameServer一个非常简单的 Topic路由注册中心,支持Broker动态注册与发现.通常也是集群方式部署,各实例间不信息通讯. Broker 向每台NameServer注册自己的路由信息,故每个NameServer实例上都保存一份完整的路由信息.若当某个NameServer因某种原因下线,Broker仍可向其它NameServer同步其路由信息,Producer和Consumer仍可动态感知Broker路由信息. NameServer 主要包括 Broker管理和路由信息管理两个功能： Broker管理： NameServer 接受Broker集群的注册信息且保存作为路由信息基本数据.提供心跳检测机制,检查Broker是否存活； 路由信息管理,每个 NameServer 将保存关于Broker集群的整个路由信息和用于客户端查询的队列信息.然后 Producer 和 Conumser 通过 NameServer 可知道整个Broker集群的路由信息,从而进行消息的投递和消费. NameServer是一个几乎无状态节点,可集群部署,节点之间无任何信息同步.NameServer启动后监听端口,等待Broker、Producer、Consumer连接,相当于一个路由控制中心. BrokerServerBroker主要负责消息的存储、投递和查询以及服务高可用保证,为了实现这些功能,Broker包含了以下几个重要子模块. Remoting Module ：整个Broker的实体,负责处理来自clients端的请求. Client Manager ：负责管理Producer和Consumer客户端和维护Consumer的Topic订阅信息 Store Service ：提供方便简单的API接口处理消息存储到物理硬盘和查询功能. HA Service ：高可用服务,提供 Master Broker 和 Slave Broker 之间的数据同步功能. Index Service ：根据特定Message key对投递到Broker的消息进行索引服务,以提供消息的快速查询. Broker分为Master与Slave ,一个Master可对应多个Slave,一个Slave只能对应一个Master,Master与Slave对应关系通过指定相同的BrokerName不同BrokerId 来定义, BrokerId为0表示Master ,非0表示Slave .Master可部署多个.每个Broker 与NameServer集群中的所有节点建立长连接,定时注册Topic信息到所有NameServer. 虽然支持一Master多Slave,但只有 BrokerId=1 的从服务器才会参与消息读负载.Broker启动后跟所有的NameServer保持长连接,定时发送心跳包.心跳包中包含当前Broker如IP、端口等信息,以及存储所有Topic信息.注册成功后NameServer集群中就有 Topic与Broker映射关系. RocketMQ使用基本样例生产者发送消息有同步发送、异步发送和单向发送三种方式:单向发送使用 sendOneway 方法来发送消息,该方法无返回值无回调. 12345678DefaultMQProducer producer = new DefaultMQProducer(&quot;ProducerGroupName&quot;);producer.setNamesrvAddr(&quot;localhost:9876&quot;);producer.start();for (int i = 0; i &lt; 20; i++) &#123; Message msg = new Message(&quot;TopicTest&quot;, &quot;TagA&quot;, &quot;OrderID188&quot;, &quot;Hello world&quot;.getBytes(RemotingHelper.DEFAULT_CHARSET)); producer.sendOneway(msg);&#125;producer.shutdown(); 同步发送使用 send 方法同步传递消息,消息会发给集群中的一个Broker节点 123456789DefaultMQProducer producer = new DefaultMQProducer(&quot;ProducerGroupName&quot;);producer.setNamesrvAddr(&quot;localhost:9876&quot;);producer.start();for (int i = 0; i &lt; 20; i++) &#123; Message msg = new Message(&quot;TopicTest&quot;, &quot;TagA&quot;, &quot;OrderID188&quot;, &quot;Hello world&quot;.getBytes(RemotingHelper.DEFAULT_CHARSET)); SendResult sendResult = producer.send(msg); System.out.printf(&quot;%s%n&quot;, sendResult);&#125;producer.shutdown(); 由于是异步发送,这里引入了CountDownLatch,保证所有Producer发送消息的回调方法都执行完了再停止Producer服务. 12345678910111213141516171819202122232425DefaultMQProducer producer = new DefaultMQProducer(&quot;Jodie_Daily_test&quot;);producer.setNamesrvAddr(&quot;localhost:9876&quot;);producer.start();producer.setRetryTimesWhenSendAsyncFailed(0);int messageCount = 100;final CountDownLatch countDownLatch = new CountDownLatch(messageCount);for (int i = 0; i &lt; messageCount; i++) &#123; final int index = i; Message msg = new Message(&quot;TopicTest&quot;, &quot;TagA&quot;, &quot;OrderID188&quot;, &quot;Hello world&quot;.getBytes(RemotingHelper.DEFAULT_CHARSET)); producer.send(msg, new SendCallback() &#123; @Override public void onSuccess(SendResult sendResult) &#123; countDownLatch.countDown(); System.out.printf(&quot;%-10d OK %s %n&quot;, index, sendResult.getMsgId()); &#125; @Override public void onException(Throwable e) &#123; countDownLatch.countDown(); System.out.printf(&quot;%-10d Exception %s %n&quot;, index, e); e.printStackTrace(); &#125; &#125;);&#125;countDownLatch.await(5, TimeUnit.SECONDS);producer.shutdown(); 消费者消费消息有两种模式：消费者主动去Broker上拉取消息的拉模式；消费者等待Broker把消息推送过来的推模式. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394public class PullConsumer &#123; private static final Map&lt;MessageQueue, Long&gt; OFFSE_TABLE = new HashMap&lt;MessageQueue, Long&gt;(); public static void main(String[] args) throws MQClientException &#123; DefaultMQPullConsumer consumer = new DefaultMQPullConsumer(&quot;please_rename_unique_group_name_5&quot;); consumer.setNamesrvAddr(&quot;localhost:9876&quot;); consumer.start(); Set&lt;MessageQueue&gt; mqs = consumer.fetchSubscribeMessageQueues(&quot;TopicTest&quot;); for (MessageQueue mq : mqs) &#123; System.out.printf(&quot;Consume from the queue: %s%n&quot;, mq); SINGLE_MQ: while (true) &#123; try &#123; PullResult pullResult = consumer.pullBlockIfNotFound(mq, null, getMessageQueueOffset(mq), 32); System.out.printf(&quot;%s%n&quot;, pullResult); putMessageQueueOffset(mq, pullResult.getNextBeginOffset()); if (pullResult.getMsgFoundList() != null) &#123; for (MessageExt messageExt : pullResult.getMsgFoundList()) &#123; System.out.println(&quot;messageExt：&quot; + messageExt); &#125; &#125; switch (pullResult.getPullStatus()) &#123; case FOUND: break; case NO_MATCHED_MSG: break; case NO_NEW_MSG: break SINGLE_MQ; case OFFSET_ILLEGAL: break; default: break; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; consumer.shutdown(); &#125; private static long getMessageQueueOffset(MessageQueue mq) &#123; Long offset = OFFSE_TABLE.get(mq); if (offset != null) &#123; return offset; &#125; return 0; &#125; private static void putMessageQueueOffset(MessageQueue mq, long offset) &#123; OFFSE_TABLE.put(mq, offset); &#125;&#125;public class LitePullConsumerAssign &#123; public static volatile boolean running = true; public static void main(String[] args) throws Exception &#123; DefaultLitePullConsumer litePullConsumer = new DefaultLitePullConsumer(&quot;please_rename_unique_group_name&quot;); litePullConsumer.setNamesrvAddr(&quot;localhost:9876&quot;); litePullConsumer.setAutoCommit(false); litePullConsumer.start(); Collection&lt;MessageQueue&gt; mqSet = litePullConsumer.fetchMessageQueues(&quot;TopicTest&quot;); List&lt;MessageQueue&gt; list = new ArrayList&lt;&gt;(mqSet); List&lt;MessageQueue&gt; assignList = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; list.size(); i++) &#123; assignList.add(list.get(i)); &#125; litePullConsumer.assign(assignList); litePullConsumer.seek(assignList.get(0), 10); try &#123; while (running) &#123; List&lt;MessageExt&gt; messageExts = litePullConsumer.poll(); System.out.printf(&quot;%s %n&quot;, messageExts); litePullConsumer.commitSync(); &#125; &#125; finally &#123; litePullConsumer.shutdown(); &#125; &#125;&#125;public class LitePullConsumerSubscribe &#123; public static volatile boolean running = true; public static void main(String[] args) throws Exception &#123; DefaultLitePullConsumer litePullConsumer = new DefaultLitePullConsumer(&quot;lite_pull_consumer_test&quot;); litePullConsumer.setNamesrvAddr(&quot;localhost:9876&quot;); litePullConsumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET); litePullConsumer.subscribe(&quot;TopicTest&quot;, &quot;*&quot;); litePullConsumer.start(); try &#123; while (running) &#123; List&lt;MessageExt&gt; messageExts = litePullConsumer.poll(); System.out.printf(&quot;%s%n&quot;, messageExts); &#125; &#125; finally &#123; litePullConsumer.shutdown(); &#125; &#125;&#125; 消费者推模式 123456789101112DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;CID_JODIE_1&quot;);consumer.setNamesrvAddr(&quot;localhost:9876&quot;);consumer.subscribe(&quot;TopicTest&quot;, &quot;*&quot;);consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; System.out.printf(&quot;%s Receive New Messages: %s %n&quot;, Thread.currentThread().getName(), msgs); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125;&#125;);consumer.start(); 顺序消息发送者端默认情况下,消息发送者会采取 Round Robin轮询方式把消息发送到不同MessageQueue分区队列,消费者消费时也从多个MessageQueue上拉取消息,该情况下消息是不能保证顺序的.仅当一组有序的消息发送到同一个MessageQueue时,才能利用MessageQueue先进先出的特性保证这一组消息有序.而Broker中一个队列内的消息是可以保证有序的. 消费者端消费者会从多个消息队列取消息.虽然每个消息队列消息是有序的,但多个队列之间消息仍是乱序的.消费者端要保证消息有序,就需要按队列一个一个来取消息,即取完一个队列的消息后,再去取下一个队列的消息.而给Consumer注入的 MessageListenerOrderly 对象,在RocketMQ内部就会通过锁队列的方式保证消息是一个一个队列来取的. MessageListenerConcurrently 消息监听器则不会锁队列,每次都是从多个Message中取一批数据,默认不超过32条,因此也无法保证消息有序. 发送者端: 12345678910111213141516171819DefaultMQProducer producer = new DefaultMQProducer(&quot;please_rename_unique_group_name&quot;);producer.setNamesrvAddr(&quot;localhost:9876&quot;);producer.start();for (int i = 0; i &lt; 10; i++) &#123; int orderId = i; for (int j = 0; j &lt;= 5; j++) &#123; Message msg = new Message(&quot;OrderTopicTest&quot;, &quot;order_&quot; + orderId, &quot;KEY&quot; + orderId, (&quot;order_&quot; + orderId + &quot; step &quot; + j).getBytes(RemotingHelper.DEFAULT_CHARSET)); SendResult sendResult = producer.send(msg, new MessageQueueSelector() &#123; @Override public MessageQueue select(List&lt;MessageQueue&gt; mqs, Message msg, Object arg) &#123; Integer id = (Integer) arg; int index = id % mqs.size(); return mqs.get(index); &#125; &#125;, orderId); System.out.printf(&quot;%s%n&quot;, sendResult); &#125;&#125;producer.shutdown(); 消费者端: 123456789101112131415DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;please_rename_unique_group_name_3&quot;);consumer.setNamesrvAddr(&quot;localhost:9876&quot;);consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_LAST_OFFSET);consumer.subscribe(&quot;OrderTopicTest&quot;, &quot;*&quot;);consumer.registerMessageListener(new MessageListenerOrderly() &#123; @Override public ConsumeOrderlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeOrderlyContext context) &#123; context.setAutoCommit(true); for (MessageExt msg : msgs) &#123; System.out.println(&quot;收到消息内容 &quot; + new String(msg.getBody())); &#125; return ConsumeOrderlyStatus.SUCCESS; &#125;&#125;);consumer.start(); 广播消息在集群状态MessageModel.CLUSTERING 下,每条消息只会被同一个消费者组中的一个实例消费到.而广播模式则是把消息模式设置为 MessageModel.BROADCASTING ,将给所有订阅对应主题的消费者发送消息,而不管消费者是不是同一个消费者组. 12345678910111213DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;please_rename_unique_group_name_1&quot;);consumer.setNamesrvAddr(&quot;localhost:9876&quot;);consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_LAST_OFFSET);consumer.setMessageModel(MessageModel.BROADCASTING); // 将消息模式设置为BROADCASTINGconsumer.subscribe(&quot;TopicTest&quot;, &quot;*&quot;);consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; System.out.printf(&quot;%s Receive New Messages: %s %n&quot;, Thread.currentThread().getName(), msgs); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125;&#125;);consumer.start(); 延迟消息延迟时间的设置是在Message消息对象上设置一个延迟级别 setDelayTimeLevel(3) ,开源版RocketMQ中,对延迟消息并不支持任意时间的延迟设定,而是只支持18个固定的延迟级别,1到18分别对应 messageDelayLevel=1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h .这18个延迟级别也支持自行定义,不过一般情况下最好不要自定义修改. 12345678910DefaultMQProducer producer = new DefaultMQProducer(&quot;please_rename_unique_group_name&quot;); // 分组名称producer.setNamesrvAddr(&quot;localhost:9876&quot;);producer.start();for (int i = 0; i &lt; 2; i++) &#123; Message msg = new Message(&quot;TopicTest&quot;, &quot;TagA&quot;, (&quot;Hello RocketMQ &quot; + i).getBytes(RemotingHelper.DEFAULT_CHARSET)); // messageDelayLevel=1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h msg.setDelayTimeLevel(3); // 延时队列 SendResult sendResult = producer.send(msg);&#125;producer.shutdown(); 批量消息将多条消息合并成一个批量消息,一次发送出去,可减少网络IO,提升吞吐量.批量消息的使用有一定限制,这些消息 Topic和waitStoreMsgOK必须相同,且不能是延迟消息、事务消息等. 12345678910DefaultMQProducer producer = new DefaultMQProducer(&quot;BatchProducerGroupName&quot;);producer.setNamesrvAddr(&quot;localhost:9876&quot;);producer.start();String topic = &quot;BatchTest&quot;;List&lt;Message&gt; messages = new ArrayList&lt;&gt;();messages.add(new Message(topic, &quot;Tag&quot;, &quot;OrderID001&quot;, &quot;Hello world 0&quot;.getBytes()));messages.add(new Message(topic, &quot;Tag&quot;, &quot;OrderID002&quot;, &quot;Hello world 1&quot;.getBytes()));messages.add(new Message(topic, &quot;Tag&quot;, &quot;OrderID003&quot;, &quot;Hello world 2&quot;.getBytes()));producer.send(messages);producer.shutdown(); 若批量消息大于1MB 就不要用一个批次发送,而要拆分成多个批次消息发送.实际最大的限制是4194304字节约 4MB ； 123456789101112131415DefaultMQProducer producer = new DefaultMQProducer(&quot;BatchProducerGroupName&quot;);producer.setNamesrvAddr(&quot;localhost:9876&quot;);producer.start();String topic = &quot;BatchTest&quot;;List&lt;Message&gt; messages = new ArrayList&lt;&gt;(100 * 1000);for (int i = 0; i &lt; 100 * 1000; i++) &#123; messages.add(new Message(topic, &quot;Tag&quot;, &quot;OrderID&quot; + i, (&quot;Hello world &quot; + i).getBytes()));&#125;producer.send(messages);ListSplitter splitter = new ListSplitter(messages);while (splitter.hasNext()) &#123; List&lt;Message&gt; listItem = splitter.next(); producer.send(listItem);&#125;producer.shutdown(); 12345678910111213141516171819202122232425262728293031323334353637383940class ListSplitter implements Iterator&lt;List&lt;Message&gt;&gt; &#123; private final List&lt;Message&gt; messages; private int sizeLimit = 1000 * 1000; private int currIndex; public ListSplitter(List&lt;Message&gt; messages) &#123; this.messages = messages; &#125; @Override public boolean hasNext() &#123; return currIndex &lt; messages.size(); &#125; @Override public List&lt;Message&gt; next() &#123; int nextIndex = currIndex; int totalSize = 0; for (; nextIndex &lt; messages.size(); nextIndex++) &#123; Message message = messages.get(nextIndex); int tmpSize = message.getTopic().length() + message.getBody().length; Map&lt;String, String&gt; properties = message.getProperties(); for (Map.Entry&lt;String, String&gt; entry : properties.entrySet()) &#123; tmpSize += entry.getKey().length() + entry.getValue().length(); &#125; tmpSize = tmpSize + 20; //for log overhead if (tmpSize &gt; sizeLimit) &#123; if (nextIndex - currIndex == 0) &#123; nextIndex++; &#125; break; &#125; if (tmpSize + totalSize &gt; sizeLimit) &#123; break; &#125; else &#123; totalSize += tmpSize; &#125; &#125; List&lt;Message&gt; subList = messages.subList(currIndex, nextIndex); currIndex = nextIndex; return subList; &#125;&#125; 过滤消息可使用Message的 Tag属性来简单快速的过滤信息,TAG是RocketMQ中特有的一个消息属性,一个应用可以就用一个Topic,而应用中的不同业务就用TAG来区分. 1234567891011DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;please_rename_unique_group_name&quot;);consumer.setNamesrvAddr(&quot;localhost:9876&quot;);consumer.subscribe(&quot;TagFilterTest&quot;, &quot;TagA || TagC&quot;);consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; System.out.printf(&quot;%s Receive New Messages: %s %n&quot;, Thread.currentThread().getName(), msgs); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125;&#125;);consumer.start(); 一个消息只能有一个TAG ,不能满足一些比较复杂的场景. 可使用 SQL表达式来对消息进行过滤,但只有推模式的消费者可使用SQL过滤.拉模式是用不了的.RocketMQ只定义了一些基本语法来支持这个特性.也可很容易地扩展它. 数值比较： &gt;、&gt;=、&lt;、&lt;=、BETWEEN、= 字符比较： =、&lt;&gt;、IN、IS NULL、IS NOT NULL 逻辑符号： AND、OR、NOT 数值：123,3.1415；字符： &#39;abc&#39; ；必须用单引号包裹起来 特殊常量：NULL,布尔值TRUE或FALSE12345678910111213141516171819202122DefaultMQProducer producer = new DefaultMQProducer(&quot;please_rename_unique_group_name&quot;);producer.start();String[] tags = new String[]&#123;&quot;TagA&quot;, &quot;TagB&quot;, &quot;TagC&quot;&#125;;for (int i = 0; i &lt; 15; i++) &#123; Message msg = new Message(&quot;SqlFilterTest&quot;, tags[i % tags.length], (&quot;Hello RocketMQ &quot; + i).getBytes(RemotingHelper.DEFAULT_CHARSET)); msg.putUserProperty(&quot;a&quot;, String.valueOf(i)); // 自定义字段 SendResult sendResult = producer.send(msg); System.out.printf(&quot;%s%n&quot;, sendResult);&#125;producer.shutdown();// 消费者示例DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;please_rename_unique_group_name&quot;);consumer.setNamesrvAddr(&quot;localhost:9876&quot;);consumer.subscribe(&quot;SqlFilterTest&quot;, MessageSelector.bySql(&quot;(TAGS is not null and TAGS in (&#x27;TagA&#x27;, &#x27;TagB&#x27;))and (a is not null and a between 0 and 3)&quot;));consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; System.out.printf(&quot;%s Receive New Messages: %s %n&quot;, Thread.currentThread().getName(), msgs); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125;&#125;);consumer.start(); 事务消息事务消息是在分布式系统中保证最终一致性的两阶段提交的消息实现,可保证本地事务执行与消息发送两个操作的原子性,事务消息只涉及到消息发送者,对消息消费者来说没有什么特别,即只保证了分布式事务的一半.事务消息的关键是在 TransactionMQProducer 中指定了一个 TransactionListener事务监听器,该事务监听器就是事务消息的关键控制器； 123456789101112131415161718192021222324TransactionListener transactionListener = new TransactionListenerImpl();TransactionMQProducer producer = new TransactionMQProducer(&quot;please_rename_unique_group_name&quot;);producer.setNamesrvAddr(&quot;127.0.0.1:9876&quot;);ExecutorService executorService = new ThreadPoolExecutor(2, 5, 100, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(2000), new ThreadFactory() &#123; @Override public Thread newThread(Runnable r) &#123; Thread thread = new Thread(r); thread.setName(&quot;client-transaction-msg-check-thread&quot;); return thread; &#125;&#125;);producer.setExecutorService(executorService);producer.setTransactionListener(transactionListener);producer.start();String[] tags = new String[]&#123;&quot;TagA&quot;, &quot;TagB&quot;, &quot;TagC&quot;, &quot;TagD&quot;, &quot;TagE&quot;&#125;;for (int i = 0; i &lt; 10; i++) &#123; Message msg = new Message(&quot;TopicTest&quot;, tags[i % tags.length], &quot;KEY&quot; + i, (&quot;Hello RocketMQ &quot; + i).getBytes(RemotingHelper.DEFAULT_CHARSET)); msg.putUserProperty(MessageConst.PROPERTY_TRANSACTION_CHECK_TIMES, &quot;15&quot;); // 回查次数 msg.putUserProperty(MessageConst.PROPERTY_CHECK_IMMUNITY_TIME_IN_SECONDS, &quot;10000&quot;); // 回查时间 SendResult sendResult = producer.sendMessageInTransaction(msg, null); System.out.printf(&quot;%s%n&quot;, sendResult); Thread.sleep(10);&#125;producer.shutdown(); 123456789101112131415161718192021222324public class TransactionListenerImpl implements TransactionListener &#123; @Override public LocalTransactionState executeLocalTransaction(Message msg, Object arg) &#123; String tags = msg.getTags(); if (StringUtils.contains(tags, &quot;TagA&quot;)) &#123; return LocalTransactionState.COMMIT_MESSAGE; &#125; else if (StringUtils.contains(tags, &quot;TagB&quot;)) &#123; return LocalTransactionState.ROLLBACK_MESSAGE; &#125; else &#123; return LocalTransactionState.UNKNOW; &#125; &#125; @Override public LocalTransactionState checkLocalTransaction(MessageExt msg) &#123; String tags = msg.getTags(); if (StringUtils.contains(tags, &quot;TagC&quot;)) &#123; return LocalTransactionState.COMMIT_MESSAGE; &#125; else if (StringUtils.contains(tags, &quot;TagD&quot;)) &#123; return LocalTransactionState.ROLLBACK_MESSAGE; &#125; else &#123; return LocalTransactionState.UNKNOW; &#125; &#125;&#125; 事务消息不支持延迟消息和批量消息,为了避免单个消息被检查太多次而导致队列消息累积,回查次数由BrokerConfig.transactionCheckMax参数来配置,默认15次,可在 broker.conf 中覆盖,实际检查次数会在message中保存一个用户属性 MessageConst.PROPERTY_TRANSACTION_CHECK_TIMES .该属性值大于transactionCheckMax 则丢弃,默认情况下同时打印错误日志,可通过重写 AbstractTransactionCheckListener 类来修改该行为. 该用户属性值按回查次数递增,也可在Producer中自行覆盖该属性. 回查时间间隔由 BrokerConfig.transactionTimeOut 参数来配置,默认6秒,可在broker.conf中修改,也可给消息配置一个 MessageConst.PROPERTY_CHECK_IMMUNITY_TIME_IN_SECONDS 属性来给消息指定一个特定的消息回查时间. 事务性消息可能不止一次被检查或消费；提交给用户的目标主题消息可能会失败,目前以日志的记录而定.其高可用性通过RocketMQ本身的高可用性机制来保证,若希望确保事务消息不丢失、且事务完整性得到保证,建议使用同步双重写入机制. 事务消息的生产者ID不能与其他类型消息的生产者ID共享.与其他类型的消息不同,事务消息允许反向查询,MQ服务器能通过事务消息的生产者ID查询到消费者. 事务消息机制在发送消息时,会将消息转为一个 half半消息,并存入RocketMQ内部的一个 RMQ_SYS_TRANS_HALF_TOPIC ,该Topic对消费者不可见,然后执行本地事务执行commit提交,则Broker会将投递到 RMQ_SYS_TRANS_HALF_TOPIC 中的消息投递到用户指定真正Topic中,然后再投递一个表示删除的消息到 RMQ_SYS_TRANS_OP_HALF_TOPIC 中,表示当前事务已完成,若本地事务rollback 回滚,则没有投递到真实Topic的过程,只需要投递表示删除的消息到 RMQ_SYS_TRANS_OP_HALF_TOPIC ,若Commit提交或Rollback回滚失败,Broker默认每6s中回查调用 checkLocalTransaction 一次,在该回查方法中再次回滚会提交事务,默认最多15次. ACL权限控制 ACL权限控制主要为RocketMQ提供 Topic资源级别的用户访问控制,可在Client客户端通过 RPCHook 注入 AccessKey 和 SecretKey 签名；将对应的权限控制属性,包括 Topic访问权限、 IP白名单和 AccessKey 和 SecretKey 签名等,设置在 $ROCKETMQ_HOME/conf/plain_acl.yml 配置文件中.Broker端对AccessKey所拥有的权限进行校验,校验不过抛出异常. 1234567891011121314151617181920212223242526272829303132333435private static final String ACL_ACCESS_KEY = &quot;RocketMQ&quot;;private static final String ACL_SECRET_KEY = &quot;1234567&quot;;public static void producer() throws MQClientException &#123; DefaultMQProducer producer = new DefaultMQProducer(&quot;ProducerGroupName&quot;, getAclRPCHook()); producer.setNamesrvAddr(&quot;127.0.0.1:9876&quot;); producer.start(); for (int i = 0; i &lt; 128; i++) &#123; try &#123; Message msg = new Message(&quot;TopicTest&quot;, &quot;TagA&quot;, &quot;OrderID188&quot;, &quot;Hello world&quot;.getBytes(RemotingHelper.DEFAULT_CHARSET)); SendResult sendResult = producer.send(msg); System.out.printf(&quot;%s%n&quot;, sendResult); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; producer.shutdown();&#125;public static void pushConsumer() throws MQClientException &#123; DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;please_rename_unique_group_name_5&quot;, getAclRPCHook(), new AllocateMessageQueueAveragely()); consumer.setNamesrvAddr(&quot;127.0.0.1:9876&quot;); consumer.subscribe(&quot;TopicTest&quot;, &quot;*&quot;); consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET); consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; System.out.printf(&quot;%s Receive New Messages: %s %n&quot;, Thread.currentThread().getName(), msgs); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; &#125;); consumer.start();&#125;static RPCHook getAclRPCHook() &#123; return new AclClientRPCHook(new SessionCredentials(ACL_ACCESS_KEY, ACL_SECRET_KEY));&#125; Broker端具体配置信息可参见源码包下 docs/cn/acl/user_guide.md ,在 broker.conf 中通过 aclEnable=true 打开acl的标志.然后就可以用 plain_acl.yml 来进行权限配置了.且该配置文件是热加载的,修改后不用重启Broker服务. 1234567891011121314151617181920212223242526globalWhiteRemoteAddresses: # 全局白名单,不受ACL控制,通常需要将主从架构中所有节点加进来- 10.10.103.*- 192.168.0.*accounts:- accessKey: RocketMQ secretKey: 12345678 whiteRemoteAddress: admin: false defaultTopicPerm: DENY # 默认Topic访问策略是拒绝 defaultGroupPerm: SUB # 默认Group访问策略是只允许订阅 topicPerms: - topicA=DENY # topicA拒绝 - topicB=PUB|SUB # topicB允许发布和订阅消息 - topicC=SUB # topicC只允许订阅 groupPerms: # the group should convert to retry topic - groupA=DENY - groupB=PUB|SUB - groupC=SUB# 第二个账户,只要是来自192.168.1.*的IP,就可以访问所有资源- accessKey: rocketmq2 secretKey: 12345678 whiteRemoteAddress: 192.168.1.* # if it is admin, it could access all resources admin: true","tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"http://example.com/tags/RocketMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RocketMQ","slug":"工具和中间件/消息队列/RocketMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RocketMQ/"}]},{"title":"RabbitMQ-Spring集成","date":"2019-03-25T09:08:20.000Z","path":"blog/工具和中间件/消息队列/RabbitMQ/RabbitMQ-Spring集成/","text":"Spring集成12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:rabbit=&quot;http://www.springframework.org/schema/rabbit&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/rabbit http://www.springframework.org/schema/rabbit/spring-rabbit.xsd&quot;&gt; &lt;!--加载配置文件--&gt; &lt;context:property-placeholder location=&quot;classpath:rabbitmq.properties&quot;/&gt; &lt;!-- 定义rabbitmq connectionFactory --&gt; &lt;rabbit:connection-factory id=&quot;connectionFactory&quot; host=&quot;$&#123;rabbitmq.host&#125;&quot; port=&quot;$&#123;rabbitmq.port&#125;&quot; username=&quot;$&#123;rabbitmq.username&#125;&quot; password=&quot;$&#123;rabbitmq.password&#125;&quot; virtual-host=&quot;$&#123;rabbitmq.virtual-host&#125;&quot;/&gt; &lt;!-- 定义管理交换机、队列 --&gt; &lt;rabbit:admin connection-factory=&quot;connectionFactory&quot;/&gt; &lt;!-- 定义持久化队列，不存在则自动创建；不绑定到交换机则绑定到默认交换机，默认交换机类型为direct，名字为：&quot;&quot;，路由键为队列的名称 --&gt; &lt;!-- id：bean的名称，name：queue的名称，auto-declare：自动创建，durable：是否持久化，auto-delete：自动删除。最后一个消费者和该队列断开连接后，自动删除队列 --&gt; &lt;rabbit:queue id=&quot;spring_queue&quot; name=&quot;spring_queue&quot; auto-declare=&quot;true&quot; durable=&quot;false&quot;/&gt; &lt;!-- 广播；所有队列都能收到消息 --&gt; &lt;!--定义广播交换机中的持久化队列，不存在则自动创建--&gt; &lt;rabbit:queue id=&quot;spring_fanout_queue_1&quot; name=&quot;spring_fanout_queue_1&quot; auto-declare=&quot;true&quot;/&gt; &lt;!--定义广播交换机中的持久化队列，不存在则自动创建--&gt; &lt;rabbit:queue id=&quot;spring_fanout_queue_2&quot; name=&quot;spring_fanout_queue_2&quot; auto-declare=&quot;true&quot;/&gt; &lt;!--定义广播类型交换机；并绑定上述两个队列--&gt; &lt;rabbit:fanout-exchange id=&quot;spring_fanout_exchange&quot; name=&quot;spring_fanout_exchange&quot; auto-declare=&quot;true&quot;&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding queue=&quot;spring_fanout_queue_1&quot;/&gt; &lt;rabbit:binding queue=&quot;spring_fanout_queue_2&quot;/&gt; &lt;/rabbit:bindings&gt; &lt;/rabbit:fanout-exchange&gt; &lt;!-- 路由；所有队列都能收到消息 --&gt; &lt;rabbit:queue id=&quot;spring_direct_queue&quot; name=&quot;spring_direct_queue&quot; auto-declare=&quot;true&quot;/&gt; &lt;rabbit:direct-exchange id=&quot;spring_direct_exchange&quot; name=&quot;spring_direct_exchange&quot;&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding queue=&quot;spring_direct_queue&quot;/&gt; &lt;/rabbit:bindings&gt; &lt;/rabbit:direct-exchange&gt; &lt;!-- 通配符；*匹配一个单词，#匹配多个单词 --&gt; &lt;rabbit:queue id=&quot;spring_topic_queue_star&quot; name=&quot;spring_topic_queue_star&quot; auto-declare=&quot;true&quot;/&gt; &lt;rabbit:queue id=&quot;spring_topic_queue_well&quot; name=&quot;spring_topic_queue_well&quot; auto-declare=&quot;true&quot;/&gt; &lt;rabbit:queue id=&quot;spring_topic_queue_well2&quot; name=&quot;spring_topic_queue_well2&quot; auto-declare=&quot;true&quot;/&gt; &lt;!-- 声明 topic 类型的交换机 --&gt; &lt;rabbit:topic-exchange name=&quot;spring_topic_exchange&quot; id=&quot;spring_topic_exchange&quot; auto-declare=&quot;true&quot;&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding pattern=&quot;eleven.*&quot; queue=&quot;spring_topic_queue_star&quot;/&gt; &lt;rabbit:binding pattern=&quot;eleven.#&quot; queue=&quot;spring_topic_queue_well&quot;/&gt; &lt;rabbit:binding pattern=&quot;itcast.*&quot; queue=&quot;spring_topic_queue_well2&quot;/&gt; &lt;/rabbit:bindings&gt; &lt;/rabbit:topic-exchange&gt; &lt;!--定义rabbitTemplate对象操作可以在代码中方便发送消息--&gt; &lt;rabbit:template id=&quot;rabbitTemplate&quot; connection-factory=&quot;connectionFactory&quot;/&gt;&lt;/beans&gt; 12345678910111213141516171819202122@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = &quot;classpath:spring-rabbitmq-producer-basic.xml&quot;)public class ProducerBasicTest &#123; @Autowired private RabbitTemplate rabbitTemplate; @Test public void testHelloWorld() &#123; rabbitTemplate.convertAndSend(&quot;spring_queue&quot;, &quot;hello world spring...&quot;); &#125; @Test public void testFanout() &#123; rabbitTemplate.convertAndSend(&quot;spring_fanout_exchange&quot;, &quot;&quot;, &quot;spring fanout...&quot;); &#125; @Test public void testDirect() &#123; rabbitTemplate.convertAndSend(&quot;spring_direct_exchange&quot;, &quot;info&quot;, &quot;spring_direct...&quot;); &#125; @Test public void testTopic() &#123; rabbitTemplate.convertAndSend(&quot;spring_topic_exchange&quot;, &quot;eleven.hehe.haha&quot;, &quot;spring topic...&quot;); &#125;&#125; 1234567891011121314151617181920212223242526272829303132&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:rabbit=&quot;http://www.springframework.org/schema/rabbit&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/rabbit http://www.springframework.org/schema/rabbit/spring-rabbit.xsd&quot;&gt; &lt;!--加载配置文件--&gt; &lt;context:property-placeholder location=&quot;classpath:rabbitmq.properties&quot;/&gt; &lt;!-- 定义rabbitmq connectionFactory --&gt; &lt;rabbit:connection-factory id=&quot;connectionFactory&quot; host=&quot;$&#123;rabbitmq.host&#125;&quot; port=&quot;$&#123;rabbitmq.port&#125;&quot; username=&quot;$&#123;rabbitmq.username&#125;&quot; password=&quot;$&#123;rabbitmq.password&#125;&quot; virtual-host=&quot;$&#123;rabbitmq.virtual-host&#125;&quot;/&gt; &lt;bean id=&quot;springQueueListener&quot; class=&quot;com.eleven.icode.rabbitmq.SpringQueueListener&quot;/&gt; &lt;bean id=&quot;fanoutListener&quot; class=&quot;com.eleven.icode.rabbitmq.SpringQueueListener&quot;/&gt; &lt;bean id=&quot;fanoutListener2&quot; class=&quot;com.eleven.icode.rabbitmq.SpringQueueListener&quot;/&gt; &lt;bean id=&quot;topicListenerStar&quot; class=&quot;com.eleven.icode.rabbitmq.SpringQueueListener&quot;/&gt; &lt;bean id=&quot;topicListenerWell&quot; class=&quot;com.eleven.icode.rabbitmq.SpringQueueListener&quot;/&gt; &lt;bean id=&quot;topicListenerWell2&quot; class=&quot;com.eleven.icode.rabbitmq.SpringQueueListener&quot;/&gt; &lt;rabbit:listener-container connection-factory=&quot;connectionFactory&quot; auto-declare=&quot;true&quot;&gt; &lt;rabbit:listener ref=&quot;springQueueListener&quot; queue-names=&quot;spring_queue&quot;/&gt; &lt;rabbit:listener ref=&quot;fanoutListener&quot; queue-names=&quot;spring_fanout_queue_1&quot;/&gt; &lt;rabbit:listener ref=&quot;fanoutListener2&quot; queue-names=&quot;spring_fanout_queue_2&quot;/&gt; &lt;rabbit:listener ref=&quot;topicListenerStar&quot; queue-names=&quot;spring_topic_queue_star&quot;/&gt; &lt;rabbit:listener ref=&quot;topicListenerWell&quot; queue-names=&quot;spring_topic_queue_well&quot;/&gt; &lt;rabbit:listener ref=&quot;topicListenerWell2&quot; queue-names=&quot;spring_topic_queue_well2&quot;/&gt; &lt;/rabbit:listener-container&gt;&lt;/beans&gt; 123456public class SpringQueueListener implements MessageListener &#123; @Override public void onMessage(Message message) &#123; System.out.println(new String(message.getBody())); &#125;&#125; SpringBoot集成1234567spring: rabbitmq: host: localhost #主机ip port: 5672 #端口 username: eleven password: eleven virtual-host: eleven 12345678910111213141516171819202122232425262728@Configurationpublic class TopicConfig &#123; @Bean public Queue topicQ1() &#123; // 声明队列 return new Queue(&quot;topic_sb_mq_q1&quot;); &#125; @Bean public Queue topicQ2() &#123; // 声明队列 return new Queue(&quot;topic_sb_mq_q2&quot;); &#125; @Bean public TopicExchange setTopicExchange() &#123; // 声明exchange return new TopicExchange(&quot;topicExchange&quot;); &#125; @Bean public Binding bindTopicHebei1() &#123; // 声明binding，需要声明一个roytingKey return BindingBuilder.bind(topicQ1()).to(setTopicExchange()).with(&quot;changsha.*&quot;); &#125; @Bean public Binding bindTopicHebei2() &#123; return BindingBuilder.bind(topicQ2()).to(setTopicExchange()).with(&quot;#.beijing&quot;); &#125;&#125;@RabbitListener(queues = &quot;topic_sb_mq_q2&quot;)public void topicReceiveq2(String message) &#123; System.out.println(&quot;Topic模式 topic_sb_mq_q2 received message : &quot; + message);&#125;","tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://example.com/tags/RabbitMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RabbitMQ","slug":"工具和中间件/消息队列/RabbitMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/"}]},{"title":"RabbitMQ-高级特性","date":"2019-03-25T07:08:20.000Z","path":"blog/工具和中间件/消息队列/RabbitMQ/RabbitMQ-高级特性/","text":"消息可靠性投递持久化: Exchange持久化、 Queue持久化、 Message持久化; 生产方确认Confirm; 消费方确认Ack; Broker高可用; 生成端确认使用RabbitMQ时,作为消息发送方希望杜绝任何消息丢失或投递失败场景.RabbitMQ提供了 Confirm确认模式 和 Return退回模式 两种方式用来控制消息的投递可靠性. RabbitMQ整个消息投递的路径为:Producer到Rabbitmq Broker到Exchange到Queue到Consumer;消息从Producer到Exchange 则会返回一个 ConfirmCallback.消息从Exchange到Queue投递失败 则会返回一个 ReturnCallback.可利用这两个Callback控制消息的可靠性投递; 设置 ConnectionFactory 的 publisher-confirms=&quot;true&quot;开启确认模式.使用 RabbitTemplate 的 setConfirmCallback 设置回调函数.当消息发送到Exchange后回调confirm方法.在方法中判断ack,若为true则发送成功,若为false则发送失败需要处理. 设置 ConnectionFactory 的 publisher-returns=&quot;true&quot;开启退回模式.使用 RabbitTemplate 的 setReturnCallback 设置退回函数,当消息从Exchange路由到Queue失败后,若设置了 rabbitTemplate.setMandatory(true) 参数,则会将消息退回给Producer并 执行回调函数returnedMessage. 消费端确认ack指 Acknowledge 确认,表示 消费端收到消息后的确认方式,有三种确认方式: 自动确认:acknowledge=&quot;none&quot; 手动确认:acknowledge=&quot;manual&quot; 根据异常情况确认:acknowledge=&quot;auto&quot; 自动确认是指当消息一旦被Consumer接收到,则自动确认收到,并将相应message从RabbitMQ消息缓存中移除.但在实际业务处理中,很可能消息接收到,业务处理出现异常,则该消息会丢失.若设置了手动确认方式,则需要在业务处理成功后,调用 channel.basicAck()手动签收,若出现异常则调用 channel.basicNack() 方法,让其自动重新发送消息. 123456789101112131415&lt;!--加载配置文件--&gt;&lt;context:property-placeholder location=&quot;classpath:rabbitmq.properties&quot;/&gt;&lt;!-- 定义rabbitmq connectionFactory --&gt;&lt;rabbit:connection-factory id=&quot;connectionFactory&quot; host=&quot;$&#123;rabbitmq.host&#125;&quot; port=&quot;$&#123;rabbitmq.port&#125;&quot; username=&quot;$&#123;rabbitmq.username&#125;&quot; password=&quot;$&#123;rabbitmq.password&#125;&quot; virtual-host=&quot;$&#123;rabbitmq.virtual-host&#125;&quot; publisher-confirms=&quot;true&quot; publisher-returns=&quot;true&quot;/&gt;&lt;!--定义管理交换机、队列--&gt;&lt;rabbit:admin connection-factory=&quot;connectionFactory&quot;/&gt;&lt;!--定义rabbitTemplate对象操作可以在代码中方便发送消息--&gt;&lt;rabbit:template id=&quot;rabbitTemplate&quot; connection-factory=&quot;connectionFactory&quot;/&gt;&lt;!--消息可靠性投递（生产端）--&gt;&lt;rabbit:queue id=&quot;test_queue_confirm&quot; name=&quot;test_queue_confirm&quot;/&gt;&lt;rabbit:direct-exchange name=&quot;test_exchange_confirm&quot;&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding queue=&quot;test_queue_confirm&quot; key=&quot;confirm&quot;/&gt; &lt;/rabbit:bindings&gt;&lt;/rabbit:direct-exchange&gt; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = &quot;classpath:spring-rabbitmq-producer.xml&quot;)public class ProducerTest &#123; @Autowired private RabbitTemplate rabbitTemplate; @Test public void testConfirm() &#123; //测试Confirm模式 //定义回调 rabbitTemplate.setConfirmCallback(new RabbitTemplate.ConfirmCallback() &#123; /** * @param correlationData 相关配置信息 * @param ack exchange交换机 是否成功收到了消息.true 成功,false代表失败 * @param cause 失败原因 */ @Override public void confirm(CorrelationData correlationData, boolean ack, String cause) &#123; System.out.println(&quot;confirm方法被执行了....&quot; + correlationData.getId()); // ack为true表示消息已经到达交换机 if (ack) &#123; // 接收成功 System.out.println(&quot;接收成功消息&quot; + cause); &#125; else &#123; // 接收失败 System.out.println(&quot;接收失败消息&quot; + cause); // 做一些处理,让消息再次发送. &#125; &#125; &#125;); // 进行消息发送 for (int i = 0; i &lt; 5; i++) &#123; rabbitTemplate.convertAndSend(&quot;test_exchange_confirm&quot;, &quot;confirm&quot;, &quot;message Confirm...&quot;); &#125; &#125; @Test public void testReturn() &#123; // 测试return模式 // 设置交换机处理失败消息的模式,为true时消息到达不了队列时,会将消息重新返回给生产者 rabbitTemplate.setMandatory(true); // 定义回调 rabbitTemplate.setReturnCallback(new RabbitTemplate.ReturnCallback() &#123; /** * @param message 消息对象 * @param replyCode 错误码 * @param replyText 错误信息 * @param exchange 交换机 * @param routingKey 路由键 */ @Override public void returnedMessage(Message message, int replyCode, String replyText, String exchange, String routingKey) &#123; System.out.println(&quot;return 执行了....&quot;); System.out.println(&quot;message:&quot; + message); System.out.println(&quot;replyCode:&quot; + replyCode); System.out.println(&quot;replyText:&quot; + replyText); System.out.println(&quot;exchange:&quot; + exchange); System.out.println(&quot;routingKey:&quot; + routingKey); &#125; &#125;); // 进行消息发送 rabbitTemplate.convertAndSend(&quot;test_exchange_confirm&quot;, &quot;confirm&quot;, &quot;message return...&quot;); &#125;&#125; 12345&lt;!--定义监听器容器 acknowledge=&quot;manual&quot;:手动签收 prefetch=&quot;1&quot;:每次抓取多少条消息 --&gt;&lt;!--定义监听器容器 acknowledge=&quot;manual&quot; prefetch=&quot;1&quot; --&gt;&lt;rabbit:listener-container connection-factory=&quot;connectionFactory&quot; acknowledge=&quot;manual&quot; prefetch=&quot;1&quot;&gt; &lt;rabbit:listener ref=&quot;ackListener&quot; queue-names=&quot;test_queue_confirm&quot;&gt;&lt;/rabbit:listener&gt;&lt;/rabbit:listener&gt;&lt;/rabbit:listener-container&gt; 12345678910111213141516171819202122@Componentpublic class AckListener implements ChannelAwareMessageListener &#123; @Override public void onMessage(Message message, Channel channel) throws Exception &#123; //1、获取消息的id long deliveryTag = message.getMessageProperties().getDeliveryTag(); try &#123; //2、获取消息 System.out.println(&quot;message:&quot; + new String(message.getBody())); //3、进行业务处理 System.out.println(&quot;=====进行业务处理====&quot;); //模拟出现异常 int i = 5/0; //4、进行消息签收 channel.basicAck(deliveryTag, false); System.out.println(&quot;收到了消息:&quot; + deliveryTag); &#125; catch (Exception e) &#123; //拒绝签收,第三个参数：requeue：重回队列.如果设置为true,则消息重新回到queue,broker会重新发送该消息给消费端 channel.basicNack(deliveryTag, false, true); &#125; &#125;&#125; 消费端限流在 &lt;rabbit:listener-container&gt; 中配置 prefetch 属性设置 消费端一次拉取多少消息 ,消费端的确认模式一定为手动确认 acknowledge=&quot;manual&quot; . TTL当消息达到存活时间后,还未被消费会被自动清除,RabbitMQ可 对消息设置过期时间,也可 对整个队列设置过期时间. 设置队列过期时间使用参数 x-message-ttl 单位 ms毫秒,会对整个队列消息统一过期.设置消息过期时间使用参数 expiration 单位 ms毫秒,当该消息在 队列头部 时,会单独判断这一消息是否过期.若 两者都进行了设置以时间短的为准. 123456789101112&lt;rabbit:queue name=&quot;test_queue_ttl&quot; id=&quot;test_queue_ttl&quot;&gt; &lt;!--设置queue的参数--&gt; &lt;rabbit:queue-arguments&gt; &lt;!--x-message-ttl指队列的过期时间--&gt; &lt;entry key=&quot;x-message-ttl&quot; value=&quot;10000&quot; value-type=&quot;java.lang.Integer&quot;/&gt; &lt;/rabbit:queue-arguments&gt;&lt;/rabbit:queue&gt;&lt;rabbit:topic-exchange name=&quot;test_exchange_ttl&quot;&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding pattern=&quot;ttl.#&quot; queue=&quot;test_queue_ttl&quot;/&gt; &lt;/rabbit:bindings&gt;&lt;/rabbit:topic-exchange&gt; 死信队列死信队列DXL.Dead Letter Exchange死信交换机,当消息成为Dead Message后,可被 重新发送到另一个交换机,这个交换机就是 DLX.消息成为死信的 三种情况： 队列消息长度到达限制; 消费者拒接消费消息,basicNack/basicReject且不把消息重新放入原目标队列,requeue=false; 原队列存在消息过期设置,消息到达超时时间未被消费; 死信交换机和死信队列和普通的没有区别，当消息成为死信后，若该队列绑定了死信交换机，则消息会被死信交换机重新路由到死信队列。可通过给队列设置 x-dead-letter-exchange 和 x-dead-letter-routing-key 参数来绑定死信交换机; 12345678910111213141516171819202122232425262728293031323334&lt;!-- 1. 声明正常的队列(test_queue_dlx)和交换机(test_exchange_dlx) 2. 声明死信队列(queue_dlx)和死信交换机(exchange_dlx) 3. 正常队列绑定死信交换机 设置两个参数： * x-dead-letter-exchange：死信交换机名称 * x-dead-letter-routing-key：发送给死信交换机的routingkey--&gt;&lt;!-- 1. 声明正常的队列(test_queue_dlx)和交换机(test_exchange_dlx) --&gt;&lt;rabbit:queue name=&quot;test_queue_dlx&quot; id=&quot;test_queue_dlx&quot;&gt; &lt;!--3. 正常队列绑定死信交换机--&gt; &lt;rabbit:queue-arguments&gt; &lt;!--3.1 x-dead-letter-exchange：死信交换机名称--&gt; &lt;entry key=&quot;x-dead-letter-exchange&quot; value=&quot;exchange_dlx&quot;/&gt; &lt;!--3.2 x-dead-letter-routing-key：发送给死信交换机的routingkey--&gt; &lt;entry key=&quot;x-dead-letter-routing-key&quot; value=&quot;dlx.hehe&quot;/&gt; &lt;!--4.1 设置队列的过期时间 ttl--&gt; &lt;entry key=&quot;x-message-ttl&quot; value=&quot;10000&quot; value-type=&quot;java.lang.Integer&quot;/&gt; &lt;!--4.2 设置队列的长度限制 max-length--&gt; &lt;entry key=&quot;x-max-length&quot; value=&quot;10&quot; value-type=&quot;java.lang.Integer&quot;/&gt; &lt;/rabbit:queue-arguments&gt;&lt;/rabbit:queue&gt;&lt;rabbit:topic-exchange name=&quot;test_exchange_dlx&quot;&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding pattern=&quot;test.dlx.#&quot; queue=&quot;test_queue_dlx&quot;/&gt; &lt;/rabbit:bindings&gt;&lt;/rabbit:topic-exchange&gt;&lt;!-- 2. 声明死信队列(queue_dlx)和死信交换机(exchange_dlx) --&gt;&lt;rabbit:queue name=&quot;queue_dlx&quot; id=&quot;queue_dlx&quot;/&gt;&lt;rabbit:topic-exchange name=&quot;exchange_dlx&quot;&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding pattern=&quot;dlx.#&quot; queue=&quot;queue_dlx&quot;/&gt; &lt;/rabbit:bindings&gt;&lt;/rabbit:topic-exchange&gt; 1234&lt;rabbit:listener-container connection-factory=&quot;connectionFactory&quot; acknowledge=&quot;manual&quot; prefetch=&quot;1&quot;&gt; &lt;!--定义监听器，监听正常队列--&gt; &lt;rabbit:listener ref=&quot;dlxListener&quot; queue-names=&quot;test_queue_dlx&quot;&gt;&lt;/rabbit:listener&gt;&lt;/rabbit:listener&gt;&lt;/rabbit:listener-container&gt; 123456789101112131415161718192021@Componentpublic class DlxListener implements ChannelAwareMessageListener &#123; @Override public void onMessage(Message message, Channel channel) throws Exception &#123; long deliveryTag = message.getMessageProperties().getDeliveryTag(); try &#123; //1.接收转换消息 System.out.println(new String(message.getBody())); //2. 处理业务逻辑 System.out.println(&quot;处理业务逻辑...&quot;); //int i = 3/0;//出现错误 //3. 手动签收 channel.basicAck(deliveryTag, true); &#125; catch (Exception e) &#123; //e.printStackTrace(); System.out.println(&quot;出现异常，拒绝接受&quot;); //4.拒绝签收，不重回队列 requeue=false channel.basicNack(deliveryTag, true, false); &#125; &#125;&#125; 延迟队列延迟队列即消息进入队列后不会立即被消费，只有到达指定时间后才会被消费，在RabbitMQ中并未提供延迟队列功能。但是可使用 TTL+死信队列 组合实现延迟队列的效果 123456789101112131415161718192021222324252627&lt;!-- 延迟队列： 1. 定义正常交换机（order_exchange）和队列(order_queue) 2. 定义死信交换机（order_exchange_dlx）和队列(order_queue_dlx) 3. 绑定，设置正常队列过期时间为30分钟--&gt;&lt;!-- 1. 定义正常交换机（order_exchange）和队列(order_queue)--&gt;&lt;rabbit:queue id=&quot;order_queue&quot; name=&quot;order_queue&quot;&gt; &lt;!--3. 绑定，设置正常队列过期时间为30分钟--&gt; &lt;rabbit:queue-arguments&gt; &lt;entry key=&quot;x-dead-letter-exchange&quot; value=&quot;order_exchange_dlx&quot;/&gt; &lt;entry key=&quot;x-dead-letter-routing-key&quot; value=&quot;dlx.order.cancel&quot;/&gt; &lt;entry key=&quot;x-message-ttl&quot; value=&quot;10000&quot; value-type=&quot;java.lang.Integer&quot;/&gt; &lt;/rabbit:queue-arguments&gt;&lt;/rabbit:queue&gt;&lt;rabbit:topic-exchange name=&quot;order_exchange&quot;&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding pattern=&quot;order.#&quot; queue=&quot;order_queue&quot;/&gt; &lt;/rabbit:bindings&gt;&lt;/rabbit:topic-exchange&gt;&lt;!--2. 定义死信交换机（order_exchange_dlx）和队列(order_queue_dlx)--&gt;&lt;rabbit:queue id=&quot;order_queue_dlx&quot; name=&quot;order_queue_dlx&quot;/&gt;&lt;rabbit:topic-exchange name=&quot;order_exchange_dlx&quot;&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding pattern=&quot;dlx.order.#&quot; queue=&quot;order_queue_dlx&quot;/&gt; &lt;/rabbit:bindings&gt;&lt;/rabbit:topic-exchange&gt; 1234&lt;rabbit:listener-container connection-factory=&quot;connectionFactory&quot; acknowledge=&quot;manual&quot; prefetch=&quot;1&quot;&gt; &lt;!--延迟队列效果实现：一定要监听的是死信队列！！！--&gt; &lt;rabbit:listener ref=&quot;orderListener&quot; queue-names=&quot;order_queue_dlx&quot;&gt;&lt;/rabbit:listener&gt;&lt;/rabbit:listener-container&gt; 消息幂等性保障可通过版本号实现乐观锁的方式优化; 消息积压消费者宕机积压、消费者消费能力不足积压、生产者者流量太大等都可能导致消息积压;可通过上线更多的消费者，进行正常消费上线专门的队列消费服务，将消息先批量取出来记录数据库再慢慢处理;","tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://example.com/tags/RabbitMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RabbitMQ","slug":"工具和中间件/消息队列/RabbitMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/"}]},{"title":"RabbitMQ-topic模式","date":"2019-03-25T03:08:20.000Z","path":"blog/工具和中间件/消息队列/RabbitMQ/RabbitMQ-topic模式/","text":"pom.xml123456789101112131415161718192021&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;artifactId&gt;rabbitmq&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;rabbitmq&lt;/name&gt; &lt;description&gt;rabbitmq&lt;/description&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt; &lt;artifactId&gt;amqp-client&lt;/artifactId&gt; &lt;version&gt;3.6.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;4.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; TestProducer.java分别在 四个路由：”usa.news”, “usa.weather”, “europe.news”, “europe.weather” 上发布 “美国新闻”, “美国天气”, “欧洲新闻”, “欧洲天气”. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package cn.peach;import java.io.IOException;import java.util.concurrent.TimeoutException; import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory; /** * 消息生成者 */public class TestProducer &#123; public final static String EXCHANGE_NAME=&quot;topics_exchange&quot;; public static void main(String[] args) throws IOException, TimeoutException &#123; RabbitMQUtil.checkServer(); //创建连接工厂 ConnectionFactory factory = new ConnectionFactory(); //设置RabbitMQ相关信息 factory.setHost(&quot;localhost&quot;); //创建一个新的连接 Connection connection = factory.newConnection(); //创建一个通道 Channel channel = connection.createChannel(); channel.exchangeDeclare(EXCHANGE_NAME, &quot;topic&quot;); String[] routing_keys = new String[] &#123; &quot;usa.news&quot;, &quot;usa.weather&quot;, &quot;europe.news&quot;, &quot;europe.weather&quot; &#125;; String[] messages = new String[] &#123; &quot;美国新闻&quot;, &quot;美国天气&quot;, &quot;欧洲新闻&quot;, &quot;欧洲天气&quot; &#125;; for (int i = 0; i &lt; routing_keys.length; i++) &#123; String routingKey = routing_keys[i]; String message = messages[i]; channel.basicPublish(EXCHANGE_NAME, routingKey, null, message .getBytes()); System.out.printf(&quot;发送消息到路由：%s, 内容是: %s%n &quot;, routingKey,message); &#125; //关闭通道和连接 channel.close(); connection.close(); &#125;&#125; TestCustomer4USA.java专门用于接受 usa.* 消息 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package cn.peach;import java.io.IOException;import java.util.concurrent.TimeoutException; import com.rabbitmq.client.AMQP;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import com.rabbitmq.client.Consumer;import com.rabbitmq.client.DefaultConsumer;import com.rabbitmq.client.Envelope; import cn.hutool.core.util.RandomUtil; public class TestCustomer4USA &#123; public final static String EXCHANGE_NAME=&quot;topics_exchange&quot;; public static void main(String[] args) throws IOException, TimeoutException &#123; //为当前消费者取名称 String name = &quot;consumer-usa&quot;; // 创建连接工厂 ConnectionFactory factory = new ConnectionFactory(); //设置RabbitMQ地址 factory.setHost(&quot;localhost&quot;); //创建一个新的连接 Connection connection = factory.newConnection(); //创建一个通道 Channel channel = connection.createChannel(); //交换机声明（参数为：交换机名称；交换机类型） channel.exchangeDeclare(EXCHANGE_NAME,&quot;topic&quot;); //获取一个临时队列 String queueName = channel.queueDeclare().getQueue(); //接受 USA 信息 channel.queueBind(queueName, EXCHANGE_NAME, &quot;usa.*&quot;); System.out.println(name +&quot; 等待接受消息&quot;); //DefaultConsumer类实现了Consumer接口，通过传入一个频道， // 告诉服务器我们需要那个频道的消息，如果频道中有消息，就会执行回调函数handleDelivery Consumer consumer = new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; String message = new String(body, &quot;UTF-8&quot;); System.out.println(name + &quot; 接收到消息 &#x27;&quot; + message + &quot;&#x27;&quot;); &#125; &#125;; //自动回复队列应答 -- RabbitMQ中的消息确认机制 channel.basicConsume(queueName, true, consumer); &#125;&#125; TestCustomer4News.java专门用于接受 *.news 消息 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package cn.peach;import java.io.IOException;import java.util.concurrent.TimeoutException; import com.rabbitmq.client.AMQP;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import com.rabbitmq.client.Consumer;import com.rabbitmq.client.DefaultConsumer;import com.rabbitmq.client.Envelope; import cn.hutool.core.util.RandomUtil; public class TestCustomer4News &#123; public final static String EXCHANGE_NAME=&quot;topics_exchange&quot;; public static void main(String[] args) throws IOException, TimeoutException &#123; //为当前消费者取名称 String name = &quot;consumer-news&quot;; // 创建连接工厂 ConnectionFactory factory = new ConnectionFactory(); //设置RabbitMQ地址 factory.setHost(&quot;localhost&quot;); //创建一个新的连接 Connection connection = factory.newConnection(); //创建一个通道 Channel channel = connection.createChannel(); //交换机声明（参数为：交换机名称；交换机类型） channel.exchangeDeclare(EXCHANGE_NAME,&quot;topic&quot;); //获取一个临时队列 String queueName = channel.queueDeclare().getQueue(); //接受 USA 信息 channel.queueBind(queueName, EXCHANGE_NAME, &quot;*.news&quot;); System.out.println(name +&quot; 等待接受消息&quot;); //DefaultConsumer类实现了Consumer接口，通过传入一个频道， // 告诉服务器我们需要那个频道的消息，如果频道中有消息，就会执行回调函数handleDelivery Consumer consumer = new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; String message = new String(body, &quot;UTF-8&quot;); System.out.println(name + &quot; 接收到消息 &#x27;&quot; + message + &quot;&#x27;&quot;); &#125; &#125;; //自动回复队列应答 -- RabbitMQ中的消息确认机制 channel.basicConsume(queueName, true, consumer); &#125;&#125; 运行效果先运行 TestCustomer4USA 专门用于接受美国专题消息再运行 TestCustomer4News 专门用于接受新闻专题消息最后运行 TestProducer ，分别在 四个路由：”usa.news”, “usa.weather”, “europe.news”, “europe.weather” 上发布 “美国新闻”, “美国天气”, “欧洲新闻”, “欧洲天气”.于是就能在消费者端看到 不同的主题收到对应的消息了。","tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://example.com/tags/RabbitMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RabbitMQ","slug":"工具和中间件/消息队列/RabbitMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/"}]},{"title":"ActiveMQ-Spring集成","date":"2019-03-24T09:09:03.000Z","path":"blog/工具和中间件/消息队列/Activemq/ActiveMQ-Spring集成/","text":"spring 模式前面的是 jms 模式，下面采用 spring 模式使用 activeMQ。 JMS即Java消息服务(Java Message Service)应用程序接口,是一个Java平台中关于面向消息中间件(MOM)的API,用于在两个应用程序之间,或分布式系统中发送消息,进行异步通信。 点到点（point to point）。基于消息队列，消息产生者将消息发送到队列中。消息消费者可以将自身与队列连接，以倾听消息。当消息到达队列时，客户可以从队列中取走，并给出响应。消息只能发送到一个队列，只能由一个消费者使用。消费者可以过滤消息，以便获得希望获得的消息。 出版和订阅（publish&#x2F;subscribe）。消息生产者将消息发送到一个话题（topic），注册到此话题的消费者都能接收到这些消息。这种情况下，许多消费者都能接收到同样的消息。 pom.xml引入 activemq, spring , junit ,hutool 1234567891011121314151617181920212223242526272829303132333435&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;artifactId&gt;activemq&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;activemq&lt;/name&gt; &lt;description&gt;activemq&lt;/description&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-client&lt;/artifactId&gt; &lt;version&gt;5.13.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jms&lt;/artifactId&gt; &lt;version&gt;4.3.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;4.2.4.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.9&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;4.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; spring_jms.xml在 resources下创建 spring_jms.xml 文件，这里其实就是对 activemq 的相关配置。 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:dubbo=&quot;http://code.alibabatech.com/schema/dubbo&quot; xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;context:component-scan base-package=&quot;cn.peach&quot;&gt;&lt;/context:component-scan&gt; &lt;!-- 真正可以产生Connection的ConnectionFactory，由对应的 JMS服务厂商提供--&gt; &lt;bean id=&quot;targetConnectionFactory&quot; class=&quot;org.apache.activemq.ActiveMQConnectionFactory&quot;&gt; &lt;property name=&quot;brokerURL&quot; value=&quot;tcp://127.0.0.1:61616&quot;/&gt; &lt;/bean&gt; &lt;!-- Spring用于管理真正的ConnectionFactory的ConnectionFactory --&gt; &lt;bean id=&quot;connectionFactory&quot; class=&quot;org.springframework.jms.connection.SingleConnectionFactory&quot;&gt; &lt;!-- 目标ConnectionFactory对应真实的可以产生JMS Connection的ConnectionFactory --&gt; &lt;property name=&quot;targetConnectionFactory&quot; ref=&quot;targetConnectionFactory&quot;/&gt; &lt;/bean&gt; &lt;!-- Spring提供的JMS工具类，它可以进行消息发送、接收等 --&gt; &lt;bean id=&quot;jmsTemplate&quot; class=&quot;org.springframework.jms.core.JmsTemplate&quot;&gt; &lt;!-- 这个connectionFactory对应的是我们定义的Spring提供的那个ConnectionFactory对象 --&gt; &lt;property name=&quot;connectionFactory&quot; ref=&quot;connectionFactory&quot;/&gt; &lt;/bean&gt; &lt;!--这个是队列目的地, ActiveMQQueue 就表示队列模式。 如果要用主题模式就改成 ActiveMQTopic就行了 --&gt; &lt;bean id=&quot;textDestination&quot; class=&quot;org.apache.activemq.command.ActiveMQQueue&quot;&gt; &lt;constructor-arg value=&quot;queue_style&quot;/&gt; &lt;/bean&gt; &lt;!-- 我的监听类 --&gt; &lt;bean id=&quot;myMessageListener&quot; class=&quot;cn.peach.MyMessageListener&quot;&gt;&lt;/bean&gt; &lt;!-- 消息监听容器，会伴随spring的启动 --&gt; &lt;bean class=&quot;org.springframework.jms.listener.DefaultMessageListenerContainer&quot;&gt; &lt;property name=&quot;connectionFactory&quot; ref=&quot;connectionFactory&quot; /&gt; &lt;property name=&quot;destination&quot; ref=&quot;textDestination&quot; /&gt; &lt;property name=&quot;messageListener&quot; ref=&quot;myMessageListener&quot; /&gt; &lt;/bean&gt;&lt;/beans&gt; Producer.java - 生产者类12345678910111213141516171819202122232425262728293031package cn.peach; import javax.jms.Destination;import javax.jms.JMSException;import javax.jms.Message;import javax.jms.Session; import org.springframework.beans.factory.annotation.Autowired;import org.springframework.jms.core.JmsTemplate;import org.springframework.jms.core.MessageCreator;import org.springframework.stereotype.Component; @Componentpublic class Producer &#123; @Autowired private JmsTemplate jmsTemplate; @Autowired private Destination textDestination; public void sendTextMessage(final String text)&#123; jmsTemplate.send(textDestination, new MessageCreator() &#123; public Message createMessage(Session session) throws JMSException &#123; return session.createTextMessage(text); &#125; &#125;); &#125; &#125; TestProducer.java测试生产者，发送100条消息 123456789101112131415161718192021222324252627package cn.peach;import org.junit.Before;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.test.context.ContextConfiguration;import org.springframework.test.context.junit4.SpringJUnit4ClassRunner; @RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations=&quot;classpath:spring_jms.xml&quot;)public class TestProducer &#123; @Autowired private Producer producer; @Before public void checkServer() &#123; // check ActiveMQ 服务器是否启动 &#125; @Test public void testSend()&#123; for (int i = 0; i &lt; 100; i++) &#123; producer.sendTextMessage(&quot;消息 &quot; + i); &#125; &#125;&#125; MyMessageListener.java - 监听类监听类，用于获取新的消息 12345678910111213141516171819202122232425package cn.peach; import javax.jms.JMSException;import javax.jms.Message;import javax.jms.MessageListener;import javax.jms.TextMessage; import cn.hutool.core.util.RandomUtil; public class MyMessageListener implements MessageListener &#123; String name = &quot;consumer-&quot;+ RandomUtil.randomString(5); public MyMessageListener() &#123; System.out.println(name + &quot; started&quot;); &#125; public void onMessage(Message message) &#123; TextMessage textMessage=(TextMessage)message; try &#123; System.out.println(name+&quot; 接收到消息：&quot;+textMessage.getText()); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125;&#125; TestConsumer.java - 消费者测试类消费者测试类，他其实什么都没做。 虽然它什么都没做，但是因为他是运行在 spring框架下的测试，所以一旦启动，就会导致一个 新的 DefaultMessageListenerContainer 被启动，间接地导致 一个 新的 MyMessageListener 被启动。 于是也就充当了消费者的角色了。其中的 1System.in.read(); 是为了这个测试类不退出，可以一直监听用。 与这个类似的， TestProducer 类的启动，也会导致一个 MyMessageListener 被启动，所以 TestProducer 本身既是一个 生产者，也是一个 消费者。 12345678910111213141516171819202122232425262728package cn.peach; import java.io.IOException; import org.junit.Before;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.test.context.ContextConfiguration;import org.springframework.test.context.junit4.SpringJUnit4ClassRunner; @RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations=&quot;classpath:spring_jms.xml&quot;)public class TestConsumer &#123; @Before public void checkServer() &#123; // check ActiveMQ 服务器是否启动.checkServer(); &#125; @Test public void test()&#123; try &#123; //写这个是为了不让当前测试退出。 因为 spring的配置， MyMessageListener 会自动启动 System.in.read(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; 启动测试先运行 1次 TestConsumer, 然后运行 1次 TestProducer。可以看到如图所示的，有两个消费者在瓜分 消息。 明明只启动了一次TestConsumer ，为什么会有两个消费者呢？因为采用 spring 模式， 会用到一个叫做 消息监听容器的类： DefaultMessageListenerContainer， 它会伴随 spring的启动而自动启动。 所以无论是 TestConsumer，还是 TestProducer 里面都会有它了。 模式切换当前例子是队列模式，那么要做主题模式怎么办呢?修改 spring_jms 就可以了，对了 queue_style 最好也修改成 topic_style","tags":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"http://example.com/tags/ActiveMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"Activemq","slug":"工具和中间件/消息队列/Activemq","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Activemq/"}]},{"title":"ActiveMQ-主题模式","date":"2019-03-23T04:08:20.000Z","path":"blog/工具和中间件/消息队列/Activemq/ActiveMQ-主题模式/","text":"主题模式主题模式就是每个订阅了的消费者，都可以获取所有的消息，而不像队列模式那样要争抢。 pom.xml导入两个包，一个是 activemq ，另一个是 hutool jar包 123456789101112131415161718192021&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;artifactId&gt;activemq&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;activemq&lt;/name&gt; &lt;description&gt;activemq&lt;/description&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-all&lt;/artifactId&gt; &lt;version&gt;5.15.9&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;4.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; TestProducer.java和队列模式的 TestProducer几乎一模一样，只有一个地方有区别:Destination destination=session.createTopic(topicName);这里是 createTopic 而 队列模式是 createQueue 12345678910111213141516171819202122232425262728293031323334353637383940414243package cn.peach; import javax.jms.Connection;import javax.jms.ConnectionFactory;import javax.jms.Destination;import javax.jms.JMSException;import javax.jms.MessageProducer;import javax.jms.Session;import javax.jms.TextMessage; import org.apache.activemq.ActiveMQConnectionFactory; public class TestProducer &#123; //服务地址，端口默认61616 private static final String url=&quot;tcp://127.0.0.1:61616&quot;; //这次发送的消息名称 private static final String topicName=&quot;topic_style&quot;; public static void main(String[] args) throws JMSException &#123; //1.创建ConnectiongFactory,绑定地址 ConnectionFactory factory=new ActiveMQConnectionFactory(url); //2.创建Connection Connection connection= factory.createConnection(); //3.启动连接 connection.start(); //4.创建会话 Session session=connection.createSession(false, Session.AUTO_ACKNOWLEDGE); //5.创建一个目标 (主题类型) Destination destination=session.createTopic(topicName); //6.创建一个生产者 MessageProducer producer=session.createProducer(destination); for (int i = 0; i &lt; 100; i++) &#123; //7.创建消息 TextMessage textMessage=session.createTextMessage(&quot;主题消息-&quot;+i); //8.发送消息 producer.send(textMessage); System.out.println(&quot;发送：&quot;+textMessage.getText()); &#125; //7. 关闭连接 connection.close(); &#125;&#125; TestConsumer.java和队列模式的 TestProducer几乎一模一样，只有一个地方有区别：Destination destination=session.createTopic(topicName);这里是 createTopic 而 队列模式是 createQueue 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package cn.peach.topic; import javax.jms.Connection;import javax.jms.ConnectionFactory;import javax.jms.Destination;import javax.jms.JMSException;import javax.jms.Message;import javax.jms.MessageConsumer;import javax.jms.MessageListener;import javax.jms.Session;import javax.jms.TextMessage; import org.apache.activemq.ActiveMQConnectionFactory;import cn.hutool.core.util.RandomUtil;/** * 订阅者 * @author root * */public class TestConsumer &#123; //服务地址，端口默认61616 private static final String url=&quot;tcp://127.0.0.1:61616&quot;; //这次消费的消息名称 private static final String topicName=&quot;topic_style&quot;; //消费者有可能是多个，为了区分不同的消费者，为其创建随机名称 private static final String consumerName=&quot;consumer-&quot; + RandomUtil.randomString(5); public static void main(String[] args) throws JMSException &#123; //1.创建ConnectiongFactory,绑定地址 ConnectionFactory factory=new ActiveMQConnectionFactory(url); //2.创建Connection Connection connection= factory.createConnection(); //3.启动连接 connection.start(); //4.创建会话 Session session=connection.createSession(false, Session.AUTO_ACKNOWLEDGE); //5.创建一个目标 （主题类型） Destination destination=session.createTopic(topicName); //6.创建一个消费者 MessageConsumer consumer=session.createConsumer(destination); //7.创建一个监听器 consumer.setMessageListener(new MessageListener() &#123; public void onMessage(Message arg0) &#123; // TODO Auto-generated method stub TextMessage textMessage=(TextMessage)arg0; try &#123; System.out.println(consumerName +&quot; 接收消息：&quot;+textMessage.getText()); &#125; catch (JMSException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; &#125;); //8. 因为不知道什么时候有，所以没法主动关闭，就不关闭了，一直处于监听状态 //connection.close(); &#125;&#125; 消费者要先启动需要注意的一点是，对于主题模式而言， 消费者要先启动。 如果在生产者生产完成之后，再启动，是看不到消息的。就如同现在才关注某个公众号，那么以前公众号发的信息，现在是看不到的。 只有以后发的，才看得到了。 运行效果 管理界面","tags":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"http://example.com/tags/ActiveMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"Activemq","slug":"工具和中间件/消息队列/Activemq","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Activemq/"}]},{"title":"RabbitMQ-direct模式","date":"2019-03-23T04:08:20.000Z","path":"blog/工具和中间件/消息队列/RabbitMQ/RabbitMQ-direct模式/","text":"pom.xml123456789101112131415161718192021&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;artifactId&gt;rabbitmq&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;rabbitmq&lt;/name&gt; &lt;description&gt;rabbitmq&lt;/description&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt; &lt;artifactId&gt;amqp-client&lt;/artifactId&gt; &lt;version&gt;3.6.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;4.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; TestDriectProducer.java1234567891011121314151617181920212223242526272829303132333435363738package cn.peach;import java.io.IOException;import java.util.concurrent.TimeoutException; import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory; /** * 消息生成者 */public class TestDriectProducer &#123; public final static String QUEUE_NAME=&quot;direct_queue&quot;; public static void main(String[] args) throws IOException, TimeoutException &#123; RabbitMQUtil.checkServer(); //创建连接工厂 ConnectionFactory factory = new ConnectionFactory(); //设置RabbitMQ相关信息 factory.setHost(&quot;localhost&quot;); //创建一个新的连接 Connection connection = factory.newConnection(); //创建一个通道 Channel channel = connection.createChannel(); for (int i = 0; i &lt; 100; i++) &#123; String message = &quot;direct 消息 &quot; +i; //发送消息到队列中 channel.basicPublish(&quot;&quot;, QUEUE_NAME, null, message.getBytes(&quot;UTF-8&quot;)); System.out.println(&quot;发送消息： &quot; + message); &#125; //关闭通道和连接 channel.close(); connection.close(); &#125;&#125; TestDriectCustomer.java12345678910111213141516171819202122232425262728293031323334353637383940414243444546package cn.peach;import java.io.IOException;import java.util.concurrent.TimeoutException; import com.rabbitmq.client.AMQP;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import com.rabbitmq.client.Consumer;import com.rabbitmq.client.DefaultConsumer;import com.rabbitmq.client.Envelope; import cn.hutool.core.util.RandomUtil; public class TestDriectCustomer &#123; private final static String QUEUE_NAME = &quot;direct_queue&quot;; public static void main(String[] args) throws IOException, TimeoutException &#123; //为当前消费者取随机名 String name = &quot;consumer-&quot;+ RandomUtil.randomString(5); // 创建连接工厂 ConnectionFactory factory = new ConnectionFactory(); //设置RabbitMQ地址 factory.setHost(&quot;localhost&quot;); //创建一个新的连接 Connection connection = factory.newConnection(); //创建一个通道 Channel channel = connection.createChannel(); //声明要关注的队列 channel.queueDeclare(QUEUE_NAME, false, false, true, null); System.out.println(name +&quot; 等待接受消息&quot;); //DefaultConsumer类实现了Consumer接口，通过传入一个频道， // 告诉服务器我们需要那个频道的消息，如果频道中有消息，就会执行回调函数handleDelivery Consumer consumer = new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; String message = new String(body, &quot;UTF-8&quot;); System.out.println(name + &quot; 接收到消息 &#x27;&quot; + message + &quot;&#x27;&quot;); &#125; &#125;; //自动回复队列应答 -- RabbitMQ中的消息确认机制 channel.basicConsume(QUEUE_NAME, true, consumer); &#125;&#125; 运行效果先运行两次 TestDriectCustomer，启动两个消费者。然后运行一次 TestDriectProducer， 启动生产者，生产100条信息。此时就可以看到如图所示两个消费者分食 这100条信息。","tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://example.com/tags/RabbitMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RabbitMQ","slug":"工具和中间件/消息队列/RabbitMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/"}]},{"title":"Kafka-Spring集成","date":"2019-03-23T04:08:20.000Z","path":"blog/工具和中间件/消息队列/Kafka/Kafka-Spring集成/","text":"Spring集成1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt; &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt;&lt;/dependency&gt; 123456789101112131415161718192021222324252627282930313233spring: kafka: bootstrap-servers: localhost:9092, localhost:9093, localhost:9094 producer: # 生产者 retries: 3 # 设置大于0的值，则客户端会将发送失败的记录重新发送 batch-size: 16384 buffer-memory: 33554432 acks: 1 # 指定消息key和消息体的编解码方式 key-serializer: org.apache.kafka.common.serialization.StringSerializer value-serializer: org.apache.kafka.common.serialization.StringSerializer consumer: group-id: default-group enable-auto-commit: false auto-offset-reset: earliest key-deserializer: org.apache.kafka.common.serialization.StringDeserializer value-deserializer: org.apache.kafka.common.serialization.StringDeserializer listener: # 当每一条记录被消费者监听器（ListenerConsumer）处理之后提交 # RECORD # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后提交 # BATCH # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后，距离上次提交时间大于TIME时提交 # TIME # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后，被处理record数量大于等于COUNT时提交 # COUNT # TIME | COUNT 有一个条件满足时提交 # COUNT_TIME # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后, 手动调用Acknowledgment.acknowledge()后提交 # MANUAL # 手动调用Acknowledgment.acknowledge()后立即提交，一般使用这种 # MANUAL_IMMEDIATE ack_mode: manual_immediate 123456private final static String TOPIC_NAME = &quot;my-replicated-topic&quot;;@Autowiredprivate KafkaTemplate&lt;String, String&gt; kafkaTemplate;public void send() &#123; kafkaTemplate.send(TOPIC_NAME, 0, &quot;key&quot;, &quot;this is a msg&quot;);&#125; 123456789101112131415161718192021222324/** * @KafkaListener(groupId = &quot;testGroup&quot;, topicPartitions = &#123; * @TopicPartition(topic = &quot;topic1&quot;, partitions = &#123;&quot;0&quot;, &quot;1&quot;&#125;), * @TopicPartition(topic = &quot;topic2&quot;, partitions = &quot;0&quot;, * partitionOffsets = @PartitionOffset(partition = &quot;1&quot;, initialOffset = &quot;100&quot;)) * &#125;, concurrency = &quot;6&quot;) * concurrency就是同组下的消费者个数，就是并发消费数，必须小于等于分区总数 */@KafkaListener(topics = &quot;my-replicated-topic&quot;, groupId = &quot;testGroup&quot;)public void listenTestGroup(ConsumerRecord&lt;String, String&gt; record, Acknowledgment ack) &#123; String value = record.value(); System.out.println(value); System.out.println(record); //手动提交offset //ack.acknowledge();&#125;// 配置多个消费组@KafkaListener(topics = &quot;my-replicated-topic&quot;, groupId = &quot;elevenGroup&quot;)public void listenElevenGroup(ConsumerRecord&lt;String, String&gt; record, Acknowledgment ack) &#123; String value = record.value(); System.out.println(value); System.out.println(record); ack.acknowledge();&#125; 设计原理 总控制器ControllerKafka集群中会有一个或多个Broker ，其中有一个Broker会被选举为Kafka Controller控制器，其负责管理整个集群中所有分区和副本的状态. 当某个分区的 Leader副本出现故障时，由控制器负责为该分区选举新的Leader副本. 当检测到某个分区的 ISR集合发生变化时，由控制器负责通知所有Broker更新其元数据信息. 当使用 kafka-topics.sh 脚本为某个 Topic增加分区数量时，同样还是由控制器负责让新分区被其他节点感知到. Kafka集群启动时自动选举一台Broker作为Controller来管理整个集群，选举过程是集群中每个Broker都会尝试在Zookeeper上创建一个 /controller临时节点，Zookeeper会保证有且仅有一个Broker能创建成功，创建成功的Broker则成为集群的总控器Controller. Controller选举机制当Controller角色的Broker宕机时Zookeeper临时节点会消失，集群里其他Broker会一直监听/controller临时节点，发现临时节点消失则竞争再次创建/controller临时节点，这就是 Controller的选举机制. 具备控制器身份的Broker需要比其他普通Broker多一份职责： 监听Broker相关的变化，为Zookeeper中的 /brokers/ids 节点添加 BrokerChangeListener ，用来处理Broker增减变化. 监听Topic相关的变化，为Zookeeper中的 /brokers/topics 节点添加 TopicChangeListener ，用来处理Topic增减的变化；为Zookeeper中的 /admin/delete_topics 节点添加 TopicDeletionListener ，用来处理删除Topic动作. 从Zookeeper中读取当前所有与Topic、 Partition以及Broker有关信息并进行相应的管理. 对所有Topic所对应的Zookeeper中的 /brokers/topics/[topic] 节点添加 PartitionModificationsListener ，用来监听Topic中分区分配变化. 更新集群元数据信息，同步到其他普通Broker节点中. Partition副本选举Leader机制Controller会监听 /brokers/ids 节点可感知Broker是否存活，当Controller感知到分区Leader所在Broker挂了，参数 unclean.leader.election.enable=false 的前提下，Controller会从 ISR列表里挑第一个Broker作为Leader，因为第一个Broker最先放进ISR列表可能是同步数据最多的副本，若参数 unclean.leader.election.enable=true 代表在 ISR列表里所有副本都挂了时可在ISR列表以外的副本中选Leader，该设置可提高可用性，但选出的新Leader可能数据少很多. 副本进入ISR列表有两个条件：副本节点不能产生分区，必须能与Zookeeper保持会话以及跟Leader副本网络连通；副本能复制Leader上的所有写操作，且不能落后太多，超过 replica.lag.time.max.ms 时间都没跟Leader同步过一次的副本会被移出 ISR 列表； offset记录机制每个Consumer会定期将自己消费分区的offset 提交给Kafka内部名称为 __consumer_offsets 的Topic，提交过去时key为consumerGroupId+topic+分区号，value就是当前offset的值，Kafka会定期清理该Topic里的消息保留最新的那条数据，因为 __consumer_offsets可能会接收高并发的请求，Kafka默认给其分配50个分区，可通过 offsets.topic.num.partitions 设置，这样可通过加机器的方式抗大并发. 通过公式 hash(consumerGroupId) % __consumer_offsets主题的分区数可选出Consumer消费的offset 要提交到 __consumer_offsets的哪个分区. 消费者Rebalance机制 Rebalance机制：若消费组中消费者数量变化或消费分区数变化，Kafka会重新分配消费者消费分区的关系. 如Consumer Group中某个消费者挂了，此时会自动把分配给它的分区交给其它消费者，若其恢复则又会把一些分区重新交还给它. Rebalance只针对Subscribe这种不指定分区消费的情况，若通过 assign 消费方式指定了分区Kafka不会进行Rebanlance . 当消费组中Consumer增加或减少、 动态给Topic增加分区、 消费组订阅了更多的Topic 等情况可能触发消费者Rebalance. Rebalance过程中消费者无法从Kafka消费消息，对Kafka的TPS会有影响，若Kafka集群内节点较多， Rebalance重平衡可能会耗时极多，应尽量避免在系统高峰期Rebalance重平衡. 消费者Rebalance分区分配策略消费者Rebalance分区分配策略主要有 range 、 round-robin 、 sticky 三种 Rebalance策略，默认为 range分配策略. Kafka提供消费者客户端参数 partition.assignment.strategy 来设置消费者与订阅主题之间的分区分配策略. range策略：按分区序号排序，假设 n＝分区数／消费者数量， m＝分区数%消费者数量，则前m个消费者每个分配n+1个分区，消费者数量 - m个消费者每个分配n个分区. round-robin策略：轮询分配 sticky策略：初始时分配策略与round-robin类似，但在Rebalance时需要保证分区分配尽可能均匀、 分区分配尽可能与上次分配保持相同两个原则. 当两者发生冲突时，第一个目标优先于第二个目标 . 这样可以最大程度维持原来的分区分配的策略. Rebalance过程当有消费者加入消费组时，消费者、 消费组及组协调器之间会依次经历选择组协调器、 加入消费组、 SYNC GROUP 三个阶段； 选择组协调器：每个Consumer Group都会选择一个Broker作为自己的组协调器GroupCoordinator ，负责监控该消费组中所有消费者心跳，以及判断是否宕机，然后开启消费者Rebalance. Consumer Group中每个Consumer启动时会向Kafka集群中某个节点发送 FindCoordinatorRequest 请求来查找对应的组协调器GroupCoordinator ，并跟其建立网络连接. Consumer消费的offset要提交到 __consumer_offsets 的哪个分区，该分区Leader对应的Broker就是该Consumer Group的GroupCoordinator. 加入消费组：消费者会向 GroupCoordinator 发送 JoinGroupRequest 请求并处理响应. 然后GroupCoordinator从一个Consumer Group中选择第一个加入Group的Consumer作为Leader消费组协调器，把Consumer Group情况发送给该Leader，接着该 Consumer Leader 会负责制定分区方案. SYNC GROUP ： Consumer Leader 通过给GroupCoordinator发送SyncGroupRequest ，接着 GroupCoordinator把分区方案下发给各个Consumer ，具体的 Consumer 根据指定分区的Leader Broker进行网络连接以及消息消费. Producer发布消息机制Producer采用 push模式将消息发布到Broker，每条消息都被append到顺序写磁盘到 Patition 中，Producer发送消息到Broker时，会根据分区算法选择将其存储到哪一个Partition，路由机制为： 指定了Patition，则直接使用； 未指定Patition但指定了key ，通过对key的value进行hash选出一个Patition Patition和key都未指定，使用轮询选出一个Patition. Producer先从Zookeeper的 /brokers/.../state 节点找到该Partition的Leader，然后将消息发送给该Leader，Leader将消息写入本地commit log，Followers从Leader Pull消息，写入本地commit log后向Leader发送ACK，Leader收到所有ISR中的Replica的ACK后，增加最后 commit 的offset即 high watermark高水位简称 HW 并向Producer发送ACK. HW和LEO High Watermark 俗称高水位，取一个 Partition 对应的 ISR中最小的log-end-offset即LEO作为HW ，Consumer最多只能消费到HW所在的位置. 每个 Replica 都有 HW ， Leader 和 Follower 各自负责更新自己的HW状态. 对于 Leader新写入的消息Consumer不能立刻消费，Leader会等待该消息被所有ISR中的Replicas同步后更新HW ，此时消息才能被Consumer消费. 这样保证了若Leader所在Broker失效，该消息仍然可从新选举的Leader中获取. 对于来自内部Broker的读取请求没有HW的限制. ISR以及HW和LEO的流转过程： Kafka复制机制既不是完全的同步复制，也不是单纯的异步复制. 同步复制要求所有能工作的Follower都复制完，这条消息才会被commit极大影响了吞吐率. 异步复制方式下Follower异步从Leader复制数据，数据只要被Leader写入log就被认为已经commit，这种情况下若Follower还未复制完落后于Leader时，若Leader宕机则会丢失数据. Kafka使用 ISR 方式则很好均衡了确保数据不丢失以及吞吐率. acks=1 的情况: 日志分段存储Kafka一个分区的消息数据对应存储在一个文件夹下，以Topic名称+分区号命名，消息在分区内是分段存储，每个段的消息都存储在不一样的log文件里，这种特性方便过期分段文件快速被删除，Kafka规定一个段位的 log文件最大为 1G . Kafka每次往分区发 4K 消息就会记录一条当前消息的 offset 到 index文件以及记录一条当前消息的发送时间戳与对应的 offset 到 timeindex文件，若要定位消息的 offset 会先在index文件里快速定位，若需要按照时间来定位消息的offset ，会先在timeindex文件里查找，再去log文件里找具体消息，相当于一个稀疏索引； 123456# 部分消息的offset索引文件，Kafka每次往分区发4K(可配置)消息就会记录一条当前消息的offset到index文件，若要定位消息的offset会先在该文件里快速定位，再去log文件里找具体消息，相当于一个稀疏索引00000000000000000000.index# 消息存储文件，主要存offset和消息体00000000000000000000.log# 消息的发送时间索引文件，kafka每次往分区发4K(可配置)消息就会记录一条当前消息的发送时间戳与对应的offset到timeindex文件，若需要按照时间来定位消息的offset，会先在这个文件里查找00000000000000000000.timeindex 一个日志段文件满了，会自动开一个新的日志段文件来写入，避免单个文件过大，影响文件的读写性能，该过程叫做 log rolling ，正在被写入的日志段文件叫做 active log segment 实际问题:消息丢失消息发送端 acks=0 ： 表示Producer不需要等待任何Broker确认收到消息的回复，就可继续发送下一条消息. 性能最高，但是最容易丢消息. 大数据统计报表场景，对性能要求很高，对数据丢失不敏感的情况可用这种. acks=1 ： 至少要等待Leader已经成功将数据写入本地log，但不需要等待所有Follower是否成功写入. 就可继续发送下一条消息. 该情况下若Follower没有成功备份数据，而此时Leader挂掉则消息会丢失. acks=-1或all ： Leader需等待所有备份即 min.insync.replicas 配置的备份个数都成功写入日志，该策略会保证只要有一个备份存活就不会丢失数据 消息消费端若消费这边配置的是自动提交，万一消费到数据还没处理完，就自动提交offset了，但此时Consumer直接宕机了，未处理完的数据丢失了，下次也消费不到了. 消息重复消费消息发送端：发送消息若配置了重试机制，如网络抖动时间过长导致发送端发送超时，实际broker可能已经接收到消息，但发送方会重新发送消息 消息消费端：若消费这边配置的是自动提交，刚拉取了一批数据处理了一部分，但还没来得及提交，服务挂了，下次重启又会拉取相同的一批数据重复处理，一般消费端都是要做消费幂等处理. 消息乱序若发送端配置了重试机制，Kafka不会等之前那条消息完全发送成功才去发送下一条消息，可能会出现发送了1，2，3条消息，第一条超时了，后面两条发送成功，再重试发送第1条消息，这时消息在broker端的顺序就是2，3，1了，是否一定要配置重试要根据业务情况而定. 也可用同步发送的模式去发消息，当然acks不能设置为0，这样也能保证消息发送的有序. kafka保证全链路消息顺序消费，需要从发送端开始，将所有有序消息发送到同一个分区，然后用一个消费者去消费，但性能比较低，可在消费者端接收到消息后将需要保证顺序消费的几条消费发到内存队列，一个内存队列开启一个线程顺序处理消息. 消息积压线上有时因为发送方发送消息速度过快，或者消费方处理消息过慢，可能会导致Broker积压大量未消费消息. 若积压了上百万未消费消息需要紧急处理，可修改消费端程序，让其将收到的消息快速转发到其他Topic ，可设置很多分区，然后再启动多个消费者同时消费新主题的不同分区. 由于消息数据格式变动或消费者程序有bug，导致消费者一直消费不成功，也可能导致broker积压大量未消费消息. 此种情况可将这些消费不成功的消息转发到其它队列里去，类似死信队列，后面再慢慢分析死信队列里的消息处理问题. 延时队列延时队列存储的对象是延时消息. 指消息被发送以后，并不想让消费者立刻获取，而是等待特定的时间后，消费者才能获取该消息进行消费，但Kafka不支持延时队列. 实现思路：发送延时消息时先把消息按照不同的延迟时间段发送到指定的队列中如topic_1s，topic_5s，topic_10s，…topic_2h，一般不能支持任意时间段的延时，然后通过定时器进行轮训消费这些Topic，查看消息是否到期，若到期则把该消息发送到具体业务处理的Topic中，队列中消息越靠前的到期时间越早，具体来说就是定时器在一次消费过程中，对消息的发送时间做判断，看下是否延迟到对应时间了，若到了就转发，如果还没到这一次定时任务就可以提前结束了. 消息回溯若某段时间对已消费消息计算的结果觉得有问题，可能是由于程序bug导致的计算错误，当程序bug修复后，这时可能需要对之前已消费的消息重新消费，可以指定从多久之前的消息回溯消费，这种可以用Consumer的offsetsForTimes、 seek等方法指定从某个offset偏移的消息开始消费. 消息传递保障kafka生产者的幂等性，因发送端重试导致的消息重复发送问题，Kafka幂等性可保证重复发送的消息只接收一次，只需在生产者加上参数 props.put(&quot;enable.idempotence&quot;, true) 即可，默认是false不开启，Kafka每次发送消息会生成 PID 和 Sequence Number 并将这两个属性一起发送给Broker，Broker将PID和Sequence Number跟消息绑定一起存起来，若生产者重发相同消息，Broker会检查PID和Sequence Number，若相同不会再接收. 每个新的Producer在初始化时会被分配一个唯一的PID，PID对用户完全是透明的，生产者若重启则会生成新的PID，每个PID该Producer发送到每个Partition的数据都有对应的序列号即 Sequence Number ，这些序列号是从0开始单调递增的. Kafka的事务Kafka事务不同于Rocketmq，Rocketmq是保障本地事务与MQ消息发送的事务一致性，Kafka的事务主要是保障一次发送多条消息的事务一致性，一般在Kafka流式计算场景用得多一点，如kafka需要对一个Topic中的消息做不同的流式计算处理，处理完分别发到不同的Topic里，这些Topic分别被不同的下游系统消费如hbase，redis，es等，这种肯定希望系统发送到多个topic的数据保持事务一致性. 12345678910111213141516171819202122Properties props = new Properties();props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);props.put(&quot;transactional.id&quot;, &quot;my-transactional-id&quot;);Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props, new StringSerializer(), new StringSerializer());producer.initTransactions(); //初始化事务try &#123; producer.beginTransaction(); //开启事务 for (int i = 0; i &lt; 100; i++) &#123;//发到不同的主题的不同分区 producer.send(new ProducerRecord&lt;&gt;(&quot;hdfs-topic&quot;, Integer.toString(i), Integer.toString(i))); producer.send(new ProducerRecord&lt;&gt;(&quot;es-topic&quot;, Integer.toString(i), Integer.toString(i))); producer.send(new ProducerRecord&lt;&gt;(&quot;redis-topic&quot;, Integer.toString(i), Integer.toString(i))); &#125; producer.commitTransaction(); //提交事务&#125; catch (ProducerFencedException | OutOfOrderSequenceException | AuthorizationException e) &#123; producer.close();&#125; catch (KafkaException e) &#123; producer.abortTransaction(); //回滚事务&#125;producer.close();","tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://example.com/tags/Kafka/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"Kafka","slug":"工具和中间件/消息队列/Kafka","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Kafka/"}]},{"title":"ActiveMQ-队列模式","date":"2019-03-23T03:08:20.000Z","path":"blog/工具和中间件/消息队列/Activemq/ActiveMQ-队列模式/","text":"pom.xml导入activemq jar包 12345678910111213141516&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;artifactId&gt;activemq&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;activemq&lt;/name&gt; &lt;description&gt;activemq&lt;/description&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-all&lt;/artifactId&gt; &lt;version&gt;5.15.9&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; TestProducer.java生产100条消息。注： activemq 服务器应先启动。 12345678910111213141516171819202122232425262728293031323334353637383940414243package cn.peach.queue; import javax.jms.Connection;import javax.jms.ConnectionFactory;import javax.jms.Destination;import javax.jms.JMSException;import javax.jms.MessageProducer;import javax.jms.Session;import javax.jms.TextMessage; import org.apache.activemq.ActiveMQConnectionFactory; public class TestProducer &#123; //服务地址，端口默认61616 private static final String url=&quot;tcp://127.0.0.1:61616&quot;; //这次发送的消息名称 private static final String topicName=&quot;queue_style&quot;; public static void main(String[] args) throws JMSException &#123; //1.创建ConnectionFactory,绑定地址 ConnectionFactory factory=new ActiveMQConnectionFactory(url); //2.创建Connection Connection connection= factory.createConnection(); //3.启动连接 connection.start(); //4.创建会话 Session session=connection.createSession(false, Session.AUTO_ACKNOWLEDGE); //5.创建一个目标 (队列类型) Destination destination=session.createQueue(topicName); //6.创建一个生产者 MessageProducer producer=session.createProducer(destination); for (int i = 0; i &lt; 100; i++) &#123; //7.创建消息 TextMessage textMessage=session.createTextMessage(&quot;队列消息-&quot;+i); //8.发送消息 producer.send(textMessage); System.out.println(&quot;发送：&quot;+textMessage.getText()); &#125; //7. 关闭连接 connection.close(); &#125;&#125; TestConsumer.java消费者，消费服务器上的消息。注： activemq 服务器应先启动。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package cn.peach.queue; import javax.jms.Connection;import javax.jms.ConnectionFactory;import javax.jms.Destination;import javax.jms.JMSException;import javax.jms.Message;import javax.jms.MessageConsumer;import javax.jms.MessageListener;import javax.jms.Session;import javax.jms.TextMessage; import org.apache.activemq.ActiveMQConnectionFactory; import cn.peach.util.ActiveMQUtil;import cn.hutool.core.util.RandomUtil;/** * 订阅者 * @author root * */public class TestConsumer &#123; //服务地址，端口默认61616 private static final String url=&quot;tcp://127.0.0.1:61616&quot;; //这次消费的消息名称 private static final String topicName=&quot;queue_style&quot;; //消费者有可能是多个，为了区分不同的消费者，为其创建随机名称 private static final String consumerName=&quot;consumer-&quot; + RandomUtil.randomString(5); public static void main(String[] args) throws JMSException &#123; //1.创建ConnectiongFactory,绑定地址 ConnectionFactory factory=new ActiveMQConnectionFactory(url); //2.创建Connection Connection connection= factory.createConnection(); //3.启动连接 connection.start(); //4.创建会话 Session session=connection.createSession(false, Session.AUTO_ACKNOWLEDGE); //5.创建一个目标 （队列类型） Destination destination=session.createQueue(topicName); //6.创建一个消费者 MessageConsumer consumer=session.createConsumer(destination); //7.创建一个监听器 consumer.setMessageListener(new MessageListener() &#123; public void onMessage(Message arg0) &#123; // TODO Auto-generated method stub TextMessage textMessage=(TextMessage)arg0; try &#123; System.out.println(consumerName +&quot; 接收消息：&quot;+textMessage.getText()); &#125; catch (JMSException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; &#125;); //8. 因为不知道什么时候有，所以没法主动关闭，就不关闭了，一直处于监听状态 //connection.close(); &#125;&#125; 管理界面访问地址： http://127.0.0.1:8161/admin/queues.jsp 就可以看到 刚才的消息处理情况。 queue_style 是在代码中定义的消息名称。 number Of Consumers 表示有2个消费者。 Messages Enqueued：表示收到了 100 个消息。 Messages Dequeued：表示消费了 100 个消息。","tags":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"http://example.com/tags/ActiveMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"Activemq","slug":"工具和中间件/消息队列/Activemq","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Activemq/"}]},{"title":"RabbitMQ-fanout模式","date":"2019-03-23T03:08:20.000Z","path":"blog/工具和中间件/消息队列/RabbitMQ/RabbitMQ-fanout模式/","text":"pom.xml提供 rabbitmq和hutool的jar 1234567891011121314151617181920&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;artifactId&gt;rabbitmq&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;rabbitmq&lt;/name&gt; &lt;description&gt;rabbitmq&lt;/description&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt; &lt;artifactId&gt;amqp-client&lt;/artifactId&gt; &lt;version&gt;3.6.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;4.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; TestProducer.java12345678910111213141516171819202122232425262728293031323334353637383940package cn.peach;import java.io.IOException;import java.util.concurrent.TimeoutException; import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory; /** * 消息生成者 */public class TestProducer &#123; public final static String EXCHANGE_NAME=&quot;fanout_exchange&quot;; public static void main(String[] args) throws IOException, TimeoutException &#123; RabbitMQUtil.checkServer(); //创建连接工厂 ConnectionFactory factory = new ConnectionFactory(); //设置RabbitMQ相关信息 factory.setHost(&quot;localhost&quot;); //创建一个新的连接 Connection connection = factory.newConnection(); //创建一个通道 Channel channel = connection.createChannel(); channel.exchangeDeclare(EXCHANGE_NAME, &quot;fanout&quot;); for (int i = 0; i &lt; 100; i++) &#123; String message = &quot;direct 消息 &quot; +i; //发送消息到队列中 channel.basicPublish(EXCHANGE_NAME, &quot;&quot;, null, message.getBytes(&quot;UTF-8&quot;)); System.out.println(&quot;发送消息： &quot; + message); &#125; //关闭通道和连接 channel.close(); connection.close(); &#125;&#125; TestDriectCustomer.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package cn.peach;import java.io.IOException;import java.util.concurrent.TimeoutException; import com.rabbitmq.client.AMQP;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import com.rabbitmq.client.Consumer;import com.rabbitmq.client.DefaultConsumer;import com.rabbitmq.client.Envelope; import cn.hutool.core.util.RandomUtil; public class TestCustomer &#123; public final static String EXCHANGE_NAME=&quot;fanout_exchange&quot;; public static void main(String[] args) throws IOException, TimeoutException &#123; //为当前消费者取随机名 String name = &quot;consumer-&quot;+ RandomUtil.randomString(5); //判断服务器是否启动 RabbitMQUtil.checkServer(); // 创建连接工厂 ConnectionFactory factory = new ConnectionFactory(); //设置RabbitMQ地址 factory.setHost(&quot;localhost&quot;); //创建一个新的连接 Connection connection = factory.newConnection(); //创建一个通道 Channel channel = connection.createChannel(); //交换机声明（参数为：交换机名称；交换机类型） channel.exchangeDeclare(EXCHANGE_NAME,&quot;fanout&quot;); //获取一个临时队列 String queueName = channel.queueDeclare().getQueue(); //队列与交换机绑定（参数为：队列名称；交换机名称；routingKey忽略） channel.queueBind(queueName,EXCHANGE_NAME,&quot;&quot;); System.out.println(name +&quot; 等待接受消息&quot;); //DefaultConsumer类实现了Consumer接口，通过传入一个频道， // 告诉服务器我们需要那个频道的消息，如果频道中有消息，就会执行回调函数handleDelivery Consumer consumer = new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; String message = new String(body, &quot;UTF-8&quot;); System.out.println(name + &quot; 接收到消息 &#x27;&quot; + message + &quot;&#x27;&quot;); &#125; &#125;; //自动回复队列应答 -- RabbitMQ中的消息确认机制 channel.basicConsume(queueName, true, consumer); &#125;&#125; 运行效果先运行两次 TestCustomer，启动两个消费者。然后运行一次 TestProducer， 启动生产者，生产100条信息。此时就可以看到如图所示两个消费者都能收到 这100条信息","tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://example.com/tags/RabbitMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RabbitMQ","slug":"工具和中间件/消息队列/RabbitMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/"}]},{"title":"ActiveMQ-基础","date":"2019-03-23T02:08:20.000Z","path":"blog/工具和中间件/消息队列/Activemq/ActiveMQ-基础/","text":"ActiveMQ：ActiveMQ 是用 Java 语言开发的消息中间件，简单易用。只需要操作系统支持Java虚拟机，ActiveMQ便可执行。 下载并启动：apache-activemq-5.15.8-bin.rar, 解压并运行32或者64位操作系统对应的 activemq.bat 就启动 启动成功界面 访问地址启动好之后， 访问地址 http://127.0.0.1:8161/ 就可以看到如图所示的界面。这就是服务器的管理界面，在里面就可以看到都有哪些消息被创建了，哪些被消费了 管理界面点击 manage activeMQ broker, 或者直接访问地址：http://127.0.0.1:8161/admin/会弹出登录对话框，输入默认的账号和密码，都是： admin就来到了管理界面了。 观察数据这里可以观察到 队列数据和主题数据等信息，不过还没有客户端发消息来，所以也没有数据，就先不管。 模式activeMQ 有两种模式，分别是 队列模式 和 主题模式。 队列模式，其实就是分食模式。 比如生产方发了 10条消息到 activeMQ 服务器， 而此时有多个 消费方，那么这些消费方就会瓜分这些10条消息，一条消息只会被一个消费方得到。 主题模式，就是订阅模式。 比如生产方发了10条消息，而此时有多个消费方，那么多个消费方都能得到这 10条消息，就如同订阅公众号那样。","tags":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"http://example.com/tags/ActiveMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"Activemq","slug":"工具和中间件/消息队列/Activemq","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Activemq/"}]},{"title":"RabbitMQ-基础","date":"2019-03-23T02:08:20.000Z","path":"blog/工具和中间件/消息队列/RabbitMQ/RabbitMQ-基础/","text":"介绍RabbitMQ 也是一种 消息中间件的实现。与ActiveMQ的区别在： rabbitmq 更专业，更灵活，大企业，大型高要求的应用，普遍会采用 rabbitmq 来支持。 erlangrabbitMQ 是基于 erlang 语言开发的，就如同 activemq 需要安装 java 环境一样， 为了使用 rabbitMQ 需要安装 erlang环境。 erlang 环境使用快捷键 win+r, 然后输入 cmd, 接着运行 erl。 出现如图所示的界面，就表示安装成功了。 安装 rabbitMQ官网下载rar包, 运行里面的 rabbitmq-server-3.6.5.exe，使用默认设置，下一步下一步即可。 配置插件运行如下命令 enable rabbitmq_management，可以做到对 rabbitmq的插件配置。 1C:\\Program Files\\RabbitMQ Server\\rabbitmq_server-3.6.5\\sbin\\rabbitmq-plugins.bat&quot; enable rabbitmq_management 重启 rabbitmq管理员身份运行以下命令以重启 rabbitmq： 1net stop RabbitMQ &amp;&amp; net start RabbitMQ 访问管理界面管理界面： http://127.0.0.1:15672 输入账号： guest密码： guest就可以登陆进去了。 管理界面 RabbitMQ - 模式AMQP AMQP 是 dvanced Message Queuing Protocol 的缩写。 与activemq不一样， rabbitmq 使用的是一种叫做 AMQP 的协议来通信。简单地说，通过这种协议，可以处理更为复杂的业务需求。 基于 AMQP 这种协议，可以实现的各种模式 消息路由过程与 ActiveMQ 拿到消息就直接放在队列等待消费者拿走不同， Rabbit 拿到消息之后，会先交给 交换机 （Exchange）, 然后交换机再根据预先设定的不同绑定( Bindings )策略，来确定要发给哪个队列。如图所示，比起 ActiveMQ 多了 Exchange 和 Bindings。由于有了 Exchange 和 Bindings， RabbitMQ 就可以灵活地支撑各种模式。 模式RabbitMQ提供了 四种Exchange模式： fanout, direct, topic, header。 1. fanout 模式fanout 模式就是广播模式, 消息来了，会发给所有的队列。 2. Direct 模式Direct 模式就是指定队列模式， 消息来了，只发给指定的 Queue, 其他Queue 都收不到。 3. Topic 模式主题模式，注意这里的主题模式，和 ActivityMQ 里的不一样。 ActivityMQ 里的主题，更像是广播模式。那么这里的主题模式是什么意思呢？ 如图所示消息来源有： 美国新闻，美国天气，欧洲新闻，欧洲天气。如果你想看 美国主题： 那么就会收到 美国新闻，美国天气。如果你想看 新闻主题： 那么就会收到 美国新闻，欧洲新闻。如果你想看 天气主题： 那么就会收到 美国天气，欧洲天气。如果你想看 欧洲主题： 那么就会收到 欧洲新闻，欧洲天气。 4. headers交换机 模式。headers交换机是一种比较复杂且少见的交换机，不同于direct和topic，它不关心路由key是否匹配，而只关心header中的key-value对是否匹配(这里的匹配为精确匹配，包含键和值都必须匹配)， 有点类似于http中的请求头。headers头路由模型中，消息是根据prop即请求头中key-value来匹配的。消费方指定的headers中必须包含一个”x-match”的键。 键”x-match”的值有2个：all和any。all：表示消费方指定的所有key-value都必须在消息header中出现并匹配。any：表示消费方指定的key-value至少有一个在消息header中出现并匹配即可。 headers 匹配规则：any 、allany: 只要在发布消息时携带的有一对键值对headers满足队列定义的多个参数的其中一个就能匹配上，注意这里是键值对的完全匹配，只匹配到键了，值却不一样是不行的；all：在发布消息时携带的所有Entry必须和绑定在队列上的所有Entry完全匹配。缺点：Headers 类型的交换器性能会很差","tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://example.com/tags/RabbitMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RabbitMQ","slug":"工具和中间件/消息队列/RabbitMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/"}]},{"title":"Kafka-基础","date":"2019-03-23T02:08:20.000Z","path":"blog/工具和中间件/消息队列/Kafka/Kafka-基础/","text":"Kafka是什么? Kafka 是 scala 语言编写的 支持partition分区、 replica多副本, 基于Zookeeper协调 的 分布式消息系统, 可 实时处理大量数据 以满足各种需求场景, 如基于hadoop批处理系统、 低延迟实时系统、 Storm&#x2F;Spark流式处理引擎, web&#x2F;nginx日志、 访问日志, 消息服务等. 名称 解释 Broker 消息中间件处理节点, 一个Kafka节点就是一个Broker, 一个或者多个Broker组成Kafka集群 Topic Kafka根据Topic对消息进行归类, 发布到Kafka集群的每条消息都需指定一个Topic Producer 消息生产者, 向Broker发送消息的客户端, 通过TCP协议来完成通信 Consumer 消息消费者, 从Broker读取消息的客户端, 通过TCP协议来完成通信 Consumer Group 每个Consumer属于一个特定Consumer Group, 一条消息可被多个不同Consumer Group消费, 但一个Consumer Group中只能有一个Consumer能消费该消息 Partition 物理上的概念, 一个Topic可分为多个Partition, 每个Partition内部消息是有序的 使用场景 日志收集：可用Kafka收集各种服务日志, 通过kafka以统一接口服务方式开放给各种Consumer, 如Hhadoop、 Hbase、 Solr等. 消息系统：解耦生产者和消费者、 缓存消息等. 用户活动跟踪：Kafka经常被用来记录Web用户或App用户的各种活动, 如浏览网页、 搜索、 点击等活动, 被各个服务器发布到kafka的Topic中, 然后订阅者通过订阅这些Topic来做实时监控分析, 或装载到Hadoop、 数据仓库中做离线分析和挖掘. 运营指标：Kafka也经常用来记录运营监控数据. 包括收集各种分布式应用数据, 生产各种操作的集中反馈, 如报警和报告. Kafka核心配置Kafka核心配置在 config/server.properties 配置文件中. 1234broker.id=0 # broker.id属性在kafka集群中必须要是唯一listeners=PLAINTEXT://localhost:9092 # kafka部署的机器ip和提供服务的端口号log.dir=/usr/local/data/kafka-logs # kafka的消息存储文件zookeeper.connect=192.168.65.60:2181 # kafka连接zookeeper的地址, 若是集群则用逗号分割 Property Default Description broker.id 0 每个Broker都可用一个唯一非负整数id进行标识 log.dirs /tmp/kafka-logs 存放数据的路径, 该路径并不唯一, 可设置多个路径之间用逗号分隔, 创建新partition时选择包含最少partitions路径下创建 listeners PLAINTEXT://192.168.65.60:9092 Server接受客户端连接的端口, ip配置kafka本机ip即可 zookeeper.connect localhost:2181 Kafka连接Zookeeper的地址, 若是集群用逗号分隔 log.retention.hours 168 每个日志文件的保存时间. 默认数据保存时间对所有topic都一样 num.partitions 1 创建Topic默认分区数 default.replication.factor 1 自动创建Topic默认副本数量, 建议设置为大于等于2 min.insync.replicas 1 写数据到repica数量达到设定值才表示Producer发送消息成功, 若Producer设置acks为-1, 则每个repica写数据都必须成功 delete.topic.enable false 是否允许删除主题 12345678910111213141516171819202122232425262728bin/kafka-server-start.sh config/server.properties # 启动kafkabin/kafka-server-stop.sh # 停止kafka# 创建名字为test的Topic, 该topic只有一个partition, 且备份因子为1bin/kafka-topics.sh --zookeeper localhost:2181 --create --replication-factor 1 --partitions 1 --topic test# 查看kafka中目前存在的topicbin/kafka-topics.sh --zookeeper localhost:2181 --list# 删除topicbin/kafka-topics.sh --zookeeper localhost:2181 --delete --topic test# 发送消息到kafka, 若是集群--broker-list参数用逗号隔开bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test# 消费kafka集群最新消息, 若是集群--bootstrap-server参数用逗号隔开bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test# 多主题消费kafka集群消息bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --whitelist &quot;test|test-2&quot;# 通过--from-beginning从开始读取kafka集群消息bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --from-beginning --topic test# 单播消费, 一条消息只能被某一个消费者消费, 让所有消费者在同一个消费组里即可bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --consumer-property group.id=testGroup --topic test# 多播消费, 同一条消息只能被同一个消费组下的某一个消费者消费的特性bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --consumer-property group.id=testGroup-2 --topic test# 查看消费组名bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list# 查看消费组的消费偏移量, current-offset当前消费组的已消费偏移量, log-end-offset主题对应分区消息结束偏移量, lag当前消费组未消费消息数bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group testGroup# 查看下topic情况bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic test# 增加topic的分区数量, 目前kafka不支持减少分区bin/kafka-topics.sh --zookeeper localhost:2181 --alter --partitions 3 --topic test 同类消息发送到同一个Topic下面, 每个Topic下面可有多个分区Partition日志文件, Partition 是一个有序的message序列, 这些message按顺序添加到 commit log文件 中. 每个Partition中消息都有一个唯一编号 offset , 用来唯一标识某个分区中的message. 每个Partition都对应一个commit log文件, 同一个Partition 中的 message 的offset都是 唯一 的, 但 不同Partition 中 message 的 offset 可能相同. 每个Partition分区中都有一个Leader副本节点和一个或多个Replicas副本以及一个 Isr 集合， Partition的Leader副本节点负责给定Partition的所有读写请求，Replicas表示某个Partition在哪几个Broker上存在备份，不管该节点是不是Leader，甚至该节点挂了也会列出. Isr 集合是Replicas的一个子集，只列出存活的备份节点，且已同步备份了该Partition的节点. Kafka一般不会删除消息，不管是否被消费. 只会根据配置的日志保留时间log.retention.hours 确认消息多久被删除，默认保留最近一周的消息. Kafka性能与保留消息数据量大小没有关系. 每个Consumer是基于commit log中消费进度即offset 来进行工作的，消费offset由Consumer来维护，一般按照顺序逐条消费commit log中的消息，可通过指定offset来重复消费某些消息或跳过某些消息. 意味Consumer对集群影响非常小，添加或减少Consumer对于集群或其他Consumer没有影响，因为每个Consumer维护各自的消费offset . 一个Topic代表逻辑上的一个业务数据集，对于大型网站来说，后端数据都是海量的，消息可能非常巨量，若把这么多数据都放在一台机器上可能会有容量限制问题，可在 Topic内部划分多个Partition 来分片存储数据，不同Partition可位于不同机器上，每台机器上都运行一个Kafka的Broker进程. 分片存储的好处，提高并行度，且 commit log 文件会受到所在机器的文件系统大小的限制，分区后可将不同分区放在不同机器上，相当于对数据做分布式存储，理论上一个Topic可处理任意数量数据. Kafka集群Kafka将很多集群关键信息记录在 Zookeeper 中，保证自己的无状态，从而在水平扩容时非常方便. commit log 的 Partitions 分布在Kafka集群中不同Broker上，每个Broker上该Partition分区的副本可请求备份其他Broker上Partition上副本的数据，Kafka集群支持配置一个Partition备份数量. 每个Partition都有一个Broker上的副本起到Leader的作用， 0个或多个其他的Broker副本作为 Follwers 作用. 作为 Leader的副本处理所有针对该Partition的读写请求，作为Followers的副本被动复制作为Leader的副本的结果，不提供读写，主要是为了保证多副本数据与消费的一致性. 若一个Partition分区中 Leader副本失效其中一个 Follower副本将自动变成新的 Leader副本. 生产者将消息发送到Topic中去，同时负责选择将message发送到 Topic的哪个Partition中. 通过 round-robin 做简单的负载均衡. 也可根据消息中某个关键字来进行区分，通常第二种方式使用更多. 对于消费者，传统的消息传递模式有队列模式和发布订阅模式，且基于这2种模式提供了一种Consumer的抽象概念 Consumer Group . Queue模式：多个Consumer从服务器中读取数据，消息只会到达一个Consumer ，所有Consumer都位于同一Consumer Group下 Publish-Subscribe模式：消息会被广播给所有Consumer，所有Consumer都有唯一的Consumer Group . 通常一个Topic会有几个Consumer Group，每个Consumer Group都是一个逻辑上的订阅者，每个Consumer Group由多个Consumer 实例组成，从而达到可扩展和容灾的功能. 一个Partition同一时刻在一个Consumer Group中只能有一个Consumer在消费， Partition分区类似于RocketMQ中的队列，从而保证消费顺序. Consumer Group中的Consumer数不能比一个Topic中Partition的数量多，否则多出来的Consumer消费不到消息. Kafka只在Partition范围内保证消息消费的局部顺序性，不能在同一个Topic中多个Partition中保证总的消费顺序性. 若有在总体上保证消费顺序的需求，则可通过将Topic的Partition数量设置为1 ，将Consumer Group中的Consumer数量也设置为1 ，但会影响性能，故Kafka顺序消费很少用. 客户端调用12345&lt;dependency&gt; &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt; &lt;version&gt;2.4.1&lt;/version&gt;&lt;/dependency&gt; 生产者包含一些关键的参数，包括发送消息持久化机制参数ProducerConfig.ACKS_CONFIG ，发送失败会重试次数 ProducerConfig.RETRIES_CONFIG ，重试时间间隔 ProducerConfig.RETRY_BACKOFF_MS_CONFIG ，以及发送时可指定Partition分区，同步发送异步发送等. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152Properties props = new Properties();props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:9092&quot;);/* 发出消息持久化机制参数（1）acks=0：表示producer不需要等待任何broker确认收到消息的回复，就可以继续发送下一条消息. 性能最高，但是最容易丢消息. （2）acks=1：至少等待leader成功将数据写入本地log，但不用等待所有followe都成功写入. 就可继续发送下一条消息. 该情况下若follower没有成功备份数据，而此时leader又挂掉，则消息会丢失. （3）acks=-1或all：需等待min.insync.replicas，默认为1，推荐配置大于等于2，该参数配置的副本个数都成功写入日志，这种策略会保证 只要有一个备份存活就不会丢失数据. 这是最强的数据保证. 一般除非是金融级别，或跟钱打交道的场景才会使用这种配置. */props.put(ProducerConfig.ACKS_CONFIG, &quot;1&quot;);// 发送失败会重试，默认重试间隔100ms，重试能保证消息发送的可靠性，但也可能造成消息重复发送，如网络抖动，故需在接收者处做好消息接收的幂等性处理props.put(ProducerConfig.RETRIES_CONFIG, 3);// 重试时间间隔设置props.put(ProducerConfig.RETRY_BACKOFF_MS_CONFIG, 300);// 设置发送消息的本地缓冲区，如果设置了该缓冲区，消息会先发送到本地缓冲区，可以提高消息发送性能，默认值是33554432，即32MBprops.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 33554432);// kafka本地线程会从缓冲区取数据，批量发送到broker，设置批量发送消息的大小，默认值是16384，即16kb，就是说一个batch满了16kb就发送出去props.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384);// 默认值是0，消息必须立即被发送，但这样会影响性能，一般设置10毫秒左右，该消息发送完后会进入本地的一个batch，// 若10毫秒内该batch满了16kb就随batch一起被发送出去，若10毫秒内batch没满，则也必须把消息发送出去，不能让消息的发送延迟时间太长props.put(ProducerConfig.LINGER_MS_CONFIG, 10);// 把发送的key从字符串序列化为字节数组props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());// 把发送消息value从字符串序列化为字节数组props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());Producer&lt;String, String&gt; producer = new KafkaProducer&lt;String, String&gt;(props);int msgNum = 5;final CountDownLatch countDownLatch = new CountDownLatch(msgNum);for (int i = 1; i &lt;= msgNum; i++) &#123; // 指定发送分区 // ProducerRecord&lt;String, String&gt; producerRecord = new ProducerRecord&lt;String, String&gt;(TOPIC_NAME , 0, order.getOrderId().toString(), JSON.toJSONString(order)); // 未指定发送分区，具体发送的分区计算公式：hash(key)%partitionNum ProducerRecord&lt;String, String&gt; producerRecord = new ProducerRecord&lt;String, String&gt;(TOPIC_NAME, String.valueOf(i), &quot;order &quot; + i); // 等待消息发送成功的同步阻塞方法 // RecordMetadata metadata = producer.send(producerRecord).get(); // System.out.println(&quot;同步方式发送消息结果：&quot; + &quot;topic-&quot; + metadata.topic() + &quot;|partition-&quot; + metadata.partition() + &quot;|offset-&quot; + metadata.offset()); //异步回调方式发送消息 producer.send(producerRecord, new Callback() &#123; @Override public void onCompletion(RecordMetadata metadata, Exception exception) &#123; if (exception != null) &#123; System.err.println(&quot;发送消息失败：&quot; + exception.getStackTrace()); &#125; if (metadata != null) &#123; System.out.println(&quot;异步方式发送消息结果：&quot; + &quot;topic-&quot; + metadata.topic() + &quot;|partition-&quot; + metadata.partition() + &quot;|offset-&quot; + metadata.offset()); &#125; countDownLatch.countDown(); &#125; &#125;);&#125;countDownLatch.await(5, TimeUnit.SECONDS);producer.close(); 消费者同样可指定消费的分区，指定消费者组名称，是否自动提交，自动提交时间间隔，心跳时间间隔等. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980String TOPIC_NAME = &quot;my-replicated-topic&quot;;String CONSUMER_GROUP_NAME = &quot;testGroup&quot;;Properties props = new Properties();props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:9092&quot;);// 消费分组名props.put(ConsumerConfig.GROUP_ID_CONFIG, CONSUMER_GROUP_NAME);// 是否自动提交offset，默认就是trueprops.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, &quot;true&quot;);// 自动提交offset的间隔时间props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, &quot;1000&quot;);//props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, &quot;false&quot;);/*当消费主题的是一个新的消费组，或指定offset的消费方式，offset不存在，则可通过以下两种方式消费消息- latest(默认) ：只消费自己启动之后发送到主题的消息- earliest：第一次从头开始消费，以后按照消费offset记录继续消费，这个需要区别于consumer.seekToBeginning(每次都从头开始消费)*///props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, &quot;earliest&quot;);// consumer给broker发送心跳的间隔时间，broker接收到心跳若此时有rebalance发生会通过心跳响应将rebalance方案下发给consumer，该时间可以稍微短一点props.put(ConsumerConfig.HEARTBEAT_INTERVAL_MS_CONFIG, 1000);// 服务端broker多久感知不到一个consumer心跳就认为他故障了，会将其踢出消费组，对应的Partition也会被重新分配给其他consumer，默认是10秒props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, 10 * 1000);// 一次poll最大拉取消息的条数，若消费者处理速度很快，可以设置大点，若处理速度一般，可以设置小点props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, 500);// 若两次poll操作间隔超过该时间，则broker认为该consumer处理能力太弱，会将其踢出消费组，将分区分配给别的consumer消费props.put(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG, 30 * 1000);props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;String, String&gt;(props);consumer.subscribe(Arrays.asList(TOPIC_NAME));// 消费指定分区//consumer.assign(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));// 消息回溯消费//consumer.seekToBeginning(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));// 指定offset消费//consumer.seek(new TopicPartition(TOPIC_NAME, 0), 10);// 从指定时间点开始消费/*List&lt;PartitionInfo&gt; topicPartitions = consumer.partitionsFor(TOPIC_NAME);//从1小时前开始消费long fetchDataTime = new Date().getTime() - 1000 * 60 * 60;Map&lt;TopicPartition, Long&gt; map = new HashMap&lt;&gt;();for (PartitionInfo par : topicPartitions) &#123; map.put(new TopicPartition(topicName, par.partition()), fetchDataTime);&#125;Map&lt;TopicPartition, OffsetAndTimestamp&gt; parMap = consumer.offsetsForTimes(map);for (Map.Entry&lt;TopicPartition, OffsetAndTimestamp&gt; entry : parMap.entrySet()) &#123; TopicPartition key = entry.getKey(); OffsetAndTimestamp value = entry.getValue(); if (key == null || value == null) continue; Long offset = value.offset(); System.out.println(&quot;partition-&quot; + key.partition() + &quot;|offset-&quot; + offset); System.out.println(); //根据消费里的timestamp确定offset if (value != null) &#123; consumer.assign(Arrays.asList(key)); consumer.seek(key, offset); &#125;&#125;*/while (true) &#123; // poll() API 是拉取消息的长轮询 ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofMillis(1000)); for (ConsumerRecord&lt;String, String&gt; record : records) &#123; System.out.printf(&quot;收到消息：partition = %d, offset = %d, key = %s, value = %s%n&quot;, record.partition(), record.offset(), record.key(), record.value()); &#125; /*if (records.count() &gt; 0) &#123; // 手动同步提交offset，当前线程会阻塞直到offset提交成功一般使用同步提交，因为提交之后一般也没有什么逻辑代码了 consumer.commitSync(); // 手动异步提交offset，当前线程提交offset不会阻塞，可以继续处理后面的程序逻辑 consumer.commitAsync(new OffsetCommitCallback() &#123; @Override public void onComplete(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets, Exception exception) &#123; if (exception != null) &#123; System.err.println(&quot;Commit failed for &quot; + offsets); System.err.println(&quot;Commit failed exception: &quot; + exception.getStackTrace()); &#125; &#125; &#125;); &#125;*/&#125;","tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://example.com/tags/Kafka/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"Kafka","slug":"工具和中间件/消息队列/Kafka","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Kafka/"}]},{"title":"Solr更新和删除索引","date":"2018-12-01T08:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/Solr/Solr更新和删除索引/","text":"SolrUtil.javaSolrUtil提供一个对象的增加或者更新(都是同一个方法） 1234567public static &lt;T&gt; boolean saveOrUpdate(T entity) throws SolrServerException, IOException &#123; DocumentObjectBinder binder = new DocumentObjectBinder(); SolrInputDocument doc = binder.toSolrInputDocument(entity); client.add(doc); client.commit(); return true;&#125; 根据id删除这个索引 12345678910public static boolean deleteById(String id) &#123; try &#123; client.deleteById(id); client.commit(); &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; return true;&#125; 完整代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102package cn.peach;import java.io.IOException;import java.util.List;import org.apache.solr.client.solrj.SolrClient;import org.apache.solr.client.solrj.SolrQuery;import org.apache.solr.client.solrj.SolrServerException;import org.apache.solr.client.solrj.beans.DocumentObjectBinder;import org.apache.solr.client.solrj.impl.HttpSolrClient;import org.apache.solr.client.solrj.response.QueryResponse;import org.apache.solr.common.SolrDocument;import org.apache.solr.common.SolrDocumentList;import org.apache.solr.common.SolrInputDocument;import org.apache.solr.common.util.NamedList;public class SolrUtil &#123; public static SolrClient client; private static String url; static &#123; url = &quot;http://localhost:8983/solr/howToSolr&quot;; client = new HttpSolrClient.Builder(url).build(); &#125; public static void queryHighlight(String keywords) throws SolrServerException, IOException &#123; SolrQuery q = new SolrQuery(); //开始页数 q.setStart(0); //每页显示条数 q.setRows(10); // 设置查询关键字 q.setQuery(keywords); // 开启高亮 q.setHighlight(true); // 高亮字段 q.addHighlightField(&quot;name&quot;); // 高亮单词的前缀 q.setHighlightSimplePre(&quot;&lt;span style=&#x27;color:red&#x27;&gt;&quot;); // 高亮单词的后缀 q.setHighlightSimplePost(&quot;&lt;/span&gt;&quot;); //摘要最长100个字符 q.setHighlightFragsize(100); //查询 QueryResponse query = client.query(q); //获取高亮字段name相应结果 NamedList&lt;Object&gt; response = query.getResponse(); NamedList&lt;?&gt; highlighting = (NamedList&lt;?&gt;) response.get(&quot;highlighting&quot;); for (int i = 0; i &lt; highlighting.size(); i++) &#123; System.out.println(highlighting.getName(i) + &quot;：&quot; + highlighting.getVal(i)); &#125; //获取查询结果 SolrDocumentList results = query.getResults(); for (SolrDocument result : results) &#123; System.out.println(result.toString()); &#125; &#125; public static &lt;T&gt; boolean batchSaveOrUpdate(List&lt;T&gt; entities) throws SolrServerException, IOException &#123; DocumentObjectBinder binder = new DocumentObjectBinder(); int total = entities.size(); int count=0; for (T t : entities) &#123; SolrInputDocument doc = binder.toSolrInputDocument(t); client.add(doc); System.out.printf(&quot;添加数据到索引中，总共要添加 %d 条记录，当前添加第%d条 %n&quot;,total,++count); &#125; client.commit(); return true; &#125; public static QueryResponse query(String keywords,int startOfPage, int numberOfPage) throws SolrServerException, IOException &#123; SolrQuery query = new SolrQuery(); query.setStart(startOfPage); query.setRows(numberOfPage); query.setQuery(keywords); QueryResponse rsp = client.query(query); return rsp; &#125; public static &lt;T&gt; boolean saveOrUpdate(T entity) throws SolrServerException, IOException &#123; DocumentObjectBinder binder = new DocumentObjectBinder(); SolrInputDocument doc = binder.toSolrInputDocument(entity); client.add(doc); client.commit(); return true; &#125; public static boolean deleteById(String id) &#123; try &#123; client.deleteById(id); client.commit(); &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; return true; &#125; &#125; TestSolr4j.java 修改之前查询一次 修改之后查询一次 删除之后查询一次 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package cn.peach;import java.io.IOException;import java.util.Collection;import java.util.List;import org.apache.solr.client.solrj.SolrServerException;import org.apache.solr.client.solrj.response.QueryResponse;import org.apache.solr.common.SolrDocument;import org.apache.solr.common.SolrDocumentList;public class TestSolr4j &#123; public static void main(String[] args) throws SolrServerException, IOException &#123; String keyword = &quot;name:鞭&quot;; System.out.println(&quot;修改之前&quot;); query(keyword); Product p = new Product(); p.setId(51173); p.setName(&quot;修改后的神鞭&quot;); SolrUtil.saveOrUpdate(p); System.out.println(&quot;修改之后&quot;); query(keyword); SolrUtil.deleteById(&quot;51173&quot;); System.out.println(&quot;删除之后&quot;); query(keyword); &#125; private static void query(String keyword) throws SolrServerException, IOException &#123; QueryResponse queryResponse = SolrUtil.query(keyword,0,10); SolrDocumentList documents= queryResponse.getResults(); System.out.println(&quot;累计找到的条数：&quot;+documents.getNumFound()); if(!documents.isEmpty())&#123; Collection&lt;String&gt; fieldNames = documents.get(0).getFieldNames(); for (String fieldName : fieldNames) &#123; System.out.print(fieldName+&quot;\\t&quot;); &#125; System.out.println(); &#125; for (SolrDocument solrDocument : documents) &#123; Collection&lt;String&gt; fieldNames= solrDocument.getFieldNames(); for (String fieldName : fieldNames) &#123; System.out.print(solrDocument.get(fieldName)+&quot;\\t&quot;); &#125; System.out.println(); &#125; &#125;&#125; 观察修改和删除的效果: Solr - 进一步学习:Solr官网展开学习：https://lucene.apache.org/solr/","tags":[{"name":"Solr","slug":"Solr","permalink":"http://example.com/tags/Solr/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"Solr","slug":"工具和中间件/搜索引擎技术/Solr","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/Solr/"}]},{"title":"Solr高亮显示","date":"2018-12-01T07:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/Solr/Solr高亮显示/","text":"SolrUtil.java增加queryHighlight 方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283package cn.peach;import java.io.IOException;import java.util.List; import org.apache.solr.client.solrj.SolrClient;import org.apache.solr.client.solrj.SolrQuery;import org.apache.solr.client.solrj.SolrServerException;import org.apache.solr.client.solrj.beans.DocumentObjectBinder;import org.apache.solr.client.solrj.impl.HttpSolrClient;import org.apache.solr.client.solrj.response.QueryResponse;import org.apache.solr.common.SolrDocument;import org.apache.solr.common.SolrDocumentList;import org.apache.solr.common.SolrInputDocument;import org.apache.solr.common.util.NamedList; public class SolrUtil &#123; public static SolrClient client; private static String url; static &#123; url = &quot;http://localhost:8983/solr/howToSolr&quot;; client = new HttpSolrClient.Builder(url).build(); &#125; public static void queryHighlight(String keywords) throws SolrServerException, IOException &#123; SolrQuery q = new SolrQuery(); //开始页数 q.setStart(0); //每页显示条数 q.setRows(10); // 设置查询关键字 q.setQuery(keywords); // 开启高亮 q.setHighlight(true); // 高亮字段 q.addHighlightField(&quot;name&quot;); // 高亮单词的前缀 q.setHighlightSimplePre(&quot;&lt;span style=&#x27;color:red&#x27;&gt;&quot;); // 高亮单词的后缀 q.setHighlightSimplePost(&quot;&lt;/span&gt;&quot;); //摘要最长100个字符 q.setHighlightFragsize(100); //查询 QueryResponse query = client.query(q); //获取高亮字段name相应结果 NamedList&lt;Object&gt; response = query.getResponse(); NamedList&lt;?&gt; highlighting = (NamedList&lt;?&gt;) response.get(&quot;highlighting&quot;); for (int i = 0; i &lt; highlighting.size(); i++) &#123; System.out.println(highlighting.getName(i) + &quot;：&quot; + highlighting.getVal(i)); &#125; //获取查询结果 SolrDocumentList results = query.getResults(); for (SolrDocument result : results) &#123; System.out.println(result.toString()); &#125; &#125; public static &lt;T&gt; boolean batchSaveOrUpdate(List&lt;T&gt; entities) throws SolrServerException, IOException &#123; DocumentObjectBinder binder = new DocumentObjectBinder(); int total = entities.size(); int count=0; for (T t : entities) &#123; SolrInputDocument doc = binder.toSolrInputDocument(t); client.add(doc); System.out.printf(&quot;添加数据到索引中，总共要添加 %d 条记录，当前添加第%d条 %n&quot;,total,++count); &#125; client.commit(); return true; &#125; public static QueryResponse query(String keywords,int startOfPage, int numberOfPage) throws SolrServerException, IOException &#123; SolrQuery query = new SolrQuery(); query.setStart(startOfPage); query.setRows(numberOfPage); query.setQuery(keywords); QueryResponse rsp = client.query(query); return rsp; &#125; &#125; TestSolr4j.java调用queryHighlight 方法 123456789101112131415package cn.peach; import java.io.IOException; import org.apache.solr.client.solrj.SolrServerException; public class TestSolr4j &#123; public static void main(String[] args) throws SolrServerException, IOException &#123; //高亮查询查询 SolrUtil.queryHighlight(&quot;name:手机&quot;); &#125; &#125;","tags":[{"name":"Solr","slug":"Solr","permalink":"http://example.com/tags/Solr/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"Solr","slug":"工具和中间件/搜索引擎技术/Solr","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/Solr/"}]},{"title":"Solr分页查询-Solrj","date":"2018-12-01T06:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/Solr/Solr分页查询-Solrj/","text":"SolrUtil.javaSolrUtil 增加分页查询的方法: 123456789public static QueryResponse query(String keywords,int startOfPage, int numberOfPage) throws SolrServerException, IOException &#123; SolrQuery query = new SolrQuery(); query.setStart(startOfPage); query.setRows(numberOfPage); query.setQuery(keywords); QueryResponse rsp = client.query(query); return rsp;&#125; 完整代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package cn.peach;import java.io.IOException;import java.util.List; import org.apache.solr.client.solrj.SolrClient;import org.apache.solr.client.solrj.SolrQuery;import org.apache.solr.client.solrj.SolrServerException;import org.apache.solr.client.solrj.beans.DocumentObjectBinder;import org.apache.solr.client.solrj.impl.HttpSolrClient;import org.apache.solr.client.solrj.response.QueryResponse;import org.apache.solr.common.SolrDocument;import org.apache.solr.common.SolrDocumentList;import org.apache.solr.common.SolrInputDocument;import org.apache.solr.common.util.NamedList; public class SolrUtil &#123; public static SolrClient client; private static String url; static &#123; url = &quot;http://localhost:8983/solr/howToSolr&quot;; client = new HttpSolrClient.Builder(url).build(); &#125; public static &lt;T&gt; boolean batchSaveOrUpdate(List&lt;T&gt; entities) throws SolrServerException, IOException &#123; DocumentObjectBinder binder = new DocumentObjectBinder(); int total = entities.size(); int count=0; for (T t : entities) &#123; SolrInputDocument doc = binder.toSolrInputDocument(t); client.add(doc); System.out.printf(&quot;添加数据到索引中，总共要添加 %d 条记录，当前添加第%d条 %n&quot;,total,++count); &#125; client.commit(); return true; &#125; public static QueryResponse query(String keywords,int startOfPage, int numberOfPage) throws SolrServerException, IOException &#123; SolrQuery query = new SolrQuery(); query.setStart(startOfPage); query.setRows(numberOfPage); query.setQuery(keywords); QueryResponse rsp = client.query(query); return rsp; &#125; &#125; TestSolr4j.java拿到分页查询的结果，遍历出来 12345678910111213141516171819202122232425262728293031323334353637383940package cn.peach; import java.io.IOException;import java.util.Collection; import org.apache.solr.client.solrj.SolrServerException;import org.apache.solr.client.solrj.response.QueryResponse;import org.apache.solr.common.SolrDocument;import org.apache.solr.common.SolrDocumentList; public class TestSolr4j &#123; public static void main(String[] args) throws SolrServerException, IOException &#123; //查询 QueryResponse queryResponse = SolrUtil.query(&quot;name:手机&quot;,0,10); SolrDocumentList documents= queryResponse.getResults(); System.out.println(&quot;累计找到的条数：&quot;+documents.getNumFound()); if(!documents.isEmpty())&#123; Collection&lt;String&gt; fieldNames = documents.get(0).getFieldNames(); for (String fieldName : fieldNames) &#123; System.out.print(fieldName+&quot;\\t&quot;); &#125; System.out.println(); &#125; for (SolrDocument solrDocument : documents) &#123; Collection&lt;String&gt; fieldNames= solrDocument.getFieldNames(); for (String fieldName : fieldNames) &#123; System.out.print(solrDocument.get(fieldName)+&quot;\\t&quot;); &#125; System.out.println(); &#125; &#125; &#125;","tags":[{"name":"Solr","slug":"Solr","permalink":"http://example.com/tags/Solr/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"Solr","slug":"工具和中间件/搜索引擎技术/Solr","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/Solr/"}]},{"title":"Solr创建索引","date":"2018-12-01T05:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/Solr/Solr创建索引/","text":"如何创建索引：solr 提供了一种方式向其中增加索引的界面，但是不太方便，也和实际工作环境不相符合。以下配置通过程序把数据加入到Solr 索引里。 Product.java准备实体类来存放产品信息注： 每个字段上都有@Field 注解，用来告诉Solr 这些和 howToSolr core里的字段对应 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package cn.peach; import org.apache.solr.client.solrj.beans.Field; public class Product &#123; @Field int id; @Field String name; @Field String category; @Field float price; @Field String place; @Field String code; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getCategory() &#123; return category; &#125; public void setCategory(String category) &#123; this.category = category; &#125; public float getPrice() &#123; return price; &#125; public void setPrice(float price) &#123; this.price = price; &#125; public String getPlace() &#123; return place; &#125; public void setPlace(String place) &#123; this.place = place; &#125; public String getCode() &#123; return code; &#125; public void setCode(String code) &#123; this.code = code; &#125; @Override public String toString() &#123; return &quot;Product [id=&quot; + id + &quot;, name=&quot; + name + &quot;, category=&quot; + category + &quot;, price=&quot; + price + &quot;, place=&quot; + place + &quot;, code=&quot; + code + &quot;]&quot;; &#125; &#125; ProductUtil.java工具类，把 140k_products.txt 文本文件，转换为泛型是Product的集合, 参考Lucene分页查询工具类。 SolrUtil.java工具类，用来把产品集合批量增加到Solr. 这里就用到了SolrJ第三方包里的api了。 123456789101112131415161718192021222324252627282930313233package cn.peach;import java.io.IOException;import java.util.List; import org.apache.solr.client.solrj.SolrClient;import org.apache.solr.client.solrj.SolrServerException;import org.apache.solr.client.solrj.beans.DocumentObjectBinder;import org.apache.solr.client.solrj.impl.HttpSolrClient;import org.apache.solr.common.SolrInputDocument; public class SolrUtil &#123; public static SolrClient client; private static String url; static &#123; url = &quot;http://localhost:8983/solr/howToSolr&quot;; client = new HttpSolrClient.Builder(url).build(); &#125; public static &lt;T&gt; boolean batchSaveOrUpdate(List&lt;T&gt; entities) throws SolrServerException, IOException &#123; DocumentObjectBinder binder = new DocumentObjectBinder(); int total = entities.size(); int count=0; for (T t : entities) &#123; SolrInputDocument doc = binder.toSolrInputDocument(t); client.add(doc); System.out.printf(&quot;添加数据到索引中，总共要添加 %d 条记录，当前添加第%d条 %n&quot;,total,++count); &#125; client.commit(); return true; &#125; &#125; TestSolr4j:得到14万个产品对象，然后通过SolrUtil 工具类提交到Solr 服务器。 123456789101112package cn.peach;import java.io.IOException;import java.util.List;import org.apache.solr.client.solrj.SolrServerException; public class TestSolr4j &#123; public static void main(String[] args) throws SolrServerException, IOException &#123; List&lt;Product&gt; products = ProductUtil.file2list(&quot;140k_products.txt&quot;); SolrUtil.batchSaveOrUpdate(products); &#125;&#125; 验证提交效果:","tags":[{"name":"Solr","slug":"Solr","permalink":"http://example.com/tags/Solr/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"Solr","slug":"工具和中间件/搜索引擎技术/Solr","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/Solr/"}]},{"title":"Solr设置字段","date":"2018-12-01T04:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/Solr/Solr设置字段/","text":"字段概念:创建Core 中的Core就相当于表，那么接下来就要为这个表设置字段，用于存放数据。 创建字段： 创建name字段：左边选中 howToSolr -&gt; Schema -&gt; Add Field 输入name: name， field type: text_ik, 这里一定要使用中文分词 中新创建的 text_ik类型，否则后续查询中文会失败。然后点击 Add Field按钮进行添加： 创建其他字段：按照创建name字段 的方式，继续创建如下字段： category text_ik, price pfloat, place text_ik, code text_ik注： price的类型是pfloat 关于id字段:id字段是默认就有的，无需自己创建 查看创建的字段:","tags":[{"name":"Solr","slug":"Solr","permalink":"http://example.com/tags/Solr/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"Solr","slug":"工具和中间件/搜索引擎技术/Solr","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/Solr/"}]},{"title":"Solr中文分词器IKAnalyzer","date":"2018-12-01T03:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/Solr/Solr中文分词器IKAnalyzer/","text":"中文分词默认情况下是没有中文分词的，如图所示，通过点击左边的howToSolr-&gt;Analysis 然后输入 四川省成都市动物园，得到是按照每个字的分词效果 配置中文分词下载 IKAnalyzer6.5.0.jar复制到如下目录：D:\\software\\solr-7.2.1\\server\\solr-webapp\\webapp\\WEB-INF\\lib 增加新的字段类型修改配置文件 managed-schema： 1D:\\software\\solr-7.2.1\\server\\solr\\howToSolr\\conf\\managed-schema 在line41 位置处 &lt;schema…&gt; 标签下增加如下代码: 12345&lt;schema name=&quot;default-config&quot; version=&quot;1.6&quot;&gt; &lt;fieldType name=&quot;text_ik&quot; class=&quot;solr.TextField&quot;&gt; &lt;analyzer class=&quot;org.wltea.analyzer.lucene.IKAnalyzer&quot;/&gt; &lt;/fieldType&gt; &lt;field name=&quot;text_ik&quot; type=&quot;text_ik&quot; indexed=&quot;true&quot; stored=&quot;true&quot; multiValued=&quot;false&quot; /&gt; 重启 Solr使用如下命令重启 123cd d:\\software\\solr-7.2.1\\binsolr.cmd stop -allsolr.cmd start 重新测试分词如图所示，使用中文分词后，就可以看到分词的效果了。注： FieldType 记得选增加新的字段类型 中的 text_ik","tags":[{"name":"Solr","slug":"Solr","permalink":"http://example.com/tags/Solr/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"Solr","slug":"工具和中间件/搜索引擎技术/Solr","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/Solr/"}]},{"title":"Solr基础","date":"2018-12-01T02:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/Solr/Solr基础/","text":"Solr概念：以连接数据库为类比：Lucene 就相当于JDBC，是基本的用法。Solr 就相当 Mybatis， 方便开发人员配置，访问和调用。而且Solr 被做成了 webapp形式，以tomcat的应用的方式启动，提供了可视化的配置界面 启动服务器官网(https://lucene.apache.org/solr/)下载solr并解压(我下载的是solr-7.2.1.rar), 我的解压目录在 D:\\software\\solr-7.2.1 12cd d:\\software\\solr-7.2.1\\binsolr.cmd start 如此就启动了服务器，会占用端口8983。 倘若端口被占用，会启动失败. 访问服务器:浏览器输入：http://127.0.0.1:8983/solr/#/ Core 概念：如果说Solr相当于一个数据库的话，那么Core就相当于一张表 不要通过图形界面创建Core如图所示，通过图形界面创建Core会失败，应该使用 命令行方式创建Core: 命令行方式创建Core12cd d:\\software\\solr-7.2.1\\binsolr.cmd create -c howToSolr 删除 new_core如果点击了步骤 不要通过图形界面创建Core 里的图形界面里的 Add Core,那么就会一直有错误提醒，那么按照如下方式删除 new_core 就不会再有错误提醒了 12cd d:\\software\\solr-7.2.1\\binsolr.cmd delete -c new_core","tags":[{"name":"Solr","slug":"Solr","permalink":"http://example.com/tags/Solr/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"Solr","slug":"工具和中间件/搜索引擎技术/Solr","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/Solr/"}]},{"title":"Lucene索引删除和更新","date":"2018-10-02T05:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/Lucene/Lucene索引删除和更新/","text":"索引删除和更新索引建立好了之后，还是需要维护的，比如新增，删除和维护。 新增就是建立索引的过程。索引里的数据，其实就是一个一个的Document 对象，那么本文就是介绍如何删除和更新这些Documen对象。 删除索引123456//删除id=51173的数据IndexWriterConfig config = new IndexWriterConfig(analyzer);IndexWriter indexWriter = new IndexWriter(index, config);indexWriter.deleteDocuments(new Term(&quot;id&quot;, &quot;51173&quot;));indexWriter.commit();indexWriter.close(); 更多删除还可以按照如下方法来删除索引: DeleteDocuments(Query query):根据Query条件来删除单个或多个Document DeleteDocuments(Query[] queries):根据Query条件来删除单个或多个Document DeleteDocuments(Term term):根据Term来删除单个或多个Document DeleteDocuments(Term[] terms):根据Term来删除单个或多个Document DeleteAll():删除所有的Document 更新索引12345678910111213// 更新索引IndexWriterConfig config = new IndexWriterConfig(analyzer);IndexWriter indexWriter = new IndexWriter(index, config);Document doc = new Document();doc.add(new TextField(&quot;id&quot;, &quot;51173&quot;, Field.Store.YES));doc.add(new TextField(&quot;name&quot;, &quot;神鞭，鞭没了，神还在&quot;, Field.Store.YES));doc.add(new TextField(&quot;category&quot;, &quot;道具&quot;, Field.Store.YES));doc.add(new TextField(&quot;price&quot;, &quot;998&quot;, Field.Store.YES));doc.add(new TextField(&quot;place&quot;, &quot;南海群岛&quot;, Field.Store.YES));doc.add(new TextField(&quot;code&quot;, &quot;888888&quot;, Field.Store.YES));indexWriter.updateDocument(new Term(&quot;id&quot;, &quot;51173&quot;), doc );indexWriter.commit();indexWriter.close(); LUCENE - 进一步学习:Lucene官网展开学习：https://lucene.apache.org/","tags":[{"name":"Lucene","slug":"Lucene","permalink":"http://example.com/tags/Lucene/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"Lucene","slug":"工具和中间件/搜索引擎技术/Lucene","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/Lucene/"}]},{"title":"Lucene分页查询","date":"2018-10-02T04:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/Lucene/Lucene分页查询/","text":"分页查询-两种方式:Lucene 分页通常来讲有两种方式： 第一种是把100条数据查出来，然后取最后10条。 优点是快，缺点是对内存消耗大。 第二种是把第90条查询出来，然后基于这一条，通过searchAfter方法查询10条数据。 优点是内存消耗小，缺点是比第一种更慢 准备实体类来存放产品信息12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package cn.peach;public class Product &#123; int id; String name; String category; float price; String place; String code; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getCategory() &#123; return category; &#125; public void setCategory(String category) &#123; this.category = category; &#125; public float getPrice() &#123; return price; &#125; public void setPrice(float price) &#123; this.price = price; &#125; public String getPlace() &#123; return place; &#125; public void setPlace(String place) &#123; this.place = place; &#125; public String getCode() &#123; return code; &#125; public void setCode(String code) &#123; this.code = code; &#125; @Override public String toString() &#123; return &quot;Product [id=&quot; + id + &quot;, name=&quot; + name + &quot;, category=&quot; + category + &quot;, price=&quot; + price + &quot;, place=&quot; + place + &quot;, code=&quot; + code + &quot;]&quot;; &#125;&#125; 准备工具类读取14万条数据把140k_products.txt 文本文件，转换为泛型是Product的集合 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package cn.peach;import java.awt.AWTException;import java.io.File;import java.io.IOException;import java.util.ArrayList;import java.util.HashSet;import java.util.List;import java.util.Set;import org.apache.commons.io.FileUtils; public class ProductUtil &#123; public static void main(String[] args) throws IOException, InterruptedException, AWTException &#123; String fileName = &quot;140k_products.txt&quot;; List&lt;Product&gt; products = file2list(fileName); System.out.println(products.size()); &#125; public static List&lt;Product&gt; file2list(String fileName) throws IOException &#123; File f = new File(fileName); List&lt;String&gt; lines = FileUtils.readLines(f,&quot;UTF-8&quot;); List&lt;Product&gt; products = new ArrayList&lt;&gt;(); for (String line : lines) &#123; Product p = line2product(line); products.add(p); &#125; return products; &#125; private static Product line2product(String line) &#123; Product p = new Product(); String[] fields = line.split(&quot;,&quot;); p.setId(Integer.parseInt(fields[0])); p.setName(fields[1]); p.setCategory(fields[2]); p.setPrice(Float.parseFloat(fields[3])); p.setPlace(fields[4]); p.setCode(fields[5]); return p; &#125;&#125; 第一种:一共查出 pageNow*pageSize条，然后取最后pageSize条： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142package cn.peach;import java.io.IOException;import java.io.StringReader;import java.util.ArrayList;import java.util.List;import org.apache.lucene.analysis.TokenStream;import org.apache.lucene.document.Document;import org.apache.lucene.document.Field;import org.apache.lucene.document.TextField;import org.apache.lucene.index.DirectoryReader;import org.apache.lucene.index.IndexReader;import org.apache.lucene.index.IndexWriter;import org.apache.lucene.index.IndexWriterConfig;import org.apache.lucene.index.IndexableField;import org.apache.lucene.queryparser.classic.QueryParser;import org.apache.lucene.search.IndexSearcher;import org.apache.lucene.search.Query;import org.apache.lucene.search.ScoreDoc;import org.apache.lucene.search.TopDocs;import org.apache.lucene.search.highlight.Highlighter;import org.apache.lucene.search.highlight.QueryScorer;import org.apache.lucene.search.highlight.SimpleHTMLFormatter;import org.apache.lucene.store.Directory;import org.apache.lucene.store.RAMDirectory;import org.wltea.analyzer.lucene.IKAnalyzer;public class TestLucene &#123; public static void main(String[] args) throws Exception &#123; // 1. 准备中文分词器 IKAnalyzer analyzer = new IKAnalyzer(); // 2. 索引 Directory index = createIndex(analyzer); // 3. 查询器 String keyword = &quot;手机&quot;; System.out.println(&quot;当前关键字是：&quot;+keyword); Query query = new QueryParser( &quot;name&quot;, analyzer).parse(keyword); // 4. 搜索 IndexReader reader = DirectoryReader.open(index); IndexSearcher searcher=new IndexSearcher(reader); int pageNow = 1; int pageSize = 10; ScoreDoc[] hits = pageSearch1(query, searcher, pageNow, pageSize); // 5. 显示查询结果 showSearchResults(searcher, hits,query,analyzer); // 6. 关闭查询 reader.close(); &#125; private static ScoreDoc[] pageSearch1(Query query, IndexSearcher searcher, int pageNow, int pageSize) throws IOException &#123; TopDocs topDocs = searcher.search(query, pageNow*pageSize); System.out.println(&quot;查询到的总条数\\t&quot;+topDocs.totalHits); ScoreDoc [] alllScores = topDocs.scoreDocs; List&lt;ScoreDoc&gt; hitScores = new ArrayList&lt;&gt;(); int start = (pageNow -1)*pageSize ; int end = pageSize*pageNow; for(int i=start;i&lt;end;i++) hitScores.add(alllScores[i]); ScoreDoc[] hits = hitScores.toArray(new ScoreDoc[]&#123;&#125;); return hits; &#125; private static void showSearchResults(IndexSearcher searcher, ScoreDoc[] hits, Query query, IKAnalyzer analyzer) throws Exception &#123; System.out.println(&quot;找到 &quot; + hits.length + &quot; 个命中.&quot;); SimpleHTMLFormatter simpleHTMLFormatter = new SimpleHTMLFormatter(&quot;&lt;span style=&#x27;color:red&#x27;&gt;&quot;, &quot;&lt;/span&gt;&quot;); Highlighter highlighter = new Highlighter(simpleHTMLFormatter, new QueryScorer(query)); System.out.println(&quot;找到 &quot; + hits.length + &quot; 个命中.&quot;); System.out.println(&quot;序号\\t匹配度得分\\t结果&quot;); for (int i = 0; i &lt; hits.length; ++i) &#123; ScoreDoc scoreDoc= hits[i]; int docId = scoreDoc.doc; Document d = searcher.doc(docId); List&lt;IndexableField&gt; fields= d.getFields(); System.out.print((i + 1) ); System.out.print(&quot;\\t&quot; + scoreDoc.score); for (IndexableField f : fields) &#123; if(&quot;name&quot;.equals(f.name()))&#123; TokenStream tokenStream = analyzer.tokenStream(f.name(), new StringReader(d.get(f.name()))); String fieldContent = highlighter.getBestFragment(tokenStream, d.get(f.name())); System.out.print(&quot;\\t&quot;+fieldContent); &#125; else&#123; System.out.print(&quot;\\t&quot;+d.get(f.name())); &#125; &#125; System.out.println(&quot;&lt;br&gt;&quot;); &#125; &#125; private static Directory createIndex(IKAnalyzer analyzer) throws IOException &#123; Directory index = new RAMDirectory(); IndexWriterConfig config = new IndexWriterConfig(analyzer); IndexWriter writer = new IndexWriter(index, config); String fileName = &quot;140k_products.txt&quot;; List&lt;Product&gt; products = ProductUtil.file2list(fileName); int total = products.size(); int count = 0; int per = 0; int oldPer =0; for (Product p : products) &#123; addDoc(writer, p); count++; per = count*100/total; if(per!=oldPer)&#123; oldPer = per; System.out.printf(&quot;索引中，总共要添加 %d 条记录，当前添加进度是： %d%% %n&quot;,total,per); &#125; if(per&gt;10) break; &#125; writer.close(); return index; &#125; private static void addDoc(IndexWriter w, Product p) throws IOException &#123; Document doc = new Document(); doc.add(new TextField(&quot;id&quot;, String.valueOf(p.getId()), Field.Store.YES)); doc.add(new TextField(&quot;name&quot;, p.getName(), Field.Store.YES)); doc.add(new TextField(&quot;category&quot;, p.getCategory(), Field.Store.YES)); doc.add(new TextField(&quot;price&quot;, String.valueOf(p.getPrice()), Field.Store.YES)); doc.add(new TextField(&quot;place&quot;, p.getPlace(), Field.Store.YES)); doc.add(new TextField(&quot;code&quot;, p.getCode(), Field.Store.YES)); w.addDocument(doc); &#125;&#125; 第二种首先是边界条件，如果是第一页，就直接查询了。如果不是第一页，那么就取start-1那一条，然后再根据它通过searchAfter 来查询： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162package cn.peach;import java.io.IOException;import java.io.StringReader;import java.util.ArrayList;import java.util.List;import org.apache.lucene.analysis.TokenStream;import org.apache.lucene.document.Document;import org.apache.lucene.document.Field;import org.apache.lucene.document.TextField;import org.apache.lucene.index.DirectoryReader;import org.apache.lucene.index.IndexReader;import org.apache.lucene.index.IndexWriter;import org.apache.lucene.index.IndexWriterConfig;import org.apache.lucene.index.IndexableField;import org.apache.lucene.queryparser.classic.QueryParser;import org.apache.lucene.search.IndexSearcher;import org.apache.lucene.search.Query;import org.apache.lucene.search.ScoreDoc;import org.apache.lucene.search.TopDocs;import org.apache.lucene.search.highlight.Highlighter;import org.apache.lucene.search.highlight.QueryScorer;import org.apache.lucene.search.highlight.SimpleHTMLFormatter;import org.apache.lucene.store.Directory;import org.apache.lucene.store.RAMDirectory;import org.wltea.analyzer.lucene.IKAnalyzer;public class TestLucene &#123; public static void main(String[] args) throws Exception &#123; // 1. 准备中文分词器 IKAnalyzer analyzer = new IKAnalyzer(); // 2. 索引 Directory index = createIndex(analyzer); // 3. 查询器 String keyword = &quot;手机&quot;; System.out.println(&quot;当前关键字是：&quot;+keyword); Query query = new QueryParser( &quot;name&quot;, analyzer).parse(keyword); // 4. 搜索 IndexReader reader = DirectoryReader.open(index); IndexSearcher searcher=new IndexSearcher(reader); int pageNow = 1; int pageSize = 10; ScoreDoc[] hits = pageSearch2(query, searcher, pageNow, pageSize); // 5. 显示查询结果 showSearchResults(searcher, hits,query,analyzer); // 6. 关闭查询 reader.close(); &#125; private static ScoreDoc[] pageSearch1(Query query, IndexSearcher searcher, int pageNow, int pageSize) throws IOException &#123; TopDocs topDocs = searcher.search(query, pageNow*pageSize); System.out.println(&quot;查询到的总条数\\t&quot;+topDocs.totalHits); ScoreDoc [] alllScores = topDocs.scoreDocs; List&lt;ScoreDoc&gt; hitScores = new ArrayList&lt;&gt;(); int start = (pageNow -1)*pageSize ; int end = pageSize*pageNow; for(int i=start;i&lt;end;i++) hitScores.add(alllScores[i]); ScoreDoc[] hits = hitScores.toArray(new ScoreDoc[]&#123;&#125;); return hits; &#125; private static ScoreDoc[] pageSearch2(Query query, IndexSearcher searcher, int pageNow, int pageSize) throws IOException &#123; int start = (pageNow - 1) * pageSize; if(0==start)&#123; TopDocs topDocs = searcher.search(query, pageNow*pageSize); return topDocs.scoreDocs; &#125; // 查询数据， 结束页面自前的数据都会查询到，但是只取本页的数据 TopDocs topDocs = searcher.search(query, start); //获取到上一页最后一条 ScoreDoc preScore= topDocs.scoreDocs[start-1]; //查询最后一条后的数据的一页数据 topDocs = searcher.searchAfter(preScore, query, pageSize); return topDocs.scoreDocs; &#125; private static void showSearchResults(IndexSearcher searcher, ScoreDoc[] hits, Query query, IKAnalyzer analyzer) throws Exception &#123; System.out.println(&quot;找到 &quot; + hits.length + &quot; 个命中.&quot;); SimpleHTMLFormatter simpleHTMLFormatter = new SimpleHTMLFormatter(&quot;&lt;span style=&#x27;color:red&#x27;&gt;&quot;, &quot;&lt;/span&gt;&quot;); Highlighter highlighter = new Highlighter(simpleHTMLFormatter, new QueryScorer(query)); System.out.println(&quot;找到 &quot; + hits.length + &quot; 个命中.&quot;); System.out.println(&quot;序号\\t匹配度得分\\t结果&quot;); for (int i = 0; i &lt; hits.length; ++i) &#123; ScoreDoc scoreDoc= hits[i]; int docId = scoreDoc.doc; Document d = searcher.doc(docId); List&lt;IndexableField&gt; fields= d.getFields(); System.out.print((i + 1) ); System.out.print(&quot;\\t&quot; + scoreDoc.score); for (IndexableField f : fields) &#123; if(&quot;name&quot;.equals(f.name()))&#123; TokenStream tokenStream = analyzer.tokenStream(f.name(), new StringReader(d.get(f.name()))); String fieldContent = highlighter.getBestFragment(tokenStream, d.get(f.name())); System.out.print(&quot;\\t&quot;+fieldContent); &#125; else&#123; System.out.print(&quot;\\t&quot;+d.get(f.name())); &#125; &#125; System.out.println(&quot;&lt;br&gt;&quot;); &#125; &#125; private static Directory createIndex(IKAnalyzer analyzer) throws IOException &#123; Directory index = new RAMDirectory(); IndexWriterConfig config = new IndexWriterConfig(analyzer); IndexWriter writer = new IndexWriter(index, config); String fileName = &quot;140k_products.txt&quot;; List&lt;Product&gt; products = ProductUtil.file2list(fileName); int total = products.size(); int count = 0; int per = 0; int oldPer =0; for (Product p : products) &#123; addDoc(writer, p); count++; per = count*100/total; if(per!=oldPer)&#123; oldPer = per; System.out.printf(&quot;索引中，总共要添加 %d 条记录，当前添加进度是： %d%% %n&quot;,total,per); &#125; if(per&gt;10) break; &#125; writer.close(); return index; &#125; private static void addDoc(IndexWriter w, Product p) throws IOException &#123; Document doc = new Document(); doc.add(new TextField(&quot;id&quot;, String.valueOf(p.getId()), Field.Store.YES)); doc.add(new TextField(&quot;name&quot;, p.getName(), Field.Store.YES)); doc.add(new TextField(&quot;category&quot;, p.getCategory(), Field.Store.YES)); doc.add(new TextField(&quot;price&quot;, String.valueOf(p.getPrice()), Field.Store.YES)); doc.add(new TextField(&quot;place&quot;, p.getPlace(), Field.Store.YES)); doc.add(new TextField(&quot;code&quot;, p.getCode(), Field.Store.YES)); w.addDocument(doc); &#125;&#125;","tags":[{"name":"Lucene","slug":"Lucene","permalink":"http://example.com/tags/Lucene/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"Lucene","slug":"工具和中间件/搜索引擎技术/Lucene","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/Lucene/"}]},{"title":"Lucene分词器","date":"2018-10-02T03:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/Lucene/Lucene分词器/","text":"分词器概念：分词器指的是搜索引擎如何使用关键字进行匹配，如 基础 中的关键字：护眼带光源。 如果使用like,那么%护眼带光源%，匹配出来的结果就是要么全匹配，要不都不匹配。而使用分词器，就会把这个关键字分为 护眼，带，光源 3个关键字，这样就可以找到不同相关程度的结果了。 IKAnalyzer6.5.0.jarIKAnalyzer 这个分词器很久都没有维护了，也不支持Lucene7。 代码演示 TestAnalyzer12345678910111213141516171819package cn.peach; import java.io.IOException; import org.apache.lucene.analysis.TokenStream;import org.wltea.analyzer.lucene.IKAnalyzer; public class TestAnalyzer &#123; public static void main(String[] args) throws IOException &#123; IKAnalyzer analyzer = new IKAnalyzer(); TokenStream ts= analyzer.tokenStream(&quot;name&quot;, &quot;护眼带光源&quot;); ts.reset(); while(ts.incrementToken())&#123; System.out.println(ts.reflectAsString(false)); &#125; &#125;&#125; 高亮显示:70,71行 81,82行 增加高亮显示123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106package cn.peach;import java.io.IOException;import java.io.StringReader;import java.util.ArrayList;import java.util.List;import org.apache.lucene.analysis.TokenStream;import org.apache.lucene.document.Document;import org.apache.lucene.document.Field;import org.apache.lucene.document.TextField;import org.apache.lucene.index.DirectoryReader;import org.apache.lucene.index.IndexReader;import org.apache.lucene.index.IndexWriter;import org.apache.lucene.index.IndexWriterConfig;import org.apache.lucene.index.IndexableField;import org.apache.lucene.queryparser.classic.QueryParser;import org.apache.lucene.search.IndexSearcher;import org.apache.lucene.search.Query;import org.apache.lucene.search.ScoreDoc;import org.apache.lucene.search.highlight.Highlighter;import org.apache.lucene.search.highlight.QueryScorer;import org.apache.lucene.search.highlight.SimpleHTMLFormatter;import org.apache.lucene.store.Directory;import org.apache.lucene.store.RAMDirectory;import org.wltea.analyzer.lucene.IKAnalyzer;public class TestLucene &#123; public static void main(String[] args) throws Exception &#123; // 1. 准备中文分词器 IKAnalyzer analyzer = new IKAnalyzer(); // 2. 索引 List&lt;String&gt; productNames = new ArrayList&lt;&gt;(); productNames.add(&quot;飞利浦led灯泡e27螺口暖白球泡灯家用照明超亮节能灯泡转色温灯泡&quot;); productNames.add(&quot;飞利浦led灯泡e14螺口蜡烛灯泡3W尖泡拉尾节能灯泡暖黄光源Lamp&quot;); productNames.add(&quot;雷士照明 LED灯泡 e27大螺口节能灯3W球泡灯 Lamp led节能灯泡&quot;); productNames.add(&quot;飞利浦 led灯泡 e27螺口家用3w暖白球泡灯节能灯5W灯泡LED单灯7w&quot;); productNames.add(&quot;飞利浦led小球泡e14螺口4.5w透明款led节能灯泡照明光源lamp单灯&quot;); productNames.add(&quot;飞利浦蒲公英护眼台灯工作学习阅读节能灯具30508带光源&quot;); productNames.add(&quot;欧普照明led灯泡蜡烛节能灯泡e14螺口球泡灯超亮照明单灯光源&quot;); productNames.add(&quot;欧普照明led灯泡节能灯泡超亮光源e14e27螺旋螺口小球泡暖黄家用&quot;); productNames.add(&quot;聚欧普照明led灯泡节能灯泡e27螺口球泡家用led照明单灯超亮光源&quot;); Directory index = createIndex(analyzer, productNames); // 3. 查询器 String keyword = &quot;护眼带光源&quot;; Query query = new QueryParser(&quot;name&quot;, analyzer).parse(keyword); // 4. 搜索 IndexReader reader = DirectoryReader.open(index); IndexSearcher searcher = new IndexSearcher(reader); int numberPerPage = 1000; System.out.printf(&quot;当前一共有%d条数据%n&quot;,productNames.size()); System.out.printf(&quot;查询关键字是：\\&quot;%s\\&quot;%n&quot;,keyword); ScoreDoc[] hits = searcher.search(query, numberPerPage).scoreDocs; // 5. 显示查询结果 showSearchResults(searcher, hits, query, analyzer); // 6. 关闭查询 reader.close(); &#125; private static void showSearchResults(IndexSearcher searcher, ScoreDoc[] hits, Query query, IKAnalyzer analyzer) throws Exception &#123; System.out.println(&quot;找到 &quot; + hits.length + &quot; 个命中.&quot;); System.out.println(&quot;序号\\t匹配度得分\\t结果&quot;); SimpleHTMLFormatter simpleHTMLFormatter = new SimpleHTMLFormatter(&quot;&lt;span style=&#x27;color:red&#x27;&gt;&quot;, &quot;&lt;/span&gt;&quot;); Highlighter highlighter = new Highlighter(simpleHTMLFormatter, new QueryScorer(query)); for (int i = 0; i &lt; hits.length; ++i) &#123; ScoreDoc scoreDoc= hits[i]; int docId = scoreDoc.doc; Document d = searcher.doc(docId); List&lt;IndexableField&gt; fields = d.getFields(); System.out.print((i + 1)); System.out.print(&quot;\\t&quot; + scoreDoc.score); for (IndexableField f : fields) &#123; TokenStream tokenStream = analyzer.tokenStream(f.name(), new StringReader(d.get(f.name()))); String fieldContent = highlighter.getBestFragment(tokenStream, d.get(f.name())); System.out.print(&quot;\\t&quot; + fieldContent); &#125; System.out.println(&quot;&lt;br&gt;&quot;); &#125; &#125; private static Directory createIndex(IKAnalyzer analyzer, List&lt;String&gt; products) throws IOException &#123; Directory index = new RAMDirectory(); IndexWriterConfig config = new IndexWriterConfig(analyzer); IndexWriter writer = new IndexWriter(index, config); for (String name : products) &#123; addDoc(writer, name); &#125; writer.close(); return index; &#125; private static void addDoc(IndexWriter w, String name) throws IOException &#123; Document doc = new Document(); doc.add(new TextField(&quot;name&quot;, name, Field.Store.YES)); w.addDocument(doc); &#125;&#125; 运行结果运行结果是html代码，为了正常显示，复制到一个html文件里，打开就可以看到效果了.","tags":[{"name":"Lucene","slug":"Lucene","permalink":"http://example.com/tags/Lucene/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"Lucene","slug":"工具和中间件/搜索引擎技术/Lucene","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/Lucene/"}]},{"title":"Lucene基础","date":"2018-10-02T02:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/Lucene/Lucene基础/","text":"Lucene 概念:Lucene 这个开源项目，使得 Java开发人员可以很方便地得到像搜索引擎google baidu那样的搜索效果。 Lucene是一个全文检索框架，通过程序扫描文本中每个单词，针对单词建立索引，并保存该单词在文本中的位置、以及出现次数。用户查询时通过之前建立好的索引来查询，将索引中单词对应文本位置、出现次数返给用户，有了具体文本位置，则可将具体内容读取出来。 Lucene基于倒排索引，对于使用的数据库主键索引是通过主键定位到某条数据，而倒排索引刚好相反，是通过数据对应到主键。 分词器：准备中文分词器， 12// 1. 准备中文分词器IKAnalyzer analyzer = new IKAnalyzer(); 创建索引:首先准备10条数据这10条数据都是字符串，相当于产品表里的数据 123456789101112// 索引List&lt;String&gt; productNames = new ArrayList&lt;&gt;();productNames.add(&quot;飞利浦led灯泡e27螺口暖白球泡灯家用照明超亮节能灯泡转色温灯泡&quot;);productNames.add(&quot;飞利浦led灯泡e14螺口蜡烛灯泡3W尖泡拉尾节能灯泡暖黄光源Lamp&quot;);productNames.add(&quot;雷士照明 LED灯泡 e27大螺口节能灯3W球泡灯 Lamp led节能灯泡&quot;);productNames.add(&quot;飞利浦 led灯泡 e27螺口家用3w暖白球泡灯节能灯5W灯泡LED单灯7w&quot;);productNames.add(&quot;飞利浦led小球泡e14螺口4.5w透明款led节能灯泡照明光源lamp单灯&quot;);productNames.add(&quot;飞利浦蒲公英护眼台灯工作学习阅读节能灯具30508带光源&quot;);productNames.add(&quot;欧普照明led灯泡蜡烛节能灯泡e14螺口球泡灯超亮照明单灯光源&quot;);productNames.add(&quot;欧普照明led灯泡节能灯泡超亮光源e14e27螺旋螺口小球泡暖黄家用&quot;);productNames.add(&quot;聚欧普照明led灯泡节能灯泡e27螺口球泡家用led照明单灯超亮光源&quot;); Directory index = createIndex(analyzer, productNames); 通过 createIndex 方法，把它加入到索引当中: 问题： 创建内存索引，为什么Lucene会比数据库快? 因为它是从内存里查，自然就比数据库里快多了.1234567891011121314private static Directory createIndex(IKAnalyzer analyzer, List&lt;String&gt; products) throws IOException &#123; &lt;!-- 创建内存索引 --&gt; Directory index = new RAMDirectory(); &lt;!-- 根据中文分词器创建配置对象 --&gt; IndexWriterConfig config = new IndexWriterConfig(analyzer); &lt;!-- 创建索引 writer --&gt; IndexWriter writer = new IndexWriter(index, config); &lt;!-- 遍历那10条数据，把他们挨个放进索引里 --&gt; for (String name : products) &#123; addDoc(writer, name); &#125; writer.close(); return index;&#125; 每条数据创建一个Document，并把这个Document放进索引里。 这个Document有一个字段，叫做”name”。 TestLucene.java 第49行创建查询器，就会指定查询这个字段. 12345private static void addDoc(IndexWriter w, String name) throws IOException &#123; Document doc = new Document(); doc.add(new TextField(&quot;name&quot;, name, Field.Store.YES)); w.addDocument(doc);&#125; 创建查询器根据关键字 护眼带光源，基于 “name” 字段进行查询。 这个 “name” 字段就是在创建索引步骤里每个Document的 “name” 字段，相当于表的字段名. 12String keyword = &quot;护眼带光源&quot;;Query query = new QueryParser(&quot;name&quot;, analyzer).parse(keyword); 执行搜索12345678910&lt;!-- 创建索引 reader: --&gt;IndexReader reader = DirectoryReader.open(index);&lt;!-- 基于 reader 创建搜索器： --&gt;IndexSearcher searcher = new IndexSearcher(reader);&lt;!-- 指定每页要显示多少条数据： --&gt;int numberPerPage = 1000;System.out.printf(&quot;当前一共有%d条数据%n&quot;,productNames.size());System.out.printf(&quot;查询关键字是：\\&quot;%s\\&quot;%n&quot;,keyword);&lt;!-- 执行搜索 --&gt;ScoreDoc[] hits = searcher.search(query, numberPerPage).scoreDocs; 显示查询结果12345678910111213141516171819202122private static void showSearchResults(IndexSearcher searcher, ScoreDoc[] hits, Query query, IKAnalyzer analyzer) throws Exception &#123; System.out.println(&quot;找到 &quot; + hits.length + &quot; 个命中.&quot;); System.out.println(&quot;序号\\t匹配度得分\\t结果&quot;); &lt;!-- 每一个ScoreDoc[] hits 就是一个搜索结果，首先把他遍历出来 --&gt; for (int i = 0; i &lt; hits.length; ++i) &#123; ScoreDoc scoreDoc= hits[i]; &lt;!-- 然后获取当前结果的docid, 这个docid相当于就是这个数据在索引中的主键 --&gt; int docId = scoreDoc.doc; &lt;!-- 再根据主键docid，通过搜索器从索引里把对应的Document取出来 --&gt; Document d = searcher.doc(docId); &lt;!-- 接着就打印出这个Document里面的数据。 虽然当前Document只有name一个字段，但是代码还是通过遍历所有字段的形式，打印出里面的值，这样当Docment有多个字段的时候，代码就不用修改了，兼容性更好点。scoreDoc.score 表示当前命中的匹配度得分，越高表示匹配程度越高 --&gt; List&lt;IndexableField&gt; fields = d.getFields(); System.out.print((i + 1)); System.out.print(&quot;\\t&quot; + scoreDoc.score); for (IndexableField f : fields) &#123; System.out.print(&quot;\\t&quot; + d.get(f.name())); &#125; System.out.println(); &#125;&#125; 运行结果:如图所示，一共是10条数据，通过关键字查询出来6条命中结果，不同的命中结果有不同的匹配度得分，比如第一条，命中都就很高，既有 护眼， 也有 带光源。 其他的命中度就比较低，没有护眼关键字的匹配，只有光源关键字的匹配。 思路图:整理一下做 Lucene的思路: 首先搜集数据数据可以是文件系统，数据库，网络上，手工输入的，或者像本例直接写在内存上的 通过数据创建索引 用户输入关键字 通过关键字创建查询器 根据查询器到索引里获取数据 然后把查询结果展示在用户面前 和like的区别：like 也可以进行查询，那么使用lucene 的方式有什么区别呢？ 主要是两点： 相关度:通过观察运行结果，可以看到不同相关度的结果都会查询出来，但是使用 like，就做不到这一点了 性能:数据量小的时候，like 也会有很好的表现，但是数据量一大，like 的表现就差很多了。 在接下来的教程里会演示对 14万条数据 的查询","tags":[{"name":"Lucene","slug":"Lucene","permalink":"http://example.com/tags/Lucene/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"Lucene","slug":"工具和中间件/搜索引擎技术/Lucene","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/Lucene/"}]},{"title":"Redis缓存及性能优化","date":"2017-12-15T07:08:20.000Z","path":"blog/Cloud/Redis/Redis缓存及性能优化/","text":"配置文件调优123456789101112131415161718192021222324252627282930313233343536373839# 列表对象listlist-max-ziplist-size -2 # 单个ziplist节点最大能存储8kb，超过则进行分裂将数据存储在新的ziplistlist-compress-depth 1 # 0表示所有节点都不压缩，1表示头结点和尾节点不压缩其他节点压缩# 哈希对象hashhash-max-ziplist-entries 512 # 元素个数超过512，将改为HashTable编码hash-max-ziplist-value 64 # 单个元素大小超过64byte，将改为HashTable编码# 集合对象setset-max-intset-entries 512 # 存储元素超过512时，使用HashTable编码# 有序集合对象zsetzset-max-ziplist-entries 128 # 元素个数超过128，将用skiplist编码zset-max-ziplist-value 64 # 单个元素大小超过64byte，将用skiplist编码# 持久化相关的save 60 1000 # 关闭RDB只需要将所有的save保存策略注释掉即可appendonly yes # 打开AOF功能appendfsync always # 每次有新命令追加到AOF文件时就执行一次fsync，非常慢也非常安全appendfsync everysec # 每秒fsync一次，足够快且在故障时只会丢失1秒钟的数据appendfsync no # 从不fsync，将数据交给操作系统来处理。更快，也更不安全的选择auto-aof-rewrite-min-size 64mb # aof文件至少达到64M才会自动重写，文件太小恢复速度本来就很快，重写意义不大auto-aof-rewrite-percentage 100 # aof文件自上一次重写后文件大小增长了100%则再次触发重写aof-use-rdb-preamble yes # 开启混合持久化，注意必须先开启aof# 集群相关的min-replicas-to-write 1 # 写数据成功最少同步的slave数量maxclients 10000 # redis支持的最大连接数maxmemory 0 # 最大可使用内存值byte，默认0不限制# volatile-lru：从已设置过期时间的key中，移出最近最少使用的key进行淘汰# volatile-ttl：从已设置过期时间的key中，根据过期时间的先后进行删除，越早过期的越先被删除# volatile-random：从已设置过期时间的key中，随机选择key淘汰# allkeys-lru：从所有key中选择最近最少使用的进行淘汰# allkeys-random：从所有key中随机选择key进行淘汰# noeviction：当内存达到阈值的时候，新写入操作报错# volatile-lfu：使用LFU算法筛选设置了过期时间的键值对删除最近一段时间被访问次数最少的数据# allkeys-lfu：使用LFU算法在所有数据中进行筛选删除最近一段时间被访问次数最少的数据maxmemory_policy noeviction # 当达到maxmemory时的淘汰策略 缓存穿透缓存穿透是指查询一个根本不存在的数据， 缓存层和存储层都不会命中， 通常出于容错的考虑， 若从存储层查不到数据则不写入缓存层。缓存穿透将导致不存在的数据每次请求都要到存储层去查询， 失去了缓存保护后端存储的意义。 缓存空对象空对象缓存过期时间设置的短一点，最长不超过5分钟 1234567891011121314151617String get(String key) &#123; // 从缓存中获取数据 String cacheValue = cache.get(key); // 缓存为空 if (StringUtils.isBlank(cacheValue)) &#123; // 从存储中获取 String storageValue = storage.get(key); cache.set(key, storageValue); // 若存储数据为空，需要设置一个过期时间(300秒) if (storageValue == null) &#123; cache.expire(key, 60 * 5); &#125; return storageValue; &#125; else &#123; return cacheValue; // 缓存非空 &#125;&#125; 布隆过滤器对于恶意攻击，向服务器请求大量不存在的数据造成的缓存穿透，可用布隆过滤器先做一次过滤，对于不存在的数据布隆过滤器一般都能够过滤掉，不让请求再往后端发送。布隆过滤器判定某个值存在时，该值可能不存在；当判定不存在时，则肯定不存在。 布隆过滤器适用于数据命中不高、 数据相对固定、 实时性低通常是数据集较大的应用场景，代码维护较为复杂，但是缓存空间占用很少。使用布隆过滤器需要把所有数据提前放入布隆过滤器，且在增加数据时也要往布隆过滤器里放。布隆过滤器不能删除数据，若要删除得重新初始化布隆过滤器。 12345&lt;dependency&gt; &lt;groupId&gt;org.redisson&lt;/groupId&gt; &lt;artifactId&gt;redisson&lt;/artifactId&gt; &lt;version&gt;3.6.5&lt;/version&gt; &lt;/dependency&gt; 1234567891011121314151617public class RedissonBloomFilter &#123; public static void main(String[] args) &#123; Config config = new Config(); config.useSingleServer().setAddress(&quot;redis://localhost:6379&quot;); // 构造Redisson RedissonClient redisson = Redisson.create(config); RBloomFilter&lt;String&gt; bloomFilter = redisson.getBloomFilter(&quot;nameList&quot;); // 初始化布隆过滤器：预计元素为100000000L，误差率为3%，根据这两个参数会计算出底层的bit数组大小 bloomFilter.tryInit(100000000L,0.03); // 将eleven插入到布隆过滤器中 bloomFilter.add(&quot;eleven&quot;); // 判断下面号码是否在布隆过滤器中 System.out.println(bloomFilter.contains(&quot;eleven&quot;)); //false System.out.println(bloomFilter.contains(&quot;张三&quot;)); //false System.out.println(bloomFilter.contains(&quot;李四&quot;)); //true &#125;&#125; 缓存失效大批量缓存在同一时间失效可能导致大量请求同时穿透缓存直达数据库，可能会造成数据库瞬间压力过大甚至挂掉，在批量增加缓存时最好将这一批数据的缓存过期时间设置为一个时间段内的不同时间。 123456789101112131415161718String get(String key) &#123; // 从缓存中获取数据 String cacheValue = cache.get(key); // 缓存为空 if (StringUtils.isBlank(cacheValue)) &#123; // 从存储中获取 String storageValue = storage.get(key); cache.set(key, storageValue); // 设置一个过期时间(300到600之间的一个随机数) int expireTime = new Random().nextInt(300) + 300; if (storageValue == null) &#123; cache.expire(key, expireTime); &#125; return storageValue; &#125; else &#123; return cacheValue; // 缓存非空 &#125;&#125; 缓存雪崩缓存雪崩是指缓存层支撑不住或宕掉后，大量请求打向后端存储层。由于缓存层承载着大量请求，有效地保护了存储层，但若缓存层由于某些原因不能提供服务，如超大并发缓存层支撑不住，或者由于缓存设计不好，类似大量请求访问**bigkey**，导致缓存能支撑的并发急剧下降，于是大量请求打到存储层，存储层调用量暴增，造成存储层也会级联宕机的情况。 预防和解决缓存雪崩问题， 可从以下三个方面进行着手。 事前：保证缓存层服务高可用性，比如使用**Redis Sentinel哨兵模式或Redis Cluster集群模式**。 事中：依赖隔离组件为后端限流熔断并降级。如使用**Sentinel或Hystrix**限流降级组件。可针对不同数据采取不同的处理方式。当业务应用访问的是非核心数据时，暂时停止从缓存中查询这些数据，而是直接返回预定义的默认降级信息、空值或是错误提示信息；当业务应用访问的是核心数据时，仍然允许查询缓存，如果缓存缺失，也可以继续通过数据库读取。 事后：开启Redis持久化机制，能尽快恢复缓存集群 提前演练。在项目上线前，演练缓存层宕掉后，应用以及后端的负载情况以及可能出现的问题，在此基础上做一些预案设定 热KEY重建优化使用缓存 + 过期时间策略既可以加速数据读写，又保证数据定期更新，这种模式基本能够满足绝大部分需求。但若当前key是一个热点key并发量非常大，或重建缓存不能在短时间完成，可能是一个复杂计算如复杂的SQL、多次IO、多个依赖等， 可能会对应用造成致命的危害。 在缓存失效的瞬间，有大量线程来重建缓存，造成后端负载加大，甚至可能会让应用崩溃，要解决该问题主要就是要避免大量线程同时重建缓存。可利用互斥锁来解决，只允许一个线程重建缓存，其他线程等待重建缓存的线程执行完，重新从缓存获取数据即可。 123456789101112131415161718192021String get(String key) &#123; // 从Redis中获取数据 String value = redis.get(key); // 如果value为空， 则开始重构缓存 if (value == null) &#123; // 只允许一个线程重建缓存， 使用nx， 并设置过期时间ex String mutexKey = &quot;mutext:key:&quot; + key; if (redis.set(mutexKey, &quot;1&quot;, &quot;ex 180&quot;, &quot;nx&quot;)) &#123; // 分布式锁 // 从数据源获取数据 value = db.get(key); // 回写Redis， 并设置过期时间 redis.setex(key, timeout, value); // 删除key_mutex redis.delete(mutexKey); &#125; else &#123; // 其他线程休息50毫秒后重试 Thread.sleep(50); get(key); &#125; &#125; return value;&#125; 缓存与数据库双写不一致在大并发下，同时操作数据库与缓存会存在数据不一致性问题 对于并发几率很小的数据，这种几乎不用考虑该问题，很少会发生缓存不一致，可给缓存数据加上过期时间，每隔一段时间触发读的主动更新即可。就算并发很高，若业务上能容忍短时间的缓存数据不一致，缓存加上过期时间依然可以解决大部分业务对于缓存的要求。 若不能容忍缓存数据不一致，可以通过加读写锁保证并发读写或写写的时候按顺序排好队，读读的时候相当于无锁。也可用阿里开源的**canal通过监听数据库的binlog日志**及时的去修改缓存，但是引入了新的中间件，增加了系统的复杂度。 以上针对的都是读多写少的情况加入缓存提高性能，若写多读多的情况又不能容忍缓存数据不一致，那就没必要加缓存了，可直接操作数据库。放入缓存的数据应该是对实时性、一致性要求不是很高的数据。切记不要为了用缓存，同时又要保证绝对的一致性做大量的过度设计和控制，增加系统复杂性。 性能优化KEY设计KEY的设计以业务名为前缀，用逗号分割，在保证语义的前提下，控制KEY的长度，不要包含空格、换行、单双引号等特殊字符。 bigkey对于value值要拒绝bigkey防止网卡流量限制以及慢查询，对于字符串类型value超过**10kb就是bigkey；非字符串类型元素个数不要超过5000；非字符串的bigkey不要使用del删除，使用hscan、sscan、zscan方式渐进式删除，同时要注意防止bigkey过期时间自动删除问题**。 bigkey会导致redis阻塞、网络拥堵等问题，每次获取要产生的网络流量较大，一般服务器会采用单机多实例的方式来部署，bigkey可能会对其他实例也造成影响。过期删除若未使用Redis 4.0的过期异步删除lazyfree-lazy-expire yes，则可能阻塞Redis。可通过bigkey拆分成几个段储存从而解决bigkey问题。 命令使用O(N)命令关注N的数量，如**hgetall、lrange、smembers、zrange、sinter等并非不能使用，但是需要明确N的值，有遍历的需求可使用hscan、sscan、zscan代替，禁止线上使用keys、flushall、flushdb**等，通过redis的rename机制禁掉命令，或者使用scan的方式渐进式处理。 redis的多数据库较弱，使用数字进行区分，很多客户端支持较差，同时多业务用多数据库实际还是单线程处理会有干扰，要合适使用数字进行分区。 过期策略惰性删除 | 被动删除当读或写key时，才对key进行检测，若已经达到过期时间，则删除。若这些过期的key没有被访问，那么他就一直无法被删除，而且一直占用内存。 定期删除 | 主动删除每隔一段时间对数据库做一次检查，删除里面的过期key。由于不可能对所有key去做轮询来删除，所以redis会每次随机取一些key去做检查和删除。 当前已用内存超过**maxmemory限定时，触发主动清理策略**。 定期+惰性都没有删除过期的key每次定期随机查询key的时候没有删掉，这些key也没有做查询的话，就会导致这些key一直保存无法被删除，这时候就会走到redis的内存淘汰机制。 volatile-lru：从已设置过期时间的key中，移出最近最少使用的key进行淘汰 volatile-ttl：从已设置过期时间的key中，根据过期时间的先后进行删除，越早过期的越先被删除 volatile-random：从已设置过期时间的key中，随机选择key淘汰 allkeys-lru：从所有key中选择最近最少使用的进行淘汰 allkeys-random：从所有key中随机选择key进行淘汰 noeviction：当内存达到阈值的时候，新写入操作报错 volatile-lfu：使用LFU算法筛选设置了过期时间的键值对删除最近一段时间被访问次数最少的数据 allkeys-lfu：使用LFU算法在所有数据中进行筛选删除最近一段时间被访问次数最少的数据 LRU &amp; LFULRU算法是以最近一次访问时间作为参考淘汰很久没被访问过的数据，LFU算法以次数作为参考淘汰最近一段时间被访问次数最少的数据。 当存在热点数据时LRU的效率很好，但偶发性、周期性的批量操作会导致LRU命中率急剧下降，缓存污染情况比较严重。这时使用LFU可能更好点。 根据自身业务类型，配置好**maxmemory-policy，默认是noeviction，推荐使用volatile-lru**。若不设置最大内存，当Redis内存超出物理内存限制时，内存数据会开始和磁盘产生频繁的交换swap，会让Redis性能急剧下降。当Redis运行在主从模式时，只有主结点才会执行过期删除策略，然后把删除操作del key同步到从结点删除数据。 连接池预热使用带有连接池的数据库，可以有效控制连接，同时提高效率 1234567891011121314151617181920212223242526List&lt;Jedis&gt; minIdleJedisList = new ArrayList&lt;Jedis&gt;(jedisPoolConfig.getMinIdle());for (int i = 0; i &lt; jedisPoolConfig.getMinIdle(); i++) &#123; Jedis jedis = null; try &#123; jedis = pool.getResource(); minIdleJedisList.add(jedis); jedis.ping(); &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; finally &#123; //注意，这里不能马上close将连接还回连接池，否则最后连接池里只会建立1个连接。。 //jedis.close(); &#125;&#125;//统一将预热的连接还回连接池for (int i = 0; i &lt; jedisPoolConfig.getMinIdle(); i++) &#123; Jedis jedis = null; try &#123; jedis = minIdleJedisList.get(i); //将连接归还回连接池 jedis.close(); &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; finally &#123; &#125;&#125;","tags":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"Redis","slug":"Cloud/Redis","permalink":"http://example.com/categories/Cloud/Redis/"}]},{"title":"Redis分布式锁实现","date":"2017-12-15T06:20:20.000Z","path":"blog/Cloud/Redis/Redis分布式锁实现/","text":"分布式锁的各种问题及优化并发情况下以下代码可能导致超买 12345678int stock = Integer.parseInt(stringRedisTemplate.opsForValue().get(&quot;stock&quot;)); // jedis.get(&quot;stock&quot;)if (stock &gt; 0) &#123; int realStock = stock - 1; stringRedisTemplate.opsForValue().set(&quot;stock&quot;, realStock + &quot;&quot;); // jedis.set(key,value) System.out.println(&quot;扣减成功，剩余库存:&quot; + realStock);&#125; else &#123; System.out.println(&quot;扣减失败，库存不足&quot;);&#125; 为了解决该问题可以通过redis加上分布式锁，该方式是解决了并发问题，但是引入了新的问题，若业务代码异常可能导致锁永远得不到释放。 1234567891011121314String lockKey = &quot;product_101&quot;;Boolean result = stringRedisTemplate.opsForValue().setIfAbsent(lockKey, &quot;product_id&quot;);if (!result) &#123; return &quot;error_code&quot;;&#125;int stock = Integer.parseInt(stringRedisTemplate.opsForValue().get(&quot;stock&quot;));if (stock &gt; 0) &#123; int realStock = stock - 1; stringRedisTemplate.opsForValue().set(&quot;stock&quot;, realStock + &quot;&quot;); System.out.println(&quot;扣减成功，剩余库存:&quot; + realStock);&#125; else &#123; System.out.println(&quot;扣减失败，库存不足&quot;);&#125;stringRedisTemplate.delete(lockKey); 可以通过finally中来释放锁来解决业务代码异常的情况，但若当锁获取成功后机器宕机了，同样锁还是不能得到释放。 1234567891011121314151617String lockKey = &quot;product_101&quot;;try &#123; Boolean result = stringRedisTemplate.opsForValue().setIfAbsent(lockKey, &quot;product_id&quot;); if (!result) &#123; return &quot;error_code&quot;; &#125; int stock = Integer.parseInt(stringRedisTemplate.opsForValue().get(&quot;stock&quot;)); if (stock &gt; 0) &#123; int realStock = stock - 1; stringRedisTemplate.opsForValue().set(&quot;stock&quot;, realStock + &quot;&quot;); System.out.println(&quot;扣减成功，剩余库存:&quot; + realStock); &#125; else &#123; System.out.println(&quot;扣减失败，库存不足&quot;); &#125;&#125; finally &#123; stringRedisTemplate.delete(lockKey);&#125; 可以通过给锁加上一个过期时间的方式来解决获取锁成功后机器宕机，导致锁不能被释放的情况，但是这种写法还是没有完全解决，因为加锁和设置缓存时间不是原子操作。 123456789101112131415161718String lockKey = &quot;product_101&quot;;try &#123; Boolean result = stringRedisTemplate.opsForValue().setIfAbsent(lockKey, &quot;product_id&quot;); stringRedisTemplate.expire(lockKey, 10, TimeUnit.SECONDS); if (!result) &#123; return &quot;error_code&quot;; &#125; int stock = Integer.parseInt(stringRedisTemplate.opsForValue().get(&quot;stock&quot;)); if (stock &gt; 0) &#123; int realStock = stock - 1; stringRedisTemplate.opsForValue().set(&quot;stock&quot;, realStock + &quot;&quot;); System.out.println(&quot;扣减成功，剩余库存:&quot; + realStock); &#125; else &#123; System.out.println(&quot;扣减失败，库存不足&quot;); &#125;&#125; finally &#123; stringRedisTemplate.delete(lockKey);&#125; 可通过在加锁的同时设置超时原子操作来解决该问题，但设置了超时时间若当前业务代码没有被执行完其本身没有释放锁，但由于过期锁被清理掉了，新的线程加锁进来后，之前执行业务代码的线程又去把新的线程的锁释放了，将导致锁完全失效。 1234567891011121314151617String lockKey = &quot;product_101&quot;;try &#123; Boolean result = stringRedisTemplate.opsForValue().setIfAbsent(lockKey, &quot;product_id&quot;, 30, TimeUnit.SECONDS); if (!result) &#123; return &quot;error_code&quot;; &#125; int stock = Integer.parseInt(stringRedisTemplate.opsForValue().get(&quot;stock&quot;)); if (stock &gt; 0) &#123; int realStock = stock - 1; stringRedisTemplate.opsForValue().set(&quot;stock&quot;, realStock + &quot;&quot;); System.out.println(&quot;扣减成功，剩余库存:&quot; + realStock); &#125; else &#123; System.out.println(&quot;扣减失败，库存不足&quot;); &#125;&#125; finally &#123; stringRedisTemplate.delete(lockKey);&#125; 可通过给锁设置唯一标识的方式来解决其他线程释放非自身设置的锁，所有线程只能释放本线程设置的锁。 1234567891011121314151617181920String lockKey = &quot;product_101&quot;;String clientId = UUID.randomUUID().toString();try &#123; Boolean result = stringRedisTemplate.opsForValue().setIfAbsent(lockKey, &quot;product_id&quot;, 30, TimeUnit.SECONDS); if (!result) &#123; return &quot;error_code&quot;; &#125; int stock = Integer.parseInt(stringRedisTemplate.opsForValue().get(&quot;stock&quot;)); if (stock &gt; 0) &#123; int realStock = stock - 1; stringRedisTemplate.opsForValue().set(&quot;stock&quot;, realStock + &quot;&quot;); System.out.println(&quot;扣减成功，剩余库存:&quot; + realStock); &#125; else &#123; System.out.println(&quot;扣减失败，库存不足&quot;); &#125;&#125; finally &#123; if (clientId.equals(stringRedisTemplate.opsForValue().get(lockKey))) &#123; stringRedisTemplate.delete(lockKey); &#125;&#125; 虽然上面的锁已经很完善了，但还是有锁因为超时时间导致的极小概率的并发问题，该问题可以通过给锁续命即判断业务代码是否执行完成，若未完成则重置超时时间的方式来解决该问题。**Redisson**就是这样做的。 1234567891011121314151617String lockKey = &quot;product_101&quot;;String clientId = UUID.randomUUID().toString();RLock redissonLock = redisson.getLock(lockKey);try &#123; //加锁 redissonLock.lock(); //setIfAbsent(lockKey, clientId, 30, TimeUnit.SECONDS); int stock = Integer.parseInt(stringRedisTemplate.opsForValue().get(&quot;stock&quot;)); // jedis.get(&quot;stock&quot;) if (stock &gt; 0) &#123; int realStock = stock - 1; stringRedisTemplate.opsForValue().set(&quot;stock&quot;, realStock + &quot;&quot;); // jedis.set(key,value) System.out.println(&quot;扣减成功，剩余库存:&quot; + realStock); &#125; else &#123; System.out.println(&quot;扣减失败，库存不足&quot;); &#125;&#125; finally &#123; redissonLock.unlock();&#125; 红锁**RedLock**是一种利用多Master对共享资源做互斥访问，基于N个完全独立的Redis节点，运行Redlock算法通过在客户端依次执行下面的步骤来完成获取锁的操作： 获取当前时间，毫秒数 按顺序依次向N个Redis节点执行获取锁操作，该获取操作跟前面基于单Redis节点获取锁过程相同，为了保证在某个Redis节点不可用的时候算法能够继续运行，该获取锁操作还有一个超时时间，几十毫秒量级，它要远小于锁的有效时间。客户端在向某个Redis节点获取锁失败后，应该立即尝试下一个Redis节点，这里的失败应该包含任何类型的失败，如该Redis节点不可用、该Redis节点上的锁已经被其它客户端持有 计算整个获取锁的过程总共消耗了多长时间，计算方法是用当前时间减去第1步记录的时间。若客户端从大多数Redis节点即**&gt;= N/2+1成功获取到了锁，且获取锁总耗时没有超过锁的有效时间**，则此时客户端才认为最终获取锁成功；否则认为最终获取锁失败 若最终获取锁成功，则该锁的有效时间应该重新计算，它等于最初的锁的有效时间减去第3步计算出来的获取锁消耗的时间 若最终获取锁失败了，可能由于获取到锁的Redis节点个数少于**N/2+1，或整个获取锁的过程耗时超过了锁的最初有效时间，则客户端应该立即向所有Redis节点发起释放锁操作** 释放锁的过程比较简单：客户端向所有Redis节点发起释放锁的操作，不管这些节点当时在获取锁时成功与否。在最后释放锁时，客户端应该向所有Redis节点发起释放锁的操作，即使当时向某个节点获取锁没有成功，在释放锁时也不应该漏掉该节点。因为若客户端发给某个Redis节点获取锁的请求成功到达了该Redis节点，该节点也成功执行了SET操作，但返回给客户端的响应包却丢失。在客户端看来，获取锁的请求由于超时而失败了，但在Redis这边看来，加锁已经成功了。因此释放锁时，客户端也应该对当时获取锁失败的那些Redis节点同样发起请求。 但由于N个Redis节点中的大多数能正常工作就能保证Redlock正常工作，因此理论上它的可用性更高。单Redis节点的分布式锁在failover的时锁失效的问题，在Redlock中不存在了，但若有节点发生崩溃重启，还是会对锁的安全性有影响，具体的影响程度跟Redis对数据的持久化程度有关。 假设一共有5个Redis节点**A、B、C、D、E，若客户端1成功锁住了A、B、C，获取锁成功， 但D和E没有锁住，节点C崩溃重启了，但客户端1在C上加的锁没有持久化下来，丢失了，节点C重启后，客户端2锁住了C、D、E， 获取锁成功，针对同一资源客户端1和客户端2同时获得了锁**。 Redis的**AOF持久化方式默认是每秒写一次磁盘，最坏情况下可能丢失1秒的数据，为了尽可能不丢数据，Redis允许设置成每次修改数据都进行fsync，但这会降低性能。当然，即使执行了fsync也仍然有可能丢失数据，这取决于系统而不是Redis的实现。故上面分析的由于节点重启引发的锁失效问题，总是有可能出现的。为了应对这一问题，可通过延迟重启，即一个节点崩溃后，先不立即重启它，而是等待一段时间再重启，该时间应该大于锁的有效时间，该节点在重启前所参与的锁都会过期**，它在重启后就不会对现有的锁造成影响。 Redisson锁原理123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119public class Redisson implements RedissonClient &#123; public RLock getLock(String name) &#123; return new RedissonLock(connectionManager.getCommandExecutor(), name); &#125;&#125;public class RedissonLock extends RedissonExpirable implements RLock &#123; public RedissonLock(CommandAsyncExecutor commandExecutor, String name) &#123; super(commandExecutor, name); this.commandExecutor = commandExecutor; this.id = commandExecutor.getConnectionManager().getId(); this.internalLockLeaseTime = commandExecutor.getConnectionManager().getCfg().getLockWatchdogTimeout(); &#125; public void lock(long leaseTime, TimeUnit unit) &#123; try &#123; lockInterruptibly(leaseTime, unit); &#125; catch (InterruptedException e) &#123; Thread.currentThread().interrupt(); &#125; &#125; public void lockInterruptibly(long leaseTime, TimeUnit unit) throws InterruptedException &#123; long threadId = Thread.currentThread().getId(); // 获取当前线程的ID Long ttl = tryAcquire(leaseTime, unit, threadId); // 尝试获取锁，并返回锁剩余持有时间 if (ttl == null) &#123; // 若锁剩余持有时间为null，表示获取锁成功 return; // 获取锁成功 &#125; RFuture&lt;RedissonLockEntry&gt; future = subscribe(threadId); commandExecutor.syncSubscription(future); try &#123; while (true) &#123; ttl = tryAcquire(leaseTime, unit, threadId); if (ttl == null) &#123; break; &#125; if (ttl &gt;= 0) &#123; getEntry(threadId).getLatch().tryAcquire(ttl, TimeUnit.MILLISECONDS); &#125; else &#123; getEntry(threadId).getLatch().acquire(); &#125; &#125; &#125; finally &#123; unsubscribe(future, threadId); &#125; &#125; private Long tryAcquire(long leaseTime, TimeUnit unit, long threadId) &#123; return get(tryAcquireAsync(leaseTime, unit, threadId)); &#125; private &lt;T&gt; RFuture&lt;Long&gt; tryAcquireAsync(long leaseTime, TimeUnit unit, final long threadId) &#123; if (leaseTime != -1) &#123; // 设置了超时时间的逻辑 return tryLockInnerAsync(leaseTime, unit, threadId, RedisCommands.EVAL_LONG); &#125; // 未设置超时时间默认设置超时时间为30s RFuture&lt;Long&gt; ttlRemainingFuture = tryLockInnerAsync(commandExecutor.getConnectionManager().getCfg().getLockWatchdogTimeout(), TimeUnit.MILLISECONDS, threadId, RedisCommands.EVAL_LONG); ttlRemainingFuture.addListener(new FutureListener&lt;Long&gt;() &#123; @Override public void operationComplete(Future&lt;Long&gt; future) throws Exception &#123; if (!future.isSuccess()) &#123; return; &#125; Long ttlRemaining = future.getNow(); if (ttlRemaining == null) &#123; // 若当前锁还没有释放，则给当前锁续超时时间 scheduleExpirationRenewal(threadId); &#125; &#125; &#125;); return ttlRemainingFuture; &#125; &lt;T&gt; RFuture&lt;T&gt; tryLockInnerAsync(long leaseTime, TimeUnit unit, long threadId, RedisStrictCommand&lt;T&gt; command) &#123; internalLockLeaseTime = unit.toMillis(leaseTime); // 异步执行lua命令获取锁，若获取锁成功返回null，否则返回剩余持有时间 return commandExecutor .evalWriteAsync(getName(), LongCodec.INSTANCE, command, &quot;if (redis.call(&#x27;exists&#x27;, KEYS[1]) == 0) then &quot; + // 判断锁是否存在 &quot;redis.call(&#x27;hset&#x27;, KEYS[1], ARGV[2], 1); &quot; + // 将锁的的状态设置为1 &quot;redis.call(&#x27;pexpire&#x27;, KEYS[1], ARGV[1]); &quot; + // 给锁加上失效时间 &quot;return nil; &quot; + &quot;end; &quot; + &quot;if (redis.call(&#x27;hexists&#x27;, KEYS[1], ARGV[2]) == 1) then &quot; + // 重入锁的处理，锁存在，且加锁对象是当前线程 &quot;redis.call(&#x27;hincrby&#x27;, KEYS[1], ARGV[2], 1); &quot; + // 将锁加一 &quot;redis.call(&#x27;pexpire&#x27;, KEYS[1], ARGV[1]); &quot; + // 重置失效时间 &quot;return nil; &quot; + &quot;end; &quot; + &quot;return redis.call(&#x27;pttl&#x27;, KEYS[1]);&quot;, // 返回锁剩余的失效时间 Collections.&lt;Object&gt;singletonList(getName()), internalLockLeaseTime, getLockName(threadId)); &#125; private void scheduleExpirationRenewal(final long threadId) &#123; if (expirationRenewalMap.containsKey(getEntryName())) &#123; return; &#125; // 每10s执行一次 Timeout task = commandExecutor.getConnectionManager().newTimeout(new TimerTask() &#123; @Override public void run(Timeout timeout) throws Exception &#123; RFuture&lt;Boolean&gt; future = commandExecutor .evalWriteAsync(getName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN, &quot;if (redis.call(&#x27;hexists&#x27;, KEYS[1], ARGV[2]) == 1) then &quot; + // 若KEY存在则返回true，否则返回false &quot;redis.call(&#x27;pexpire&#x27;, KEYS[1], ARGV[1]); &quot; + // 重置超时时间 &quot;return 1; &quot; + &quot;end; &quot; + &quot;return 0;&quot;, Collections.&lt;Object&gt;singletonList(getName()), internalLockLeaseTime, getLockName(threadId)); future.addListener(new FutureListener&lt;Boolean&gt;() &#123; @Override public void operationComplete(Future&lt;Boolean&gt; future) throws Exception &#123; expirationRenewalMap.remove(getEntryName()); if (!future.isSuccess()) &#123; return; &#125; if (future.getNow()) &#123; // 若当前锁还没有释放，则给当前锁续超时时间 scheduleExpirationRenewal(threadId); &#125; &#125; &#125;); &#125; &#125;, internalLockLeaseTime / 3, TimeUnit.MILLISECONDS); if (expirationRenewalMap.putIfAbsent(getEntryName(), task) != null) &#123; task.cancel(); &#125; &#125;&#125; LUA脚本Redis在2.6推出了脚本功能，允许开发者使用Lua语言编写脚本传到Redis中执行： 减少网络开销：本来5次网络请求的操作，可用一个请求完成，原先5次请求的逻辑放在redis服务器上完成。使用脚本，减少了网络往返时延。这点跟管道类似。 原子操作：Redis会将整个脚本作为一个整体执行，中间不会被其他命令插入。管道不是原子的，不过redis的批量操作命令是原子。 替代redis的事务功能：redis自带的事务功能很鸡肋，而redis的lua脚本几乎实现了常规的事务功能，官方推荐如果要使用redis的事务功能可以用redis lua替代。 可以使用EVAL命令对Lua脚本进行求值。EVAL命令的格式如下： 1EVAL script numkeys key [key ...] arg [arg ...] script参数是一段Lua脚本程序，它会被运行在Redis服务器上下文中，**numkeys参数用于指定键名参数的个数。键名参数key [key ...]从EVAL的第三个参数开始算起，表示在脚本中所用到的那些Redis键(key)，这些键名参数可在Lua中通过全局变量KEYS数组，用1为基址**的形式访问KEYS[1]，KEYS[2] 以此类推。 在命令的最后不是键名参数的附加参数**arg [arg ...]，可在Lua中通过全局变量ARGV数组访问，访问的形式和KEYS变量类似(ARGV[1]、ARGV[2]，在Lua脚本中，可使用redis.call()**函数来执行Redis命令： 1234567891011jedis.set(&quot;product_stock_10016&quot;, &quot;15&quot;); //初始化商品10016的库存String script = &quot; local count = redis.call(&#x27;get&#x27;, KEYS[1]) &quot; + &quot; local a = tonumber(count) &quot; + &quot; local b = tonumber(ARGV[1]) &quot; + &quot; if a &gt;= b then &quot; + &quot; redis.call(&#x27;set&#x27;, KEYS[1], a-b) &quot; + &quot; return 1 &quot; + &quot; end &quot; + &quot; return 0 &quot;;Object obj = jedis.eval(script, Arrays.asList(&quot;product_stock_10016&quot;), Arrays.asList(&quot;10&quot;));System.out.println(obj); 不要在Lua脚本中出现死循环和耗时的运算，否则redis会阻塞，将不接受其他的命令，所以使用时要注意不能出现死循环、耗时的运算。redis是单进程、单线程执行脚本。**管道不会阻塞redis**。","tags":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"Redis","slug":"Cloud/Redis","permalink":"http://example.com/categories/Cloud/Redis/"}]},{"title":"Redis实践-Java","date":"2017-12-15T06:08:20.000Z","path":"blog/Cloud/Redis/Redis实践-Java/","text":"什么是Jedis在常见命令中，使用各种Redis自带客户端的命令行方式访问Redis服务。 而在实际工作中却需要用到Java代码才能访问，使用第三方jar包 ：Jedis就能方便地访问Redis的各种服务了。 简单运用：TestJedis：12345678910111213package redis;import redis.clients.jedis.Jedis;public class TestRedis &#123; public static void main(String[] args) &#123; Jedis jedis = new Jedis(&quot;localhost&quot;); jedis.set(&quot;foo&quot;, &quot;bar&quot;); String value = jedis.get(&quot;foo&quot;); System.out.println(value); &#125;&#125; TestRedisManyCommands:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151package redis;import java.util.HashMap;import java.util.Iterator;import java.util.List;import java.util.Map; import org.junit.Before;import org.junit.Test; import redis.clients.jedis.Jedis;import redis.clients.jedis.JedisPool; public class TestRedisManyCommands &#123; JedisPool pool; Jedis jedis; @Before public void setUp() &#123; jedis = new Jedis(&quot;localhost&quot;); &#125; /** * Redis存储初级的字符串 * CRUD */ @Test public void testBasicString()&#123; //-----添加数据---------- jedis.set(&quot;name&quot;,&quot;meepo&quot;);//向key--&gt;name中放入了value--&gt;meepo System.out.println(jedis.get(&quot;name&quot;));//执行结果：meepo //-----修改数据----------- //1、在原来基础上修改 jedis.append(&quot;name&quot;,&quot;dota&quot;); //很直观，类似map 将dota append到已经有的value之后 System.out.println(jedis.get(&quot;name&quot;));//执行结果:meepodota //2、直接覆盖原来的数据 jedis.set(&quot;name&quot;,&quot;poofu&quot;); System.out.println(jedis.get(&quot;name&quot;));//执行结果：poofu //删除key对应的记录 jedis.del(&quot;name&quot;); System.out.println(jedis.get(&quot;name&quot;));//执行结果：null /** * mset相当于 * jedis.set(&quot;name&quot;,&quot;meepo&quot;); * jedis.set(&quot;dota&quot;,&quot;poofu&quot;); */ jedis.mset(&quot;name&quot;,&quot;meepo&quot;,&quot;dota&quot;,&quot;poofu&quot;); System.out.println(jedis.mget(&quot;name&quot;,&quot;dota&quot;)); &#125; /** * jedis操作Map */ @Test public void testMap()&#123; Map&lt;String,String&gt; user=new HashMap&lt;String,String&gt;(); user.put(&quot;name&quot;,&quot;meepo&quot;); user.put(&quot;pwd&quot;,&quot;password&quot;); jedis.hmset(&quot;user&quot;,user); //取出user中的name，执行结果:[meepo]--&gt;注意结果是一个泛型的List //第一个参数是存入redis中map对象的key，后面跟的是放入map中的对象的key，后面的key可以跟多个，是可变参数 List&lt;String&gt; rsmap = jedis.hmget(&quot;user&quot;, &quot;name&quot;); System.out.println(rsmap); //删除map中的某个键值 // jedis.hdel(&quot;user&quot;,&quot;pwd&quot;); System.out.println(jedis.hmget(&quot;user&quot;, &quot;pwd&quot;)); //因为删除了，所以返回的是null System.out.println(jedis.hlen(&quot;user&quot;)); //返回key为user的键中存放的值的个数1 System.out.println(jedis.exists(&quot;user&quot;));//是否存在key为user的记录 返回true System.out.println(jedis.hkeys(&quot;user&quot;));//返回map对象中的所有key [pwd, name] System.out.println(jedis.hvals(&quot;user&quot;));//返回map对象中的所有value [meepo, password] Iterator&lt;String&gt; iter=jedis.hkeys(&quot;user&quot;).iterator(); while (iter.hasNext())&#123; String key = iter.next(); System.out.println(key+&quot;:&quot;+jedis.hmget(&quot;user&quot;,key)); &#125; &#125; /** * jedis操作List */ @Test public void testList()&#123; //开始前，先移除所有的内容 jedis.del(&quot;java framework&quot;); // 第一个是key，第二个是起始位置，第三个是结束位置，jedis.llen获取长度 -1表示取得所有 System.out.println(jedis.lrange(&quot;java framework&quot;,0,-1)); //先向key java framework中存放三条数据 jedis.lpush(&quot;java framework&quot;,&quot;spring&quot;); jedis.lpush(&quot;java framework&quot;,&quot;struts&quot;); jedis.lpush(&quot;java framework&quot;,&quot;hibernate&quot;); //再取出所有数据jedis.lrange是按范围取出， // 第一个是key，第二个是起始位置，第三个是结束位置，jedis.llen获取长度 -1表示取得所有 System.out.println(jedis.lrange(&quot;java framework&quot;,0,-1)); &#125; /** * jedis操作Set */ @Test public void testSet()&#123; //添加 jedis.sadd(&quot;sname&quot;,&quot;meepo&quot;); jedis.sadd(&quot;sname&quot;,&quot;dota&quot;); jedis.sadd(&quot;sname&quot;,&quot;poofu&quot;); jedis.sadd(&quot;sname&quot;,&quot;noname&quot;); //移除noname jedis.srem(&quot;sname&quot;,&quot;noname&quot;); System.out.println(jedis.smembers(&quot;sname&quot;));//获取所有加入的value System.out.println(jedis.sismember(&quot;sname&quot;, &quot;meepo&quot;));//判断 meepo 是否是sname集合的元素 System.out.println(jedis.srandmember(&quot;sname&quot;)); System.out.println(jedis.scard(&quot;sname&quot;));//返回集合的元素个数 &#125; @Test public void test() throws InterruptedException &#123; //keys中传入的可以用通配符 System.out.println(jedis.keys(&quot;*&quot;)); //返回当前库中所有的key [sose, sanme, name, dota, foo, sname, java framework, user, braand] System.out.println(jedis.keys(&quot;*name&quot;));//返回的sname [sname, name] System.out.println(jedis.del(&quot;sanmdde&quot;));//删除key为sanmdde的对象 删除成功返回1 删除失败（或者不存在）返回 0 System.out.println(jedis.ttl(&quot;sname&quot;));//返回给定key的有效时间，如果是-1则表示永远有效 jedis.setex(&quot;timekey&quot;, 10, &quot;min&quot;);//通过此方法，可以指定key的存活（有效时间） 时间为秒 Thread.sleep(5000);//睡眠5秒后，剩余时间将为&lt;=5 System.out.println(jedis.ttl(&quot;timekey&quot;)); //输出结果为5 jedis.setex(&quot;timekey&quot;, 1, &quot;min&quot;); //设为1后，下面再看剩余时间就是1了 System.out.println(jedis.ttl(&quot;timekey&quot;)); //输出结果为1 System.out.println(jedis.exists(&quot;key&quot;));//检查key是否存在 System.out.println(jedis.rename(&quot;timekey&quot;,&quot;time&quot;)); System.out.println(jedis.get(&quot;timekey&quot;));//因为移除，返回为null System.out.println(jedis.get(&quot;time&quot;)); //因为将timekey 重命名为time 所以可以取得值 min //jedis 排序 //注意，此处的rpush和lpush是List的操作。是一个双向链表（但从表现来看的） jedis.del(&quot;a&quot;);//先清除数据，再加入数据进行测试 jedis.rpush(&quot;a&quot;, &quot;1&quot;); jedis.lpush(&quot;a&quot;,&quot;6&quot;); jedis.lpush(&quot;a&quot;,&quot;3&quot;); jedis.lpush(&quot;a&quot;,&quot;9&quot;); System.out.println(jedis.lrange(&quot;a&quot;,0,-1));// [9, 3, 6, 1] System.out.println(jedis.sort(&quot;a&quot;)); //[1, 3, 6, 9] //输入排序后结果 System.out.println(jedis.lrange(&quot;a&quot;,0,-1)); &#125; &#125;","tags":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"Redis","slug":"Cloud/Redis","permalink":"http://example.com/categories/Cloud/Redis/"}]},{"title":"Redis集群架构","date":"2017-12-15T04:08:20.000Z","path":"blog/Cloud/Redis/Redis集群架构/","text":"主从架构：12345678910111213141516171819# 复制一份redis.conf文件port 6380pidfile /var/run/redis_6380.pid # 把pid进程号写入pidfile配置的文件logfile &quot;6380.log&quot;dir /usr/local/redis-5.0.3/data/6380 # 指定数据存放目录# 需要注释掉bind# bind 127.0.0.1 绑定机器网卡ip，多块网卡可配多个ip，代表允许客户端通过机器的哪些网卡ip去访问，内网一般可不配置bind# 配置主从复制replicaof 192.168.0.60 6379 # 从本机6379的redis实例复制数据，Redis 5.0之前使用slaveofreplica-read-only yes # 配置从节点只读# 启动从节点redis-server redis.conf# 连接从节点redis-cli -p 6380# 测试在6379实例上写数据，6380实例是否能及时同步新修改数据# 可以自己再配置一个6381的从节点 若为**master主节点配置了一个slave从节点，不管该slave从节点是否是第一次连接上Master主节点，都会发送一个PSYNC**命令给master请求复制数据。 master主节点收到**PSYNC命令后，会在后台进行数据持久化，通过bgsave生成最新的rdb快照文件，持久化期间master会继续接收客户端请求，且把这些可能修改数据集的请求缓存在内存中。当持久化进行完毕以后，master主节点会把这份rdb文件数据集发送给slave从节点，slave会把接收到的数据进行持久化生成rdb，然后再加载到内存中。master主节点再将之前缓存在内存中的命令发送给slave从节点**。 当master主节点与slave从节点之间的连接由于某些原因而断开时，slave从节点能够自动重连Master主节点，若master收到了多个slave从节点并发连接请求，它只会进行一次持久化，然后把这一份持久化的数据发送给多个并发连接的slave从节点。 当master主节点和slave从节点断开重连后，一般都会对整份数据进行复制。但从**Redis 2.8开始，PSYNC命令支持部分数据复制去master同步数据，slave从节点与master主节点能够在网络连接断开重连后只进行部分数据复制即断点续传**。 若有很多从节点，多个从节点同时复制主节点导致主节点压力过大，为了缓解主从复制风暴，可让部分从节点与从节点同步数据： 哨兵模式sentinel哨兵是特殊的redis服务，不提供读写服务，主要用来监控redis实例节点，哨兵架构下**client端第一次从哨兵找出redis的主节点，后续直接访问redis主节点，不会每次都通过sentinel哨兵代理访问redis的主节点，当redis的主节点发生变化，哨兵会第一时间感知到，并且将新的redis主节点通知给client端，redis的client端一般都实现了订阅**功能，订阅sentinel哨兵发布的节点变动消息。 12345678910111213141516171819# 复制一份sentinel.conf文件cp sentinel.conf sentinel-26379.confport 26379daemonize yespidfile &quot;/var/run/redis-sentinel-26379.pid&quot;logfile &quot;26379.log&quot;dir &quot;/usr/local/redis-5.0.3/data&quot;# sentinel monitor &lt;master-redis-name&gt; &lt;master-redis-ip&gt; &lt;master-redis-port&gt; &lt;quorum&gt;# quorum是一个数字，指明当有多少个sentinel认为一个master失效时(值一般为：sentinel总数/2 + 1)，master才算真正失效sentinel monitor mmaster 192.168.0.60 6379 2 # mmaster名字随便取，客户端访问时会用到# 启动sentinel哨兵实例src/redis-sentinel sentinel-26379.conf# 查看sentinel的info信息src/redis-cli -p 26379127.0.0.1:26379&gt;info # 可以看到Sentinel的info里已经识别出了redis的主从# 可再配置两个sentinel，端口26380和26381，注意上述配置文件里的对应数字都要修改 sentinel集群都启动完毕后，会将哨兵集群的元数据信息写入所有sentinel配置文件中，追加在文件的最下面： 1234sentinel known-replica mmaster 192.168.0.60 6380 #代表redis主节点的从节点信息sentinel known-replica mmaster 192.168.0.60 6381 #代表redis主节点的从节点信息sentinel known-sentinel mmaster 192.168.0.60 26380 52d0a5d70c1f90475b4fc03b6ce7c3c56935760f # 感知到的其它哨兵节点sentinel known-sentinel mmaster 192.168.0.60 26381 e9f530d3882f8043f76ebb8e1686438ba8bd5ca6 当redis主节点如果挂了，哨兵集群会重新选举出新的**redis主节点**，同时修改所有sentinel节点配置文件的集群元数据信息，如6379的redis挂了，假设选举出的新主节点是6380： 1234sentinel known-replica mmaster 192.168.0.60 6379 # 主节点的从节点信息sentinel known-replica mmaster 192.168.0.60 6381 # 主节点的从节点信息sentinel known-sentinel mmaster 192.168.0.60 26380 52d0a5d70c1f90475b4fc03b6ce7c3c56935760f # 感知到的其它哨兵节点sentinel known-sentinel mmaster 192.168.0.60 26381 e9f530d3882f8043f76ebb8e1686438ba8bd5ca6 同时修改sentinel文件里之前配置的mmaster对应的**6379端口，改为6380，当6379的redis实例再次启动时，哨兵集群根据集群元数据信息就可以将6379端口的redis节点作为从节点**加入集群: 1sentinel monitor mmaster 192.168.0.60 6380 2 1234567891011121314151617181920212223242526272829public class JedisSentinelTest &#123; public static void main(String[] args) throws IOException &#123; JedisPoolConfig config = new JedisPoolConfig(); config.setMaxTotal(20); config.setMaxIdle(10); config.setMinIdle(5); String masterName = &quot;mmaster&quot;; Set&lt;String&gt; sentinels = new HashSet&lt;String&gt;(); sentinels.add(new HostAndPort(&quot;172.16.20.53&quot;, 26379).toString()); sentinels.add(new HostAndPort(&quot;172.16.20.53&quot;, 26380).toString()); sentinels.add(new HostAndPort(&quot;172.16.20.53&quot;, 26381).toString()); // JedisSentinelPool其实本质跟JedisPool类似，都是与redis主节点建立的连接池 // JedisSentinelPool并不是说与sentinel建立的连接池，而是通过sentinel发现redis主节点并与其建立连接 JedisSentinelPool jedisSentinelPool = new JedisSentinelPool(masterName, sentinels, config, 3000, null); Jedis jedis = null; try &#123; jedis = jedisSentinelPool.getResource(); System.out.println(jedis.set(&quot;sentinel&quot;, &quot;eleven&quot;)); System.out.println(jedis.get(&quot;sentinel&quot;)); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; // 注意这里不是关闭连接，在JedisPool模式下，Jedis会被归还给资源池。 if (jedis != null) &#123; jedis.close(); &#125; &#125; &#125;&#125; Spring Boot整合Redis哨兵模式:只需要引入如下依赖，并将哨兵的节点信息配置到配置文件中，即可通过自动注入的方式引入**StringRedisTemplate或RedisTemplate**进行使用: 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt;&lt;/dependency&gt; 12345678910111213spring: redis: database: 0 timeout: 3000 sentinel: # 哨兵模式 master: mmaster # 主服务器所在集群名称 nodes: 192.168.0.60:26379,192.168.0.60:26380,192.168.0.60:26381 lettuce: pool: max-idle: 50 min-idle: 10 max-active: 100 max-wait: 1000 12345678910111213141516171819202122232425@RestControllerpublic class IndexController &#123; private static final Logger logger = LoggerFactory.getLogger(IndexController.class); @Autowired private StringRedisTemplate stringRedisTemplate; /** * 测试节点挂了哨兵重新选举新的master节点，客户端是否能动态感知到 * 新的master选举出来后，哨兵会把消息发布出去，客户端实际上是实现了一个消息监听机制， * 当哨兵把新master的消息发布出去，客户端会立马感知到新master的信息，从而动态切换访问的masterip */ @RequestMapping(&quot;/test_sentinel&quot;) public void testSentinel() throws InterruptedException &#123; int i = 1; while (true)&#123; try &#123; stringRedisTemplate.opsForValue().set(&quot;zhuge&quot;+i, i+&quot;&quot;); System.out.println(&quot;设置key：&quot;+ &quot;zhuge&quot; + i); i++; Thread.sleep(1000); &#125;catch (Exception e)&#123; logger.error(&quot;错误：&quot;, e); &#125; &#125; &#125;&#125; 问题：Redis 3.0以前的版本要实现集群一般是借助哨兵sentinel工具来监控master节点的状态，若master节点异常则会做主从切换，将某一台slave作为master，哨兵的配置略微复杂，且性能和高可用性等各方面表现一般，且在主从切换瞬间存在访问瞬断情况，且哨兵模式只有一个主节点对外提供服务，无法支持很高的并发，且单个主节点内存也不宜设置得过大，否则会导致持久化文件过大，影响数据恢复或主从同步的效率。 集群模式： Redis集群是一个由多个主从节点群组成的分布式服务器群，具有复制、高可用和分片特性，Redis集群不需要sentinel哨兵也能完成节点移除和故障转移的功能。只需要将每个节点设置成集群模式，这种集群模式没有中心节点可水平扩展，据官方文档称可以线性扩展到上万个节点，官方推荐不超过1000个节点。Redis集群的性能和高可用性均优于之前版本的哨兵模式，且集群配置非常简单，**Redis集群需要至少三个master主节点**。 1234567891011121314151617181920212223242526272829303132333435363738# 第一步：在第一台机器的/usr/local下创建文件夹redis-cluster，然后在其下面分别创建2个文件夾如下mkdir -p /usr/local/redis-clustermkdir 8001 8004# 把之前的redis.conf配置文件copy到8001下，修改如下内容：daemonize yesport 8001 # 分别对每个机器的端口号进行设置pidfile /var/run/redis_8001.pid # 把pid进程号写入pidfile配置的文件dir /usr/local/redis-cluster/8001/（指定数据文件存放位置，必须要指定不同的目录位置，不然会丢失数据）cluster-enabled yes（启动集群模式）cluster-config-file nodes-8001.conf（集群节点信息文件，这里800x最好和port对应上）cluster-node-timeout 10000# bind 127.0.0.1 绑定机器网卡ip，若有多块网卡可配多个ip，代表允许客户端通过机器的哪些网卡ip去访问protected-mode no # 关闭保护模式appendonly yes# 如果要设置密码需要增加如下配置：requirepass eleven # 设置redis访问密码masterauth eleven # 设置集群节点间访问密码，跟上面一致# 分别启动redis实例，然后检查是否启动成功src/redis-server redis.confps -ef | grep redis # 查看是否启动成功# 首先需要确认集群机器之间redis实例能相互访问，可先把所有机器防火墙关掉，若不关闭防火墙则需打开redis服务端口和集群节点gossip通信端口16379，默认是在redis端口号上加1W# systemctl stop firewalld # 临时关闭防火墙# systemctl disable firewalld # 禁止开机启动# 用redis-cli创建整个redis集群，redis5以前版本集群依靠ruby脚本redis-trib.rb实现# 命令中的1代表为每个创建的主服务器节点创建一个从服务器节点src/redis-cli -a zhuge --cluster create --cluster-replicas 1 192.168.0.61:8001 192.168.0.62:8002 192.168.0.63:8003 192.168.0.61:8004 192.168.0.62:8005 192.168.0.63:8006# 验证集群， -a访问服务端密码，-c表示集群模式，指定ip地址和端口号src/redis-cli -a eleven -c -h 192.168.0.61 -p 8001cluster info # 查看集群信息cluster nodes # 查看节点列表# 关闭集群则需要逐个进行关闭，使用命令：src/redis-cli -a eleven -c -h 192.168.0.60 -p 8001 shutdown 集群使用:借助redis的java客户端jedis可以操作以上集群，引用jedis版本的maven如下: 12345&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt;&lt;/dependency&gt; 12345678910111213141516171819202122232425262728293031public class JedisClusterTest &#123; public static void main(String[] args) throws IOException &#123; JedisPoolConfig config = new JedisPoolConfig(); config.setMaxTotal(20); config.setMaxIdle(10); config.setMinIdle(5); Set&lt;HostAndPort&gt; jedisClusterNode = new HashSet&lt;HostAndPort&gt;(); jedisClusterNode.add(new HostAndPort(&quot;192.168.0.61&quot;, 8001)); jedisClusterNode.add(new HostAndPort(&quot;192.168.0.62&quot;, 8002)); jedisClusterNode.add(new HostAndPort(&quot;192.168.0.63&quot;, 8003)); jedisClusterNode.add(new HostAndPort(&quot;192.168.0.61&quot;, 8004)); jedisClusterNode.add(new HostAndPort(&quot;192.168.0.62&quot;, 8005)); jedisClusterNode.add(new HostAndPort(&quot;192.168.0.63&quot;, 8006)); JedisCluster jedisCluster = null; try &#123; // connectionTimeout：指的是连接一个url的连接等待时间 // soTimeout：指的是连接上一个url，获取response的返回等待时间 jedisCluster = new JedisCluster(jedisClusterNode, 6000, 5000, 10, &quot;eleven&quot;, config); System.out.println(jedisCluster.set(&quot;cluster&quot;, &quot;eleven&quot;)); System.out.println(jedisCluster.get(&quot;cluster&quot;)); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; if (jedisCluster != null) &#123; jedisCluster.close(); &#125; &#125; &#125;&#125; 集群的Spring Boot整合Redis连接12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt;&lt;/dependency&gt; 12345678910111213spring: redis: database: 0 timeout: 3000 password: root cluster: nodes: 192.168.0.61:8001,192.168.0.62:8002,192.168.0.63:8003,192.168.0.61:8004,192.168.0.62:8005,192.168.0.63:8006 lettuce: pool: max-idle: 50 min-idle: 10 max-active: 100 max-wait: 1000 1234567891011@RestControllerpublic class IndexController &#123; @Autowired private StringRedisTemplate stringRedisTemplate; @RequestMapping(&quot;/test_cluster&quot;) public void testCluster() throws InterruptedException &#123; stringRedisTemplate.opsForValue().set(&quot;eleven&quot;, &quot;666&quot;); System.out.println(stringRedisTemplate.opsForValue().get(&quot;eleven&quot;)); &#125;&#125;","tags":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"Redis","slug":"Cloud/Redis","permalink":"http://example.com/categories/Cloud/Redis/"}]},{"title":"Redis安装","date":"2017-12-15T03:08:20.000Z","path":"blog/Cloud/Redis/Redis安装/","text":"Redis官网： redis官网：http://redis.io windows版本的下载地址是： http://redis.io/download 点击进去之后会跳转到： https://github.com/mythz/redis-windows 是一个开源项目，所以从github上下载后，需要自己编译生成exe文件，但是为了编译生成exe文件，又需要用到Visual Studio一套。 启动服务端：redis-server.exe 启动客户端:redis-cli.exe 详细步骤：1234567891011121314151617181920212223242526272829303132333435# 安装gccyum install gcc# 把下载好的redis-5.0.3.tar.gz放在/usr/local文件夹下，并解压wget http://download.redis.io/releases/redis-5.0.3.tar.gztar xzf redis-5.0.3.tar.gzcd redis-5.0.3# 进入到解压好的redis-5.0.3目录下，进行编译与安装make# 修改配置daemonize yes # 后台启动protected-mode no # 关闭保护模式，若开启只有本机才可访问redis# bind 127.0.0.1 绑定机器网卡ip，若有多块网卡可配多个ip，代表允许客户端通过机器哪些网卡ip去访问，内网一般可不配置bind，注释掉即可# 启动服务src/redis-server redis.conf# 验证启动是否成功 ps -ef | grep redis # 进入redis客户端 src/redis-cli # 退出客户端quit# 退出redis服务pkill redis-server kill 进程号 src/redis-cli shutdown # 查看redis支持的最大连接数，在redis.conf文件中可修改，默认maxclients 10000CONFIG GET maxclients 简单运用:12set hero gareenget hero 就可以实现了向服务器设置 hero 这个键值，并从服务器获取hero对应的值","tags":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"Redis","slug":"Cloud/Redis","permalink":"http://example.com/categories/Cloud/Redis/"}]},{"title":"Redis基础","date":"2017-12-15T02:08:20.000Z","path":"blog/Cloud/Redis/Redis基础/","text":"什么是Redis： Redis是一个开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。 换句话说，Redis就像是一个HashMap，不过不是在JVM中运行，而是以一个独立进程的形式运行。 一般说来，会被当作缓存使用。 因为它比数据库(mysql)快，所以常用的数据，可以考虑放在这里，这样就提高了性能。 Redis是非关系型的键值对数据库，可根据键以O(1)时间复杂度取出或插入关联值，Redis数据是存在内存中，键值对中键可以是字符串、整型、浮点型等且键唯一。值的类型可以是string、list、hash、set、sorted set等。内置了复制、磁盘持久化、LUA脚本、事务、SSL、ACLs、客户端缓存、客户端代理等功能，通过哨兵模式和Cluster模式提供高可用。 Redis的速度非常的快，单机的Redis就可以支撑每秒10几万的并发，相对于MySQL来说，性能是MySQL的几十倍。 完全基于内存操作 C语言实现，优化过的数据结构，基于几种基础的数据结构，Redis做了大量的优化，性能极高 使用单线程，无上下文的切换成本 基于非阻塞的IO多路复用机制 常见命令5种数据类型： String（字符串） List（列表） Hash（字典） Set（集合） Sorted Set（有序集合） 不同的数据类型，有不同的命令方式:String 字符串： SET key value 设置key&#x3D;value GET key 获得键key对应的值 GETRANGE key start end 得到字符串的子字符串存放在一个键 GETSET key value 设置键的字符串值，并返回旧值 GETBIT key offset 返回存储在键位值的字符串值的偏移 MGET key1 [key2..] 得到所有的给定键的值 SETBIT key offset value 设置或清除该位在存储在键的字符串值偏移 SETEX key seconds value 键到期时设置值 SETNX key value 设置键的值，只有当该键不存在 SETRANGE key offset value 覆盖字符串的一部分从指定键的偏移 STRLEN key 得到存储在键的值的长度 MSET key value [key value…] 设置多个键和多个值 MSETNX key value [key value…] 设置多个键多个值，只有在当没有按键的存在时 PSETEX key milliseconds value 设置键的毫秒值和到期时间 INCR key 增加键的整数值一次 INCRBY key increment 由给定的数量递增键的整数值 INCRBYFLOAT key increment 由给定的数量递增键的浮点值 DECR key 递减键一次的整数值 DECRBY key decrement 由给定数目递减键的整数值 APPEND key value 追加值到一个键 DEL key 如果存在删除键 DUMP key 返回存储在指定键的值的序列化版本 EXISTS key 此命令检查该键是否存在 EXPIRE key seconds 指定键的过期时间 EXPIREAT key timestamp 指定的键过期时间。在这里，时间是在Unix时间戳格式 PEXPIRE key milliseconds 设置键以毫秒为单位到期 PEXPIREAT key milliseconds-timestamp 设置键在Unix时间戳指定为毫秒到期 KEYS pattern 查找与指定模式匹配的所有键 MOVE key db 移动键到另一个数据库 PERSIST key 移除过期的键 PTTL key 以毫秒为单位获取剩余时间的到期键。 TTL key 获取键到期的剩余时间。 RANDOMKEY 从Redis返回随机键 RENAME key newkey 更改键的名称 RENAMENX key newkey 重命名键，如果新的键不存在 TYPE key 返回存储在键的数据类型的值。 List 列表： BLPOP key1 [key2 ] timeout 取出并获取列表中的第一个元素，或阻塞，直到有可用 BRPOP key1 [key2 ] timeout 取出并获取列表中的最后一个元素，或阻塞，直到有可用 BRPOPLPUSH source destination timeout 从列表中弹出一个值，它推到另一个列表并返回它;或阻塞，直到有可用 LINDEX key index 从一个列表其索引获取对应的元素 LINSERT key BEFORE|AFTER pivot value 在列表中的其他元素之后或之前插入一个元素 LLEN key 获取列表的长度 LPOP key 获取并取出列表中的第一个元素 LPUSH key value1 [value2] 在前面加上一个或多个值的列表 LPUSHX key value 在前面加上一个值列表，仅当列表中存在 LRANGE key start stop 从一个列表获取各种元素 LREM key count value 从列表中删除元素 LSET key index value 在列表中的索引设置一个元素的值 LTRIM key start stop 修剪列表到指定的范围内 RPOP key 取出并获取列表中的最后一个元素 RPOPLPUSH source destination 删除最后一个元素的列表，将其附加到另一个列表并返回它 RPUSH key value1 [value2] 添加一个或多个值到列表 RPUSHX key value 添加一个值列表，仅当列表中存在 Hash 字典，哈希表： HDEL key field[field…] 删除对象的一个或几个属性域，不存在的属性将被忽略 HEXISTS key field 查看对象是否存在该属性域 HGET key field 获取对象中该field属性域的值 HGETALL key 获取对象的所有属性域和值 HINCRBY key field value 将该对象中指定域的值增加给定的value，原子自增操作，只能是integer的属性值可以使用 HINCRBYFLOAT key field increment 将该对象中指定域的值增加给定的浮点数 HKEYS key 获取对象的所有属性字段 HVALS key 获取对象的所有属性值 HLEN key 获取对象的所有属性字段的总数 HMGET key field[field…] 获取对象的一个或多个指定字段的值 HSET key field value 设置对象指定字段的值 HMSET key field value [field value …] 同时设置对象中一个或多个字段的值 HSETNX key field value 只在对象不存在指定的字段时才设置字段的值 HSTRLEN key field 返回对象指定field的value的字符串长度，如果该对象或者field不存在，返回0. HSCAN key cursor [MATCH pattern] [COUNT count] 类似SCAN命令 Set 集合： SADD key member [member …] 添加一个或者多个元素到集合(set)里 SCARD key 获取集合里面的元素数量 SDIFF key [key …] 获得队列不存在的元素 SDIFFSTORE destination key [key …] 获得队列不存在的元素，并存储在一个关键的结果集 SINTER key [key …] 获得两个集合的交集 SINTERSTORE destination key [key …] 获得两个集合的交集，并存储在一个集合中 SISMEMBER key member 确定一个给定的值是一个集合的成员 SMEMBERS key 获取集合里面的所有key SMOVE source destination member 移动集合里面的一个key到另一个集合 SPOP key [count] 获取并删除一个集合里面的元素 SRANDMEMBER key [count] 从集合里面随机获取一个元素 SREM key member [member …] 从集合里删除一个或多个元素，不存在的元素会被忽略 SUNION key [key …] 添加多个set元素 SUNIONSTORE destination key [key …] 合并set元素，并将结果存入新的set里面 SSCAN key cursor [MATCH pattern] [COUNT count] 迭代set里面的元素 Sorted Set 有序集合： ZADD key score1 member1 [score2 member2] 添加一个或多个成员到有序集合，或者如果它已经存在更新其分数 ZCARD key 得到的有序集合成员的数量 ZCOUNT key min max 计算一个有序集合成员与给定值范围内的分数 ZINCRBY key increment member 在有序集合增加成员的分数 ZINTERSTORE destination numkeys key [key …] 多重交叉排序集合，并存储生成一个新的键有序集合。 ZLEXCOUNT key min max 计算一个给定的字典范围之间的有序集合成员的数量 ZRANGE key start stop [WITHSCORES] 由索引返回一个成员范围的有序集合（从低到高） ZRANGEBYLEX key min max [LIMIT offset count]返回一个成员范围的有序集合（由字典范围） ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT] 返回有序集key中，所有 score 值介于 min 和 max 之间(包括等于 min 或 max )的成员，有序集成员按 score 值递增(从小到大)次序排列 ZRANK key member 确定成员的索引中有序集合 ZREM key member [member …] 从有序集合中删除一个或多个成员，不存在的成员将被忽略 ZREMRANGEBYLEX key min max 删除所有成员在给定的字典范围之间的有序集合 ZREMRANGEBYRANK key start stop 在给定的索引之内删除所有成员的有序集合 ZREMRANGEBYSCORE key min max 在给定的分数之内删除所有成员的有序集合 ZREVRANGE key start stop [WITHSCORES] 返回一个成员范围的有序集合，通过索引，以分数排序，从高分到低分 ZREVRANGEBYSCORE key max min [WITHSCORES] 返回一个成员范围的有序集合，以socre排序从高到低 ZREVRANK key member 确定一个有序集合成员的索引，以分数排序，从高分到低分 ZSCORE key member 获取给定成员相关联的分数在一个有序集合 ZUNIONSTORE destination numkeys key [key …] 添加多个集排序，所得排序集合存储在一个新的键 ZSCAN key cursor [MATCH pattern] [COUNT count] 增量迭代排序元素集和相关的分数 官方命令手册:如果还想查询每个命令的详细用法，请到redis官方命令手册： http://www.redis.cn/commands.html Redis备份策略 写crontab定时调度脚本，每小时都copy一份rdb或aof的备份到一个目录中去，仅仅保留最近48小时的备份； 每天都保留一份当日的数据备份到一个目录中去，可以保留最近1个月的备份，每次copy备份的时候，都把太旧的备份删除； 每天晚上将当前机器上的备份复制一份到其他机器上，以防机器损坏。 应用场景: 计数器：可对String进行自增自减运算从而实现计数器功能，这种内存型数据库读写性能非常高，很适合存储频繁读写的计数量 分布式ID生成：利用自增特性，一次请求一个大一点的步长如**incr 2000**，缓存在本地使用，用完再请求 海量数据统计：通过位图**bitmap存储是否参过某次活动，是否已读谋篇文章，用户是否为会员，日活统计** Session共享：可统一存储多台应用服务器会话信息，一个用户可请求任意一个应用服务器，从而更容易实现高可用性以及可伸缩性 分布式队列、阻塞队列：List双向链表可通过**lpush/rpush和rpop/lpop写入和读取消息，可通过使用brpop/blpop**来实现阻塞队列 分布式锁实现：使用Redis自带的**SETNX**命令实现分布式锁 热点数据存储：最新评论，最新文章列表，使用list存储，ltrim取出热点数据，删除老数据 社交类需求：可通过Set交集实现共同好友等功能，可通过Set求差集进行好友推荐、文章推荐 排行榜：**sorted_set**可实现有序性操作，从而实现排行榜等功能 延迟队列：通过**sorted_set使用当前时间戳 + 需要延迟的时长做score，消息内容作为元素，调用zadd来生产消息，消费者使用zrangbyscore获取当前时间之前的数据做轮询处理。消费完再删除任务rem key member**","tags":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"Redis","slug":"Cloud/Redis","permalink":"http://example.com/categories/Cloud/Redis/"}]},{"title":"Gateway源码分析","date":"2017-12-14T16:00:00.000Z","path":"blog/Cloud/Gateway源码分析/","text":"Gateway源码:网关作为流量的入口，常用的功能包括路由转发，权限校验，限流等，Spring Cloud Gateway是Spring Cloud官方推出的由**WebFlux + Netty + Reactor实现的响应式的第二代API网关**框架，定位于取代Netflix Zuul。 Spring Cloud Gateway的核心概念：路由Route、断言、过滤器。路由是网关中最基础的部分，路由信息包括一个ID、一个目的URI、一组断言工厂、一组Filter组成，若断言为真则说明请求的URL和配置的路由匹配；Spring Cloud Gateway中的断言函数类型是Spring5.0框架中的**ServerWebExchange，允许开发者去定义匹配Http Request中的任何信息，如请求头和参数等；Spring Cloud Gateway的过滤器分为GatewayFilIer和GlobalFilter，可对请求和响应进行处理**。 Spring Cloud Gateway工作原理跟Zuul的差不多，最大的区别就是Gateway的Filter只有**pre和post两种，客户端向Spring Cloud Gateway发出请求，若请求与网关定义的路由匹配，则该请求会被发送到网关Web处理程序，此时处理程序运行特定的请求过滤器链。过滤器之间用虚线分开的原因是过滤器可能会在发送代理请求的前后执行逻辑。所有pre过滤器逻辑先执行，然后执行代理请求；代理请求完成后执行post过滤器逻辑**。 Gateway对请求处理的核心逻辑是在**DispatcherHandler中，在DispatcherHandler中依次调用HandlerMapping、HandlerAdapter、HandlerResultHandler**三个核心接口 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class DispatcherHandler implements WebHandler, ApplicationContextAware &#123; public Mono&lt;Void&gt; handle(ServerWebExchange exchange) &#123; if (this.handlerMappings == null) &#123; return createNotFoundError(); &#125; return Flux.fromIterable(this.handlerMappings) .concatMap(mapping -&gt; mapping.getHandler(exchange)) // 获取具体的HandlerMapping，这里返回FilteringWebHandler .next() .switchIfEmpty(createNotFoundError()) // 若路由断言匹配未匹配到，则返回Empty，这里对Empty进行处理 .flatMap(handler -&gt; invokeHandler(exchange, handler)) // 调用具体的HandlerAdapter的handle .flatMap(result -&gt; handleResult(exchange, result)); &#125; private Mono&lt;HandlerResult&gt; invokeHandler(ServerWebExchange exchange, Object handler) &#123; if (this.handlerAdapters != null) &#123; for (HandlerAdapter handlerAdapter : this.handlerAdapters) &#123; if (handlerAdapter.supports(handler)) &#123; return handlerAdapter.handle(exchange, handler); &#125; &#125; &#125; return Mono.error(new IllegalStateException(&quot;No HandlerAdapter: &quot; + handler)); &#125; private Mono&lt;Void&gt; handleResult(ServerWebExchange exchange, HandlerResult result) &#123; return getResultHandler(result).handleResult(exchange, result) .checkpoint(&quot;Handler &quot; + result.getHandler() + &quot; [DispatcherHandler]&quot;) .onErrorResume(ex -&gt; result.applyExceptionHandler(ex).flatMap(exResult -&gt; &#123; String text = &quot;Exception handler &quot; + exResult.getHandler() + &quot;, error=\\&quot;&quot; + ex.getMessage() + &quot;\\&quot; [DispatcherHandler]&quot;; return getResultHandler(exResult).handleResult(exchange, exResult).checkpoint(text); &#125;)); &#125; private HandlerResultHandler getResultHandler(HandlerResult handlerResult) &#123; if (this.resultHandlers != null) &#123; for (HandlerResultHandler resultHandler : this.resultHandlers) &#123; if (resultHandler.supports(handlerResult)) &#123; return resultHandler; &#125; &#125; &#125; throw new IllegalStateException(&quot;No HandlerResultHandler for &quot; + handlerResult.getReturnValue()); &#125; private &lt;R&gt; Mono&lt;R&gt; createNotFoundError() &#123; return Mono.defer(() -&gt; &#123; Exception ex = new ResponseStatusException(HttpStatus.NOT_FOUND, &quot;No matching handler&quot;); return Mono.error(ex); &#125;); &#125;&#125; HandlerMappingHandlerMapping负责路径到Handler的映射，Gateway中RoutePredicateHandlerMapping实现了AbstractHandlerMapping，其作用是执行所有的Route的断言工厂PredicateFactory匹配路由信息，通过断言判断路由是否可用，且将路由信息绑定到请求上下文中，最终返回**FilteringWebHandler**。 也可自定义断言工厂需继承AbstractRoutePredicateFactory类重写apply方法的逻辑。在apply方法中可以通过exchange.getRequest()拿到ServerHttpRequest对象，从而可获取到请求的参数、请求方式、请求头等信息。 12345678910111213141516public abstract class AbstractHandlerMapping extends ApplicationObjectSupport implements HandlerMapping, Ordered, BeanNameAware &#123; public Mono&lt;Object&gt; getHandler(ServerWebExchange exchange) &#123; return getHandlerInternal(exchange).map(handler -&gt; &#123; ServerHttpRequest request = exchange.getRequest(); if (hasCorsConfigurationSource(handler) || CorsUtils.isPreFlightRequest(request)) &#123; // 处理跨域问题 CorsConfiguration config = (this.corsConfigurationSource != null ? this.corsConfigurationSource.getCorsConfiguration(exchange) : null); CorsConfiguration handlerConfig = getCorsConfiguration(handler, exchange); config = (config != null ? config.combine(handlerConfig) : handlerConfig); if (!this.corsProcessor.process(config, exchange) || CorsUtils.isPreFlightRequest(request)) &#123; return REQUEST_HANDLED_HANDLER; &#125; &#125; return handler; &#125;); &#125;&#125; 首先通过**lookupRoute方法找出所有与当前请求匹配的Route，在匹配之前从RouteLocator的实现类CachingRouteLocator中已经转换好的Route，在应用启动时会通过RouteLocator的实现类RouteDefinitionRouteLocator通过PropertiesRouteDefinitionLocator从GatewayProperties中读取路由配置RouteDefinition且将其转换为Route并缓存到CachingRouteLocator中。除此之外若在DiscoveryClientRouteDefinitionLocator会获取集群中所有的实例并将其构建成RouteDefinition，最终转换并合并到CachingRouteLocator**中。 在**lookupRoute中通过遍历所有的Route，并遍历调用其具体的PredicateFactory的test方法，过滤出其test方法放回true的route。然后将匹配的路由绑定到请求上下文中。最终返回FilteringWebHandler** 1234567891011121314151617181920212223242526public class RoutePredicateHandlerMapping extends AbstractHandlerMapping &#123; protected Mono&lt;?&gt; getHandlerInternal(ServerWebExchange exchange) &#123; if (this.managementPortType == DIFFERENT &amp;&amp; this.managementPort != null &amp;&amp; exchange.getRequest().getURI().getPort() == this.managementPort) &#123; return Mono.empty(); &#125; exchange.getAttributes().put(GATEWAY_HANDLER_MAPPER_ATTR, getSimpleName()); return lookupRoute(exchange).flatMap((Function&lt;Route, Mono&lt;?&gt;&gt;) r -&gt; &#123; exchange.getAttributes().remove(GATEWAY_PREDICATE_ROUTE_ATTR); exchange.getAttributes().put(GATEWAY_ROUTE_ATTR, r); // 将匹配的路由绑定到请求上下文中，以便FilteringWebHandler的handle方法中使用 return Mono.just(webHandler); // 最终返回FilteringWebHandler &#125;).switchIfEmpty(Mono.empty().then(Mono.fromRunnable(() -&gt; &#123; // 未找到匹配的路由 exchange.getAttributes().remove(GATEWAY_PREDICATE_ROUTE_ATTR); &#125;))); &#125; protected Mono&lt;Route&gt; lookupRoute(ServerWebExchange exchange) &#123; return this.routeLocator.getRoutes().concatMap(route -&gt; Mono.just(route).filterWhen(r -&gt; &#123; exchange.getAttributes().put(GATEWAY_PREDICATE_ROUTE_ATTR, r.getId()); return r.getPredicate().apply(exchange); // 调用具体的PredicateFactory的test方法，过滤出test方法放回true的route &#125;).doOnError(e -&gt; logger.error(&quot;Error applying predicate for route: &quot; + route.getId(), e)).onErrorResume(e -&gt; Mono.empty())) .next() .map(route -&gt; &#123; validateRoute(route, exchange); return route; &#125;); &#125;&#125; HandlerAdapter调用具体的**HandlerAdapter的调用，在DelegatingWebFluxConfiguration配置类的超类WebFluxConfigurationSupport中注入了SimpleHandlerAdapter。而FilteringWebHandler是WebHandler的子类。在SimpleHandlerAdapter的handle方法中调用FilteringWebHandler的handle方法。由于SimpleHandlerAdapter返回的是Mono.empty()故不会触发handleResult**方法。 123456789101112public class SimpleHandlerAdapter implements HandlerAdapter &#123; @Override public boolean supports(Object handler) &#123; return WebHandler.class.isAssignableFrom(handler.getClass()); &#125; @Override public Mono&lt;HandlerResult&gt; handle(ServerWebExchange exchange, Object handler) &#123; WebHandler webHandler = (WebHandler) handler; Mono&lt;Void&gt; mono = webHandler.handle(exchange); return mono.then(Mono.empty()); &#125;&#125; 在**GatewayAutoConfiguration配置类中注入了FilteringWebHandler，由于全局的过滤器GlobalFilter与GatewayFilter故在其构造方法中通过适配器模式将GlobalFilter转换成了GatewayFilter。然后通过责任链模式挨个调用GatewayFilter的filter**方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960@Configuration(proxyBeanMethods = false)@ConditionalOnProperty(name = &quot;spring.cloud.gateway.enabled&quot;, matchIfMissing = true)@EnableConfigurationProperties@AutoConfigureBefore(&#123; HttpHandlerAutoConfiguration.class, WebFluxAutoConfiguration.class &#125;)@AutoConfigureAfter(&#123; GatewayLoadBalancerClientAutoConfiguration.class, GatewayClassPathWarningAutoConfiguration.class &#125;)@ConditionalOnClass(DispatcherHandler.class)public class GatewayAutoConfiguration &#123; public FilteringWebHandler filteringWebHandler(List&lt;GlobalFilter&gt; globalFilters) &#123; return new FilteringWebHandler(globalFilters); &#125;&#125;public class FilteringWebHandler implements WebHandler &#123; private final List&lt;GatewayFilter&gt; globalFilters; public FilteringWebHandler(List&lt;GlobalFilter&gt; globalFilters) &#123; this.globalFilters = loadFilters(globalFilters);// 通过适配器模式将GlobalFilter转换为GatewayFilter &#125; private static List&lt;GatewayFilter&gt; loadFilters(List&lt;GlobalFilter&gt; filters) &#123; return filters.stream().map(filter -&gt; &#123; GatewayFilterAdapter gatewayFilter = new GatewayFilterAdapter(filter); if (filter instanceof Ordered) &#123; int order = ((Ordered) filter).getOrder(); return new OrderedGatewayFilter(gatewayFilter, order); &#125; return gatewayFilter; &#125;).collect(Collectors.toList()); &#125; public Mono&lt;Void&gt; handle(ServerWebExchange exchange) &#123; Route route = exchange.getRequiredAttribute(GATEWAY_ROUTE_ATTR); // 从请求上下文中取出前面绑定的Route List&lt;GatewayFilter&gt; gatewayFilters = route.getFilters(); // 获取Route中配置的filters List&lt;GatewayFilter&gt; combined = new ArrayList&lt;&gt;(this.globalFilters); combined.addAll(gatewayFilters); // 合并配置的filters和自动注入的全局的filters AnnotationAwareOrderComparator.sort(combined); // 对GatewayFilter列表排序 return new DefaultGatewayFilterChain(combined).filter(exchange); &#125;&#125;private static class DefaultGatewayFilterChain implements GatewayFilterChain &#123; private final int index; private final List&lt;GatewayFilter&gt; filters; DefaultGatewayFilterChain(List&lt;GatewayFilter&gt; filters) &#123; this.filters = filters; this.index = 0; &#125; private DefaultGatewayFilterChain(DefaultGatewayFilterChain parent, int index) &#123; this.filters = parent.getFilters(); this.index = index; &#125; public Mono&lt;Void&gt; filter(ServerWebExchange exchange) &#123; return Mono.defer(() -&gt; &#123; if (this.index &lt; filters.size()) &#123; GatewayFilter filter = filters.get(this.index); DefaultGatewayFilterChain chain = new DefaultGatewayFilterChain(this, this.index + 1); return filter.filter(exchange, chain); &#125; else &#123; return Mono.empty(); // complete &#125; &#125;); &#125;&#125; 也可自定义**GatewayFilter，自定义GatewayFilter是通过自定义过滤器工厂来完成的，自定义工厂可集成一些列的AbstractGatewayFilterFactory来完成响应的功能，还可通过实现GlobalFilter来自定义全局的过滤器。对于uri支持lb://的方式类配置目标微服务的请求地址，就是通过LoadBalancerClientFilter**过滤器来完成的。 123456789101112131415161718192021222324252627282930313233343536373839public class LoadBalancerClientFilter implements GlobalFilter, Ordered &#123; public static final int LOAD_BALANCER_CLIENT_FILTER_ORDER = 10100; protected final LoadBalancerClient loadBalancer; private LoadBalancerProperties properties; public LoadBalancerClientFilter(LoadBalancerClient loadBalancer, LoadBalancerProperties properties) &#123; this.loadBalancer = loadBalancer; this.properties = properties; &#125; public int getOrder() &#123; return LOAD_BALANCER_CLIENT_FILTER_ORDER; &#125; @Override @SuppressWarnings(&quot;Duplicates&quot;) public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; URI url = exchange.getAttribute(GATEWAY_REQUEST_URL_ATTR); String schemePrefix = exchange.getAttribute(GATEWAY_SCHEME_PREFIX_ATTR); if (url == null || (!&quot;lb&quot;.equals(url.getScheme()) &amp;&amp; !&quot;lb&quot;.equals(schemePrefix))) &#123; return chain.filter(exchange); &#125; addOriginalRequestUrl(exchange, url); final ServiceInstance instance = choose(exchange); if (instance == null) &#123; throw NotFoundException.create(properties.isUse404(), &quot;Unable to find instance for &quot; + url.getHost()); &#125; URI uri = exchange.getRequest().getURI(); String overrideScheme = instance.isSecure() ? &quot;https&quot; : &quot;http&quot;; if (schemePrefix != null) &#123; overrideScheme = url.getScheme(); &#125; URI requestUrl = loadBalancer.reconstructURI(new DelegatingServiceInstance(instance, overrideScheme), uri); exchange.getAttributes().put(GATEWAY_REQUEST_URL_ATTR, requestUrl); return chain.filter(exchange); &#125; protected ServiceInstance choose(ServerWebExchange exchange) &#123; // 通过负载均衡算法获取具体的实例对象 return loadBalancer.choose(((URI) exchange.getAttribute(GATEWAY_REQUEST_URL_ATTR)).getHost()); &#125;&#125;","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"}]},{"title":"Welcome TaoLiu's Blog","date":"2016-03-24T07:21:55.000Z","path":"blog/index/","text":"Welcome TaoLiu’s Blog","tags":[],"categories":[]},{"title":"Hello hexo","date":"2016-03-12T04:08:20.000Z","path":"blog/hello-hexo/","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","tags":[],"categories":[]},{"title":"访问者模式","date":"2016-01-04T05:50:20.000Z","path":"blog/设计模式/行为型模式/访问者模式/","text":"访问者模式是一种集中规整模式，特别适用于大规模重构的项目，通过访问者模式可以很容易把一些功能进行梳理。还可以与其他模式混编建立一套自己的过滤器或者拦截器。 访问者模式是对迭代器模式的扩充，可以遍历不同的对象，然后执行不同的操作，也就是针对访问的对象不同， 执行不同的操作。 访问者模式还可以充当**拦截器Interceptor**角色 。 访问者模式能把处理方法从数据结构中分离出来，并可以根据需要增加新的处理方法，且不用修改原来的程序代码与数据结构，这提高了程序的扩展性和灵活性。 定义封装一些作用于某种数据结构中的各元素的操作，它可以在不改变数据结构的前提下定义作用于这些元素的新的操作。 将作用于某种数据结构中的各元素的操作分离出来封装成独立的类，使其在不改变数据结构的前提下可以添加作用于这些元素的新的操作，为数据结构中的每个元素提供多种访问方式。它将对数据的操作与数据结构进行分离，是行为类模式中最复杂的一种模式。 实现抽象访问者Visitor：定义一个访问具体元素的接口，为每个具体元素类对应一个访问操作**visit()** ，该操作中的参数类型标识了被访问的具体元素。 1234public interface Visitor &#123; void visit(ConcreteElementA element); void visit(ConcreteElementB element);&#125; **具体访问者角色ConcreteVisitor**：实现抽象访问者角色中声明的各个访问操作，确定访问者访问一个元素时的具体功能。 1234567891011121314151617181920212223public class ConcreteVisitorA implements Visitor &#123; @Override public void visit(ConcreteElementA element) &#123; System.out.println(&quot;具体访问者A访问--&gt;&quot; + element.operationA()); &#125; @Override public void visit(ConcreteElementB element) &#123; System.out.println(&quot;具体访问者A访问--&gt;&quot; + element.operationB()); &#125;&#125;public class ConcreteVisitorB implements Visitor &#123; @Override public void visit(ConcreteElementA element) &#123; System.out.println(&quot;具体访问者B访问--&gt;&quot; + element.operationA()); &#125; @Override public void visit(ConcreteElementB element) &#123; System.out.println(&quot;具体访问者B访问--&gt;&quot; + element.operationB()); &#125;&#125; **抽象元素角色Element：声明一个包含接受操作accept()**的接口，被接受的访问者对象作为accept()方法的参数。 123public interface Element &#123; void accept(Visitor visitor);&#125; 具体元素角色ConcreteElement：实现抽象元素角色提供的 accept() 操作，其方法体通常都是visitor.visit(this)，另外具体元素中可能还包含本身业务逻辑的相关操作。 123456789101112131415161718192021public class ConcreteElementA implements Element &#123; @Override public void accept(Visitor visitor) &#123; visitor.visit(this); &#125; public String operationA() &#123; return &quot;具体元素A的操作。&quot;; &#125;&#125;public class ConcreteElementB implements Element &#123; @Override public void accept(Visitor visitor) &#123; visitor.visit(this); &#125; public String operationB() &#123; return &quot;具体元素B的操作。&quot;; &#125;&#125; 对象结构角色ObjectStructure：是一个包含元素角色的容器，提供让访问者对象遍历容器中的所有元素的方法，通常由 List、Set、Map 等聚合类实现。 12345678910111213141516171819202122232425262728public class ObjectStructure &#123; private List&lt;Element&gt; list = new ArrayList&lt;Element&gt;(); public void accept(Visitor visitor) &#123; for (Element element : list) &#123; element.accept(visitor); &#125; &#125; public void add(Element element) &#123; list.add(element); &#125; public void remove(Element element) &#123; list.remove(element); &#125; public static void main(String[] args) &#123; ObjectStructure os = new ObjectStructure(); os.add(new ConcreteElementA()); os.add(new ConcreteElementB()); Visitor visitor = new ConcreteVisitorA(); os.accept(visitor); System.out.println(&quot;------------------------&quot;); visitor = new ConcreteVisitorB(); os.accept(visitor); &#125;&#125; 优点 扩展性好：能够在不修改对象结构中的元素的情况下，为对象结构中的元素添加新的功能。 复用性好：可以通过访问者来定义整个对象结构通用的功能，从而提高系统的复用程度。 灵活性好：访问者模式将数据结构与作用于结构上的操作解耦，使得操作集合可相对自由地演化而不影响系统的数据结构。 符合单一职责原则：访问者模式把相关行为封装在一起构成一个访问者，使每个访问者功能都比较单一。 缺点 增加新的元素类很困难：每增加一个新的元素类，都要在每个具体访问者类中增加相应的具体操作，违背开闭原则。 破坏封装：具体元素对访问者公布细节，这破坏了对象的封装性。 违反了依赖倒置原则：访问者模式依赖了具体类，而没有依赖抽象类。 应用 需要对一个对象结构中的对象进行很多不同并且不相关的操作，而你想避免让这些操作污染这些对象的类 数据元素相对稳定而访问方式多种多样的数据结构 对象结构相对稳定，但其操作算法经常变化的程序。 对象结构中的对象需要提供多种不同且不相关的操作，而且要避免让这些操作的变化影响对象的结构。 对象结构包含很多类型的对象，希望对这些对象实施一些依赖于其具体类型的操作。 扩展 统计功能：数据统计和报表的批处理通过访问者模式来处理会比较简单 多个访问者：用于展示的访问者和用于汇总的访问者","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"行为型模式","slug":"设计模式/行为型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"迭代器模式","date":"2016-01-04T05:50:20.000Z","path":"blog/设计模式/行为型模式/迭代器模式/","text":"从JDK1.2开始增加java.util.Iterator接口， 并逐步把Iterator应用到各个Collection聚集类中，Collection、List、Set、Map 等都包含了迭代器 。正因为把迭代器模式已经融入到基本API中了，再去写迭代器， 就有点多余，所以迭代器模式没落了，基本上没人会单独写一个迭代器。 迭代器模式提供了遍历容器的方便性，容器只要管理增减元素就可以了，需要遍历时交由迭代器进行。 定义提供一种方法访问一个容器对象中各个元素，而又不暴露该对象的内部细节。 实现迭代器模式是通过将聚合对象的遍历行为分离出来，抽象成迭代器类来实现的，其目的是在不暴露聚合对象的内部结构的情况下，让外部代码透明地访问聚合的内部数据。 Iterator抽象迭代器，定义访问和遍历聚合元素的接口，通常包含hasNext()、first()、next()等方法 。 12345interface Iterator &#123; Object first(); Object next(); boolean hasNext();&#125; ConcreteIterator具体迭代器，实现抽象迭代器接口中所定义的方法，完成对聚合对象的遍历，记录遍历的当前位置。 1234567891011121314151617181920212223242526public class ConcreteIterator implements Iterator &#123; private List&lt;Object&gt; list = null; private int index = -1; public ConcreteIterator(List&lt;Object&gt; list) &#123; this.list = list; &#125; public boolean hasNext() &#123; if (index &lt; list.size() - 1) &#123; return true; &#125; else &#123; return false; &#125; &#125; public Object first() &#123; index = 0; Object obj = list.get(index); return obj; &#125; public Object next() &#123; Object obj = null; if (this.hasNext()) &#123; obj = list.get(++index); &#125; return obj; &#125;&#125; Aggregate抽象容器，定义存储、添加、删除聚合对象以及创建迭代器对象的接口。 12345public interface Aggregate &#123; public void add(Object obj); public void remove(Object obj); public Iterator getIterator();&#125; ConcreteAggregate具体容器 ，实现抽象聚合类，返回一个具体迭代器的实例。 123456789101112public class ConcreteAggregate implements Aggregate &#123; private List&lt;Object&gt; list = new ArrayList&lt;Object&gt;(); public void add(Object obj) &#123; list.add(obj); &#125; public void remove(Object obj) &#123; list.remove(obj); &#125; public Iterator getIterator() &#123; return (new ConcreteIterator(list)); &#125;&#125; 客户端调用 12345678910111213public static void main(String[] args) &#123; Aggregate ag = new ConcreteAggregate(); ag.add(&quot;中山大学&quot;); ag.add(&quot;华南理工&quot;); ag.add(&quot;西华大学&quot;); Iterator it = ag.getIterator(); while (it.hasNext()) &#123; Object ob = it.next(); System.out.print(ob.toString() + &quot;\\t&quot;); &#125; Object ob = it.first(); System.out.println(&quot;\\nFirst：&quot; + ob.toString());&#125; 优点 访问一个聚合对象的内容而无须暴露它的内部表示 遍历任务交由迭代器完成，这简化了聚合类 它支持以不同方式遍历一个聚合，甚至可以自定义迭代器的子类以支持新的遍历 增加新的聚合类和迭代器类都很方便，无须修改原有代码 封装性良好，为遍历不同的聚合结构提供一个统一的接口 缺点 增加了类的个数，这在一定程度上增加了系统的复杂性 应用当需要为聚合对象提供多种遍历方式时；当需要为遍历不同的聚合结构提供一个统一的接口时。当访问一个聚合对象的内容而无须暴露其内部细节的表示时。 迭代器模式常常与组合模式结合起来使用，在对组合模式中的容器构件进行访问时，经常将迭代器潜藏在组合模式的容器构成类中。","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"行为型模式","slug":"设计模式/行为型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"责任链模式","date":"2016-01-04T05:40:20.000Z","path":"blog/设计模式/行为型模式/责任链模式/","text":"定义：使多个对象都有机会处理请求，从而避免了请求的发送者和接受者之间的耦合关系。将这些对象连成一条链，并沿着这条链传递该请求，直到有对象处理它为止。 责任链模式的关键是在链上，链是由多个处理者ConcreteHandler组成，由一条链去处理相似的请求在链中决定谁来处理这个请求，并返回相应结果。 实现抽象处理者角色，定义一个处理请求的接口，包含抽象处理方法和一个后继连接，融合了模板方法模式。 123456789101112131415161718192021public abstract class AbstractChainHandler&lt;T&gt; &#123; private AbstractChainHandler next; protected abstract &lt;T&gt; T doHandler(Object... obj); protected abstract &lt;T&gt; boolean isAccordWith(T t); public &lt;T&gt; T handler(Object... obj) &#123; T result = doHandler(obj); if (!isAccordWith(result) &amp;&amp; next != null) &#123; return (T) next.handler(obj); &#125; else &#123; return result; &#125; &#125; public void setNext(AbstractChainHandler next) &#123; this.next = next; &#125;&#125; 具体处理者角色，实现抽象处理者的处理方法，判断能否处理本次请求，如果可以处理请求则处理，否则将该请求转给它的后继者。 12345678910111213141516171819202122232425public class ConcreteChainHandler1&lt;T&gt; extends AbstractChainHandler&lt;T&gt; &#123; protected &lt;T&gt; T doHandler(Object... obj) &#123; // 具体业务逻辑 return null; &#125; @Override protected &lt;T1&gt; boolean isAccordWith(T1 t1) &#123; // 根据具体业务逻辑判断返回true还是false return false; &#125;&#125;public class ConcreteChainHandler2&lt;T&gt; extends AbstractChainHandler&lt;T&gt; &#123; protected &lt;T&gt; T doHandler(Object... obj) &#123; // 具体业务逻辑 return null; &#125; @Override protected &lt;T1&gt; boolean isAccordWith(T1 t1) &#123; // 根据具体业务逻辑判断返回true还是false return false; &#125;&#125; 客户类角色，创建处理链，并向链头的具体处理者对象提交请求，它不关心处理细节和请求的传递过程。 123456public static void main(String[] args) &#123; AbstractChainHandler h1 = new ConcreteChainHandler1(); AbstractChainHandler h2 = new ConcreteChainHandler2(); h1.setNext(h2); h1.handler(new Object[]&#123;&#125;);&#125; 责任链模式的本质是解耦请求与处理，让请求在处理链中能进行传递与被处理；独到之处是将其节点处理者组合成了链式结构，并允许节点自身决定是否进行请求处理或转发，相当于让请求流动起来。 优点只需要将请求发送到责任链上即可，无须关心请求的处理细节和请求的传递过程，请求会自动进行传递。所以责任链将请求的发送者和请求的处理者解耦了。 降低了对象之间的耦合度，对象无须知道到底是哪一个对象处理其请求以及链的结构，发送者和接收者也无须拥有对方的明确信息 增强了系统的可扩展性，可以根据需要增加新的请求处理类 增强了给对象指派职责的灵活性，当工作流程发生变化，可以动态地改变链内的成员或者调动它们的次序，也可动态地新增或者删除责任 简化了对象之间的连接，每个对象只需保持一个指向其后继者的引用，不需保持其他所有处理者的引用，这避免了使用众多的 if 或者 if···else 语句。 责任分担，每个类只需要处理自己该处理的工作 缺点 不能保证每个请求一定被处理，没有明确的接收者，所以不能保证它一定会被处理，该请求可能一直传到链的末端都得不到处理 对比较长的职责链，请求的处理可能涉及多个处理对象，系统性能将受到一定影响 职责链建立的合理性要靠客户端来保证，增加了客户端的复杂性，可能会由于职责链的错误设置而导致系统出错，如可能会造成循环调用 应用场景过滤器链的实现，Spring中的拦截器链 多个对象可以处理一个请求，但具体由哪个对象处理该请求在运行时自动确定。 可动态指定一组对象处理请求，或添加新的处理者 需要在不明确指定请求处理者的情况下，向多个处理者中的一个提交请求","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"行为型模式","slug":"设计模式/行为型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"观察者模式","date":"2016-01-04T05:30:20.000Z","path":"blog/设计模式/行为型模式/观察者模式/","text":"实现观察者模式时要注意具体目标对象和具体观察者对象之间不能直接调用，否则将使两者之间紧密耦合起来，这违反了面向对象的设计原则。 定义定义对象间一种一对多的依赖关系，使得每当一个对象改变状态，则所有依赖于它的对象都会得到通知并被自动更新。 实现Subject被观察者，定义被观察者的实现职责，必须能够动态的增加、取消观察者，一般是抽象类或者实现类，仅仅完成作为被观察者必须实现的职责：管理观察者并通知观察者。 123456789101112131415161718public abstract class Subject &#123; //定义一个观察者数组 private Vector&lt;Observer&gt; obsVector = new Vector&lt;Observer&gt;(); //增加一个观察者 public void addObserver(Observer o)&#123; this.obsVector.add(o); &#125; //删除一个观察者 public void delObserver(Observer o)&#123; this.obsVector.remove(o); &#125; //通知所有观察者 public void notifyObservers()&#123; for(Observer o:this.obsVector)&#123; o.update(); &#125; &#125;&#125; Observer观察者，观察者接收到消息后，对消息进行处理。 123public interface Observer &#123; void update();&#125; ConcreteSubject具体的被观察者，定义被观察者自己的业务逻辑，同时定义对哪些事件进行通知。 1234567public class ConcreteSubject extends Subject &#123; //具体的业务 public void doSomething()&#123; System.out.println(&quot;do something&quot;); super.notifyObservers(); &#125;&#125; ConcreteObserver具体的观察者，每个观察者接收到消息后的处理逻辑是不一样的。 123456public class ConcreteObserver implements Observer &#123; @Override public void update() &#123; System.out.println(&quot;接收到信息， 并进行处理！ &quot;); &#125;&#125; 客户端使用 12345678910public static void main(String[] args) &#123; //创建一个被观察者 ConcreteSubject subject = new ConcreteSubject(); //定义一个观察者 Observer obs= new ConcreteObserver(); //观察者观察被观察者 subject.addObserver(obs); //观察者开始活动了 subject.doSomething();&#125; 优点 降低了目标与观察者之间的耦合关系，两者之间是抽象耦合关系。符合依赖倒置原则。 目标与观察者之间建立了一套触发机制。形成了一个触发链。 观察者模式可以完美地实现这里的链条形式。 缺点 目标与观察者之间的依赖关系并没有完全解除，而且有可能出现循环引用。 观察者对象很多时，开发和调试就会比较复杂，通知的发布会花费很多时间，影响程序的效率，且一个观察者卡壳，会影响整体的执行效率；在这种情况下，一般考虑采用异步的方式。 应用在软件系统中，当系统一方行为依赖另一方行为的变动时，可使用观察者模式松耦合联动双方，使得一方的变动可以通知到感兴趣的另一方对象，从而让另一方对象对此做出响应。 对象间存在一对多关系，一个对象的状态发生改变会影响其他对象。 当一个抽象模型有两个方面，其中一个方面依赖于另一方面时，可将这二者封装在独立的对象中以使它们可以各自独立地改变和复用。 实现类似广播机制的功能，不需要知道具体收听者，只需分发广播，系统中感兴趣的对象会自动接收该广播。 多层级嵌套使用，形成一种链式触发机制，使得事件具备跨域（跨越两种观察者类型）通知。 注意广播链的问题，一个观察者可以有双重身份，既是观察者，也是被观察者，链一旦建立，逻辑就比较复杂，可维护性非常差，根据经验建议，在一个观察者模式中最多出现一个对象既是观察者也是被观察者，也就是说消息最多转发一次（传递两次），这还是比较好控制的。 它和责任链模式的最大区别就是观察者广播链在传播的过程中消息是随时更改的，它是由相邻的两个节点协商的消息结构；而责任链模式在消息传递过程中基本上保持消息不可变，如果要改变，也只是在原有的消息上进行修正。 异步处理问题，被观察者发生动作，观察者要做出回应，如果观察者比较多，而且处理时间比较长，就用异步处理，异步处理就要考虑线程安全和队列的问题。 扩展Java提供了**java.util.Observable类和java.util.Observer**接口定义了观察者模式，只要实现它们的子类就可以编写观察者模式实例。 Observable类是抽象目标类，它有一个 Vector 向量，用于保存所有要通知的观察者对象； 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class Observable &#123; // 内部标志位，注明目标对象发生了变化,为true时，notifyObservers()才会通知观察者 private boolean changed = false; private Vector&lt;Observer&gt; obs; public Observable() &#123; obs = new Vector&lt;&gt;(); &#125; public synchronized void addObserver(Observer o) &#123; if (o == null) throw new NullPointerException(); if (!obs.contains(o)) &#123; obs.addElement(o); &#125; &#125; public synchronized void deleteObserver(Observer o) &#123; obs.removeElement(o); &#125; public void notifyObservers() &#123; notifyObservers(null); &#125; public void notifyObservers(Object arg) &#123; Object[] arrLocal; synchronized (this) &#123; if (!changed) return; arrLocal = obs.toArray(); clearChanged(); &#125; for (int i = arrLocal.length-1; i&gt;=0; i--) ((Observer)arrLocal[i]).update(this, arg); &#125; public synchronized void deleteObservers() &#123; obs.removeAllElements(); &#125; protected synchronized void setChanged() &#123; changed = true; &#125; protected synchronized void clearChanged() &#123; changed = false; &#125; public synchronized boolean hasChanged() &#123; return changed; &#125; public synchronized int countObservers() &#123; return obs.size(); &#125;&#125; Observer接口是抽象观察者，它监视目标对象的变化，当目标对象发生变化时，观察者得到通知，并调用**void update(Observable o,Object arg)**方法，进行相应的工作。 123public interface Observer &#123; void update(Observable o, Object arg);&#125; 利用Observable类和Observer接口实现观察者模式实例 1234567891011121314151617181920212223242526public class ConcreteSubject extends Observable &#123; public void doSomething()&#123; System.out.println(&quot;do something&quot;); // 设置内部标志位，注明数据发生变化 super.setChanged(); super.notifyObservers(&quot;msg&quot;); &#125;&#125;public class ConcreteObserver implements Observer &#123; @Override public void update(Observable o, Object arg) &#123; System.out.println(&quot;接收到信息：&quot; + arg); &#125;&#125;public static void main(String[] args) &#123; //创建一个被观察者 ConcreteSubject subject = new ConcreteSubject(); //定义一个观察者 Observer obs= new ConcreteObserver(); //观察者观察被观察者 subject.addObserver(obs); //观察者开始活动了 subject.doSomething();&#125;","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"行为型模式","slug":"设计模式/行为型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"策略模式","date":"2016-01-04T05:20:20.000Z","path":"blog/设计模式/行为型模式/策略模式/","text":"当实现某一个功能存在多种算法或者策略，可以根据环境或者条件的不同选择不同的算法或者策略来完成该功能。 如果使用多重条件转移语句实现即硬编码，不但使条件语句变得很复杂，而且增加、删除或更换算法要修改原代码，不易维护，违背开闭原则。采用策略模式就能很好解决该问题。 定义定义一系列算法，并将每个算法封装起来，使它们可以相互替换，且算法的变化不会影响使用算法的客户。 实现策略模式是准备一组算法，并将这组算法封装到一系列的策略类里面，作为一个抽象策略类的子类。策略模式的重心不是如何实现算法，而是如何组织这些算法，从而让程序结构更加灵活，具有更好的维护性和扩展性。 Strategy抽象策略类定义一个公共接口，各种不同算法以不同方式实现该接口，环境角色使用该接口调用不同的算法 123public interface Strategy &#123; void strategy();&#125; ConcreteStrategy具体策略类，实现了抽象策略定义的接口，提供具体的算法实现 12345678910111213public class ConcreteStrategyA implements Strategy &#123; @Override public void strategy() &#123; System.out.println(&quot;具体策略A的策略方法被访问！&quot;); &#125;&#125;public class ConcreteStrategyB implements Strategy &#123; @Override public void strategy() &#123; System.out.println(&quot;具体策略B的策略方法被访问！&quot;); &#125;&#125; Context环境类，持有一个策略类的引用，最终给客户端调用 1234567891011public class Context &#123; private Strategy strategy; public void setStrategy(Strategy strategy) &#123; this.strategy = strategy; &#125; public void strategy() &#123; this.strategy.strategy(); &#125;&#125; 客户端使用 123456789public static void main(String[] args) &#123; Context c = new Context(); Strategy strategyA = new ConcreteStrategyA(); c.setStrategy(strategyA); c.strategy(); Strategy strategyB = new ConcreteStrategyB(); c.setStrategy(strategyB); c.strategy();&#125; 如果一个策略家族的具体策略数量超过4个，则需要考虑使用混合模式，解决策略类膨胀和对外暴露的问题。 优点 多重条件语句不易维护，而使用策略模式可以避免使用多重条件语句 策略模式提供了一系列的可供重用的算法族，恰当使用继承可以把算法族的公共代码转移到父类里面，从而避免重复的代码 自由切换，策略模式可以提供相同行为的不同实现，客户可以根据不同时间或空间要求选择不同的 策略模式提供了对开闭原则的完美支持，可以在不修改原代码的情况下，灵活增加新算法 策略模式把算法的使用放到环境类中，而算法的实现移到具体策略类中，实现了二者的分离 缺点 会造成很多的策略类，增加维护难度 所有策略类都需要对外暴露，上层模块必须知道有哪些策略，才能决定使用哪个策略，与迪米特法则相违背 应用 多个类只有在算法或行为上稍有不同的场景 算法需要自由切换的场景 需要屏蔽算法规则的场景 扩展策略枚举，把原有定义在抽象策略中的方法移植到枚举中，每个枚举成员就成为一个具体策略 。略枚举是一个非常优秀和方便的模式，但是它受枚举类型的限制，每个枚举项都是public、final、static的，扩展性受到了一定的约束，因此在系统开发中，策略枚举一般担当不经常发生变化的角色。 1234567891011121314151617181920212223242526public enum StrategyEnum &#123; ADD(&quot;+&quot;)&#123; public int exec(int a,int b)&#123; return a + b; &#125; &#125;, SUB(&quot;-&quot;)&#123; public int exec(int a,int b)&#123; return a - b; &#125; &#125;; String value; private StrategyEnum(String _value)&#123; this.value = _value; &#125; public String getValue()&#123; return this.value; &#125; public abstract int exec(int a,int b);&#125;public static void main(String[] args) &#123; int a = Integer.parseInt(args[0]); int b = Integer.parseInt(args[2]); System.out.println(&quot;运行结果为： &quot; + StrategyEnum.ADD.exec(a, b));&#125;","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"行为型模式","slug":"设计模式/行为型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"中介者模式","date":"2016-01-04T05:10:20.000Z","path":"blog/设计模式/行为型模式/中介者模式/","text":"常常会出现好多对象之间存在复杂的交互关系，这种交互关系常常是网状结构，它要求每个对象都必须知道它需要交互的对象。若把这种网状结构改为星形结构的话，将大大降低它们之间的耦合性，这时只要找一个中介者就可以了。 定义一个中介对象来封装一系列对象之间的交互，中介者使各对象不需要显示地相互作用 ，使原有对象之间的耦合松散，且可以独立地改变它们之间的交互。中介者模式又叫调停模式，它是迪米特法则的典型应用。 实现中介者模式由抽象中介者、具体中介者、抽象同事、具体同事几个主要角色。 抽象中介者：定义统一的接口， 用于各同事角色之间的通信 12345678910@Datapublic abstract class Mediator &#123; //定义同事类 protected ConcreteColleague1 c1; protected ConcreteColleague2 c2; //中介者模式的业务逻辑 public abstract void doSomething1(); public abstract void doSomething2();&#125; 具体中介者：通过协调各同事角色实现协作行为， 因此它必须依赖于各个同事角色 12345678910111213public class ConcreteMediator extends Mediator &#123; @Override public void doSomething1() &#123; super.c1.selfMethod1(); super.c2.selfMethod2(); &#125; @Override public void doSomething2() &#123; super.c1.selfMethod1(); super.c2.selfMethod2(); &#125;&#125; 抽象同事类：定义同事类的接口，保存中介者对象，提供同事对象交互的抽象方法，实现所有相互影响的同事类的公共功能 1234567public abstract class Colleague &#123; protected Mediator mediator; public Colleague(Mediator mediator) &#123; this.mediator = mediator; &#125;&#125; 具体同事类：是抽象同事类的实现者，当需要与其他同事对象交互时，由中介者对象负责后续的交互，每个同事角色都知道中介者角色， 且与其他同事角色通信时， 一定要通过中介者角色协作 123456789101112131415public class ConcreteColleague1 extends Colleague &#123; public ConcreteColleague1(Mediator mediator) &#123; super(mediator); &#125; public void selfMethod1() &#123; //处理自己的业务逻辑 &#125; public void depMethod1() &#123; //处理自己的业务逻辑 //自己不能处理的业务逻辑， 委托给中介者处理 super.mediator.doSomething1(); &#125;&#125; 123456789101112131415public class ConcreteColleague2 extends Colleague &#123; public ConcreteColleague2(Mediator mediator) &#123; super(mediator); &#125; public void selfMethod2() &#123; //处理自己的业务逻辑 &#125; public void depMethod2() &#123; //处理自己的业务逻辑 //自己不能处理的业务逻辑， 委托给中介者处理 super.mediator.doSomething2(); &#125;&#125; 优点 类之间各司其职，符合迪米特法则 降低了对象之间的耦合性，使得对象易于独立地被复用 将对象间的一对多关联转变为一对一的关联，提高系统的灵活性，使得系统易于维护和扩展 缺点中介者模式将原本多个对象直接的相互依赖变成了中介者和多个同事类的依赖关系。当同事类越多时，中介者就会越臃肿，变得复杂且难以维护 应用在MVC框架中，控制器（C）就是模型（M）和视图（V）的中介者。","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"行为型模式","slug":"设计模式/行为型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"状态模式","date":"2016-01-04T03:40:20.000Z","path":"blog/设计模式/行为型模式/状态模式/","text":"状态模式适用于当某个对象在它的状态发生改变时，其行为也随着发生比较大的变化，在行为受状态约束的情况下可以使用状态模式，而且使用时对象的状态最好不要超过5个 。 定义当一个对象内在状态改变时允许其改变行为，这个对象看起来像改变了其类 优点 结构清晰，避免了过多的switch…case或者if…else语句的使用，避免了程序的复杂性,提高系统的可维护性 很好地体现了开闭原则和单一职责原则，每个状态都是一个子类 封装性非常好，状态变换放置到类内部实现，外部调用不用知道类内部如何实现状态和行为的变换 缺点 子类太多导致类膨胀 应用 行为随状态改变而改变的场景 条件、分支判断语句的替代者","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"行为型模式","slug":"设计模式/行为型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"模板方法模式","date":"2016-01-04T03:35:20.000Z","path":"blog/设计模式/行为型模式/模板方法模式/","text":"模板方法模式非常简单应用非常广泛的模式，定义一个操作中的算法框架，而将一些步骤延迟到子类中。使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。 AbstractClass叫做抽象模板，其方法分为基本方法和模板方法两类。基本方法也叫做基本操作，由子类实现的方法，且在模板方法中被调用。模板方法可以有一个或几个，用于实现对基本方法的调度，完成固定的逻辑。为了防止恶意操作，一般模板方法都使用final关键之修饰，防止被覆盖。 抽象模板类：1234567891011public abstract class AbstractPerson &#123; public final void prepareGotoSchool()&#123; dressUp(); eatBreakfast(); tackThings(); &#125; protected abstract void dressUp(); protected abstract void eatBreakfast(); protected abstract void tackThings();&#125; 具体的模板类： 1234567891011121314public class Student extends AbstractPerson&#123; @Override protected void dressUp() &#123; System.out.println(&quot;穿衣服&quot;); &#125; @Override protected void eatBreakfast() &#123; System.out.println(&quot;吃妈妈做的早餐&quot;); &#125; @Override protected void tackThings() &#123; System.out.println(&quot;背书包，带上家庭作业和红领巾&quot;); &#125;&#125; 1234567891011121314public class Teacher extends AbstractPerson&#123; @Override protected void dressUp() &#123; System.out.println(&quot;穿工作服&quot;); &#125; @Override protected void eatBreakfast() &#123; System.out.println(&quot;做早饭，照顾孩子吃早饭&quot;); &#125; @Override protected void tackThings() &#123; System.out.println(&quot;带上昨天晚上准备的考卷&quot;); &#125;&#125; 场景类的调用: 1234Student student = new Student();student.prepareGotoSchool();Teacher teacher = new Teacher();teacher.prepareGotoSchool(); 抽象模板中的基本方法尽量设计为protected类型，符合迪米特法则，不需要暴露的属性或方法尽量不要设置为protected类型。实现类若非必要，尽量不要扩大父类中的访问权限。 模板方法模式可封装不变部分，扩展可变部分；可提取公共部分代码，便于维护；行为由父类控制，子类实现。但一般的设计习惯，抽象类负责声明最抽象、最一般的事物属性和方法，实现类完成具体的事物属性和方法。但是模板方法模式却颠倒了，抽象类定义了部分抽象方法，由子类实现，子类执行的结果影响了父类的结果，也就是子类对父类产生了影响，在复杂的项目中，会带来代码阅读的难度。 使用场景 多个子类有公有的方法，且逻辑基本相同时 重要、复杂的算发，可以把核心算法设计为模板方法，周边的相关细节功能由各个子类实现 重构时，模板方法模式时一个经常使用的模式，把相同的代码抽取到父类中，然后通过钩子函数约束其行为 在Spring源码中refresh()就是典型的模板方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475public interface ConfigurableApplicationContext extends ApplicationContext, ifecycle, Closeable &#123; void refresh() throws BeansException, IllegalStateException;&#125;public abstract class AbstractApplicationContext extends DefaultResourceLoader implements ConfigurableApplicationContext &#123; @Override public void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; StartupStep contextRefresh = this.applicationStartup.start(&quot;spring.context.refresh&quot;); // Prepare this context for refreshing. prepareRefresh(); // Tell the subclass to refresh the internal bean factory. ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); StartupStep beanPostProcess = this.applicationStartup.start(&quot;spring.context.beans.post-process&quot;); // Invoke factory processors registered as beans in the context. invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. registerBeanPostProcessors(beanFactory); beanPostProcess.end(); // Initialize message source for this context. initMessageSource(); // Initialize event multicaster for this context. initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. onRefresh(); // Check for listener beans and register them. registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(&quot;Exception encountered during context initialization - &quot; + &quot;cancelling refresh attempt: &quot; + ex); &#125; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset &#x27;active&#x27; flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; finally &#123; // Reset common introspection caches in Spring&#x27;s core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); contextRefresh.end(); &#125; &#125; &#125;&#125; **JDK中HashMap、Map、AQS**中都有用到模板方法设计模式。 12345678910111213// AQS中用到的模板方法public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125;// JDK8 Map中的模板方法default V getOrDefault(Object key, V defaultValue) &#123; V v; return (((v = get(key)) != null) || containsKey(key)) ? v : defaultValue;&#125;","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"行为型模式","slug":"设计模式/行为型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"备忘录模式","date":"2016-01-04T03:30:20.000Z","path":"blog/设计模式/行为型模式/备忘录模式/","text":"备忘录模式又叫快照模式，就是一个对象的备份模式，提供了一种程序数据的备份方法。当后悔时能撤销当前操作，使数据恢复到它原先的状态。 备忘录创建出来就要在“最近”的代码中使用，要主动管理它的生命周期，建立就要使用，不使用就要立刻删除其引用。不要在频繁建立备份的场景中使用备忘录模式。 定义在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态。这样以后就可将该对象恢复到原先保存的状态。 **发起人角色Originator**：记录当前时刻的内部状态信息，提供创建备忘录和恢复备忘录数据的功能，实现其他业务功能，它可以访问备忘录里的所有信息。 123456789101112131415public class Originator &#123; private String state; public void setState(String state) &#123; this.state = state; &#125; public String getState() &#123; return state; &#125; public Memento createMemento() &#123; return new Memento(state); &#125; public void restoreMemento(Memento m) &#123; this.setState(m.getState()); &#125;&#125; **备忘录角色Memento**：负责存储发起人的内部状态，在需要的时候提供这些内部状态给发起人。 123456789101112131415public class Memento &#123; private String state; public Memento(String state) &#123; this.state = state; &#125; public void setState(String state) &#123; this.state = state; &#125; public String getState() &#123; return state; &#125;&#125; **管理者角色Caretaker**：对备忘录进行管理，提供保存与获取备忘录的功能，但其不能对备忘录的内容进行访问与修改。 123456789public class Caretaker &#123; private Memento memento; public void setMemento(Memento m) &#123; memento = m; &#125; public Memento getMemento() &#123; return memento; &#125;&#125; 客户端代码： 12345678910111213public class MementoPattern &#123; public static void main(String[] args) &#123; Originator or = new Originator(); Caretaker cr = new Caretaker(); or.setState(&quot;S0&quot;); System.out.println(&quot;初始状态:&quot; + or.getState()); cr.setMemento(or.createMemento()); //保存状态 or.setState(&quot;S1&quot;); System.out.println(&quot;新的状态:&quot; + or.getState()); or.restoreMemento(cr.getMemento()); //恢复状态 System.out.println(&quot;恢复状态:&quot; + or.getState()); &#125;&#125; 优点 提供了一种可以恢复状态的机制。当用户需要时能够比较方便地将数据恢复到某个历史的状态 实现了内部状态的封装。除了创建它的发起人之外，其他对象都不能够访问这些状态信息 发起人不需要管理和保存其内部状态的各个备份，所有状态信息都保存在备忘录中，并由管理者进行管理，符合单一职责原则 缺点 资源消耗大。如果要保存的内部状态信息过多或者特别频繁，将会占用比较大的内存资源 应用 需要保存和恢复数据的相关状态场景，游戏中的存档功能 提供一个可回滚rollback的操作，如Word、记事本、Photoshop，Eclipse 等软件在编辑时按 Ctrl+Z 组合键，还有数据库中事务操作 需要监控的副本场景中 扩展clone方式的备忘录发起人角色Originator 1234567891011121314151617181920212223class OriginatorPrototype implements Cloneable &#123; private String state; public void setState(String state) &#123; this.state = state; &#125; public String getState() &#123; return state; &#125; public OriginatorPrototype createMemento() &#123; return this.clone(); &#125; public void restoreMemento(OriginatorPrototype opt) &#123; this.setState(opt.getState()); &#125; public OriginatorPrototype clone() &#123; try &#123; return (OriginatorPrototype) super.clone(); &#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace(); &#125; return null; &#125;&#125; 管理者角色Caretaker 123456789class PrototypeCaretaker &#123; private OriginatorPrototype opt; public void setMemento(OriginatorPrototype opt) &#123; this.opt = opt; &#125; public OriginatorPrototype getMemento() &#123; return opt; &#125;&#125; 客户端代码：12345678910111213public class Client &#123; public static void main(String[] args) &#123; OriginatorPrototype or = new OriginatorPrototype(); PrototypeCaretaker cr = new PrototypeCaretaker(); or.setState(&quot;S0&quot;); System.out.println(&quot;初始状态:&quot; + or.getState()); cr.setMemento(or.createMemento()); //保存状态 or.setState(&quot;S1&quot;); System.out.println(&quot;新的状态:&quot; + or.getState()); or.restoreMemento(cr.getMemento()); //恢复状态 System.out.println(&quot;恢复状态:&quot; + or.getState()); &#125;&#125; 多状态的备忘录模式可以通过对 备忘录角色Memento 角色进行扩展，将存储状态的字段用Map来存储多个状态，从而实现多状态备忘录模式。","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"行为型模式","slug":"设计模式/行为型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"命令模式","date":"2016-01-04T02:30:20.000Z","path":"blog/设计模式/行为型模式/命令模式/","text":"命令模式是一个高内聚的模式 ，将一个请求封装成一个对象， 从而让你使用不同的请求把客户端参数化， 对请求排队或者记录请求日志， 可以提供命令的撤销和恢复功能 。 命令模式有三个角色： Receiver接收者角色：执行命令功能的相关操作，具体命令对象业务的真正实现者。 Command命令角色：需要执行的所有命令在该角色中声明，拥有执行命令的抽象方法execute()。 Invoker调用者角色：是请求发送者，通常拥有很多命令对象，并通过访问命令对象来执行相关请求，它不直接访问接收者 实现通用的Receiver类： 123456789public abstract class Receiver &#123; public abstract void find(); public abstract void add(); public abstract void delete(); public abstract void update();&#125; 接收者可以是多个，具体的Receiver类： 1234567891011121314151617public class ConcreteReceiver1 extends Receiver&#123; @Override public void find() &#123; &#125; @Override public void add() &#123; &#125; @Override public void delete() &#123; &#125; @Override public void update() &#123; &#125;&#125; 1234567891011121314151617public class ConcreteReceiver2 extends Receiver&#123; @Override public void find() &#123; &#125; @Override public void add() &#123; &#125; @Override public void delete() &#123; &#125; @Override public void update() &#123; &#125;&#125; 命令角色是命令模式的核心，抽象的Command类： 123public abstract class Command &#123; public abstract void execute();&#125; 具体的Command类，可以在实际应用中扩展该命令类，在每个命令类中，通过构造函数定义该命令是针对哪个接收者发出的，定义一个命令接收的主题，这样调用者就仅需要实现命令的传递即可： 12345678910111213141516public class ConcreteCommand1 extends Command &#123; private Receiver receiver; public ConcreteCommand1(Receiver receiver) &#123; this.receiver = receiver; &#125; @Override public void execute() &#123; this.receiver.find(); this.receiver.add(); this.receiver.delete(); this.receiver.update(); &#125;&#125; 12345678910111213141516public class ConcreteCommand2 extends Command &#123; private Receiver receiver; public ConcreteCommand2(Receiver receiver) &#123; this.receiver = receiver; &#125; @Override public void execute() &#123; this.receiver.find(); this.receiver.add(); this.receiver.delete(); this.receiver.update(); &#125;&#125; 调用者Invoker类，不管什么命令都要接收、执行： 1234567891011public class Invoker &#123; private Command command; public void setCommand(Command command) &#123; this.command = command; &#125; public void action() &#123; this.command.execute(); &#125;&#125; 场景类： 12345678910111213public class Client &#123; public static void main(String[] args) &#123; //首先声明调用者Invoker Invoker invoker = new Invoker(); //定义接收者 Receiver receiver = new ConcreteReceiver1(); //定义一个发送给接收者的命令 Command command = new ConcreteCommand1(receiver); //把命令交给调用者去执行 invoker.setCommand(command); invoker.action(); &#125;&#125; 命令模式的Receiver在实际应用中可以被封装掉，从而减少高层模块Client类对低层模块Receiver角色类的依赖关系，提高系统整体的稳定性。 123456789public abstract class Command &#123; //定义一个子类的全局共享变量 protected final Receiver receiver; //实现类必须定义一个接收者 public Command(Receiver _receiver)&#123; this.receiver = _receiver; &#125; public abstract void execute();&#125; 12345678910111213141516public class ConcreteCommand1 extends Command &#123; public ConcreteCommand1() &#123; super(new ConcreteReceiver1()); &#125; public ConcreteCommand1(Receiver receiver) &#123; super(receiver); &#125; @Override public void execute() &#123; this.receiver.find(); this.receiver.add(); this.receiver.delete(); this.receiver.update(); &#125;&#125; 优点 类间解耦：调用者角色和接收者角色之间没有任何依赖关系，调用者实现功能时只需要调用Command抽象类的execute方法即可，不需要了解到底是哪个接收者执行。 可扩展性：Command子类可以非常容易地扩展，而调用者Invoker和高层模块Client不产生严重代码耦合。 和其他模式结合会更优秀：命令模式和结合责任链模式，实现命令族解析任务；结合模板方法模式，可减少Command子类的膨胀问题。 缺点Command子类会出现膨胀问题。 应用命令模式在Spring框架**JdbcTemplate**源码的应用： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950private &lt;T&gt; T execute(StatementCallback&lt;T&gt; action, boolean closeResources) throws DataAccessException &#123; Assert.notNull(action, &quot;Callback object must not be null&quot;); Connection con = DataSourceUtils.getConnection(obtainDataSource()); Statement stmt = null; try &#123; stmt = con.createStatement(); applyStatementSettings(stmt); T result = action.doInStatement(stmt); handleWarnings(stmt); return result; &#125; catch (SQLException ex) &#123; String sql = getSql(action); JdbcUtils.closeStatement(stmt); stmt = null; DataSourceUtils.releaseConnection(con, getDataSource()); con = null; throw translateException(&quot;StatementCallback&quot;, sql, ex); &#125; finally &#123; if (closeResources) &#123; JdbcUtils.closeStatement(stmt); DataSourceUtils.releaseConnection(con, getDataSource()); &#125; &#125;&#125;public &lt;T&gt; T query(final String sql, final ResultSetExtractor&lt;T&gt; rse) throws DataAccessException &#123; Assert.notNull(sql, &quot;SQL must not be null&quot;); Assert.notNull(rse, &quot;ResultSetExtractor must not be null&quot;); if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Executing SQL query [&quot; + sql + &quot;]&quot;); &#125; class QueryStatementCallback implements StatementCallback&lt;T&gt;, SqlProvider &#123; @Override @Nullable public T doInStatement(Statement stmt) throws SQLException &#123; ResultSet rs = null; try &#123; rs = stmt.executeQuery(sql); return rse.extractData(rs); &#125; finally &#123; JdbcUtils.closeResultSet(rs); &#125; &#125; @Override public String getSql() &#123; return sql; &#125; &#125; return execute(new QueryStatementCallback(), true);&#125; StatementCallback接口，类似Command命令接口，QueryStatementCallback匿名内部类，实现了命令接口，同时也充当命令接收者；命令调用者是 JdbcTemplate，不同的实现StatementCallback接口的对象，对应不同的doInStatement实现逻辑； 扩展实现在没有执行或执行后撤回，有两种方法可以解决，一是结合备忘录模式还原最后状态，该方法适合接收者为状态的变更情况，而不适合事件处理；二是通过增加一个新的命令，实现事件的回滚。","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"行为型模式","slug":"设计模式/行为型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"适配器模式","date":"2016-01-03T05:30:20.000Z","path":"blog/设计模式/结构型模式/适配器模式/","text":"适配器模式是一个补偿模式，通常用来解决接口不相容的问题 ，又叫变压器模式，也叫包装模式。 适配器模式最好在详细设计阶段不要考虑它，它不是为了解决还处在开发阶段的问题，而是解决正在服役的项目问题，该模式使用的主要场景是扩展应用。 定义将一个类的接口变换成客户端所期待的另一种接口，从而使原本因接口不匹配儿无法再一起工作的两个类能够在一起工作。 实现适配器模式分为类结构型模式和对象结构型模式两种，前者类之间的耦合度比后者高，且要求了解现有组件库中的相关组件的内部结构。类结构型模式:对象结构型模式: Target目标接口，当前系统业务所期待的接口，它可以是抽象类或接口。 123public interface Target &#123; void request();&#125; Adaptee适配者类，它是被访问和适配的现存组件库中的组件接口。 12345public class Adaptee &#123; public void specificRequest() &#123; System.out.println(&quot;适配者中的业务代码被调用！&quot;); &#125;&#125; Adapter适配器类，它是一个转换器，通过继承或引用适配者的对象，把适配者接口转换成目标接口，让客户按目标接口的格式访问适配者。 通过继承进行的适配， 叫做类适配器 。 1234567891011public class ClassAdapter extends Adaptee implements Target &#123; @Override public void request() &#123; super.specificRequest(); &#125;&#125;public static void main(String[] args) &#123; Target target = new ClassAdapter(); target.request();&#125; 通过关联关系进行的适配，叫做对象适配器。可釆用将现有组件库中已经实现的组件引入适配器类中，该类同时实现当前系统的业务接口。 1234567891011121314151617public class ObjectAdapter implements Target &#123; private Adaptee adaptee; public ObjectAdapter(Adaptee adaptee) &#123; this.adaptee = adaptee; &#125; @Override public void request() &#123; adaptee.specificRequest(); &#125;&#125;public static void main(String[] args) &#123; Adaptee adaptee = new Adaptee(); Target target = new ObjectAdapter(adaptee); target.request();&#125; 对象适配器和类适配器的区别是：类适配器是类间继承，对象适配器是对象的组合关系，对象适配器是通过类间的关联关系进行耦合的，因此在设计时就可以做到比较灵活；而类适配器就只能通过覆写源角色的方法进行扩展。 优点 可以让两个没有任何关系的类在一起运行 增加了类的透明性，客户端通过适配器可以透明地调用目标接口 提高了类的复用度，复用了现存的类，不需要修改原有代码而重用现有的适配者类 将目标类和适配者类解耦，解决了目标类和适配者类接口不一致的问题 灵活性非常好 缺点 适配器编写过程需要结合业务场景全面考虑，可能会增加系统的复杂性 增加代码阅读难度，降低代码可读性，过多使用适配器会使系统代码变得凌乱 应用场景在Spring AOP源码中适配器模式应用非常广泛，Advice就是来增强被代理类的功能，Advice 的类型主要有 BeforeAdvice、AfterReturningAdvice、ThrowsAdvice。 1234567891011public interface Advice &#123;&#125;public interface AfterAdvice extends Advice &#123;&#125;public interface BeforeAdvice extends Advice &#123;&#125;public interface ThrowsAdvice extends AfterAdvice &#123;&#125; 每种Advice都有对应的拦截器，即MethodBeforeAdviceInterceptor、AfterReturningAdviceInterceptor、ThrowsAdviceInterceptor，不同类型的Interceptor，通过适配器统一对外提供接口，最终调用不同的 advice来实现被代理类的增强。 12345678910111213141516171819202122232425262728293031323334353637383940public interface Interceptor extends Advice &#123;&#125;public interface MethodInterceptor extends Interceptor &#123; @Nullable Object invoke(@Nonnull MethodInvocation invocation) throws Throwable;&#125;public class AfterReturningAdviceInterceptor implements MethodInterceptor, AfterAdvice, Serializable &#123; private final AfterReturningAdvice advice; public AfterReturningAdviceInterceptor(AfterReturningAdvice advice) &#123; Assert.notNull(advice, &quot;Advice must not be null&quot;); this.advice = advice; &#125; @Override @Nullable public Object invoke(MethodInvocation mi) throws Throwable &#123; Object retVal = mi.proceed(); this.advice.afterReturning(retVal, mi.getMethod(), mi.getArguments(), mi.getThis()); return retVal; &#125;&#125;public class MethodBeforeAdviceInterceptor implements MethodInterceptor, BeforeAdvice, Serializable &#123; private final MethodBeforeAdvice advice; public MethodBeforeAdviceInterceptor(MethodBeforeAdvice advice) &#123; Assert.notNull(advice, &quot;Advice must not be null&quot;); this.advice = advice; &#125; @Override @Nullable public Object invoke(MethodInvocation mi) throws Throwable &#123; this.advice.before(mi.getMethod(), mi.getArguments(), mi.getThis()); return mi.proceed(); &#125;&#125; Spring AOP的AdvisorAdapter类有 4 个实现类，即 SimpleBeforeAdviceAdapter、MethodBeforeAdviceAdapter、AfterReturningAdviceAdapter、ThrowsAdviceAdapter； 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public interface AdvisorAdapter &#123; boolean supportsAdvice(Advice advice); MethodInterceptor getInterceptor(Advisor advisor);&#125;class AfterReturningAdviceAdapter implements AdvisorAdapter, Serializable &#123; @Override public boolean supportsAdvice(Advice advice) &#123; return (advice instanceof AfterReturningAdvice); &#125; @Override public MethodInterceptor getInterceptor(Advisor advisor) &#123; AfterReturningAdvice advice = (AfterReturningAdvice) advisor.getAdvice(); return new AfterReturningAdviceInterceptor(advice); &#125;&#125;public class MethodBeforeAdviceInterceptor implements MethodInterceptor, BeforeAdvice, Serializable &#123; private final MethodBeforeAdvice advice; public MethodBeforeAdviceInterceptor(MethodBeforeAdvice advice) &#123; Assert.notNull(advice, &quot;Advice must not be null&quot;); this.advice = advice; &#125; @Override @Nullable public Object invoke(MethodInvocation mi) throws Throwable &#123; this.advice.before(mi.getMethod(), mi.getArguments(), mi.getThis()); return mi.proceed(); &#125;&#125;class SimpleBeforeAdviceAdapter implements AdvisorAdapter, Serializable &#123; @Override public boolean supportsAdvice(Advice advice) &#123; return (advice instanceof SimpleBeforeAdvice); &#125; @Override public MethodInterceptor getInterceptor(Advisor advisor) &#123; SimpleBeforeAdvice advice = (SimpleBeforeAdvice) advisor.getAdvice(); return new SimpleBeforeAdviceInterceptor(advice) ; &#125;&#125;class ThrowsAdviceAdapter implements AdvisorAdapter, Serializable &#123; @Override public boolean supportsAdvice(Advice advice) &#123; return (advice instanceof ThrowsAdvice); &#125; @Override public MethodInterceptor getInterceptor(Advisor advisor) &#123; return new ThrowsAdviceInterceptor(advisor.getAdvice()); &#125;&#125; 适配器模式在Spring MVC中的经典使用： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public interface HandlerAdapter &#123; boolean supports(Object handler); @Nullable ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception; long getLastModified(HttpServletRequest request, Object handler);&#125;public class SimpleServletHandlerAdapter implements HandlerAdapter &#123; @Override public boolean supports(Object handler) &#123; return (handler instanceof Servlet); &#125; @Override @Nullable public ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; ((Servlet) handler).service(request, response); return null; &#125; @Override public long getLastModified(HttpServletRequest request, Object handler) &#123; return -1; &#125;&#125;public class HttpRequestHandlerAdapter implements HandlerAdapter &#123; @Override public boolean supports(Object handler) &#123; return (handler instanceof HttpRequestHandler); &#125; @Override @Nullable public ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; ((HttpRequestHandler) handler).handleRequest(request, response); return null; &#125; @Override public long getLastModified(HttpServletRequest request, Object handler) &#123; if (handler instanceof LastModified) &#123; return ((LastModified) handler).getLastModified(request); &#125; return -1L; &#125;&#125; MVC中体现在它的核心方法doDispatch方法中： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; boolean multipartRequestParsed = false; WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); try &#123; ModelAndView mv = null; Exception dispatchException = null; try &#123; processedRequest = checkMultipart(request); multipartRequestParsed = (processedRequest != request); // Determine handler for the current request. mappedHandler = getHandler(processedRequest); if (mappedHandler == null) &#123; noHandlerFound(processedRequest, response); return; &#125; // Determine handler adapter for the current request. HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler()); // Process last-modified header, if supported by the handler. String method = request.getMethod(); boolean isGet = &quot;GET&quot;.equals(method); if (isGet || &quot;HEAD&quot;.equals(method)) &#123; long lastModified = ha.getLastModified(request, mappedHandler.getHandler()); if (new ServletWebRequest(request, response).checkNotModified(lastModified) &amp;&amp; isGet) &#123; return; &#125; &#125; if (!mappedHandler.applyPreHandle(processedRequest, response)) &#123; return; &#125; // Actually invoke the handler. mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); if (asyncManager.isConcurrentHandlingStarted()) &#123; return; &#125; applyDefaultViewName(processedRequest, mv); mappedHandler.applyPostHandle(processedRequest, response, mv); &#125; catch (Exception ex) &#123; dispatchException = ex; &#125; catch (Throwable err) &#123; // As of 4.3, we&#x27;re processing Errors thrown from handler methods as well, // making them available for @ExceptionHandler methods and other scenarios. dispatchException = new NestedServletException(&quot;Handler dispatch failed&quot;, err); &#125; processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException); &#125; catch (Exception ex) &#123; triggerAfterCompletion(processedRequest, response, mappedHandler, ex); &#125; catch (Throwable err) &#123; triggerAfterCompletion(processedRequest, response, mappedHandler, new NestedServletException(&quot;Handler processing failed&quot;, err)); &#125; finally &#123; if (asyncManager.isConcurrentHandlingStarted()) &#123; // Instead of postHandle and afterCompletion if (mappedHandler != null) &#123; mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response); &#125; &#125; else &#123; // Clean up any resources used by a multipart request. if (multipartRequestParsed) &#123; cleanupMultipart(processedRequest); &#125; &#125; &#125;&#125; 在doDispatch()方法中调用了getHandlerAdapter()方法，在getHandlerAdapter()方法中循环调用supports()方法来判断是否兼容，循环迭代集合中的Adapter在初始化时早已被赋值。 1234567891011protected HandlerAdapter getHandlerAdapter(Object handler) throws ServletException &#123; if (this.handlerAdapters != null) &#123; for (HandlerAdapter adapter : this.handlerAdapters) &#123; if (adapter.supports(handler)) &#123; return adapter; &#125; &#125; &#125; throw new ServletException(&quot;No adapter for handler [&quot; + handler + &quot;]: The DispatcherServlet configuration needs to include a HandlerAdapter that supports this handler&quot;);&#125;","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"结构型模式","slug":"设计模式/结构型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E7%BB%93%E6%9E%84%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"装饰模式","date":"2016-01-03T04:30:20.000Z","path":"blog/设计模式/结构型模式/装饰模式/","text":"动态地给一个对象添加一些额外的职责。就增加功能来说，装饰模式相比生成子类更为灵活。是对继承的有力补充。 扩展一个类的功能会使用继承方式来实现。但继承具有静态特征，耦合度高，并且随着扩展功能的增多，子类会很膨胀。装饰器模式的目标是使用组合关系来创建一个装饰对象来包裹真实对象，并在保持真实对象的类结构不变的前提下，为其提供额外的功能。 实现抽象构件角色：定义一个抽象接口以规范准备接收附加责任的对象。 123public interface Component &#123; void operation();&#125; 具体构件角色：实现抽象构件，通过装饰角色为其添加一些职责。 123456public class ConcreteComponent implements Component &#123; @Override public void operation() &#123; System.out.println(&quot;ConcreteComponent operation&quot;); &#125;&#125; 抽象装饰角色：继承抽象构件，并包含具体构件的实例，可以通过其子类扩展具体构件的功能。 123456789101112public abstract class Decorator implements Component &#123; private Component component; public Decorator(Component component) &#123; this.component = component; &#125; @Override public void operation() &#123; this.component.operation(); &#125;&#125; 具体装饰角色：实现抽象装饰的相关方法，并给具体构件对象添加附加的责任。 123456789101112public class ConcreteDecorator extends Decorator &#123; public ConcreteDecorator(Component component) &#123; super(component); &#125; public void operation() &#123; super.operation(); addedFunction(); &#125; public void addedFunction() &#123; System.out.println(&quot;为具体构件角色增加额外的功能addedFunction()&quot;); &#125;&#125; 场景类 123456public static void main(String[] args) &#123; Component p = new ConcreteComponent(); p.operation(); Component d = new ConcreteDecorator(p); d.operation();&#125; 若只有一个具体构件而没有抽象构件时，可以让抽象装饰继承具体构件。若只有一个具体装饰时，可以将抽象装饰和具体装饰合并。 优点 装饰类和被装饰类可以独立发展， 而不会相互耦合； 装饰模式是继承关系的一个替代方案； 装饰模式可以动态地扩展一个实现类的功能； 缺点装饰器模式会增加许多子类，过度使用会增加程序得复杂性，尽量减少装饰类的数量， 以便降低系统的复杂度。 应用场景 需要扩展一个类的功能， 或给一个类增加附加功能，而又不能采用生成子类的方法进行扩充时； 需要动态地给一个对象增加功能， 这些功能可以再动态地撤销； 当需要通过对现有的一组基本功能进行排列组合而产生非常多的功能时，采用继承关系很难实现； Java I/O 标准库的设计，InputStream的子类FilterInputStream，OutputStream的子类FilterOutputStream，Reader的子类BufferedReader以及FilterReader，还有Writer的子类BufferedWriter、FilterWriter以及 PrintWriter等，它们都是抽象装饰类。 12BufferedReader in = new BufferedReader(new FileReader(&quot;filename.txt&quot;));String s = in.readLine();","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"结构型模式","slug":"设计模式/结构型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E7%BB%93%E6%9E%84%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"组合模式","date":"2016-01-03T03:30:20.000Z","path":"blog/设计模式/结构型模式/组合模式/","text":"组合模式也叫合成模式，有时又叫部分整体模式，主要是用来描述部分与整体的关系； 只要是树形结构， 就要考虑使用组合模式， 只要是要体现局部和整体的关系的时候， 而且这种关系还可能比较深， 考虑使用组合模式。 定义将对象组合成树形结构以表示部分—整体的层次结构，使得用户对单个对象和组合对象的使用具有一致性。 实现组合模式一般用来描述整体与部分的关系，它将对象组织到树形结构中，顶层的节点被称为根节点，根节点下面可以包含树枝节点和叶子节点，树枝节点下面又可以包含树枝节点和叶子节点。 组合模式分为透明式的组合模式和安全式的组合模式。 透明式的组合模式中，抽象构件声明了所有子类中的全部方法，所以客户端无须区别树叶对象和树枝对象，对客户端来说是透明的。 缺点是树叶构件本来没有 add()、remove()、getChild() 方法，却要实现它们，空实现或抛异常，会带来一些安全性问题。 Component抽象构件角色，其主要作用是为树叶构件和树枝构件声明公共接口，并实现它们的默认行为。在透明式的组合模式中抽象构件还声明访问和管理子类的接口；在安全式的组合模式中不声明访问和管理子类的接口，管理工作由树枝构件完成。 123456789public interface Component &#123; void add(Component c); void remove(Component c); Component getChild(int i); void operation();&#125; Leaf树叶构件角色，是组合中的叶节点对象，它没有子节点，用于继承或实现抽象构件。 12345678910111213141516public class Leaf implements Component &#123; private String name; public Leaf(String name) &#123; this.name = name; &#125; public void add(Component c) &#123; &#125; public void remove(Component c) &#123; &#125; public Component getChild(int i) &#123; return null; &#125; public void operation() &#123; System.out.println(&quot;树叶&quot; + name + &quot;：被访问！&quot;); &#125;&#125; Composite树枝构件角色 &#x2F; 中间构件，是组合中的分支节点对象，它有子节点，用于继承和实现抽象构件。它的主要作用是存储和管理子部件，通常包含 add()、remove()、getChild() 等方法。 123456789101112131415161718192021public class Composite implements Component &#123; private ArrayList&lt;Component&gt; children = new ArrayList&lt;&gt;(); public void add(Component c) &#123; children.add(c); &#125; public void remove(Component c) &#123; children.remove(c); &#125; public Component getChild(int i) &#123; return children.get(i); &#125; public void operation() &#123; for (Object obj : children) &#123; ((Component) obj).operation(); &#125; &#125;&#125; 客户端使用： 123456789101112public static void main(String[] args) &#123; Component c0 = new Composite(); Component c1 = new Composite(); Component leaf1 = new Leaf(&quot;1&quot;); Component leaf2 = new Leaf(&quot;2&quot;); Component leaf3 = new Leaf(&quot;3&quot;); c0.add(leaf1); c0.add(c1); c1.add(leaf2); c1.add(leaf3); c0.operation();&#125; 安全式的组合模式中，将管理子构件的方法移到树枝构件中，抽象构件和树叶构件没有对子对象的管理方法，这样就避免了上一种方式的安全性问题，但由于叶子和分支有不同的接口，客户端在调用时要知道树叶对象和树枝对象的存在，所以失去了透明性。 安全式的组合模式与透明式组合模式的实现代码类似，只要对其做简单修改就可以了： 12345678910111213141516public interface Component &#123; void operation();&#125;public static void main(String[] args) &#123; Composite c0 = new Composite(); Composite c1 = new Composite(); Component leaf1 = new Leaf(&quot;1&quot;); Component leaf2 = new Leaf(&quot;2&quot;); Component leaf3 = new Leaf(&quot;3&quot;); c0.add(leaf1); c0.add(c1); c1.add(leaf2); c1.add(leaf3); c0.operation();&#125; 优点 简化客户端代码，使客户端代码可一致地处理单个对象和组合对象，无须关心处理的是单个对象，还是组合对象 更容易在组合体内加入新的对象，客户端不会因为加入了新的对象而更改源代码，满足开闭原则 缺点 设计较复杂，客户端需要花更多时间理清类之间的层次关系 不容易限制容器中的构件 容易用继承的方法来增加构件的新功能 应用在需要表示一个对象整体与部分的层次结构的场合；要求对用户隐藏组合对象与单个对象的不同，用户可以用统一的接口使用组合结构中的所有对象的场合；","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"结构型模式","slug":"设计模式/结构型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E7%BB%93%E6%9E%84%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"代理模式","date":"2016-01-03T03:00:20.000Z","path":"blog/设计模式/结构型模式/代理模式/","text":"由于某些原因需要给某对象提供一个代理以控制对该对象的访问。访问对象不适合或者不能直接引用目标对象，代理对象作为访问对象和目标对象之间的中介。 代理模式是一个使用率非常高的模式，为其他对象提供一种代理以控制这个对象的访问。代理模式也叫做委托模式，它是一项基本设计技巧。许多其他的模式，如状态模式、策略模式、访问者模式本质上是在更特殊的场合采用了委托模式，而且在日常的应用中，代理模式可以提供非常好的访问控制。 代理模式的结构比较简单，主要是通过定义一个继承抽象主题的代理来包含真实主题，从而实现对真实主题的访问； 抽象主题类**Subject通过接口或抽象类声明真实主题和代理对象**实现的业务方法： 123public interface Subject &#123; void request();&#125; 真实主题类RealSubject实现了抽象主题中的具体业务，是代理对象所代表的真实对象，是最终要引用的对象，为具体主题角色，也叫被委托角色或被代理角色，是业务逻辑的具体执行者： 123456public class RealSubject implements Subject &#123; @Override public void request() &#123; // 业务逻辑处理 &#125;&#125; 代理类Proxy提供了与真实主题相同的接口，其内部含有对真实主题的引用，它可以访问、控制或扩展真实主题的功能，也叫委托类或代理类： 1234567891011121314public class Proxy implements Subject &#123; private Subject subject; public Proxy(Subject subject) &#123; this.subject = subject; &#125; @Override public void request() &#123; this.before(); this.subject.request(); this.after(); &#125; private void before() &#123;&#125; private void after() &#123;&#125;&#125; 一般代理会被理解为代码增强，实际上就是在原代码逻辑前后增加一些代码逻辑，而使调用者无感知；一个代理类可以代理多个被委托者或被代理者， 因此一个代理类具体代理哪个真实主题角色， 是由场景类决定。 代理模式优点职责清晰，真实的角色就是实现实际的业务逻辑，不用关心其他非本职责的事务；高扩展性；智能化。 根据代理的创建时期，代理模式分为静态代理和动态代理，还可以通过反射的方式实现动态代理 优点 在客户端与目标对象之间起到一个中介作用和保护目标对象的作用 可以扩展目标对象的功能 能将客户端与目标对象分离，在一定程度上降低了系统的耦合度，增加了程序的可扩展性 缺点 会造成系统设计中类的数量增加 在客户端和目标对象之间增加一个代理对象，会造成请求处理速度变慢 增加了系统的复杂度 应用场景当无法或不想直接引用某个对象或访问某个对象存在困难时，可以通过代理对象来间接访问。使用代理模式主要有两个目的：保护目标对象，增强目标对象。 远程代理，通常是为了隐藏目标对象存在于不同地址空间的事实，方便客户端访问。 虚拟代理，通常用于要创建的目标对象开销很大时。 安全代理，通常用于控制不同种类客户对真实对象的访问权限。 智能指引，主要用于调用目标对象时，代理附加一些额外的处理功能。 延迟加载，指为了提高系统的性能，延迟对目标的加载。","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"结构型模式","slug":"设计模式/结构型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E7%BB%93%E6%9E%84%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"外观模式","date":"2016-01-03T02:00:20.000Z","path":"blog/设计模式/结构型模式/外观模式/","text":"外观模式也叫门面模式，注重统一的对象，是一种通过为多个复杂的子系统提供一个一致的接口，而使这些子系统更加容易被访问的模式。 该模式对外有一个统一接口，外部应用程序不用关心内部子系统的具体细节，这样会大大降低应用程序的复杂度，提高了程序的可维护性。 除了这个接口不允许有任何访问子系统的行为发生，是外界访问子系统内部的唯一通道，是一种比较常用的封装模式。 一般情况下，一个子系统只要一个门面，但若门面已经庞大到不能忍受的程度，可拆分成多个门面；需要子系统可以提供不同访问路径的情况，也可提供多个门面。 门面不参与子系统的业务逻辑，否则会产生倒依赖问题，子系统必须依赖门面才能被访问，违反了单一职责原则，同时也破坏了系统的封装性。 定义要求一个子系统的外部与其内部的通信必须通过一个统一的对象进行，外观模式提供一个高层次的接口，使得子系统更易于使用。 实现 **外观角色Facade**：为多个子系统对外提供一个共同的接口。 1234567891011public class Facade &#123; private SubSystem01 obj1 = new SubSystem01(); private SubSystem02 obj2 = new SubSystem02(); private SubSystem03 obj3 = new SubSystem03(); public void method() &#123; obj1.method1(); obj2.method2(); obj3.method3(); &#125;&#125; **子系统角色SubSystem**：实现系统的部分功能，客户可以通过外观角色访问它。 1234567891011121314151617public class SubSystem01 &#123; public void method1() &#123; System.out.println(&quot;子系统01的method1()被调用&quot;); &#125;&#125;public class SubSystem02 &#123; public void method2() &#123; System.out.println(&quot;子系统02的method2()被调用&quot;); &#125;&#125;public class SubSystem03 &#123; public void method3() &#123; System.out.println(&quot;子系统03的method3()被调用&quot;); &#125;&#125; **客户角色Client**：通过一个外观角色访问各个子系统的功能。 1234public static void main(String[] args) &#123; Facade facade = new Facade(); facade.method();&#125; 优点 减少了系统的相互依赖，所有的依赖都是对门面对象的依赖，与子系统无关，降低了子系统与客户端之间的耦合度 对客户屏蔽了子系统组件，减少了客户处理的对象数目，并使得子系统使用起来更加容易。 提高了灵活性，不管子系统内部如何变化，只要不影响到门面对象，可随意修改 提高了安全性，不在门面上开通的方法不能访问 缺点 不符合开闭原则，增加新的子系统可能需要修改外观类或客户端的源代码 应用场景 为一个复杂的模块或子系统提供一个供外界访问的接口 子系统相对独立，外界对子系统的访问只要黑箱操作即可，如利息计算问题 预防低水平人员带来的风险扩散 对分层结构系统构建时，使用外观模式定义子系统中每层的入口点可以简化子系统之间的依赖关系 当客户端与多个子系统之间存在很大的联系时，引入外观模式可将它们分离，从而提高子系统的独立性和可移植性。 使用外观模式整合已有的API","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"结构型模式","slug":"设计模式/结构型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E7%BB%93%E6%9E%84%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"建造者模式","date":"2016-01-02T09:08:20.000Z","path":"blog/设计模式/创建型模式/建造者模式/","text":"建造者模式也叫生成器模式，将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。当一个类的构造函数参数个数超过4个，而且这些参数有些是可选的参数，考虑使用构造者模式。 车辆模型抽象类： 1234567891011121314151617181920212223public abstract class CarModel &#123; private List&lt;String&gt; sequence = new ArrayList&lt;&gt;(); protected abstract void start(); protected abstract void stop(); protected abstract void alarm(); protected abstract void engineBoom(); public final void setSequence(List&lt;String&gt; sequence) &#123; this.sequence = sequence; &#125; public final void run() &#123; for (String actionName : sequence) &#123; if (&quot;start&quot;.equals(actionName)) &#123; this.start(); &#125; else if (&quot;stop&quot;.equals(actionName)) &#123; this.stop(); &#125; else if (&quot;alarm&quot;.equals(actionName)) &#123; this.alarm(); &#125; else if (&quot;engineBoom&quot;.equals(actionName)) &#123; this.engineBoom(); &#125; &#125; &#125;&#125; 车辆模型的具体代码： 12345678910111213141516171819202122232425262728293031323334353637public class BenzModel extends CarModel &#123; @Override protected void start() &#123; System.out.println(&quot;Benz开动&quot;); &#125; @Override protected void stop() &#123; System.out.println(&quot;Benz停车&quot;); &#125; @Override protected void alarm() &#123; System.out.println(&quot;Benz鸣笛&quot;); &#125; @Override protected void engineBoom() &#123; System.out.println(&quot;Benz发动引擎&quot;); &#125;&#125;public class BMWModel extends CarModel &#123; @Override protected void start() &#123; System.out.println(&quot;BMW开动&quot;); &#125; @Override protected void stop() &#123; System.out.println(&quot;BMW停车&quot;); &#125; @Override protected void alarm() &#123; System.out.println(&quot;BMW鸣笛&quot;); &#125; @Override protected void engineBoom() &#123; System.out.println(&quot;BMW发动引擎&quot;); &#125;&#125; 抽象汽车的组装者： 1234public abstract class CarBuilder &#123; public abstract void setSequence(List&lt;String&gt; seqence); public abstract CarModel getCarModel();&#125; 具体的车的组装者： 1234567891011121314151617181920212223public class BenzBuilder extends CarBuilder &#123; private BenzModel benz = new BenzModel(); @Override public void setSequence(List&lt;String&gt; sequence) &#123; this.benz.setSequence(sequence); &#125; @Override public CarModel getCarModel() &#123; return this.benz; &#125;&#125;public class BMWBuilder extends CarBuilder &#123; private BMWModel bmw = new BMWModel(); @Override public void setSequence(List&lt;String&gt; sequence) &#123; this.bmw.setSequence(sequence); &#125; @Override public CarModel getCarModel() &#123; return this.bmw; &#125;&#125; 场景类的调用： 123456789101112List&lt;String&gt; sequence = new ArrayList&lt;&gt;();sequence.add(&quot;engineBoom&quot;);sequence.add(&quot;start&quot;);sequence.add(&quot;stop&quot;);BenzBuilder benzBuilder = new BenzBuilder();benzBuilder.setSequence(sequence);BenzModel benz = (BenzModel)benzBuilder.getCarModel();benz.run();BMWBuilder bmwBuilder = new BMWBuilder();bmwBuilder.setSequence(sequence);BMWModel bmw = (BMWModel)bmwBuilder.getCarModel();bmw.run(); CarModel及其之类都是产品类，CarBuilder是抽象的建造者，用于规范产品的组建，其子类是具体的建造者，实现抽象类定义的所有，并返回一个组建好的对象。 建造者模式有良好的封装性，使用建造者模式可以使客户端不必知道产品内部组成的细节，建造者是独立的容易扩展，因此也便于控制细节风险，对建造过程逐步细化，而不对其他的模式产生任何影响。 使用场景 相同的方法，不同的执行顺序，产生不同的事件结果时。 多个部件或零件，都可以装配到一个对象中，但是产生的运行结果又不相同时。 产品类非常复杂，或者产品类中的调用顺序不同产生了不同的效能。 在对象创建过程中会使用到系统中的一些其他对象，这些对象在产品对象的创建过程中不易得到时，也可以采用建造者模式封装该对象的创建过程，该种场景只能是一个补偿方法。 与工厂模式的区别建造者模式最主要的功能是基本方法的调用顺序安排，也就是这些基本方法已经实现了，通俗地说就是零件的装配，顺序不同产生的对象也不同；而工厂方法则重点是创建，创建零件是它的主要职责，组装顺序则不是它关心的。","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"创建型模式","slug":"设计模式/创建型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E5%88%9B%E5%BB%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"工厂模式","date":"2016-01-02T08:08:20.000Z","path":"blog/设计模式/创建型模式/工厂模式/","text":"工厂方法模式工厂方法模式使用的频率非常高 ，用于创建对象的接口， 让子类决定实例化哪一个类。 工厂方法使一个类的实例化延迟到其子类 。用于封装和管理对象的创建，是一种创建模式。是典型的解耦框架，在需要灵活的、可扩展的框架时可以采用，可以用在异构项目中，可以使用在测试驱动的开发框架下。抽象产品类，抽象人种类： 1234public interface Human &#123; void getColor(); void talk();&#125; 具体的产品类可以有多个， 都继承于抽象产品类，具体的人种类： 1234567891011public class BlackHuman implements Human &#123; @Override public void getColor() &#123; System.out.println(&quot;黑色人种&quot;); &#125; @Override public void talk() &#123; System.out.println(&quot;我是黑色人种&quot;); &#125;&#125; 1234567891011public class WhiteHuman implements Human &#123; @Override public void getColor() &#123; System.out.println(&quot;白色人种&quot;); &#125; @Override public void talk() &#123; System.out.println(&quot;我是白色人种&quot;); &#125;&#125; 1234567891011public class YellowHuman implements Human &#123; @Override public void getColor() &#123; System.out.println(&quot;黄色人种&quot;); &#125; @Override public void talk() &#123; System.out.println(&quot;我是黄色人种&quot;); &#125;&#125; 抽象工厂类负责定义产品对象的产生： 123public abstract class AbstractHumanFactory &#123; public abstract &lt;T extends Human&gt; T createHuman(Class&lt;T&gt; clazz);&#125; 具体如何产生一个产品的对象， 是由具体的工厂类实现的，具体的工厂类： 1234567891011public class HumanFactory extends AbstractHumanFactory &#123; @Override public &lt;T extends Human&gt; T createHuman(Class&lt;T&gt; clazz) &#123; try &#123; return (T) Class.forName(clazz.getName()).newInstance(); &#125; catch (Exception e) &#123; System.out.println(&quot;人种生成错误&quot;); &#125; return null; &#125;&#125; 场景类的调用: 12345678910AbstractHumanFactory TaoLiu = new HumanFactory();Human whiteHuman = TaoLiu.createHuman(WhiteHuman.class);whiteHuman.getColor();whiteHuman.talk();Human blackHuman = TaoLiu.createHuman(BlackHuman.class);blackHuman.getColor();blackHuman.talk();Human yellowHuman = TaoLiu.createHuman(YellowHuman.class);yellowHuman.getColor();yellowHuman.talk(); 优点 良好的封装性， 代码结构清晰 良好的扩展性，增加产品类， 只要适当地修改具体的工厂类或扩展一个工厂类 屏蔽产品类，产品类的实现如何变化， 调用者都不需要关心，上层模块不发生变化 典型的解耦框架，高层模块值需要知道产品的抽象类，符合迪米特法则、依赖倒置原则、里氏替换原则 使用场景 需要生成对象的地方都可以使用， 但是需要慎重考虑是否要增加一个工厂类进行管理， 增加代码的复杂度 需要灵活的、 可扩展的框架时 异构项目中，如通过WebService与一个非Java的项目交互 可以使用在测试驱动开发的框架下 扩展工厂方法模式有很多扩展，且与其他模式结合使用威力更大，可将其缩小为简单工厂模式，可升级为多个工厂类，可替代单例模式，可延迟初始化。 缩小为简单工厂模式该模式是工厂方法模式的弱化，简单工厂模式又叫静态工厂模式，仅简单的对不同类对象的创建进行了简单的封装。缺点是工厂类的扩展比较困难， 不符合开闭原则。 简单工厂模式相对于工厂方法模式，去掉了AbstractHumanFactory抽象类， 同时把createHuman方法设置为静态类型， 简化了类的创建过程。 12345678910public class HumanFactory &#123; public static &lt;T extends Human&gt; T createHuman(Class&lt;T&gt; clazz) &#123; try &#123; return (T) Class.forName(clazz.getName()).newInstance(); &#125; catch (Exception e) &#123; System.out.println(&quot;人种生成错误&quot;); &#125; return null; &#125;&#125; 场景类的调用: 123456789Human whiteHuman = HumanFactory.createHuman(WhiteHuman.class);whiteHuman.getColor();whiteHuman.talk();Human blackHuman = HumanFactory.createHuman(BlackHuman.class);blackHuman.getColor();blackHuman.talk();Human yellowHuman = HumanFactory.createHuman(YellowHuman.class);yellowHuman.getColor();yellowHuman.talk(); 升级为多个工厂类在相对比较复杂的项目中，经常遇到初始化一个对象很耗费精力的情况，所有产品类都放到一个工厂方法中进行初始化会使代码结构不清晰。为每个产品定义一个创造者， 然后由调用者自己去选择与哪个工厂方法关联。 多工厂模式的工厂抽象类，抽象方法中已经不再需要传递相关参数了， 因为每一个具体的工厂都已经非常明确自己的职责。但也给可扩展性和可维护性带来了一定的影响。 多工厂模式的抽象工厂类： 123public abstract class AbstractHumanFactory &#123; public abstract Human createHuman();&#125; 黑色人种的创建工厂实现： 12345public class BlackHumanFactory extends AbstractHumanFactory &#123; public Human createHuman() &#123; return new BlackHuman(); &#125;&#125; 黄色人种的创建工厂实现： 12345public class YellowHumanFactory extends AbstractHumanFactory &#123; public Human createHuman() &#123; return new BlackHuman(); &#125;&#125; 白色人种的创建工厂实现： 12345public class WhiteHumanFactory extends AbstractHumanFactory &#123; public Human createHuman() &#123; return new BlackHuman(); &#125;&#125; 场景类的调用: 123456789Human whiteHuman = (new WhiteHumanFactory()).createHuman();whiteHuman.getColor();whiteHuman.talk();Human blackHuman = (new BlackHumanFactory()).createHuman();blackHuman.getColor();blackHuman.talk();Human yellowHuman = (new YellowHumanFactory()).createHuman();yellowHuman.getColor();yellowHuman.talk(); 在复杂的应用中一般采用多工厂的方法， 然后再增加一个协调类， 避免调用者与各个子工厂交流， 协调类的作用是封装子工厂类， 对高层模块提供统一的访问接口。 替代单例模式通过获得类构造器， 然后设置访问权限， 生成一个对象， 然后提供外部访问， 保证内存中的对象唯一。 通过工厂方法模式创建了一个单例对象， 该框架可以继续扩展， 在一个项目中可以产生一个单例构造器， 所有需要产生单例的类都遵循一定的规则 ， 然后通过扩展该框架。 12345678910111213141516171819202122232425public class Singleton &#123; private Singleton() &#123;&#125; public void doSomething() &#123;&#125;&#125;public class SingletonFactory &#123; private static Singleton singleton; static&#123; try &#123; Class cl= Class.forName(Singleton.class.getName()); // 获得无参构造 Constructor constructor = cl.getDeclaredConstructor(); // 设置无参构造是可访问的 constructor.setAccessible(true); // 产生一个实例对象 singleton = (Singleton)constructor.newInstance(); &#125; catch (Exception e) &#123; // 异常处理 &#125; &#125; public static Singleton getSingleton()&#123; return singleton; &#125;&#125; 延迟初始化一个对象被消费完后，并不立即释放，工厂类保持其初始状态，等待再次被调用。 12345678910111213141516171819public class ProductFactory &#123; private static final Map&lt;String, Human&gt; humanMap = new HashMap&lt;&gt;(); public static synchronized Human createHuman(String type) throws Exception &#123; Human human; if (humanMap.containsKey(type)) &#123; human = humanMap.get(type); &#125; else &#123; if (type.equals(&quot;BlackHuman&quot;)) &#123; human = new BlackHuman(); &#125; else if (type.equals(&quot;WhiteHuman&quot;)) &#123; human = new WhiteHuman(); &#125; else &#123; human = new YellowHuman(); &#125; humanMap.put(type, human); &#125; return human; &#125;&#125; 延迟加载框架是可扩展的， 例如限制某一个产品类的最大实例化数量， 可以通过判断Map中已有的对象数量来实现，还可以用在对象初始化比较复杂的情况下， 例如硬件访问， 涉及多方面的交互， 则可以通过延迟加载降低对象的产生和销毁带来的复杂性。 抽象工厂模式抽象工厂模式是一种比较常用的模式，为创建一组相关或相互依赖的对象提供一个接口， 且无须指定它们的具体类。 当一个对象族有相同的约束时可以使用抽象工厂模式。 优点封装性，产品的具体实现细节高层模块不需要关心；产品族内的约束为非公开状态。缺点产品族扩展非常困难，严重违反开闭原则。 抽象工厂模式是工厂方法模式的升级版， 在有多个业务品种、 业务分类时， 通过抽象工厂模式产生需要的对象是一种非常好的解决方式。 人种接口： 12345public interface Human &#123; void getColor(); void talk(); void getSex();&#125; 人种有三个抽象类， 负责人种的抽象属性定义： 1234567891011121314151617181920212223242526272829303132333435public abstract class AbstractBlackHuman implements Human &#123; @Override public void getColor() &#123; System.out.println(&quot;黑色人种&quot;); &#125; @Override public void talk() &#123; System.out.println(&quot;我是黑色人种&quot;); &#125;&#125;public abstract class AbstractWhiteHuman implements Human &#123; @Override public void getColor() &#123; System.out.println(&quot;白色人种&quot;); &#125; @Override public void talk() &#123; System.out.println(&quot;我是白色人种&quot;); &#125;&#125;public abstract class AbstractYellowHuman implements Human &#123; @Override public void getColor() &#123; System.out.println(&quot;黄色人种&quot;); &#125; @Override public void talk() &#123; System.out.println(&quot;我是黄色人种&quot;); &#125;&#125; 每个抽象类都有两个实现类， 分别实现公共的最细节、 最具体的事物： 123456789101112public class FemaleYellowHuman extends AbstractYellowHuman &#123; @Override public void getSex() &#123; System.out.println(&quot;黄种女人&quot;); &#125;&#125;public class MaleYellowHuman extends AbstractYellowHuman &#123; @Override public void getSex() &#123; System.out.println(&quot;黄种男人&quot;); &#125;&#125; 制造人类的抽象工厂类： 12345public interface HumanFactory &#123; Human createYellowHuman(); Human createWhiteHuman(); Human createBlackHuman();&#125; 制造男人和女人的具体工厂类： 123456789101112131415161718192021222324252627282930313233public class FemaleFactory implements HumanFactory &#123; @Override public Human createYellowHuman() &#123; return new FemaleYellowHuman(); &#125; @Override public Human createWhiteHuman() &#123; return new FemaleWhiteHuman(); &#125; @Override public Human createBlackHuman() &#123; return new FemaleBlackHuman(); &#125;&#125;public class MaleFactory implements HumanFactory &#123; @Override public Human createYellowHuman() &#123; return new MaleYellowHuman(); &#125; @Override public Human createWhiteHuman() &#123; return new MaleWhiteHuman(); &#125; @Override public Human createBlackHuman() &#123; return new MaleBlackHuman(); &#125;&#125; 场景类的调用: 12345678910HumanFactory maleHumanFactory = new MaleFactory();HumanFactory femaleHumanFactory = new FemaleFactory();Human maleYellowHuman = maleHumanFactory.createYellowHuman();Human femaleYellowHuman = femaleHumanFactory.createYellowHuman();femaleYellowHuman.getColor();femaleYellowHuman.talk();femaleYellowHuman.getSex();maleYellowHuman.getColor();maleYellowHuman.talk();maleYellowHuman.getSex();","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"创建型模式","slug":"设计模式/创建型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E5%88%9B%E5%BB%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"原型模式","date":"2016-01-02T07:08:20.000Z","path":"blog/设计模式/创建型模式/原型模式/","text":"用一个已经创建的实例作为原型，通过复制该原型对象来创建一个和原型相同或相似的新对象。用这种方式创建对象非常高效，无须知道对象创建的细节。 在实际项目中，原型模式很少单独出现，一般是和工厂方法模式一起出现， 通过clone的方法创建一个对象，然后由工厂方法提供给调用者。 原型模式简单程度仅次于单例模式和迭代器模式，Java中的Object类提供了浅克隆的clone()方法，具体原型类只要实现**Cloneable接口就可实现对象的浅克隆。Cloneable 接口只是一个标记**作用， 在JVM中具有这个标记的对象才有可能被拷贝。 原型模式的克隆分为 浅克隆 和 深克隆浅克隆：创建一个新对象，新对象的属性和原来对象 完全相同，对于非基本类型属性，仍指向原有属性所指向的对象的内存地址。 12345678910111213public class Thing implements Cloneable &#123; private ArrayList&lt;String&gt; arrayList = new ArrayList&lt;String&gt;(); @Override public Thing clone() &#123; Thing thing = null; try &#123; thing = (Thing) super.clone(); &#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace(); &#125; return thing; &#125;&#125; 深克隆：创建一个新对象，属性中引用的其他对象 也会被克隆，不再指向原有对象地址。 1234567891011121314public class Thing implements Cloneable &#123; private ArrayList&lt;String&gt; arrayList = new ArrayList&lt;String&gt;(); @Override public Thing clone() &#123; Thing thing = null; try &#123; thing = (Thing) super.clone(); thing.arrayList = (ArrayList&lt;String&gt;)this.arrayList.clone(); &#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace(); &#125; return thing; &#125;&#125; 对象的clone与对象内的final关键字是有冲突的 ，要使用clone方法， 类的成员变量上不要增加final关键字。 优点Java自带的原型模式基于内存二进制流的复制，在性能上比直接new一个对象更加优良，特别是要在一个循环体内产生大量的对象时, 可以使用深克隆方式保存对象的状态，使用原型模式将对象复制一份，并将其状态保存起来，简化了创建对象的过程，以便在需要的时候使用。 逃避构造函数的约束，直接在内存中拷贝， 构造函数是不会执行的 缺点需要为每一个类都配置一个**clone**方法, clone 方法位于类的内部，当对已有类进行改造的时候，需要修改代码，违背了开闭原则当实现深克隆时，需要编写较为复杂的代码，而且当对象之间存在多重嵌套引用时，为了实现深克隆，每一层对象对应的类都必须支持深克隆，实现起来会比较麻烦。 应用场景 对象之间相同或相似，即只是个别的几个属性不同的时候, 创建对象成本较大，例如初始化时间长，占用CPU太多，或者占用网络资源太多等，需要优化资源, 创建一个对象需要繁琐的数据准备或访问权限等，需要提高性能或者提高安全性, 系统中大量使用该类对象，且各个调用者都需要给它的属性重新赋值 一个对象需要提供给其他对象访问， 而且各个调用者可能都需要修改其值时， 可以考虑使用原型模式拷贝多个对象供调用者使用 JDK源码中 ArrayList的应用： 1234567891011public Object clone() &#123; try &#123; ArrayList&lt;?&gt; v = (ArrayList&lt;?&gt;) super.clone(); v.elementData = Arrays.copyOf(elementData, size); v.modCount = 0; return v; &#125; catch (CloneNotSupportedException e) &#123; // this shouldn&#x27;t happen, since we are Cloneable throw new InternalError(e); &#125;&#125;","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"创建型模式","slug":"设计模式/创建型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E5%88%9B%E5%BB%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"单例模式","date":"2016-01-02T06:08:20.000Z","path":"blog/设计模式/创建型模式/单例模式/","text":"单例模式的核心代码就是将构造方法私有化，只有一个实例，自己负责创建自己的对象即自行实例化，提供一种访问其唯一对象的方式，可直接访问，不需要实例化该类的对象。 优点： 内存中只有一个实例，减少了内存开支，特别是一个对象需要频繁创建和销毁时。 只生成一个实例，减少了系统性能开销，当一个对象的产生需要比较多的资源时，如读取配置、产生其他依赖对象时，则可通过在应用启动时直接产生一个单例对象，永久驻留内存的方式解决。 可以避免对资源的多重占用，例如写文件动作，避免了对同一个资源文件同事写操作。 可以在系统设置全局访问点，优化和共享资源访问。如设计一个单例类，负责所有数据表的映射处理。 缺点： 单例模式一般没有接口，扩展困难。单例模式要求自行实例化，且提供单一实例，接口和抽象类是不能被实例化的。 对测试不利，单例模式未开发完，是不能进行测试的，没有接口也不能使用mock方式来进行测试。 与单一职责原则冲突。 懒汉式实例在使用时才去创建，用的时候才去检查有没有实例。有线程安全和线程不安全两种写法，区别就是synchronized关键字。下面这种写法存在线程安全问题，在并发获取实例时，可能会存在创建多个实例的情况。 123456789101112public class LazySingleton &#123; private static LazySingleton instance; private LazySingleton() &#123;&#125; public static LazySingleton getInstance() &#123; if (instance == null) &#123; instance = new LazySingleton(); &#125; return instance; &#125;&#125; 饿汉式在类加载时实例被创建。实现简单且没有线程安全的问题，可能在还不需要此实例的时候就已经把实例创建出来了，浪费内存空间，没起到lazy loading的效果。 123456789public class HungrySingleton &#123; private static HungrySingleton instance = new HungrySingleton(); private HungrySingleton() &#123;&#125; private static HungrySingleton getInstance() &#123; return instance; &#125;&#125; 双检锁双重校验锁，综合了懒汉式和饿汉式两者的优缺点。特点在synchronized关键字内外都加了一层 if 条件判断，既保证了线程安全，又比直接上锁提高了执行效率，还节省了内存空间。这里还用到了volatile关键字来修饰instance，其最关键的作用是防止指令重排。 12345678910111213141516public class Singleton &#123; private static volatile Singleton instance; private Singleton()&#123;&#125; public static Singleton getInstance()&#123; if (instance == null) &#123; synchronized (Singleton.class) &#123; if (instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; 静态内部类静态内部类的方式效果类似双检锁，但实现更简单且线程安全。同时静态内部类不会在Singleton类加载时就加载，而是在调用getInstance()方法时才进行加载，达到了懒加载的效果。但这种方式只适用于静态域的情况，双检锁方式可在实例域需要延迟初始化时使用。 1234567891011public class Singleton &#123; private static class SingletonHolder &#123; private static final Singleton INSTANCE = new Singleton(); &#125; private Singleton()&#123;&#125; public static Singleton getInstance() &#123; return SingletonHolder.INSTANCE; &#125;&#125; 枚举枚举的方式是比较少见的一种实现方式，却更简洁清晰。还自动支持序列化机制，绝对防止多次实例化。单元素的枚举类型已经成为实现Singleton的最佳方法。 123456789101112131415161718public class Singleton &#123; private enum SingletonEnum &#123; INSTANCE; private Singleton singleton; private SingletonEnum() &#123; singleton = new Singleton(); &#125; public Singleton getInstance() &#123; return singleton; &#125; &#125; public static Singleton getInstance() &#123; return SingletonEnum.INSTANCE.getInstance(); &#125;&#125; 使用场景在系统中要求一个类有且仅有一个对象，若出现多个对象会出现副作用，可以采用单例模式。 要求生成唯一序列号的环境 在整个项目中需要一个共享访问点或共享数据 创建一个对象需要消耗的资源过多，如访问IO和数据库等资源 需要定义大量的静态常量和静态方法的环境 Spring中典型应用1234567891011121314151617181920212223242526/** Cache of singleton objects: bean name to bean instance. */private final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;&gt;(256);/** Cache of singleton factories: bean name to ObjectFactory. */private final Map&lt;String, ObjectFactory&lt;?&gt;&gt; singletonFactories = new HashMap&lt;&gt;(16);/** Cache of early singleton objects: bean name to bean instance. */private final Map&lt;String, Object&gt; earlySingletonObjects = new HashMap&lt;&gt;(16);protected Object getSingleton(String beanName, boolean allowEarlyReference) &#123; Object singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) &#123; synchronized (this.singletonObjects) &#123; singletonObject = this.earlySingletonObjects.get(beanName); if (singletonObject == null &amp;&amp; allowEarlyReference) &#123; ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName); if (singletonFactory != null) &#123; singletonObject = singletonFactory.getObject(); this.earlySingletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); &#125; &#125; &#125; &#125; return singletonObject;&#125;","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"创建型模式","slug":"设计模式/创建型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E5%88%9B%E5%BB%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"SOLID基本原则","date":"2016-01-01T06:08:20.000Z","path":"blog/设计模式/SOLID基本原则/","text":"6大设计基本原则：单一职责原则、里氏替换原则、依赖倒置原则、接口隔离原则、迪米特法则、开闭原则 单一职责原则SRP​ 单一职责原则提出了一个编写程序的标准，用职责或变化原因来衡量接口或类设计得是否优良，但职责和变化原因都是不可度量得，因项目和环境而异。单一职责适用于接口、类、方法。定义：应该有且仅有一个原因引起类的变更。优点：类复杂性降低，实现职责清晰明确；可读性高；可维护性高；变更引起的风险低； 里氏替换原则LSP定义：每一个类型为S的对象s，都有类型为T的对象t，使得以T定义的所有程序P在所有的对象s都代替成t时，程序P的行为无变化，则类型S是类型T的子类；所有引用基类的地方必须能透明的使用其子类的对象。 子类必须完全实现父类的方法：若子类不能完全实现父类方法，或某些方法在子类种已发生畸变，建议断开父子继承关系。 子类可以有自己的个性：子类出现的地方父类未必能出现 覆盖或实现父类方法时输入参数可以被放大 覆写或实现父类的方法时输出结果可以被缩小 在类中调用其他类时务必使用父类或接口，否则即是违背LSP原则。 依赖倒置原则DIP​ 采用依赖倒置原则可以减少类间的耦合性，提高系统的稳定性，降低并行开发引起的风险，提高代码的可读性和可维护性。可以通过依赖倒置原则涉及的接口或抽象类对实现类进行约束，可减少需求变化引起的工作量剧增的情况，可让维护人员轻松地扩展和维护，是实现开闭原则的重要途径。TDD测试驱动开发模式就是依赖倒置原则的最高级应用。 定义：高层模块不应该依赖底层模块两者都应该依赖其抽象；抽象不应该依赖细节；细节应该依赖抽象；表现：模块间依赖通过抽象发生，实现类之间不发生直接的依赖关系，其依赖关系是通过接口或抽象类产生；接口和抽象类不依赖于实现类；实现类依赖接口或抽象类； 依赖的三种写法： 构造函数传递依赖对象，也叫构造函数注入 Setter方法传递依赖对象，也叫Setter依赖注入 接口声明依赖对象，也叫接口注入 依赖倒置原则的本质就是通过抽象（接口或抽象类）使各个类或模块的实现彼此独立，不互相影响，实现模块间的松耦合。 每个类尽量都有接口或抽象类，或抽象类和接口两者都具备 变量的表面类型尽量是接口或抽象类 任何类都不应该从具体类派生 尽量不要覆写基类的方法 结合里氏替换原则使用 接口隔离原则ISP定义：客户端不应该依赖它不需要的接口；类间的依赖关系应该建立在最小的接口上。建立单一的接口，不要建立臃肿庞大的接口； 接口尽量小 接口要高内聚：提高接口、类、模块的处理能力，减少对外的交互 定制服务，单独为一个个体提供优良的服务 接口设计要有限度 根据接口隔离原则拆分接口时，首先必须满足单一职责原则。接口和类尽量使用原子接口或原子类来组装。 一个接口只服务玉一个子模块或业务 通过业务逻辑压缩接口中的public方法 已经被污染的接口，尽量去修改，若变更风险较大，则采用适配器模式进行转化处理 了解环境，拒绝盲从 迪米特法则LD也称最少知识原则：一个对象应该对其他对象有最少的了解，对需要耦合或调用的类知道越少越好。 只和朋友交流：类与类间的关系是建立在类之间而不是方法间，一个方法尽量不引入一个类中不存在的对象 朋友间也是有距离的：尽量不对外公布太多public方法和非静态得public变量，尽量内敛 是自己的就是自己的：若一个方法放在本类中，即不增加类间关系，也对本类不产生负面影响，那就放置在本类中。 谨慎使用Serializable 两个对象之间的耦合就成为朋友关系，朋友关系类型很多如组合、聚合、依赖等。 注：朋友类的定义，出现在成员变量、方法输入输出参数中的类称为成员朋友类，出现在方法体内部的类不属于朋友类。 迪米尔法则要求类羞涩一点，尽量不对外公布太多public方法和非静态得public变量，尽量内敛，多使用private、package-private、protected等访问权限。类公开的public属性或方法越多，修改时涉及得面也就越大，变更引起得风险扩散也就越大。迪米特法则核心观念是类间解耦、弱耦合。 缺点：会产生大量中转或跳转类，导致系统的复杂性提高，同时也为维护带来了难度。使用时请反复权衡，既做到让结构清晰，又做到高内聚底耦合。 开闭原则OCP一个软件实体如类、模块和函数应该对扩展开放，对修改关闭。应该通过扩展来实现变化，而不是通过修改已有代码来实现变化。 开闭原则对扩展开放，对修改关闭，并不意味着不做任何修改，底层模块的变更，必然要有更高层模块进行耦合。 可把变化大致分为三类： 逻辑变化：可以通过修改原有类中的方法来完成，前提是所有依赖或者关联类都按照相同的逻辑处理。 子模块变化：底层模块变化必然引起高层模块变化，因此通过扩展完成变化时，高层模块修改是必然的。 可见视图变化 开闭原则是最基础的一个原则，前五个原则都是开闭原则的具体形态，前五个原则就是指导设计的工具和方法，而开闭原则才是精神领袖。 开闭原则对测试的影响在比较重要的方法，测试方法都会很多，可能测试逻辑都很复杂，若要通过修改修改一个方法或多个方法来完成变化，基本上测试用例都得重新写。所以需要通过扩展来实现业务逻辑而不是修改。 开闭原则可以提高复用性在面向对象设计中，所有的逻辑都是从原子逻辑组合而来，而不是在一个类中独立实现一个业务逻辑。颗粒度越小，被复用的可能性就越大。避免相同的逻辑分撒在多个角落，缩小颗粒度，直到一个逻辑不可再拆分为止。 开闭原则可以提高可维护性面向对象开发的要求开闭原则应用抽象约束通过接口或抽象类可以约束一组可能变化的行为，并且能够实现对扩展开放： 通过接口或抽象类约束扩展，对扩展边界限定，不允许出现在接口或抽象类中不存在的public方法 参数类型、引用对象尽量使用接口或抽象类，而不是实现类 抽象层尽量保持稳定 元数据（metadata）控制模块行为尽量使用元数据来控制程序行为，减少重复开发，如login方法中提供的先检查IP地址是否在允许访问的列表中，然后在确定是否需要到数据库中验证密码，表达的极致其实就是控制反转，如Spring的IoC容器。 注：元数据是用来描述环境和数据的数据，通俗的说就是配置参数。 制定项目章程对于项目来说约定优于配置。 封装变化对变化的封装：将相同的变化封装到一个接口或抽象类中，将不同的变化封装到不同的接口或抽象类中，不应该有两个不同的变化出现在同一个接口或抽象类中。 封装变化，也就是受保护的变化，找出预计有变化或不稳定的点。","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"设计模式概览","date":"2016-01-01T02:08:20.000Z","path":"blog/设计模式/设计模式概览/","text":"设计模式分类23种设计模式大体上可以分为三类： 创建型模式（5个）：对象实例化的模式，用于解耦对象的实例化过程； 结构型模式（7个）：把类或对象结合在一起形成一个更大的结构； 行为型模式（11个）：类和对象如何交互，及划分职责和算法； 各种模式的关键点：创建型模式：单例模式：某个类只能生成一个实例，该类提供了一个全局访问点供外部获取该实例。简单工厂：一个工厂类根据传入的参量决定创建出那一种产品类的实例。工厂方法：定义一个用于创建产品的接口，由子类决定生产什么产品。抽象工厂：提供一个创建产品族的接口，其每个子类可以生产一系列相关的产品。建造者模式：封装一个复杂对象的构建过程，并可以按步骤构造。原型模式：将一个对象作为原型，通过对其进行复制而克隆出多个和原型类似的新实例。 结构型模式适配器模式：将一个类的接口转换成客户希望的另外一个接口，使得原本由于接口不兼容而不能一起工作的那些类能一起工作。组合模式：将对象组合成树状层次结构，使用户对单个对象和组合对象具有一致的访问性。装饰模式：动态的给对象增加一些职责，即增加其额外的功能。代理模式：为某对象提供一种代理以控制对该对象的访问。即客户端通过代理间接地访问该对象，从而限制、增强或修改该对象的一些特性。亨元模式：运用共享技术来有效地支持大量细粒度对象的复用。外观模式：为多个复杂的子系统提供一个一致的接口，使这些子系统更加容易被访问。桥接模式：将抽象与实现分离，使它们可以独立变化。它是用组合关系代替继承关系来实现，从而降低了抽象和实现这两个可变维度的耦合度。 行为型模式：模板模式：定义一个操作中的算法骨架，而将算法的一些步骤延迟到子类中，使得子类可以不改变该算法结构的情况下重定义该算法的某些特定步骤。解释器模式：提供如何定义语言的文法，以及对语言句子的解释方法，即解释器。策略模式：定义了一系列算法，并将每个算法封装起来，使它们可以相互替换，且算法的改变不会影响使用算法的客户。状态模式：允许一个对象在其内部状态发生改变时改变其行为能力。观察者模式：多个对象间存在一对多关系，当一个对象发生改变时，把这种改变通知给其他多个对象，从而影响其他对象的行为。备忘录模式：在不破坏封装性的前提下，获取并保存一个对象的内部状态，以便以后恢复它。中介者模式：定义一个中介对象来简化原有对象之间的交互关系，降低系统中对象间的耦合度，使原有对象之间不必相互了解。命令模式：将一个请求封装为一个对象，使发出请求的责任和执行请求的责任分割开。访问者模式：在不改变集合元素的前提下，为一个集合中的每个元素提供多种访问方式，即每个元素有多个访问者对象访问。责任链模式：把请求从链中的一个对象传到下一个对象，直到请求被响应为止。通过这种方式去除对象之间的耦合。迭代器模式：提供一种方法来顺序访问聚合对象中的一系列数据，而不暴露聚合对象的内部表示。 23种设计模式间的关系：","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]}],"categories":[{"name":"DB","slug":"DB","permalink":"http://example.com/categories/DB/"},{"name":"mysql","slug":"DB/mysql","permalink":"http://example.com/categories/DB/mysql/"},{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"ElasticSearch","slug":"工具和中间件/搜索引擎技术/ElasticSearch","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/ElasticSearch/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"},{"name":"数据结构和算法","slug":"数据结构和算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/"},{"name":"索引","slug":"DB/索引","permalink":"http://example.com/categories/DB/%E7%B4%A2%E5%BC%95/"},{"name":"分库分表","slug":"DB/分库分表","permalink":"http://example.com/categories/DB/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"},{"name":"MongoDB","slug":"DB/MongoDB","permalink":"http://example.com/categories/DB/MongoDB/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"},{"name":"SpringBoot","slug":"Spring/SpringBoot","permalink":"http://example.com/categories/Spring/SpringBoot/"},{"name":"Test","slug":"Test","permalink":"http://example.com/categories/Test/"},{"name":"RocketMQ","slug":"工具和中间件/消息队列/RocketMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RocketMQ/"},{"name":"RabbitMQ","slug":"工具和中间件/消息队列/RabbitMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/"},{"name":"Activemq","slug":"工具和中间件/消息队列/Activemq","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Activemq/"},{"name":"Kafka","slug":"工具和中间件/消息队列/Kafka","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Kafka/"},{"name":"Solr","slug":"工具和中间件/搜索引擎技术/Solr","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/Solr/"},{"name":"Lucene","slug":"工具和中间件/搜索引擎技术/Lucene","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/Lucene/"},{"name":"Redis","slug":"Cloud/Redis","permalink":"http://example.com/categories/Cloud/Redis/"},{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"行为型模式","slug":"设计模式/行为型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"},{"name":"结构型模式","slug":"设计模式/结构型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E7%BB%93%E6%9E%84%E5%9E%8B%E6%A8%A1%E5%BC%8F/"},{"name":"创建型模式","slug":"设计模式/创建型模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E5%88%9B%E5%BB%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"springCloud","slug":"springCloud","permalink":"http://example.com/tags/springCloud/"},{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"http://example.com/tags/ElasticSearch/"},{"name":"Kibana","slug":"Kibana","permalink":"http://example.com/tags/Kibana/"},{"name":"JAVA数据结构和算法","slug":"JAVA数据结构和算法","permalink":"http://example.com/tags/JAVA%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/"},{"name":"索引","slug":"索引","permalink":"http://example.com/tags/%E7%B4%A2%E5%BC%95/"},{"name":"数据库优化","slug":"数据库优化","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/tags/MySQL/"},{"name":"MongoDB","slug":"MongoDB","permalink":"http://example.com/tags/MongoDB/"},{"name":"DB","slug":"DB","permalink":"http://example.com/tags/DB/"},{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"},{"name":"Spring, IOC","slug":"Spring-IOC","permalink":"http://example.com/tags/Spring-IOC/"},{"name":"SpringBoot, 限流, 熔断","slug":"SpringBoot-限流-熔断","permalink":"http://example.com/tags/SpringBoot-%E9%99%90%E6%B5%81-%E7%86%94%E6%96%AD/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://example.com/tags/SpringBoot/"},{"name":"Spring, AOP","slug":"Spring-AOP","permalink":"http://example.com/tags/Spring-AOP/"},{"name":"Test","slug":"Test","permalink":"http://example.com/tags/Test/"},{"name":"RocketMQ","slug":"RocketMQ","permalink":"http://example.com/tags/RocketMQ/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://example.com/tags/RabbitMQ/"},{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"http://example.com/tags/ActiveMQ/"},{"name":"Kafka","slug":"Kafka","permalink":"http://example.com/tags/Kafka/"},{"name":"Solr","slug":"Solr","permalink":"http://example.com/tags/Solr/"},{"name":"Lucene","slug":"Lucene","permalink":"http://example.com/tags/Lucene/"},{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"},{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]}