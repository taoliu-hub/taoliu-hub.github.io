{"pages":[{"title":"About","date":"2022-05-12T08:53:51.333Z","path":"about/index.html","text":"Welcome TaoLiu’s Blog"},{"title":"Categories","date":"2022-05-12T08:42:52.543Z","path":"categories/index.html","text":""},{"title":"Tags","date":"2022-05-12T08:42:52.567Z","path":"tags/index.html","text":""}],"posts":[{"title":"ElasticSearch-Springboot","date":"2022-01-02T06:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/ElasticSearch/ElasticSearch-Springboot/","text":"版本问题springboot 有一个 spring data 组件，可以用来连接各种数据源。 用来连接 elasticsearch 的是 spring-data-elasticsearch。 启动 elasticsearch运行elasticsearch.bat, 启动后, 可以看到左上角的版本号。 创建 springboot 项目:pom.xml各种jar包，主要是 spring-boot-starter-data-elastisearch 这个 jar包。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.howToElasticSearch&lt;/groupId&gt; &lt;artifactId&gt;springboot&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;springboot&lt;/name&gt; &lt;description&gt;springboot&lt;/description&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.9.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- servlet依赖. --&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- tomcat的支持.--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt; &lt;artifactId&gt;tomcat-embed-jasper&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;!-- 这个需要为 true 热部署才有效 --&gt; &lt;/dependency&gt; &lt;!-- mysql--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.21&lt;/version&gt; &lt;/dependency&gt; &lt;!-- elastisearch依赖包 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-elasticsearch&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; Category.javaCategory 实体类，其中的 @Document就表明了要连接到 ElasticSearch 的哪个索引和哪个 type 上 @Document(indexName &#x3D; “howToElasticSearch”,type &#x3D; “category”)索引相当于就是数据库，type 相当于就是表 1234567891011121314151617181920212223package cn.peach.springboot.pojo; import org.springframework.data.elasticsearch.annotations.Document; @Document(indexName = &quot;howToElasticSearch&quot;,type = &quot;category&quot;)public class Category &#123; private int id; private String name; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; &#125; 控制类：CategoryController.java控制类提供 CRUD 一套 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889package cn.peach.springboot.web;import java.text.SimpleDateFormat;import java.util.Date;import org.elasticsearch.index.query.QueryBuilders;import org.elasticsearch.index.query.functionscore.FunctionScoreQueryBuilder;import org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.domain.Page;import org.springframework.data.domain.PageRequest;import org.springframework.data.domain.Pageable;import org.springframework.data.domain.Sort;import org.springframework.data.elasticsearch.core.query.NativeSearchQueryBuilder;import org.springframework.data.elasticsearch.core.query.SearchQuery;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam;import cn.peach.springboot.dao.CategoryDAO;import cn.peach.springboot.pojo.Category; @Controllerpublic class CategoryController &#123; @Autowired CategoryDAO categoryDAO; //每页数量 @GetMapping(&quot;/listCategory&quot;) public String listCategory(Model m,@RequestParam(value = &quot;start&quot;, defaultValue = &quot;0&quot;) int start,@RequestParam(value = &quot;size&quot;, defaultValue = &quot;5&quot;) int size)&#123; String query = &quot;商品&quot;; //查询条件，但是并未使用，放在这里，为的是将来使用，方便参考，知道如何用 SearchQuery searchQuery=getEntitySearchQuery(start,size,query); Page&lt;Category&gt; page = categoryDAO.search(searchQuery); m.addAttribute(&quot;page&quot;, page); return &quot;listCategory&quot;; &#125; private SearchQuery getEntitySearchQuery(int start, int size, String searchContent) &#123; FunctionScoreQueryBuilder functionScoreQueryBuilder = QueryBuilders.functionScoreQuery() .add(QueryBuilders.matchAllQuery(), //查询所有 ScoreFunctionBuilders.weightFactorFunction(100))// 查询条件，但是并未使用，放在这里，为的是将来使用，方便参考，知道如何用// .add(QueryBuilders.matchPhraseQuery(&quot;name&quot;, searchContent),// ScoreFunctionBuilders.weightFactorFunction(100)) //设置权重分 求和模式 .scoreMode(&quot;sum&quot;) //设置权重分最低分 .setMinScore(10); // 设置分页 Sort sort = new Sort(Sort.Direction.DESC,&quot;id&quot;); Pageable pageable = new PageRequest(start, size,sort); return new NativeSearchQueryBuilder() .withPageable(pageable) .withQuery(functionScoreQueryBuilder).build(); &#125; @RequestMapping(&quot;/addCategory&quot;) public String addCategory(Category c) throws Exception &#123; int id = currentTime(); c.setId(id); categoryDAO.save(c); return &quot;redirect:listCategory&quot;; &#125; private int currentTime() &#123; SimpleDateFormat sdf = new SimpleDateFormat(&quot;MMddHHmmss&quot;); String time= sdf.format(new Date()); return Integer.parseInt(time); &#125; @RequestMapping(&quot;/deleteCategory&quot;) public String deleteCategory(Category c) throws Exception &#123; categoryDAO.delete(c); return &quot;redirect:listCategory&quot;; &#125; @RequestMapping(&quot;/updateCategory&quot;) public String updateCategory(Category c) throws Exception &#123; categoryDAO.save(c); return &quot;redirect:listCategory&quot;; &#125; @RequestMapping(&quot;/editCategory&quot;) public String ediitCategory(int id,Model m) throws Exception &#123; Category c= categoryDAO.findOne(id); m.addAttribute(&quot;c&quot;, c); return &quot;editCategory&quot;; &#125;&#125; 配置文件：application.properties配置 jsp 作为视图配置spring端口 为8080配置 elastic链接地址为 127.0.0.1:9300 1234spring.mvc.view.prefix=/WEB-INF/jsp/spring.mvc.view.suffix=.jspserver.port=8080spring.data.elasticsearch.cluster-nodes = 127.0.0.1:9300 启动并测试:运行 Application.java 启动项目, 接着访问地址： 1http://127.0.0.1:8080/listCategory kibana查看数据启动 kibana 并访问: http://127.0.0.1:5601, 选择索引刚开始是没有选定索引的，所以要自己指定索引。 把默认勾选的 Index contians time-based evens 去掉 输入 howToElasticSearch 点击 Create 按钮 查看数据然后点击上面的Discover，就可以看到左边是当前的索引 :howToElasticSearch. 右边就是数据了。","tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"http://example.com/tags/ElasticSearch/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"ElasticSearch","slug":"工具和中间件/搜索引擎技术/ElasticSearch","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/ElasticSearch/"}]},{"title":"ElasticSearch工具-Kibana","date":"2022-01-02T05:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/ElasticSearch/ElasticSearch工具-Kibana/","text":"Kibana 是什么Kibana 是一个针对 ElasticSearch 的开源分析及可视化平台，用来搜索、查看交互存储在 ElasticSearch 索引中的数据。使用 Kibana，可以通过各种图表进行高级数据分析及展示。 Kibana 是在ElasticSearch 有了相当多的数据之后，进行分析这些数据用的工具。 但是现在还么有数据呀，为什么就要介绍这个工具呢？ 因为Kibana 里面有一个叫做 Dev Tools的，可以很方便地以Restful 风格向 ElasticSearch 服务器提交请求。Kibana 让海量数据更容易理解。它操作简单，基于浏览器的用户界面可以快速创建仪表板（DashBoard）实时显示 ElasticSearch 查询动态。 官网下载(https://www.elastic.co/cn/kibana/)下载rar，并解压。 假设下载路径在：C:\\Users\\X7TI运行启动中的 kibana.bat 1C:\\Users\\X7TI\\Downloads\\kibana-6.2.2-windows-x86_64\\bin\\kibana.bat 验证启动浏览器输入 http://localhost:5601/app/kibana#/dev_tools/console?_g=(), 打开当前的开发工具 Dev Tools 界面 运行测试在控制台里输入 1GET /_cat/health?v 然后点击绿色箭头进行运行，就可以看到右侧出现查询结果GET &#x2F;_cat&#x2F;health?v 这个命令用来查看服务器状态（健康度）， green 表示一切OK。 索引概念索引相当于就是一个数据库服务器上的某个数据库，所以索引也可以看成是Elastic Search里的某个数据库 Restful 风格管理索引，管理无非就是增删改查，即 CRUD。在使用Restful风格之前，进行所以管理需要这样的访问地址： add,delete,update,get 等不同的访问地址来表示不同的业务请求。但是使用Restful 风格，就通过提交不同的method 来表示 CRUD： PUT 表示增加 GET 表示获取 DELETE 表示删除 POST表示更新 增加索引:在 kibana 控制台中输入如下命令：打开 kibana控制台： 1http://localhost:5601/app/kibana#/dev_tools/console?_g=() 运行如下命令： 1PUT /howToKibana?pretty 返回： 12345&#123; &quot;acknowledged&quot;: true, &quot;shards_acknowledged&quot;: true, &quot;index&quot;: &quot;howToKibana&quot;&#125; 表示创建成功了，索引名称是howToKibana注： 要运行kibana控制台，需要先安装kibana: 查询运行如下命令： 1GET /_cat/indices?v 可以观察到新建立的索引 删除运行如下命令：DELETE &#x2F;howToKibana?pretty再运行 1GET /_cat/indices?v 可以观察到索引howToKibana被删除了，右侧一个索引也看不到了 修改修改两种方式， 第一种还是用PUT，PUT本来用来做增加的，但是当输入的id已经存在的时候，就自动变成修改功能了; 第二种使用 POST，这才是正规的修改，其实和第一种效果一样的。 批量导入批量导入两条数据在 kibana 控制台中输入如下命令：打开 kibana控制台： 1http://localhost:5601/app/kibana#/dev_tools/console?_g=() 运行如下命令： 12345POST _bulk&#123;&quot;index&quot;:&#123;&quot;_index&quot;:&quot;howToKibana&quot;,&quot;_type&quot;:&quot;product&quot;,&quot;_id&quot;:10001&#125;&#125;&#123;&quot;code&quot;:&quot;540785126782&quot;,&quot;price&quot;:398,&quot;name&quot;:&quot;房屋卫士自流平美缝剂瓷砖地砖专用双组份真瓷胶防水填缝剂镏金色&quot;,&quot;place&quot;:&quot;上海&quot;,&quot;category&quot;:&quot;品质建材&quot;&#125;&#123;&quot;index&quot;:&#123;&quot;_index&quot;:&quot;howToKibana&quot;,&quot;_type&quot;:&quot;product&quot;,&quot;_id&quot;:10002&#125;&#125;&#123;&quot;code&quot;:&quot;24727352473&quot;,&quot;price&quot;:21.799999237060547,&quot;name&quot;:&quot;艾瑞泽手工大号小号调温热熔胶枪玻璃胶枪硅胶条热溶胶棒20W-100W&quot;,&quot;place&quot;:&quot;山东青岛&quot;,&quot;category&quot;:&quot;品质建材&quot;&#125; 注： 要运行kibana控制台，需要先安装kibana并启动 注： 其中的product在elastic search里是type的概念，相当于数据库里的表，这里就相当于向 product 表里插入了一条数据 验证插入的数据使用命令查询howToKibana 索引里所有的数据： 1234GET /howToKibana/_search&#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;&#125; 可以看到刚刚批量插入的两条数据.","tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"http://example.com/tags/ElasticSearch/"},{"name":"Kibana","slug":"Kibana","permalink":"http://example.com/tags/Kibana/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"ElasticSearch","slug":"工具和中间件/搜索引擎技术/ElasticSearch","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/ElasticSearch/"}]},{"title":"ElasticSearch进阶","date":"2022-01-02T04:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/ElasticSearch/ElasticSearch进阶/","text":"分值计算首先根据用户query条件,过滤出包含指定term的doc,Field-length norm即field长度越长相关度越弱。 123query &quot;hello world&quot; --&gt; hello / world / hello &amp; worldbool --&gt; must/must not/should --&gt; 过滤 --&gt; 包含 / 不包含 / 可能包含doc --&gt; 不打分数 --&gt; 正或反 true or false --&gt; 为了减少后续要计算的doc的数量,提升性能 relevance score算法：计算出一个 索引中文本 与 搜索文本 之间 关联匹配程度,ES使用 term frequency/inverse document frequency算法 简称为 TF/IDF 算法。 Term frequency 即 搜索文本 中 各个词条 在 field 文本中 出现次数,次数越多越相关 。Inverse document frequency 即 搜索文本 中 各个词条 在 整个索引所有文档 中 出现次数,出现次数越多越不相关 。 向量空间模型vector space model向量空间模型,多个term对一个doc的总分数,es会根据查询字符串在所有doc中的评分情况,计算出一个 query vector 即 query向量,会给每一个doc,拿每个term计算出一个分数来。每个doc vector计算出对 query vector 的 弧度,最后基于该弧度给出一个doc相对于query中多个term的总分数,弧度越大分数越低,弧度越小分数越高 。若是多个term,那么就是线性代数来计算,无法用图表示若查询条件字符串为hello world,hello这个term,给的基于所有doc的一个评分就是3,world这个term,给的基于所有doc的一个评分就是6,则 query向量 为 [3, 6],若3个doc一个包含hello,一个包含world,一个包含hello和world,doc向量分别为[3, 0]、[0, 6]、[3, 6] 分词器工作流程首先进行 normalization切分词语,将目标文本拆分成单个单词,同时对每个单词进行 normalization时态转换单复数转换、分词器recall、搜索时召回率、增加能搜索到的结果的数量 。分词器将文本进行各种处理,最后处理好的结果才会用来建立倒排索引 。 123character filter：在一段文本进行分词之前,先进行预处理,如过滤html标签（&lt;span&gt;hello&lt;span&gt; --&gt; hello）,&amp; --&gt; and (I&amp;you --&gt; I and you)tokenizer：分词,hello you and me --&gt; hello, you, and, metoken filter：lowercase,stop word,synonymom,liked --&gt; like,Tom --&gt; tom,a/the/an --&gt; 干掉,small --&gt; little 对于默认的 standard分词器 ： standard tokenizer： 以单词边界进行切分 standard token filter：什么都不做 lowercase token filter：将所有字母转换为小写 stop token filer：默认被禁用,移除停用词,比如a the it等等1234567891011121314151617181920212223242526272829303132333435363738394041424344454647POST _analyze&#123; &quot;analyzer&quot;: &quot;standard&quot;, &quot;text&quot;: &quot;Set the shape to semi-transparent by calling set_trans(5)&quot;&#125;PUT /my_index&#123; &quot;settings&quot;: &#123; &quot;analysis&quot;: &#123; &quot;analyzer&quot;: &#123; &quot;es_std&quot;: &#123; &quot;type&quot;: &quot;standard&quot;, &quot;stopwords&quot;: &quot;_english_&quot; // 启用english停用词token filter &#125; &#125; &#125; &#125;&#125;GET /my_index/_analyze&#123; &quot;analyzer&quot;: &quot;standard&quot;, &quot;text&quot;: &quot;a dog is in the house&quot;&#125;GET /my_index/_analyze&#123; &quot;analyzer&quot;: &quot;es_std&quot;, &quot;text&quot;:&quot;a dog is in the house&quot;&#125;PUT /my_index // 定制化分词器&#123; &quot;settings&quot;: &#123; &quot;analysis&quot;: &#123; &quot;char_filter&quot;: &#123;&quot;&amp;_to_and&quot;: &#123;&quot;type&quot;: &quot;mapping&quot;,&quot;mappings&quot;: [&quot;&amp;=&gt; and&quot;]&#125;&#125;, &quot;filter&quot;: &#123;&quot;my_stopwords&quot;: &#123;&quot;type&quot;: &quot;stop&quot;,&quot;stopwords&quot;: [&quot;the&quot;,&quot;a&quot;]&#125; &#125;, &quot;analyzer&quot;: &#123; &quot;my_analyzer&quot;: &#123;&quot;type&quot;: &quot;custom&quot;,&quot;char_filter&quot;: [&quot;html_strip&quot;,&quot;&amp;_to_and&quot;],&quot;tokenizer&quot;: &quot;standard&quot;,&quot;filter&quot;: [&quot;lowercase&quot;,&quot;my_stopwords&quot;]&#125; &#125; &#125; &#125;&#125;GET /my_index/_analyze&#123; &quot;text&quot;: &quot;tom&amp;jerry are a friend in the house, &lt;a&gt;, HAHA!!&quot;, &quot;analyzer&quot;: &quot;my_analyzer&quot;&#125; IK分词器IK分词器配置文件地址为 es/plugins/ik/config,ik原生最重要的是 main.dic 和 stopword.dic 两个配置文件 IKAnalyzer.cfg.xml：用来配置自定义词库 main.dic：ik原生内置中文词库,总共有27万多条,会按照该文件中的词语去分词 quantifier.dic：单位相关的词 suffix.dic：后缀相关的词 surname.dic：中国姓氏 stopword.dic：英文停用词,停用词会在分词时被干掉,不会建立在倒排索引中 可通过在 IKAnalyzer.cfg.xml 配置文件中通过修改 &lt;entry key=&quot;ext_dict&quot;&gt;&lt;/entry&gt; 配置内容 扩展自己的词库,需重启es才能生效,还可以通过修改 &lt;entry key=&quot;ext_stopwords&quot;&gt;&lt;/entry&gt; 配置扩展停用词 。 每次在es扩展词典中,手动添加新词语,添加完都要重启es才能生效,非常麻烦,且es是分布式的,可能有数百个节点,不能每次都一个一个节点上面去修改。 IKAnalyzer.cfg.xml 配置文件中可通过 &lt;entry key=&quot;remote_ext_dict&quot;&gt;words_location&lt;/entry&gt; 和 &lt;entry key=&quot;remote_ext_stopwords&quot;&gt;words_location&lt;/entry&gt; 配置支持 远程扩展字典 。 高亮显示搜索中经常需要对搜索关键字做高亮显示,ES默认通过添加 &lt;em&gt;&lt;/em&gt;标签,在HTML中会变成红色,指定的field中若包含了搜索词,就会在那个field文本中,对搜索词进行红色高亮显示。highlight中的field必须跟 query 中field一一对齐 默认的 highlight 为 plain highlight 即 lucene highlight,在 mapping 中设置 index_options 为 offsets 使用 posting highlight 。在 mapping 中设置 term_vector 为 term_vector 使用 fast verctor highlight,对 大于1mb的field性能更高 。也可通过在查询时强制使用某种highlighter 。 一般情况下用 plain highlight 也就足够了,不需要做其他额外设置,若对高亮性能要求很高,可尝试启用 posting highlight,若 field值特别大超过了1M,则可用 fast vector highlight 。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455PUT /news_website&#123; &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123; &quot;title&quot;: &#123;&quot;type&quot;: &quot;text&quot;,&quot;analyzer&quot;: &quot;ik_max_word&quot;&#125;, &quot;content&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;index_options&quot;: &quot;offsets&quot; &#125; &#125; &#125;&#125;PUT /news_website&#123; &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123; &quot;title&quot;: &#123;&quot;type&quot;: &quot;text&quot;,&quot;analyzer&quot;: &quot;ik_max_word&quot;&#125;, &quot;content&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;term_vector&quot;: &quot;with_positions_offsets&quot; &#125; &#125; &#125;&#125;GET /news_website/_doc/_search&#123; &quot;query&quot;: &#123;&quot;match&quot;: &#123;&quot;content&quot;: &quot;文章&quot;&#125;&#125;, &quot;highlight&quot;: &#123; &quot;fields&quot;: &#123;&quot;content&quot;: &#123;&quot;type&quot;: &quot;plain&quot;&#125;&#125; &#125;&#125;GET /news_website/_doc/_search&#123; &quot;query&quot;: &#123;&quot;match&quot;: &#123;&quot;content&quot;: &quot;文章&quot;&#125;&#125;, &quot;highlight&quot;: &#123; // 设置高亮html标签,默认是&lt;em&gt;标签 &quot;pre_tags&quot;: [&quot;&lt;span color=&#x27;red&#x27;&gt;&quot;], &quot;post_tags&quot;: [&quot;&lt;/span&gt;&quot;], &quot;fields&quot;: &#123;&quot;content&quot;: &#123;&quot;type&quot;: &quot;plain&quot;&#125;&#125; &#125;&#125;GET /_search&#123; &quot;query&quot;: &#123;&quot;match&quot;: &#123;&quot;content&quot;: &quot;文章&quot;&#125;&#125;, &quot;highlight&quot;: &#123; &quot;fields&quot;: &#123; &quot;content&quot;: &#123; &quot;fragment_size&quot;: 150, // 设置要显示出来的fragment文本长度,默认100 &quot;number_of_fragments&quot;: 3 // 指定显示高亮fragment文本片段个数 &#125; &#125; &#125;&#125;用一个大家容易理解的SQL语法来解释,如：select count(*) from table group by column。那么group by column分组后的每组数据就是bucket。对每个分组执行的count(*)就是metric。 聚合搜索bucket就是一个聚合搜索时的数据分组,metric就是对一个bucket数据执行的统计分析,metric有求和,最大值,最小值,平均值等多种统计 。如 select count(*) from table group by column 其中 group by column 分组后的 每组数据就是bucket,每个分组执行的 count(*) 就是 metric 。 1234567891011121314151617181920PUT /cars&#123;&quot;mappings&quot;:&#123;&quot;properties&quot;:&#123;&quot;price&quot;:&#123;&quot;type&quot;:&quot;long&quot;&#125;,&quot;color&quot;:&#123;&quot;type&quot;:&quot;keyword&quot;&#125;,&quot;brand&quot;:&#123;&quot;type&quot;:&quot;keyword&quot;&#125;,&quot;model&quot;:&#123;&quot;type&quot;:&quot;keyword&quot;&#125;,&quot;sold_date&quot;:&#123;&quot;type&quot;:&quot;date&quot;&#125;,&quot;remark&quot;:&#123;&quot;type&quot;:&quot;text&quot;,&quot;analyzer&quot;:&quot;ik_max_word&quot;&#125;&#125;&#125;&#125;POST /cars/_bulk&#123;&quot;index&quot;:&#123;&#125;&#125;&#123;&quot;price&quot;:258000,&quot;color&quot;:&quot;金色&quot;,&quot;brand&quot;:&quot;大众&quot;,&quot;model&quot;:&quot;大众迈腾&quot;,&quot;sold_date&quot;:&quot;2021-10-28&quot;,&quot;remark&quot;:&quot;大众中档车&quot;&#125;&#123;&quot;index&quot;:&#123;&#125;&#125;&#123;&quot;price&quot;:123000,&quot;color&quot;:&quot;金色&quot;,&quot;brand&quot;:&quot;大众&quot;,&quot;model&quot;:&quot;大众速腾&quot;,&quot;sold_date&quot;:&quot;2021-11-05&quot;,&quot;remark&quot;:&quot;大众神车&quot;&#125;&#123;&quot;index&quot;:&#123;&#125;&#125;&#123;&quot;price&quot;:239800,&quot;color&quot;:&quot;白色&quot;,&quot;brand&quot;:&quot;标志&quot;,&quot;model&quot;:&quot;标志508&quot;,&quot;sold_date&quot;:&quot;2021-05-18&quot;,&quot;remark&quot;:&quot;标志品牌全球上市车型&quot;&#125;&#123;&quot;index&quot;:&#123;&#125;&#125;&#123;&quot;price&quot;:148800,&quot;color&quot;:&quot;白色&quot;,&quot;brand&quot;:&quot;标志&quot;,&quot;model&quot;:&quot;标志408&quot;,&quot;sold_date&quot;:&quot;2021-07-02&quot;,&quot;remark&quot;:&quot;比较大的紧凑型车&quot;&#125;&#123;&quot;index&quot;:&#123;&#125;&#125;&#123;&quot;price&quot;:1998000,&quot;color&quot;:&quot;黑色&quot;,&quot;brand&quot;:&quot;大众&quot;,&quot;model&quot;:&quot;大众辉腾&quot;,&quot;sold_date&quot;:&quot;2021-08-19&quot;,&quot;remark&quot;:&quot;大众最让人肝疼的车&quot;&#125;&#123;&quot;index&quot;:&#123;&#125;&#125;&#123;&quot;price&quot;:218000,&quot;color&quot;:&quot;红色&quot;,&quot;brand&quot;:&quot;奥迪&quot;,&quot;model&quot;:&quot;奥迪A4&quot;,&quot;sold_date&quot;:&quot;2021-11-05&quot;,&quot;remark&quot;:&quot;小资车型&quot;&#125;&#123;&quot;index&quot;:&#123;&#125;&#125;&#123;&quot;price&quot;:489000,&quot;color&quot;:&quot;黑色&quot;,&quot;brand&quot;:&quot;奥迪&quot;,&quot;model&quot;:&quot;奥迪A6&quot;,&quot;sold_date&quot;:&quot;2022-01-01&quot;,&quot;remark&quot;:&quot;政府专用？&quot;&#125;&#123;&quot;index&quot;:&#123;&#125;&#125;&#123;&quot;price&quot;:1899000,&quot;color&quot;:&quot;黑色&quot;,&quot;brand&quot;:&quot;奥迪&quot;,&quot;model&quot;:&quot;奥迪A 8&quot;,&quot;sold_date&quot;:&quot;2022-02-12&quot;,&quot;remark&quot;:&quot;很贵的大A6。。。&quot;&#125; 根据color 分组统计销售数量,只执行聚合分组,ES中 最基础的聚合 为 terms,相当于SQL中的count,ES中默认为分组数据做排序,使用的是 doc_count 数据执行 降序排列 。可使用 _key 元数据根据分组后的 字段数据 执行不同的排序方案,也可根据 _count 元数据,根据分组后的统计值执行不同的排序方案 。 1234567891011GET /cars/_search&#123; &quot;aggs&quot;: &#123; &quot;group_by_color&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;color&quot;, &quot;order&quot;: &#123;&quot;_count&quot;: &quot;desc&quot;&#125; &#125; &#125; &#125;&#125; 先根据color执行聚合分组,在此分组的基础上,对组内数据执行聚合统计,组内数据的聚合统计就是 metric,同样可执行排序,因为组内有聚合统计,且对统计数据给予了命名avg_by_price,所以可根据该聚合统计数据字段名执行排序逻辑。 size可设置为0,表示不返回文档只返回聚合之后的数据,提高查询速度,若需要这些文档也可按照实际情况进行设置。对聚合统计数据进行排序,若有多层 aggs 执行 下钻聚合 时也可 根据最内层聚合数据执行排序 。 1234567891011121314151617181920212223242526272829GET /cars/_search&#123; &quot;aggs&quot;: &#123; &quot;group_by_color&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;color&quot;, &quot;order&quot;: &#123;&quot;avg_by_price&quot;: &quot;asc&quot;&#125; &#125;, &quot;aggs&quot;: &#123; &quot;avg_by_price&quot;: &#123;&quot;avg&quot;: &#123;&quot;field&quot;: &quot;price&quot;&#125;&#125; &#125; &#125; &#125;&#125;GET /cars/_search&#123; &quot;size&quot;: 0, &quot;aggs&quot;: &#123; &quot;group_by_color&quot;: &#123; &quot;terms&quot;: &#123;&quot;field&quot;: &quot;color&quot;&#125;, &quot;aggs&quot;: &#123; &quot;group_by_brand&quot;: &#123; &quot;terms&quot;: &#123;&quot;field&quot;: &quot;brand&quot;,&quot;order&quot;: &#123;&quot;avg_by_price&quot;: &quot;desc&quot;&#125;&#125;, &quot;aggs&quot;: &#123;&quot;avg_by_price&quot;: &#123;&quot;avg&quot;: &#123;&quot;field&quot;: &quot;price&quot;&#125;&#125;&#125; &#125; &#125; &#125; &#125;&#125; 先根据color聚合分组,在组内根据brand再次聚合分组,这种操作可称为下钻分析,aggs若定义比较多,则会感觉语法格式混乱,aggs语法格式有一个相对固定的结构,aggs可嵌套定义也可水平定义 。嵌套定义称为下钻分析,水平定义就是平铺多个分组方式 123456789101112131415GET /index_name/type_name/_search&#123; &quot;aggs&quot;: &#123; &quot;定义分组名称&quot;: &#123; &quot;分组策略如：terms、avg、sum&quot;: &#123; &quot;field&quot;: &quot;根据哪一个字段分组&quot;, &quot;其他参数&quot;: &quot;&quot; &#125;, &quot;aggs&quot;: &#123; &quot;分组名称1&quot;: &#123;&#125;, &quot;分组名称2&quot;: &#123;&#125; &#125; &#125; &#125;&#125; 统计不同color中的最大和最小价格、总价,聚合分析最常用的种类就是统计数量,最大,最小,平均,总计等 12345678910111213141516171819202122232425262728293031GET /cars/_search&#123; &quot;aggs&quot;: &#123; &quot;group_by_color&quot;: &#123; &quot;terms&quot;: &#123;&quot;field&quot;: &quot;color&quot;&#125;, &quot;aggs&quot;: &#123; &quot;max_price&quot;: &#123;&quot;max&quot;: &#123;&quot;field&quot;: &quot;price&quot;&#125;&#125;, &quot;min_price&quot;: &#123;&quot;min&quot;: &#123;&quot;field&quot;: &quot;price&quot;&#125;&#125;, &quot;sum_price&quot;: &#123;&quot;sum&quot;: &#123;&quot;field&quot;: &quot;price&quot;&#125;&#125; &#125; &#125; &#125;&#125;GET cars/_search // 统计不同品牌汽车中价格排名最高的车型&#123; &quot;size&quot;: 0, &quot;aggs&quot;: &#123; &quot;group_by_brand&quot;: &#123; &quot;terms&quot;: &#123;&quot;field&quot;: &quot;brand&quot;&#125;, &quot;aggs&quot;: &#123; &quot;top_car&quot;: &#123; &quot;top_hits&quot;: &#123; &quot;size&quot;: 1, // 取组内多少条数据,默认为10 &quot;sort&quot;: [&#123;&quot;price&quot;: &#123;&quot;order&quot;: &quot;desc&quot;&#125;&#125;], // 组内使用什么字段什么规则排序,默认使用_doc的asc规则排序 &quot;_source&quot;: &#123;&quot;includes&quot;: [&quot;model&quot;,&quot;price&quot;]&#125; // 结果中包含document中的哪些字段,默认包含全部字段 &#125; &#125; &#125; &#125; &#125;&#125; histogram区间统计 类似 terms, 也是用于 bucket分组操作, 是根据一个field实现数据区间分组 。如以100万为一个范围,统计不同范围内车辆销售量和平均价格。使用 histogram聚合 时field指定价格字段price,区间范围是100万,此时ES会将price价格区间划分为： [0, 1000000), [1000000, 2000000), [2000000, 3000000)等依次类推。在划分区间同时 histogram 会类似 terms 进行 数据数量统计, 可通过嵌套aggs对聚合分组后的组内数据做再次聚合分析 。 123456789101112GET /cars/_search&#123; &quot;aggs&quot;: &#123; &quot;histogram_by_price&quot;: &#123; &quot;histogram&quot;: &#123; &quot;field&quot;: &quot;price&quot;, &quot;interval&quot;: 1000000 &#125;, &quot;aggs&quot;: &#123;&quot;avg_by_price&quot;: &#123;&quot;avg&quot;: &#123;&quot;field&quot;: &quot;price&quot;&#125;&#125;&#125; &#125; &#125;&#125; date_histogram区间分组可对date类型的field执行区间聚合分组,若以月为单位,统计不同月份汽车销售数量及销售总金额。此时可使用 date_histogram 实现聚合分组,其中field来指定用于聚合分组的字段,interval指定 区间范围,可选值有 year、quarter、month、week、day、hour、minute、second,format指定日期格式化,min_doc_count指定每个区间最少document,若不指定默认为0,当区间范围内没有document时,也会显示bucket分组,extended_bounds指定起始时间和结束时间,若不指定默认使用字段中日期最小值和最大值作为起始和结束时间。 123456789101112131415GET /cars/_search&#123; &quot;aggs&quot;: &#123; &quot;histogram_by_date&quot;: &#123; &quot;date_histogram&quot;: &#123; &quot;field&quot;: &quot;sold_date&quot;, &quot;interval&quot;: &quot;month&quot;, // 7.X之后使用calendar_interval,指定区间范围 &quot;format&quot;: &quot;yyyy-MM-dd&quot;, // 指定日期格式化 &quot;min_doc_count&quot;: 1, &quot;extended_bounds&quot;: &#123;&quot;min&quot;: &quot;2021-01-01&quot;,&quot;max&quot;: &quot;2022-12-31&quot;&#125; &#125;, &quot;aggs&quot;: &#123;&quot;sum_by_price&quot;: &#123;&quot;sum&quot;: &#123;&quot;field&quot;: &quot;price&quot;&#125;&#125;&#125; &#125; &#125;&#125; 聚合统计数据时,有时需要对比部分数据和总体数据,如统计某品牌车辆平均价格和所有车辆平均价格。 global 是用于定义一个全局bucket,该 bucket 会 忽略query 的条件,检索所有document进行对应的聚合统计。 123456789101112GET /cars/_search&#123; &quot;size&quot;: 0, &quot;query&quot;: &#123;&quot;match&quot;: &#123;&quot;brand&quot;: &quot;大众&quot;&#125;&#125;, &quot;aggs&quot;: &#123; &quot;volkswagen_of_avg_price&quot;: &#123;&quot;avg&quot;: &#123;&quot;field&quot;: &quot;price&quot;&#125;&#125;, // 统计某品牌车辆平均价格 &quot;all_avg_price&quot;: &#123; // 所有车辆平均价格 &quot;global&quot;: &#123;&#125;, &quot;aggs&quot;: &#123;&quot;all_of_price&quot;: &#123;&quot;avg&quot;: &#123;&quot;field&quot;: &quot;price&quot;&#125;&#125;&#125; &#125; &#125;&#125; filter也可和aggs组合使用,实现相对复杂的过滤聚合分析,filter的范围决定了其过滤的范围,将filter放在aggs内部,代表该过滤器只对query搜索得到的结果执行filter过滤 。若filter放在aggs外部,过滤器则会过滤所有数据。 12345678910111213141516171819GET /cars/_search // filter和aggs组合使用,实现相对复杂的过滤聚合分析&#123; &quot;query&quot;: &#123; &quot;constant_score&quot;: &#123; &quot;filter&quot;: &#123;&quot;range&quot;: &#123;&quot;price&quot;: &#123;&quot;gte&quot;: 100000,&quot;lte&quot;: 500000&#125;&#125;&#125; &#125; &#125;, &quot;aggs&quot;: &#123;&quot;avg_by_price&quot;: &#123;&quot;avg&quot;: &#123;&quot;field&quot;: &quot;price&quot;&#125;&#125;&#125;&#125;GET /cars/_search&#123; &quot;query&quot;: &#123;&quot;match&quot;: &#123;&quot;brand&quot;: &quot;大众&quot;&#125;&#125;, &quot;aggs&quot;: &#123; &quot;count_last_year&quot;: &#123; // 12M/M表示12个月,1y/y表示1年,d表示天 &quot;filter&quot;: &#123;&quot;range&quot;: &#123;&quot;sold_date&quot;: &#123;&quot;gte&quot;: &quot;now-12M&quot;&#125;&#125;&#125;, &quot;aggs&quot;: &#123;&quot;sum_of_price_last_year&quot;: &#123;&quot;sum&quot;: &#123;&quot;field&quot;: &quot;price&quot;&#125;&#125;&#125; &#125; &#125;&#125; 数据建模如下设计一个用户document数据类型,其中包含一个地址数据的数组,该设计方式相对复杂,但在管理数据时更加的灵活。但也有明显的缺陷,针对地址数据做数据搜索时,经常会搜索出不必要的数据 。 123456789101112131415161718192021222324252627282930313233343536373839404142434445PUT /user_index&#123; &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123; &quot;login_name&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;&#125;, &quot;age &quot;: &#123;&quot;type&quot;: &quot;short&quot;&#125;, &quot;address&quot;: &#123; &quot;properties&quot;: &#123; &quot;province&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;&#125;, &quot;city&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;&#125;, &quot;street&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;&#125; &#125; &#125; &#125; &#125;&#125;PUT /user_index/_doc/1&#123; &quot;login_name&quot;: &quot;jack&quot;, &quot;age&quot;: 25, &quot;address&quot;: [ &#123;&quot;province&quot;: &quot;北京&quot;,&quot;city&quot;: &quot;北京&quot;,&quot;street&quot;: &quot;枫林三路&quot;&#125;, &#123;&quot;province&quot;: &quot;天津&quot;,&quot;city&quot;: &quot;天津&quot;,&quot;street&quot;: &quot;华夏路&quot;&#125; ]&#125;PUT /user_index/_doc/2&#123; &quot;login_name&quot;: &quot;rose&quot;, &quot;age&quot;: 21, &quot;address&quot;: [ &#123;&quot;province&quot;: &quot;河北&quot;,&quot;city&quot;: &quot;廊坊&quot;,&quot;street&quot;: &quot;燕郊经济开发区&quot;&#125;, &#123;&quot;province&quot;: &quot;天津&quot;,&quot;city&quot;: &quot;天津&quot;,&quot;street&quot;: &quot;华夏路&quot;&#125; ]&#125;GET /user_index/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [ &#123;&quot;match&quot;: &#123;&quot;address.province&quot;: &quot;北京&quot;&#125;&#125;, &#123;&quot;match&quot;: &#123;&quot;address.city&quot;: &quot;天津&quot;&#125;&#125; ] &#125; &#125;&#125; 可使用 nested object 作为 地址数组 的集体类型可解决上述问题,且搜索时需要 使用nested对应的搜索语法 123456789101112131415161718192021222324252627282930PUT /user_index&#123; &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123; &quot;login_name&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;&#125;, &quot;age &quot;: &#123;&quot;type&quot;: &quot;short&quot;&#125;, &quot;address&quot;: &#123; &quot;type&quot;: &quot;nested&quot;, &quot;properties&quot;: &#123; &quot;province&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;&#125;, &quot;city&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;&#125;, &quot;street&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;&#125; &#125; &#125; &#125; &#125;&#125;GET /user_index/_search&#123; &quot;query&quot;: &#123;&quot;bool&quot;: &#123;&quot;must&quot;: [ &#123;&quot;nested&quot;: &#123;&quot;path&quot;: &quot;address&quot;, &quot;query&quot;: &#123; &quot;bool&quot;: &#123;&quot;must&quot;: [ &#123;&quot;match&quot;: &#123;&quot;address.province&quot;: &quot;北京&quot;&#125;&#125;, &#123;&quot;match&quot;: &#123;&quot;address.city&quot;: &quot;北京&quot;&#125;&#125; ]&#125; &#125;&#125; &#125;] &#125;&#125;&#125; 普通数组数据在ES中会被扁平化处理,nested object数据类型ES在保存时不会扁平化处理 1234567891011121314151617181920&#123; // 普通数组 &quot;login_name&quot; : &quot;jack&quot;, &quot;address.province&quot; : [ &quot;北京&quot;, &quot;天津&quot; ], &quot;address.city&quot; : [ &quot;北京&quot;, &quot;天津&quot; ] &quot;address.street&quot; : [ &quot;枫林三路&quot;, &quot;华夏路&quot; ]&#125;// nested数据&#123; &quot;login_name&quot; : &quot;jack&quot;&#125;&#123; &quot;address.province&quot; : &quot;北京&quot;, &quot;address.city&quot; : &quot;北京&quot;, &quot;address.street&quot; : &quot;枫林三路&quot;&#125;&#123; &quot;address.province&quot; : &quot;天津&quot;, &quot;address.city&quot; : &quot;天津&quot;, &quot;address.street&quot; : &quot;华夏路&quot;,&#125; nested object建模缺点是采取的是类似冗余数据的方式,将多个数据放在一起,维护成本比较高,每次更新需要重新索引整个对象,包括根对象和嵌套对象。ES提供 类似关系型数据库 中 Join 的实现,使用Join数据类型实现父子关系,从而分离两个文档对象。 更新父文档无需重新索引整个子文档,子文档被新增,更改和删除也不会影响到父文档和其他子文档,父子关系元数据映射,用于确保查询时高性能,但是有一个限制父子数据包括映射其关联关系的元数据必须存在于一个shard中,搜索父子关系数据时,不用跨分片性能高。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495PUT my_blogs&#123; &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123; &quot;blog_comments_relation&quot;: &#123; &quot;type&quot;: &quot;join&quot;, // 指明join类型 &quot;relations&quot;: &#123; // 声明父子关系 &quot;blog&quot;: &quot;comment&quot; // blog为父文档名称,comment为子文档名称 &#125; &#125;, &quot;content&quot;: &#123;&quot;type&quot;: &quot;text&quot;&#125;, &quot;title&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;&#125; &#125; &#125;&#125;PUT my_blogs/_doc/blog1 // blog1为父文档id&#123; &quot;title&quot;: &quot;Learning Elasticsearch&quot;, &quot;content&quot;: &quot;learning ELK is happy&quot;, &quot;blog_comments_relation&quot;: &#123; // 声明文档类型 &quot;name&quot;: &quot;blog&quot; &#125;&#125;PUT my_blogs/_doc/blog2 // blog2为父文档id&#123; &quot;title&quot;: &quot;Learning Hadoop&quot;, &quot;content&quot;: &quot;learning Hadoop&quot;, &quot;blog_comments_relation&quot;: &#123; // 声明文档类型 &quot;name&quot;: &quot;blog&quot; &#125;&#125;// 父文档和子文档必须存在相同的分片上, 当指定文档时候,必须指定它的父文档IDPUT my_blogs/_doc/comment1?routing=blog1 // 使用route参数来保证,分配到相同分片&#123; &quot;comment&quot;: &quot;I am learning ELK&quot;, &quot;username&quot;: &quot;Jack&quot;, &quot;blog_comments_relation&quot;: &#123; &quot;name&quot;: &quot;comment&quot;, &quot;parent&quot;: &quot;blog1&quot; &#125;&#125;PUT my_blogs/_doc/comment2?routing=blog2 // comment2为子文档id,blog2为父文档id&#123; &quot;comment&quot;: &quot;I like Hadoop!!!!!&quot;, &quot;username&quot;: &quot;Jack&quot;, &quot;blog_comments_relation&quot;: &#123; &quot;name&quot;: &quot;comment&quot;, &quot;parent&quot;: &quot;blog2&quot; &#125;&#125;PUT my_blogs/_doc/comment3?routing=blog2&#123; &quot;comment&quot;: &quot;Hello Hadoop&quot;, &quot;username&quot;: &quot;Bob&quot;, &quot;blog_comments_relation&quot;: &#123; &quot;name&quot;: &quot;comment&quot;, &quot;parent&quot;: &quot;blog2&quot; &#125;&#125;POST my_blogs/_search // 查询所有文档&#123;&#125;GET my_blogs/_doc/blog2 // 根据父文档ID查看POST my_blogs/_search // parent_id查询,返回所有相关子文档&#123; &quot;query&quot;: &#123; &quot;parent_id&quot;: &#123;&quot;type&quot;: &quot;comment&quot;,&quot;id&quot;: &quot;blog2&quot;&#125; &#125;&#125;POST my_blogs/_search // has_child查询,返回父文档&#123; &quot;query&quot;: &#123; &quot;has_child&quot;: &#123; &quot;type&quot;: &quot;comment&quot;, &quot;query&quot;: &#123;&quot;match&quot;: &#123;&quot;username&quot;: &quot;Jack&quot;&#125;&#125; &#125; &#125;&#125;POST my_blogs/_search // has_parent查询,返回相关的子文档&#123; &quot;query&quot;: &#123; &quot;has_parent&quot;: &#123; &quot;parent_type&quot;: &quot;blog&quot;, &quot;query&quot;: &#123;&quot;match&quot;: &#123;&quot;title&quot;: &quot;Learning Hadoop&quot;&#125;&#125; &#125; &#125;&#125;PUT my_blogs/_doc/comment3?routing=blog2 //更新子文档不会影响到父文档&#123; &quot;comment&quot;: &quot;Hello Hadoop??&quot;, &quot;blog_comments_relation&quot;: &#123; &quot;name&quot;: &quot;comment&quot;, &quot;parent&quot;: &quot;blog2&quot; &#125;&#125; 文件系统数据若需要使用 文件路径搜索 内容,只需要为其中的字段定义一个特殊的 path_hierarchy 分词器 123456789101112131415161718192021222324252627282930313233343536373839404142PUT /codes&#123; &quot;settings&quot;: &#123;&quot;analysis&quot;: &#123;&quot;analyzer&quot;: &#123;&quot;path_analyzer&quot;: &#123;&quot;tokenizer&quot;: &quot;path_hierarchy&quot;&#125;&#125;&#125;&#125;, &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123; &quot;fileName&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;&#125;, &quot;path&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;path_analyzer&quot;, &quot;fields&quot;: &#123;&quot;keyword&quot;: &#123;&quot;type&quot;: &quot;text&quot;,&quot;analyzer&quot;: &quot;standard&quot;&#125;&#125; &#125;, &quot;content&quot;: &#123;&quot;type&quot;: &quot;text&quot;,&quot;analyzer&quot;: &quot;standard&quot;&#125; &#125; &#125;&#125;PUT /codes/_doc/1&#123; &quot;fileName&quot;: &quot;HelloWorld.java&quot;, &quot;path&quot;: &quot;/com/eleven/first&quot;, &quot;content&quot;: &quot;package com.eleven.first; public class HelloWorld &#123; // some code... &#125;&quot;&#125;GET /codes/_search&#123; &quot;query&quot;: &#123;&quot;match&quot;: &#123;&quot;path&quot;: &quot;/com&quot;&#125;&#125;&#125;GET /codes/_analyze&#123; &quot;text&quot;: &quot;/a/b/c/d&quot;, &quot;field&quot;: &quot;path&quot;&#125;GET /codes/_search&#123; &quot;query&quot;: &#123;&quot;match&quot;: &#123;&quot;path.keyword&quot;: &quot;/com&quot;&#125;&#125;&#125;GET /codes/_search&#123; &quot;query&quot;: &#123;&quot;bool&quot;: &#123;&quot;should&quot;: [ &#123;&quot;match&quot;: &#123;&quot;path&quot;: &quot;/com&quot;&#125;&#125;, &#123;&quot;match&quot;: &#123;&quot;path.keyword&quot;: &quot;/com/eleven&quot;&#125;&#125; ]&#125;&#125;&#125; Scroll分页使用 from 和 size 方式查询1W以内的数据都OK,但若数据比较多时会出现性能问题。ES做了一个限制 不允许查询1W条以后的数据 。若要查询1W条以后的数据,可使用ES中提供的 scroll游标 来查询。 在进行大量分页时,每次分页都需要将要查询数据进行重新排序,这样非常浪费性能。使用 scroll游标 是 将要用的数据一次性排序好, 然后 分批取出 。性能要比from + size好得多,使用scroll查询后,排序后的数据会保持一定的时间, 后续分页查询都从该快照取数据。响应结果中会返回_scroll_id,第二次查询直接使用_scroll_id来查询。 1234567891011121314GET /es_db/_search?scroll=1m // 让排序的数据保持1分钟&#123; &quot;query&quot;: &#123; &quot;multi_match&quot;: &#123; &quot;query&quot;: &quot;广州长沙张三&quot;, &quot;fields&quot;: [&quot;address&quot;,&quot;name&quot;] &#125; &#125;, &quot;size&quot;: 100&#125;GET _search/scroll?scroll=1m&#123; &quot;scroll_id&quot;: &quot;FGluY2x1ZGVfY29udGV4dF91dWlkDXF1ZXJ5QW5kRmV0Y2gBFnJKUnZmX1pIVGVpM05TWDBQX0JJeXcAAAAAAAaeghZDUkdZN1FJNVIwYUJhYUxvNWVxd1Rn&quot;&#125; SQL支持ES SQL允许执行类SQL查询,REST接口、命令行或 JDBC 等都可使用 SQL 来进行 数据检索 和 数据聚合 。特点： 本地集成：ES SQL是专门为ES构建的,每个SQL查询都根据底层存储对相关节点有效执行 无额外要求：不依赖其他硬件、进程、运行时库,可直接运行在ES集群上 轻量且高效：像SQL那样简洁、高效地完成查询1234567891011121314GET /es_db/_search?scroll=1m // 让排序的数据保持1分钟&#123; &quot;query&quot;: &#123; &quot;multi_match&quot;: &#123; &quot;query&quot;: &quot;广州长沙张三&quot;, &quot;fields&quot;: [&quot;address&quot;,&quot;name&quot;] &#125; &#125;, &quot;size&quot;: 100&#125;GET _search/scroll?scroll=1m&#123; &quot;scroll_id&quot;: &quot;FGluY2x1ZGVfY29udGV4dF91dWlkDXF1ZXJ5QW5kRmV0Y2gBFnJKUnZmX1pIVGVpM05TWDBQX0JJeXcAAAAAAAaeghZDUkdZN1FJNVIwYUJhYUxvNWVxd1Rn&quot;&#125; 目前 FROM只支持单表, 不支持JOIN、不支持较复杂的子查询,format 表示 指定返回数据类型, 支持的类型有 逗号分隔csv、json、制表符分隔符tsv、txt、yaml 。 12345678910111213141516GET /_sql?format=json&#123; &quot;query&quot;: &quot;SELECT * FROM es_db limit 1&quot;&#125;GET /_sql/translate // 将SQL转换为DSL&#123; &quot;query&quot;: &quot;SELECT * FROM es_db limit 1&quot;&#125;GET /_sql?format=json // field_exp匹配字段,constant_exp匹配常量表达式,&#123; // 检索address包含广州和name中包含张三的用户 &quot;query&quot;: &quot;select * from es_db where MATCH(address, &#x27;广州&#x27;) or MATCH(name, &#x27;张三&#x27;) limit 10&quot;&#125;GET /_sql?format=txt // 统计分组&#123; &quot;query&quot;: &quot;select age, count(*) as age_cnt from es_db group by age&quot;&#125; 模板模板搜索可将一些搜索进行模板化,每次执行该搜索就直接调用模板,传入一些参数即可。 123456789101112131415161718192021222324252627282930GET /cars/_search/template // 简单定义参数并传递&#123; &quot;source&quot;: &#123; &quot;query&quot;: &#123;&quot;match&quot;: &#123;&quot;remark&quot;: &quot;&#123;&#123;kw&#125;&#125;&quot;&#125;&#125;, &quot;size&quot;: &quot;&#123;&#123;size&#125;&#125;&quot; &#125;, &quot;params&quot;: &#123;&quot;kw&quot;: &quot;大众&quot;,&quot;size&quot;: 2&#125;&#125;GET cars/_search/template // toJson方式传递参数&#123; &quot;source&quot;: &quot;&quot;&quot;&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123;&#123;#toJson&#125;&#125;parameter&#123;&#123;/toJson&#125;&#125; &#125;&#125;&quot;&quot;&quot;, &quot;params&quot;: &#123; &quot;parameter&quot;: &#123;&quot;remark&quot;: &quot;大众&quot;&#125; &#125;&#125;GET cars/_search/template // json方式传递参数&#123; &quot;source&quot;: &#123;&quot;query&quot;: &#123;&quot;match&quot;: &#123; &quot;remark&quot;: &quot;&#123;&#123;#join delimiter=&#x27; &#x27;&#125;&#125;kw&#123;&#123;/join delimiter=&#x27; &#x27;&#125;&#125;&quot; &#125;&#125;&#125;, &quot;params&quot;: &#123;&quot;kw&quot;: [&quot;大众&quot;,&quot;标致&quot;]&#125;&#125;GET cars/_search/template&#123; &quot;source&quot;: &#123;&quot;query&quot;: &#123;&quot;range&quot;: &#123;&quot;price&quot;: &#123; &quot;gte&quot;: &quot;&#123;&#123;start&#125;&#125;&quot;, &quot;lte&quot;: &quot;&#123;&#123;end&#125;&#125;&#123;&#123;^end&#125;&#125;200000&#123;&#123;/end&#125;&#125;&quot; // 默认值定义 &#125;&#125;&#125;&#125;, &quot;params&quot;: &#123;&quot;start&quot;: 100000,&quot;end&quot;: 140000&#125;&#125; 记录template实现重复调用 可使用 Mustache 语言作为 搜索请求预处理, 它提供模板 通过键值对 来替换模板中的变量。把 脚本存储在本地磁盘中, 默认位置为 elasticsearch\\config\\scripts, 通过引用脚本名称进行使用 12345678910111213POST _scripts/test // test为脚本id&#123; &quot;script&quot;: &#123; &quot;lang&quot;: &quot;mustache&quot;, // 指定mustache语言 &quot;source&quot;: &#123;&quot;query&quot;: &#123;&quot;match&quot;: &#123;&quot;remark&quot;: &quot;&#123;&#123;kw&#125;&#125;&quot;&#125;&#125;&#125; &#125;&#125;GET cars/_search/template&#123; &quot;id&quot;: &quot;test&quot;, // 指定调用脚本的id &quot;params&quot;: &#123;&quot;kw&quot;: &quot;大众&quot;&#125;&#125;DELETE _scripts/test // 删除脚本id为test的脚本 suggest searchsuggest search(completion suggest) 即 建议搜索 或 搜索建议, 也可叫做自动完成,类似百度中搜索联想提示功能。ES实现 suggest时 性能非常高, 其构建的不是倒排索引也不是正排索引,是纯粹用于前缀搜索的一种特殊数据结构,且会全部放在内存中,所以suggest search进行前缀搜索提示性能是非常高。需要使用suggest时候,必须在定义index时为其mapping指定开启suggest 。 12345678910111213141516171819202122232425262728293031323334PUT /movie&#123; &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123;&quot;title&quot;: &#123;&quot;type&quot;: &quot;text&quot;,&quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;fields&quot;: &#123;&quot;suggest&quot;: &#123;&quot;type&quot;: &quot;completion&quot;,&quot;analyzer&quot;: &quot;ik_max_word&quot;&#125;&#125; &#125;, &quot;content&quot;: &#123;&quot;type&quot;: &quot;text&quot;,&quot;analyzer&quot;: &quot;ik_max_word&quot;&#125; &#125; &#125;&#125;PUT /movie/_doc/1&#123; &quot;title&quot;: &quot;西游记电影系列&quot;, &quot;content&quot;: &quot;西游记之月光宝盒将与2021年进行......&quot;&#125;PUT /movie/_doc/2&#123; &quot;title&quot;: &quot;西游记文学系列&quot;, &quot;content&quot;: &quot;某知名网络小说作家已经完成了大话西游同名小说的出版&quot;&#125;PUT /movie/_doc/3&#123; &quot;title&quot;: &quot;西游记之大话西游手游&quot;, &quot;content&quot;: &quot;网易游戏近日出品了大话西游经典IP的手游,正在火爆内测中&quot;&#125;GET /movie/_search&#123; &quot;suggest&quot;: &#123; &quot;my-suggest&quot;: &#123; &quot;prefix&quot;: &quot;西游记&quot;, &quot;completion&quot;: &#123;&quot;field&quot;: &quot;title.suggest&quot;&#125; &#125; &#125;&#125; 地理位置搜索ES支持 地理位置搜索 和 聚合分析, 可实现 在指定区域内搜索数据、搜索指定地点附近的数据、聚合分析指定地点附近的数据 等操作。ES中若使用地理位置搜索,必须提供一个特殊的字段类型 geo_point, 用于指定地理位置坐标点。 新增一个基于 geo_point 类型数据,可使用多种方式。多种类型描述 geo_point 类型字段时,在 搜索数据时显示格式和录入格式是统一的 。 任何数据描述 的 geo_point 类型字段, 都适用地理位置搜索 。 数据范围要求 纬度范围 是-90~90之间, 经度范围 是-180~180之间,经纬度数据都是 浮点数 或 数字串, 最大精度为 小数点后7位 。 latitude ： 纬度 、 longitude ： 经度 。 123456789101112131415161718192021222324PUT /hotel_app&#123; &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123; &quot;pin&quot;: &#123;&quot;type&quot;: &quot;geo_point&quot;&#125;, &quot;name&quot;: &#123;&quot;type&quot;: &quot;text&quot;,&quot;analyzer&quot;: &quot;ik_max_word&quot;&#125; &#125; &#125;&#125;PUT /hotel_app/_doc/1&#123; &quot;name&quot;: &quot;七天连锁酒店&quot;, &quot;pin&quot;: &#123;&quot;lat&quot;: 40.12,&quot;lon&quot;: -71.34&#125;&#125;PUT /hotel_app/_doc/2&#123; &quot;name&quot;: &quot;维多利亚大酒店&quot;, &quot;pin&quot;: &quot;40.99, -70.81&quot;&#125;PUT /hotel_app/_doc/3&#123; &quot;name&quot;: &quot; 红树林宾馆&quot;, &quot;pin&quot;: [40,-73.81] // 基于数组：依次定义经度、纬度,不推荐使用&#125; 矩形范围搜索 传入 top_left 和 bottom_right 坐标点是有固定要求的, top_left 即 从西北向东南, Bottom_right 即从东南向西北, 且 top_left纬度应大于bottom_right, top_left经度应小于bottom_right 。多边形范围搜索 对传入若干点坐标顺序没有任何要求,只要传入若干地理位置坐标点,即可形成多边形。 12345678910111213141516171819202122232425GET /hotel_app/_doc/_search // 矩形搜索&#123; &quot;query&quot;: &#123; &quot;geo_bounding_box&quot;: &#123; &quot;pin&quot;: &#123; &quot;top_left&quot;: &#123;&quot;lat&quot;: 41.73,&quot;lon&quot;: -74.1&#125;, &quot;bottom_right&quot;: &#123;&quot;lat&quot;: 40.01,&quot;lon&quot;: -70.12&#125; &#125; &#125; &#125;&#125;GET /hotel_app/_doc/_search // 多边形搜索&#123; &quot;query&quot;: &#123; &quot;geo_polygon&quot;: &#123; &quot;pin&quot;: &#123; &quot;points&quot;: [ &#123;&quot;lat&quot;: 40.73,&quot;lon&quot;: -74.1&#125;, &#123;&quot;lat&quot;: 40.01,&quot;lon&quot;: -71.12&#125;, &#123;&quot;lat&quot;: 50.56,&quot;lon&quot;: -90.58&#125; ] &#125; &#125; &#125;&#125; Distance距离的单位,常用米m和千米km,建议使用 filter 来过滤 geo_point 数据,因为 geo_point 数据相关度评分计算比较耗时。使用query来搜索geo_point数据效率相对会慢一些。 12345678910111213141516171819GET /hotel_app/_doc/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;filter&quot;: &#123; &quot;geo_distance&quot;: &#123;&quot;distance&quot;: &quot;200km&quot;,&quot;pin&quot;: &#123;&quot;lat&quot;: 40,&quot;lon&quot;: -70&#125;&#125; &#125; &#125; &#125;&#125;GET hotel_app/_search&#123; &quot;query&quot;: &#123; &quot;geo_distance&quot;: &#123; &quot;distance&quot;: &quot;90km&quot;, &quot;pin&quot;: &#123;&quot;lat&quot;: 40.55,&quot;lon&quot;: -71.12&#125; &#125; &#125;&#125; 聚合统计某位置附近区域内的数据,unit是距离单位,常用单位有米m,千米km,英里mi,distance_type是统计算法：sloppy_arc默认算法、 arc最高精度 、 plane最高效率 。 12345678910111213141516171819GET /hotel_app/_doc/_search&#123; &quot;size&quot;: 0, &quot;aggs&quot;: &#123; &quot;agg_by_pin&quot;: &#123; &quot;geo_distance&quot;: &#123; &quot;distance_type&quot;: &quot;arc&quot;, &quot;field&quot;: &quot;pin&quot;, &quot;origin&quot;: &#123;&quot;lat&quot;: 40,&quot;lon&quot;: -70&#125;, &quot;unit&quot;: &quot;mi&quot;, &quot;ranges&quot;: [ // 聚合统计分别距离某位置80英里,300英里,1000英里范围内的数据数量 &#123;&quot;to&quot;: 80&#125;, &#123;&quot;from&quot;: 80,&quot;to&quot;: 300&#125;, &#123;&quot;from&quot;: 300,&quot;to&quot;: 1000&#125; ] &#125; &#125; &#125;&#125; ElasticSearch: 进一步学习Elasticsearch 官方学习文档：https://www.elastic.co/guide/en/elasticsearch/reference/current/index.htmlJava API:https://www.elastic.co/guide/en/elasticsearch/client/java-api/current/java-api.html","tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"http://example.com/tags/ElasticSearch/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"ElasticSearch","slug":"工具和中间件/搜索引擎技术/ElasticSearch","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/ElasticSearch/"}]},{"title":"ElasticSearch实战","date":"2022-01-02T03:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/ElasticSearch/ElasticSearch实战/","text":"引入pom依赖：12345&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch-rest-high-level-client&lt;/artifactId&gt; &lt;version&gt;7.6.1&lt;/version&gt;&lt;/dependency&gt; 使用Java API来操作ES集群初始化连接，基于 RestClient.builder 方法来构建 RestClientBuilder, 使用 RestHighLevelClient 去连接ES集群，用 HttpHost 来添加ES的节点。 123456789// 建立与ES的连接// 1. 使用RestHighLevelClient构建客户端连接。// 2. 基于RestClient.builder方法来构建RestClientBuilder// 3. 用HttpHost来添加ES的节点RestClientBuilder restClientBuilder = RestClient.builder( new HttpHost(&quot;192.168.21.130&quot;, 9200, &quot;http&quot;) , new HttpHost(&quot;192.168.21.131&quot;, 9200, &quot;http&quot;) , new HttpHost(&quot;192.168.21.132&quot;, 9200, &quot;http&quot;));RestHighLevelClient restHighLevelClient = new RestHighLevelClient(restClientBuilder); 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155public void add(JobDetail jobDetail) throws IOException &#123; // 构建IndexRequest对象，用来描述ES发起请求的数据 IndexRequest indexRequest = new IndexRequest(JOB_IDX); // 设置文档ID indexRequest.id(String.valueOf(jobDetail.getId())); // 使用FastJSON将实体类对象转换为JSON String json = JSONObject.toJSONString(jobDetail); // 使用IndexRequest.source方法设置文档数据，并设置请求的数据为JSON格式 indexRequest.source(json, XContentType.JSON); // 使用ES RestHighLevelClient调用index方法发起请求，将一个文档添加到索引中 restHighLevelClient.index(indexRequest, RequestOptions.DEFAULT);&#125;public JobDetail findById(long id) throws IOException &#123; GetRequest getRequest = new GetRequest(JOB_IDX, id + &quot;&quot;); // 构建GetRequest请求 // 使用RestHighLevelClient.get发送GetRequest请求，并获取到ES服务器的响应。 GetResponse getResponse = restHighLevelClient.get(getRequest, RequestOptions.DEFAULT); String json = getResponse.getSourceAsString();// 将ES响应的数据转换为JSON字符串 // 并使用FastJSON将JSON字符串转换为JobDetail类对象 JobDetail jobDetail = JSONObject.parseObject(json, JobDetail.class); jobDetail.setId(id);// 单独设置ID return jobDetail;&#125;public void update(JobDetail jobDetail) throws IOException &#123; // 判断对应ID的文档是否存在，构建GetRequest GetRequest getRequest = new GetRequest(JOB_IDX, jobDetail.getId() + &quot;&quot;); // 执行client的exists方法，发起请求，判断是否存在 boolean exists = restHighLevelClient.exists(getRequest, RequestOptions.DEFAULT); if(exists) &#123; // 构建UpdateRequest请求 UpdateRequest updateRequest = new UpdateRequest(JOB_IDX, jobDetail.getId() + &quot;&quot;); // 设置UpdateRequest的文档，并配置为JSON格式 updateRequest.doc(JSONObject.toJSONString(jobDetail), XContentType.JSON); // 执行client发起update请求 restHighLevelClient.update(updateRequest, RequestOptions.DEFAULT); &#125;&#125;public void deleteById(long id) throws IOException &#123; DeleteRequest deleteRequest = new DeleteRequest(JOB_IDX, id + &quot;&quot;);// 构建delete请求 restHighLevelClient.delete(deleteRequest, RequestOptions.DEFAULT);// 使用RestHighLevelClient执行delete请求&#125;public List&lt;JobDetail&gt; searchByKeywords(String keywords) throws IOException &#123; // 构建SearchRequest检索请求 专门用来进行全文检索、关键字检索的API SearchRequest searchRequest = new SearchRequest(JOB_IDX); // 创建一个SearchSourceBuilder专门用于构建查询条件 SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); // 使用QueryBuilders.multiMatchQuery构建一个查询条件（搜索title、jd），并配置到SearchSourceBuilder MultiMatchQueryBuilder multiMatchQueryBuilder = QueryBuilders.multiMatchQuery(keywords, &quot;title&quot;, &quot;jd&quot;); searchSourceBuilder.query(multiMatchQueryBuilder);// 将查询条件设置到查询请求构建器中 searchRequest.source(searchSourceBuilder);// 调用SearchRequest.source将查询条件设置到检索请求 // 执行RestHighLevelClient.search发起请求 SearchResponse searchResponse = restHighLevelClient.search(searchRequest, RequestOptions.DEFAULT); SearchHit[] hitArray = searchResponse.getHits().getHits(); ArrayList&lt;JobDetail&gt; jobDetailArrayList = new ArrayList&lt;&gt;(); for (SearchHit documentFields : hitArray) &#123;// 遍历结果 String json = documentFields.getSourceAsString();// 获取命中的结果 JobDetail jobDetail = JSONObject.parseObject(json, JobDetail.class);// 将JSON字符串转换为对象 jobDetail.setId(Long.parseLong(documentFields.getId()));// 使用SearchHit.getId设置文档ID jobDetailArrayList.add(jobDetail); &#125; return jobDetailArrayList;&#125;public Map&lt;String, Object&gt; searchByPage(String keywords, int pageNum, int pageSize) throws IOException &#123; // 构建SearchRequest检索请求 专门用来进行全文检索、关键字检索的API SearchRequest searchRequest = new SearchRequest(JOB_IDX); // 创建一个SearchSourceBuilder专门用于构建查询条件 SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); // 使用QueryBuilders.multiMatchQuery构建一个查询条件（搜索title、jd），并配置到SearchSourceBuilder MultiMatchQueryBuilder multiMatchQueryBuilder = QueryBuilders.multiMatchQuery(keywords, &quot;title&quot;, &quot;jd&quot;); searchSourceBuilder.query(multiMatchQueryBuilder); // 将查询条件设置到查询请求构建器中 searchSourceBuilder.size(pageSize);// 每页显示多少条 searchSourceBuilder.from((pageNum - 1) * pageSize);// 设置从第几条开始查询 searchRequest.source(searchSourceBuilder);// 调用SearchRequest.source将查询条件设置到检索请求 // 执行RestHighLevelClient.search发起请求 SearchResponse searchResponse = restHighLevelClient.search(searchRequest, RequestOptions.DEFAULT); SearchHit[] hitArray = searchResponse.getHits().getHits(); ArrayList&lt;JobDetail&gt; jobDetailArrayList = new ArrayList&lt;&gt;(); for (SearchHit documentFields : hitArray) &#123;// 遍历结果 String json = documentFields.getSourceAsString();// 获取命中的结果 JobDetail jobDetail = JSONObject.parseObject(json, JobDetail.class);// 将JSON字符串转换为对象 jobDetail.setId(Long.parseLong(documentFields.getId()));// 使用SearchHit.getId设置文档ID jobDetailArrayList.add(jobDetail); &#125; // 将结果封装到Map结构中（带有分页信息） long totalNum = searchResponse.getHits().getTotalHits().value; Map&lt;String, Object&gt; resultMap = new HashMap&lt;&gt;(); resultMap.put(&quot;total&quot;, totalNum); // total -&gt; 使用SearchHits.getTotalHits().value获取到所有的记录数 resultMap.put(&quot;content&quot;, jobDetailArrayList); content -&gt; 当前分页中的数据 return resultMap;&#125;public Map&lt;String, Object&gt; searchByScrollPage(String keywords, String scrollId, int pageSize) throws IOException &#123; SearchResponse searchResponse = null; if(scrollId == null) &#123; // 构建SearchRequest检索请求 专门用来进行全文检索、关键字检索的API SearchRequest searchRequest = new SearchRequest(JOB_IDX); // 创建一个SearchSourceBuilder专门用于构建查询条件 SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); // 使用QueryBuilders.multiMatchQuery构建一个查询条件（搜索title、jd），并配置到SearchSourceBuilder MultiMatchQueryBuilder multiMatchQueryBuilder = QueryBuilders.multiMatchQuery(keywords, &quot;title&quot;, &quot;jd&quot;); searchSourceBuilder.query(multiMatchQueryBuilder);// 将查询条件设置到查询请求构建器中 HighlightBuilder highlightBuilder = new HighlightBuilder(); // 设置高亮 highlightBuilder.field(&quot;title&quot;); highlightBuilder.field(&quot;jd&quot;); highlightBuilder.preTags(&quot;&lt;font color=&#x27;red&#x27;&gt;&quot;); highlightBuilder.postTags(&quot;&lt;/font&gt;&quot;); searchSourceBuilder.highlighter(highlightBuilder); // 给请求设置高亮 searchSourceBuilder.size(pageSize); // 每页显示多少条 searchRequest.source(searchSourceBuilder); // 调用SearchRequest.source将查询条件设置到检索请求 searchRequest.scroll(TimeValue.timeValueMinutes(5)); // 设置scroll查询 // 执行RestHighLevelClient.search发起请求 searchResponse = restHighLevelClient.search(searchRequest, RequestOptions.DEFAULT); &#125; else &#123; // 第二次查询的时候，直接通过scroll id查询数据 SearchScrollRequest searchScrollRequest = new SearchScrollRequest(scrollId); searchScrollRequest.scroll(TimeValue.timeValueMinutes(5)); // 使用RestHighLevelClient发送scroll请求 searchResponse = restHighLevelClient.scroll(searchScrollRequest, RequestOptions.DEFAULT); &#125; SearchHit[] hitArray = searchResponse.getHits().getHits(); ArrayList&lt;JobDetail&gt; jobDetailArrayList = new ArrayList&lt;&gt;(); for (SearchHit documentFields : hitArray) &#123; // 遍历结果，迭代ES响应的数据 String json = documentFields.getSourceAsString(); // 获取命中的结果 JobDetail jobDetail = JSONObject.parseObject(json, JobDetail.class); // 将JSON字符串转换为对象 jobDetail.setId(Long.parseLong(documentFields.getId())); // 使用SearchHit.getId设置文档ID jobDetailArrayList.add(jobDetail); // 设置高亮的一些文本到实体类中 封装了高亮 Map&lt;String, HighlightField&gt; highlightFieldMap = documentFields.getHighlightFields(); HighlightField titleHL = highlightFieldMap.get(&quot;title&quot;); HighlightField jdHL = highlightFieldMap.get(&quot;jd&quot;); if(titleHL != null) &#123; Text[] fragments = titleHL.getFragments(); // 获取指定字段的高亮片段 StringBuilder builder = new StringBuilder(); for(Text text : fragments) &#123; // 将这些高亮片段拼接成一个完整的高亮字段 builder.append(text); &#125; jobDetail.setTitle(builder.toString()); // 设置到实体类中 &#125; if(jdHL != null) &#123; Text[] fragments = jdHL.getFragments(); // 获取指定字段的高亮片段 StringBuilder builder = new StringBuilder(); for(Text text : fragments) &#123;// 将这些高亮片段拼接成一个完整的高亮字段 builder.append(text); &#125; jobDetail.setJd(builder.toString()); // 设置到实体类中 &#125; &#125; // 将结果封装到Map结构中，带有分页信息 long totalNum = searchResponse.getHits().getTotalHits().value; Map&lt;String, Object&gt; hashMap = new HashMap&lt;&gt;(); hashMap.put(&quot;scroll_id&quot;, searchResponse.getScrollId()); hashMap.put(&quot;content&quot;, jobDetailArrayList); // content -&gt; 当前分页中的数据 hashMap.put(&quot;total_num&quot;, totalNum); // total -&gt; 使用SearchHits.getTotalHits().value获取到所有的记录数 return hashMap;&#125;public void close() throws IOException &#123; restHighLevelClient.close();&#125; 京东商城搜索效果实现ES索引库表结构分析 1234567891011121314151617181920212223242526272829303132333435363738PUT product_db // 创建索引库&#123;&quot;mappings&quot;:&#123;&quot;properties&quot;:&#123;&quot;id&quot;:&#123;&quot;type&quot;:&quot;long&quot;&#125;,&quot;name&quot;:&#123;&quot;type&quot;:&quot;text&quot;,&quot;analyzer&quot;:&quot;ik_max_word&quot;&#125;,&quot;keywords&quot;:&#123;&quot;type&quot;:&quot;text&quot;,&quot;analyzer&quot;:&quot;ik_max_word&quot;&#125;,&quot;subTitle&quot;:&#123;&quot;type&quot;:&quot;text&quot;,&quot;analyzer&quot;:&quot;ik_max_word&quot;&#125;,&quot;salecount&quot;:&#123;&quot;type&quot;:&quot;long&quot;&#125;,&quot;putawayDate&quot;:&#123;&quot;type&quot;:&quot;date&quot;&#125;,&quot;price&quot;:&#123;&quot;type&quot;:&quot;double&quot;&#125;,&quot;promotionPrice&quot;:&#123;&quot;type&quot;:&quot;keyword&quot;&#125;,&quot;originalPrice&quot;:&#123;&quot;type&quot;:&quot;keyword&quot;&#125;,&quot;pic&quot;:&#123;&quot;type&quot;:&quot;keyword&quot;&#125;,&quot;sale&quot;:&#123;&quot;type&quot;:&quot;long&quot;&#125;,&quot;hasStock&quot;:&#123;&quot;type&quot;:&quot;boolean&quot;&#125;,&quot;brandId&quot;:&#123;&quot;type&quot;:&quot;long&quot;&#125;,&quot;brandName&quot;:&#123;&quot;type&quot;:&quot;keyword&quot;&#125;,&quot;brandImg&quot;:&#123;&quot;type&quot;:&quot;keyword&quot;&#125;,&quot;categoryId&quot;:&#123;&quot;type&quot;:&quot;long&quot;&#125;,&quot;categoryName&quot;:&#123;&quot;type&quot;:&quot;keyword&quot;&#125;,&quot;attrs&quot;:&#123;&quot;type&quot;:&quot;nested&quot;,&quot;properties&quot;:&#123;&quot;attrId&quot;:&#123;&quot;type&quot;:&quot;long&quot;&#125;,&quot;attrName&quot;:&#123;&quot;type&quot;:&quot;keyword&quot;&#125;,&quot;attrValue&quot;:&#123;&quot;type&quot;:&quot;keyword&quot;&#125;&#125;&#125;&#125;&#125;&#125;// 索引数据准备PUT /product_db/_doc/1&#123;&quot;id&quot;:&quot;26&quot;,&quot;name&quot;:&quot;小米 11 手机&quot;,&quot;keywords&quot;:&quot;小米手机&quot;,&quot;subTitle&quot;:&quot;AI智慧全面屏 6GB +64GB 亮黑色 全网通版 移动联通电信4G手机 双卡双待 双卡双待&quot;,&quot;price&quot;:&quot;3999&quot;,&quot;promotionPrice&quot;:&quot;2999&quot;,&quot;originalPrice&quot;:&quot;5999&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/xiaomi.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:999,&quot;putawayDate&quot;:&quot;2021-04-01&quot;,&quot;brandId&quot;:6,&quot;brandName&quot;:&quot;小米&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/1e34aef2a409119018a4c6258e39ecfb_222_222.png&quot;,&quot;categoryId&quot;:19,&quot;categoryName&quot;:&quot;手机通讯&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:1,&quot;attrName&quot;:&quot;cpu&quot;,&quot;attrValue&quot;:&quot;2核&quot;&#125;,&#123;&quot;attrId&quot;:2,&quot;attrName&quot;:&quot;颜色&quot;,&quot;attrValue&quot;:&quot;黑色&quot;&#125;]&#125;PUT /product_db/_doc/2&#123;&quot;id&quot;:&quot;27&quot;,&quot;name&quot;:&quot;小米 10 手机&quot;,&quot;keywords&quot;:&quot;小米手机&quot;,&quot;subTitle&quot;:&quot;AI智慧全面屏 4GB +64GB 亮白色 全网通版 移动联通电信4G手机 双卡双待 双卡双待&quot;,&quot;price&quot;:&quot;2999&quot;,&quot;promotionPrice&quot;:&quot;1999&quot;,&quot;originalPrice&quot;:&quot;3999&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/xiaomi.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:false,&quot;salecount&quot;:99,&quot;putawayDate&quot;:&quot;2021-04-02&quot;,&quot;brandId&quot;:6,&quot;brandName&quot;:&quot;小米&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/1e34aef2a409119018a4c6258e39ecfb_222_222.png&quot;,&quot;categoryId&quot;:19,&quot;categoryName&quot;:&quot;手机通讯&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:1,&quot;attrName&quot;:&quot;cpu&quot;,&quot;attrValue&quot;:&quot;4核&quot;&#125;,&#123;&quot;attrId&quot;:2,&quot;attrName&quot;:&quot;颜色&quot;,&quot;attrValue&quot;:&quot;白色&quot;&#125;]&#125;PUT /product_db/_doc/3&#123;&quot;id&quot;:&quot;28&quot;,&quot;name&quot;:&quot;小米 手机&quot;,&quot;keywords&quot;:&quot;小米手机&quot;,&quot;subTitle&quot;:&quot;AI智慧全面屏 4GB +64GB 亮蓝色 全网通版 移动联通电信4G手机 双卡双待 双卡双待&quot;,&quot;price&quot;:&quot;2999&quot;,&quot;promotionPrice&quot;:&quot;1999&quot;,&quot;originalPrice&quot;:&quot;3999&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/xiaomi.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:199,&quot;putawayDate&quot;:&quot;2021-04-03&quot;,&quot;brandId&quot;:6,&quot;brandName&quot;:&quot;小米&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/1e34aef2a409119018a4c6258e39ecfb_222_222.png&quot;,&quot;categoryId&quot;:19,&quot;categoryName&quot;:&quot;手机通讯&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:1,&quot;attrName&quot;:&quot;cpu&quot;,&quot;attrValue&quot;:&quot;2核&quot;&#125;,&#123;&quot;attrId&quot;:2,&quot;attrName&quot;:&quot;颜色&quot;,&quot;attrValue&quot;:&quot;蓝色&quot;&#125;]&#125;PUT /product_db/_doc/4&#123;&quot;id&quot;:&quot;29&quot;,&quot;name&quot;:&quot;Apple iPhone 8 Plus 64GB 金色特别版 移动联通电信4G手机&quot;,&quot;keywords&quot;:&quot;苹果手机&quot;,&quot;subTitle&quot;:&quot;苹果手机 Apple产品年中狂欢节，好物尽享，美在智慧！速来 &gt;&gt; 勾选[保障服务][原厂保2年]，获得AppleCare+全方位服务计划，原厂延保售后无忧。&quot;,&quot;price&quot;:&quot;5999&quot;,&quot;promotionPrice&quot;:&quot;4999&quot;,&quot;originalPrice&quot;:&quot;7999&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/5acc5248N6a5f81cd.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:1199,&quot;putawayDate&quot;:&quot;2021-04-04&quot;,&quot;brandId&quot;:51,&quot;brandName&quot;:&quot;苹果&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180607/timg.jpg&quot;,&quot;categoryId&quot;:19,&quot;categoryName&quot;:&quot;手机通讯&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:1,&quot;attrName&quot;:&quot;cpu&quot;,&quot;attrValue&quot;:&quot;4核&quot;&#125;,&#123;&quot;attrId&quot;:2,&quot;attrName&quot;:&quot;颜色&quot;,&quot;attrValue&quot;:&quot;金色&quot;&#125;]&#125;PUT /product_db/_doc/5&#123;&quot;id&quot;:&quot;30&quot;,&quot;name&quot;:&quot;HLA海澜之家简约动物印花短袖T恤&quot;,&quot;keywords&quot;:&quot;海澜之家衣服&quot;,&quot;subTitle&quot;:&quot;HLA海澜之家短袖T恤&quot;,&quot;price&quot;:&quot;199&quot;,&quot;promotionPrice&quot;:&quot;99&quot;,&quot;originalPrice&quot;:&quot;299&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/5ad83a4fN6ff67ecd.jpg!cc_350x449.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:19,&quot;putawayDate&quot;:&quot;2021-04-05&quot;,&quot;brandId&quot;:50,&quot;brandName&quot;:&quot;海澜之家&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/99d3279f1029d32b929343b09d3c72de_222_222.jpg&quot;,&quot;categoryId&quot;:8,&quot;categoryName&quot;:&quot;T恤&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:3,&quot;attrName&quot;:&quot;尺寸&quot;,&quot;attrValue&quot;:&quot;M&quot;&#125;,&#123;&quot;attrId&quot;:4,&quot;attrName&quot;:&quot;颜色&quot;,&quot;attrValue&quot;:&quot;黑色&quot;&#125;]&#125;PUT /product_db/_doc/6&#123;&quot;id&quot;:&quot;31&quot;,&quot;name&quot;:&quot;HLA海澜之家蓝灰花纹圆领针织布短袖T恤&quot;,&quot;keywords&quot;:&quot;海澜之家衣服&quot;,&quot;subTitle&quot;:&quot;HLA海澜之家短袖T恤&quot;,&quot;price&quot;:&quot;299&quot;,&quot;promotionPrice&quot;:&quot;199&quot;,&quot;originalPrice&quot;:&quot;299&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/5ac98b64N70acd82f.jpg!cc_350x449.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:399,&quot;putawayDate&quot;:&quot;2021-04-06&quot;,&quot;brandId&quot;:50,&quot;brandName&quot;:&quot;海澜之家&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/99d3279f1029d32b929343b09d3c72de_222_222.jpg&quot;,&quot;categoryId&quot;:8,&quot;categoryName&quot;:&quot;T恤&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:3,&quot;attrName&quot;:&quot;尺寸&quot;,&quot;attrValue&quot;:&quot;X&quot;&#125;,&#123;&quot;attrId&quot;:4,&quot;attrName&quot;:&quot;颜色&quot;,&quot;attrValue&quot;:&quot;蓝灰&quot;&#125;]&#125;PUT /product_db/_doc/7&#123;&quot;id&quot;:&quot;32&quot;,&quot;name&quot;:&quot;HLA海澜之家短袖T恤男基础款&quot;,&quot;keywords&quot;:&quot;海澜之家衣服&quot;,&quot;subTitle&quot;:&quot;HLA海澜之家短袖T恤&quot;,&quot;price&quot;:&quot;269&quot;,&quot;promotionPrice&quot;:&quot;169&quot;,&quot;originalPrice&quot;:&quot;399&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/5a51eb88Na4797877.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:399,&quot;putawayDate&quot;:&quot;2021-04-07&quot;,&quot;brandId&quot;:50,&quot;brandName&quot;:&quot;海澜之家&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/99d3279f1029d32b929343b09d3c72de_222_222.jpg&quot;,&quot;categoryId&quot;:8,&quot;categoryName&quot;:&quot;T恤&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:3,&quot;attrName&quot;:&quot;尺寸&quot;,&quot;attrValue&quot;:&quot;L&quot;&#125;,&#123;&quot;attrId&quot;:4,&quot;attrName&quot;:&quot;颜色&quot;,&quot;attrValue&quot;:&quot;蓝色&quot;&#125;]&#125;PUT /product_db/_doc/8&#123;&quot;id&quot;:&quot;33&quot;,&quot;name&quot;:&quot;小米（MI）小米电视4A &quot;,&quot;keywords&quot;:&quot;小米电视机家用电器&quot;,&quot;subTitle&quot;:&quot;小米（MI）小米电视4A 55英寸 L55M5-AZ/L55M5-AD 2GB+8GB HDR 4K超高清 人工智能网络液晶平板电视&quot;,&quot;price&quot;:&quot;2269&quot;,&quot;promotionPrice&quot;:&quot;2169&quot;,&quot;originalPrice&quot;:&quot;2399&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/5b02804dN66004d73.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:132,&quot;putawayDate&quot;:&quot;2021-04-09&quot;,&quot;brandId&quot;:6,&quot;brandName&quot;:&quot;小米&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/1e34aef2a409119018a4c6258e39ecfb_222_222.png&quot;,&quot;categoryId&quot;:35,&quot;categoryName&quot;:&quot;手机数码&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:5,&quot;attrName&quot;:&quot;屏幕尺寸&quot;,&quot;attrValue&quot;:&quot;52&quot;&#125;,&#123;&quot;attrId&quot;:6,&quot;attrName&quot;:&quot;机身颜色&quot;,&quot;attrValue&quot;:&quot;黑色&quot;&#125;]&#125;PUT /product_db/_doc/9&#123;&quot;id&quot;:&quot;34&quot;,&quot;name&quot;:&quot;小米（MI）小米电视4A 65英寸&quot;,&quot;keywords&quot;:&quot;小米电视机家用电器&quot;,&quot;subTitle&quot;:&quot;小米（MI）小米电视4A 65英寸 L55M5-AZ/L55M5-AD 2GB+8GB HDR 4K超高清 人工智能网络液晶平板电视&quot;,&quot;price&quot;:&quot;3269&quot;,&quot;promotionPrice&quot;:&quot;3169&quot;,&quot;originalPrice&quot;:&quot;3399&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/5b028530N51eee7d4.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:999,&quot;putawayDate&quot;:&quot;2021-04-10&quot;,&quot;brandId&quot;:6,&quot;brandName&quot;:&quot;小米&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/1e34aef2a409119018a4c6258e39ecfb_222_222.png&quot;,&quot;categoryId&quot;:35,&quot;categoryName&quot;:&quot;手机数码&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:5,&quot;attrName&quot;:&quot;屏幕尺寸&quot;,&quot;attrValue&quot;:&quot;65&quot;&#125;,&#123;&quot;attrId&quot;:6,&quot;attrName&quot;:&quot;机身颜色&quot;,&quot;attrValue&quot;:&quot;金色&quot;&#125;]&#125;PUT /product_db/_doc/10&#123;&quot;id&quot;:&quot;35&quot;,&quot;name&quot;:&quot;耐克NIKE 男子 休闲鞋 ROSHE RUN 运动鞋 511881-010黑色41码&quot;,&quot;keywords&quot;:&quot;耐克运动鞋 鞋子&quot;,&quot;subTitle&quot;:&quot;耐克NIKE 男子 休闲鞋 ROSHE RUN 运动鞋 511881-010黑色41码&quot;,&quot;price&quot;:&quot;569&quot;,&quot;promotionPrice&quot;:&quot;369&quot;,&quot;originalPrice&quot;:&quot;899&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/5b235bb9Nf606460b.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:399,&quot;putawayDate&quot;:&quot;2021-04-11&quot;,&quot;brandId&quot;:58,&quot;brandName&quot;:&quot;NIKE&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/timg (51).jpg&quot;,&quot;categoryId&quot;:29,&quot;categoryName&quot;:&quot;男鞋&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:7,&quot;attrName&quot;:&quot;尺码&quot;,&quot;attrValue&quot;:&quot;42&quot;&#125;,&#123;&quot;attrId&quot;:8,&quot;attrName&quot;:&quot;颜色&quot;,&quot;attrValue&quot;:&quot;黑色&quot;&#125;]&#125;PUT /product_db/_doc/11&#123;&quot;id&quot;:&quot;36&quot;,&quot;name&quot;:&quot;耐克NIKE 男子 气垫 休闲鞋 AIR MAX 90 ESSENTIAL 运动鞋 AJ1285-101白色41码&quot;,&quot;keywords&quot;:&quot;耐克运动鞋 鞋子&quot;,&quot;subTitle&quot;:&quot;AIR MAX 90 ESSENTIAL 运动鞋 AJ1285-101白色&quot;,&quot;price&quot;:&quot;769&quot;,&quot;promotionPrice&quot;:&quot;469&quot;,&quot;originalPrice&quot;:&quot;999&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/5b19403eN9f0b3cb8.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:499,&quot;putawayDate&quot;:&quot;2021-04-13&quot;,&quot;brandId&quot;:58,&quot;brandName&quot;:&quot;NIKE&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/timg (51).jpg&quot;,&quot;categoryId&quot;:29,&quot;categoryName&quot;:&quot;男鞋&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:7,&quot;attrName&quot;:&quot;尺码&quot;,&quot;attrValue&quot;:&quot;44&quot;&#125;,&#123;&quot;attrId&quot;:8,&quot;attrName&quot;:&quot;颜色&quot;,&quot;attrValue&quot;:&quot;白色&quot;&#125;]&#125;PUT /product_db/_doc/12&#123;&quot;id&quot;:&quot;37&quot;,&quot;name&quot;:&quot;(华为)HUAWEI MateBook X Pro 2019款 13.9英寸3K触控全面屏 轻薄笔记本&quot;,&quot;keywords&quot;:&quot;轻薄笔记本华为 笔记本电脑&quot;,&quot;subTitle&quot;:&quot;轻薄华为笔记本 电脑&quot;,&quot;price&quot;:&quot;4769&quot;,&quot;promotionPrice&quot;:&quot;4469&quot;,&quot;originalPrice&quot;:&quot;4999&quot;,&quot;pic&quot;:&quot;http://tuling-mall.oss-cn-shenzhen.aliyuncs.com/tulingmall/images/20200317/800_800_1555752016264mp.png&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:699,&quot;putawayDate&quot;:&quot;2021-04-14&quot;,&quot;brandId&quot;:3,&quot;brandName&quot;:&quot;华为&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/17f2dd9756d9d333bee8e60ce8c03e4c_222_222.jpg&quot;,&quot;categoryId&quot;:19,&quot;categoryName&quot;:&quot;手机通讯&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:9,&quot;attrName&quot;:&quot;容量&quot;,&quot;attrValue&quot;:&quot;16G&quot;&#125;,&#123;&quot;attrId&quot;:10,&quot;attrName&quot;:&quot;网络&quot;,&quot;attrValue&quot;:&quot;4G&quot;&#125;]&#125;PUT /product_db/_doc/13&#123;&quot;id&quot;:&quot;38&quot;,&quot;name&quot;:&quot;华为nova6se 手机 绮境森林 全网通（8G+128G)&quot;,&quot;keywords&quot;:&quot;轻薄笔记本华为 手机&quot;,&quot;subTitle&quot;:&quot;华为nova6se 手机&quot;,&quot;price&quot;:&quot;6769&quot;,&quot;promotionPrice&quot;:&quot;6469&quot;,&quot;originalPrice&quot;:&quot;6999&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180607/5ac1bf58Ndefaac16.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:899,&quot;putawayDate&quot;:&quot;2021-04-15&quot;,&quot;brandId&quot;:3,&quot;brandName&quot;:&quot;华为&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/17f2dd9756d9d333bee8e60ce8c03e4c_222_222.jpg&quot;,&quot;categoryId&quot;:19,&quot;categoryName&quot;:&quot;手机通讯&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:9,&quot;attrName&quot;:&quot;容量&quot;,&quot;attrValue&quot;:&quot;64G&quot;&#125;,&#123;&quot;attrId&quot;:10,&quot;attrName&quot;:&quot;网络&quot;,&quot;attrValue&quot;:&quot;5G&quot;&#125;]&#125;PUT /product_db/_doc/14&#123;&quot;id&quot;:&quot;39&quot;,&quot;name&quot;:&quot;iPhone7/6s/8钢化膜苹果8Plus全屏复盖抗蓝光防窥防偷看手机膜&quot;,&quot;keywords&quot;:&quot;手机膜&quot;,&quot;subTitle&quot;:&quot;iPhone7/6s/8钢化膜苹果8Plus全屏复盖抗蓝光防窥防偷看手机膜&quot;,&quot;price&quot;:&quot;29&quot;,&quot;promotionPrice&quot;:&quot;39&quot;,&quot;originalPrice&quot;:&quot;49&quot;,&quot;pic&quot;:&quot;http://tuling-mall.oss-cn-shenzhen.aliyuncs.com/tulingmall/images/20200311/6df99dab78bb2014.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:799,&quot;putawayDate&quot;:&quot;2021-04-16&quot;,&quot;brandId&quot;:51,&quot;brandName&quot;:&quot;苹果&quot;,&quot;brandImg&quot;:&quot;http://tuling-mall.oss-cn-shenzhen.aliyuncs.com/tulingmall/images/20200311/2b84746650fc122d67749a876c453619.png&quot;,&quot;categoryId&quot;:30,&quot;categoryName&quot;:&quot;手机配件&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:11,&quot;attrName&quot;:&quot;手机膜-材料&quot;,&quot;attrValue&quot;:&quot;钢化&quot;&#125;,&#123;&quot;attrId&quot;:12,&quot;attrName&quot;:&quot;手机膜-颜色&quot;,&quot;attrValue&quot;:&quot;白色&quot;&#125;]&#125;PUT /product_db/_doc/15&#123;&quot;id&quot;:&quot;40&quot;,&quot;name&quot;:&quot;七匹狼短袖T恤男纯棉舒适春夏修身运动休闲短袖三条装 圆领3条装&quot;,&quot;keywords&quot;:&quot;七匹狼服装 衣服&quot;,&quot;subTitle&quot;:&quot;七匹狼短袖T恤男纯棉舒适春夏修身运动休闲短袖三条装 圆领3条装&quot;,&quot;price&quot;:&quot;129&quot;,&quot;promotionPrice&quot;:&quot;139&quot;,&quot;originalPrice&quot;:&quot;149&quot;,&quot;pic&quot;:&quot;http://tuling-mall.oss-cn-shenzhen.aliyuncs.com/tulingmall/images/20200311/19e846e727dff337.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:199,&quot;putawayDate&quot;:&quot;2021-04-20&quot;,&quot;brandId&quot;:49,&quot;brandName&quot;:&quot;七匹狼&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/18d8bc3eb13533fab466d702a0d3fd1f40345bcd.jpg&quot;,&quot;categoryId&quot;:8,&quot;categoryName&quot;:&quot;T恤&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:3,&quot;attrName&quot;:&quot;尺寸&quot;,&quot;attrValue&quot;:&quot;M&quot;&#125;,&#123;&quot;attrId&quot;:4,&quot;attrName&quot;:&quot;颜色&quot;,&quot;attrValue&quot;:&quot;白色&quot;&#125;]&#125;PUT /product_db/_doc/16&#123;&quot;id&quot;:&quot;41&quot;,&quot;name&quot;:&quot;华为P40 Pro手机&quot;,&quot;keywords&quot;:&quot;华为手机&quot;,&quot;subTitle&quot;:&quot;华为P40 Pro手机&quot;,&quot;price&quot;:&quot;2129&quot;,&quot;promotionPrice&quot;:&quot;2139&quot;,&quot;originalPrice&quot;:&quot;2149&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180607/5ac1bf58Ndefaac16.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:199,&quot;putawayDate&quot;:&quot;2021-05-03&quot;,&quot;brandId&quot;:3,&quot;brandName&quot;:&quot;华为&quot;,&quot;brandImg&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20190129/17f2dd9756d9d333bee8e60ce8c03e4c_222_222.jpg&quot;,&quot;categoryId&quot;:19,&quot;categoryName&quot;:&quot;手机通讯&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:9,&quot;attrName&quot;:&quot;容量&quot;,&quot;attrValue&quot;:&quot;128G&quot;&#125;,&#123;&quot;attrId&quot;:10,&quot;attrName&quot;:&quot;网络&quot;,&quot;attrValue&quot;:&quot;5G&quot;&#125;]&#125;PUT /product_db/_doc/17&#123;&quot;id&quot;:&quot;42&quot;,&quot;name&quot;:&quot;朵唯智能手机 4G全网通 老人学生双卡双待手机&quot;,&quot;keywords&quot;:&quot;朵唯手机&quot;,&quot;subTitle&quot;:&quot;朵唯手机后置双摄，国产虎贲芯片！优化散热结构！浅薄机身！朵唯4月特惠！&quot;,&quot;price&quot;:&quot;3129&quot;,&quot;promotionPrice&quot;:&quot;3139&quot;,&quot;originalPrice&quot;:&quot;3249&quot;,&quot;pic&quot;:&quot;http://macro-oss.oss-cn-shenzhen.aliyuncs.com/mall/images/20180615/xiaomi.jpg&quot;,&quot;sale&quot;:999,&quot;hasStock&quot;:true,&quot;salecount&quot;:1199,&quot;putawayDate&quot;:&quot;2021-06-01&quot;,&quot;brandId&quot;:59,&quot;brandName&quot;:&quot;朵唯&quot;,&quot;brandImg&quot;:&quot;http://tuling-mall.oss-cn-shenzhen.aliyuncs.com/tulingmall/images/20200311/2b84746650fc122d67749a876c453619.png&quot;,&quot;categoryId&quot;:19,&quot;categoryName&quot;:&quot;手机通讯&quot;,&quot;attrs&quot;:[&#123;&quot;attrId&quot;:9,&quot;attrName&quot;:&quot;容量&quot;,&quot;attrValue&quot;:&quot;32G&quot;&#125;,&#123;&quot;attrId&quot;:10,&quot;attrName&quot;:&quot;网络&quot;,&quot;attrValue&quot;:&quot;4G&quot;&#125;]&#125; 检索DSL语句构建 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647POST /product_db/_doc/_search&#123; &quot;from&quot;: 0, &quot;size&quot;: 8, &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [&#123;&quot;match&quot;: &#123;&quot;name&quot;: &#123;&quot;query&quot;: &quot;手机&quot;&#125;&#125;&#125;], &quot;filter&quot;: [ &#123;&quot;term&quot;: &#123;&quot;hasStock&quot;: &#123;&quot;value&quot;: true&#125;&#125;&#125;, &#123;&quot;range&quot;: &#123;&quot;price&quot;: &#123;&quot;from&quot;: &quot;1&quot;,&quot;to&quot;: &quot;5000&quot;&#125;&#125;&#125; ] &#125; &#125;, &quot;sort&quot;: [&#123;&quot;salecount&quot;: &#123;&quot;order&quot;: &quot;asc&quot;&#125;&#125;], &quot;aggregations&quot;: &#123; &quot;brand_agg&quot;: &#123; &quot;terms&quot;: &#123;&quot;field&quot;: &quot;brandId&quot;,&quot;size&quot;: 50&#125;, &quot;aggregations&quot;: &#123; &quot;brand_name_agg&quot;: &#123;&quot;terms&quot;: &#123;&quot;field&quot;: &quot;brandName&quot;&#125;&#125;, &quot;brand_img_agg&quot;: &#123;&quot;terms&quot;: &#123;&quot;field&quot;: &quot;brandImg&quot;&#125;&#125; &#125; &#125;, &quot;category_agg&quot;: &#123; &quot;terms&quot;: &#123;&quot;field&quot;: &quot;categoryId&quot;,&quot;size&quot;: 50,&quot;min_doc_count&quot;: 1&#125;, &quot;aggregations&quot;: &#123; &quot;category_name_agg&quot;: &#123;&quot;terms&quot;: &#123;&quot;field&quot;: &quot;categoryName&quot;&#125;&#125; &#125; &#125;, &quot;attr_agg&quot;: &#123; &quot;nested&quot;: &#123;&quot;path&quot;: &quot;attrs&quot;&#125;, &quot;aggregations&quot;: &#123; &quot;attr_id_agg&quot;: &#123; &quot;terms&quot;: &#123;&quot;field&quot;: &quot;attrs.attrId&quot;&#125;, &quot;aggregations&quot;: &#123; &quot;attr_name_agg&quot;: &#123;&quot;terms&quot;: &#123;&quot;field&quot;: &quot;attrs.attrName&quot;&#125;&#125;, &quot;attr_value_agg&quot;: &#123;&quot;terms&quot;: &#123;&quot;field&quot;: &quot;attrs.attrValue&quot;&#125;&#125; &#125; &#125; &#125; &#125; &#125;, &quot;highlight&quot;: &#123; &quot;pre_tags&quot;: [&quot;&lt;b style=&#x27;color:red&#x27;&gt;&quot;], &quot;post_tags&quot;: [&quot;&lt;/b&gt;&quot;], &quot;fields&quot;: &#123;&quot;name&quot;: &#123;&#125;&#125; &#125;&#125; Java代码实现 1234567@ResponseBody@RequestMapping(value = &quot;/searchList&quot;)public CommonResult&lt;ESResponseResult&gt; listPage(ESRequestParam param, HttpServletRequest request) &#123; // 根据传递来的页面的查询参数，去es中检索商品 ESResponseResult searchResult = tulingMallSearchService.search(param); return CommonResult.success(searchResult);&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221@Overridepublic ESResponseResult search(ESRequestParam param) &#123; try &#123; // 构建检索对象-封装请求相关参数信息 SearchRequest searchRequest = startBuildRequestParam(param); // 进行检索操作 SearchResponse response = client.search(searchRequest, RequestOptions.DEFAULT); // 分析响应数据，封装成指定的格式 ESResponseResult responseResult = startBuildResponseResult(response, param); return responseResult; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null;&#125;/** * 封装请求参数信息，关键字查询、根据属性、分类、品牌、价格区间、是否有库存等进行过滤、分页、高亮、以及聚合统计品牌分类属性 */private SearchRequest startBuildRequestParam(ESRequestParam param) &#123; SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); // 关键字查询、根据属性、分类、品牌、价格区间、是否有库存等进行过滤、分页、高亮、以及聚合统计品牌分类属性 BoolQueryBuilder boolQueryBuilder = new BoolQueryBuilder(); if (!StringUtils.isEmpty(param.getKeyword())) &#123; //单字段查询 boolQueryBuilder.must(QueryBuilders.matchQuery(&quot;name&quot;, param.getKeyword())); //多字段查询 boolQueryBuilder.must(QueryBuilders.multiMatchQuery(param.getKeyword(),&quot;name&quot;,&quot;keywords&quot;,&quot;subTitle&quot;)); &#125; // 根据类目ID进行过滤 if (null != param.getCategoryId()) &#123; boolQueryBuilder.filter(QueryBuilders.termQuery(&quot;categoryId&quot;, param.getCategoryId())); &#125; // 根据品牌ID进行过滤 if (null != param.getBrandId() &amp;&amp; param.getBrandId().size() &gt; 0) &#123; boolQueryBuilder.filter(QueryBuilders.termsQuery(&quot;brandId&quot;, param.getBrandId())); &#125; // 根据属性进行相关过滤 if (param.getAttrs() != null &amp;&amp; param.getAttrs().size() &gt; 0) &#123; param.getAttrs().forEach(item -&gt; &#123; //attrs=1_白色&amp;2_4核 BoolQueryBuilder boolQuery = QueryBuilders.boolQuery(); //attrs=1_64G String[] s = item.split(&quot;_&quot;); String attrId = s[0]; String[] attrValues = s[1].split(&quot;:&quot;);//这个属性检索用的值 boolQuery.must(QueryBuilders.termQuery(&quot;attrs.attrId&quot;, attrId)); boolQuery.must(QueryBuilders.termsQuery(&quot;attrs.attrValue&quot;, attrValues)); NestedQueryBuilder nestedQueryBuilder = QueryBuilders.nestedQuery(&quot;attrs&quot;, boolQuery, ScoreMode.None); boolQueryBuilder.filter(nestedQueryBuilder); &#125;); &#125; // 是否有库存 if (null != param.getHasStock()) &#123; boolQueryBuilder.filter(QueryBuilders.termQuery(&quot;hasStock&quot;, param.getHasStock() == 1)); &#125; // 根据价格过滤 if (!StringUtils.isEmpty(param.getPrice())) &#123; // 价格的输入形式为：10-100（起始价格和最终价格）或-100（不指定起始价格）或10-（不限制最终价格） RangeQueryBuilder rangeQueryBuilder = QueryBuilders.rangeQuery(&quot;price&quot;); String[] price = param.getPrice().split(&quot;_&quot;); if (price.length == 2) &#123; rangeQueryBuilder.gte(price[0]).lte(price[1]); &#125; else if (price.length == 1) &#123; if (param.getPrice().startsWith(&quot;_&quot;)) &#123; rangeQueryBuilder.lte(price[1]); &#125; if (param.getPrice().endsWith(&quot;_&quot;)) &#123; rangeQueryBuilder.gte(price[0]); &#125; &#125; boolQueryBuilder.filter(rangeQueryBuilder); &#125; // 封装所有查询条件 searchSourceBuilder.query(boolQueryBuilder); //实现排序、高亮、分页操作，排序，页面传入的参数值形式 sort=price_asc/desc if (!StringUtils.isEmpty(param.getSort())) &#123; String sort = param.getSort(); String[] sortFileds = sort.split(&quot;_&quot;); System.out.println(&quot;sortFileds:&quot;+sortFileds.length); if(!StringUtils.isEmpty(sortFileds[0]))&#123; SortOrder sortOrder = &quot;asc&quot;.equalsIgnoreCase(sortFileds[1]) ? SortOrder.ASC : SortOrder.DESC; searchSourceBuilder.sort(sortFileds[0], sortOrder); &#125; &#125; // 分页查询 searchSourceBuilder.from((param.getPageNum() - 1) * SearchConstant.PAGE_SIZE); searchSourceBuilder.size(SearchConstant.PAGE_SIZE); // 高亮显示 if (!StringUtils.isEmpty(param.getKeyword())) &#123; HighlightBuilder highlightBuilder = new HighlightBuilder(); highlightBuilder.field(&quot;name&quot;); highlightBuilder.preTags(&quot;&lt;b style=&#x27;color:red&#x27;&gt;&quot;); highlightBuilder.postTags(&quot;&lt;/b&gt;&quot;); searchSourceBuilder.highlighter(highlightBuilder); &#125; // 对品牌、分类信息、属性信息进行聚合分析，按照品牌进行聚合 TermsAggregationBuilder brand_agg = AggregationBuilders.terms(&quot;brand_agg&quot;); brand_agg.field(&quot;brandId&quot;).size(50); // 品牌的子聚合-品牌名聚合 brand_agg.subAggregation(AggregationBuilders.terms(&quot;brand_name_agg&quot;).field(&quot;brandName&quot;).size(1)); // 品牌的子聚合-品牌图片聚合 brand_agg.subAggregation(AggregationBuilders.terms(&quot;brand_img_agg&quot;).field(&quot;brandImg&quot;).size(1)); searchSourceBuilder.aggregation(brand_agg); // 按照分类信息进行聚合 TermsAggregationBuilder category_agg = AggregationBuilders.terms(&quot;category_agg&quot;); category_agg.field(&quot;categoryId&quot;).size(50); category_agg.subAggregation(AggregationBuilders.terms(&quot;category_name_agg&quot;).field(&quot;categoryName&quot;).size(1)); searchSourceBuilder.aggregation(category_agg); // 按照属性信息进行聚合 NestedAggregationBuilder attr_agg = AggregationBuilders.nested(&quot;attr_agg&quot;, &quot;attrs&quot;); // 按照属性ID进行聚合 TermsAggregationBuilder attr_id_agg = AggregationBuilders.terms(&quot;attr_id_agg&quot;).field(&quot;attrs.attrId&quot;); attr_agg.subAggregation(attr_id_agg); // 在每个属性ID下，按照属性名进行聚合 attr_id_agg.subAggregation(AggregationBuilders.terms(&quot;attr_name_agg&quot;).field(&quot;attrs.attrName&quot;).size(1)); // 在每个属性ID下，按照属性值进行聚合 attr_id_agg.subAggregation(AggregationBuilders.terms(&quot;attr_value_agg&quot;).field(&quot;attrs.attrValue&quot;).size(50)); searchSourceBuilder.aggregation(attr_agg); System.out.println(&quot;构建的DSL语句 &#123;&#125;:&quot;+ searchSourceBuilder.toString()); SearchRequest searchRequest = new SearchRequest(new String[]&#123;SearchConstant.INDEX_NAME&#125;, searchSourceBuilder); return searchRequest;&#125;/** * 封装查询到的结果信息，关键字查询、根据属性、分类、品牌、价格区间、是否有库存等进行过滤、分页、高亮、以及聚合统计品牌分类属性 */private ESResponseResult startBuildResponseResult(SearchResponse response, ESRequestParam param) &#123; ESResponseResult result = new ESResponseResult(); // 获取查询到的商品信息 SearchHits hits = response.getHits(); List&lt;EsProduct&gt; esModels = new ArrayList&lt;&gt;(); // 遍历所有商品信息 if (hits.getHits() != null &amp;&amp; hits.getHits().length &gt; 0) &#123; for (SearchHit hit : hits.getHits()) &#123; String sourceAsString = hit.getSourceAsString(); EsProduct esModel = JSON.parseObject(sourceAsString, EsProduct.class); // 判断是否按关键字检索，若是就显示高亮，否则不显示 if (!StringUtils.isEmpty(param.getKeyword())) &#123; // 拿到高亮信息显示标题 HighlightField name = hit.getHighlightFields().get(&quot;name&quot;); // 判断name中是否含有查询的关键字(因为是多字段查询，因此可能不包含指定的关键字，假设不包含则显示原始name字段的信息) String nameValue = name!=null ? name.getFragments()[0].string() : esModel.getName(); esModel.setName(nameValue); &#125; esModels.add(esModel); &#125; &#125; result.setProducts(esModels); // 当前商品涉及到的所有品牌信息，小米手机和小米电脑都属于小米品牌，过滤重复品牌信息 Set&lt;ESResponseResult.BrandVo&gt; brandVos = new LinkedHashSet&lt;&gt;(); // 获取到品牌的聚合 ParsedLongTerms brandAgg = response.getAggregations().get(&quot;brand_agg&quot;); for (Terms.Bucket bucket : brandAgg.getBuckets()) &#123; ESResponseResult.BrandVo brandVo = new ESResponseResult.BrandVo(); // 获取品牌的id long brandId = bucket.getKeyAsNumber().longValue(); brandVo.setBrandId(brandId); // 获取品牌的名字 ParsedStringTerms brandNameAgg = bucket.getAggregations().get(&quot;brand_name_agg&quot;); String brandName = brandNameAgg.getBuckets().get(0).getKeyAsString(); brandVo.setBrandName(brandName); // 获取品牌的LOGO ParsedStringTerms brandImgAgg = bucket.getAggregations().get(&quot;brand_img_agg&quot;); String brandImg = brandImgAgg.getBuckets().get(0).getKeyAsString(); brandVo.setBrandImg(brandImg); System.out.println(&quot;brandId:&quot;+brandId+&quot;brandName:&quot;+brandName+&quot;brandImg&quot;); brandVos.add(brandVo); &#125; System.out.println(&quot;brandVos.size:&quot;+brandVos.size()); result.setBrands(brandVos); // 当前商品相关的所有类目信息，获取到分类的聚合 List&lt;ESResponseResult.categoryVo&gt; categoryVos = new ArrayList&lt;&gt;(); ParsedLongTerms categoryAgg = response.getAggregations().get(&quot;category_agg&quot;); for (Terms.Bucket bucket : categoryAgg.getBuckets()) &#123; ESResponseResult.categoryVo categoryVo = new ESResponseResult.categoryVo(); // 获取分类id String keyAsString = bucket.getKeyAsString(); categoryVo.setCategoryId(Long.parseLong(keyAsString)); // 获取分类名 ParsedStringTerms categoryNameAgg = bucket.getAggregations().get(&quot;category_name_agg&quot;); String categoryName = categoryNameAgg.getBuckets().get(0).getKeyAsString(); categoryVo.setCategoryName(categoryName); categoryVos.add(categoryVo); &#125; result.setCategorys(categoryVos); // 获取商品相关的所有属性信息 List&lt;ESResponseResult.AttrVo&gt; attrVos = new ArrayList&lt;&gt;(); // 获取属性信息的聚合 ParsedNested attrsAgg = response.getAggregations().get(&quot;attr_agg&quot;); ParsedLongTerms attrIdAgg = attrsAgg.getAggregations().get(&quot;attr_id_agg&quot;); for (Terms.Bucket bucket : attrIdAgg.getBuckets()) &#123; ESResponseResult.AttrVo attrVo = new ESResponseResult.AttrVo(); // 获取属性ID值 long attrId = bucket.getKeyAsNumber().longValue(); attrVo.setAttrId(attrId); // 获取属性的名字 ParsedStringTerms attrNameAgg = bucket.getAggregations().get(&quot;attr_name_agg&quot;); String attrName = attrNameAgg.getBuckets().get(0).getKeyAsString(); attrVo.setAttrName(attrName); // 获取属性的值 ParsedStringTerms attrValueAgg = bucket.getAggregations().get(&quot;attr_value_agg&quot;); List&lt;String&gt; attrValues = attrValueAgg.getBuckets().stream().map(item -&gt; item.getKeyAsString()).collect(Collectors.toList()); attrVo.setAttrValue(attrValues); attrVos.add(attrVo); &#125; result.setAttrs(attrVos); // 进行分页操作 result.setPageNum(param.getPageNum()); // 获取总记录数 long total = hits.getTotalHits().value; result.setTotal(total); // 计算总页码 int totalPages = (int) total % SearchConstant.PAGE_SIZE == 0 ? (int) total / SearchConstant.PAGE_SIZE : ((int) total / SearchConstant.PAGE_SIZE + 1); result.setTotalPages(totalPages); List&lt;Integer&gt; pageNavs = new ArrayList&lt;&gt;(); for (int i = 1; i &lt;= totalPages; i++) &#123; pageNavs.add(i); &#125; result.setPageNavs(pageNavs); return result;&#125;","tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"http://example.com/tags/ElasticSearch/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"ElasticSearch","slug":"工具和中间件/搜索引擎技术/ElasticSearch","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/ElasticSearch/"}]},{"title":"ElasticSearch基础","date":"2022-01-02T02:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/ElasticSearch/ElasticSearch基础/","text":"Elasticsearch是什么？ Elasticsearch 是用 Java开发 的当前 最流行 的 开源 的企业级搜索引擎,能够达到 实时搜索, 稳定, 可靠, 快速,安装使用方便。 和Solr一样的,Elasticsearch 是基于 Lucene 进行了封装, 提供了更为便利的访问和调用, Lucene可被认为是迄今为止最先进、性能最好、功能最全的搜索引擎框架。 ES与Solr对比：单纯对已有数据进行搜索时 Solr更快,当实时建立索引时Solr会产生 IO阻塞,查询性能较差,该情况下 Elasticsearch 具有明显优势。 Solr利用Zookeeper进行分布式管理,而 Elasticsearch自带分布式协调管理功能 Solr支持更多格式数据,如JSON、XML、CSV,而 Elasticsearch仅支持JSON文件格式 Solr在传统搜索应用中表现好于Elasticsearch,但在处理实时搜索应用时效率明显低于Elasticsearch Solr是传统搜索应用的有力解决方案,但Elasticsearch更适用于新兴实时搜索应用。 ES与关系型数据库: 关系型数据库 Database数据库 Table表 ROW行 Column列 Elasticsearch Index索引库 Type类型 Document文档 Field字段 ES核心概念: 索引index:一个索引就是一个拥有几分相似特征的文档集合,相当于关系型数据库中的database,一个索引由一个名字来标识, 必须全部是小写字母,且当要对对应于该索引中的文档进行索引搜索、更新和删除时,都要使用该名字。 Mapping映射:ElasticSearch中的Mapping映射用来定义一个文档,Mapping是处理数据的方式和规则方面做一些限制,如某个字段的数据类型、默认值、分词器、是否被索引等,这都是映射里面可设置的。 Field字段:相当于是数据表的字段或列。 Type字段类型：每个字段都应该有一个对应的类型,如 Text、Keyword、Byte 等。 Document文档：一个文档是一个可被索引的基础信息单元,类似一条记录, 文档以JSON格式来表示。 Cluster集群：一个集群由一个或多个节点组织在一起, 共同持有整个数据,并一起提供索引和搜索功能 Node节点：一个节点即集群中一个服务器,作为集群的一部分,它存储数据,参与集群的索引和搜索功能,一个节点可通过配置集群名称的方式来加入一个指定的集群。默认每个节点都会被安排加入到一个叫做 elasticsearch的集群中。一个集群中可拥有任意多个节点,且若当前网络中没有运行任何Elasticsearch节点,这时启动一个节点,会默认创建并加入一个叫做 elasticsearch 的集群。 分片：一个索引可存储超出单个结点硬件限制的大量数据,如一个具有10亿文档的索引占据1TB磁盘空间,而任一节点都没有这样大的磁盘空间,或者单个节点处理搜索请求,响应太慢,为了解决这个问题,Elasticsearch提供了将索引划分成多份的能力,每一份就是一个分片。当创建索引时可指定分片数量, 每个分片本身也是一个功能完善且独立的索引,该分片可被放置到集群中任何节点上, 分片允许水平分割扩展内容容量,允许在分片之上进行分布式并行操作,进而提高性能和吞吐量,每个分片怎样分布, 文档怎样聚合回搜索请求,完全由Elasticsearch管理,对于用户透明 副本：在一个网络环境中,失败随时都可能发生,在某个分片或节点处于离线状态,或由于任何原因消失,该情况下有一个故障转移机制是非常有用且强烈推荐。为此 Elasticsearch允许创建分片的一份或多份拷贝,这些拷贝叫做副本分片或直接叫副本。扩展搜索量和吞吐量,搜索可在所有的副本上并行运行, 每个索引可被分成多个分片, 一个索引有零个或者多个副本, 一旦设置了副本,每个索引就有了主分片和副本分片, 分片和副本数量可在索引创建时指定,在索引创建后, 可在任何时候动态地改变副本数量,但不能改变分片数量。 ES安装注： ES不能使用root用户来启动,必须使用普通用户来安装启动。 12345678910groupadd elasticsearch # 创建elasticsearch用户组useradd eleven # 创建eleven用户passwd eleven # 给eleven用户设置密码为elevenusermod -G elasticsearch eleven # 将用户eleven添加到elasticsearch用户组mkdir -p /usr/local/es # 创建es文件夹chown -R eleven /usr/local/es/elasticsearch-7.6.1 # 修改owner为eleven用户visudo # 使用root用户执行visudo命令然后为es用户添加权限eleven ALL=(ALL) ALL # 在root ALL=(ALL) ALL 一行下面添加eleven用户 修改elasticsearch.yml,可通过修改jvm.options配置文件调整JVM参数: 123456789101112cluster.name: eleven-es # 集群名称node.name: node1 # 节点名称path.data: /usr/local/es/elasticsearch-7.6.1/data # 数据目录path.logs: /usr/local/es/elasticsearch-7.6.1/log # 日志目录network.host: 0.0.0.0http.port: 9200discovery.seed_hosts: [&quot;IP1&quot;, &quot;IP2&quot;, &quot;IP3&quot;]cluster.initial_master_nodes: [&quot;节点1名称&quot;, &quot;节点2名称&quot;, &quot;节点3名称&quot;]bootstrap.system_call_filter: falsebootstrap.memory_lock: falsehttp.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot; ES需要大量创建索引文件,需要大量打开系统文件,所以需要解除linux系统当中打开文件最大数目限制,不然ES启动会抛错：max file descriptors [4096] for elasticsearch process likely too low, increase to at least [65536] 12345sudo vim /etc/security/limits.conf* soft nofile 65536* hard nofile 131072* soft nproc 2048* hard nproc 4096 若出现max number of threads [1024] for user [es] likely too low, increase to at least [4096] 错误信息,是由于普通用户启动线程数限制最大可创建线程数太小,无法创建本地线程问题。 安装IK分词器使用ElasticSearch来进行中文分词,需要单独给Elasticsearch安装IK分词器插件, 123mkdir -p /usr/local/es/elasticsearch-7.6.1/plugins/ikcd /usr/local/es/elasticsearch-7.6.1/plugins/ikunzip elasticsearch-analysis-ik-7.6.1.zip ES的默认分词设置是 standard单字拆分,可使用 IK分词器 的 ik_smart 和 ik_max_word 分词方式, ik_smart 会做 最粗粒度拆分, ik_max_word会将文本做最细粒度拆分。修改默认分词方法,修改 eleven_index索引的默认分词为 ik_max_word 1234567891011121314151617181920212223PUT /school_index&#123; &quot;settings&quot;: &#123; &quot;index&quot;: &#123; &quot;analysis.analyzer.default.type&quot;: &quot;ik_max_word&quot; &#125; &#125;&#125;POST _analyze&#123; &quot;analyzer&quot;: &quot;standard&quot;, &quot;text&quot;: &quot;中华人民共和国&quot;&#125;POST _analyze&#123; &quot;analyzer&quot;: &quot;ik_smart&quot;, &quot;text&quot;: &quot;中华人民共和国&quot;&#125;POST _analyze&#123; &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;text&quot;: &quot;中华人民共和国&quot;&#125; ES基础ES是面向文档Document的, 使用JSON作为文档序列化格式,这其可存储整个对象或文档Document,不仅仅是存储,还会索引index每个文档内容使之可被搜索。ES中可对文档而非成行成列的数据进行索引、搜索、排序、过滤。 条件查询：GET /索引名称/类型/_search?q=字段1:字段值,字段2:字段值,条件之间是通过逗号分隔多个条件,如分页、排序、输出指定字段等通过 &amp;符号分隔 123456789101112131415161718192021222324252627GET _cat/nodes?v // 查看集群节点状态GET _cat/health?v // 查看集群健康状态GET /es_db // 查询索引：GET /索引名称PUT /es_db // 创建索引：PUT /索引名称DELETE /es_db // 删除索引：DELETE /索引名称PUT /es_db/_doc/1 // 添加文档：PUT /索引名称/类型/id&#123; &quot;name&quot;: &quot;张三&quot;, &quot;sex&quot;: 1, &quot;age&quot;: 25, &quot;address&quot;: &quot;广州天河公园&quot;, &quot;remark&quot;: &quot;java developer&quot;&#125;GET /es_db/_doc/1 // 查询文档：GET /索引名称/类型/idDELETE /es_db/_doc/1 // 删除文档：DELETE /索引名称/类型/idGET /es_db/_doc/_search // 查询当前类型中的所有文档：GET /索引名称/类型/_searchGET /es_db/_doc/_search?q=age:28 // 条件查询：GET /索引名称/类型/_search?q=*:***GET /es_db/_doc/_search?q=age[25 TO 26] // 范围查询：GET /索引名称/类型/_search?q=***[** TO **]GET /es_db/_doc/_mget // 根据多个ID进行批量查询：GET /索引名称/类型/_mget&#123;&quot;ids&quot;:[&quot;1&quot;,&quot;2&quot;]&#125;GET /es_db/_doc/_search?q=age:&lt;=28 // 查询小于等于：GET /索引名称/类型/_search?q=age:&lt;=**GET /es_db/_doc/_search?q=age:&gt;=28 // 查询大于等于：GET /索引名称/类型/_search?q=age:&gt;=**GET /es_db/_doc/_search?q=age[25 TO 26]&amp;from=0&amp;size=1 // 分页查询：from=*&amp;size=*GET /es_db/_doc/_search?_source=name,age // 对查询结果只输出某些字段：_search?_source=字段,字段GET /es_db/_doc/_search?q=age[25 TO 26],sex:0 // 多条件查询GET /es_db/_doc/_search?sort=age:desc // 对查询结果排序sort=字段:desc/asc ES是基于Restful API和所有客户端交互都是使用JSON格式数据,其他所有程序语言都可使用RESTful API,通过9200端口的与ES进行通信,GET查询、PUT添加、POST修改、DELETE删除, POST和PUT都能起到创建&#x2F;更新的作用： PUT需要对一个具体的资源进行操作,也就是要确定id才能进行更新&#x2F;创建,而 POST可针对整个资源集合进行操作,若不写id则由ES生成一个唯一id进行创建新文档,过填了id则针对该id文档进行创建&#x2F;更新 PUT会将JSON数据都进行替换,POST只会更新相同字段的值 PUT与DELETE都是幂等性操作,不论操作多少次结果都一样 文档批量操作通过 _mget 的API来实现 批量操作多个文档,可通过 _id 批量获取 不同index和type的数据,若查询的是同一个文档可将index和type放到URL上。且可 通过_source指定查询字段。 1234567891011121314151617181920212223242526GET _mget&#123; &quot;docs&quot;: [ &#123; &quot;_index&quot;: &quot;es_db_1&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: 1, &#125;, &#123; &quot;_index&quot;: &quot;es_db&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: 2 &#125; ]&#125;GET /es_db/_doc/_mget?_source=age,name&#123; &quot;docs&quot;: [ &#123; &quot;_id&quot;: 1 &#125;, &#123; &quot;_id&quot;: 2 &#125; ]&#125; 批量 对文档进行 写操作 是通过 _bulk 的API来实现的,通过 _bulk 写操作文档,一般至少有两行参数,第一行参数为指定 操作的类型 及 操作的对象 如index、type、id,第二行参数为 操作的数据. actionName 表示 操作类型, 主要有 create、index、delete、update 。 1234567891011&#123; &quot;actionName&quot;: &#123; &quot;_index&quot;: &quot;indexName&quot;, &quot;_type&quot;: &quot;typeName&quot;, &quot;_id&quot;: &quot;id&quot; &#125;&#125;&#123; &quot;field1&quot;: &quot;value1&quot;, &quot;field2&quot;: &quot;value2&quot;&#125; 1234567891011&#123; &quot;actionName&quot;: &#123; &quot;_index&quot;: &quot;indexName&quot;, &quot;_type&quot;: &quot;typeName&quot;, &quot;_id&quot;: &quot;id&quot; &#125;&#125;&#123; &quot;field1&quot;: &quot;value1&quot;, &quot;field2&quot;: &quot;value2&quot;&#125; 乐观并发控制在数据库领域中,有悲观并发控制和乐观并发控制两种方法来确保并发更新不丢失数据, 悲观并发控制被关系型数据库广泛使用,阻塞访问资源以防止冲突；ES使用乐观并发控制,若源数据在读写当中被修改,更新将会失败。 12345678PUT /db_index/_doc/1?if_seq_no=1&amp;if_primary_term=1&#123; &quot;name&quot;: &quot;Jack&quot;, &quot;sex&quot;: 1, &quot;age&quot;: 25, &quot;book&quot;: &quot;Spring Boot 入门到精通2&quot;, &quot;remark&quot;: &quot;hello world2&quot;&#125; ES老版本是使用 version字段来乐观并发控制,新版本7.x使用if_seq_no&#x3D;文档版本号&amp;if_primary_term&#x3D;文档位置来乐观并发控制。 每当Primary Shard发生重新分配时如 重启, Primary选举 等, _primary_term会递增1, _primary_term 主要是用来 恢复数据时 处理当多个文档的 _seq_no一样 时的冲突. 如当一个shard宕机了,raplica需要用到最新的数据,就会根据_primary_term和_seq_no两个值来拿到最新的document。 文档映射ES中映射可以分为动态映射和静态映射,在关系数据库中,需要事先在数据库下创建数据表,并创建表字段、类型、长度、主键等,最后才能基于表插入数据。而Elasticsearch中不需要定义Mapping映射,在文档写入ES时,会根据文档字段自动识别类型,该机制为动态映射；也可事先定义好映射,包含文档的各字段类型、分词器等,该方式为静态映射 字符串： string类型包含text和keyword text： 该类型被用来索引长文本,创建索引前会将文本进行分词,转化为词的组合,建立索引；允许es来检索这些词, 不能用来排序和聚合 keyword： 该类型不能分词,可被用来检索过滤、排序和聚合, 不可用text进行分词模糊检索 数值型： long、integer、short、byte、double、float 日期型： date 布尔型： boolean 123456789101112131415161718192021222324252627282930313233343536GET /es_db/_mapping // 获取文档映射 PUT /es_db2 // 创建索引且设置文档映射&#123; &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123; &quot;name&quot;: &#123; &quot;type&quot;: &quot;keyword&quot;, &quot;index&quot;: true, &quot;store&quot;: true &#125;, &quot;sex&quot;: &#123; &quot;type&quot;: &quot;integer&quot;, &quot;index&quot;: true, &quot;store&quot;: true &#125;, &quot;age&quot;: &#123; &quot;type&quot;: &quot;integer&quot;, &quot;index&quot;: true, &quot;store&quot;: true &#125;, &quot;book&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;index&quot;: true, &quot;store&quot;: true, &quot;analyzer&quot;: &quot;ik_smart&quot;, // 指定text类型的ik分词器 &quot;search_analyzer&quot;: &quot;ik_smart&quot; // 指定text类型的ik分词器 &#125;, &quot;address&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;index&quot;: true, &quot;store&quot;: true &#125; &#125; &#125;&#125; 若要推倒现有的映射,得重新建立一个静态索引,然后把之前索引里的数据导入到新的索引里, 删除原创建的索引, 为新索引起个别名,为原索引名。 1234567891011POST _reindex // 把之前索引里的数据导入到新的索引里&#123; &quot;source&quot;: &#123; &quot;index&quot;: &quot;db_index&quot; &#125;, &quot;dest&quot;: &#123; &quot;index&quot;: &quot;db_index_2&quot; &#125;&#125;DELETE /db_index // 删除原创建的索引PUT /db_index_2/_alias/db_index // 为新索引起个别名, 为原索引名 若要推倒现有的映射,得重新建立一个静态索引,然后把之前索引里的数据导入到新的索引里, 删除原创建的索引, 为新索引起个别名,为原索引名。 1234567891011POST _reindex // 把之前索引里的数据导入到新的索引里&#123; &quot;source&quot;: &#123; &quot;index&quot;: &quot;db_index&quot; &#125;, &quot;dest&quot;: &#123; &quot;index&quot;: &quot;db_index_2&quot; &#125;&#125;DELETE /db_index // 删除原创建的索引PUT /db_index_2/_alias/db_index // 为新索引起个别名, 为原索引名 DSL高级查询Domain Specific Language领域专用语言,由叶子查询子句和复合查询子句两种子句组成。DSL查询语言又分为查询DSL和过滤DSL。ES中索引的数据都会存储一个 _score分值, 分值越高就代表越匹配, 查询上下文中不仅要判断查询条件与文档是否匹配,且还要关心相关度即 _score分值,需要根据分值排序；过滤器上下文中值关心查询条件与文档是否匹配,不计算 _score分值, 不关心排序问题,经常使用过滤器,ES会自动缓存过滤器内容。 12GET /es_db/_doc/_search // 无查询条件是查询所有,默认查询所有,或使用match_all表示所有&#123;&quot;query&quot;:&#123;&quot;match_all&quot;:&#123;&#125;&#125;&#125; 叶子查询模糊匹配模糊匹配主要是针对文本类型的字段,文本类型的字段会对内容进行分词, 查询时也会对搜索条件进行分词,然后通过倒排索引查找到匹配数据,模糊匹配主要通过 match 等参数来实现 match：通过match关键词模糊匹配条件内容, 需指定字段名, 会进行分词 query：指定匹配的值 operator：匹配条件类型 and：条件分词后都要匹配 or：条件分词后有一个匹配即可,默认为or minmum_should_match：指定最小匹配数量 query_string：和match类似, 可不指定字段即所有字段中搜索,范围更广泛 match_phase：会对输入做分词,但结果中也包含所有分词,且顺序一样 prefix：前缀匹配 regexp：通过正则表达式来匹配数据 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566POST /es_db/_doc/_search&#123; &quot;from&quot;: 0, &quot;size&quot;: 2, &quot;query&quot;: &#123; &quot;match&quot;: &#123; // match会根据该字段的分词器,进行分词查询 &quot;address&quot;: &quot;广州&quot; &#125; &#125;&#125;POST /es_db/_doc/_search&#123; &quot;query&quot;: &#123; &quot;multi_match&quot;: &#123; // 多字段模糊匹配查询 &quot;query&quot;: &quot;长沙&quot;, &quot;fields&quot;: [&quot;address&quot;, &quot;name&quot;] // address或name字段中匹配到“长沙” &#125; &#125;&#125;POST /es_db/_doc/_search&#123; &quot;query&quot;: &#123; &quot;query_string&quot;: &#123; // 未指定字段条件查询query_string, 含AND与OR条件 &quot;query&quot;: &quot;广州 OR 长沙&quot; // 所有的字段中只要包含“广州”或“长沙” &#125; &#125;&#125;POST /es_db/_doc/_search&#123; &quot;query&quot;: &#123; &quot;query_string&quot;: &#123; // 指定字段条件查询query_string &quot;query&quot;: &quot;admin AND 长沙&quot;, &quot;fields&quot;: [&quot;name&quot;, &quot;address&quot;] // name或address匹配admin和长沙 &#125; &#125;&#125;GET /es_db/_search&#123; &quot;query&quot;: &#123; // ES执行搜索时,默认operator为or &quot;match&quot;: &#123; // remark字段包含java或developer词组,则符合搜索条件。 &quot;remark&quot;: &quot;java developer&quot; &#125; &#125;&#125;GET /es_db/_search&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;remark&quot;: &#123; // remark字段包含java和developer词组 &quot;query&quot;: &quot;java developer&quot;, &quot;operator&quot;: &quot;and&quot; &#125; &#125; &#125;&#125;GET /es_db/_search&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;remark&quot;: &#123; // 需要remark字段中包含多个搜索词条中的一定比例 &quot;query&quot;: &quot;java architect assistant&quot;, &quot;minimum_should_match&quot;: &quot;50%&quot; // minimum_should_match可使用百分比或固定数字 &#125; &#125; &#125;&#125; match_phrase短语搜索,使用短语搜索时和match类似,首先对搜索条件进行分词,ES在做分词时除了将数据切分外,还会保留一个词在整个数据中的下标position。当ES执行match phrase短语搜索时,首先将搜索条件分词,然后在倒排索引中检索数据,若搜索条件分词数据在某个document某个field出现时,则检查匹配到的单词的position是否连续,若不连续则匹配失败。 ES对match phrase短语搜索提供了 slop参数,可实现数据在所有匹配结果中,多个单词距离越近相关度评分越高排序越靠前,若当 slop 移动次数使用完毕还没有匹配成功则无搜索结果。 12345678910111213141516171819GET _search&#123; &quot;query&quot;: &#123; &quot;match_phrase&quot;: &#123; // 短语搜索,搜索条件不分词 &quot;remark&quot;: &quot;java assistant&quot; &#125; &#125;&#125;GET /es_db/_search&#123; &quot;query&quot;: &#123; &quot;match_phrase&quot;: &#123; &quot;remark&quot;: &#123; &quot;query&quot;: &quot;java assistant&quot;, &quot;slop&quot;: 1 &#125; &#125; &#125;&#125; 前缀搜索通常针对 keyword 类型字段即不分词字段, keyword类型字段数据大小写敏感, 前缀搜索效率比较低,且不计算相关度分数, 前缀越短效率越低。若使用前缀搜索,建议使用长前缀,因为前缀搜索需要扫描完整索引内容,所以前缀越长相对效率越高。 12345678GET /test_a/_search&#123; &quot;query&quot;: &#123; &quot;prefix&quot;: &#123; &quot;f.keyword&quot;: &#123;&quot;value&quot;: &quot;Jav&quot;&#125; &#125; &#125;&#125; 通配符搜索通配符可在倒排索引中使用,也可在 keyword类型字段中使用。?问号匹配一个任意字符, *星号匹配0到n个任意字符。性能也很低,也需要扫描完整索引。 12345678GET /test_a/_search&#123; &quot;query&quot;: &#123; &quot;wildcard&quot;: &#123; &quot;f.keyword&quot;: &#123; &quot;value&quot;: &quot;?e*o*&quot; &#125; &#125; &#125;&#125; 正则搜索可在 倒排索引 或 keyword 类型字段中使用, 性能很低需要扫描完整索引。 123456GET /test_a/_search&#123; &quot;query&quot;: &#123; &quot;regexp&quot;: &#123;&quot;f.keyword&quot;: &quot;[A-z].+&quot;&#125; &#125;&#125; 搜索推荐其原理和 match phrase类似,先使用match匹配term数据即示例中的java,然后在指定 slop移动次数范围内前缀匹配示例数据sp, max_expansions是用于指定prefix最多匹配多少个term,超过该数量就不再匹配了。该语法限制只有最后一个term会执行前缀搜索。执行性能很差, 最后一个term 需要 扫描所有符合slop要求的倒排索引的term. 若必须使用一定要使用参数 max_expansions. 12345678GET /test_a/_search&#123; &quot;query&quot;: &#123; &quot;match_phrase_prefix&quot;: &#123; &quot;f&quot;: &#123;&quot;query&quot;: &quot;java sp&quot;,&quot;slop&quot;: 10,&quot;max_expansions&quot;: 10&#125; &#125; &#125;&#125; 模糊搜索搜索时可能搜索条件文本输入错误,fuzzy技术就是用于解决错误拼写的,英文中很有效但中文中几乎无效,其中 fuzziness 代表 value值word可修改多少个字母来进行拼写错误纠正,修改字母数量包含字母变更,增加或减少字母. 12345678GET /test_a/_search&#123; &quot;query&quot;: &#123; &quot;fuzzy&quot;: &#123; &quot;f&quot;: &#123;&quot;value&quot;: &quot;word&quot;,&quot;fuzziness&quot;: 2&#125; &#125; &#125;&#125; 精确匹配 term： 单个条件相等,查询字段映射类型属于为 keyword, 不会被分词 terms： 单个字段属于某个值数组内的值 range： 字段属于某个范围内的值 gte： 大于等于 lte： 小于等于 gt： 大于 lt： 小于 now： 当前时间 exists： 某个字段的值是否存在 ids： 通过ID批量查询 12345678910111213141516171819202122232425262728POST /es_db/_doc/_search&#123; &quot;query&quot;: &#123; &quot;term&quot;: &#123; // term查询不会对字段进行分词查询,会采用精确匹配 &quot;name&quot;: &quot;admin&quot; &#125; &#125;&#125;POST /es_db/_doc/_search&#123; &quot;query&quot;: &#123; &quot;range&quot;: &#123; // 范围查询 &quot;age&quot;: &#123;&quot;gte&quot;: 25,&quot;lte&quot;: 28&#125; &#125; &#125;&#125;POST /es_db/_doc/_search // 范围、分页、输出字段、综合查询&#123; &quot;query&quot;: &#123; &quot;range&quot;: &#123; // 范围查询 &quot;age&quot;: &#123;&quot;gte&quot;: 25,&quot;lte&quot;: 28&#125; &#125; &#125;, &quot;from&quot;: 0, // 分页 &quot;size&quot;: 2, &quot;_source&quot;: [&quot;name&quot;, &quot;age&quot;, &quot;book&quot;], // 指定输出字段 &quot;sort&quot;: &#123;&quot;age&quot;: &quot;desc&quot;&#125;// 排序&#125; 组合查询组合条件查询是将叶子条件查询语句进行组合而形成的一个完整的查询条件, must、filter、shoud、must_not等子条件是通过 term、terms、range、ids、exists、match等叶子条件为参数,当只有一个搜索条件时,must等对应的是一个对象,当多个条件时,对应的是一个数组。 bool： 各条件之间有 and, or 或 not 关系 must： 各个条件都必须满足,即各条件是 and 关系 should： 各个条件有一个满足即可,即各条件是 or 关系 must_not： 不满足所有条件,即各条件是 not 关系 filter： 不计算相关度评分,即不计算_score, 不对结果排序,效率更高, 查询结果可被缓存 constant_score： 不计算相关度评分 1234567891011121314151617181920212223POST /es_db/_doc/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;filter&quot;: &#123; // 对数据进行过滤 &quot;term&quot;: &#123;&quot;age&quot;: 25&#125; &#125; &#125; &#125;&#125; GET /es_db/_search&#123; &quot;query&quot;: &#123; // 使用should+bool搜索,控制搜索条件的匹配度 &quot;bool&quot;: &#123; &quot;should&quot;: [ // 必须匹配java、developer、assistant三个词条中的至少2个 &#123;&quot;match&quot;: &#123;&quot;remark&quot;: &quot;java&quot;&#125;&#125;, &#123;&quot;match&quot;: &#123;&quot;remark&quot;: &quot;developer&quot;&#125;&#125;, &#123;&quot;match&quot;: &#123;&quot;remark&quot;: &quot;assistant&quot;&#125;&#125; ], &quot;minimum_should_match&quot;: 2 // 控制搜索条件的匹配度 &#125; &#125;&#125; ES中执行 match搜索 时,ES底层通常会对搜索条件进行底层转换,来实现最终的搜索结果,若不怕麻烦, 尽量使用转换后的语法执行搜索, 效率更高。 123456789101112131415GET /es_db/_search // 转换前&#123;&quot;query&quot;:&#123;&quot;match&quot;:&#123;&quot;remark&quot;:&quot;java developer&quot;&#125;&#125;&#125;GET /es_db/_search // 转换后&#123;&quot;query&quot;:&#123;&quot;bool&quot;:&#123;&quot;should&quot;:[&#123;&quot;term&quot;:&#123;&quot;remark&quot;:&quot;java&quot;&#125;&#125;,&#123;&quot;term&quot;:&#123;&quot;remark&quot;:&#123;&quot;value&quot;:&quot;developer&quot;&#125;&#125;&#125;]&#125;&#125;&#125;GET /es_db/_search // 转换前&#123;&quot;query&quot;:&#123;&quot;match&quot;:&#123;&quot;remark&quot;:&#123;&quot;query&quot;:&quot;java developer&quot;,&quot;operator&quot;:&quot;and&quot;&#125;&#125;&#125;&#125;GET /es_db/_search // 转换后&#123;&quot;query&quot;:&#123;&quot;bool&quot;:&#123;&quot;must&quot;:[&#123;&quot;term&quot;:&#123;&quot;remark&quot;:&quot;java&quot;&#125;&#125;,&#123;&quot;term&quot;:&#123;&quot;remark&quot;:&#123;&quot;value&quot;:&quot;developer&quot;&#125;&#125;&#125;]&#125;&#125;&#125;GET /es_db/_search // 转换前&#123;&quot;query&quot;:&#123;&quot;match&quot;:&#123;&quot;remark&quot;:&#123;&quot;query&quot;:&quot;java architect assistant&quot;,&quot;minimum_should_match&quot;:&quot;68%&quot;&#125;&#125;&#125;&#125;GET /es_db/_search // 转换后&#123;&quot;query&quot;:&#123;&quot;bool&quot;:&#123;&quot;should&quot;:[&#123;&quot;term&quot;:&#123;&quot;remark&quot;:&quot;java&quot;&#125;&#125;,&#123;&quot;term&quot;:&#123;&quot;remark&quot;:&quot;architect&quot;&#125;&#125;,&#123;&quot;term&quot;:&#123;&quot;remark&quot;:&quot;assistant&quot;&#125;&#125;],&quot;minimum_should_match&quot;:2&#125;&#125;&#125; boost权重控制boost权重控制一般用于搜索时相关度排序使用,将某字段数据匹配时相关度分数增加 123456789101112GET /es_db/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [&#123;&quot;match&quot;: &#123;&quot;remark&quot;: &quot;java&quot;&#125;&#125;], &quot;should&quot;: [ &#123;&quot;match&quot;: &#123;&quot;remark&quot;: &#123;&quot;query&quot;: &quot;developer&quot;,&quot;boost&quot;: 3&#125;&#125;&#125;, &#123;&quot;match&quot;: &#123;&quot;remark&quot;: &#123;&quot;query&quot;: &quot;architect&quot;,&quot;boost&quot;: 1&#125;&#125;&#125; ] &#125; &#125;&#125; dis_maxdis_max 语法是直接 获取搜索多条件 中 单条件query相关度分数最高 的数据,以该数据做 相关度排序。基于dis_max 实现 best fields策略 进行 多字段搜索, best fields策略是搜索document中某个field, 尽可能多的匹配搜索条件。与之相反的是 most fields策略 即 尽可能多的字段匹配到搜索条件 。 best fields策略优点是精确匹配的数据可尽可能排列在最前端,且可通过 minimum_should_match 去除 长尾数据,避免长尾数据字段对排序结果的影响。缺点相对排序不均匀。 1234567891011GET /es_db/_search&#123; &quot;query&quot;: &#123; &quot;dis_max&quot;: &#123; // 找name字段中rod匹配相关度分数或remark字段中java developer匹配相关度分数,哪个高就使用哪个相关度分数进行结果排序 &quot;queries&quot;: [ &#123;&quot;match&quot;: &#123;&quot;name&quot;: &quot;rod&quot;&#125;&#125;, &#123;&quot;match&quot;: &#123;&quot;remark&quot;: &quot;java developer&quot;&#125;&#125; ] &#125; &#125;&#125; dis_max 是将 多个 搜索query条件中 相关度分数最高 的用于结果排序, 忽略其他query分数,在某些情况下 需要其他query条件中相关度介入最终结果排序,此时可 使用tie_breaker参数来优化dis_max搜索。 tie_breaker 参数表示 将其他query搜索条件相关度分数乘以参数值再参与结果排序。若不定义 tie_breaker 参数相当于 参数值为0,故其他query条件的相关度分数被忽略。 123456789101112GET /es_db/_search&#123; &quot;query&quot;: &#123; &quot;dis_max&quot;: &#123; // 找name字段中rod匹配相关度分数或remark字段中java developer匹配相关度分数,哪个高就使用哪个相关度分数进行结果排序 &quot;queries&quot;: [ &#123;&quot;match&quot;: &#123;&quot;name&quot;: &quot;rod&quot;&#125;&#125;, &#123;&quot;match&quot;: &#123;&quot;remark&quot;: &quot;java developer&quot;&#125;&#125; ], &quot;tie_breaker&quot;: 0.5 &#125; &#125;&#125; 使用multi_match简化dis_max+tie_breaker,ES中相同结果搜索也可使用不同语法语句来实现。 123456789101112131415161718192021222324252627GET /es_db/_search&#123; &quot;query&quot;: &#123; &quot;dis_max&quot;: &#123; &quot;queries&quot;: [ &#123;&quot;match&quot;: &#123;&quot;name&quot;: &quot;rod&quot;&#125;&#125;, &#123;&quot;match&quot;: &#123;&quot;remark&quot;: &#123;&quot;query&quot;: &quot;java assistant&quot;,&quot;boost&quot;: 2&#125;&#125;&#125; ], &quot;tie_breaker&quot;: 0.5 &#125; &#125;&#125;GET /es_db/_search&#123; &quot;query&quot;: &#123; &quot;multi_match&quot;: &#123; &quot;query&quot;: &quot;rod java developer&quot;, &quot;fields&quot;: [ &quot;name&quot;, &quot;remark^2&quot; // ^n代表权重,相当于&quot;boost&quot;:n ], &quot;type&quot;: &quot;best_fields&quot;, // 其中type常用的有best_fields和most_fields &quot;tie_breaker&quot;: 0.5, &quot;minimum_should_match&quot;: &quot;50%&quot; &#125; &#125;&#125; cross fields 是一个 唯一标识,且分布在 多个fields 中, 使用该唯一标识搜索数据即cross fields搜索。如人名可分为姓和名,地址可分为省、市、区县、街道等。使用人名或地址来搜索document,就称为cross fields搜索。 实现这种搜索,一般都是使用 most fields搜索策略,因为这就是 多个field 问题。 Cross fields 搜索策略是 从多个字段中搜索条件数据, 默认和most fields搜索逻辑一致 但 计算相关度分数和best fields策略一致。一般若使用cross fields搜索策略,都会携带 operator 额外参数,用来标记搜索条件如何在多个字段中匹配。 1234567891011GET /es_db/_search&#123; &quot;query&quot;: &#123; &quot;multi_match&quot;: &#123; // 搜索条件中java必须在name或remark字段中匹配,developer也必须在name或remark字段中匹配 &quot;query&quot;: &quot;java developer&quot;, &quot;fields&quot;: [&quot;name&quot;, &quot;remark&quot;], &quot;type&quot;: &quot;cross_fields&quot;, &quot;operator&quot;: &quot;and&quot; &#125; &#125;&#125; most fields策略 是尽可能匹配更多字段,会导致 精确搜索结果排序问题 ,又因为cross fields搜索,不能使用 minimum_should_match 来去除长尾数据。故在使用 most fields 和 cross fields 策略搜索数据时,都有不同缺陷,商业项目开发中都 推荐使用best fields策略 实现搜索。 可通过 copy_to 解决 cross fields搜索问题, copy_to 就是将 多个字段复制到一个字段 中实现一个 多字段组合,在商业项目中,也用于 解决搜索条件默认字段问题。若需要使用copy_to语法,则需要在定义 index 时手工指定 mapping映射策略。 123456789PUT /es_db/_mapping&#123; &quot;properties&quot;: &#123; &quot;provice&quot;: &#123;&quot;type&quot;: &quot;text&quot;,&quot;analyzer&quot;: &quot;standard&quot;,&quot;copy_to&quot;: &quot;address&quot;&#125;, &quot;city&quot;: &#123;&quot;type&quot;: &quot;text&quot;,&quot;copy_to&quot;: &quot;address&quot;&#125;, &quot;street&quot;: &#123;&quot;type&quot;: &quot;text&quot;,&quot;analyzer&quot;: &quot;standard&quot;,&quot;copy_to&quot;: &quot;address&quot;&#125;, &quot;address&quot;: &#123;&quot;type&quot;: &quot;text&quot;,&quot;analyzer&quot;: &quot;standard&quot;&#125; &#125;&#125; 在mapping定义中新增provice、city、street、address等字段,其中provice、city、street三个字段值会自动复制到address字段中,实现一个字段组合。在搜索地址时可在address字段中做条件匹配,从而避免most fields策略导致的问题。在维护数据时不需对address字段特殊维护,ES会自动维护组合字段。在存储时物理上不一定存在但逻辑上存在,因为address由3个物理存在属性province、city、street组成。 使用 match 和 proximity search 实现 召回率 和 精准度平衡 ,若搜索时只使用match phrase语法,会导致 召回率低下,若只使用match语法,会导致 精准度低下,因为搜索结果排序是根据相关度分数算法计算得到。若需要在结果中 兼顾召回率 和 精准度,就需要将 match 和 proximity search 混合使用。 召回率：搜索结果比率,如索引A中有100个document,搜索时返回多少个document 精准度：搜索结果准确率,如搜索条件为hello java,搜索结果中尽可能让短语匹配和hello java离的近的结果排序靠前1234567891011121314151617181920POST /test_a/_doc/3&#123;&quot;f&quot;:&quot;hello, java is very good, spark is also very good&quot;&#125;POST /test_a/_doc/4&#123;&quot;f&quot;:&quot;java and spark, development language &quot;&#125;POST /test_a/_doc/5&#123;&quot;f&quot;:&quot;Java Spark is a fast and general-purpose cluster computing system. It provides high-level APIs in Java, Scala, Python and R, and an optimized engine that supports general execution graphs.&quot;&#125;POST /test_a/_doc/6&#123;&quot;f&quot;:&quot;java spark and, development language &quot;&#125;GET /test_a/_search&#123;&quot;query&quot;:&#123;&quot;match&quot;:&#123;&quot;f&quot;:&quot;java spark&quot;&#125;&#125;&#125;GET /test_a/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [&#123;&quot;match&quot;: &#123;&quot;f&quot;: &quot;java spark&quot;&#125;&#125;], &quot;should&quot;: [&#123;&quot;match_phrase&quot;: &#123;&quot;f&quot;: &#123;&quot;query&quot;: &quot;java spark&quot;,&quot;slop&quot;: 50&#125;&#125;&#125;] &#125; &#125;&#125; 连接查询 父子 文档查询： parent/child 嵌套 文档查询： nested ES架构原理在ES中主要分成 Master 和 DataNode 两类节点,ES启动时会选举出一个Master节点,当某个节点启动后,使用 Zen Discovery机制 找到集群中的其他节点并 建立连接,并 从候选主节点中选举出一个主节点。一个ES集群中只有一个Master节点,但会有 N个DataNode 节点,在生产环境中内存可相对小一点但机器要稳定。 Master：管理索引即创建、删除索引, 分配分片, 维护元数据, 管理集群节点状态, 不负责数据写入和查询,比较轻量级 DataNode：数据写入, 数据检索,大部分ES压力都在DataNode节点上 分片ShardES是一个分布式搜索引擎,索引数据也分成若干部分,分布在不同服务器节点中,分布在不同服务器节点中的索引数据,就是Shard分片。Elasticsearch会自动管理分片,若发现分片分布不均衡,会自动迁移一个索引index由多个shard分片组成, 分片是分布在不同的服务器上。 副本为了对ES分片进行容错,假设某个节点不可用,会导致整个索引库都将不可用。故需要对分片进行副本容错, 每个分片都会有对应的副本。默认创建索引为1个分片、每个分片有 1个主分片 和 1个副本分片。 每个分片都会有一个Primary Shard主分片,也会有若干个Replica Shard副本分片, Primary Shard和Replica Shard不在同一个节点上。 12345678910111213141516PUT /job_idx_shard_temp // 创建指定分片数量、副本数量的索引&#123; &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123; &quot;id&quot;: &#123;&quot;type&quot;: &quot;long&quot;,&quot;store&quot;: true&#125;, &quot;area&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;,&quot;store&quot;: true&#125;, &quot;edu&quot;: &#123;&quot;type&quot;: &quot;keyword&quot;,&quot;store&quot;: true&#125; &#125; &#125;, &quot;settings&quot;: &#123; &quot;number_of_shards&quot;: 3, // 指定分片数量 &quot;number_of_replicas&quot;: 2 // 指定副本数量 &#125;&#125;GET /_cat/indices?v // 查看分片、主分片、副本分片 文档写入原理 选择 任意一个DataNode发送请求 如node2,此时node2就成为一个 coordinating node协调节点,通过协调节点 计算得到文档要写入的分片shard = hash(routing) % number_of_primary_shards,其中 routing 是一个 可变值, 默认为文档_id,然后 协调节点会进行路由,将请求 转发给对应 primary shard主分片所在的 DataNode,假设primary shard主分片在node1、replica shard副分片在node2,node1节点上的Primary Shard处理请求,写入数据到索引库中,并将数据同步到Replica shard副分片,Primary Shard和Replica Shard都保存好了文档则返回Client。 检索原理 Client发起查询请求某个 DataNode 接收到请求后,该 DataNode 就成为 Coordinating Node协调节点, 协调节点将查询请求广播到每一个数据节点,这些 数据节点 的 分片 会处理该查询请求, 每个分片进行数据查询,将符合条件的数据放在一个 优先队列 中,并将这些数据的 文档ID 、 节点信息 、 分片信息 返回给 协调节点 , 协调节点将所有结果进行汇总并全局排序,协调节点向包含这些 文档ID 的 分片 发送 get请求,对应的分片将文档数据返回给协调节点,最后协调节点将数据返回给客户端。 准实时索引 当数据写入到ES分片时会 首先写入到内存中,然后通过 内存buffer 生成一个 Segment,并刷到 文件系统缓存 中而 不是直接刷到磁盘,数据可被检索,ES中 默认1秒refresh一次。数据在 写入内存的同时,也会 记录Translog日志,若 在refresh期间出现异常,会 根据Translog 来进行 数据恢复,等到 文件系统缓存 中的 Segment 数据 都刷到磁盘中,则 清空Translog文件,ES 默认每隔30分钟 会将 文件系统缓存 的数据 刷入到磁盘. Segment太多 时ES 定期 会将多个 Segment合并 成为大的Segment, 减少索引查询时IO开销,此阶段ES会真正的 物理删除 之前 执行过delete的数据。","tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"http://example.com/tags/ElasticSearch/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"ElasticSearch","slug":"工具和中间件/搜索引擎技术/ElasticSearch","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/ElasticSearch/"}]},{"title":"SpringCloud系列14-总结","date":"2021-10-07T04:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列14-总结/","text":"多个微服务:12345678910&lt;modules&gt; &lt;module&gt;eureka-server&lt;/module&gt; &lt;module&gt;product-data-service&lt;/module&gt; &lt;module&gt;product-view-service-ribbon&lt;/module&gt; &lt;module&gt;product-view-service-feign&lt;/module&gt; &lt;module&gt;config-server&lt;/module&gt; &lt;module&gt;hystrix-dashboard&lt;/module&gt; &lt;module&gt;turbine&lt;/module&gt; &lt;module&gt;productServiceZuul&lt;/module&gt;&lt;/modules&gt; 端口号总结:微服务： eureka-server: 8761 product-data-service: 8001,8002,8003 product-view-service-ribbon: 8010 product-view-service-feign: 8012, 8013, 8014 hystrix-dashboard: 8020 turbine: 8021 config-server: 8030 zuul: 8040 第三方: zipkin:9411 rabbitMQ: 5672","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"SpringCloud系列13-网关Zuul","date":"2021-10-07T03:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列13-网关Zuul/","text":"问题：为何要用网关? 我们现在有两种微服务，分别是数据微服务和视图微服务。它们有可能放在不同的 ip 地址上，有可能是不同的端口。 为了访问他们，就需要记录这些地址和端口。 而地址和端口都可能会变化，这就增加了访问者的负担。这个时候，我们就可以用网关来解决这个问题。 如图所示，我们只需要记住网关的地址和端口号就行了： 如果要访问数据服务，访问地址 http://ip:port/api-data/products 即可。 如果要访问视图服务，访问地址 http://ip:port/api-view/products 即可 创建子项目： zuulpom.xml：12345678910111213141516171819202122232425262728293031&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;spring-cloud-parent&lt;/artifactId&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-parent/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;productServiceZuul&lt;/artifactId&gt; &lt;name&gt;productServiceZuul&lt;/name&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; ProductServiceZuulApplication.java:12345678910111213141516171819202122232425package cn.peach;import cn.hutool.core.util.NetUtil;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.boot.builder.SpringApplicationBuilder;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.cloud.netflix.eureka.EnableEurekaClient;import org.springframework.cloud.netflix.zuul.EnableZuulProxy;@SpringBootApplication@EnableZuulProxy@EnableEurekaClient@EnableDiscoveryClientpublic class ProductServiceZuulApplication&#123; public static void main( String[] args ) &#123; int port = 8040; if(!NetUtil.isUsableLocalPort(port)) &#123; System.err.printf(&quot;端口%d被占用了，无法启动%n&quot;, port ); System.exit(1); &#125; new SpringApplicationBuilder(ProductServiceZuulApplication.class).properties(&quot;server.port=&quot; + port).run(args); &#125;&#125; application.yml:配置文件，进行了路由映射 12345678zuul: routes: api-a: path: /api-data/** serviceId: PRODUCT-DATA-SERVICE api-b: path: /api-view/** serviceId: PRODUCT-VIEW-SERVICE-FEIGN 完整代码： 123456789101112131415eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/spring: application: name: product-service-zuulzuul: routes: api-a: path: /api-data/** serviceId: PRODUCT-DATA-SERVICE api-b: path: /api-view/** serviceId: PRODUCT-VIEW-SERVICE-FEIGN 启动： 首先挨个运行 EurekaServerApplication, ConfigServerApplication, ProductDataServiceApplication， ProductViewServiceFeignApplication。 然后启动 ProductServiceZuulApplication 接着访问地址: http://localhost:8040/api-data/products http://localhost:8040/api-view/products 这样就可以访问数据微服务和视微服务集群了，并且无需去记住那么多ip地址和端口号了。","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"SpringCloud系列12-断路器聚合监控","date":"2021-10-07T02:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列12-断路器聚合监控/","text":"需求:前面是针对一个微服务的断路器监控，但是微服务通常会是多个实例组成的一个集群。 倘若集群里的实例比较多，难道要挨个挨个去监控这些实例吗？ 何况有时候，根据集群的需要，会动态增加或者减少实例，监控起来就更麻烦了。 为了方便监控集群里的多个实例，springCloud 提供了一个 turbine 项目，它的作用是把一个集群里的多个实例汇聚在一个 turbine里，这个然后再在 断路器监控里查看这个 turbine, 这样就能够在集群层面进行监控了。 创建子项目： turbinepom.xml:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;spring-cloud-parent&lt;/artifactId&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-parent/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;turbine&lt;/artifactId&gt; &lt;name&gt;turbine&lt;/name&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-turbine&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; ProductServiceTurbineApplication.java1234567891011121314151617181920package cn.peach;import cn.hutool.core.util.NetUtil;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.boot.builder.SpringApplicationBuilder;import org.springframework.cloud.netflix.turbine.EnableTurbine;@SpringBootApplication@EnableTurbinepublic class ProductServiceTurbineApplication &#123; public static void main(String[] args) &#123; int port = 8021; if(!NetUtil.isUsableLocalPort(port)) &#123; System.err.printf(&quot;端口%d被占用了，无法启动%n&quot;, port ); System.exit(1); &#125; new SpringApplicationBuilder(ProductServiceTurbineApplication.class).properties(&quot;server.port=&quot; + port).run(args); &#125;&#125; application.yml配置信息，主要是：appConfig: product-view-service-feign, 这就表示它会把所有微服务名称是product-view-service-feign 的实例信息都收集起来。 1234567891011121314spring: application.name: turbineturbine: aggregator: clusterConfig: default # 指定聚合哪些集群，多个使用&quot;,&quot;分割，默认为default。可使用http://.../turbine.stream?cluster=&#123;clusterConfig之一&#125;访问 appConfig: product-view-service-feign ### 配置Eureka中的serviceId列表，表明监控哪些服务 clusterNameExpression: new String(&quot;default&quot;) # 1. clusterNameExpression指定集群名称，默认表达式appName；此时：turbine.aggregator.clusterConfig需要配置想要监控的应用名称 # 2. 当clusterNameExpression:default时，turbine.aggregator.clusterConfig可以不写，因为默认就是default # 3. 当clusterNameExpression:metadata[&#x27;cluster&#x27;]时，假设想要监控的应用配置了eureka.instance.metadata-map.cluster: ABC，则需要配置，同时turbine.aggregator.clusterConfig: ABCeureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"SpringCloud系列11-断路器监控","date":"2021-10-06T13:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列11-断路器监控/","text":"需求:断路器，是当数据服务不可用的时候， 断路器就会发挥作用。那么数据服务什么时候可用，什么时候不可用，如何监控这个事情呢？ 我们就要用到 断路器监控 来可视化掌控这个情况了。 创建子项目：hystrix-dashboardpom.xml文件1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;spring-cloud-parent&lt;/artifactId&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-parent/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;hystrix-dashboard&lt;/artifactId&gt; &lt;name&gt;hystrix-dashboard&lt;/name&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; ProductServiceHystrixDashboardApplication.java断路器监控启动类，主要就是@EnableHystrixDashboard 1234567891011121314151617181920package cn.peach;import cn.hutool.core.util.NetUtil;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.boot.builder.SpringApplicationBuilder;import org.springframework.cloud.netflix.hystrix.dashboard.EnableHystrixDashboard;@SpringBootApplication@EnableHystrixDashboardpublic class ProductServiceHystrixDashboardApplication&#123; public static void main(String[] args) &#123; int port = 8020; if(!NetUtil.isUsableLocalPort(port)) &#123; System.err.printf(&quot;端口%d被占用了，无法启动%n&quot;, port ); System.exit(1); &#125; new SpringApplicationBuilder(ProductServiceHystrixDashboardApplication.class).properties(&quot;server.port=&quot; + port).run(args); &#125;&#125; application.yml:123spring: application: name: hystrix-dashboard ProductViewServiceFeignApplication.java 修改视图微服务项目，以使得它可以把信息共享给监控中心。 修改ProductViewServiceFeignApplication， 增加 @EnableCircuitBreaker 1234567891011121314151617181920212223242526272829303132333435package cn.peach;import brave.sampler.Sampler;import cn.hutool.core.util.NetUtil;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.circuitbreaker.EnableCircuitBreaker;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.cloud.netflix.eureka.EnableEurekaClient;import org.springframework.cloud.openfeign.EnableFeignClients;import org.springframework.context.annotation.Bean;@SpringBootApplication@EnableEurekaClient@EnableDiscoveryClient@EnableFeignClients@EnableCircuitBreaker //把信息共享给监控中心public class ProductViewServiceFeignApplication &#123; public static void main(String[] args) &#123; // 判断 rabiitMQ 是否启动 int rabbitMQPort = 5672; if(NetUtil.isUsableLocalPort(rabbitMQPort)) &#123; System.err.printf(&quot;未在端口%d 发现 rabbitMQ服务，请检查rabbitMQ 是否启动&quot;, rabbitMQPort ); System.exit(1); &#125; // 推荐 8012 、 8013 或者 8014 SpringApplication.run(ProductViewServiceFeignApplication.class, args); &#125; @Bean public Sampler defaultSampler() &#123; return Sampler.ALWAYS_SAMPLE; &#125;&#125; AccessViewService.java:准备一个不停访问服务的类： AccessViewService。 这样可以不断地访问服务，才便于在监控那里观察现象。 1234567891011121314151617181920212223242526package cn.peach.util;import cn.hutool.core.thread.ThreadUtil;import cn.hutool.http.HttpUtil;public class AccessViewService &#123; public static void main(String[] args) &#123; while(true) &#123; ThreadUtil.sleep(1000); access(8012); access(8013); &#125; &#125; public static void access(int port) &#123; try &#123; String html= HttpUtil.get(String.format(&quot;http://127.0.0.1:%d/products&quot;,port)); System.out.printf(&quot;%d 地址的视图服务访问成功，返回大小是 %d%n&quot; ,port, html.length()); &#125; catch(Exception e) &#123; System.err.printf(&quot;%d 地址的视图服务无法访问%n&quot;,port); &#125; &#125;&#125; 启动： 首先挨个运行 EurekaServerApplication, ConfigServerApplication, ProductDataServiceApplication， ProductViewServiceFeignApplication，ProductServiceHystrixDashboardApplication; 运行视图微服务里的 AccessViewService 来周期性地访问 http://127.0.0.1:8012/products 。 因为只有访问了，监控里才能看到数据; 打开监控地址 http://localhost:8020/hystrix; 如图所示，在最上面输入http://localhost:8012/actuator/hystrix.stream : 点击 Monitor Stream 就可以看到监控信息了。","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"SpringCloud系列10-断路器Hystrix","date":"2021-10-06T12:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列10-断路器Hystrix/","text":"问题:视图微服务是依赖于数据微服务的。那么当数据微服务不可用的时候，会怎么样呢？我们主动把 ProductDataServiceApplication 关闭，然后再访问：http://localhost:8012/products 就会抛出异常。客户也看不懂这个是什么。为了解决这个问题，我们就会引入断路器的概念。 断路器:断路器: 就是当被访问的微服务无法使用的时候，当前服务能够感知这个现象，并且提供一个备用的方案出来。 改造:pom.xml:增加 jar spring-cloud-starter-netflix-hystrix 以支持断路器。 12345&lt;!--增加 jar spring-cloud-starter-netflix-hystrix 以支持断路器--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;&lt;/dependency&gt; ProductClientFeign.java注解由原来的 @FeignClient(value = &quot;PRODUCT-DATA-SERVICE&quot;)修改为 @FeignClient(value = &quot;PRODUCT-DATA-SERVICE&quot;,fallback = ProductClientFeignHystrix.class)。 123456789101112131415package cn.peach.client;import cn.peach.pojo.Product;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;import java.util.List;@FeignClient(value = &quot;PRODUCT-DATA-SERVICE&quot;,fallback = ProductClientFeignHystrix.class)public interface ProductClientFeign &#123; @GetMapping(&quot;/products&quot;) public List&lt;Product&gt; listProdcuts();&#125; ProductClientFeignHystrix.javaProductClientFeignHystrix 实现了 ProductClientFeign 接口，并提供了 listProdcuts() 方法。这个方法就会固定返回包含一条信息的集合。 1234567891011121314151617181920package cn.peach.client;/* * Create By Tao on 2022/4/24. * * */import cn.peach.pojo.Product;import org.springframework.stereotype.Component;import java.util.ArrayList;import java.util.List;@Componentpublic class ProductClientFeignHystrix implements ProductClientFeign&#123; public List&lt;Product&gt; listProdcuts()&#123; List&lt;Product&gt; result = new ArrayList&lt;&gt;(); result.add(new Product(0,&quot;产品数据微服务现在不可用&quot;,0)); return result; &#125;&#125; application.yml在配置文件里开启断路器: 1feign.hystrix.enabled: true 启动:挨个启动： EurekaServerApplication, ConfigServerApplication, ProductViewServiceFeignApplication。注意: 数据服务是没有启动的。然后访问地址：http://127.0.0.1:8012/products会发现，依然可以打开，并且得到提示信息： 产品数据微服务不可用。","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"SpringCloud系列9-消息总线Bus","date":"2021-10-06T11:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列9-消息总线Bus/","text":"问题：虽然配置了config-server, 也把视图服务改造成了配置客户端，但是当需要刷新配置信息的时候，不得不既重启 config-server, 又重启微服务。 这样的体验当然是不太好的。 我们当然是希望一旦 git 上的配置信息修改之后，就可以自动地刷新到微服务里，而不是需要手动重启才可以。 RabbitMQ： springCloud 通过 rabbitMQ 来进行消息广播，以达到有配置信息发生改变的时候，广播给多个微服务的效果。 需要先安装 rabbitMQ 服务器。 改造:pom.xml:product-view-service-feign: 新增spring-boot-starter-actuator 用于访问路径：&#x2F;actuator&#x2F;bus-refresh 新增spring-cloud-starter-bus-amqp 用于支持 rabbitmq 12345678910&lt;!--多了spring-boot-starter-actuator 用于访问路径：/actuator/bus-refresh--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--多了spring-cloud-starter-bus-amqp 用于支持 rabbitmq--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt;&lt;/dependency&gt; bootstrap.yml:新增 but总线配置: 123456spring: cloud: bus: enabled: true trace: enabled: true 新增 rabbitMQ 配置: 12345rabbitmq: host: localhost port: 5672 username: guest password: guest 完整代码： 123456789101112131415161718192021spring: cloud: config: label: develop profile: dev discovery: enabled: true serviceId: config-server bus: enabled: true trace: enabled: true client: serviceUrl: defaultZone: http://localhost:8761/eureka/rabbitmq: host: localhost port: 5672 username: guest password: guest application.yml:新增路径访问允许,这样才能访问 &#x2F;actuator&#x2F;bus-refresh: 12345678management: endpoints: web: exposure: include: &quot;*&quot; cors: allowed-origins: &quot;*&quot; allowed-methods: &quot;*&quot; FreshConfigUtil.java使用 post 的方式访问 http://localhost:8012/actuator/bus-refresh 地址，之所以要专门做一个 FreshConfigUtil 类，就是为了可以使用 post 访问，因为它不支持 get 方式访问，直接把这个地址放在浏览器里，是会抛出 405错误的。 12345678910111213141516171819202122package cn.peach.util;/* * Create By Tao on 2022/4/24. * * */import cn.hutool.http.HttpUtil;import java.util.HashMap;public class FreshConfigUtil &#123; public static void main(String[] args) &#123; HashMap&lt;String,String&gt; headers =new HashMap&lt;&gt;(); headers.put(&quot;Content-Type&quot;, &quot;application/json; charset=utf-8&quot;); System.out.println(&quot;因为要去git获取，还要刷新config-server, 会比较卡，所以一般会要好几秒才能完成，请耐心等待&quot;); String result = HttpUtil.createPost(&quot;http://localhost:8012/actuator/bus-refresh&quot;).addHeaders(headers).execute().body(); System.out.println(&quot;result:&quot;+result); System.out.println(&quot;refresh 完成&quot;); &#125;&#125; 对服务链路追踪的影响因为视图服务进行了改造，支持了 rabbitMQ, 那么在默认情况下，它的信息就不会进入 Zipkin了。 在Zipkin 里看不到视图服务的资料了。为了解决这个问题，在启动 Zipkin 的时候 带一个参数就好了：–zipkin.collector.rabbitmq.addresses&#x3D;localhost即改成了： 1java -jar zipkin-server-2.10.1-exec.jar --zipkin.collector.rabbitmq.addresses=localhost 注： 重启 zipkin 后，要再访问业务地址才可以看到依赖关系。","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"SpringCloud系列8-配置客户端","date":"2021-10-06T10:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列8-配置客户端/","text":"配置客户端把现成的 视图微服务-Feign 改造成配置客户端，使得其可以从配置服务器上获取版本信息。 pom.xml增加一个 spring-cloud-starter-config 用于访问配置服务器。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;&lt;/dependency&gt; bootstrap.yml 作为配置客户端，它需要在 bootstrap.yml 里配置 config-server 的信息，而不是像以前那样在 application.yml 里进行配置。 bootstrap.yml 和 application.yml 的区别，简单说就是前者先启动，并且一些系统方面的配置需要在 bootstrap.yml 里进行配置。 在 bootstrap.yml 里配置提供了 serviceId: config-server, 这个是配置服务器在 eureka server 里的服务名称，这样就可以定位 config-server了。123456789101112131415spring: cloud: config: label: develop profile: dev discovery: enabled: true serviceId: config-server bus: enabled: true trace: enabled: true client: serviceUrl: defaultZone: http://localhost:8761/eureka/ application.yml把 eureka 地址信息移动到了 bootstrap.yml 里。 123456789101112spring: application: name: product-view-service-feign thymeleaf: cache: false prefix: classpath:/templates/ suffix: .html encoding: UTF-8 content-type: text/html mode: HTML5 zipkin: base-url: http://localhost:9411 ProductController.java增加这个属性，就可以从 config-server 去获取 version 信息了。 12@Value(&quot;$&#123;version&#125;&quot;)String version; 然后把这个信息放在 Model里 1m.addAttribute(&quot;version&quot;, version); 完整代码： 12345678910111213141516@Controller@RefreshScopepublic class ProductController &#123; @Autowired ProductService productService; @Value(&quot;$&#123;version&#125;&quot;) String version; @RequestMapping(&quot;/products&quot;) public Object products(Model m) &#123; List&lt;Product&gt; ps = productService.listProducts(); m.addAttribute(&quot;version&quot;, version); m.addAttribute(&quot;ps&quot;, ps); return &quot;products&quot;; &#125;&#125; products.html:12345&lt;tr&gt; &lt;td align=&quot;center&quot; colspan=&quot;3&quot;&gt; &lt;p th:text=&quot;$&#123;version&#125;&quot; &gt;how2j springcloud version unknown&lt;/p&gt; &lt;/td&gt;&lt;/tr&gt; 启动:挨个启动 EurekaServerApplication, ConfigServerApplication, ProductDataServiceApplication, ProductViewServiceFeignApplication, 然后访问如下地址：http://localhost:8012/products","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"SpringCloud系列7-配置服务器","date":"2021-10-06T09:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列7-配置服务器/","text":"配置服务的需要:有时候，微服务要做集群，这就意味着，会有多个微服务实例。 在业务上有时候需要修改一些配置信息，比如说 版本信息吧~ 倘若没有配置服务， 那么就需要挨个修改微服务，挨个重新部署微服务，这样就比较麻烦。为了偷懒， 这些配置信息就会放在一个公共的地方，比如git, 然后通过配置服务器把它获取下来，然后微服务再从配置服务器上取下来。这样只要修改git上的信息，那么同一个集群里的所有微服务都立即获取相应信息了，这样就大大节约了开发，上线和重新部署的时间了。 如图所示，我们先在 git 里保存 version 信息， 然后通过 ConfigServer 去获取 version 信息， 接着不同的视图微服务实例再去 ConfigServer 里获取 version. git首先要准备git。如下是已经准备好的 git:https://github.com/taoliu-hub/spring-cloud-angular11/blob/develop/respo/product-view-service-feign-dev.properties这里就准备了版本信息： version &#x3D; Version 1.1 创建子项目: config-serverpom.xml主要是 spring-cloud-config-server 这个 jar 包 1234567891011121314151617181920212223242526272829303132&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;spring-cloud-parent&lt;/artifactId&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-parent/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;artifactId&gt;config-server&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;config-server&lt;/name&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 启动类：ConfigServerApplication123456789101112131415161718package cn.peach;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.cloud.config.server.EnableConfigServer;import org.springframework.cloud.netflix.eureka.EnableEurekaClient;@SpringBootApplication@EnableConfigServer@EnableDiscoveryClient@EnableEurekaClientpublic class ConfigServerApplication &#123; public static void main(String[] args) &#123; // 推荐 8030 SpringApplication.run(ConfigServerApplication.class, args); &#125;&#125; application.yml12345678910111213141516171819spring: application: name: config-server cloud: config: label: develop name: product-view-service-feign profile: dev server: git: uri: https://github.com/taoliu-hub/spring-cloud-angular11.git searchPaths: respo default-label: main timeout: 500000eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/ 启动先启动 EurekaServerApplication， 再启动 ConfigServerApplication， 然后访问http://localhost:8030/version/dev","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"SpringCloud系列6-服务链路追踪","date":"2021-10-06T08:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列6-服务链路追踪/","text":"什么是服务链路我们有两个微服务，分别是数据服务和视图服务，随着业务的增加，就会有越来越多的微服务存在，他们之间也会有更加复杂的调用关系。这个调用关系，仅仅通过观察代码，会越来越难以识别，所以就需要通过 zipkin 服务链路追踪服务器 这个东西来用图片进行识别了 改造 eureka-server 不需要做改造; product-data-service和product-view-service 需要进行改造以使其可以被追踪到。 pom.xml都加上以下依赖：12345&lt;!--服务链路追踪--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt;&lt;/dependency&gt; application.yml都加上以下配置信息：123spring: zipkin: base-url: http://localhost:9411 启动类都加上以下配置信息：ProductDataServiceApplication.java 和 ProductViewServiceFeignApplication.java： 1234@Beanpublic Sampler defaultSampler() &#123; return Sampler.ALWAYS_SAMPLE;&#125; 启动测试： 需要启动链路追踪服务器：zipkin-server-2.10.1-exec.jar, 命令启动:1java -jar zipkin-server-2.10.1-exec.jar 启动 eureka-server, 改造后的 product-data-service 和 product-view-service-feign; 访问一次 http://127.0.0.1:8012/products 通过 视图微服务去访问数据微服务，这样链路追踪服务器才知道有这事儿发生 然后打开链路追踪服务器 http://localhost:9411/zipkin/dependency/ 就可以看到如图所示的 视图微服务调用数据微服务 的图形了","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"SpringCloud系列5-视图微服务-Feign","date":"2021-10-06T07:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列5-视图微服务-Feign/","text":"Feign 概念:是对Ribbon的封装，调用起来更简单。 代码片段的区别 Ribbon方式：123456@AutowiredRestTemplate restTemplate;public List&lt;Product&gt; listProdcuts() &#123; return restTemplate.getForObject(&quot;http://PRODUCT-DATA-SERVICE/products&quot;,List.class);&#125; Feign方式：123456@FeignClient(value = &quot;PRODUCT-DATA-SERVICE&quot;)public interface ProductClientFeign &#123; @GetMapping(&quot;/products&quot;) public List&lt;Product&gt; listProdcuts();&#125; 创建子项目 product-view-service-feignpom.xml:123456789101112131415161718192021222324252627282930313233&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;spring-cloud-parent&lt;/artifactId&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-parent/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;product-view-service-feign&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; Feign 客户端:Feign 客户端， 通过 注解方式 访问 访问PRODUCT-DATA-SERVICE服务的 products路径， product-data-service 既不是域名也不是ip地址，而是 数据服务在 eureka 注册中心的名称。 注意: 这里只是指定了要访问的 微服务名称，但是并没有指定端口号到底是 8001, 还是 8002. Feign方式：1234567891011121314package cn.peach.client;import cn.peach.pojo.Product;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;import java.util.List;@FeignClient(value = &quot;PRODUCT-DATA-SERVICE&quot;)public interface ProductClientFeign &#123; @GetMapping(&quot;/products&quot;) public List&lt;Product&gt; listProdcuts();&#125; Java code: 注意：这里忽略controller、 service、 repository, html层的代码，只列出重要部分代码，如需了解详情可参阅以下地址获取代码：https://github.com/taoliu-hub/spring-cloud-angular11/tree/main/spring-cloud. 服务类: ProductServiceImpl 123456789101112131415161718192021package cn.peach.service.impl;import cn.peach.client.ProductClientFeign;import cn.peach.pojo.Product;import cn.peach.service.ProductService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import java.util.List;@Servicepublic class ProductServiceImpl implements ProductService &#123; @Autowired ProductClientFeign productClientFeign; @Override public List&lt;Product&gt; listProducts() &#123; return productClientFeign.listProdcuts(); &#125;&#125; 启动类，注解多了个 @EnableFeignClients， 表示用于使用 Feign 方式。 1234567891011121314151617181920package cn.peach;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.EnableEurekaClient;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.cloud.openfeign.EnableFeignClients;@SpringBootApplication@EnableEurekaClient@EnableDiscoveryClient@EnableFeignClientspublic class ProductViewServiceFeignApplication &#123; public static void main(String[] args) &#123; // 推荐 8012 、 8013 或者 8014 SpringApplication.run(ProductViewServiceFeignApplication.class, args); &#125;&#125; 配置application.yml配置类，指定了 eureka server 的地址，以及自己的名称。 另外是一些 thymeleaf 的默认配置。 1234567891011121314eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/spring: application: name: product-view-service-feign thymeleaf: cache: false prefix: classpath:/templates/ suffix: .html encoding: UTF-8 content-type: text/html mode: HTML5 启动并访问注册中心Eureka:刷新访问：http://127.0.0.1:8761/。 启动并访问视图微服务product-view-service-feign:刷新访问：http://127.0.0.1:8012/products。 调用图：如图所示： 首先数据微服务和视图微服务都被 eureka 管理起来了。 数据服务是由两个实例的集群组成的，端口分别是 8001 ， 8002 视图微服务通过 注册中心调用微服务， 然后负载均衡到 8001 或者 8002 端口的应用上。","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"SpringCloud系列4-视图微服务-RIBBON","date":"2021-10-06T06:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列4-视图微服务-RIBBON/","text":"Ribbon 概念访问前面注册好的数据微服务, springcloud 提供了两种方式: Ribbon: 是使用 restTemplate 进行调用，并进行客户端负载均衡。 Feign: 是对 Ribbon的封装，调用起来更简单。 什么是客户端负载均衡:在前面注册数据微服务里，注册了8001和8002两个微服务， Ribbon会从注册中心获知这个信息，然后由 Ribbon 这个客户端自己决定是调用哪个，这个就叫做客户端负载均衡。 创建子项目: product-view-service-ribbonpom.xml包含以下jar: spring-cloud-starter-netflix-eureka-client: eureka 客户端 spring-boot-starter-web： springmvc spring-boot-starter-thymeleaf： thymeleaf 做服务端渲染，(前后端分离项目不用配置)。 12345678910111213141516171819202122232425262728293031&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;spring-cloud-parent&lt;/artifactId&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-parent/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;product-view-service-ribbon&lt;/artifactId&gt; &lt;name&gt;product-view-service-ribbon&lt;/name&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; Ribbon 客户端Ribbon客户端: 通过restTemplate 访问 http://PRODUCT-DATA-SERVICE/products,而 product-data-service既不是域名也不是ip地址，而是数据服务在eureka 注册中心的名称. 注意: 这里只是指定了要访问的 微服务名称，但是并没有指定端口号到底是8001, 还是8002. 12345678910111213141516171819package cn.peach.client;import cn.peach.pojo.Product;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Component;import org.springframework.web.client.RestTemplate;import java.util.List;@Componentpublic class ProductClientRibbon &#123; @Autowired RestTemplate restTemplate; public List&lt;Product&gt; listProdcuts() &#123; return restTemplate.getForObject(&quot;http://PRODUCT-DATA-SERVICE/products&quot;,List.class); &#125;&#125; Java code: 注意：这里忽略controller、 service、 repository, html层的代码，只列出重要部分代码，如需了解详情可参阅以下地址获取代码：https://github.com/taoliu-hub/spring-cloud-angular11/tree/main/spring-cloud. 服务类: ProductServiceImpl 12345678910111213141516171819202122package cn.peach.service.impl;import cn.peach.client.ProductClientRibbon;import cn.peach.pojo.Product;import cn.peach.service.ProductService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import java.util.List;@Servicepublic class ProductServiceImpl implements ProductService &#123; @Autowired ProductClientRibbon productClientRibbon; @Override public List&lt;Product&gt; listProducts() &#123; return productClientRibbon.listProdcuts(); &#125;&#125; 启动类，注解多了个 @EnableDiscoveryClient，表示用于发现eureka 注册中心的微服务, 启动类，多了个 RestTemplate，就表示用 restTemplate 这个工具来做负载均衡, 考虑到要做集群。 自己输入端口，推荐 80010，8002，8003. 1234567891011121314151617181920212223import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.EnableEurekaClient;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.context.annotation.Bean;import org.springframework.cloud.client.loadbalancer.LoadBalanced;import org.springframework.web.client.RestTemplate;@SpringBootApplication@EnableEurekaClient@EnableDiscoveryClientpublic class ProductViewServiceRibbonApplication &#123; public static void main( String[] args ) &#123; SpringApplication.run(ProductDataServiceApplication.class, args); &#125; @Bean @LoadBalanced RestTemplate restTemplate() &#123; return new RestTemplate(); &#125;&#125; 配置application.yml配置类，指定了 eureka server 的地址，以及自己的名称。 另外是一些 thymeleaf 的默认配置。 1234567891011121314eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/spring: application: name: product-view-service-ribbon thymeleaf: cache: false prefix: classpath:/templates/ suffix: .html encoding: UTF-8 content-type: text/html mode: HTML5 启动并访问注册中心Eureka:刷新访问：http://127.0.0.1:8761/。 启动并访问视图微服务product-view-service-ribbon:刷新访问：http://127.0.0.1:8010/products。 调用图：如图所示： 首先数据微服务和视图微服务都被 eureka 管理起来了。 数据服务是由两个实例的集群组成的，端口分别是 8001 ， 8002 视图微服务通过 注册中心调用微服务， 然后负载均衡到 8001 或者 8002 端口的应用上。","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"SpringCloud系列3-注册数据微服务","date":"2021-10-06T05:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列3-注册数据微服务/","text":"创建子项目: product-data-service注意：若前面父子(聚合)项目创建了数据微服务，可直接更新此微服务。修改 pom.xml 为如下： spring-cloud-starter-netflix-eureka-client 表示这是个 eureka 客户端。 spring-boot-starter-web: 表示这是个web服务，会提供控制层1234567891011121314151617181920212223242526&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;spring-cloud-parent&lt;/artifactId&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-parent/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;product-data-service&lt;/artifactId&gt; &lt;name&gt;product-data-service&lt;/name&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 启动类ProductDataServiceApplication 启动类， 考虑到要做集群。 自己输入端口，推荐 8001，8002，8003. 注意：这里忽略controller、 service、 repository, html层的代码，只列出重要部分代码，如需了解详情可参阅以下地址获取代码：https://github.com/taoliu-hub/spring-cloud-angular11/tree/main/spring-cloud. 123456789101112131415package cn.peach;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.EnableEurekaClient;@SpringBootApplication@EnableEurekaClientpublic class ProductDataServiceApplication&#123; public static void main( String[] args ) &#123; SpringApplication.run(ProductDataServiceApplication.class, args); &#125;&#125; 配置application.yml 设置微服务的名称： product-data-service 设置注册中心的地址： http://localhost:8761/eureka/, 与eureka-server中的配置 application.yml一致。 12345678910# server:# port: 因为会启动多个 product-data-service, 所以端口号由用户自动设置，推荐 8001,8002,8003 spring: application: name: product-data-serviceeureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/ 启动并访问注册中心Eureka:刷新访问：http://127.0.0.1:8761/。 补充(上图红色信息)： EMERGENCY! EUREKA MAY BE INCORRECTLY CLAIMING INSTANCES ARE UP WHEN THEY’RE NOT. RENEWALS ARE LESSER THAN THRESHOLD AND HENCE THE INSTANCES ARE NOT BEING EXPIRED JUST TO BE SAFE. 上面这句话意思是，Eureka可能会声明已经不存在的实例。刷新数小于阈值时，为了安全起见不会剔除过期实例。 Eureka的默认阈值为：85% 比如目前有10个微服务，只有8个有心跳反应时，（8&#x2F;10&#x3D;80%&lt;85%）Eureka就会开启保护机制，过期的实例不会立马剔除。并且出这个紧急警告，在搭建Eureka Server时，比如我们搭建了2个Eureka Server，并且禁止自注册，Eureka Server自身算一个服务，那么其中任意一个Eureka，只能获得一个心跳，1&#x2F;2&#x3D;50%。那么也会出现这个警告。 当不想有这个红色警告是，本机自测可以关闭Eureka保护配置。生产环境下不要关。在application.yml文件中配置：12server: enable-self-preservation: false","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"SpringCloud系列2-服务注册中心","date":"2021-10-06T04:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列2-服务注册中心/","text":"创建子项目: eureka-serverpom.xml ，增加 spring-cloud-starter-netflix-eureka-server jar 包 12345678910111213141516171819202122&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;spring-cloud-parent&lt;/artifactId&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-parent/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;eureka-server&lt;/artifactId&gt; &lt;name&gt;eureka-server&lt;/name&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 启动类: EurekaServerApplication EurekaServer，它扮演的角色是注册中心，用于注册各种微服务，以便于其他微服务找到和访问。 EurekaServer 本身就是个 Springboot 微服务, 所以它有 @SpringBootApplication 注解。 @EnableEurekaServer 表示这是个 EurekaServer 。完整代码：123456789101112131415161718192021package cn.peach;import cn.hutool.core.util.NetUtil;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.boot.builder.SpringApplicationBuilder;import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;@SpringBootApplication@EnableEurekaServerpublic class EurekaServerApplication&#123; public static void main(String[] args) &#123; //8761 这个端口是默认的，就不要修改了，后面的子项目，都会访问这个端口。 int port = 8761; if(!NetUtil.isUsableLocalPort(port)) &#123; System.err.printf(&quot;端口%d被占用了，无法启动%n&quot;, port ); System.exit(1); &#125; new SpringApplicationBuilder(EurekaServerApplication.class).properties(&quot;server.port=&quot; + port).run(args); &#125;&#125; 配置application.yml 设置微服务的名称： eureka-server hostname: localhost 表示主机名称。 registerWithEureka：false. 表示是否注册到服务器。 因为它本身就是服务器，所以就无需把自己注册到服务器了。 fetchRegistry: false. 表示是否获取服务器的注册信息，和上面同理，这里也设置为 false。 defaultZone： http:&#x2F;&#x2F;${eureka.instance.hostname}:${server.port}&#x2F;eureka&#x2F; 自己作为服务器，公布出来的地址。 比如后续某个微服务要把自己注册到 eureka server, 那么就要使用这个地址： http://localhost:8761/eureka/ 123456789101112eureka: instance: hostname: localhost client: registerWithEureka: false fetchRegistry: false serviceUrl: defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ spring: application: name: eureka-server 启动并访问注册中心Eureka:运行 EurekaServerApplication，并访问：http://127.0.0.1:8761/，默认端口号为：8761。","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"SpringCloud系列1-父子(聚合)项目","date":"2021-10-06T03:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud系列1-父子(聚合)项目/","text":"SpringCloud代码结构 创建父项目: spring-cloud-parent修改pom： 1&lt;packaging&gt;pom&lt;/packaging&gt; 注意： 父项目只有pom.xml文件， packaging值为pom. 完整代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.6.RELEASE&lt;/version&gt; &lt;!-- 踩坑:版本不对会导致Feign连接不上，亲测其它版本, 2.3.3.RELEASE version. --&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-parent&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;spring-cloud-parent&lt;/name&gt; &lt;description&gt;spring-cloud-parent project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Finchley.SR2&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt;&lt;/project&gt; 创建子项目: product-data-service修改pom： 123456789&lt;parent&gt; &lt;artifactId&gt;spring-cloud-parent&lt;/artifactId&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-parent/pom.xml&lt;/relativePath&gt;&lt;/parent&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;artifactId&gt;product-data-service&lt;/artifactId&gt;&lt;name&gt;product-data-service&lt;/name&gt;","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"JAVA数据结构和算法","date":"2021-10-06T02:08:20.000Z","path":"blog/数据结构和算法/JAVA数据结构和算法/","text":"JAVA数据结构和算法： 数据结构分类：线性结构和非线性结构： 问题一：什么是线性和非线性； 个人的理解是：数据结构中线性结构指的是数据元素之间存在着“一对一”的线性关系的数据结构；线性结构包括：数组，链表，队列，栈；非线性结构包括：树，图，表； 详解：一.线性结构 1.数组特点：我们都知道数组中的元素在内存中连续存储的，可以根据是下标快速访问元素，因此，查询速度很快，然而插入和删除时，需要对元素移动空间，比较慢。数组使用场景：频繁查询，很少增加和删除的情况。 2.链表特点：元素可以不连续内存中，是以索引将数据联系起来的，当查询元素的时候需要从头开始查询，所以效率比较低，然而添加和删除的只需要修改索引就可以了链表使用场景：少查询，需要频繁的插入或删除情况 3.队列特点：先进先出，队列使用场景：多线程阻塞队列管理非常有用 4.栈特点：先进后出，就像一个箱子，栈使用场景：实现递归以及表示式 5.数组与链表的区别数组连续，链表不连续（从数据存储形式来说）数组内存静态分配，链表动态分配数组查询复杂度O(1)，链表查询复杂度O(n)数组添加或删除，复杂度O(n),链表添加删除，复杂度O(1)数组从栈中分配内存。链表从堆中分配内存。 补充：时间复杂度O(1), O(n), O(logn), O(nlogn)指什么 描述算法复杂度时,常用o(1), o(n), o(logn), o(nlogn)表示对应算法的时间复杂度，是算法的时空复杂度的表示。不仅仅用于表示时间复杂度，也用于表示空间复杂度。O后面的括号中有一个函数，指明某个算法的耗时&#x2F;耗空间与数据增长量之间的关系。其中的n代表输入数据的量。 O(1)： 是最低的时空复杂度了，代表耗时&#x2F;耗空间与输入数据大小无关，无论输入数据增大多少倍，耗时&#x2F;耗空间都不变。 哈希算法就是典型的O(1)时间复杂度，无论数据规模多大，都可以在一次计算后找到目标（不考虑冲突的话） O(n)： 代表数据量增大几倍，耗时也增大几倍。比如常见的遍历算法。 O(n^2)： 代表数据量增大n倍时，耗时增大n的平方倍，这是比线性更高的时间复杂度。比如冒泡排序，就是典型的O(n^2)的算法，对n个数排序，需要扫描n×n次。 O(logn)： 代表当数据增大n倍时，耗时增大logn倍（这里的log是以2为底的，比如，当数据增大256倍时，耗时只增大8倍，是比线性还要低的时间复杂度）。二分查找就是O(logn)的算法，每找一次排除一半的可能，256个数据中查找只要找8次就可以找到目标。 O(nlogn)： 代表n乘以logn，当数据增大256倍时，耗时增大256*8&#x3D;2048倍。这个复杂度高于线性低于平方。归并排序就是O(nlogn)的时间复杂度。 问题二：c1）插入排序（直接插入排序、希尔排序） 2）交换排序（冒泡排序、快速排序）3）选择排序（直接选择排序、堆排序）4）归并排序5）分配排序（基数排序）特点:所需辅助空间最多：归并排序所需辅助空间最少：堆排序平均速度最快：快速排序不稳定：快速排序，希尔排序，堆排序 直接插入排序 基本思想：在要排序的一组数中，假设前面(n-1)[n&gt;&#x3D;2] 个数已经是排好顺序的，现在要把第n 个数插到前面的有序数中，使得这 n个数也是排好顺序的。如此反复循环，直到全部排好顺序 12345678910111213141516/** * 插入排序法 * * @param datas */ public static int[] sortInsert(int[] datas) &#123; for (int i = 1; i &lt; datas.length; i++) &#123; int j = i - 1; AlgorithmUtil.temp = datas[i]; for (; j &gt;= 0 &amp;&amp; AlgorithmUtil.temp &lt; datas[j]; j--) &#123; datas[j + 1] = datas[j]; &#125; datas[j + 1] = AlgorithmUtil.temp; &#125; return datas; &#125; 简单选择排序 基本思想：在要排序的一组数中，选出最小的一个数与第一个位置的数交换；然后在剩下的数当中再找最小的与第二个位置的数交换，如此循环到倒数第二个数和最后一个数比较为止。 1234567891011121314151617/** * 选择排序 * * @return */ public static int[] sortSelect(int[] datas) &#123; for (int i = 0; i &lt; datas.length; i++) &#123; int index = i; for (int j = i + 1; j &lt; datas.length; j++) &#123; if (datas[j] &lt; datas[index]) index = j; &#125; if (i != index) AlgorithmUtil.swap(datas, i, index); &#125; return datas; &#125; 冒泡排序 基本思想：在要排序的一组数中，对当前还未排好序的范围内的全部数，自上而下对相邻的两个数依次进行比较和调整，让较大的数往下沉，较小的往上冒。即：每当两相邻的数比较后发现它们的排序与排序要求相反时，就将它们互换。 1234567891011121314/** * 冒泡排序 * * @return */ public static int[] sortBubble(int[] datas) &#123; for (int i = 0; i &lt; datas.length - 1; i++) &#123; for (int j = 0; j &lt; datas.length - 1 - i; j++) &#123; if (datas[j] &gt; datas[j + 1]) AlgorithmUtil.swap(datas, j, j + 1); &#125; &#125; return datas; &#125; 快速排序 基本思想：选择一个基准元素,通常选择第一个元素或者最后一个元素,通过一趟扫描，将待排序列分成两部分,一部分比基准元素小,一部分大于等于基准元素,此时基准元素在其排好序后的正确位置,然后再用同样的方法递归地排序划分的两部分。 1234567891011121314151617181920212223242526272829303132/** * 快速排序；分割数组 * * @param datas */ public static int QuickPartition(int[] datas, int left, int right) &#123; int pivot = datas[left]; while (left &lt; right) &#123; while (left &lt; right &amp;&amp; datas[right] &gt;= pivot) --right; datas[left] = datas[right]; // 将比枢轴小的元素移到低端，此时right位相当于空，等待低位比pivotkey大的数补上 while (left &lt; right &amp;&amp; datas[left] &lt;= pivot) ++left; datas[right] = datas[left]; // 将比枢轴大的元素移到高端，此时left位相当于空，等待高位比pivotkey小的数补上 &#125; datas[left] = pivot; // 当left == right，完成一趟快速排序，此时left位相当于空，等待pivotkey补上 return left; &#125; /** * 快速排序；递归返回数组 * * @param datas */ public static int[] sortQuick(int[] datas, int left, int right) &#123; if (left &lt; right) &#123; int data = QuickPartition(datas, left, right); sortQuick(datas, left, data - 1); sortQuick(datas, data + 1, right); &#125; return datas; &#125; 1.冒泡算法，2.选择算法，3.快速算法。4.插入算法，5.希尔算法，6.堆算法 基本思想：在要排序的一组数中，选出最小的一个数与第一个位置的数交换；然后在剩下的数当中再找最小的与第二个位置的数交换，如此循环到倒数第二个数和最后一个数比较为止。 123456789101112131415161718192021222324252627282930313233343536public class AlgorithmUtil &#123; public static int temp,index = 0; /** * 临时值交换 * * @param datas * 数组 * @param i * @param j */ public static void swap(int[] datas, int i, int j) &#123; temp = datas[i]; datas[i] = datas[j]; datas[j] = temp; &#125; /** * 扩充数组长度 * * @param datas * @param value * @return */ public static int[] expandArray(int[] datas, int value) &#123; if (datas.length &lt;= index) &#123; int[] arrays = new int[datas.length * 2]; System.arraycopy(datas, 0, arrays, 0, datas.length); datas = arrays; &#125; datas[index] = value; index++; return datas; &#125; &#125;","tags":[{"name":"JAVA数据结构和算法","slug":"JAVA数据结构和算法","permalink":"http://example.com/tags/JAVA%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/"}],"categories":[{"name":"数据结构和算法","slug":"数据结构和算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/"}]},{"title":"SpringCloud介绍","date":"2021-10-06T02:08:20.000Z","path":"blog/Cloud/SpringCloud/SpringCloud/","text":"基础知识介绍：单体架构系统：单体架构就是所有功能，都放在一个应用里。 好处：便于开发，测试，部署也很方便，直接打成一个 jar 或者 war, 就什么都好了。 弊端：要体现在高访问，高并发的上限是固定的。 比如一个单体架构，能够承受 1000次访问&#x2F;秒。 但是访问量达到 2000次&#x2F;秒的时候，就会非常卡顿，严重影响业务，并且仅仅依靠单体架构本身，很难突破这个瓶颈了。 集群和分布式：既然单体架构会有性能上的瓶颈，那么总要解决呀。 解决办法通常就是采用集群和分布式来做。 集群：指一组相互独立的计算机，通过高速的网络组成一个计算机系统。服务器集群就是指将很多服务器集中起来一起进行同一种服务，在客户端看来就像是只有一个服务器。 集群的特点和优势: 高性能 性价比 可伸缩性集群的分类 负载均衡集群（Load balancing clusters）简称LBC 高可用性集群（High-availability clusters）简称HAC 高性能计算集群（High-perfomance clusters）简称HPC 分布式：指将不同的业务分布在不同的地方，而集群指的是将几台服务器集中在一起，实现同一业务。分布式中的每一个节点，都可以做集群，而集群并不一定就是分布式的。 分布式一致性：分布式系统中，一个问题是负载均衡，另外一个问题就是数据的一致性。 在分布式集群中，很难保障数据的一致性。在以往的单节点服务中，通常使用锁来实现，当发生并发冲突时 通过对锁的持有获得对象的操作权，从而保证数据在同一时刻只允许被一个请求操作。但是在集群中，若同样采用锁的机制，那么需要一台节点用来管理分配锁，当其他节点进行请求前，首先去获取锁从而获得执行权。但是这样会产生单节点问题，即若管理锁的节点down掉，那么整个集群将无法工作。同时，由于锁的机制会使整个集群变成串行化单节点的形式，失去了集群的意义。 分布式和集群的关系： 根据分布式的介绍看出，其主要的功能是用了将我们的系统模块化，将系统进行解耦的，方便我们的维护和开发的，但是其并不能解决我们的并发问题，也无法保证我们的系统在服务器宕机后的正常运转。 集群就恰好弥补了分布式的缺陷，集群就是多个服务器处理相同的业务，这在一方面可以解决或者说改善我们系统的并发问题，一方面可以解决我们服务器如果出现一定数量的宕机后，系统仍然可以正常运转。 SpringCloud介绍：SpringCloud 就是一套工具。 Spring Cloud 并不是一个项目，而是一组项目的集合。包含了很多的子项目，每一个子项目都是一种微服务开发过程中遇到的问题的一种解决方案。它利用 Spring Boot的开发便利性巧妙地简化了分布式系统基础设施的开发，如服务发现注册、配置中心、消息总线、负载均衡、断路器、数据监控等，都可以用 Spring Boot的开发风格做到一键启动和部署。Spring Cloud并没有重复制造轮子，它只是将目前各家公司开发的比较成熟、经得起实际考验的服务框架组合起来，通过Spring Boot风格进行再封装屏蔽掉了复杂的配置和实现原理，最终给开发者留出了一套简单易懂、易部署和易维护的分布式系统开发工具包。 子项目介绍: Spring Cloud Config：集中配置管理工具，分布式系统中统一的外部配置管理，可以支持客户端配置的刷新及加密、解密操作, 可以让你把配置放到远程服务器，目前支持本地存储、Git 以及 Subversion。 Spring Cloud Netflix：针对多种 Netflix 组件提供的开发工具包，其中包括 Eureka、Hystrix、Ribbon、Feign、Zuul、Archaius 等组件, 如下: Eureka：服务治理组件，包括服务端的注册中心和客户端的服务发现机制； Hystrix：服务容错组件，实现了断路器模式，为依赖服务的出错和延迟提供了容错能力； Ribbon：负载均衡的服务调用组件，具有多种负载均衡调用策略； Feign：基于Ribbon和Hystrix的声明式服务调用组件； Zuul：API网关组件，对请求提供路由及过滤功能； Archaius：基于java的配置管理类库，主要用于多配置存储的动态获取。 Spring Cloud Bus：事件、消息总线，用于在集群（例如，配置变化事件）中传播状态变化，可与 Spring Cloud Config 联合实现热部署。 Spring Cloud Consul：封装了 Consul 操作，consul 是一个服务发现与配置工具，与 Docker 容器可以无缝集成。 Spring Cloud Security ：安全工具包，对Zuul代理中的负载均衡OAuth2客户端及登录认证进行支持。 Spring Cloud Sleuth：日志收集工具包，封装了 Dapper，Zipkin 和 HTrace 操作. Spring Cloud 应用的分布式跟踪实现。 Spring Cloud Stream：数据流操作开发包，封装了与 Redis，Rabbit、Kafka 等发送接收消息，实现的消息微服务。 Spring Cloud Task：用于快速构建短暂、有限数据处理任务的微服务框架，用于向应用中添加功能性和非功能性的特性。 Spring Cloud Zookeeper：基于 ZooKeeper 的服务发现与配置管理组件。 Spring Cloud Gateway：API网关组件，对请求提供路由及过滤功能, Spring Cloud 网关相关的整合实现。 Spring Cloud Aws：用于简化整合 Amazon Web Service 的组件。 Spring Cloud Cli：基于 Spring Boot CLI，可以让你以命令行方式快速建立云组件。 Spring Cloud Commons：服务发现、负载均衡、熔断机制这种模式为 Spring Cloud 客户端提供了一个通用的抽象层。 Spring Cloud Contract：Spring Cloud Contract是一个总体项目，其中包含帮助用户成功实施消费者驱动合同方法的解决方案(契约测试)。 Spring Cloud Cloudfoundry：通过 Oauth2 协议绑定服务到 CloudFoundry，CloudFoundry 是 VMware 推出的开源 PaaS 云平台。 Spring Cloud OpenFeign：基于Ribbon和Hystrix的声明式服务调用组件，可以动态创建基于Spring MVC注解的接口实现用于服务调用，在Spring Cloud 2.0中已经取代Feign成为了一等公民。","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"}]},{"title":"消息队列","date":"2021-03-23T02:00:20.000Z","path":"blog/工具和中间件/消息队列/消息队列/","text":"什么是消息中间件呢？以公众号为例，如果某用户订阅（关注）了这个公众号，每当管理员发布新文章的时候，都可以在这个公众号得到通知，这就是一种广播订阅模式。 公众号如何实现这一点呢？ 可以通过 消息中间件 来轻松实现。 管理员把最新的教程信息 发给 消息中间件服务器， 用户手机上的微信里的 消息中间件客户端，就会自动去把消息获取出来显示，这样管理员就达到了文章广播的效果了。 消息队列的作用： 应用耦合：多应用间通过消息队列对同一消息进行处理，避免调用接口失败导致整个过程失败； 异步处理：多应用对消息队列中同一消息进行处理，应用间并发处理消息，相比串行处理，减少处理时间； 限流削峰：广泛应用于秒杀或抢购活动中，避免流量过大导致应用系统挂掉的情况； 消息驱动的系统：系统分为消息队列、消息生产者、消息消费者，生产者负责产生消息，消费者(可能有多个)负责对消息进行处理； 选择消息队列要满足以下几个条件： 开源 流行 兼容性强 消息队列需要： 消息的可靠传递：确保不丢消息； 性能：具备足够好的性能，能满足绝大多数场景的性能要求。 Cluster：支持集群，确保不会因为某个节点宕机导致服务不可用，当然也不能丢消息； 实现选择：消息中间件有很多种，如 Activemq, Rabbitmq, RocketMQ, Kafka 等等 几种常见MQ的对比:","tags":[],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"}]},{"title":"RocketMQ-Spring集成","date":"2019-05-01T02:08:20.000Z","path":"blog/工具和中间件/消息队列/RocketMQ/RocketMQ-Spring集成/","text":"SpringBoot集成SpringBoot集成RocketMQ的starter依赖是由Spring社区提供的,目前正在快速迭代的过程当中,不同版本之间的差距非常大,故需特别注意版本.通过内置的 RocketMQTemplate 来与RocketMQ交互. 123456789101112131415161718192021222324&lt;dependency&gt; &lt;groupId&gt;org.apache.rocketmq&lt;/groupId&gt; &lt;artifactId&gt;rocketmq-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.1.1&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;version&gt;2.1.6.RELEASE&lt;/version&gt;&lt;/dependency&gt; 1234# NameServer地址rocketmq.name-server=localhost:9876# 默认的消息生产者组rocketmq.producer.group=springBootGroup SpringBoot集成RocketMQ,消费者部分核心功能都集成到 @RocketMQMessageListener 注解.消息过滤可以由里面的 selectorType 属性和 selectorExpression 来定制,由 consumeMode 来有序消费还是并发消费等； 1234567891011121314151617181920@Componentpublic class SpringProducer &#123; @Resource private RocketMQTemplate rocketMQTemplate; public void sendMessage(String topic, String msg) &#123; String[] tags = new String[]&#123;&quot;TagA&quot;, &quot;TagB&quot;, &quot;TagC&quot;, &quot;TagD&quot;, &quot;TagE&quot;&#125;; for (String tag : tags) &#123; String destination = topic + &quot;:&quot; + tag; this.rocketMQTemplate.convertAndSend(destination, msg); &#125; &#125;&#125;@Component@RocketMQMessageListener(consumerGroup = &quot;MyConsumerGroup&quot;, messageModel = MessageModel.CLUSTERING, topic = &quot;TestTopic&quot;, consumeMode = ConsumeMode.CONCURRENTLY, selectorExpression = &quot;TagA&quot;)public class SpringConsumer implements RocketMQListener&lt;String&gt; &#123; @Override public void onMessage(String message) &#123; System.out.println(&quot;Received message1 : &quot; + message); &#125;&#125; 对于事务消息需要添加一个 事务消息监听器 ,对于消息TAG的使用,需要通过将TAG拼接到Topic后面.SpringBoot依赖中的 Message 对象和RocketMQ中的 Message 对象是两个不同的对象,SpringBoot中的Message中就没有TAG属性,Tag属性被移到了发送目标中,以 Topic:Tag 的方式指定. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465@ExtRocketMQTemplateConfigurationpublic class ExtRocketMQTemplate extends RocketMQTemplate &#123;&#125;@RocketMQTransactionListener(rocketMQTemplateBeanName = &quot;extRocketMQTemplate&quot;)public class MyTransactionImpl implements RocketMQLocalTransactionListener &#123; private ConcurrentHashMap&lt;Object, Message&gt; localTrans = new ConcurrentHashMap&lt;&gt;(); @Override public RocketMQLocalTransactionState executeLocalTransaction(Message msg, Object arg) &#123; Object transId = msg.getHeaders().get(RocketMQHeaders.PREFIX + RocketMQHeaders.TRANSACTION_ID); String destination = arg.toString(); localTrans.put(transId, msg); //这个msg的实现类是GenericMessage,里面实现了toString方法 //在Header中自定义的RocketMQHeaders.TAGS属性,到这里就没了.但是RocketMQHeaders.TRANSACTION_ID这个属性就还在. //而message的Header里面会默认保存RocketMQHeaders里的属性,但是都会加上一个RocketMQHeaders.PREFIX前缀 System.out.println(&quot;executeLocalTransaction msg = &quot; + msg); //转成RocketMQ的Message对象 org.apache.rocketmq.common.message.Message message = RocketMQUtil.convertToRocketMessage(new StringMessageConverter(), &quot;UTF-8&quot;, destination, msg); String tags = message.getTags(); if (StringUtils.contains(tags, &quot;TagA&quot;)) &#123; return RocketMQLocalTransactionState.COMMIT; &#125; else if (StringUtils.contains(tags, &quot;TagB&quot;)) &#123; return RocketMQLocalTransactionState.ROLLBACK; &#125; else &#123; return RocketMQLocalTransactionState.UNKNOWN; &#125; &#125; @Override public RocketMQLocalTransactionState checkLocalTransaction(Message msg) &#123; String transId = msg.getHeaders().get(RocketMQHeaders.PREFIX + RocketMQHeaders.TRANSACTION_ID).toString(); Message originalMessage = localTrans.get(transId); // 这里能够获取到自定义的transaction_id属性 System.out.println(&quot;checkLocalTransaction msg = &quot; + originalMessage); // 获取标签时,自定义的RocketMQHeaders.TAGS拿不到,但是框架会封装成一个带RocketMQHeaders.PREFIX的属性 String tags = msg.getHeaders().get(RocketMQHeaders.PREFIX + RocketMQHeaders.TAGS).toString(); if (StringUtils.contains(tags, &quot;TagC&quot;)) &#123; return RocketMQLocalTransactionState.COMMIT; &#125; else if (StringUtils.contains(tags, &quot;TagD&quot;)) &#123; return RocketMQLocalTransactionState.ROLLBACK; &#125; else &#123; return RocketMQLocalTransactionState.UNKNOWN; &#125; &#125;&#125;@Componentpublic class SpringProducer &#123; @Resource private RocketMQTemplate extRocketMQTemplate; public void sendMessageInTransaction(String topic, String msg) throws InterruptedException &#123; String[] tags = new String[]&#123;&quot;TagA&quot;, &quot;TagB&quot;, &quot;TagC&quot;, &quot;TagD&quot;, &quot;TagE&quot;&#125;; for (int i = 0; i &lt; 10; i++) &#123; //尝试在Header中加入一些自定义的属性. Message&lt;String&gt; message = MessageBuilder.withPayload(msg) .setHeader(RocketMQHeaders.TRANSACTION_ID, &quot;TransID_&quot; + i) //发到事务监听器里后,这个自己设定的TAGS属性会丢失.但是上面那个属性不会丢失. .setHeader(RocketMQHeaders.TAGS, tags[i % tags.length]) //MyProp在事务监听器里也能拿到,为什么就单单这个RocketMQHeaders.TAGS拿不到？这只能去调源码了. .setHeader(&quot;MyProp&quot;, &quot;MyProp_&quot; + i) .build(); String destination = topic + &quot;:&quot; + tags[i % tags.length]; //这里发送事务消息时,还是会转换成RocketMQ的Message对象,再调用RocketMQ的API完成事务消息机制. SendResult sendResult = extRocketMQTemplate.sendMessageInTransaction(destination, message, destination); System.out.printf(&quot;%s%n&quot;, sendResult); Thread.sleep(10); &#125; &#125;&#125;","tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"http://example.com/tags/RocketMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RocketMQ","slug":"工具和中间件/消息队列/RocketMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RocketMQ/"}]},{"title":"RocketMQ-消费者源码","date":"2019-04-23T04:08:20.000Z","path":"blog/工具和中间件/消息队列/RocketMQ/RocketMQ-消费者源码/","text":"消费者以消费者组的模式开展.消费者组之间有集群模式和广播模式两种消费模式.消费模式有推模式和拉模式.推模式是由拉模式封装组成. 集群模式下,一个消费队列同一时间只能被一个消费者消费,而一个消费者可以同时消费多个队列.RocketMQ只支持一个队列上的局部消息顺序,不保证全局消息顺序. 在 DefaultMQPushConsumer 中的 start 方法中,通过调用 MQClientManager 的 getOrCreateMQClientInstance 方法实例化关键类 MQClientInstance ,在 MQClientInstance 中实例化了 PullMessageService 和 RebalanceService 两个线程类. MQClientInstance 的start方法中会启动 PullMessageService 和 RebalanceService 线程. RebalanceService 线程默认每 20s 执行一次,调用 MQClientInstance 的 doRebalance 方法遍历当前客户端所有消费者组的所有消费者,再通过 RebalanceImpl 的 doRebalance 方法遍历消费者对应的所有Topic,然后通过 rebalanceByTopic 对集群模式和广播模式进行处理,然后通过 updateProcessQueueTableInRebalance 方法遍历Topic下所有的队列将未消费的消息封装成 PullRequest列表最终通过 PullMessageService 的 executePullRequestImmediately 方法将 PullRequest 任务添加阻塞队列中. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149public class RebalanceService extends ServiceThread &#123; public void run() &#123; log.info(this.getServiceName() + &quot; service started&quot;); while (!this.isStopped()) &#123; this.waitForRunning(waitInterval); this.mqClientFactory.doRebalance(); &#125; log.info(this.getServiceName() + &quot; service end&quot;); &#125;&#125;public class MQClientInstance &#123; public void doRebalance() &#123; // 客户端负载均衡 针对当前消费者所属的每一个消费者组 for (Map.Entry&lt;String, MQConsumerInner&gt; entry : this.consumerTable.entrySet()) &#123; MQConsumerInner impl = entry.getValue(); if (impl != null) &#123; try &#123; impl.doRebalance(); &#125; &#125; &#125; &#125;&#125;public abstract class RebalanceImpl &#123; public void doRebalance(final boolean isOrder) &#123; Map&lt;String, SubscriptionData&gt; subTable = this.getSubscriptionInner(); if (subTable != null) &#123; for (final Map.Entry&lt;String, SubscriptionData&gt; entry : subTable.entrySet()) &#123; final String topic = entry.getKey(); try &#123; // 客户端负载：真正进行负载都是根据主题来进行的. this.rebalanceByTopic(topic, isOrder); &#125; catch (Throwable e) &#123; &#125; &#125; &#125; this.truncateMessageQueueNotMyTopic(); &#125; private void rebalanceByTopic(final String topic, final boolean isOrder) &#123; switch (messageModel) &#123; case BROADCASTING: &#123; //广播模式,不需要进行负载.每个消费者都要消费.只需要更新负载信息. Set&lt;MessageQueue&gt; mqSet = this.topicSubscribeInfoTable.get(topic); if (mqSet != null) &#123; boolean changed = this.updateProcessQueueTableInRebalance(topic, mqSet, isOrder); // 关键代码 if (changed) &#123; this.messageQueueChanged(topic, mqSet, mqSet); &#125; &#125; break; &#125; case CLUSTERING: &#123; // 客户端负载：集群模式负载方法 Set&lt;MessageQueue&gt; mqSet = this.topicSubscribeInfoTable.get(topic); //订阅的主题 List&lt;String&gt; cidAll = this.mQClientFactory.findConsumerIdList(topic, consumerGroup); //客户端ID if (mqSet != null &amp;&amp; cidAll != null) &#123; List&lt;MessageQueue&gt; mqAll = new ArrayList&lt;MessageQueue&gt;(); mqAll.addAll(mqSet); Collections.sort(mqAll); //排序后才能保证消费者负载策略相对稳定. Collections.sort(cidAll); AllocateMessageQueueStrategy strategy = this.allocateMessageQueueStrategy; //MessageQueue的负载策略,有五种实现类 List&lt;MessageQueue&gt; allocateResult = null; try &#123;//按负载策略进行分配,返回当前消费者实际订阅的MessageQueue集合. allocateResult = strategy.allocate(this.consumerGroup, this.mQClientFactory.getClientId(), mqAll, cidAll); &#125; catch (Throwable e) &#123; return; &#125; Set&lt;MessageQueue&gt; allocateResultSet = new HashSet&lt;MessageQueue&gt;(); if (allocateResult != null) &#123; allocateResultSet.addAll(allocateResult); &#125; boolean changed = this.updateProcessQueueTableInRebalance(topic, allocateResultSet, isOrder); // 关键代码 if (changed) &#123; this.messageQueueChanged(topic, mqSet, allocateResultSet); &#125; &#125; break; &#125; default: break; &#125; &#125; private boolean updateProcessQueueTableInRebalance(final String topic, final Set&lt;MessageQueue&gt; mqSet, final boolean isOrder) &#123; boolean changed = false; Iterator&lt;Entry&lt;MessageQueue, ProcessQueue&gt;&gt; it = this.processQueueTable.entrySet().iterator(); while (it.hasNext()) &#123; Entry&lt;MessageQueue, ProcessQueue&gt; next = it.next(); MessageQueue mq = next.getKey(); ProcessQueue pq = next.getValue(); if (mq.getTopic().equals(topic)) &#123; if (!mqSet.contains(mq)) &#123; pq.setDropped(true); if (this.removeUnnecessaryMessageQueue(mq, pq)) &#123; it.remove(); changed = true; &#125; &#125; else if (pq.isPullExpired()) &#123; switch (this.consumeType()) &#123; case CONSUME_ACTIVELY: break; case CONSUME_PASSIVELY: pq.setDropped(true); if (this.removeUnnecessaryMessageQueue(mq, pq)) &#123; it.remove(); changed = true; &#125; break; default: break; &#125; &#125; &#125; &#125; List&lt;PullRequest&gt; pullRequestList = new ArrayList&lt;PullRequest&gt;(); for (MessageQueue mq : mqSet) &#123; if (!this.processQueueTable.containsKey(mq)) &#123; if (isOrder &amp;&amp; !this.lock(mq)) &#123; continue; &#125; this.removeDirtyOffset(mq); ProcessQueue pq = new ProcessQueue(); long nextOffset = this.computePullFromWhere(mq); if (nextOffset &gt;= 0) &#123; ProcessQueue pre = this.processQueueTable.putIfAbsent(mq, pq); if (pre != null) &#123; &#125; else &#123; PullRequest pullRequest = new PullRequest(); pullRequest.setConsumerGroup(consumerGroup); pullRequest.setNextOffset(nextOffset); pullRequest.setMessageQueue(mq); pullRequest.setProcessQueue(pq); pullRequestList.add(pullRequest); changed = true; &#125; &#125; &#125; &#125; this.dispatchPullRequest(pullRequestList); return changed; &#125;&#125;public class RebalancePushImpl extends RebalanceImpl &#123; public void dispatchPullRequest(List&lt;PullRequest&gt; pullRequestList) &#123; for (PullRequest pullRequest : pullRequestList) &#123; this.defaultMQPushConsumerImpl.executePullRequestImmediately(pullRequest); &#125; &#125;&#125;public class DefaultMQPushConsumerImpl implements MQConsumerInner &#123; public void executePullRequestImmediately(final PullRequest pullRequest) &#123; this.mQClientFactory.getPullMessageService().executePullRequestImmediately(pullRequest); &#125;&#125; PullMessageService 线程的 run 方法中消费 PullRequest 请求,最终调用 DefaultMQPushConsumerImpl 的 pullMessage 方法,首先会对消息进行流量和消息大小限流,若不满足限流条线丢到线程池中延迟处理,定义了一个拉取消息的回调函数PullCallback ,若拉取消息失败则调用 onException 将其丢到线程池中延迟处理下次继续重试处理,若成功则调用 onSuccess 方法,在该方法中若拉取到数据后会调用 executePullRequestLater 或 executePullRequestImmediately 方法再次将拉取请求放入任务队列中,若有数据则会一直拉取直到数据被消费完则 PullStatus 会变为非 FOUND 状态.不论获取消息成功还是失败都会将请求再次放回队列,便于长轮训的方式拉取消息. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157public class PullMessageService extends ServiceThread &#123; public void run() &#123; while (!this.isStopped()) &#123; try &#123; //拉取消息的请求队列 PullRequest pullRequest = this.pullRequestQueue.take(); this.pullMessage(pullRequest); //处理请求 &#125; &#125; &#125; private void pullMessage(final PullRequest pullRequest) &#123; final MQConsumerInner consumer = this.mQClientFactory.selectConsumer(pullRequest.getConsumerGroup()); if (consumer != null) &#123; DefaultMQPushConsumerImpl impl = (DefaultMQPushConsumerImpl) consumer; impl.pullMessage(pullRequest); // 推模式的消费者最终还是会使用拉消息的方式 &#125; &#125;&#125;public class DefaultMQPushConsumerImpl implements MQConsumerInner &#123; public void pullMessage(final PullRequest pullRequest) &#123; // 拉取消息的核心流程 final ProcessQueue processQueue = pullRequest.getProcessQueue(); //获取要处理的消息：ProcessQueue if (processQueue.isDropped()) &#123; //如果队列被抛弃,直接返回 return; &#125; pullRequest.getProcessQueue().setLastPullTimestamp(System.currentTimeMillis()); //先更新时间戳 try &#123; this.makeSureStateOK(); &#125; catch (MQClientException e) &#123; this.executePullRequestLater(pullRequest, pullTimeDelayMillsWhenException); return; &#125; if (this.isPause()) &#123; //如果处理队列被挂起,延迟1S后再执行. this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_SUSPEND); return; &#125; long cachedMessageCount = processQueue.getMsgCount().get(); //获得最大待处理消息数量 long cachedMessageSizeInMiB = processQueue.getMsgSize().get() / (1024 * 1024); //获得最大待处理消息大小 if (cachedMessageCount &gt; this.defaultMQPushConsumer.getPullThresholdForQueue()) &#123; //从数量进行流控 this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL); return; &#125; if (cachedMessageSizeInMiB &gt; this.defaultMQPushConsumer.getPullThresholdSizeForQueue()) &#123; //从消息大小进行流控 this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL); return; &#125; if (!this.consumeOrderly) &#123; // 若是有序消息 if (processQueue.getMaxSpan() &gt; this.defaultMQPushConsumer.getConsumeConcurrentlyMaxSpan()) &#123; this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL); return; &#125; &#125; else &#123; if (processQueue.isLocked()) &#123; if (!pullRequest.isLockedFirst()) &#123; final long offset = this.rebalanceImpl.computePullFromWhere(pullRequest.getMessageQueue()); boolean brokerBusy = offset &lt; pullRequest.getNextOffset(); pullRequest.setLockedFirst(true); pullRequest.setNextOffset(offset); &#125; &#125; else &#123; this.executePullRequestLater(pullRequest, pullTimeDelayMillsWhenException); return; &#125; &#125; // 获取订阅信息 final SubscriptionData subscriptionData = this.rebalanceImpl.getSubscriptionInner().get(pullRequest.getMessageQueue().getTopic()); if (null == subscriptionData) &#123; this.executePullRequestLater(pullRequest, pullTimeDelayMillsWhenException); return; &#125; final long beginTimestamp = System.currentTimeMillis(); PullCallback pullCallback = new PullCallback() &#123; // 客户端默认的拉取的回调函数,在拉取到消息后会进入这个方法处理. @Override public void onSuccess(PullResult pullResult) &#123; if (pullResult != null) &#123; pullResult = DefaultMQPushConsumerImpl.this.pullAPIWrapper.processPullResult(pullRequest.getMessageQueue(), pullResult, subscriptionData); switch (pullResult.getPullStatus()) &#123; case FOUND: long prevRequestOffset = pullRequest.getNextOffset(); pullRequest.setNextOffset(pullResult.getNextBeginOffset()); long pullRT = System.currentTimeMillis() - beginTimestamp; DefaultMQPushConsumerImpl.this.getConsumerStatsManager().incPullRT(pullRequest.getConsumerGroup(), pullRequest.getMessageQueue().getTopic(), pullRT); long firstMsgOffset = Long.MAX_VALUE; if (pullResult.getMsgFoundList() == null || pullResult.getMsgFoundList().isEmpty()) &#123; DefaultMQPushConsumerImpl.this.executePullRequestImmediately(pullRequest); &#125; else &#123; firstMsgOffset = pullResult.getMsgFoundList().get(0).getQueueOffset(); DefaultMQPushConsumerImpl.this.getConsumerStatsManager().incPullTPS(pullRequest.getConsumerGroup(), pullRequest.getMessageQueue().getTopic(), pullResult.getMsgFoundList().size()); boolean dispatchToConsume = processQueue.putMessage(pullResult.getMsgFoundList()); // 消费者消息服务处理消费到的消息 DefaultMQPushConsumerImpl.this.consumeMessageService.submitConsumeRequest(pullResult.getMsgFoundList(), processQueue, pullRequest.getMessageQueue(), dispatchToConsume); if (DefaultMQPushConsumerImpl.this.defaultMQPushConsumer.getPullInterval() &gt; 0) &#123; // 退模式下任务间隔时间 DefaultMQPushConsumerImpl.this.executePullRequestLater(pullRequest, DefaultMQPushConsumerImpl.this.defaultMQPushConsumer.getPullInterval()); &#125; else &#123; DefaultMQPushConsumerImpl.this.executePullRequestImmediately(pullRequest); &#125; &#125; break; case NO_NEW_MSG: pullRequest.setNextOffset(pullResult.getNextBeginOffset()); DefaultMQPushConsumerImpl.this.correctTagsOffset(pullRequest); DefaultMQPushConsumerImpl.this.executePullRequestImmediately(pullRequest); break; case NO_MATCHED_MSG: pullRequest.setNextOffset(pullResult.getNextBeginOffset()); DefaultMQPushConsumerImpl.this.correctTagsOffset(pullRequest); DefaultMQPushConsumerImpl.this.executePullRequestImmediately(pullRequest); break; case OFFSET_ILLEGAL: pullRequest.setNextOffset(pullResult.getNextBeginOffset()); pullRequest.getProcessQueue().setDropped(true); DefaultMQPushConsumerImpl.this.executeTaskLater(new Runnable() &#123; @Override public void run() &#123; try &#123; DefaultMQPushConsumerImpl.this.offsetStore.updateOffset(pullRequest.getMessageQueue(), pullRequest.getNextOffset(), false); DefaultMQPushConsumerImpl.this.offsetStore.persist(pullRequest.getMessageQueue()); DefaultMQPushConsumerImpl.this.rebalanceImpl.removeProcessQueue(pullRequest.getMessageQueue()); &#125; &#125; &#125;, 10000); break; default: break; &#125; &#125; &#125; @Override public void onException(Throwable e) &#123; DefaultMQPushConsumerImpl.this.executePullRequestLater(pullRequest, pullTimeDelayMillsWhenException); &#125; &#125;; boolean commitOffsetEnable = false; long commitOffsetValue = 0L; if (MessageModel.CLUSTERING == this.defaultMQPushConsumer.getMessageModel()) &#123; commitOffsetValue = this.offsetStore.readOffset(pullRequest.getMessageQueue(), ReadOffsetType.READ_FROM_MEMORY); if (commitOffsetValue &gt; 0) &#123; commitOffsetEnable = true; &#125; &#125; String subExpression = null; boolean classFilter = false; SubscriptionData sd = this.rebalanceImpl.getSubscriptionInner().get(pullRequest.getMessageQueue().getTopic()); if (sd != null) &#123; if (this.defaultMQPushConsumer.isPostSubscriptionWhenPull() &amp;&amp; !sd.isClassFilterMode()) &#123; subExpression = sd.getSubString(); &#125; classFilter = sd.isClassFilterMode(); &#125; int sysFlag = PullSysFlag.buildSysFlag(commitOffsetEnable, true, subExpression != null, classFilter); try &#123;// 客户端实际与服务器交互,拉取消息的地方,拉取成功后回调PullCallback this.pullAPIWrapper.pullKernelImpl(pullRequest.getMessageQueue(), subExpression, subscriptionData.getExpressionType(), subscriptionData.getSubVersion(), pullRequest.getNextOffset(), this.defaultMQPushConsumer.getPullBatchSize(), sysFlag, commitOffsetValue, BROKER_SUSPEND_MAX_TIME_MILLIS, CONSUMER_TIMEOUT_MILLIS_WHEN_SUSPEND, CommunicationMode.ASYNC, pullCallback); &#125; catch (Exception e) &#123; this.executePullRequestLater(pullRequest, pullTimeDelayMillsWhenException); &#125; &#125;&#125; 在拉取消息成功 PullCallback回调方法中,普通消息和顺序消息分别调用 ConsumeMessageConcurrentlyService 和 ConsumeMessageOrderlyService 的 submitConsumeRequest 方法.最终通过 ConsumeRequest 线程来处理,在该线程中具体消费者的 consumeMessage 方法. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135public class ConsumeMessageConcurrentlyService implements ConsumeMessageService &#123; public void submitConsumeRequest(final List&lt;MessageExt&gt; msgs, final ProcessQueue processQueue, final MessageQueue messageQueue, final boolean dispatchToConsume) &#123; final int consumeBatchSize = this.defaultMQPushConsumer.getConsumeMessageBatchMaxSize(); if (msgs.size() &lt;= consumeBatchSize) &#123; //一次只拉取32条数据,不足32直接处理 ConsumeRequest consumeRequest = new ConsumeRequest(msgs, processQueue, messageQueue); try &#123; this.consumeExecutor.submit(consumeRequest); &#125; catch (RejectedExecutionException e) &#123; this.submitConsumeRequestLater(consumeRequest); &#125; &#125; else &#123;//超过32条,就进行分页处理. for (int total = 0; total &lt; msgs.size(); ) &#123; List&lt;MessageExt&gt; msgThis = new ArrayList&lt;MessageExt&gt;(consumeBatchSize); for (int i = 0; i &lt; consumeBatchSize; i++, total++) &#123; if (total &lt; msgs.size()) &#123; msgThis.add(msgs.get(total)); &#125; else &#123; break; &#125; &#125; ConsumeRequest consumeRequest = new ConsumeRequest(msgThis, processQueue, messageQueue); //消费请求处理线程 try &#123; this.consumeExecutor.submit(consumeRequest); &#125; catch (RejectedExecutionException e) &#123; for (; total &lt; msgs.size(); total++) &#123; msgThis.add(msgs.get(total)); &#125; this.submitConsumeRequestLater(consumeRequest); &#125; &#125; &#125; &#125;&#125;public class ConsumeMessageOrderlyService implements ConsumeMessageService &#123; public void submitConsumeRequest(final List&lt;MessageExt&gt; msgs, final ProcessQueue processQueue, final MessageQueue messageQueue, final boolean dispathToConsume) &#123; if (dispathToConsume) &#123; ConsumeRequest consumeRequest = new ConsumeRequest(processQueue, messageQueue); this.consumeExecutor.submit(consumeRequest); &#125; &#125;&#125;class ConsumeRequest implements Runnable &#123; public void run() &#123; if (this.processQueue.isDropped()) &#123; return; &#125; final Object objLock = messageQueueLock.fetchLockObject(this.messageQueue); synchronized (objLock) &#123;//通过加锁,将并发的消息顺序进行消费.消息处理的方式没什么特别. if (MessageModel.BROADCASTING.equals(ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.messageModel()) || (this.processQueue.isLocked() &amp;&amp; !this.processQueue.isLockExpired())) &#123; final long beginTime = System.currentTimeMillis(); for (boolean continueConsume = true; continueConsume; ) &#123; if (this.processQueue.isDropped()) &#123; break; &#125; if (MessageModel.CLUSTERING.equals(ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.messageModel()) &amp;&amp; !this.processQueue.isLocked()) &#123; ConsumeMessageOrderlyService.this.tryLockLaterAndReconsume(this.messageQueue, this.processQueue, 10); break; &#125; if (MessageModel.CLUSTERING.equals(ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.messageModel()) &amp;&amp; this.processQueue.isLockExpired()) &#123; ConsumeMessageOrderlyService.this.tryLockLaterAndReconsume(this.messageQueue, this.processQueue, 10); break; &#125; long interval = System.currentTimeMillis() - beginTime; if (interval &gt; MAX_TIME_CONSUME_CONTINUOUSLY) &#123; ConsumeMessageOrderlyService.this.submitConsumeRequestLater(processQueue, messageQueue, 10); break; &#125; final int consumeBatchSize = ConsumeMessageOrderlyService.this.defaultMQPushConsumer.getConsumeMessageBatchMaxSize(); List&lt;MessageExt&gt; msgs = this.processQueue.takeMessages(consumeBatchSize); defaultMQPushConsumerImpl.resetRetryAndNamespace(msgs, defaultMQPushConsumer.getConsumerGroup()); if (!msgs.isEmpty()) &#123; final ConsumeOrderlyContext context = new ConsumeOrderlyContext(this.messageQueue); ConsumeOrderlyStatus status = null; ConsumeMessageContext consumeMessageContext = null; if (ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.hasHook()) &#123; consumeMessageContext = new ConsumeMessageContext(); consumeMessageContext.setConsumerGroup(ConsumeMessageOrderlyService.this.defaultMQPushConsumer.getConsumerGroup()); consumeMessageContext.setNamespace(defaultMQPushConsumer.getNamespace()); consumeMessageContext.setMq(messageQueue); consumeMessageContext.setMsgList(msgs); consumeMessageContext.setSuccess(false); consumeMessageContext.setProps(new HashMap&lt;String, String&gt;()); // init the consume context type ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.executeHookBefore(consumeMessageContext); &#125; long beginTimestamp = System.currentTimeMillis(); ConsumeReturnType returnType = ConsumeReturnType.SUCCESS; boolean hasException = false; try &#123; this.processQueue.getLockConsume().lock(); status = messageListener.consumeMessage(Collections.unmodifiableList(msgs), context); // 调用消费者具体的消费方法 &#125; catch (Throwable e) &#123; hasException = true; &#125; finally &#123; this.processQueue.getLockConsume().unlock(); &#125; long consumeRT = System.currentTimeMillis() - beginTimestamp; if (null == status) &#123; if (hasException) &#123; returnType = ConsumeReturnType.EXCEPTION; &#125; else &#123; returnType = ConsumeReturnType.RETURNNULL; &#125; &#125; else if (consumeRT &gt;= defaultMQPushConsumer.getConsumeTimeout() * 60 * 1000) &#123; returnType = ConsumeReturnType.TIME_OUT; &#125; else if (ConsumeOrderlyStatus.SUSPEND_CURRENT_QUEUE_A_MOMENT == status) &#123; returnType = ConsumeReturnType.FAILED; &#125; else if (ConsumeOrderlyStatus.SUCCESS == status) &#123; returnType = ConsumeReturnType.SUCCESS; &#125; if (ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.hasHook()) &#123; consumeMessageContext.getProps().put(MixAll.CONSUME_CONTEXT_TYPE, returnType.name()); &#125; if (null == status) &#123; status = ConsumeOrderlyStatus.SUSPEND_CURRENT_QUEUE_A_MOMENT; &#125; if (ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.hasHook()) &#123; consumeMessageContext.setStatus(status.toString()); consumeMessageContext.setSuccess(ConsumeOrderlyStatus.SUCCESS == status || ConsumeOrderlyStatus.COMMIT == status); ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.executeHookAfter(consumeMessageContext); &#125; ConsumeMessageOrderlyService.this.getConsumerStatsManager().incConsumeRT(ConsumeMessageOrderlyService.this.consumerGroup, messageQueue.getTopic(), consumeRT); continueConsume = ConsumeMessageOrderlyService.this.processConsumeResult(msgs, status, context, this); &#125; else &#123; continueConsume = false; &#125; &#125; &#125; else &#123; if (this.processQueue.isDropped()) &#123; return; &#125; ConsumeMessageOrderlyService.this.tryLockLaterAndReconsume(this.messageQueue, this.processQueue, 100); &#125; &#125; &#125;&#125; 消息的拉取最终调用的是 PullAPIWrapper 的 pullKernelImpl 方法,拉取模式固定为 ASYNC ,最终调用 MQClientAPIImpl 的 pullMessageAsync 方法想 Broker 发送 RequestCode.PULL_MESSAGE 命令拉取消息,在 operationComplete 方法中完成 PullCallback回调. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788public class PullAPIWrapper &#123; public PullResult pullKernelImpl(final MessageQueue mq, final String subExpression, final String expressionType, final long subVersion, final long offset, final int maxNums, final int sysFlag, final long commitOffset, final long brokerSuspendMaxTimeMillis, final long timeoutMillis, final CommunicationMode communicationMode, final PullCallback pullCallback) throws MQClientException, RemotingException, MQBrokerException, InterruptedException &#123; //找到Broker FindBrokerResult findBrokerResult = this.mQClientFactory.findBrokerAddressInSubscribe(mq.getBrokerName(), this.recalculatePullFromWhichNode(mq), false); if (null == findBrokerResult) &#123; this.mQClientFactory.updateTopicRouteInfoFromNameServer(mq.getTopic()); findBrokerResult = this.mQClientFactory.findBrokerAddressInSubscribe(mq.getBrokerName(), this.recalculatePullFromWhichNode(mq), false); &#125; if (findBrokerResult != null) &#123; &#123;// check version 版本检查 if (!ExpressionType.isTagType(expressionType) &amp;&amp; findBrokerResult.getBrokerVersion() &lt; MQVersion.Version.V4_1_0_SNAPSHOT.ordinal()) &#123; throw new MQClientException(&quot;The broker[&quot; + mq.getBrokerName() + &quot;, &quot; + findBrokerResult.getBrokerVersion() + &quot;] does not upgrade to support for filter message by &quot; + expressionType, null); &#125; &#125; int sysFlagInner = sysFlag; if (findBrokerResult.isSlave()) &#123; sysFlagInner = PullSysFlag.clearCommitOffsetFlag(sysFlagInner); &#125; //构建请求 PullMessageRequestHeader requestHeader = new PullMessageRequestHeader(); requestHeader.setConsumerGroup(this.consumerGroup); requestHeader.setTopic(mq.getTopic()); requestHeader.setQueueId(mq.getQueueId()); requestHeader.setQueueOffset(offset); requestHeader.setMaxMsgNums(maxNums); requestHeader.setSysFlag(sysFlagInner); requestHeader.setCommitOffset(commitOffset); requestHeader.setSuspendTimeoutMillis(brokerSuspendMaxTimeMillis); requestHeader.setSubscription(subExpression); requestHeader.setSubVersion(subVersion); requestHeader.setExpressionType(expressionType); String brokerAddr = findBrokerResult.getBrokerAddr(); if (PullSysFlag.hasClassFilterFlag(sysFlagInner)) &#123; brokerAddr = computPullFromWhichFilterServer(mq.getTopic(), brokerAddr); &#125; //拉取消息 PullResult pullResult = this.mQClientFactory.getMQClientAPIImpl().pullMessage(brokerAddr, requestHeader, timeoutMillis, communicationMode, pullCallback); return pullResult; &#125; throw new MQClientException(&quot;The broker[&quot; + mq.getBrokerName() + &quot;] not exist&quot;, null); &#125;&#125;public class MQClientAPIImpl &#123; public PullResult pullMessage(final String addr, final PullMessageRequestHeader requestHeader, final long timeoutMillis, final CommunicationMode communicationMode, final PullCallback pullCallback) throws RemotingException, MQBrokerException, InterruptedException &#123; RemotingCommand request = RemotingCommand.createRequestCommand(RequestCode.PULL_MESSAGE, requestHeader); //几种拉取方式 switch (communicationMode) &#123; case ONEWAY: assert false; return null; case ASYNC: this.pullMessageAsync(addr, request, timeoutMillis, pullCallback); return null; case SYNC: return this.pullMessageSync(addr, request, timeoutMillis); default: assert false; break; &#125; return null; &#125; private void pullMessageAsync(final String addr, final RemotingCommand request, final long timeoutMillis, final PullCallback pullCallback) throws RemotingException, InterruptedException &#123; this.remotingClient.invokeAsync(addr, request, timeoutMillis, new InvokeCallback() &#123; //异步拉取 @Override public void operationComplete(ResponseFuture responseFuture) &#123; RemotingCommand response = responseFuture.getResponseCommand(); //处理拉取消息的结果 if (response != null) &#123; //有响应 try &#123; PullResult pullResult = MQClientAPIImpl.this.processPullResponse(response); assert pullResult != null; pullCallback.onSuccess(pullResult); &#125; catch (Exception e) &#123; pullCallback.onException(e); &#125; &#125; else &#123;//没响应 if (!responseFuture.isSendRequestOK()) &#123; pullCallback.onException(new MQClientException(&quot;send request failed to &quot; + addr + &quot;. Request: &quot; + request, responseFuture.getCause())); &#125; else if (responseFuture.isTimeout()) &#123; pullCallback.onException(new MQClientException(&quot;wait response from &quot; + addr + &quot; timeout :&quot; + responseFuture.getTimeoutMillis() + &quot;ms&quot; + &quot;. Request: &quot; + request, responseFuture.getCause())); &#125; else &#123; pullCallback.onException(new MQClientException(&quot;unknown reason. addr: &quot; + addr + &quot;, timeoutMillis: &quot; + timeoutMillis + &quot;. Request: &quot; + request, responseFuture.getCause())); &#125; &#125; &#125; &#125;); &#125;&#125; 在Broker通过 PullMessageProcessor 方法的 processRequest 方法处理 RequestCode.PULL_MESSAGE 请求.首先端构建消息过滤器,然后在 DefaultMessageStore 的 getMessage 查询消息中调用 MessageFilter 的 isMatchedByConsumeQueue 方法.若 ResponseCode.PULL_NOT_FOUND 未拉取到数据,则再创建一个拉取请求且通过 PullRequestHoldService 的 suspendPullRequest 将该请求放入 ManyPullRequest 请求拉取队列,从而实现长连接. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109private RemotingCommand processRequest(final Channel channel, RemotingCommand request, boolean brokerAllowSuspend) throws RemotingCommandException &#123; RemotingCommand response = RemotingCommand.createResponseCommand(PullMessageResponseHeader.class); final PullMessageResponseHeader responseHeader = (PullMessageResponseHeader) response.readCustomHeader(); final PullMessageRequestHeader requestHeader = (PullMessageRequestHeader) request.decodeCommandCustomHeader(PullMessageRequestHeader.class); response.setOpaque(request.getOpaque()); SubscriptionGroupConfig subscriptionGroupConfig = this.brokerController.getSubscriptionGroupManager().findSubscriptionGroupConfig(requestHeader.getConsumerGroup()); final boolean hasSuspendFlag = PullSysFlag.hasSuspendFlag(requestHeader.getSysFlag()); final boolean hasCommitOffsetFlag = PullSysFlag.hasCommitOffsetFlag(requestHeader.getSysFlag()); final boolean hasSubscriptionFlag = PullSysFlag.hasSubscriptionFlag(requestHeader.getSysFlag()); final long suspendTimeoutMillisLong = hasSuspendFlag ? requestHeader.getSuspendTimeoutMillis() : 0; TopicConfig topicConfig = this.brokerController.getTopicConfigManager().selectTopicConfig(requestHeader.getTopic()); SubscriptionData subscriptionData = null; ConsumerFilterData consumerFilterData = null; if (hasSubscriptionFlag) &#123; try &#123; subscriptionData = FilterAPI.build(requestHeader.getTopic(), requestHeader.getSubscription(), requestHeader.getExpressionType()); if (!ExpressionType.isTagType(subscriptionData.getExpressionType())) &#123; consumerFilterData = ConsumerFilterManager.build(requestHeader.getTopic(), requestHeader.getConsumerGroup(), requestHeader.getSubscription(), requestHeader.getExpressionType(), requestHeader.getSubVersion()); assert consumerFilterData != null; &#125; &#125; &#125; else &#123; ConsumerGroupInfo consumerGroupInfo = this.brokerController.getConsumerManager().getConsumerGroupInfo(requestHeader.getConsumerGroup()); subscriptionData = consumerGroupInfo.findSubscriptionData(requestHeader.getTopic()); if (!ExpressionType.isTagType(subscriptionData.getExpressionType())) &#123; consumerFilterData = this.brokerController.getConsumerFilterManager().get(requestHeader.getTopic(), requestHeader.getConsumerGroup()); &#125; &#125; //在Broker端构建消息过滤器 MessageFilter messageFilter; if (this.brokerController.getBrokerConfig().isFilterSupportRetry()) &#123; messageFilter = new ExpressionForRetryMessageFilter(subscriptionData, consumerFilterData, this.brokerController.getConsumerFilterManager()); &#125; else &#123; messageFilter = new ExpressionMessageFilter(subscriptionData, consumerFilterData, this.brokerController.getConsumerFilterManager()); &#125; // 获取消息 final GetMessageResult getMessageResult = this.brokerController.getMessageStore().getMessage(requestHeader.getConsumerGroup(), requestHeader.getTopic(), requestHeader.getQueueId(), requestHeader.getQueueOffset(), requestHeader.getMaxMsgNums(), messageFilter); if (getMessageResult != null) &#123; response.setRemark(getMessageResult.getStatus().name()); responseHeader.setNextBeginOffset(getMessageResult.getNextBeginOffset()); responseHeader.setMinOffset(getMessageResult.getMinOffset()); responseHeader.setMaxOffset(getMessageResult.getMaxOffset()); if (getMessageResult.isSuggestPullingFromSlave()) &#123; responseHeader.setSuggestWhichBrokerId(subscriptionGroupConfig.getWhichBrokerWhenConsumeSlowly()); &#125; else &#123; responseHeader.setSuggestWhichBrokerId(MixAll.MASTER_ID); &#125; //消息拉取结果 switch (getMessageResult.getStatus()) &#123; case FOUND: response.setCode(ResponseCode.SUCCESS); break; case MESSAGE_WAS_REMOVING: response.setCode(ResponseCode.PULL_RETRY_IMMEDIATELY); break; case NO_MATCHED_LOGIC_QUEUE: case NO_MESSAGE_IN_QUEUE: break; case NO_MATCHED_MESSAGE: response.setCode(ResponseCode.PULL_RETRY_IMMEDIATELY); break; case OFFSET_FOUND_NULL: response.setCode(ResponseCode.PULL_NOT_FOUND); break; case OFFSET_OVERFLOW_BADLY: response.setCode(ResponseCode.PULL_OFFSET_MOVED); break; case OFFSET_OVERFLOW_ONE: response.setCode(ResponseCode.PULL_NOT_FOUND); break; case OFFSET_TOO_SMALL: response.setCode(ResponseCode.PULL_OFFSET_MOVED); break; default: assert false; break; &#125; switch (response.getCode()) &#123; case ResponseCode.SUCCESS: this.brokerController.getBrokerStatsManager().incGroupGetNums(requestHeader.getConsumerGroup(), requestHeader.getTopic(), getMessageResult.getMessageCount()); this.brokerController.getBrokerStatsManager().incGroupGetSize(requestHeader.getConsumerGroup(), requestHeader.getTopic(), getMessageResult.getBufferTotalSize()); this.brokerController.getBrokerStatsManager().incBrokerGetNums(getMessageResult.getMessageCount()); break; case ResponseCode.PULL_NOT_FOUND: if (brokerAllowSuspend &amp;&amp; hasSuspendFlag) &#123; long pollingTimeMills = suspendTimeoutMillisLong; if (!this.brokerController.getBrokerConfig().isLongPollingEnable()) &#123;// 消息长轮询 pollingTimeMills = this.brokerController.getBrokerConfig().getShortPollingTimeMills(); &#125; String topic = requestHeader.getTopic(); long offset = requestHeader.getQueueOffset(); int queueId = requestHeader.getQueueId(); //没有拉取到消息,就再创建一个拉取请求 PullRequest pullRequest = new PullRequest(request, channel, pollingTimeMills, this.brokerController.getMessageStore().now(), offset, subscriptionData, messageFilter); //将请求放入ManyRequestPull请求队列,为了配合长连接处理 this.brokerController.getPullRequestHoldService().suspendPullRequest(topic, queueId, pullRequest); response = null; break; &#125; &#125; &#125; boolean storeOffsetEnable = brokerAllowSuspend; storeOffsetEnable = storeOffsetEnable &amp;&amp; hasCommitOffsetFlag; storeOffsetEnable = storeOffsetEnable &amp;&amp; this.brokerController.getMessageStoreConfig().getBrokerRole() != BrokerRole.SLAVE; if (storeOffsetEnable) &#123; this.brokerController.getConsumerOffsetManager().commitOffset(RemotingHelper.parseChannelRemoteAddr(channel), requestHeader.getConsumerGroup(), requestHeader.getTopic(), requestHeader.getQueueId(), requestHeader.getCommitOffset()); &#125; return response;&#125; 长轮询对于消息的发送基本能达到实时的效果,是通过 PullRequestHoldService 类中长轮训来实现的,该类是一个线程类,在 Broker 中的 BrokerController 中被实例化和启动.客户端拉取数时未拉取到数据就会将请求通过 suspendPullRequest 方法放入 pullRequestTable 中.在run方法中一直循环若没有消息就 waitForRunning 方法等待 5s ,若有数据则会被提前唤醒.然后通过 checkHoldRequest 方法检查请求对象,若有数据则将数据返回给客户端. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117public class PullRequestHoldService extends ServiceThread &#123; private ConcurrentMap&lt;String, ManyPullRequest&gt; pullRequestTable = new ConcurrentHashMap&lt;String, ManyPullRequest&gt;(1024); public void suspendPullRequest(final String topic, final int queueId, final PullRequest pullRequest) &#123; String key = this.buildKey(topic, queueId); ManyPullRequest mpr = this.pullRequestTable.get(key); if (null == mpr) &#123; mpr = new ManyPullRequest(); ManyPullRequest prev = this.pullRequestTable.putIfAbsent(key, mpr); if (prev != null) &#123; mpr = prev; &#125; &#125; mpr.addPullRequest(pullRequest); &#125; public void run() &#123; // 处理ManyPullRequest线程 while (!this.isStopped()) &#123; try &#123;// 如果开启了长轮询,等待5秒后再去查 if (this.brokerController.getBrokerConfig().isLongPollingEnable()) &#123; this.waitForRunning(5 * 1000); &#125; else &#123;//没有开启长轮询,等待1秒后再去查. this.waitForRunning(this.brokerController.getBrokerConfig().getShortPollingTimeMills()); &#125; long beginLockTimestamp = this.systemClock.now(); this.checkHoldRequest(); //检查请求对象 long costTime = this.systemClock.now() - beginLockTimestamp; &#125; catch (Throwable e) &#123; &#125; &#125; &#125; private void checkHoldRequest() &#123; for (String key : this.pullRequestTable.keySet()) &#123; String[] kArray = key.split(TOPIC_QUEUEID_SEPARATOR); if (2 == kArray.length) &#123; String topic = kArray[0]; int queueId = Integer.parseInt(kArray[1]); //从CommitLog中检查是否有新的消息. final long offset = this.brokerController.getMessageStore().getMaxOffsetInQueue(topic, queueId); try &#123;//通知消息到达 this.notifyMessageArriving(topic, queueId, offset); &#125; catch (Throwable e) &#123; &#125; &#125; &#125; &#125; public void notifyMessageArriving(final String topic, final int queueId, final long maxOffset) &#123; notifyMessageArriving(topic, queueId, maxOffset, null, 0, null, null); &#125; public void notifyMessageArriving(final String topic, final int queueId, final long maxOffset, final Long tagsCode, long msgStoreTime, byte[] filterBitMap, Map&lt;String, String&gt; properties) &#123; String key = this.buildKey(topic, queueId); //CommitLog消息到达通知 ManyPullRequest mpr = this.pullRequestTable.get(key); if (mpr != null) &#123; List&lt;PullRequest&gt; requestList = mpr.cloneListAndClear(); if (requestList != null) &#123; List&lt;PullRequest&gt; replayList = new ArrayList&lt;PullRequest&gt;(); for (PullRequest request : requestList) &#123; long newestOffset = maxOffset; if (newestOffset &lt;= request.getPullFromThisOffset()) &#123; newestOffset = this.brokerController.getMessageStore().getMaxOffsetInQueue(topic, queueId); &#125; if (newestOffset &gt; request.getPullFromThisOffset()) &#123; //判断是否有新的消息 //检查新的消息是否是ConsumeQueue感兴趣的消息 boolean match = request.getMessageFilter().isMatchedByConsumeQueue(tagsCode, new ConsumeQueueExt.CqExtUnit(tagsCode, msgStoreTime, filterBitMap)); if (match &amp;&amp; properties != null) &#123; match = request.getMessageFilter().isMatchedByCommitLog(null, properties); &#125; if (match) &#123; //如果是感兴趣的消息,就等待线程唤醒后执行消息推送. try &#123; this.brokerController.getPullMessageProcessor().executeRequestWhenWakeup(request.getClientChannel(), request.getRequestCommand()); &#125; catch (Throwable e) &#123; &#125; continue; &#125; &#125; if (System.currentTimeMillis() &gt;= (request.getSuspendTimestamp() + request.getTimeoutMillis())) &#123; try &#123; //请求超时后也给客户端响应. this.brokerController.getPullMessageProcessor().executeRequestWhenWakeup(request.getClientChannel(), request.getRequestCommand()); &#125; catch (Throwable e) &#123; &#125; continue; &#125; replayList.add(request); &#125; if (!replayList.isEmpty()) &#123; mpr.addPullRequest(replayList); &#125; &#125; &#125; &#125;&#125;public class PullMessageProcessor extends AsyncNettyRequestProcessor implements NettyRequestProcessor &#123; public void executeRequestWhenWakeup(final Channel channel, final RemotingCommand request) throws RemotingCommandException &#123; Runnable run = new Runnable() &#123; @Override public void run() &#123; try &#123; final RemotingCommand response = PullMessageProcessor.this.processRequest(channel, request, false); if (response != null) &#123; response.setOpaque(request.getOpaque()); response.markResponseType(); try &#123; channel.writeAndFlush(response).addListener(new ChannelFutureListener() &#123; @Override public void operationComplete(ChannelFuture future) throws Exception &#123; if (!future.isSuccess()) &#123; &#125; &#125; &#125;); &#125; catch (Throwable e) &#123; &#125; &#125; &#125; catch (RemotingCommandException e1) &#123; &#125; &#125; &#125;; this.brokerController.getPullMessageExecutor().submit(new RequestTask(run, channel, request)); &#125;&#125; 还有一种方式在 DefaultMessageStore 的 ReputMessageService 线程类的 run 方法中执行分发请求时,执行完分发请求后通过调用 NotifyMessageArrivingListener 的 arriving 方法从而调用 PullRequestHoldService 的 notifyMessageArriving 方法进行一起请求线程的检查从而通知到客户端. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667class ReputMessageService extends ServiceThread &#123; @Override public void run() &#123; while (!this.isStopped()) &#123; try &#123; // 每隔1毫秒,往ConsumeQueue和IndexFile中转发一次CommitLog写入的消息 Thread.sleep(1); this.doReput(); &#125; catch (Exception e) &#123; &#125; &#125; &#125; private void doReput() &#123; if (this.reputFromOffset &lt; DefaultMessageStore.this.commitLog.getMinOffset()) &#123; log.warn(&quot;The reputFromOffset=&#123;&#125; is smaller than minPyOffset=&#123;&#125;, this usually indicate that the dispatch behind too much and the commitlog has expired.&quot;, this.reputFromOffset, DefaultMessageStore.this.commitLog.getMinOffset()); this.reputFromOffset = DefaultMessageStore.this.commitLog.getMinOffset(); &#125; for (boolean doNext = true; this.isCommitLogAvailable() &amp;&amp; doNext; ) &#123; if (DefaultMessageStore.this.getMessageStoreConfig().isDuplicationEnable() &amp;&amp; this.reputFromOffset &gt;= DefaultMessageStore.this.getConfirmOffset()) &#123; break; &#125; SelectMappedBufferResult result = DefaultMessageStore.this.commitLog.getData(reputFromOffset); // 获取CommitLog中的消息 if (result != null) &#123; try &#123; this.reputFromOffset = result.getStartOffset(); for (int readSize = 0; readSize &lt; result.getSize() &amp;&amp; doNext; ) &#123; //从CommitLog中获取一个DispatchRequest,拿到一份需要进行转发的消息,也就是从commitlog中读取的. DispatchRequest dispatchRequest = DefaultMessageStore.this.commitLog.checkMessageAndReturnSize(result.getByteBuffer(), false, false); int size = dispatchRequest.getBufferSize() == -1 ? dispatchRequest.getMsgSize() : dispatchRequest.getBufferSize(); if (dispatchRequest.isSuccess()) &#123; if (size &gt; 0) &#123; DefaultMessageStore.this.doDispatch(dispatchRequest); //分发CommitLog写入消息 // 长轮询： 如果有消息到了主节点,并且开启了长轮询. if (BrokerRole.SLAVE != DefaultMessageStore.this.getMessageStoreConfig().getBrokerRole() &amp;&amp; DefaultMessageStore.this.brokerConfig.isLongPollingEnable()) &#123; //唤醒NotifyMessageArrivingListener的arriving方法,进行一次请求线程的检查 DefaultMessageStore.this.messageArrivingListener.arriving(dispatchRequest.getTopic(), dispatchRequest.getQueueId(), dispatchRequest.getConsumeQueueOffset() + 1, dispatchRequest.getTagsCode(), dispatchRequest.getStoreTimestamp(), dispatchRequest.getBitMap(), dispatchRequest.getPropertiesMap()); &#125; this.reputFromOffset += size; readSize += size; if (DefaultMessageStore.this.getMessageStoreConfig().getBrokerRole() == BrokerRole.SLAVE) &#123; // 从节点 DefaultMessageStore.this.storeStatsService.getSinglePutMessageTopicTimesTotal(dispatchRequest.getTopic()).incrementAndGet(); DefaultMessageStore.this.storeStatsService.getSinglePutMessageTopicSizeTotal(dispatchRequest.getTopic()).addAndGet(dispatchRequest.getMsgSize()); &#125; &#125; else if (size == 0) &#123; this.reputFromOffset = DefaultMessageStore.this.commitLog.rollNextFile(this.reputFromOffset); readSize = result.getSize(); &#125; &#125; else if (!dispatchRequest.isSuccess()) &#123; if (size &gt; 0) &#123; this.reputFromOffset += size; &#125; else &#123; doNext = false; if (DefaultMessageStore.this.getMessageStoreConfig().isEnableDLegerCommitLog() || DefaultMessageStore.this.brokerConfig.getBrokerId() == MixAll.MASTER_ID) &#123; this.reputFromOffset += result.getSize() - readSize; &#125; &#125; &#125; &#125; &#125; finally &#123; result.release(); &#125; &#125; else &#123; doNext = false; &#125; &#125; &#125;&#125; 集群模式下消费者策略Consumer也是以 MessageQueue 为单位来进行负载均衡,分为集群模式和广播模式.广播模式下每条消息都会投递给订阅了Topic的所有消费者实例,在Consumer分配Queue时,所有Consumer都分到所有的Queue.集群消费模式每条消息只需要投递到订阅该Topic的Consumer Group下的一个实例,RocketMQ采用主动拉取方式拉取并消费消息,在拉取时需明确指定拉取哪一条MessageQueue . 每当实例的数量有变更,都会触发一次所有实例的负载均衡,这时会按照 Queue的数量和实例的数量平均分配Queue给每个实例.每次分配时都会将 MessageQueue 和消费者ID进行排序,再用不同的分配算法进行分配.内置的分配的算法共有六种,分别对应 AllocateMessageQueueStrategy下的六种实现类,可在Consumer中直接指定.默认情况下使用的是最简单的平均分配策略. AllocateMachineRoomNearby ：将同机房的Consumer和Broker优先分配在一起.该策略可通过一个 machineRoomResolver 对象来定制Consumer和Broker的机房解析规则.还需要引入另外一个分配策略来对同机房的Broker和Consumer进行分配.一般用平均分配策略或轮询分配策略. AllocateMessageQueueAveragely ：平均分配,将所有MessageQueue平均分给每一个消费者 AllocateMessageQueueAveragelyByCircle ： 轮询分配,轮流的给一个消费者分配一个MessageQueue. AllocateMessageQueueByConfig ： 直接指定一个messageQueue列表,类似于广播模式,直接指定所有队列. AllocateMessageQueueByMachineRoom ：按逻辑机房的概念进行分配.对BrokerName和ConsumerIdc有定制化的配置. AllocateMessageQueueConsistentHash ：一致性哈希策略只需要指定一个虚拟节点数,用一个哈希环算法,虚拟节点是为了让Hash数据在环上分布更为均匀. 对于消费者策略可以通过 DefaultMQPushConsumer 构造方法设置,默认是使用 AllocateMessageQueueAveragely平均分配策略.且该负载均衡策略在 RebalanceImpl 的 rebalanceByTopic 方法中被调用. 123456789101112131415161718192021222324252627public class AllocateMessageQueueAveragely implements AllocateMessageQueueStrategy &#123; public List&lt;MessageQueue&gt; allocate(String consumerGroup, String currentCID, List&lt;MessageQueue&gt; mqAll, List&lt;String&gt; cidAll) &#123; if (currentCID == null || currentCID.length() &lt; 1) &#123; throw new IllegalArgumentException(&quot;currentCID is empty&quot;); &#125; if (mqAll == null || mqAll.isEmpty()) &#123; throw new IllegalArgumentException(&quot;mqAll is null or mqAll empty&quot;); &#125; if (cidAll == null || cidAll.isEmpty()) &#123; throw new IllegalArgumentException(&quot;cidAll is null or cidAll empty&quot;); &#125; List&lt;MessageQueue&gt; result = new ArrayList&lt;MessageQueue&gt;(); if (!cidAll.contains(currentCID)) &#123; log.info(&quot;[BUG] ConsumerGroup: &#123;&#125; The consumerId: &#123;&#125; not in cidAll: &#123;&#125;&quot;, consumerGroup, currentCID, cidAll); return result; &#125; int index = cidAll.indexOf(currentCID); int mod = mqAll.size() % cidAll.size(); int averageSize = mqAll.size() &lt;= cidAll.size() ? 1 : (mod &gt; 0 &amp;&amp; index &lt; mod ? mqAll.size() / cidAll.size() + 1 : mqAll.size() / cidAll.size()); int startIndex = (mod &gt; 0 &amp;&amp; index &lt; mod) ? index * averageSize : index * averageSize + mod; int range = Math.min(averageSize, mqAll.size() - startIndex); for (int i = 0; i &lt; range; i++) &#123; result.add(mqAll.get((startIndex + i) % mqAll.size())); &#125; return result; &#125;&#125; 顺序消息12345678910111213141516171819DefaultMQProducer producer = new DefaultMQProducer(&quot;please_rename_unique_group_name&quot;);producer.setNamesrvAddr(&quot;localhost:9876&quot;);producer.start();for (int i = 0; i &lt; 10; i++) &#123; int orderId = i; for (int j = 0; j &lt;= 5; j++) &#123; Message msg = new Message(&quot;OrderTopicTest&quot;, &quot;order_&quot; + orderId, &quot;KEY&quot; + orderId, (&quot;order_&quot; + orderId + &quot; step &quot; + j).getBytes(RemotingHelper.DEFAULT_CHARSET)); SendResult sendResult = producer.send(msg, new MessageQueueSelector() &#123; @Override public MessageQueue select(List&lt;MessageQueue&gt; mqs, Message msg, Object arg) &#123; Integer id = (Integer) arg; // 实际就是传入的orderId int index = id % mqs.size(); return mqs.get(index); &#125; &#125;, orderId); System.out.printf(&quot;%s%n&quot;, sendResult); &#125;&#125;producer.shutdown(); 顺序消息,对于生产者发送消息需要将消息发送到同一个 MessageQueue 中,可通过 MessageQueueSelector ,对于需要保持顺序的消息传入同一个业务参数orderId,通过orderId对消息队列的取模得到一个固定的 MessageQueue ,在发送消息时就能将数据发送到同一个消息队列中了.但不能100%保证消息的顺序,若发生宕机可能导致发送到不同的 MessageQueue 中. 12345678910111213141516171819202122232425262728293031323334353637public class DefaultMQProducer extends ClientConfig implements MQProducer &#123; public SendResult send(Message msg, MessageQueueSelector selector, Object arg) throws MQClientException, RemotingException, MQBrokerException, InterruptedException &#123; msg.setTopic(withNamespace(msg.getTopic())); return this.defaultMQProducerImpl.send(msg, selector, arg); &#125; private SendResult sendSelectImpl(Message msg, MessageQueueSelector selector, Object arg, final CommunicationMode communicationMode, final SendCallback sendCallback, final long timeout) throws MQClientException, RemotingException, MQBrokerException, InterruptedException &#123; long beginStartTime = System.currentTimeMillis(); this.makeSureStateOK(); Validators.checkMessage(msg, this.defaultMQProducer); TopicPublishInfo topicPublishInfo = this.tryToFindTopicPublishInfo(msg.getTopic()); if (topicPublishInfo != null &amp;&amp; topicPublishInfo.ok()) &#123; MessageQueue mq = null; try &#123; List&lt;MessageQueue&gt; messageQueueList = mQClientFactory.getMQAdminImpl().parsePublishMessageQueues(topicPublishInfo.getMessageQueueList()); Message userMessage = MessageAccessor.cloneMessage(msg); String userTopic = NamespaceUtil.withoutNamespace(userMessage.getTopic(), mQClientFactory.getClientConfig().getNamespace()); userMessage.setTopic(userTopic); // 这里回调上面示例中MessageQueueSelector的select方法,这里的arg就是传入的orderId mq = mQClientFactory.getClientConfig().queueWithNamespace(selector.select(messageQueueList, userMessage, arg)); &#125; catch (Throwable e) &#123; throw new MQClientException(&quot;select message queue throwed exception.&quot;, e); &#125; long costTime = System.currentTimeMillis() - beginStartTime; if (timeout &lt; costTime) &#123; throw new RemotingTooMuchRequestException(&quot;sendSelectImpl call timeout&quot;); &#125; if (mq != null) &#123; return this.sendKernelImpl(msg, mq, communicationMode, sendCallback, null, timeout - costTime); &#125; else &#123; throw new MQClientException(&quot;select message queue return null.&quot;, null); &#125; &#125; validateNameServerSetting(); throw new MQClientException(&quot;No route info for this topic, &quot; + msg.getTopic(), null); &#125;&#125; 对于每个消费端在创建 DefaultMQPushConsumer 时指定 consumerGroup ,在 DefaultMQPushConsumer 的start方法中调用 DefaultMQPushConsumerImpl 的 start 方法从而将 consumerGroup 设置到 RebalancePushImpl 中.且通过 registerMessageListener 方法设置的 MessageListenerOrderly 会被赋值给 DefaultMQPushConsumerImpl 的 messageListenerInner ,在DefaultMQPushConsumerImpl的start方法中判断messageListenerInner类型最终调用 ConsumeMessageOrderlyService 的 start 方法启动异步线程. 1234567891011121314DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;please_rename_unique_group_name_3&quot;);consumer.setNamesrvAddr(&quot;localhost:9876&quot;);consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_LAST_OFFSET);consumer.subscribe(&quot;OrderTopicTest&quot;, &quot;*&quot;);consumer.registerMessageListener(new MessageListenerOrderly() &#123; @Override public ConsumeOrderlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeOrderlyContext context) &#123; context.setAutoCommit(true); for (MessageExt msg : msgs) &#123; System.out.println(&quot;收到消息内容 &quot; + new String(msg.getBody())); &#125; return ConsumeOrderlyStatus.SUCCESS; &#125;&#125;); 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100public class DefaultMQPushConsumer extends ClientConfig implements MQPushConsumer &#123; private String consumerGroup; public DefaultMQPushConsumer(final String consumerGroup) &#123; this(null, consumerGroup, null, new AllocateMessageQueueAveragely()); &#125; public DefaultMQPushConsumer(final String namespace, final String consumerGroup, RPCHook rpcHook, AllocateMessageQueueStrategy allocateMessageQueueStrategy) &#123; this.consumerGroup = consumerGroup; this.namespace = namespace; this.allocateMessageQueueStrategy = allocateMessageQueueStrategy; defaultMQPushConsumerImpl = new DefaultMQPushConsumerImpl(this, rpcHook); &#125; public void registerMessageListener(MessageListenerOrderly messageListener) &#123; this.messageListener = messageListener; this.defaultMQPushConsumerImpl.registerMessageListener(messageListener); &#125; public void start() throws MQClientException &#123; setConsumerGroup(NamespaceUtil.wrapNamespace(this.getNamespace(), this.consumerGroup)); this.defaultMQPushConsumerImpl.start(); if (null != traceDispatcher) &#123; try &#123; traceDispatcher.start(this.getNamesrvAddr(), this.getAccessChannel()); &#125; catch (MQClientException e) &#123; &#125; &#125; &#125;&#125;public class DefaultMQPushConsumerImpl implements MQConsumerInner &#123; public void registerMessageListener(MessageListener messageListener) &#123; this.messageListenerInner = messageListener; &#125; public MessageListener getMessageListenerInner() &#123; return messageListenerInner; &#125; public synchronized void start() throws MQClientException &#123; switch (this.serviceState) &#123; case CREATE_JUST: this.serviceState = ServiceState.START_FAILED; this.checkConfig(); // 检查配置 this.copySubscription(); if (this.defaultMQPushConsumer.getMessageModel() == MessageModel.CLUSTERING) &#123; this.defaultMQPushConsumer.changeInstanceNameToPID(); &#125; //K2 客户端创建工厂,这个是核心对象 this.mQClientFactory = MQClientManager.getInstance().getOrCreateMQClientInstance(this.defaultMQPushConsumer, this.rpcHook); this.rebalanceImpl.setConsumerGroup(this.defaultMQPushConsumer.getConsumerGroup()); this.rebalanceImpl.setMessageModel(this.defaultMQPushConsumer.getMessageModel()); // 集群模式下消费者策略 this.rebalanceImpl.setAllocateMessageQueueStrategy(this.defaultMQPushConsumer.getAllocateMessageQueueStrategy()); this.rebalanceImpl.setmQClientFactory(this.mQClientFactory); this.pullAPIWrapper = new PullAPIWrapper(mQClientFactory, this.defaultMQPushConsumer.getConsumerGroup(), isUnitMode()); this.pullAPIWrapper.registerFilterMessageHook(filterMessageHookList); if (this.defaultMQPushConsumer.getOffsetStore() != null) &#123; this.offsetStore = this.defaultMQPushConsumer.getOffsetStore(); &#125; else &#123; switch (this.defaultMQPushConsumer.getMessageModel()) &#123; case BROADCASTING: this.offsetStore = new LocalFileOffsetStore(this.mQClientFactory, this.defaultMQPushConsumer.getConsumerGroup()); break; case CLUSTERING: this.offsetStore = new RemoteBrokerOffsetStore(this.mQClientFactory, this.defaultMQPushConsumer.getConsumerGroup()); break; default: break; &#125; this.defaultMQPushConsumer.setOffsetStore(this.offsetStore); &#125; this.offsetStore.load(); //根据客户端配置实例化不同的consumeMessageService if (this.getMessageListenerInner() instanceof MessageListenerOrderly) &#123; // 顺序消息 this.consumeOrderly = true; this.consumeMessageService = new ConsumeMessageOrderlyService(this, (MessageListenerOrderly) this.getMessageListenerInner()); &#125; else if (this.getMessageListenerInner() instanceof MessageListenerConcurrently) &#123; // 非顺序消息 this.consumeOrderly = false; this.consumeMessageService = new ConsumeMessageConcurrentlyService(this, (MessageListenerConcurrently) this.getMessageListenerInner()); &#125; this.consumeMessageService.start(); //注册本地的消费者组缓存. boolean registerOK = mQClientFactory.registerConsumer(this.defaultMQPushConsumer.getConsumerGroup(), this); if (!registerOK) &#123; this.serviceState = ServiceState.CREATE_JUST; this.consumeMessageService.shutdown(defaultMQPushConsumer.getAwaitTerminationMillisWhenShutdown()); throw new MQClientException(&quot;The consumer group[&quot; + this.defaultMQPushConsumer.getConsumerGroup() + &quot;] has been created before, specify another name please.&quot; + FAQUrl.suggestTodo(FAQUrl.GROUP_NAME_DUPLICATE_URL), null); &#125; mQClientFactory.start(); this.serviceState = ServiceState.RUNNING; break; case RUNNING: case START_FAILED: case SHUTDOWN_ALREADY: throw new MQClientException(&quot;The PushConsumer service state not OK, maybe started once, &quot; + this.serviceState + FAQUrl.suggestTodo(FAQUrl.CLIENT_SERVICE_NOT_OK), null); default: break; &#125; this.updateTopicSubscribeInfoWhenSubscriptionChanged(); this.mQClientFactory.checkClientInBroker(); this.mQClientFactory.sendHeartbeatToAllBrokerWithLock(); this.mQClientFactory.rebalanceImmediately(); &#125;&#125; ConsumeMessageOrderlyService 线程会每隔 20s 执行一次,最终调用 RebalancePushImpl 超类 RebalanceImpl 的 lock 方法,通过 LockBatchRequestBody 设置前面设置到 RebalancePushImpl 中的 consumerGroup ,向Broker获取队列锁,且将锁定的队列缓存到 processQueueTable 中. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203public class ConsumeMessageOrderlyService implements ConsumeMessageService &#123; public void start() &#123; if (MessageModel.CLUSTERING.equals(ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.messageModel())) &#123; this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() &#123; @Override public void run() &#123; // 每20s执行一次 ConsumeMessageOrderlyService.this.lockMQPeriodically(); &#125; &#125;, 1000 * 1, ProcessQueue.REBALANCE_LOCK_INTERVAL, TimeUnit.MILLISECONDS); &#125; &#125; public synchronized void lockMQPeriodically() &#123; if (!this.stopped) &#123; this.defaultMQPushConsumerImpl.getRebalanceImpl().lockAll(); &#125; &#125;&#125;public abstract class RebalanceImpl &#123; private boolean updateProcessQueueTableInRebalance(final String topic, final Set&lt;MessageQueue&gt; mqSet, final boolean isOrder) &#123; boolean changed = false; Iterator&lt;Entry&lt;MessageQueue, ProcessQueue&gt;&gt; it = this.processQueueTable.entrySet().iterator(); while (it.hasNext()) &#123; Entry&lt;MessageQueue, ProcessQueue&gt; next = it.next(); MessageQueue mq = next.getKey(); ProcessQueue pq = next.getValue(); if (mq.getTopic().equals(topic)) &#123; if (!mqSet.contains(mq)) &#123; pq.setDropped(true); if (this.removeUnnecessaryMessageQueue(mq, pq)) &#123; it.remove(); changed = true; &#125; &#125; else if (pq.isPullExpired()) &#123; switch (this.consumeType()) &#123; case CONSUME_ACTIVELY: break; case CONSUME_PASSIVELY: pq.setDropped(true); if (this.removeUnnecessaryMessageQueue(mq, pq)) &#123; it.remove(); changed = true; &#125; break; default: break; &#125; &#125; &#125; &#125; List&lt;PullRequest&gt; pullRequestList = new ArrayList&lt;PullRequest&gt;(); for (MessageQueue mq : mqSet) &#123; if (!this.processQueueTable.containsKey(mq)) &#123; if (isOrder &amp;&amp; !this.lock(mq)) &#123; continue; &#125; this.removeDirtyOffset(mq); ProcessQueue pq = new ProcessQueue(); long nextOffset = this.computePullFromWhere(mq); if (nextOffset &gt;= 0) &#123; ProcessQueue pre = this.processQueueTable.putIfAbsent(mq, pq); if (pre != null) &#123; &#125; else &#123; PullRequest pullRequest = new PullRequest(); pullRequest.setConsumerGroup(consumerGroup); pullRequest.setNextOffset(nextOffset); pullRequest.setMessageQueue(mq); pullRequest.setProcessQueue(pq); pullRequestList.add(pullRequest); changed = true; &#125; &#125; &#125; &#125; this.dispatchPullRequest(pullRequestList); return changed; &#125; public boolean lock(final MessageQueue mq) &#123; FindBrokerResult findBrokerResult = this.mQClientFactory.findBrokerAddressInSubscribe(mq.getBrokerName(), MixAll.MASTER_ID, true); if (findBrokerResult != null) &#123; LockBatchRequestBody requestBody = new LockBatchRequestBody(); requestBody.setConsumerGroup(this.consumerGroup); requestBody.setClientId(this.mQClientFactory.getClientId()); requestBody.getMqSet().add(mq); try &#123; Set&lt;MessageQueue&gt; lockedMq = this.mQClientFactory.getMQClientAPIImpl().lockBatchMQ(findBrokerResult.getBrokerAddr(), requestBody, 1000); for (MessageQueue mmqq : lockedMq) &#123; ProcessQueue processQueue = this.processQueueTable.get(mmqq); if (processQueue != null) &#123; processQueue.setLocked(true); processQueue.setLastLockTimestamp(System.currentTimeMillis()); &#125; &#125; boolean lockOK = lockedMq.contains(mq); return lockOK; &#125; catch (Exception e) &#123; &#125; &#125; return false; &#125;&#125;public class ConsumeMessageOrderlyService implements ConsumeMessageService &#123; class ConsumeRequest implements Runnable &#123; private final ProcessQueue processQueue; private final MessageQueue messageQueue; @Override public void run() &#123; // 每一个ConsumeRequest消费任务不是以消费消息条数来计算,而是根据消费时间,默认当消费时长大于MAX_TIME_CONSUME_CONTINUOUSLY,默认60s后,本次消费任务结束,由消费组内其他线程继续消费 if (this.processQueue.isDropped()) &#123; return; &#125; final Object objLock = messageQueueLock.fetchLockObject(this.messageQueue); synchronized (objLock) &#123; // 通过加锁,将并发的消息顺序进行消费.消息处理的方式没什么特别. // 广播模式直接进入消费,无需锁定处理对列因为相互直接无竞争,集群模式proceessQueue被锁定并且锁未超时 if (MessageModel.BROADCASTING.equals(ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.messageModel()) || (this.processQueue.isLocked() &amp;&amp; !this.processQueue.isLockExpired())) &#123; final long beginTime = System.currentTimeMillis(); for (boolean continueConsume = true; continueConsume; ) &#123; if (this.processQueue.isDropped()) &#123; break; &#125; if (MessageModel.CLUSTERING.equals(ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.messageModel()) &amp;&amp; !this.processQueue.isLocked()) &#123; ConsumeMessageOrderlyService.this.tryLockLaterAndReconsume(this.messageQueue, this.processQueue, 10); break; &#125; if (MessageModel.CLUSTERING.equals(ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.messageModel()) &amp;&amp; this.processQueue.isLockExpired()) &#123; ConsumeMessageOrderlyService.this.tryLockLaterAndReconsume(this.messageQueue, this.processQueue, 10); break; &#125; long interval = System.currentTimeMillis() - beginTime; if (interval &gt; MAX_TIME_CONSUME_CONTINUOUSLY) &#123; ConsumeMessageOrderlyService.this.submitConsumeRequestLater(processQueue, messageQueue, 10); break; &#125; final int consumeBatchSize = ConsumeMessageOrderlyService.this.defaultMQPushConsumer.getConsumeMessageBatchMaxSize(); List&lt;MessageExt&gt; msgs = this.processQueue.takeMessages(consumeBatchSize); defaultMQPushConsumerImpl.resetRetryAndNamespace(msgs, defaultMQPushConsumer.getConsumerGroup()); if (!msgs.isEmpty()) &#123; final ConsumeOrderlyContext context = new ConsumeOrderlyContext(this.messageQueue); ConsumeOrderlyStatus status = null; ConsumeMessageContext consumeMessageContext = null; if (ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.hasHook()) &#123; consumeMessageContext = new ConsumeMessageContext(); consumeMessageContext.setConsumerGroup(ConsumeMessageOrderlyService.this.defaultMQPushConsumer.getConsumerGroup()); consumeMessageContext.setNamespace(defaultMQPushConsumer.getNamespace()); consumeMessageContext.setMq(messageQueue); consumeMessageContext.setMsgList(msgs); consumeMessageContext.setSuccess(false); consumeMessageContext.setProps(new HashMap&lt;String, String&gt;()); // init the consume context type ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.executeHookBefore(consumeMessageContext); &#125; long beginTimestamp = System.currentTimeMillis(); ConsumeReturnType returnType = ConsumeReturnType.SUCCESS; boolean hasException = false; try &#123; this.processQueue.getLockConsume().lock(); if (this.processQueue.isDropped()) &#123; break; &#125; status = messageListener.consumeMessage(Collections.unmodifiableList(msgs), context); // 调用消费者具体的消费方法 &#125; catch (Throwable e) &#123; hasException = true; &#125; finally &#123; this.processQueue.getLockConsume().unlock(); &#125; long consumeRT = System.currentTimeMillis() - beginTimestamp; if (null == status) &#123; if (hasException) &#123; returnType = ConsumeReturnType.EXCEPTION; &#125; else &#123; returnType = ConsumeReturnType.RETURNNULL; &#125; &#125; else if (consumeRT &gt;= defaultMQPushConsumer.getConsumeTimeout() * 60 * 1000) &#123; returnType = ConsumeReturnType.TIME_OUT; &#125; else if (ConsumeOrderlyStatus.SUSPEND_CURRENT_QUEUE_A_MOMENT == status) &#123; returnType = ConsumeReturnType.FAILED; &#125; else if (ConsumeOrderlyStatus.SUCCESS == status) &#123; returnType = ConsumeReturnType.SUCCESS; &#125; if (ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.hasHook()) &#123; consumeMessageContext.getProps().put(MixAll.CONSUME_CONTEXT_TYPE, returnType.name()); &#125; if (null == status) &#123; status = ConsumeOrderlyStatus.SUSPEND_CURRENT_QUEUE_A_MOMENT; &#125; if (ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.hasHook()) &#123; consumeMessageContext.setStatus(status.toString()); consumeMessageContext.setSuccess(ConsumeOrderlyStatus.SUCCESS == status || ConsumeOrderlyStatus.COMMIT == status); ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.executeHookAfter(consumeMessageContext); &#125; ConsumeMessageOrderlyService.this.getConsumerStatsManager().incConsumeRT(ConsumeMessageOrderlyService.this.consumerGroup, messageQueue.getTopic(), consumeRT); continueConsume = ConsumeMessageOrderlyService.this.processConsumeResult(msgs, status, context, this); &#125; else &#123; continueConsume = false; &#125; &#125; &#125; else &#123; if (this.processQueue.isDropped()) &#123; return; &#125; ConsumeMessageOrderlyService.this.tryLockLaterAndReconsume(this.messageQueue, this.processQueue, 100); &#125; &#125; &#125; &#125;&#125;","tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"http://example.com/tags/RocketMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RocketMQ","slug":"工具和中间件/消息队列/RocketMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RocketMQ/"}]},{"title":"RocketMQ-生产者源码","date":"2019-04-23T03:08:20.000Z","path":"blog/工具和中间件/消息队列/RocketMQ/RocketMQ-生产者源码/","text":"普通消息不论同步请求还是异步请求最终都是调用 DefaultMQProducerImpl 的 sendDefaultImpl 方法,首先通过 tryToFindTopicPublishInfo 方法获取Topic信息,先从本地缓存找,若本地缓存没有则调用 MQClientAPIImpl 的 getTopicRouteInfoFromNameServer 方法通过 RequestCode.GET_ROUTEINFO_BY_TOPIC 关联调用NameServer的 DefaultRequestProcessor 的 getRouteInfoByTopic 方法获取Topic信息； Topic 信息在 Producter 启动时就注册到 NameServer 了,且每 30s 发送心跳也会发送 Topic 相关的信息. 然后通过 MQFaultStrategy 的 selectOneMessageQueue 获取具体的具体要将消息发送到哪一个队列中,Producer选择 MessageQueue 方法是消息数自增对队列数取模,可通过 sendLatencyFaultEnable 参数开启Broker故障延迟机制,发送消息失败后一定时间内不在往同一个Queue重复发送的机制,在 LatencyFaultToleranceImpl 中维护了曾经发送失败的Broker列表到faultItemTable 中. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189public class DefaultMQProducer extends ClientConfig implements MQProducer &#123; public SendResult send(Message msg) throws MQClientException, RemotingException, MQBrokerException, InterruptedException &#123; Validators.checkMessage(msg, this); msg.setTopic(withNamespace(msg.getTopic())); return this.defaultMQProducerImpl.send(msg); &#125; public void send(Message msg, SendCallback sendCallback) throws MQClientException, RemotingException, InterruptedException &#123; msg.setTopic(withNamespace(msg.getTopic())); this.defaultMQProducerImpl.send(msg, sendCallback); &#125;&#125;public class DefaultMQProducerImpl implements MQProducerInner &#123; public void send(final Message msg, final SendCallback sendCallback, final long timeout) throws MQClientException, RemotingException, InterruptedException &#123; final long beginStartTime = System.currentTimeMillis(); ExecutorService executor = this.getAsyncSenderExecutor(); try &#123; executor.submit(new Runnable() &#123; @Override public void run() &#123; long costTime = System.currentTimeMillis() - beginStartTime; if (timeout &gt; costTime) &#123; try &#123; sendDefaultImpl(msg, CommunicationMode.ASYNC, sendCallback, timeout - costTime); &#125; catch (Exception e) &#123; sendCallback.onException(e); // 调用回调方法 &#125; &#125; else &#123; // 调用回调方法 sendCallback.onException(new RemotingTooMuchRequestException(&quot;DEFAULT ASYNC send call timeout&quot;)); &#125; &#125; &#125;); &#125; catch (RejectedExecutionException e) &#123; throw new MQClientException(&quot;executor rejected &quot;, e); &#125; &#125; private SendResult sendDefaultImpl(Message msg, final CommunicationMode communicationMode, final SendCallback sendCallback, final long timeout) throws MQClientException, RemotingException, MQBrokerException, InterruptedException &#123; this.makeSureStateOK(); Validators.checkMessage(msg, this.defaultMQProducer); final long invokeID = random.nextLong(); long beginTimestampFirst = System.currentTimeMillis(); long beginTimestampPrev = beginTimestampFirst; long endTimestamp = beginTimestampFirst; // 生产者获取Topic的公开信息 TopicPublishInfo topicPublishInfo = this.tryToFindTopicPublishInfo(msg.getTopic()); if (topicPublishInfo != null &amp;&amp; topicPublishInfo.ok()) &#123; boolean callTimeout = false; MessageQueue mq = null; Exception exception = null; SendResult sendResult = null; int timesTotal = communicationMode == CommunicationMode.SYNC ? 1 + this.defaultMQProducer.getRetryTimesWhenSendFailed() : 1; int times = 0; String[] brokersSent = new String[timesTotal]; for (; times &lt; timesTotal; times++) &#123; // 重试次数,异步默认重试2次共3次,同步不重试共1次 String lastBrokerName = null == mq ? null : mq.getBrokerName(); // Producer计算把消息发到哪个MessageQueue中,自增然后取模 MessageQueue mqSelected = this.selectOneMessageQueue(topicPublishInfo, lastBrokerName); if (mqSelected != null) &#123; mq = mqSelected; brokersSent[times] = mq.getBrokerName(); // 根据MessageQueue去获取目标节点的信息. try &#123; beginTimestampPrev = System.currentTimeMillis(); if (times &gt; 0) &#123; // 重新发送期间使用命名空间重置主题 msg.setTopic(this.defaultMQProducer.withNamespace(msg.getTopic())); &#125; long costTime = beginTimestampPrev - beginTimestampFirst; if (timeout &lt; costTime) &#123; // 判断是否超时,默认3s callTimeout = true; break; // 若超时 &#125; // 实际发送消息的方法 sendResult = this.sendKernelImpl(msg, mq, communicationMode, sendCallback, topicPublishInfo, timeout - costTime); endTimestamp = System.currentTimeMillis(); this.updateFaultItem(mq.getBrokerName(), endTimestamp - beginTimestampPrev, false); switch (communicationMode) &#123; case ASYNC: return null; // 异步发送返回null case ONEWAY: return null; // 单向发送返回null case SYNC: if (sendResult.getSendStatus() != SendStatus.SEND_OK) &#123; if (this.defaultMQProducer.isRetryAnotherBrokerWhenNotStoreOK()) &#123; continue; // 若重试则继续,否则直接返回结果 &#125; &#125; return sendResult; default: break; &#125; &#125; &#125; else &#123; break; &#125; &#125; if (sendResult != null) &#123; return sendResult; &#125; info += FAQUrl.suggestTodo(FAQUrl.SEND_MSG_FAILED); MQClientException mqClientException = new MQClientException(info, exception); if (callTimeout) &#123; throw new RemotingTooMuchRequestException(&quot;sendDefaultImpl call timeout&quot;); &#125; throw mqClientException; &#125; validateNameServerSetting(); throw new MQClientException(&quot;No route info of this topic: &quot; + msg.getTopic() + FAQUrl.suggestTodo(FAQUrl.NO_TOPIC_ROUTE_INFO), null).setResponseCode(ClientErrorCode.NOT_FOUND_TOPIC_EXCEPTION); &#125; public MessageQueue selectOneMessageQueue(final TopicPublishInfo tpInfo, final String lastBrokerName) &#123; return this.mqFaultStrategy.selectOneMessageQueue(tpInfo, lastBrokerName); &#125; // 找路由表的过程都是先从本地缓存找,本地缓存没有,就去NameServer上申请. private TopicPublishInfo tryToFindTopicPublishInfo(final String topic) &#123; TopicPublishInfo topicPublishInfo = this.topicPublishInfoTable.get(topic); if (null == topicPublishInfo || !topicPublishInfo.ok()) &#123; this.topicPublishInfoTable.putIfAbsent(topic, new TopicPublishInfo()); // Producer向NameServer获取更新Topic的路由信息. this.mQClientFactory.updateTopicRouteInfoFromNameServer(topic); // 还是从本地缓存中寻找Topic路由信息. topicPublishInfo = this.topicPublishInfoTable.get(topic); &#125; if (topicPublishInfo.isHaveTopicRouterInfo() || topicPublishInfo.ok()) &#123; return topicPublishInfo; &#125; else &#123; this.mQClientFactory.updateTopicRouteInfoFromNameServer(topic, true, this.defaultMQProducer); topicPublishInfo = this.topicPublishInfoTable.get(topic); return topicPublishInfo; &#125; &#125;&#125;public class MQFaultStrategy &#123; public MessageQueue selectOneMessageQueue(final TopicPublishInfo tpInfo, final String lastBrokerName) &#123; // sendLatencyFaultEnable默认关闭,Broker故障延迟机制,表示一种发送消息失败后一定时间内不在往同一个Queue重复发送的机制 if (this.sendLatencyFaultEnable) &#123; try &#123; // Producer选择MessageQueue的方法是自增然后取模. int index = tpInfo.getSendWhichQueue().getAndIncrement(); for (int i = 0; i &lt; tpInfo.getMessageQueueList().size(); i++) &#123; int pos = Math.abs(index++) % tpInfo.getMessageQueueList().size(); if (pos &lt; 0) pos = 0; MessageQueue mq = tpInfo.getMessageQueueList().get(pos); // Broker轮询,尽量将请求平均分配给不同的Broker if (latencyFaultTolerance.isAvailable(mq.getBrokerName())) &#123; if (null == lastBrokerName || mq.getBrokerName().equals(lastBrokerName)) return mq; &#125; &#125; final String notBestBroker = latencyFaultTolerance.pickOneAtLeast(); int writeQueueNums = tpInfo.getQueueIdByBroker(notBestBroker); if (writeQueueNums &gt; 0) &#123; final MessageQueue mq = tpInfo.selectOneMessageQueue();// 自增取模计算 if (notBestBroker != null) &#123; mq.setBrokerName(notBestBroker); mq.setQueueId(tpInfo.getSendWhichQueue().getAndIncrement() % writeQueueNums); &#125; return mq; &#125; else &#123; latencyFaultTolerance.remove(notBestBroker); &#125; &#125; return tpInfo.selectOneMessageQueue(); // 自增取模计算 &#125; return tpInfo.selectOneMessageQueue(lastBrokerName); // 自增取模计算 &#125;&#125;public class TopicPublishInfo &#123; //选择MessageQueue的方式：递增取模 public MessageQueue selectOneMessageQueue() &#123; int index = this.sendWhichQueue.getAndIncrement(); int pos = Math.abs(index) % this.messageQueueList.size(); if (pos &lt; 0) pos = 0; return this.messageQueueList.get(pos); &#125; public MessageQueue selectOneMessageQueue(final String lastBrokerName) &#123; if (lastBrokerName == null) &#123; return selectOneMessageQueue(); &#125; else &#123; int index = this.sendWhichQueue.getAndIncrement(); for (int i = 0; i &lt; this.messageQueueList.size(); i++) &#123; int pos = Math.abs(index++) % this.messageQueueList.size(); if (pos &lt; 0) pos = 0; MessageQueue mq = this.messageQueueList.get(pos); if (!mq.getBrokerName().equals(lastBrokerName)) &#123; return mq; &#125; &#125; return selectOneMessageQueue(); &#125; &#125;&#125; 不论是同步还是异步或是单向消息最终都会调用 MQClientAPIImpl 的 sendMessage 方法,不同的是同步方法没有 SendCallback 回调. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152public class DefaultMQProducerImpl implements MQProducerInner &#123; private SendResult sendKernelImpl(final Message msg, final MessageQueue mq, final CommunicationMode communicationMode, final SendCallback sendCallback, final TopicPublishInfo topicPublishInfo, final long timeout) throws MQClientException, RemotingException, MQBrokerException, InterruptedException &#123; long beginStartTime = System.currentTimeMillis(); String brokerAddr = this.mQClientFactory.findBrokerAddressInPublish(mq.getBrokerName()); // 找到Master节点地址 if (null == brokerAddr) &#123;// 通过Broker名称获取Broker地址,若获取不到则去NameServer上获取. tryToFindTopicPublishInfo(mq.getTopic()); brokerAddr = this.mQClientFactory.findBrokerAddressInPublish(mq.getBrokerName()); &#125; SendMessageContext context = null; if (brokerAddr != null) &#123; brokerAddr = MixAll.brokerVIPChannel(this.defaultMQProducer.isSendMessageWithVIPChannel(), brokerAddr); byte[] prevBody = msg.getBody(); try &#123; if (!(msg instanceof MessageBatch)) &#123; //for MessageBatch,ID has been set in the generating process MessageClientIDSetter.setUniqID(msg); // 批量消息 &#125; boolean topicWithNamespace = false; if (null != this.mQClientFactory.getClientConfig().getNamespace()) &#123; msg.setInstanceId(this.mQClientFactory.getClientConfig().getNamespace()); topicWithNamespace = true; &#125; int sysFlag = 0; boolean msgBodyCompressed = false; if (this.tryToCompressMessage(msg)) &#123; // 消息体大于4K将默认压缩 sysFlag |= MessageSysFlag.COMPRESSED_FLAG; msgBodyCompressed = true; &#125; final String tranMsg = msg.getProperty(MessageConst.PROPERTY_TRANSACTION_PREPARED); if (tranMsg != null &amp;&amp; Boolean.parseBoolean(tranMsg)) &#123; sysFlag |= MessageSysFlag.TRANSACTION_PREPARED_TYPE; &#125; SendMessageRequestHeader requestHeader = new SendMessageRequestHeader(); requestHeader.setProducerGroup(this.defaultMQProducer.getProducerGroup()); requestHeader.setTopic(msg.getTopic()); requestHeader.setDefaultTopic(this.defaultMQProducer.getCreateTopicKey()); requestHeader.setDefaultTopicQueueNums(this.defaultMQProducer.getDefaultTopicQueueNums()); requestHeader.setQueueId(mq.getQueueId()); requestHeader.setSysFlag(sysFlag); requestHeader.setBornTimestamp(System.currentTimeMillis()); requestHeader.setFlag(msg.getFlag()); requestHeader.setProperties(MessageDecoder.messageProperties2String(msg.getProperties())); requestHeader.setReconsumeTimes(0); requestHeader.setUnitMode(this.isUnitMode()); requestHeader.setBatch(msg instanceof MessageBatch); if (requestHeader.getTopic().startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)) &#123; // 重试消息 String reconsumeTimes = MessageAccessor.getReconsumeTime(msg); if (reconsumeTimes != null) &#123; requestHeader.setReconsumeTimes(Integer.valueOf(reconsumeTimes)); MessageAccessor.clearProperty(msg, MessageConst.PROPERTY_RECONSUME_TIME); &#125; String maxReconsumeTimes = MessageAccessor.getMaxReconsumeTimes(msg); if (maxReconsumeTimes != null) &#123; requestHeader.setMaxReconsumeTimes(Integer.valueOf(maxReconsumeTimes)); MessageAccessor.clearProperty(msg, MessageConst.PROPERTY_MAX_RECONSUME_TIMES); &#125; &#125; SendResult sendResult = null; switch (communicationMode) &#123; case ASYNC: Message tmpMessage = msg; boolean messageCloned = false; if (msgBodyCompressed) &#123; tmpMessage = MessageAccessor.cloneMessage(msg); messageCloned = true; msg.setBody(prevBody); &#125; if (topicWithNamespace) &#123; if (!messageCloned) &#123; tmpMessage = MessageAccessor.cloneMessage(msg); messageCloned = true; &#125; msg.setTopic(NamespaceUtil.withoutNamespace(msg.getTopic(), this.defaultMQProducer.getNamespace())); &#125; long costTimeAsync = System.currentTimeMillis() - beginStartTime; if (timeout &lt; costTimeAsync) &#123; throw new RemotingTooMuchRequestException(&quot;sendKernelImpl call timeout&quot;); &#125; // 真正向Broker发送消息,异步要传入回调函数 sendResult = this.mQClientFactory.getMQClientAPIImpl().sendMessage(brokerAddr, mq.getBrokerName(), tmpMessage, requestHeader, timeout - costTimeAsync, communicationMode, sendCallback, topicPublishInfo, this.mQClientFactory, this.defaultMQProducer.getRetryTimesWhenSendAsyncFailed(), context, this); break; case ONEWAY: case SYNC: long costTimeSync = System.currentTimeMillis() - beginStartTime; if (timeout &lt; costTimeSync) &#123; throw new RemotingTooMuchRequestException(&quot;sendKernelImpl call timeout&quot;); &#125; // 真正向Broker发送消息,同步不需要传入回调函数 sendResult = this.mQClientFactory.getMQClientAPIImpl().sendMessage(brokerAddr, mq.getBrokerName(), msg, requestHeader, timeout - costTimeSync, communicationMode, context, this); break; default: assert false; break; &#125; if (this.hasSendMessageHook()) &#123;//消息发送完成后执行钩子程序. context.setSendResult(sendResult); this.executeSendMessageHookAfter(context); &#125; return sendResult; &#125; &#125; throw new MQClientException(&quot;The broker[&quot; + mq.getBrokerName() + &quot;] not exist&quot;, null); &#125;&#125;public class MQClientAPIImpl &#123; // 不论同步还是异步最终都会调用该方法 public SendResult sendMessage(final String addr, final String brokerName, final Message msg, final SendMessageRequestHeader requestHeader, final long timeoutMillis, final CommunicationMode communicationMode, final SendCallback sendCallback, final TopicPublishInfo topicPublishInfo, final MQClientInstance instance, final int retryTimesWhenSendFailed, final SendMessageContext context, final DefaultMQProducerImpl producer) throws RemotingException, MQBrokerException, InterruptedException &#123; long beginStartTime = System.currentTimeMillis(); RemotingCommand request = null; String msgType = msg.getProperty(MessageConst.PROPERTY_MESSAGE_TYPE); boolean isReply = msgType != null &amp;&amp; msgType.equals(MixAll.REPLY_MESSAGE_FLAG); if (isReply) &#123; if (sendSmartMsg) &#123; SendMessageRequestHeaderV2 requestHeaderV2 = SendMessageRequestHeaderV2.createSendMessageRequestHeaderV2(requestHeader); request = RemotingCommand.createRequestCommand(RequestCode.SEND_REPLY_MESSAGE_V2, requestHeaderV2); &#125; else &#123; request = RemotingCommand.createRequestCommand(RequestCode.SEND_REPLY_MESSAGE, requestHeader); &#125; &#125; else &#123; if (sendSmartMsg || msg instanceof MessageBatch) &#123; SendMessageRequestHeaderV2 requestHeaderV2 = SendMessageRequestHeaderV2.createSendMessageRequestHeaderV2(requestHeader); request = RemotingCommand.createRequestCommand(msg instanceof MessageBatch ? RequestCode.SEND_BATCH_MESSAGE : RequestCode.SEND_MESSAGE_V2, requestHeaderV2); &#125; else &#123; request = RemotingCommand.createRequestCommand(RequestCode.SEND_MESSAGE, requestHeader); &#125; &#125; request.setBody(msg.getBody()); switch (communicationMode) &#123; case ONEWAY: this.remotingClient.invokeOneway(addr, request, timeoutMillis); return null; case ASYNC: final AtomicInteger times = new AtomicInteger(); long costTimeAsync = System.currentTimeMillis() - beginStartTime; if (timeoutMillis &lt; costTimeAsync) &#123; throw new RemotingTooMuchRequestException(&quot;sendMessage call timeout&quot;); &#125; this.sendMessageAsync(addr, brokerName, msg, timeoutMillis - costTimeAsync, request, sendCallback, topicPublishInfo, instance, retryTimesWhenSendFailed, times, context, producer); return null; case SYNC: long costTimeSync = System.currentTimeMillis() - beginStartTime; if (timeoutMillis &lt; costTimeSync) &#123; throw new RemotingTooMuchRequestException(&quot;sendMessage call timeout&quot;); &#125; return this.sendMessageSync(addr, brokerName, msg, timeoutMillis - costTimeSync, request); default: assert false; break; &#125; return null; &#125; &#125; 对于同步消息最终用通过 RequestCode.SEND_MESSAGE 编号最终在 Broker 中执行 SendMessageProcessor 的 processRequest 方法,异步消息最终调用的是 SendMessageProcessor 的 asyncProcessRequest 方法,最终都是调用的 asyncProcessRequest 方法,不同点在于同步消息的 processRequest 中获取到异步 CompletableFuture 直接调用get方法等待结果,不论是同步还是异步方法最终都是在 handlePutMessageResultFuture 方法中调用 CompletableFuture 的 thenApply 方法,在响应后最终在 handlePutMessageResult 中调用 doResponse 方法将结果写回给客户端. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109public class MQClientAPIImpl &#123; private SendResult sendMessageSync(final String addr, final String brokerName, final Message msg, final long timeoutMillis, final RemotingCommand request) throws RemotingException, MQBrokerException, InterruptedException &#123; RemotingCommand response = this.remotingClient.invokeSync(addr, request, timeoutMillis); assert response != null; return this.processSendResponse(brokerName, msg, response); &#125;&#125;public class NettyRemotingClient extends NettyRemotingAbstract implements RemotingClient &#123; public RemotingCommand invokeSync(String addr, final RemotingCommand request, long timeoutMillis) throws InterruptedException, RemotingConnectException, RemotingSendRequestException, RemotingTimeoutException &#123; long beginStartTime = System.currentTimeMillis(); // channel是和Nameserver之间建立的一个连接. final Channel channel = this.getAndCreateChannel(addr); if (channel != null &amp;&amp; channel.isActive()) &#123; // 网络连接ok则发送请求 try &#123; doBeforeRpcHooks(addr, request); //计算时间 long costTime = System.currentTimeMillis() - beginStartTime; if (timeoutMillis &lt; costTime) &#123; throw new RemotingTimeoutException(&quot;invokeSync call timeout&quot;); &#125; RemotingCommand response = this.invokeSyncImpl(channel, request, timeoutMillis - costTime); // 真正发网络请求的地方 doAfterRpcHooks(RemotingHelper.parseChannelRemoteAddr(channel), request, response); return response; &#125; catch (RemotingSendRequestException e) &#123; this.closeChannel(addr, channel); throw e; &#125; catch (RemotingTimeoutException e) &#123; if (nettyClientConfig.isClientCloseSocketIfTimeout()) &#123; this.closeChannel(addr, channel); &#125; throw e; &#125; &#125; else &#123; this.closeChannel(addr, channel); throw new RemotingConnectException(addr); &#125; &#125;&#125;public class SendMessageProcessor extends AbstractSendMessageProcessor implements NettyRequestProcessor &#123; public RemotingCommand processRequest(ChannelHandlerContext ctx, RemotingCommand request) throws RemotingCommandException &#123; RemotingCommand response = null; try &#123; response = asyncProcessRequest(ctx, request).get(); &#125; return response; &#125; public CompletableFuture&lt;RemotingCommand&gt; asyncProcessRequest(ChannelHandlerContext ctx, RemotingCommand request) throws RemotingCommandException &#123; final SendMessageContext mqtraceContext; switch (request.getCode()) &#123; case RequestCode.CONSUMER_SEND_MSG_BACK: return this.asyncConsumerSendMsgBack(ctx, request); default: SendMessageRequestHeader requestHeader = parseRequestHeader(request); if (requestHeader == null) &#123; return CompletableFuture.completedFuture(null); &#125; mqtraceContext = buildMsgContext(ctx, requestHeader); this.executeSendMessageHookBefore(ctx, request, mqtraceContext); if (requestHeader.isBatch()) &#123; return this.asyncSendBatchMessage(ctx, request, mqtraceContext, requestHeader); &#125; else &#123; return this.asyncSendMessage(ctx, request, mqtraceContext, requestHeader); &#125; &#125; &#125; private CompletableFuture&lt;RemotingCommand&gt; asyncSendMessage(ChannelHandlerContext ctx, RemotingCommand request, SendMessageContext mqtraceContext, SendMessageRequestHeader requestHeader) &#123; final RemotingCommand response = preSend(ctx, request, requestHeader); final SendMessageResponseHeader responseHeader = (SendMessageResponseHeader)response.readCustomHeader(); if (response.getCode() != -1) &#123; return CompletableFuture.completedFuture(response); &#125; final byte[] body = request.getBody(); int queueIdInt = requestHeader.getQueueId(); TopicConfig topicConfig = this.brokerController.getTopicConfigManager().selectTopicConfig(requestHeader.getTopic()); if (queueIdInt &lt; 0) &#123; queueIdInt = randomQueueId(topicConfig.getWriteQueueNums()); &#125; MessageExtBrokerInner msgInner = new MessageExtBrokerInner(); msgInner.setTopic(requestHeader.getTopic()); msgInner.setQueueId(queueIdInt); if (!handleRetryAndDLQ(requestHeader, response, request, msgInner, topicConfig)) &#123; return CompletableFuture.completedFuture(response); &#125; msgInner.setBody(body); msgInner.setFlag(requestHeader.getFlag()); MessageAccessor.setProperties(msgInner, MessageDecoder.string2messageProperties(requestHeader.getProperties())); msgInner.setPropertiesString(requestHeader.getProperties()); msgInner.setBornTimestamp(requestHeader.getBornTimestamp()); msgInner.setBornHost(ctx.channel().remoteAddress()); msgInner.setStoreHost(this.getStoreHost()); msgInner.setReconsumeTimes(requestHeader.getReconsumeTimes() == null ? 0 : requestHeader.getReconsumeTimes()); String clusterName = this.brokerController.getBrokerConfig().getBrokerClusterName(); MessageAccessor.putProperty(msgInner, MessageConst.PROPERTY_CLUSTER, clusterName); msgInner.setPropertiesString(MessageDecoder.messageProperties2String(msgInner.getProperties())); CompletableFuture&lt;PutMessageResult&gt; putMessageResult = null; Map&lt;String, String&gt; origProps = MessageDecoder.string2messageProperties(requestHeader.getProperties()); String transFlag = origProps.get(MessageConst.PROPERTY_TRANSACTION_PREPARED); if (transFlag != null &amp;&amp; Boolean.parseBoolean(transFlag)) &#123; if (this.brokerController.getBrokerConfig().isRejectTransactionMessage()) &#123; response.setCode(ResponseCode.NO_PERMISSION); response.setRemark(&quot;the broker[&quot; + this.brokerController.getBrokerConfig().getBrokerIP1() + &quot;] sending transaction message is forbidden&quot;); return CompletableFuture.completedFuture(response); &#125; putMessageResult = this.brokerController.getTransactionalMessageService().asyncPrepareMessage(msgInner); // 事务消息持久化 &#125; else &#123; putMessageResult = this.brokerController.getMessageStore().asyncPutMessage(msgInner); // 普通消息持久化 &#125; return handlePutMessageResultFuture(putMessageResult, response, request, msgInner, responseHeader, mqtraceContext, ctx, queueIdInt); &#125;&#125; 对于异步方法当获取到响应后会回调 InvokeCallback 中的 operationComplete 方法,在该方法中若成功则回调用 SendCallback 的 onSuccess 方法.若失败则走重试逻辑若中还是失败则回调用 SendCallback 的 onException 方法. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class MQClientAPIImpl &#123; private void sendMessageAsync(final String addr, final String brokerName, final Message msg, final long timeoutMillis, final RemotingCommand request, final SendCallback sendCallback, final TopicPublishInfo topicPublishInfo, final MQClientInstance instance, final int retryTimesWhenSendFailed, final AtomicInteger times, final SendMessageContext context, final DefaultMQProducerImpl producer) throws InterruptedException, RemotingException &#123; final long beginStartTime = System.currentTimeMillis(); this.remotingClient.invokeAsync(addr, request, timeoutMillis, new InvokeCallback() &#123; @Override public void operationComplete(ResponseFuture responseFuture) &#123; long cost = System.currentTimeMillis() - beginStartTime; RemotingCommand response = responseFuture.getResponseCommand(); if (null == sendCallback &amp;&amp; response != null) &#123; try &#123; SendResult sendResult = MQClientAPIImpl.this.processSendResponse(brokerName, msg, response); if (context != null &amp;&amp; sendResult != null) &#123; context.setSendResult(sendResult); context.getProducer().executeSendMessageHookAfter(context); &#125; &#125; catch (Throwable e) &#123; &#125; producer.updateFaultItem(brokerName, System.currentTimeMillis() - responseFuture.getBeginTimestamp(), false); return; &#125; if (response != null) &#123; try &#123; SendResult sendResult = MQClientAPIImpl.this.processSendResponse(brokerName, msg, response); assert sendResult != null; if (context != null) &#123; context.setSendResult(sendResult); context.getProducer().executeSendMessageHookAfter(context); &#125; try &#123; sendCallback.onSuccess(sendResult); // 回调用SendCallback的onSuccess方法 &#125; catch (Throwable e) &#123; &#125; producer.updateFaultItem(brokerName, System.currentTimeMillis() - responseFuture.getBeginTimestamp(), false); &#125; catch (Exception e) &#123; producer.updateFaultItem(brokerName, System.currentTimeMillis() - responseFuture.getBeginTimestamp(), true); onExceptionImpl(brokerName, msg, timeoutMillis - cost, request, sendCallback, topicPublishInfo, instance, retryTimesWhenSendFailed, times, e, context, false, producer); &#125; &#125; else &#123; producer.updateFaultItem(brokerName, System.currentTimeMillis() - responseFuture.getBeginTimestamp(), true); if (!responseFuture.isSendRequestOK()) &#123; MQClientException ex = new MQClientException(&quot;send request failed&quot;, responseFuture.getCause()); onExceptionImpl(brokerName, msg, timeoutMillis - cost, request, sendCallback, topicPublishInfo, instance, retryTimesWhenSendFailed, times, ex, context, true, producer); &#125; else if (responseFuture.isTimeout()) &#123; MQClientException ex = new MQClientException(&quot;wait response timeout &quot; + responseFuture.getTimeoutMillis() + &quot;ms&quot;, responseFuture.getCause()); onExceptionImpl(brokerName, msg, timeoutMillis - cost, request, sendCallback, topicPublishInfo, instance, retryTimesWhenSendFailed, times, ex, context, true, producer); &#125; else &#123; MQClientException ex = new MQClientException(&quot;unknow reseaon&quot;, responseFuture.getCause()); onExceptionImpl(brokerName, msg, timeoutMillis - cost, request, sendCallback, topicPublishInfo, instance, retryTimesWhenSendFailed, times, ex, context, true, producer); &#125; &#125; &#125; &#125;); &#125;&#125; 事务消息对于事务消息的发送是通过 TransactionMQProducer 类的 sendMessageInTransaction 方法来完成的,若事务消息设置了延迟参数则将会被清除,会设置 TRAN_MSG 属性为 true ,然后调用send方法发送消费到 Broker ,send方法中和普通的发送消息调用的一个方法,但普通消息是走的 DefaultMessageStore 的 asyncPutMessage 方法,事务消息是走的 TransactionalMessageServiceImpl 的 asyncPrepareMessage 方法.若发送成功则调用设置的 TransactionListener 的 executeLocalTransaction 方法,然后调用 MQClientAPIImpl 的 endTransactionOneway 方法. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111public class TransactionMQProducer extends DefaultMQProducer &#123; public TransactionSendResult sendMessageInTransaction(final Message msg, final Object arg) throws MQClientException &#123; if (null == this.transactionListener) &#123; throw new MQClientException(&quot;TransactionListener is null&quot;, null); &#125; msg.setTopic(NamespaceUtil.wrapNamespace(this.getNamespace(), msg.getTopic())); return this.defaultMQProducerImpl.sendMessageInTransaction(msg, null, arg); &#125;&#125;public class DefaultMQProducerImpl implements MQProducerInner &#123; public TransactionSendResult sendMessageInTransaction(final Message msg, final LocalTransactionExecuter localTransactionExecuter, final Object arg) throws MQClientException &#123; TransactionListener transactionListener = getCheckListener(); if (null == localTransactionExecuter &amp;&amp; null == transactionListener) &#123; throw new MQClientException(&quot;tranExecutor is null&quot;, null); &#125; if (msg.getDelayTimeLevel() != 0) &#123; // 不支持延迟消息 MessageAccessor.clearProperty(msg, MessageConst.PROPERTY_DELAY_TIME_LEVEL); &#125; Validators.checkMessage(msg, this.defaultMQProducer); SendResult sendResult = null; MessageAccessor.putProperty(msg, MessageConst.PROPERTY_TRANSACTION_PREPARED, &quot;true&quot;); MessageAccessor.putProperty(msg, MessageConst.PROPERTY_PRODUCER_GROUP, this.defaultMQProducer.getProducerGroup()); try &#123; sendResult = this.send(msg); &#125; catch (Exception e) &#123; throw new MQClientException(&quot;send message Exception&quot;, e); &#125; LocalTransactionState localTransactionState = LocalTransactionState.UNKNOW; // 默认本地事务状态为UNKNOW Throwable localException = null; switch (sendResult.getSendStatus()) &#123; case SEND_OK: &#123; try &#123; if (sendResult.getTransactionId() != null) &#123; msg.putUserProperty(&quot;__transactionId__&quot;, sendResult.getTransactionId()); &#125; String transactionId = msg.getProperty(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX); if (null != transactionId &amp;&amp; !&quot;&quot;.equals(transactionId)) &#123; msg.setTransactionId(transactionId); &#125; if (null != localTransactionExecuter) &#123; // 默认localTransactionExecuter为null localTransactionState = localTransactionExecuter.executeLocalTransactionBranch(msg, arg); &#125; else if (transactionListener != null) &#123; // transactionListener是调用时设置的 localTransactionState = transactionListener.executeLocalTransaction(msg, arg); &#125; if (null == localTransactionState) &#123; localTransactionState = LocalTransactionState.UNKNOW; &#125; &#125; catch (Throwable e) &#123; localException = e; &#125; &#125; break; case FLUSH_DISK_TIMEOUT: case FLUSH_SLAVE_TIMEOUT: case SLAVE_NOT_AVAILABLE: localTransactionState = LocalTransactionState.ROLLBACK_MESSAGE; break; default: break; &#125; try &#123; this.endTransaction(sendResult, localTransactionState, localException); &#125; TransactionSendResult transactionSendResult = new TransactionSendResult(); transactionSendResult.setSendStatus(sendResult.getSendStatus()); transactionSendResult.setMessageQueue(sendResult.getMessageQueue()); transactionSendResult.setMsgId(sendResult.getMsgId()); transactionSendResult.setQueueOffset(sendResult.getQueueOffset()); transactionSendResult.setTransactionId(sendResult.getTransactionId()); transactionSendResult.setLocalTransactionState(localTransactionState); return transactionSendResult; &#125; public void endTransaction(final SendResult sendResult, final LocalTransactionState localTransactionState, final Throwable localException) throws RemotingException, MQBrokerException, InterruptedException, UnknownHostException &#123; final MessageId id; if (sendResult.getOffsetMsgId() != null) &#123; id = MessageDecoder.decodeMessageId(sendResult.getOffsetMsgId()); &#125; else &#123; id = MessageDecoder.decodeMessageId(sendResult.getMsgId()); &#125; String transactionId = sendResult.getTransactionId(); final String brokerAddr = this.mQClientFactory.findBrokerAddressInPublish(sendResult.getMessageQueue().getBrokerName()); EndTransactionRequestHeader requestHeader = new EndTransactionRequestHeader(); requestHeader.setTransactionId(transactionId); requestHeader.setCommitLogOffset(id.getOffset()); switch (localTransactionState) &#123; case COMMIT_MESSAGE: requestHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_COMMIT_TYPE); break; case ROLLBACK_MESSAGE: requestHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_ROLLBACK_TYPE); break; case UNKNOW: requestHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_NOT_TYPE); break; default: break; &#125; requestHeader.setProducerGroup(this.defaultMQProducer.getProducerGroup()); requestHeader.setTranStateTableOffset(sendResult.getQueueOffset()); requestHeader.setMsgId(sendResult.getMsgId()); String remark = localException != null ? (&quot;executeLocalTransactionBranch exception: &quot; + localException.toString()) : null; this.mQClientFactory.getMQClientAPIImpl().endTransactionOneway(brokerAddr, requestHeader, remark, this.defaultMQProducer.getSendMsgTimeout()); &#125;&#125;public class MQClientAPIImpl &#123; public void endTransactionOneway(final String addr, final EndTransactionRequestHeader requestHeader, final String remark, final long timeoutMillis) throws RemotingException, MQBrokerException, InterruptedException &#123; RemotingCommand request = RemotingCommand.createRequestCommand(RequestCode.END_TRANSACTION, requestHeader); request.setRemark(remark); this.remotingClient.invokeOneway(addr, request, timeoutMillis); &#125;&#125; 首先会将将真正的事务 Topic 存储到 REAL_TOPIC 属性中,然后将 Topic 换成 RMQ_SYS_TRANS_HALF_TOPIC ,然后将替换了Topic的事务消息通过 DefaultMessageStore 的 asyncPutMessage 方法最终存储到 CommitLog 中. 1234567891011121314151617public class TransactionalMessageServiceImpl implements TransactionalMessageService &#123; public CompletableFuture&lt;PutMessageResult&gt; asyncPrepareMessage(MessageExtBrokerInner messageInner) &#123; return transactionalMessageBridge.asyncPutHalfMessage(messageInner); &#125; public CompletableFuture&lt;PutMessageResult&gt; asyncPutHalfMessage(MessageExtBrokerInner messageInner) &#123; return store.asyncPutMessage(parseHalfMessageInner(messageInner)); &#125; private MessageExtBrokerInner parseHalfMessageInner(MessageExtBrokerInner msgInner) &#123; MessageAccessor.putProperty(msgInner, MessageConst.PROPERTY_REAL_TOPIC, msgInner.getTopic()); // 将真正的事务Topic存储到REAL_TOPIC属性中 MessageAccessor.putProperty(msgInner, MessageConst.PROPERTY_REAL_QUEUE_ID, String.valueOf(msgInner.getQueueId())); msgInner.setSysFlag(MessageSysFlag.resetTransactionValue(msgInner.getSysFlag(), MessageSysFlag.TRANSACTION_NOT_TYPE)); msgInner.setTopic(TransactionalMessageUtil.buildHalfTopic()); // Topic换成RMQ_SYS_TRANS_HALF_TOPIC msgInner.setQueueId(0); msgInner.setPropertiesString(MessageDecoder.messageProperties2String(msgInner.getProperties())); return msgInner; &#125;&#125; 最终通过 RequestCode.END_TRANSACTION 编码关联调用 EndTransactionProcessor 的 processRequest 方法,不论是是 COMMIT 还是 ROLLBACK 都将消息从 RMQ_SYS_TRANS_HALF_TOPIC 队列中查询出,若是 COMMIT 则将从 RMQ_SYS_TRANS_HALF_TOPIC 队列中查询的消息真正存储到其真实的Topic队列中,然后成功则再在 RMQ_SYS_TRANS_OP_HALF_TOPIC 队列中添加一条对应的消息标识该Half消息被删除.若为 ROLLBACK 则直接在 RMQ_SYS_TRANS_OP_HALF_TOPIC 队列中添加一条对应的消标识事务结束.开源版本进行了阉割,不会走回查逻辑. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class EndTransactionProcessor extends AsyncNettyRequestProcessor implements NettyRequestProcessor &#123; public RemotingCommand processRequest(ChannelHandlerContext ctx, RemotingCommand request) throws RemotingCommandException &#123; final RemotingCommand response = RemotingCommand.createResponseCommand(null); final EndTransactionRequestHeader requestHeader = (EndTransactionRequestHeader)request.decodeCommandCustomHeader(EndTransactionRequestHeader.class); if (BrokerRole.SLAVE == brokerController.getMessageStoreConfig().getBrokerRole()) &#123; response.setCode(ResponseCode.SLAVE_NOT_AVAILABLE); return response; // 若当前节点是从节点 &#125; OperationResult result = new OperationResult(); if (MessageSysFlag.TRANSACTION_COMMIT_TYPE == requestHeader.getCommitOrRollback()) &#123; result = this.brokerController.getTransactionalMessageService().commitMessage(requestHeader); if (result.getResponseCode() == ResponseCode.SUCCESS) &#123; RemotingCommand res = checkPrepareMessage(result.getPrepareMessage(), requestHeader); if (res.getCode() == ResponseCode.SUCCESS) &#123; MessageExtBrokerInner msgInner = endMessageTransaction(result.getPrepareMessage()); msgInner.setSysFlag(MessageSysFlag.resetTransactionValue(msgInner.getSysFlag(), requestHeader.getCommitOrRollback())); msgInner.setQueueOffset(requestHeader.getTranStateTableOffset()); msgInner.setPreparedTransactionOffset(requestHeader.getCommitLogOffset()); msgInner.setStoreTimestamp(result.getPrepareMessage().getStoreTimestamp()); MessageAccessor.clearProperty(msgInner, MessageConst.PROPERTY_TRANSACTION_PREPARED); // 将事务消息TRAN_MSG标记移除 RemotingCommand sendResult = sendFinalMessage(msgInner);// 将从RMQ_SYS_TRANS_HALF_TOPIC队列中查询的消息真正存储到其真实的Topic队列中 if (sendResult.getCode() == ResponseCode.SUCCESS) &#123;// 存储成功则在RMQ_SYS_TRANS_OP_HALF_TOPIC队列中添加对应的消息 this.brokerController.getTransactionalMessageService().deletePrepareMessage(result.getPrepareMessage()); &#125; return sendResult; &#125; return res; &#125; &#125; else if (MessageSysFlag.TRANSACTION_ROLLBACK_TYPE == requestHeader.getCommitOrRollback()) &#123; result = this.brokerController.getTransactionalMessageService().rollbackMessage(requestHeader); if (result.getResponseCode() == ResponseCode.SUCCESS) &#123; RemotingCommand res = checkPrepareMessage(result.getPrepareMessage(), requestHeader); if (res.getCode() == ResponseCode.SUCCESS) &#123;// 成功则在RMQ_SYS_TRANS_OP_HALF_TOPIC队列中添加对应的消息 this.brokerController.getTransactionalMessageService().deletePrepareMessage(result.getPrepareMessage()); &#125; return res; &#125; &#125; response.setCode(result.getResponseCode()); response.setRemark(result.getResponseRemark()); return response; &#125;&#125;public class TransactionalMessageServiceImpl implements TransactionalMessageService &#123; public OperationResult commitMessage(EndTransactionRequestHeader requestHeader) &#123; return getHalfMessageByOffset(requestHeader.getCommitLogOffset()); &#125; public OperationResult rollbackMessage(EndTransactionRequestHeader requestHeader) &#123; return getHalfMessageByOffset(requestHeader.getCommitLogOffset()); &#125; private OperationResult getHalfMessageByOffset(long commitLogOffset) &#123; OperationResult response = new OperationResult(); MessageExt messageExt = this.transactionalMessageBridge.lookMessageByOffset(commitLogOffset); if (messageExt != null) &#123; response.setPrepareMessage(messageExt); response.setResponseCode(ResponseCode.SUCCESS); &#125; else &#123; response.setResponseCode(ResponseCode.SYSTEM_ERROR); response.setResponseRemark(&quot;Find prepared transaction message failed&quot;); &#125; return response; &#125;&#125; 在 BrokerController 的 initialTransaction() 方法中会初始化事务消息检查类TransactionalMessageCheckService ,该类是一个线程类,在 BrokerController 的 start 方法中通过 startProcessorByHa 方法开启事务消息检查线程.若已经超过最大回查次数,则将消息添加到 TRANS_CHECK_MAXTIME_TOPIC 队列中,若需要检查则将消息写回 RMQ_SYS_TRANS_HALF_TOPIC 队列中防止再次失败,然后调用 AbstractTransactionalMessageCheckListener 的 resolveHalfMsg 方法检查消息. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130public class TransactionalMessageCheckService extends ServiceThread &#123; public void run() &#123; // 默认60s long checkInterval = brokerController.getBrokerConfig().getTransactionCheckInterval(); while (!this.isStopped()) &#123; this.waitForRunning(checkInterval); &#125; &#125; protected void waitForRunning(long interval) &#123; if (hasNotified.compareAndSet(true, false)) &#123; this.onWaitEnd(); return; &#125; waitPoint.reset(); try &#123; waitPoint.await(interval, TimeUnit.MILLISECONDS); &#125; catch (InterruptedException e) &#123; &#125; finally &#123; hasNotified.set(false); this.onWaitEnd(); &#125; &#125; protected void onWaitEnd() &#123; long timeout = brokerController.getBrokerConfig().getTransactionTimeOut(); // 获取超时时间6s int checkMax = brokerController.getBrokerConfig().getTransactionCheckMax(); // 获取最大回查次数15 long begin = System.currentTimeMillis(); this.brokerController.getTransactionalMessageService().check(timeout, checkMax, this.brokerController.getTransactionalMessageCheckListener()); &#125;&#125;public class TransactionalMessageServiceImpl implements TransactionalMessageService &#123; public void check(long transactionTimeout, int transactionCheckMax, AbstractTransactionalMessageCheckListener listener) &#123; try &#123; String topic = TopicValidator.RMQ_SYS_TRANS_HALF_TOPIC; // RMQ_SYS_TRANS_HALF_TOPIC Set&lt;MessageQueue&gt; msgQueues = transactionalMessageBridge.fetchMessageQueues(topic); if (msgQueues == null || msgQueues.size() == 0) &#123; return; &#125; for (MessageQueue messageQueue : msgQueues) &#123; long startTime = System.currentTimeMillis(); MessageQueue opQueue = getOpQueue(messageQueue); long halfOffset = transactionalMessageBridge.fetchConsumeOffset(messageQueue); long opOffset = transactionalMessageBridge.fetchConsumeOffset(opQueue); if (halfOffset &lt; 0 || opOffset &lt; 0) &#123; continue; &#125; List&lt;Long&gt; doneOpOffset = new ArrayList&lt;&gt;(); HashMap&lt;Long, Long&gt; removeMap = new HashMap&lt;&gt;(); PullResult pullResult = fillOpRemoveMap(removeMap, opQueue, opOffset, halfOffset, doneOpOffset); if (null == pullResult) &#123; continue; &#125; int getMessageNullCount = 1; long newOffset = halfOffset; long i = halfOffset; while (true) &#123; if (System.currentTimeMillis() - startTime &gt; MAX_PROCESS_TIME_LIMIT) &#123; break; &#125; if (removeMap.containsKey(i)) &#123; Long removedOpOffset = removeMap.remove(i); doneOpOffset.add(removedOpOffset); &#125; else &#123; GetResult getResult = getHalfMsg(messageQueue, i); // 消费RMQ_SYS_TRANS_HALF_TOPIC队列中的事务消息 MessageExt msgExt = getResult.getMsg(); if (msgExt == null) &#123; if (getMessageNullCount++ &gt; MAX_RETRY_COUNT_WHEN_HALF_NULL) &#123; break; &#125; if (getResult.getPullResult().getPullStatus() == PullStatus.NO_NEW_MSG) &#123; break; &#125; else &#123; i = getResult.getPullResult().getNextBeginOffset(); newOffset = i; continue; &#125; &#125; if (needDiscard(msgExt, transactionCheckMax) || needSkip(msgExt)) &#123;// 若已经超过最大回查次数了 listener.resolveDiscardMsg(msgExt); // 将消息添加到TRANS_CHECK_MAXTIME_TOPIC队列中 newOffset = i + 1; i++; continue; &#125; if (msgExt.getStoreTimestamp() &gt;= startTime) &#123; break; &#125; long valueOfCurrentMinusBorn = System.currentTimeMillis() - msgExt.getBornTimestamp(); long checkImmunityTime = transactionTimeout; String checkImmunityTimeStr = msgExt.getUserProperty(MessageConst.PROPERTY_CHECK_IMMUNITY_TIME_IN_SECONDS); if (null != checkImmunityTimeStr) &#123; checkImmunityTime = getImmunityTime(checkImmunityTimeStr, transactionTimeout); if (valueOfCurrentMinusBorn &lt; checkImmunityTime) &#123; if (checkPrepareQueueOffset(removeMap, doneOpOffset, msgExt)) &#123; newOffset = i + 1; i++; continue; &#125; &#125; &#125; else &#123; if ((0 &lt;= valueOfCurrentMinusBorn) &amp;&amp; (valueOfCurrentMinusBorn &lt; checkImmunityTime)) &#123; break; &#125; &#125; List&lt;MessageExt&gt; opMsg = pullResult.getMsgFoundList(); boolean isNeedCheck = (opMsg == null &amp;&amp; valueOfCurrentMinusBorn &gt; checkImmunityTime) || (opMsg != null &amp;&amp; (opMsg.get(opMsg.size() - 1).getBornTimestamp() - startTime &gt; transactionTimeout)) || (valueOfCurrentMinusBorn &lt;= -1); if (isNeedCheck) &#123; if (!putBackHalfMsgQueue(msgExt, i)) &#123; // 写回RMQ_SYS_TRANS_HALF_TOPIC队列中 continue; &#125; listener.resolveHalfMsg(msgExt); // 真正检查消息的地方,回调客户端checkLocalTransaction方法 &#125; else &#123; pullResult = fillOpRemoveMap(removeMap, opQueue, pullResult.getNextBeginOffset(), halfOffset, doneOpOffset); continue; &#125; &#125; newOffset = i + 1; i++; &#125; if (newOffset != halfOffset) &#123; transactionalMessageBridge.updateConsumeOffset(messageQueue, newOffset); &#125; long newOpOffset = calculateOpOffset(doneOpOffset, opOffset); if (newOpOffset != opOffset) &#123; transactionalMessageBridge.updateConsumeOffset(opQueue, newOpOffset); &#125; &#125; &#125; &#125;&#125; 检查消息是异步执行的,首先还原当前消息真正的Topic,然后通过 Broker2Client 的 checkProducerTransactionState 方法中通过 RequestCode.CHECK_TRANSACTION_STATE 关联调用 ClientRemotingProcessor 的 ClientRemotingProcessor 方法. 123456789101112131415161718192021222324252627282930313233343536373839public abstract class AbstractTransactionalMessageCheckListener &#123; public void resolveHalfMsg(final MessageExt msgExt) &#123; executorService.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; sendCheckMessage(msgExt); &#125; catch (Exception e) &#123; &#125; &#125; &#125;); &#125; public void sendCheckMessage(MessageExt msgExt) throws Exception &#123; CheckTransactionStateRequestHeader checkTransactionStateRequestHeader = new CheckTransactionStateRequestHeader(); checkTransactionStateRequestHeader.setCommitLogOffset(msgExt.getCommitLogOffset()); checkTransactionStateRequestHeader.setOffsetMsgId(msgExt.getMsgId()); checkTransactionStateRequestHeader.setMsgId(msgExt.getUserProperty(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX)); checkTransactionStateRequestHeader.setTransactionId(checkTransactionStateRequestHeader.getMsgId()); checkTransactionStateRequestHeader.setTranStateTableOffset(msgExt.getQueueOffset()); msgExt.setTopic(msgExt.getUserProperty(MessageConst.PROPERTY_REAL_TOPIC)); // 真正的Topic msgExt.setQueueId(Integer.parseInt(msgExt.getUserProperty(MessageConst.PROPERTY_REAL_QUEUE_ID))); msgExt.setStoreSize(0); String groupId = msgExt.getProperty(MessageConst.PROPERTY_PRODUCER_GROUP); Channel channel = brokerController.getProducerManager().getAvaliableChannel(groupId); if (channel != null) &#123; brokerController.getBroker2Client().checkProducerTransactionState(groupId, channel, checkTransactionStateRequestHeader, msgExt); &#125; &#125;&#125;public class Broker2Client &#123; public void checkProducerTransactionState(final String group, final Channel channel, final CheckTransactionStateRequestHeader requestHeader, final MessageExt messageExt) throws Exception &#123; RemotingCommand request = RemotingCommand.createRequestCommand(RequestCode.CHECK_TRANSACTION_STATE, requestHeader); request.setBody(MessageDecoder.encode(messageExt, false)); try &#123; this.brokerController.getRemotingServer().invokeOneway(channel, request, 10); &#125; catch (Exception e) &#123; &#125; &#125;&#125; 首先调用自定义 TransactionListener 的 checkLocalTransaction 方法,然后调用 MQClientAPIImpl 的 endTransactionOneway 方法.最终又调用 EndTransactionProcessor 的 processRequest 方法. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596public class ClientRemotingProcessor extends AsyncNettyRequestProcessor implements NettyRequestProcessor &#123; public class ClientRemotingProcessor extends AsyncNettyRequestProcessor implements NettyRequestProcessor &#123; public RemotingCommand checkTransactionState(ChannelHandlerContext ctx, RemotingCommand request) throws RemotingCommandException &#123; final CheckTransactionStateRequestHeader requestHeader = (CheckTransactionStateRequestHeader) request.decodeCommandCustomHeader(CheckTransactionStateRequestHeader.class); final ByteBuffer byteBuffer = ByteBuffer.wrap(request.getBody()); final MessageExt messageExt = MessageDecoder.decode(byteBuffer); if (messageExt != null) &#123; if (StringUtils.isNotEmpty(this.mqClientFactory.getClientConfig().getNamespace())) &#123; messageExt.setTopic(NamespaceUtil.withoutNamespace(messageExt.getTopic(), this.mqClientFactory.getClientConfig().getNamespace())); &#125; String transactionId = messageExt.getProperty(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX); if (null != transactionId &amp;&amp; !&quot;&quot;.equals(transactionId)) &#123; messageExt.setTransactionId(transactionId); &#125; final String group = messageExt.getProperty(MessageConst.PROPERTY_PRODUCER_GROUP); if (group != null) &#123; MQProducerInner producer = this.mqClientFactory.selectProducer(group); if (producer != null) &#123; final String addr = RemotingHelper.parseChannelRemoteAddr(ctx.channel()); producer.checkTransactionState(addr, messageExt, requestHeader); &#125; &#125; &#125; return null; &#125; &#125;&#125;public class DefaultMQProducerImpl implements MQProducerInner &#123; public void checkTransactionState(final String addr, final MessageExt msg, final CheckTransactionStateRequestHeader header) &#123; Runnable request = new Runnable() &#123; private final String brokerAddr = addr; private final MessageExt message = msg; private final CheckTransactionStateRequestHeader checkRequestHeader = header; private final String group = DefaultMQProducerImpl.this.defaultMQProducer.getProducerGroup(); @Override public void run() &#123; TransactionCheckListener transactionCheckListener = DefaultMQProducerImpl.this.checkListener(); TransactionListener transactionListener = getCheckListener(); if (transactionCheckListener != null || transactionListener != null) &#123; LocalTransactionState localTransactionState = LocalTransactionState.UNKNOW; Throwable exception = null; try &#123; if (transactionCheckListener != null) &#123; localTransactionState = transactionCheckListener.checkLocalTransactionState(message); &#125; else if (transactionListener != null) &#123; localTransactionState = transactionListener.checkLocalTransaction(message); &#125; &#125; catch (Throwable e) &#123; exception = e; &#125; this.processTransactionState(localTransactionState, group, exception); &#125; &#125; private void processTransactionState(final LocalTransactionState localTransactionState, final String producerGroup, final Throwable exception) &#123; final EndTransactionRequestHeader thisHeader = new EndTransactionRequestHeader(); thisHeader.setCommitLogOffset(checkRequestHeader.getCommitLogOffset()); thisHeader.setProducerGroup(producerGroup); thisHeader.setTranStateTableOffset(checkRequestHeader.getTranStateTableOffset()); thisHeader.setFromTransactionCheck(true); String uniqueKey = message.getProperties().get(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX); if (uniqueKey == null) &#123; uniqueKey = message.getMsgId(); &#125; thisHeader.setMsgId(uniqueKey); thisHeader.setTransactionId(checkRequestHeader.getTransactionId()); switch (localTransactionState) &#123; case COMMIT_MESSAGE: thisHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_COMMIT_TYPE); break; case ROLLBACK_MESSAGE: thisHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_ROLLBACK_TYPE); break; case UNKNOW: thisHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_NOT_TYPE); break; default: break; &#125; String remark = null; if (exception != null) &#123; remark = &quot;checkLocalTransactionState Exception: &quot; + RemotingHelper.exceptionSimpleDesc(exception); &#125; try &#123; DefaultMQProducerImpl.this.mQClientFactory.getMQClientAPIImpl().endTransactionOneway(brokerAddr, thisHeader, remark, 3000); &#125; catch (Exception e) &#123; &#125; &#125; &#125;; this.checkExecutor.submit(request); &#125;&#125;public void endTransactionOneway(final String addr, final EndTransactionRequestHeader requestHeader, final String remark, final long timeoutMillis) throws RemotingException, MQBrokerException, InterruptedException &#123; RemotingCommand request = RemotingCommand.createRequestCommand(RequestCode.END_TRANSACTION, requestHeader); request.setRemark(remark); this.remotingClient.invokeOneway(addr, request, timeoutMillis);&#125; 延迟消息 延迟消息写入时会将延迟消息转为写入到SCHEDULE_TOPIC_XXXX的Topic中,系统内置的该Topic有 18 个队列,对应18个延迟级别. ScheduleMessageService 会每隔1s 执行一次 DeliverDelayedMessageTimerTask.executeOnTimeup 任务,将消息从延迟队列中写入正常Topic中. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107public class ScheduleMessageService extends ConfigManager &#123; private static final long FIRST_DELAY_TIME = 1000L; private static final long DELAY_FOR_A_WHILE = 100L; private static final long DELAY_FOR_A_PERIOD = 10000L; public void start() &#123; // 延迟消息服务的启动方法 if (started.compareAndSet(false, true)) &#123; this.timer = new Timer(&quot;ScheduleMessageTimerThread&quot;, true); for (Map.Entry&lt;Integer, Long&gt; entry : this.delayLevelTable.entrySet()) &#123; Integer level = entry.getKey(); Long timeDelay = entry.getValue(); Long offset = this.offsetTable.get(level); if (null == offset) &#123; offset = 0L; &#125; if (timeDelay != null) &#123;//定时执行延迟消息处理任务 this.timer.schedule(new DeliverDelayedMessageTimerTask(level, offset), FIRST_DELAY_TIME); &#125; &#125; this.timer.scheduleAtFixedRate(new TimerTask() &#123; //每隔10秒,将延迟消息持久化到硬盘中. @Override public void run() &#123; try &#123; if (started.get()) ScheduleMessageService.this.persist(); &#125; catch (Throwable e) &#123; &#125; &#125; &#125;, 10000, this.defaultMessageStore.getMessageStoreConfig().getFlushDelayOffsetInterval()); &#125; &#125;&#125;class DeliverDelayedMessageTimerTask extends TimerTask &#123; public void run() &#123; try &#123; if (isStarted()) &#123; this.executeOnTimeup(); &#125; &#125; catch (Exception e) &#123; ScheduleMessageService.this.timer.schedule(new DeliverDelayedMessageTimerTask(this.delayLevel, this.offset), DELAY_FOR_A_PERIOD); &#125; &#125; public void executeOnTimeup() &#123; // 拿到延迟级别对应的队列 ConsumeQueue cq = ScheduleMessageService.this.defaultMessageStore.findConsumeQueue(TopicValidator.RMQ_SYS_SCHEDULE_TOPIC, delayLevel2QueueId(delayLevel)); long failScheduleOffset = offset; if (cq != null) &#123; SelectMappedBufferResult bufferCQ = cq.getIndexBuffer(this.offset); if (bufferCQ != null) &#123; try &#123; long nextOffset = offset; int i = 0; ConsumeQueueExt.CqExtUnit cqExtUnit = new ConsumeQueueExt.CqExtUnit(); // 遍历每个延迟队列的消息 for (; i &lt; bufferCQ.getSize(); i += ConsumeQueue.CQ_STORE_UNIT_SIZE) &#123; long offsetPy = bufferCQ.getByteBuffer().getLong(); int sizePy = bufferCQ.getByteBuffer().getInt(); long tagsCode = bufferCQ.getByteBuffer().getLong(); if (cq.isExtAddr(tagsCode)) &#123; if (cq.getExt(tagsCode, cqExtUnit)) &#123; tagsCode = cqExtUnit.getTagsCode(); &#125; &#125; long now = System.currentTimeMillis(); long deliverTimestamp = this.correctDeliverTimestamp(now, tagsCode); nextOffset = offset + (i / ConsumeQueue.CQ_STORE_UNIT_SIZE); long countdown = deliverTimestamp - now; if (countdown &lt;= 0) &#123; //把每个延迟消息封装成一个MessageExt MessageExt msgExt = ScheduleMessageService.this.defaultMessageStore.lookMessageByOffset(offsetPy, sizePy); if (msgExt != null) &#123; try &#123; MessageExtBrokerInner msgInner = this.messageTimeup(msgExt); if (TopicValidator.RMQ_SYS_TRANS_HALF_TOPIC.equals(msgInner.getTopic())) &#123; continue; &#125; //将延迟消息写入正常消息队列,这样就能被消费者正常消费了. PutMessageResult putMessageResult = ScheduleMessageService.this.writeMessageStore.putMessage(msgInner); if (putMessageResult != null &amp;&amp; putMessageResult.getPutMessageStatus() == PutMessageStatus.PUT_OK) &#123; continue; &#125; else &#123; ScheduleMessageService.this.timer.schedule(new DeliverDelayedMessageTimerTask(this.delayLevel, nextOffset), DELAY_FOR_A_PERIOD); ScheduleMessageService.this.updateOffset(this.delayLevel, nextOffset); return; &#125; &#125; catch (Exception e) &#123; &#125; &#125; &#125; else &#123; ScheduleMessageService.this.timer.schedule(new DeliverDelayedMessageTimerTask(this.delayLevel, nextOffset), countdown); ScheduleMessageService.this.updateOffset(this.delayLevel, nextOffset); return; &#125; &#125; // end of for nextOffset = offset + (i / ConsumeQueue.CQ_STORE_UNIT_SIZE); ScheduleMessageService.this.timer.schedule(new DeliverDelayedMessageTimerTask(this.delayLevel, nextOffset), DELAY_FOR_A_WHILE); ScheduleMessageService.this.updateOffset(this.delayLevel, nextOffset); return; &#125; finally &#123; bufferCQ.release(); &#125; &#125; else &#123; // end of if (bufferCQ != null) long cqMinOffset = cq.getMinOffsetInQueue(); if (offset &lt; cqMinOffset) &#123; failScheduleOffset = cqMinOffset; &#125; &#125; &#125; // end of if (cq != null) ScheduleMessageService.this.timer.schedule(new DeliverDelayedMessageTimerTask(this.delayLevel, failScheduleOffset), DELAY_FOR_A_WHILE); &#125;&#125;","tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"http://example.com/tags/RocketMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RocketMQ","slug":"工具和中间件/消息队列/RocketMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RocketMQ/"}]},{"title":"RocketMQ-基础","date":"2019-04-23T02:08:20.000Z","path":"blog/工具和中间件/消息队列/RocketMQ/RocketMQ-基础/","text":"介绍Apache RocketMQ作为阿里开源的一款高性能、高吞吐量的分布式消息中间件. RocketMQ架构 生产者-Producer消息发布的角色,支持分布式集群方式部署.Producer 通过MQ的负载均衡模块 选择相应的 Broker集群队列 进行消息投递,投递的过程支持 快速失败 并且 低延迟. Producer启动后会 随机选择 NameServer集群中 其中一个节点建立长连接,定期从NameServer获取 Topic路由信息,并判断 当前订阅Topic存在哪些Broker上, 轮询从队列列表中选择一个队列,并向 提供Topic服务的队列所在的Master建立长连接,且 定时向Master发送心跳. Producer 完全无状态,可集群部署. 消费者-Consumer消息消费的角色,支持分布式集群方式部署.支持以 Push推,Pull拉两种模式对消息进行消费.同时支持集群方式和广播方式消费,提供实时消息订阅机制. Consumer启动后会随机选择NameServer集群中其中一个节点建立长连接,定期从NameServer获取 Topic路由信息,并判断当前订阅Topic存在哪些Broker上,并向提供Topic服务的Master、Slave建立长连接,且定时向Master、Slave发送心跳.Consumer既可从Master订阅消息,也可从Slave订阅消息,消费者在向Master拉取消息时,Master服务器会根据拉取偏移量与最大偏移量的距离,判断是否读老消息产生读I&#x2F;O,以及从服务器是否可读等因素建议下一次是从Master还是Slave拉取. NameServerNameServer一个非常简单的 Topic路由注册中心,支持Broker动态注册与发现.通常也是集群方式部署,各实例间不信息通讯. Broker 向每台NameServer注册自己的路由信息,故每个NameServer实例上都保存一份完整的路由信息.若当某个NameServer因某种原因下线,Broker仍可向其它NameServer同步其路由信息,Producer和Consumer仍可动态感知Broker路由信息. NameServer 主要包括 Broker管理和路由信息管理两个功能： Broker管理： NameServer 接受Broker集群的注册信息且保存作为路由信息基本数据.提供心跳检测机制,检查Broker是否存活； 路由信息管理,每个 NameServer 将保存关于Broker集群的整个路由信息和用于客户端查询的队列信息.然后 Producer 和 Conumser 通过 NameServer 可知道整个Broker集群的路由信息,从而进行消息的投递和消费. NameServer是一个几乎无状态节点,可集群部署,节点之间无任何信息同步.NameServer启动后监听端口,等待Broker、Producer、Consumer连接,相当于一个路由控制中心. BrokerServerBroker主要负责消息的存储、投递和查询以及服务高可用保证,为了实现这些功能,Broker包含了以下几个重要子模块. Remoting Module ：整个Broker的实体,负责处理来自clients端的请求. Client Manager ：负责管理Producer和Consumer客户端和维护Consumer的Topic订阅信息 Store Service ：提供方便简单的API接口处理消息存储到物理硬盘和查询功能. HA Service ：高可用服务,提供 Master Broker 和 Slave Broker 之间的数据同步功能. Index Service ：根据特定Message key对投递到Broker的消息进行索引服务,以提供消息的快速查询. Broker分为Master与Slave ,一个Master可对应多个Slave,一个Slave只能对应一个Master,Master与Slave对应关系通过指定相同的BrokerName不同BrokerId 来定义, BrokerId为0表示Master ,非0表示Slave .Master可部署多个.每个Broker 与NameServer集群中的所有节点建立长连接,定时注册Topic信息到所有NameServer. 虽然支持一Master多Slave,但只有 BrokerId=1 的从服务器才会参与消息读负载.Broker启动后跟所有的NameServer保持长连接,定时发送心跳包.心跳包中包含当前Broker如IP、端口等信息,以及存储所有Topic信息.注册成功后NameServer集群中就有 Topic与Broker映射关系. RocketMQ使用基本样例生产者发送消息有同步发送、异步发送和单向发送三种方式:单向发送使用 sendOneway 方法来发送消息,该方法无返回值无回调. 12345678DefaultMQProducer producer = new DefaultMQProducer(&quot;ProducerGroupName&quot;);producer.setNamesrvAddr(&quot;localhost:9876&quot;);producer.start();for (int i = 0; i &lt; 20; i++) &#123; Message msg = new Message(&quot;TopicTest&quot;, &quot;TagA&quot;, &quot;OrderID188&quot;, &quot;Hello world&quot;.getBytes(RemotingHelper.DEFAULT_CHARSET)); producer.sendOneway(msg);&#125;producer.shutdown(); 同步发送使用 send 方法同步传递消息,消息会发给集群中的一个Broker节点 123456789DefaultMQProducer producer = new DefaultMQProducer(&quot;ProducerGroupName&quot;);producer.setNamesrvAddr(&quot;localhost:9876&quot;);producer.start();for (int i = 0; i &lt; 20; i++) &#123; Message msg = new Message(&quot;TopicTest&quot;, &quot;TagA&quot;, &quot;OrderID188&quot;, &quot;Hello world&quot;.getBytes(RemotingHelper.DEFAULT_CHARSET)); SendResult sendResult = producer.send(msg); System.out.printf(&quot;%s%n&quot;, sendResult);&#125;producer.shutdown(); 由于是异步发送,这里引入了CountDownLatch,保证所有Producer发送消息的回调方法都执行完了再停止Producer服务. 12345678910111213141516171819202122232425DefaultMQProducer producer = new DefaultMQProducer(&quot;Jodie_Daily_test&quot;);producer.setNamesrvAddr(&quot;localhost:9876&quot;);producer.start();producer.setRetryTimesWhenSendAsyncFailed(0);int messageCount = 100;final CountDownLatch countDownLatch = new CountDownLatch(messageCount);for (int i = 0; i &lt; messageCount; i++) &#123; final int index = i; Message msg = new Message(&quot;TopicTest&quot;, &quot;TagA&quot;, &quot;OrderID188&quot;, &quot;Hello world&quot;.getBytes(RemotingHelper.DEFAULT_CHARSET)); producer.send(msg, new SendCallback() &#123; @Override public void onSuccess(SendResult sendResult) &#123; countDownLatch.countDown(); System.out.printf(&quot;%-10d OK %s %n&quot;, index, sendResult.getMsgId()); &#125; @Override public void onException(Throwable e) &#123; countDownLatch.countDown(); System.out.printf(&quot;%-10d Exception %s %n&quot;, index, e); e.printStackTrace(); &#125; &#125;);&#125;countDownLatch.await(5, TimeUnit.SECONDS);producer.shutdown(); 消费者消费消息有两种模式：消费者主动去Broker上拉取消息的拉模式；消费者等待Broker把消息推送过来的推模式. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394public class PullConsumer &#123; private static final Map&lt;MessageQueue, Long&gt; OFFSE_TABLE = new HashMap&lt;MessageQueue, Long&gt;(); public static void main(String[] args) throws MQClientException &#123; DefaultMQPullConsumer consumer = new DefaultMQPullConsumer(&quot;please_rename_unique_group_name_5&quot;); consumer.setNamesrvAddr(&quot;localhost:9876&quot;); consumer.start(); Set&lt;MessageQueue&gt; mqs = consumer.fetchSubscribeMessageQueues(&quot;TopicTest&quot;); for (MessageQueue mq : mqs) &#123; System.out.printf(&quot;Consume from the queue: %s%n&quot;, mq); SINGLE_MQ: while (true) &#123; try &#123; PullResult pullResult = consumer.pullBlockIfNotFound(mq, null, getMessageQueueOffset(mq), 32); System.out.printf(&quot;%s%n&quot;, pullResult); putMessageQueueOffset(mq, pullResult.getNextBeginOffset()); if (pullResult.getMsgFoundList() != null) &#123; for (MessageExt messageExt : pullResult.getMsgFoundList()) &#123; System.out.println(&quot;messageExt：&quot; + messageExt); &#125; &#125; switch (pullResult.getPullStatus()) &#123; case FOUND: break; case NO_MATCHED_MSG: break; case NO_NEW_MSG: break SINGLE_MQ; case OFFSET_ILLEGAL: break; default: break; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; consumer.shutdown(); &#125; private static long getMessageQueueOffset(MessageQueue mq) &#123; Long offset = OFFSE_TABLE.get(mq); if (offset != null) &#123; return offset; &#125; return 0; &#125; private static void putMessageQueueOffset(MessageQueue mq, long offset) &#123; OFFSE_TABLE.put(mq, offset); &#125;&#125;public class LitePullConsumerAssign &#123; public static volatile boolean running = true; public static void main(String[] args) throws Exception &#123; DefaultLitePullConsumer litePullConsumer = new DefaultLitePullConsumer(&quot;please_rename_unique_group_name&quot;); litePullConsumer.setNamesrvAddr(&quot;localhost:9876&quot;); litePullConsumer.setAutoCommit(false); litePullConsumer.start(); Collection&lt;MessageQueue&gt; mqSet = litePullConsumer.fetchMessageQueues(&quot;TopicTest&quot;); List&lt;MessageQueue&gt; list = new ArrayList&lt;&gt;(mqSet); List&lt;MessageQueue&gt; assignList = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; list.size(); i++) &#123; assignList.add(list.get(i)); &#125; litePullConsumer.assign(assignList); litePullConsumer.seek(assignList.get(0), 10); try &#123; while (running) &#123; List&lt;MessageExt&gt; messageExts = litePullConsumer.poll(); System.out.printf(&quot;%s %n&quot;, messageExts); litePullConsumer.commitSync(); &#125; &#125; finally &#123; litePullConsumer.shutdown(); &#125; &#125;&#125;public class LitePullConsumerSubscribe &#123; public static volatile boolean running = true; public static void main(String[] args) throws Exception &#123; DefaultLitePullConsumer litePullConsumer = new DefaultLitePullConsumer(&quot;lite_pull_consumer_test&quot;); litePullConsumer.setNamesrvAddr(&quot;localhost:9876&quot;); litePullConsumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET); litePullConsumer.subscribe(&quot;TopicTest&quot;, &quot;*&quot;); litePullConsumer.start(); try &#123; while (running) &#123; List&lt;MessageExt&gt; messageExts = litePullConsumer.poll(); System.out.printf(&quot;%s%n&quot;, messageExts); &#125; &#125; finally &#123; litePullConsumer.shutdown(); &#125; &#125;&#125; 消费者推模式 123456789101112DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;CID_JODIE_1&quot;);consumer.setNamesrvAddr(&quot;localhost:9876&quot;);consumer.subscribe(&quot;TopicTest&quot;, &quot;*&quot;);consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; System.out.printf(&quot;%s Receive New Messages: %s %n&quot;, Thread.currentThread().getName(), msgs); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125;&#125;);consumer.start(); 顺序消息发送者端默认情况下,消息发送者会采取 Round Robin轮询方式把消息发送到不同MessageQueue分区队列,消费者消费时也从多个MessageQueue上拉取消息,该情况下消息是不能保证顺序的.仅当一组有序的消息发送到同一个MessageQueue时,才能利用MessageQueue先进先出的特性保证这一组消息有序.而Broker中一个队列内的消息是可以保证有序的. 消费者端消费者会从多个消息队列取消息.虽然每个消息队列消息是有序的,但多个队列之间消息仍是乱序的.消费者端要保证消息有序,就需要按队列一个一个来取消息,即取完一个队列的消息后,再去取下一个队列的消息.而给Consumer注入的 MessageListenerOrderly 对象,在RocketMQ内部就会通过锁队列的方式保证消息是一个一个队列来取的. MessageListenerConcurrently 消息监听器则不会锁队列,每次都是从多个Message中取一批数据,默认不超过32条,因此也无法保证消息有序. 发送者端: 12345678910111213141516171819DefaultMQProducer producer = new DefaultMQProducer(&quot;please_rename_unique_group_name&quot;);producer.setNamesrvAddr(&quot;localhost:9876&quot;);producer.start();for (int i = 0; i &lt; 10; i++) &#123; int orderId = i; for (int j = 0; j &lt;= 5; j++) &#123; Message msg = new Message(&quot;OrderTopicTest&quot;, &quot;order_&quot; + orderId, &quot;KEY&quot; + orderId, (&quot;order_&quot; + orderId + &quot; step &quot; + j).getBytes(RemotingHelper.DEFAULT_CHARSET)); SendResult sendResult = producer.send(msg, new MessageQueueSelector() &#123; @Override public MessageQueue select(List&lt;MessageQueue&gt; mqs, Message msg, Object arg) &#123; Integer id = (Integer) arg; int index = id % mqs.size(); return mqs.get(index); &#125; &#125;, orderId); System.out.printf(&quot;%s%n&quot;, sendResult); &#125;&#125;producer.shutdown(); 消费者端: 123456789101112131415DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;please_rename_unique_group_name_3&quot;);consumer.setNamesrvAddr(&quot;localhost:9876&quot;);consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_LAST_OFFSET);consumer.subscribe(&quot;OrderTopicTest&quot;, &quot;*&quot;);consumer.registerMessageListener(new MessageListenerOrderly() &#123; @Override public ConsumeOrderlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeOrderlyContext context) &#123; context.setAutoCommit(true); for (MessageExt msg : msgs) &#123; System.out.println(&quot;收到消息内容 &quot; + new String(msg.getBody())); &#125; return ConsumeOrderlyStatus.SUCCESS; &#125;&#125;);consumer.start(); 广播消息在集群状态MessageModel.CLUSTERING 下,每条消息只会被同一个消费者组中的一个实例消费到.而广播模式则是把消息模式设置为 MessageModel.BROADCASTING ,将给所有订阅对应主题的消费者发送消息,而不管消费者是不是同一个消费者组. 12345678910111213DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;please_rename_unique_group_name_1&quot;);consumer.setNamesrvAddr(&quot;localhost:9876&quot;);consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_LAST_OFFSET);consumer.setMessageModel(MessageModel.BROADCASTING); // 将消息模式设置为BROADCASTINGconsumer.subscribe(&quot;TopicTest&quot;, &quot;*&quot;);consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; System.out.printf(&quot;%s Receive New Messages: %s %n&quot;, Thread.currentThread().getName(), msgs); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125;&#125;);consumer.start(); 延迟消息延迟时间的设置是在Message消息对象上设置一个延迟级别 setDelayTimeLevel(3) ,开源版RocketMQ中,对延迟消息并不支持任意时间的延迟设定,而是只支持18个固定的延迟级别,1到18分别对应 messageDelayLevel=1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h .这18个延迟级别也支持自行定义,不过一般情况下最好不要自定义修改. 12345678910DefaultMQProducer producer = new DefaultMQProducer(&quot;please_rename_unique_group_name&quot;); // 分组名称producer.setNamesrvAddr(&quot;localhost:9876&quot;);producer.start();for (int i = 0; i &lt; 2; i++) &#123; Message msg = new Message(&quot;TopicTest&quot;, &quot;TagA&quot;, (&quot;Hello RocketMQ &quot; + i).getBytes(RemotingHelper.DEFAULT_CHARSET)); // messageDelayLevel=1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h msg.setDelayTimeLevel(3); // 延时队列 SendResult sendResult = producer.send(msg);&#125;producer.shutdown(); 批量消息将多条消息合并成一个批量消息,一次发送出去,可减少网络IO,提升吞吐量.批量消息的使用有一定限制,这些消息 Topic和waitStoreMsgOK必须相同,且不能是延迟消息、事务消息等. 12345678910DefaultMQProducer producer = new DefaultMQProducer(&quot;BatchProducerGroupName&quot;);producer.setNamesrvAddr(&quot;localhost:9876&quot;);producer.start();String topic = &quot;BatchTest&quot;;List&lt;Message&gt; messages = new ArrayList&lt;&gt;();messages.add(new Message(topic, &quot;Tag&quot;, &quot;OrderID001&quot;, &quot;Hello world 0&quot;.getBytes()));messages.add(new Message(topic, &quot;Tag&quot;, &quot;OrderID002&quot;, &quot;Hello world 1&quot;.getBytes()));messages.add(new Message(topic, &quot;Tag&quot;, &quot;OrderID003&quot;, &quot;Hello world 2&quot;.getBytes()));producer.send(messages);producer.shutdown(); 若批量消息大于1MB 就不要用一个批次发送,而要拆分成多个批次消息发送.实际最大的限制是4194304字节约 4MB ； 123456789101112131415DefaultMQProducer producer = new DefaultMQProducer(&quot;BatchProducerGroupName&quot;);producer.setNamesrvAddr(&quot;localhost:9876&quot;);producer.start();String topic = &quot;BatchTest&quot;;List&lt;Message&gt; messages = new ArrayList&lt;&gt;(100 * 1000);for (int i = 0; i &lt; 100 * 1000; i++) &#123; messages.add(new Message(topic, &quot;Tag&quot;, &quot;OrderID&quot; + i, (&quot;Hello world &quot; + i).getBytes()));&#125;producer.send(messages);ListSplitter splitter = new ListSplitter(messages);while (splitter.hasNext()) &#123; List&lt;Message&gt; listItem = splitter.next(); producer.send(listItem);&#125;producer.shutdown(); 12345678910111213141516171819202122232425262728293031323334353637383940class ListSplitter implements Iterator&lt;List&lt;Message&gt;&gt; &#123; private final List&lt;Message&gt; messages; private int sizeLimit = 1000 * 1000; private int currIndex; public ListSplitter(List&lt;Message&gt; messages) &#123; this.messages = messages; &#125; @Override public boolean hasNext() &#123; return currIndex &lt; messages.size(); &#125; @Override public List&lt;Message&gt; next() &#123; int nextIndex = currIndex; int totalSize = 0; for (; nextIndex &lt; messages.size(); nextIndex++) &#123; Message message = messages.get(nextIndex); int tmpSize = message.getTopic().length() + message.getBody().length; Map&lt;String, String&gt; properties = message.getProperties(); for (Map.Entry&lt;String, String&gt; entry : properties.entrySet()) &#123; tmpSize += entry.getKey().length() + entry.getValue().length(); &#125; tmpSize = tmpSize + 20; //for log overhead if (tmpSize &gt; sizeLimit) &#123; if (nextIndex - currIndex == 0) &#123; nextIndex++; &#125; break; &#125; if (tmpSize + totalSize &gt; sizeLimit) &#123; break; &#125; else &#123; totalSize += tmpSize; &#125; &#125; List&lt;Message&gt; subList = messages.subList(currIndex, nextIndex); currIndex = nextIndex; return subList; &#125;&#125; 过滤消息可使用Message的 Tag属性来简单快速的过滤信息,TAG是RocketMQ中特有的一个消息属性,一个应用可以就用一个Topic,而应用中的不同业务就用TAG来区分. 1234567891011DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;please_rename_unique_group_name&quot;);consumer.setNamesrvAddr(&quot;localhost:9876&quot;);consumer.subscribe(&quot;TagFilterTest&quot;, &quot;TagA || TagC&quot;);consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; System.out.printf(&quot;%s Receive New Messages: %s %n&quot;, Thread.currentThread().getName(), msgs); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125;&#125;);consumer.start(); 一个消息只能有一个TAG ,不能满足一些比较复杂的场景. 可使用 SQL表达式来对消息进行过滤,但只有推模式的消费者可使用SQL过滤.拉模式是用不了的.RocketMQ只定义了一些基本语法来支持这个特性.也可很容易地扩展它. 数值比较： &gt;、&gt;=、&lt;、&lt;=、BETWEEN、= 字符比较： =、&lt;&gt;、IN、IS NULL、IS NOT NULL 逻辑符号： AND、OR、NOT 数值：123,3.1415；字符： &#39;abc&#39; ；必须用单引号包裹起来 特殊常量：NULL,布尔值TRUE或FALSE12345678910111213141516171819202122DefaultMQProducer producer = new DefaultMQProducer(&quot;please_rename_unique_group_name&quot;);producer.start();String[] tags = new String[]&#123;&quot;TagA&quot;, &quot;TagB&quot;, &quot;TagC&quot;&#125;;for (int i = 0; i &lt; 15; i++) &#123; Message msg = new Message(&quot;SqlFilterTest&quot;, tags[i % tags.length], (&quot;Hello RocketMQ &quot; + i).getBytes(RemotingHelper.DEFAULT_CHARSET)); msg.putUserProperty(&quot;a&quot;, String.valueOf(i)); // 自定义字段 SendResult sendResult = producer.send(msg); System.out.printf(&quot;%s%n&quot;, sendResult);&#125;producer.shutdown();// 消费者示例DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;please_rename_unique_group_name&quot;);consumer.setNamesrvAddr(&quot;localhost:9876&quot;);consumer.subscribe(&quot;SqlFilterTest&quot;, MessageSelector.bySql(&quot;(TAGS is not null and TAGS in (&#x27;TagA&#x27;, &#x27;TagB&#x27;))and (a is not null and a between 0 and 3)&quot;));consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; System.out.printf(&quot;%s Receive New Messages: %s %n&quot;, Thread.currentThread().getName(), msgs); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125;&#125;);consumer.start(); 事务消息事务消息是在分布式系统中保证最终一致性的两阶段提交的消息实现,可保证本地事务执行与消息发送两个操作的原子性,事务消息只涉及到消息发送者,对消息消费者来说没有什么特别,即只保证了分布式事务的一半.事务消息的关键是在 TransactionMQProducer 中指定了一个 TransactionListener事务监听器,该事务监听器就是事务消息的关键控制器； 123456789101112131415161718192021222324TransactionListener transactionListener = new TransactionListenerImpl();TransactionMQProducer producer = new TransactionMQProducer(&quot;please_rename_unique_group_name&quot;);producer.setNamesrvAddr(&quot;127.0.0.1:9876&quot;);ExecutorService executorService = new ThreadPoolExecutor(2, 5, 100, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(2000), new ThreadFactory() &#123; @Override public Thread newThread(Runnable r) &#123; Thread thread = new Thread(r); thread.setName(&quot;client-transaction-msg-check-thread&quot;); return thread; &#125;&#125;);producer.setExecutorService(executorService);producer.setTransactionListener(transactionListener);producer.start();String[] tags = new String[]&#123;&quot;TagA&quot;, &quot;TagB&quot;, &quot;TagC&quot;, &quot;TagD&quot;, &quot;TagE&quot;&#125;;for (int i = 0; i &lt; 10; i++) &#123; Message msg = new Message(&quot;TopicTest&quot;, tags[i % tags.length], &quot;KEY&quot; + i, (&quot;Hello RocketMQ &quot; + i).getBytes(RemotingHelper.DEFAULT_CHARSET)); msg.putUserProperty(MessageConst.PROPERTY_TRANSACTION_CHECK_TIMES, &quot;15&quot;); // 回查次数 msg.putUserProperty(MessageConst.PROPERTY_CHECK_IMMUNITY_TIME_IN_SECONDS, &quot;10000&quot;); // 回查时间 SendResult sendResult = producer.sendMessageInTransaction(msg, null); System.out.printf(&quot;%s%n&quot;, sendResult); Thread.sleep(10);&#125;producer.shutdown(); 123456789101112131415161718192021222324public class TransactionListenerImpl implements TransactionListener &#123; @Override public LocalTransactionState executeLocalTransaction(Message msg, Object arg) &#123; String tags = msg.getTags(); if (StringUtils.contains(tags, &quot;TagA&quot;)) &#123; return LocalTransactionState.COMMIT_MESSAGE; &#125; else if (StringUtils.contains(tags, &quot;TagB&quot;)) &#123; return LocalTransactionState.ROLLBACK_MESSAGE; &#125; else &#123; return LocalTransactionState.UNKNOW; &#125; &#125; @Override public LocalTransactionState checkLocalTransaction(MessageExt msg) &#123; String tags = msg.getTags(); if (StringUtils.contains(tags, &quot;TagC&quot;)) &#123; return LocalTransactionState.COMMIT_MESSAGE; &#125; else if (StringUtils.contains(tags, &quot;TagD&quot;)) &#123; return LocalTransactionState.ROLLBACK_MESSAGE; &#125; else &#123; return LocalTransactionState.UNKNOW; &#125; &#125;&#125; 事务消息不支持延迟消息和批量消息,为了避免单个消息被检查太多次而导致队列消息累积,回查次数由BrokerConfig.transactionCheckMax参数来配置,默认15次,可在 broker.conf 中覆盖,实际检查次数会在message中保存一个用户属性 MessageConst.PROPERTY_TRANSACTION_CHECK_TIMES .该属性值大于transactionCheckMax 则丢弃,默认情况下同时打印错误日志,可通过重写 AbstractTransactionCheckListener 类来修改该行为. 该用户属性值按回查次数递增,也可在Producer中自行覆盖该属性. 回查时间间隔由 BrokerConfig.transactionTimeOut 参数来配置,默认6秒,可在broker.conf中修改,也可给消息配置一个 MessageConst.PROPERTY_CHECK_IMMUNITY_TIME_IN_SECONDS 属性来给消息指定一个特定的消息回查时间. 事务性消息可能不止一次被检查或消费；提交给用户的目标主题消息可能会失败,目前以日志的记录而定.其高可用性通过RocketMQ本身的高可用性机制来保证,若希望确保事务消息不丢失、且事务完整性得到保证,建议使用同步双重写入机制. 事务消息的生产者ID不能与其他类型消息的生产者ID共享.与其他类型的消息不同,事务消息允许反向查询,MQ服务器能通过事务消息的生产者ID查询到消费者. 事务消息机制在发送消息时,会将消息转为一个 half半消息,并存入RocketMQ内部的一个 RMQ_SYS_TRANS_HALF_TOPIC ,该Topic对消费者不可见,然后执行本地事务执行commit提交,则Broker会将投递到 RMQ_SYS_TRANS_HALF_TOPIC 中的消息投递到用户指定真正Topic中,然后再投递一个表示删除的消息到 RMQ_SYS_TRANS_OP_HALF_TOPIC 中,表示当前事务已完成,若本地事务rollback 回滚,则没有投递到真实Topic的过程,只需要投递表示删除的消息到 RMQ_SYS_TRANS_OP_HALF_TOPIC ,若Commit提交或Rollback回滚失败,Broker默认每6s中回查调用 checkLocalTransaction 一次,在该回查方法中再次回滚会提交事务,默认最多15次. ACL权限控制 ACL权限控制主要为RocketMQ提供 Topic资源级别的用户访问控制,可在Client客户端通过 RPCHook 注入 AccessKey 和 SecretKey 签名；将对应的权限控制属性,包括 Topic访问权限、 IP白名单和 AccessKey 和 SecretKey 签名等,设置在 $ROCKETMQ_HOME/conf/plain_acl.yml 配置文件中.Broker端对AccessKey所拥有的权限进行校验,校验不过抛出异常. 1234567891011121314151617181920212223242526272829303132333435private static final String ACL_ACCESS_KEY = &quot;RocketMQ&quot;;private static final String ACL_SECRET_KEY = &quot;1234567&quot;;public static void producer() throws MQClientException &#123; DefaultMQProducer producer = new DefaultMQProducer(&quot;ProducerGroupName&quot;, getAclRPCHook()); producer.setNamesrvAddr(&quot;127.0.0.1:9876&quot;); producer.start(); for (int i = 0; i &lt; 128; i++) &#123; try &#123; Message msg = new Message(&quot;TopicTest&quot;, &quot;TagA&quot;, &quot;OrderID188&quot;, &quot;Hello world&quot;.getBytes(RemotingHelper.DEFAULT_CHARSET)); SendResult sendResult = producer.send(msg); System.out.printf(&quot;%s%n&quot;, sendResult); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; producer.shutdown();&#125;public static void pushConsumer() throws MQClientException &#123; DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;please_rename_unique_group_name_5&quot;, getAclRPCHook(), new AllocateMessageQueueAveragely()); consumer.setNamesrvAddr(&quot;127.0.0.1:9876&quot;); consumer.subscribe(&quot;TopicTest&quot;, &quot;*&quot;); consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET); consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; System.out.printf(&quot;%s Receive New Messages: %s %n&quot;, Thread.currentThread().getName(), msgs); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; &#125;); consumer.start();&#125;static RPCHook getAclRPCHook() &#123; return new AclClientRPCHook(new SessionCredentials(ACL_ACCESS_KEY, ACL_SECRET_KEY));&#125; Broker端具体配置信息可参见源码包下 docs/cn/acl/user_guide.md ,在 broker.conf 中通过 aclEnable=true 打开acl的标志.然后就可以用 plain_acl.yml 来进行权限配置了.且该配置文件是热加载的,修改后不用重启Broker服务. 1234567891011121314151617181920212223242526globalWhiteRemoteAddresses: # 全局白名单,不受ACL控制,通常需要将主从架构中所有节点加进来- 10.10.103.*- 192.168.0.*accounts:- accessKey: RocketMQ secretKey: 12345678 whiteRemoteAddress: admin: false defaultTopicPerm: DENY # 默认Topic访问策略是拒绝 defaultGroupPerm: SUB # 默认Group访问策略是只允许订阅 topicPerms: - topicA=DENY # topicA拒绝 - topicB=PUB|SUB # topicB允许发布和订阅消息 - topicC=SUB # topicC只允许订阅 groupPerms: # the group should convert to retry topic - groupA=DENY - groupB=PUB|SUB - groupC=SUB# 第二个账户,只要是来自192.168.1.*的IP,就可以访问所有资源- accessKey: rocketmq2 secretKey: 12345678 whiteRemoteAddress: 192.168.1.* # if it is admin, it could access all resources admin: true","tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"http://example.com/tags/RocketMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RocketMQ","slug":"工具和中间件/消息队列/RocketMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RocketMQ/"}]},{"title":"RabbitMQ-Spring集成","date":"2019-03-25T09:08:20.000Z","path":"blog/工具和中间件/消息队列/RabbitMQ/RabbitMQ-Spring集成/","text":"Spring集成12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:rabbit=&quot;http://www.springframework.org/schema/rabbit&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/rabbit http://www.springframework.org/schema/rabbit/spring-rabbit.xsd&quot;&gt; &lt;!--加载配置文件--&gt; &lt;context:property-placeholder location=&quot;classpath:rabbitmq.properties&quot;/&gt; &lt;!-- 定义rabbitmq connectionFactory --&gt; &lt;rabbit:connection-factory id=&quot;connectionFactory&quot; host=&quot;$&#123;rabbitmq.host&#125;&quot; port=&quot;$&#123;rabbitmq.port&#125;&quot; username=&quot;$&#123;rabbitmq.username&#125;&quot; password=&quot;$&#123;rabbitmq.password&#125;&quot; virtual-host=&quot;$&#123;rabbitmq.virtual-host&#125;&quot;/&gt; &lt;!-- 定义管理交换机、队列 --&gt; &lt;rabbit:admin connection-factory=&quot;connectionFactory&quot;/&gt; &lt;!-- 定义持久化队列，不存在则自动创建；不绑定到交换机则绑定到默认交换机，默认交换机类型为direct，名字为：&quot;&quot;，路由键为队列的名称 --&gt; &lt;!-- id：bean的名称，name：queue的名称，auto-declare：自动创建，durable：是否持久化，auto-delete：自动删除。最后一个消费者和该队列断开连接后，自动删除队列 --&gt; &lt;rabbit:queue id=&quot;spring_queue&quot; name=&quot;spring_queue&quot; auto-declare=&quot;true&quot; durable=&quot;false&quot;/&gt; &lt;!-- 广播；所有队列都能收到消息 --&gt; &lt;!--定义广播交换机中的持久化队列，不存在则自动创建--&gt; &lt;rabbit:queue id=&quot;spring_fanout_queue_1&quot; name=&quot;spring_fanout_queue_1&quot; auto-declare=&quot;true&quot;/&gt; &lt;!--定义广播交换机中的持久化队列，不存在则自动创建--&gt; &lt;rabbit:queue id=&quot;spring_fanout_queue_2&quot; name=&quot;spring_fanout_queue_2&quot; auto-declare=&quot;true&quot;/&gt; &lt;!--定义广播类型交换机；并绑定上述两个队列--&gt; &lt;rabbit:fanout-exchange id=&quot;spring_fanout_exchange&quot; name=&quot;spring_fanout_exchange&quot; auto-declare=&quot;true&quot;&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding queue=&quot;spring_fanout_queue_1&quot;/&gt; &lt;rabbit:binding queue=&quot;spring_fanout_queue_2&quot;/&gt; &lt;/rabbit:bindings&gt; &lt;/rabbit:fanout-exchange&gt; &lt;!-- 路由；所有队列都能收到消息 --&gt; &lt;rabbit:queue id=&quot;spring_direct_queue&quot; name=&quot;spring_direct_queue&quot; auto-declare=&quot;true&quot;/&gt; &lt;rabbit:direct-exchange id=&quot;spring_direct_exchange&quot; name=&quot;spring_direct_exchange&quot;&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding queue=&quot;spring_direct_queue&quot;/&gt; &lt;/rabbit:bindings&gt; &lt;/rabbit:direct-exchange&gt; &lt;!-- 通配符；*匹配一个单词，#匹配多个单词 --&gt; &lt;rabbit:queue id=&quot;spring_topic_queue_star&quot; name=&quot;spring_topic_queue_star&quot; auto-declare=&quot;true&quot;/&gt; &lt;rabbit:queue id=&quot;spring_topic_queue_well&quot; name=&quot;spring_topic_queue_well&quot; auto-declare=&quot;true&quot;/&gt; &lt;rabbit:queue id=&quot;spring_topic_queue_well2&quot; name=&quot;spring_topic_queue_well2&quot; auto-declare=&quot;true&quot;/&gt; &lt;!-- 声明 topic 类型的交换机 --&gt; &lt;rabbit:topic-exchange name=&quot;spring_topic_exchange&quot; id=&quot;spring_topic_exchange&quot; auto-declare=&quot;true&quot;&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding pattern=&quot;eleven.*&quot; queue=&quot;spring_topic_queue_star&quot;/&gt; &lt;rabbit:binding pattern=&quot;eleven.#&quot; queue=&quot;spring_topic_queue_well&quot;/&gt; &lt;rabbit:binding pattern=&quot;itcast.*&quot; queue=&quot;spring_topic_queue_well2&quot;/&gt; &lt;/rabbit:bindings&gt; &lt;/rabbit:topic-exchange&gt; &lt;!--定义rabbitTemplate对象操作可以在代码中方便发送消息--&gt; &lt;rabbit:template id=&quot;rabbitTemplate&quot; connection-factory=&quot;connectionFactory&quot;/&gt;&lt;/beans&gt; 12345678910111213141516171819202122@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = &quot;classpath:spring-rabbitmq-producer-basic.xml&quot;)public class ProducerBasicTest &#123; @Autowired private RabbitTemplate rabbitTemplate; @Test public void testHelloWorld() &#123; rabbitTemplate.convertAndSend(&quot;spring_queue&quot;, &quot;hello world spring...&quot;); &#125; @Test public void testFanout() &#123; rabbitTemplate.convertAndSend(&quot;spring_fanout_exchange&quot;, &quot;&quot;, &quot;spring fanout...&quot;); &#125; @Test public void testDirect() &#123; rabbitTemplate.convertAndSend(&quot;spring_direct_exchange&quot;, &quot;info&quot;, &quot;spring_direct...&quot;); &#125; @Test public void testTopic() &#123; rabbitTemplate.convertAndSend(&quot;spring_topic_exchange&quot;, &quot;eleven.hehe.haha&quot;, &quot;spring topic...&quot;); &#125;&#125; 1234567891011121314151617181920212223242526272829303132&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:rabbit=&quot;http://www.springframework.org/schema/rabbit&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/rabbit http://www.springframework.org/schema/rabbit/spring-rabbit.xsd&quot;&gt; &lt;!--加载配置文件--&gt; &lt;context:property-placeholder location=&quot;classpath:rabbitmq.properties&quot;/&gt; &lt;!-- 定义rabbitmq connectionFactory --&gt; &lt;rabbit:connection-factory id=&quot;connectionFactory&quot; host=&quot;$&#123;rabbitmq.host&#125;&quot; port=&quot;$&#123;rabbitmq.port&#125;&quot; username=&quot;$&#123;rabbitmq.username&#125;&quot; password=&quot;$&#123;rabbitmq.password&#125;&quot; virtual-host=&quot;$&#123;rabbitmq.virtual-host&#125;&quot;/&gt; &lt;bean id=&quot;springQueueListener&quot; class=&quot;com.eleven.icode.rabbitmq.SpringQueueListener&quot;/&gt; &lt;bean id=&quot;fanoutListener&quot; class=&quot;com.eleven.icode.rabbitmq.SpringQueueListener&quot;/&gt; &lt;bean id=&quot;fanoutListener2&quot; class=&quot;com.eleven.icode.rabbitmq.SpringQueueListener&quot;/&gt; &lt;bean id=&quot;topicListenerStar&quot; class=&quot;com.eleven.icode.rabbitmq.SpringQueueListener&quot;/&gt; &lt;bean id=&quot;topicListenerWell&quot; class=&quot;com.eleven.icode.rabbitmq.SpringQueueListener&quot;/&gt; &lt;bean id=&quot;topicListenerWell2&quot; class=&quot;com.eleven.icode.rabbitmq.SpringQueueListener&quot;/&gt; &lt;rabbit:listener-container connection-factory=&quot;connectionFactory&quot; auto-declare=&quot;true&quot;&gt; &lt;rabbit:listener ref=&quot;springQueueListener&quot; queue-names=&quot;spring_queue&quot;/&gt; &lt;rabbit:listener ref=&quot;fanoutListener&quot; queue-names=&quot;spring_fanout_queue_1&quot;/&gt; &lt;rabbit:listener ref=&quot;fanoutListener2&quot; queue-names=&quot;spring_fanout_queue_2&quot;/&gt; &lt;rabbit:listener ref=&quot;topicListenerStar&quot; queue-names=&quot;spring_topic_queue_star&quot;/&gt; &lt;rabbit:listener ref=&quot;topicListenerWell&quot; queue-names=&quot;spring_topic_queue_well&quot;/&gt; &lt;rabbit:listener ref=&quot;topicListenerWell2&quot; queue-names=&quot;spring_topic_queue_well2&quot;/&gt; &lt;/rabbit:listener-container&gt;&lt;/beans&gt; 123456public class SpringQueueListener implements MessageListener &#123; @Override public void onMessage(Message message) &#123; System.out.println(new String(message.getBody())); &#125;&#125; SpringBoot集成1234567spring: rabbitmq: host: localhost #主机ip port: 5672 #端口 username: eleven password: eleven virtual-host: eleven 12345678910111213141516171819202122232425262728@Configurationpublic class TopicConfig &#123; @Bean public Queue topicQ1() &#123; // 声明队列 return new Queue(&quot;topic_sb_mq_q1&quot;); &#125; @Bean public Queue topicQ2() &#123; // 声明队列 return new Queue(&quot;topic_sb_mq_q2&quot;); &#125; @Bean public TopicExchange setTopicExchange() &#123; // 声明exchange return new TopicExchange(&quot;topicExchange&quot;); &#125; @Bean public Binding bindTopicHebei1() &#123; // 声明binding，需要声明一个roytingKey return BindingBuilder.bind(topicQ1()).to(setTopicExchange()).with(&quot;changsha.*&quot;); &#125; @Bean public Binding bindTopicHebei2() &#123; return BindingBuilder.bind(topicQ2()).to(setTopicExchange()).with(&quot;#.beijing&quot;); &#125;&#125;@RabbitListener(queues = &quot;topic_sb_mq_q2&quot;)public void topicReceiveq2(String message) &#123; System.out.println(&quot;Topic模式 topic_sb_mq_q2 received message : &quot; + message);&#125;","tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://example.com/tags/RabbitMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RabbitMQ","slug":"工具和中间件/消息队列/RabbitMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/"}]},{"title":"RabbitMQ-高级特性","date":"2019-03-25T07:08:20.000Z","path":"blog/工具和中间件/消息队列/RabbitMQ/RabbitMQ-高级特性/","text":"消息可靠性投递持久化: Exchange持久化、 Queue持久化、 Message持久化; 生产方确认Confirm; 消费方确认Ack; Broker高可用; 生成端确认使用RabbitMQ时,作为消息发送方希望杜绝任何消息丢失或投递失败场景.RabbitMQ提供了 Confirm确认模式 和 Return退回模式 两种方式用来控制消息的投递可靠性. RabbitMQ整个消息投递的路径为:Producer到Rabbitmq Broker到Exchange到Queue到Consumer;消息从Producer到Exchange 则会返回一个 ConfirmCallback.消息从Exchange到Queue投递失败 则会返回一个 ReturnCallback.可利用这两个Callback控制消息的可靠性投递; 设置 ConnectionFactory 的 publisher-confirms=&quot;true&quot;开启确认模式.使用 RabbitTemplate 的 setConfirmCallback 设置回调函数.当消息发送到Exchange后回调confirm方法.在方法中判断ack,若为true则发送成功,若为false则发送失败需要处理. 设置 ConnectionFactory 的 publisher-returns=&quot;true&quot;开启退回模式.使用 RabbitTemplate 的 setReturnCallback 设置退回函数,当消息从Exchange路由到Queue失败后,若设置了 rabbitTemplate.setMandatory(true) 参数,则会将消息退回给Producer并 执行回调函数returnedMessage. 消费端确认ack指 Acknowledge 确认,表示 消费端收到消息后的确认方式,有三种确认方式: 自动确认:acknowledge=&quot;none&quot; 手动确认:acknowledge=&quot;manual&quot; 根据异常情况确认:acknowledge=&quot;auto&quot; 自动确认是指当消息一旦被Consumer接收到,则自动确认收到,并将相应message从RabbitMQ消息缓存中移除.但在实际业务处理中,很可能消息接收到,业务处理出现异常,则该消息会丢失.若设置了手动确认方式,则需要在业务处理成功后,调用 channel.basicAck()手动签收,若出现异常则调用 channel.basicNack() 方法,让其自动重新发送消息. 123456789101112131415&lt;!--加载配置文件--&gt;&lt;context:property-placeholder location=&quot;classpath:rabbitmq.properties&quot;/&gt;&lt;!-- 定义rabbitmq connectionFactory --&gt;&lt;rabbit:connection-factory id=&quot;connectionFactory&quot; host=&quot;$&#123;rabbitmq.host&#125;&quot; port=&quot;$&#123;rabbitmq.port&#125;&quot; username=&quot;$&#123;rabbitmq.username&#125;&quot; password=&quot;$&#123;rabbitmq.password&#125;&quot; virtual-host=&quot;$&#123;rabbitmq.virtual-host&#125;&quot; publisher-confirms=&quot;true&quot; publisher-returns=&quot;true&quot;/&gt;&lt;!--定义管理交换机、队列--&gt;&lt;rabbit:admin connection-factory=&quot;connectionFactory&quot;/&gt;&lt;!--定义rabbitTemplate对象操作可以在代码中方便发送消息--&gt;&lt;rabbit:template id=&quot;rabbitTemplate&quot; connection-factory=&quot;connectionFactory&quot;/&gt;&lt;!--消息可靠性投递（生产端）--&gt;&lt;rabbit:queue id=&quot;test_queue_confirm&quot; name=&quot;test_queue_confirm&quot;/&gt;&lt;rabbit:direct-exchange name=&quot;test_exchange_confirm&quot;&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding queue=&quot;test_queue_confirm&quot; key=&quot;confirm&quot;/&gt; &lt;/rabbit:bindings&gt;&lt;/rabbit:direct-exchange&gt; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = &quot;classpath:spring-rabbitmq-producer.xml&quot;)public class ProducerTest &#123; @Autowired private RabbitTemplate rabbitTemplate; @Test public void testConfirm() &#123; //测试Confirm模式 //定义回调 rabbitTemplate.setConfirmCallback(new RabbitTemplate.ConfirmCallback() &#123; /** * @param correlationData 相关配置信息 * @param ack exchange交换机 是否成功收到了消息.true 成功,false代表失败 * @param cause 失败原因 */ @Override public void confirm(CorrelationData correlationData, boolean ack, String cause) &#123; System.out.println(&quot;confirm方法被执行了....&quot; + correlationData.getId()); // ack为true表示消息已经到达交换机 if (ack) &#123; // 接收成功 System.out.println(&quot;接收成功消息&quot; + cause); &#125; else &#123; // 接收失败 System.out.println(&quot;接收失败消息&quot; + cause); // 做一些处理,让消息再次发送. &#125; &#125; &#125;); // 进行消息发送 for (int i = 0; i &lt; 5; i++) &#123; rabbitTemplate.convertAndSend(&quot;test_exchange_confirm&quot;, &quot;confirm&quot;, &quot;message Confirm...&quot;); &#125; &#125; @Test public void testReturn() &#123; // 测试return模式 // 设置交换机处理失败消息的模式,为true时消息到达不了队列时,会将消息重新返回给生产者 rabbitTemplate.setMandatory(true); // 定义回调 rabbitTemplate.setReturnCallback(new RabbitTemplate.ReturnCallback() &#123; /** * @param message 消息对象 * @param replyCode 错误码 * @param replyText 错误信息 * @param exchange 交换机 * @param routingKey 路由键 */ @Override public void returnedMessage(Message message, int replyCode, String replyText, String exchange, String routingKey) &#123; System.out.println(&quot;return 执行了....&quot;); System.out.println(&quot;message:&quot; + message); System.out.println(&quot;replyCode:&quot; + replyCode); System.out.println(&quot;replyText:&quot; + replyText); System.out.println(&quot;exchange:&quot; + exchange); System.out.println(&quot;routingKey:&quot; + routingKey); &#125; &#125;); // 进行消息发送 rabbitTemplate.convertAndSend(&quot;test_exchange_confirm&quot;, &quot;confirm&quot;, &quot;message return...&quot;); &#125;&#125; 12345&lt;!--定义监听器容器 acknowledge=&quot;manual&quot;:手动签收 prefetch=&quot;1&quot;:每次抓取多少条消息 --&gt;&lt;!--定义监听器容器 acknowledge=&quot;manual&quot; prefetch=&quot;1&quot; --&gt;&lt;rabbit:listener-container connection-factory=&quot;connectionFactory&quot; acknowledge=&quot;manual&quot; prefetch=&quot;1&quot;&gt; &lt;rabbit:listener ref=&quot;ackListener&quot; queue-names=&quot;test_queue_confirm&quot;&gt;&lt;/rabbit:listener&gt;&lt;/rabbit:listener&gt;&lt;/rabbit:listener-container&gt; 12345678910111213141516171819202122@Componentpublic class AckListener implements ChannelAwareMessageListener &#123; @Override public void onMessage(Message message, Channel channel) throws Exception &#123; //1、获取消息的id long deliveryTag = message.getMessageProperties().getDeliveryTag(); try &#123; //2、获取消息 System.out.println(&quot;message:&quot; + new String(message.getBody())); //3、进行业务处理 System.out.println(&quot;=====进行业务处理====&quot;); //模拟出现异常 int i = 5/0; //4、进行消息签收 channel.basicAck(deliveryTag, false); System.out.println(&quot;收到了消息:&quot; + deliveryTag); &#125; catch (Exception e) &#123; //拒绝签收,第三个参数：requeue：重回队列.如果设置为true,则消息重新回到queue,broker会重新发送该消息给消费端 channel.basicNack(deliveryTag, false, true); &#125; &#125;&#125; 消费端限流在 &lt;rabbit:listener-container&gt; 中配置 prefetch 属性设置 消费端一次拉取多少消息 ,消费端的确认模式一定为手动确认 acknowledge=&quot;manual&quot; . TTL当消息达到存活时间后,还未被消费会被自动清除,RabbitMQ可 对消息设置过期时间,也可 对整个队列设置过期时间. 设置队列过期时间使用参数 x-message-ttl 单位 ms毫秒,会对整个队列消息统一过期.设置消息过期时间使用参数 expiration 单位 ms毫秒,当该消息在 队列头部 时,会单独判断这一消息是否过期.若 两者都进行了设置以时间短的为准. 123456789101112&lt;rabbit:queue name=&quot;test_queue_ttl&quot; id=&quot;test_queue_ttl&quot;&gt; &lt;!--设置queue的参数--&gt; &lt;rabbit:queue-arguments&gt; &lt;!--x-message-ttl指队列的过期时间--&gt; &lt;entry key=&quot;x-message-ttl&quot; value=&quot;10000&quot; value-type=&quot;java.lang.Integer&quot;/&gt; &lt;/rabbit:queue-arguments&gt;&lt;/rabbit:queue&gt;&lt;rabbit:topic-exchange name=&quot;test_exchange_ttl&quot;&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding pattern=&quot;ttl.#&quot; queue=&quot;test_queue_ttl&quot;/&gt; &lt;/rabbit:bindings&gt;&lt;/rabbit:topic-exchange&gt; 死信队列死信队列DXL.Dead Letter Exchange死信交换机,当消息成为Dead Message后,可被 重新发送到另一个交换机,这个交换机就是 DLX.消息成为死信的 三种情况： 队列消息长度到达限制; 消费者拒接消费消息,basicNack/basicReject且不把消息重新放入原目标队列,requeue=false; 原队列存在消息过期设置,消息到达超时时间未被消费; 死信交换机和死信队列和普通的没有区别，当消息成为死信后，若该队列绑定了死信交换机，则消息会被死信交换机重新路由到死信队列。可通过给队列设置 x-dead-letter-exchange 和 x-dead-letter-routing-key 参数来绑定死信交换机; 12345678910111213141516171819202122232425262728293031323334&lt;!-- 1. 声明正常的队列(test_queue_dlx)和交换机(test_exchange_dlx) 2. 声明死信队列(queue_dlx)和死信交换机(exchange_dlx) 3. 正常队列绑定死信交换机 设置两个参数： * x-dead-letter-exchange：死信交换机名称 * x-dead-letter-routing-key：发送给死信交换机的routingkey--&gt;&lt;!-- 1. 声明正常的队列(test_queue_dlx)和交换机(test_exchange_dlx) --&gt;&lt;rabbit:queue name=&quot;test_queue_dlx&quot; id=&quot;test_queue_dlx&quot;&gt; &lt;!--3. 正常队列绑定死信交换机--&gt; &lt;rabbit:queue-arguments&gt; &lt;!--3.1 x-dead-letter-exchange：死信交换机名称--&gt; &lt;entry key=&quot;x-dead-letter-exchange&quot; value=&quot;exchange_dlx&quot;/&gt; &lt;!--3.2 x-dead-letter-routing-key：发送给死信交换机的routingkey--&gt; &lt;entry key=&quot;x-dead-letter-routing-key&quot; value=&quot;dlx.hehe&quot;/&gt; &lt;!--4.1 设置队列的过期时间 ttl--&gt; &lt;entry key=&quot;x-message-ttl&quot; value=&quot;10000&quot; value-type=&quot;java.lang.Integer&quot;/&gt; &lt;!--4.2 设置队列的长度限制 max-length--&gt; &lt;entry key=&quot;x-max-length&quot; value=&quot;10&quot; value-type=&quot;java.lang.Integer&quot;/&gt; &lt;/rabbit:queue-arguments&gt;&lt;/rabbit:queue&gt;&lt;rabbit:topic-exchange name=&quot;test_exchange_dlx&quot;&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding pattern=&quot;test.dlx.#&quot; queue=&quot;test_queue_dlx&quot;/&gt; &lt;/rabbit:bindings&gt;&lt;/rabbit:topic-exchange&gt;&lt;!-- 2. 声明死信队列(queue_dlx)和死信交换机(exchange_dlx) --&gt;&lt;rabbit:queue name=&quot;queue_dlx&quot; id=&quot;queue_dlx&quot;/&gt;&lt;rabbit:topic-exchange name=&quot;exchange_dlx&quot;&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding pattern=&quot;dlx.#&quot; queue=&quot;queue_dlx&quot;/&gt; &lt;/rabbit:bindings&gt;&lt;/rabbit:topic-exchange&gt; 1234&lt;rabbit:listener-container connection-factory=&quot;connectionFactory&quot; acknowledge=&quot;manual&quot; prefetch=&quot;1&quot;&gt; &lt;!--定义监听器，监听正常队列--&gt; &lt;rabbit:listener ref=&quot;dlxListener&quot; queue-names=&quot;test_queue_dlx&quot;&gt;&lt;/rabbit:listener&gt;&lt;/rabbit:listener&gt;&lt;/rabbit:listener-container&gt; 123456789101112131415161718192021@Componentpublic class DlxListener implements ChannelAwareMessageListener &#123; @Override public void onMessage(Message message, Channel channel) throws Exception &#123; long deliveryTag = message.getMessageProperties().getDeliveryTag(); try &#123; //1.接收转换消息 System.out.println(new String(message.getBody())); //2. 处理业务逻辑 System.out.println(&quot;处理业务逻辑...&quot;); //int i = 3/0;//出现错误 //3. 手动签收 channel.basicAck(deliveryTag, true); &#125; catch (Exception e) &#123; //e.printStackTrace(); System.out.println(&quot;出现异常，拒绝接受&quot;); //4.拒绝签收，不重回队列 requeue=false channel.basicNack(deliveryTag, true, false); &#125; &#125;&#125; 延迟队列延迟队列即消息进入队列后不会立即被消费，只有到达指定时间后才会被消费，在RabbitMQ中并未提供延迟队列功能。但是可使用 TTL+死信队列 组合实现延迟队列的效果 123456789101112131415161718192021222324252627&lt;!-- 延迟队列： 1. 定义正常交换机（order_exchange）和队列(order_queue) 2. 定义死信交换机（order_exchange_dlx）和队列(order_queue_dlx) 3. 绑定，设置正常队列过期时间为30分钟--&gt;&lt;!-- 1. 定义正常交换机（order_exchange）和队列(order_queue)--&gt;&lt;rabbit:queue id=&quot;order_queue&quot; name=&quot;order_queue&quot;&gt; &lt;!--3. 绑定，设置正常队列过期时间为30分钟--&gt; &lt;rabbit:queue-arguments&gt; &lt;entry key=&quot;x-dead-letter-exchange&quot; value=&quot;order_exchange_dlx&quot;/&gt; &lt;entry key=&quot;x-dead-letter-routing-key&quot; value=&quot;dlx.order.cancel&quot;/&gt; &lt;entry key=&quot;x-message-ttl&quot; value=&quot;10000&quot; value-type=&quot;java.lang.Integer&quot;/&gt; &lt;/rabbit:queue-arguments&gt;&lt;/rabbit:queue&gt;&lt;rabbit:topic-exchange name=&quot;order_exchange&quot;&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding pattern=&quot;order.#&quot; queue=&quot;order_queue&quot;/&gt; &lt;/rabbit:bindings&gt;&lt;/rabbit:topic-exchange&gt;&lt;!--2. 定义死信交换机（order_exchange_dlx）和队列(order_queue_dlx)--&gt;&lt;rabbit:queue id=&quot;order_queue_dlx&quot; name=&quot;order_queue_dlx&quot;/&gt;&lt;rabbit:topic-exchange name=&quot;order_exchange_dlx&quot;&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding pattern=&quot;dlx.order.#&quot; queue=&quot;order_queue_dlx&quot;/&gt; &lt;/rabbit:bindings&gt;&lt;/rabbit:topic-exchange&gt; 1234&lt;rabbit:listener-container connection-factory=&quot;connectionFactory&quot; acknowledge=&quot;manual&quot; prefetch=&quot;1&quot;&gt; &lt;!--延迟队列效果实现：一定要监听的是死信队列！！！--&gt; &lt;rabbit:listener ref=&quot;orderListener&quot; queue-names=&quot;order_queue_dlx&quot;&gt;&lt;/rabbit:listener&gt;&lt;/rabbit:listener-container&gt; 消息幂等性保障可通过版本号实现乐观锁的方式优化; 消息积压消费者宕机积压、消费者消费能力不足积压、生产者者流量太大等都可能导致消息积压;可通过上线更多的消费者，进行正常消费上线专门的队列消费服务，将消息先批量取出来记录数据库再慢慢处理;","tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://example.com/tags/RabbitMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RabbitMQ","slug":"工具和中间件/消息队列/RabbitMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/"}]},{"title":"RabbitMQ-topic模式","date":"2019-03-25T03:08:20.000Z","path":"blog/工具和中间件/消息队列/RabbitMQ/RabbitMQ-topic模式/","text":"pom.xml123456789101112131415161718192021&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;artifactId&gt;rabbitmq&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;rabbitmq&lt;/name&gt; &lt;description&gt;rabbitmq&lt;/description&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt; &lt;artifactId&gt;amqp-client&lt;/artifactId&gt; &lt;version&gt;3.6.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;4.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; TestProducer.java分别在 四个路由：”usa.news”, “usa.weather”, “europe.news”, “europe.weather” 上发布 “美国新闻”, “美国天气”, “欧洲新闻”, “欧洲天气”. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package cn.peach;import java.io.IOException;import java.util.concurrent.TimeoutException; import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory; /** * 消息生成者 */public class TestProducer &#123; public final static String EXCHANGE_NAME=&quot;topics_exchange&quot;; public static void main(String[] args) throws IOException, TimeoutException &#123; RabbitMQUtil.checkServer(); //创建连接工厂 ConnectionFactory factory = new ConnectionFactory(); //设置RabbitMQ相关信息 factory.setHost(&quot;localhost&quot;); //创建一个新的连接 Connection connection = factory.newConnection(); //创建一个通道 Channel channel = connection.createChannel(); channel.exchangeDeclare(EXCHANGE_NAME, &quot;topic&quot;); String[] routing_keys = new String[] &#123; &quot;usa.news&quot;, &quot;usa.weather&quot;, &quot;europe.news&quot;, &quot;europe.weather&quot; &#125;; String[] messages = new String[] &#123; &quot;美国新闻&quot;, &quot;美国天气&quot;, &quot;欧洲新闻&quot;, &quot;欧洲天气&quot; &#125;; for (int i = 0; i &lt; routing_keys.length; i++) &#123; String routingKey = routing_keys[i]; String message = messages[i]; channel.basicPublish(EXCHANGE_NAME, routingKey, null, message .getBytes()); System.out.printf(&quot;发送消息到路由：%s, 内容是: %s%n &quot;, routingKey,message); &#125; //关闭通道和连接 channel.close(); connection.close(); &#125;&#125; TestCustomer4USA.java专门用于接受 usa.* 消息 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package cn.peach;import java.io.IOException;import java.util.concurrent.TimeoutException; import com.rabbitmq.client.AMQP;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import com.rabbitmq.client.Consumer;import com.rabbitmq.client.DefaultConsumer;import com.rabbitmq.client.Envelope; import cn.hutool.core.util.RandomUtil; public class TestCustomer4USA &#123; public final static String EXCHANGE_NAME=&quot;topics_exchange&quot;; public static void main(String[] args) throws IOException, TimeoutException &#123; //为当前消费者取名称 String name = &quot;consumer-usa&quot;; // 创建连接工厂 ConnectionFactory factory = new ConnectionFactory(); //设置RabbitMQ地址 factory.setHost(&quot;localhost&quot;); //创建一个新的连接 Connection connection = factory.newConnection(); //创建一个通道 Channel channel = connection.createChannel(); //交换机声明（参数为：交换机名称；交换机类型） channel.exchangeDeclare(EXCHANGE_NAME,&quot;topic&quot;); //获取一个临时队列 String queueName = channel.queueDeclare().getQueue(); //接受 USA 信息 channel.queueBind(queueName, EXCHANGE_NAME, &quot;usa.*&quot;); System.out.println(name +&quot; 等待接受消息&quot;); //DefaultConsumer类实现了Consumer接口，通过传入一个频道， // 告诉服务器我们需要那个频道的消息，如果频道中有消息，就会执行回调函数handleDelivery Consumer consumer = new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; String message = new String(body, &quot;UTF-8&quot;); System.out.println(name + &quot; 接收到消息 &#x27;&quot; + message + &quot;&#x27;&quot;); &#125; &#125;; //自动回复队列应答 -- RabbitMQ中的消息确认机制 channel.basicConsume(queueName, true, consumer); &#125;&#125; TestCustomer4News.java专门用于接受 *.news 消息 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package cn.peach;import java.io.IOException;import java.util.concurrent.TimeoutException; import com.rabbitmq.client.AMQP;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import com.rabbitmq.client.Consumer;import com.rabbitmq.client.DefaultConsumer;import com.rabbitmq.client.Envelope; import cn.hutool.core.util.RandomUtil; public class TestCustomer4News &#123; public final static String EXCHANGE_NAME=&quot;topics_exchange&quot;; public static void main(String[] args) throws IOException, TimeoutException &#123; //为当前消费者取名称 String name = &quot;consumer-news&quot;; // 创建连接工厂 ConnectionFactory factory = new ConnectionFactory(); //设置RabbitMQ地址 factory.setHost(&quot;localhost&quot;); //创建一个新的连接 Connection connection = factory.newConnection(); //创建一个通道 Channel channel = connection.createChannel(); //交换机声明（参数为：交换机名称；交换机类型） channel.exchangeDeclare(EXCHANGE_NAME,&quot;topic&quot;); //获取一个临时队列 String queueName = channel.queueDeclare().getQueue(); //接受 USA 信息 channel.queueBind(queueName, EXCHANGE_NAME, &quot;*.news&quot;); System.out.println(name +&quot; 等待接受消息&quot;); //DefaultConsumer类实现了Consumer接口，通过传入一个频道， // 告诉服务器我们需要那个频道的消息，如果频道中有消息，就会执行回调函数handleDelivery Consumer consumer = new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; String message = new String(body, &quot;UTF-8&quot;); System.out.println(name + &quot; 接收到消息 &#x27;&quot; + message + &quot;&#x27;&quot;); &#125; &#125;; //自动回复队列应答 -- RabbitMQ中的消息确认机制 channel.basicConsume(queueName, true, consumer); &#125;&#125; 运行效果先运行 TestCustomer4USA 专门用于接受美国专题消息再运行 TestCustomer4News 专门用于接受新闻专题消息最后运行 TestProducer ，分别在 四个路由：”usa.news”, “usa.weather”, “europe.news”, “europe.weather” 上发布 “美国新闻”, “美国天气”, “欧洲新闻”, “欧洲天气”.于是就能在消费者端看到 不同的主题收到对应的消息了。","tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://example.com/tags/RabbitMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RabbitMQ","slug":"工具和中间件/消息队列/RabbitMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/"}]},{"title":"ActiveMQ-Spring集成","date":"2019-03-24T09:09:03.000Z","path":"blog/工具和中间件/消息队列/Activemq/ActiveMQ-Spring集成/","text":"spring 模式前面的是 jms 模式，下面采用 spring 模式使用 activeMQ。 JMS即Java消息服务(Java Message Service)应用程序接口,是一个Java平台中关于面向消息中间件(MOM)的API,用于在两个应用程序之间,或分布式系统中发送消息,进行异步通信。 点到点（point to point）。基于消息队列，消息产生者将消息发送到队列中。消息消费者可以将自身与队列连接，以倾听消息。当消息到达队列时，客户可以从队列中取走，并给出响应。消息只能发送到一个队列，只能由一个消费者使用。消费者可以过滤消息，以便获得希望获得的消息。 出版和订阅（publish&#x2F;subscribe）。消息生产者将消息发送到一个话题（topic），注册到此话题的消费者都能接收到这些消息。这种情况下，许多消费者都能接收到同样的消息。 pom.xml引入 activemq, spring , junit ,hutool 1234567891011121314151617181920212223242526272829303132333435&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;artifactId&gt;activemq&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;activemq&lt;/name&gt; &lt;description&gt;activemq&lt;/description&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-client&lt;/artifactId&gt; &lt;version&gt;5.13.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jms&lt;/artifactId&gt; &lt;version&gt;4.3.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;4.2.4.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.9&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;4.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; spring_jms.xml在 resources下创建 spring_jms.xml 文件，这里其实就是对 activemq 的相关配置。 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:dubbo=&quot;http://code.alibabatech.com/schema/dubbo&quot; xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;context:component-scan base-package=&quot;cn.peach&quot;&gt;&lt;/context:component-scan&gt; &lt;!-- 真正可以产生Connection的ConnectionFactory，由对应的 JMS服务厂商提供--&gt; &lt;bean id=&quot;targetConnectionFactory&quot; class=&quot;org.apache.activemq.ActiveMQConnectionFactory&quot;&gt; &lt;property name=&quot;brokerURL&quot; value=&quot;tcp://127.0.0.1:61616&quot;/&gt; &lt;/bean&gt; &lt;!-- Spring用于管理真正的ConnectionFactory的ConnectionFactory --&gt; &lt;bean id=&quot;connectionFactory&quot; class=&quot;org.springframework.jms.connection.SingleConnectionFactory&quot;&gt; &lt;!-- 目标ConnectionFactory对应真实的可以产生JMS Connection的ConnectionFactory --&gt; &lt;property name=&quot;targetConnectionFactory&quot; ref=&quot;targetConnectionFactory&quot;/&gt; &lt;/bean&gt; &lt;!-- Spring提供的JMS工具类，它可以进行消息发送、接收等 --&gt; &lt;bean id=&quot;jmsTemplate&quot; class=&quot;org.springframework.jms.core.JmsTemplate&quot;&gt; &lt;!-- 这个connectionFactory对应的是我们定义的Spring提供的那个ConnectionFactory对象 --&gt; &lt;property name=&quot;connectionFactory&quot; ref=&quot;connectionFactory&quot;/&gt; &lt;/bean&gt; &lt;!--这个是队列目的地, ActiveMQQueue 就表示队列模式。 如果要用主题模式就改成 ActiveMQTopic就行了 --&gt; &lt;bean id=&quot;textDestination&quot; class=&quot;org.apache.activemq.command.ActiveMQQueue&quot;&gt; &lt;constructor-arg value=&quot;queue_style&quot;/&gt; &lt;/bean&gt; &lt;!-- 我的监听类 --&gt; &lt;bean id=&quot;myMessageListener&quot; class=&quot;cn.peach.MyMessageListener&quot;&gt;&lt;/bean&gt; &lt;!-- 消息监听容器，会伴随spring的启动 --&gt; &lt;bean class=&quot;org.springframework.jms.listener.DefaultMessageListenerContainer&quot;&gt; &lt;property name=&quot;connectionFactory&quot; ref=&quot;connectionFactory&quot; /&gt; &lt;property name=&quot;destination&quot; ref=&quot;textDestination&quot; /&gt; &lt;property name=&quot;messageListener&quot; ref=&quot;myMessageListener&quot; /&gt; &lt;/bean&gt;&lt;/beans&gt; Producer.java - 生产者类12345678910111213141516171819202122232425262728293031package cn.peach; import javax.jms.Destination;import javax.jms.JMSException;import javax.jms.Message;import javax.jms.Session; import org.springframework.beans.factory.annotation.Autowired;import org.springframework.jms.core.JmsTemplate;import org.springframework.jms.core.MessageCreator;import org.springframework.stereotype.Component; @Componentpublic class Producer &#123; @Autowired private JmsTemplate jmsTemplate; @Autowired private Destination textDestination; public void sendTextMessage(final String text)&#123; jmsTemplate.send(textDestination, new MessageCreator() &#123; public Message createMessage(Session session) throws JMSException &#123; return session.createTextMessage(text); &#125; &#125;); &#125; &#125; TestProducer.java测试生产者，发送100条消息 123456789101112131415161718192021222324252627package cn.peach;import org.junit.Before;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.test.context.ContextConfiguration;import org.springframework.test.context.junit4.SpringJUnit4ClassRunner; @RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations=&quot;classpath:spring_jms.xml&quot;)public class TestProducer &#123; @Autowired private Producer producer; @Before public void checkServer() &#123; // check ActiveMQ 服务器是否启动 &#125; @Test public void testSend()&#123; for (int i = 0; i &lt; 100; i++) &#123; producer.sendTextMessage(&quot;消息 &quot; + i); &#125; &#125;&#125; MyMessageListener.java - 监听类监听类，用于获取新的消息 12345678910111213141516171819202122232425package cn.peach; import javax.jms.JMSException;import javax.jms.Message;import javax.jms.MessageListener;import javax.jms.TextMessage; import cn.hutool.core.util.RandomUtil; public class MyMessageListener implements MessageListener &#123; String name = &quot;consumer-&quot;+ RandomUtil.randomString(5); public MyMessageListener() &#123; System.out.println(name + &quot; started&quot;); &#125; public void onMessage(Message message) &#123; TextMessage textMessage=(TextMessage)message; try &#123; System.out.println(name+&quot; 接收到消息：&quot;+textMessage.getText()); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125;&#125; TestConsumer.java - 消费者测试类消费者测试类，他其实什么都没做。 虽然它什么都没做，但是因为他是运行在 spring框架下的测试，所以一旦启动，就会导致一个 新的 DefaultMessageListenerContainer 被启动，间接地导致 一个 新的 MyMessageListener 被启动。 于是也就充当了消费者的角色了。其中的 1System.in.read(); 是为了这个测试类不退出，可以一直监听用。 与这个类似的， TestProducer 类的启动，也会导致一个 MyMessageListener 被启动，所以 TestProducer 本身既是一个 生产者，也是一个 消费者。 12345678910111213141516171819202122232425262728package cn.peach; import java.io.IOException; import org.junit.Before;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.test.context.ContextConfiguration;import org.springframework.test.context.junit4.SpringJUnit4ClassRunner; @RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations=&quot;classpath:spring_jms.xml&quot;)public class TestConsumer &#123; @Before public void checkServer() &#123; // check ActiveMQ 服务器是否启动.checkServer(); &#125; @Test public void test()&#123; try &#123; //写这个是为了不让当前测试退出。 因为 spring的配置， MyMessageListener 会自动启动 System.in.read(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; 启动测试先运行 1次 TestConsumer, 然后运行 1次 TestProducer。可以看到如图所示的，有两个消费者在瓜分 消息。 明明只启动了一次TestConsumer ，为什么会有两个消费者呢？因为采用 spring 模式， 会用到一个叫做 消息监听容器的类： DefaultMessageListenerContainer， 它会伴随 spring的启动而自动启动。 所以无论是 TestConsumer，还是 TestProducer 里面都会有它了。 模式切换当前例子是队列模式，那么要做主题模式怎么办呢?修改 spring_jms 就可以了，对了 queue_style 最好也修改成 topic_style","tags":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"http://example.com/tags/ActiveMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"Activemq","slug":"工具和中间件/消息队列/Activemq","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Activemq/"}]},{"title":"Kafka-Spring集成","date":"2019-03-23T04:08:20.000Z","path":"blog/工具和中间件/消息队列/Kafka/Kafka-Spring集成/","text":"Spring集成1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt; &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt;&lt;/dependency&gt; 123456789101112131415161718192021222324252627282930313233spring: kafka: bootstrap-servers: localhost:9092, localhost:9093, localhost:9094 producer: # 生产者 retries: 3 # 设置大于0的值，则客户端会将发送失败的记录重新发送 batch-size: 16384 buffer-memory: 33554432 acks: 1 # 指定消息key和消息体的编解码方式 key-serializer: org.apache.kafka.common.serialization.StringSerializer value-serializer: org.apache.kafka.common.serialization.StringSerializer consumer: group-id: default-group enable-auto-commit: false auto-offset-reset: earliest key-deserializer: org.apache.kafka.common.serialization.StringDeserializer value-deserializer: org.apache.kafka.common.serialization.StringDeserializer listener: # 当每一条记录被消费者监听器（ListenerConsumer）处理之后提交 # RECORD # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后提交 # BATCH # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后，距离上次提交时间大于TIME时提交 # TIME # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后，被处理record数量大于等于COUNT时提交 # COUNT # TIME | COUNT 有一个条件满足时提交 # COUNT_TIME # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后, 手动调用Acknowledgment.acknowledge()后提交 # MANUAL # 手动调用Acknowledgment.acknowledge()后立即提交，一般使用这种 # MANUAL_IMMEDIATE ack_mode: manual_immediate 123456private final static String TOPIC_NAME = &quot;my-replicated-topic&quot;;@Autowiredprivate KafkaTemplate&lt;String, String&gt; kafkaTemplate;public void send() &#123; kafkaTemplate.send(TOPIC_NAME, 0, &quot;key&quot;, &quot;this is a msg&quot;);&#125; 123456789101112131415161718192021222324/** * @KafkaListener(groupId = &quot;testGroup&quot;, topicPartitions = &#123; * @TopicPartition(topic = &quot;topic1&quot;, partitions = &#123;&quot;0&quot;, &quot;1&quot;&#125;), * @TopicPartition(topic = &quot;topic2&quot;, partitions = &quot;0&quot;, * partitionOffsets = @PartitionOffset(partition = &quot;1&quot;, initialOffset = &quot;100&quot;)) * &#125;, concurrency = &quot;6&quot;) * concurrency就是同组下的消费者个数，就是并发消费数，必须小于等于分区总数 */@KafkaListener(topics = &quot;my-replicated-topic&quot;, groupId = &quot;testGroup&quot;)public void listenTestGroup(ConsumerRecord&lt;String, String&gt; record, Acknowledgment ack) &#123; String value = record.value(); System.out.println(value); System.out.println(record); //手动提交offset //ack.acknowledge();&#125;// 配置多个消费组@KafkaListener(topics = &quot;my-replicated-topic&quot;, groupId = &quot;elevenGroup&quot;)public void listenElevenGroup(ConsumerRecord&lt;String, String&gt; record, Acknowledgment ack) &#123; String value = record.value(); System.out.println(value); System.out.println(record); ack.acknowledge();&#125; 设计原理 总控制器ControllerKafka集群中会有一个或多个Broker ，其中有一个Broker会被选举为Kafka Controller控制器，其负责管理整个集群中所有分区和副本的状态. 当某个分区的 Leader副本出现故障时，由控制器负责为该分区选举新的Leader副本. 当检测到某个分区的 ISR集合发生变化时，由控制器负责通知所有Broker更新其元数据信息. 当使用 kafka-topics.sh 脚本为某个 Topic增加分区数量时，同样还是由控制器负责让新分区被其他节点感知到. Kafka集群启动时自动选举一台Broker作为Controller来管理整个集群，选举过程是集群中每个Broker都会尝试在Zookeeper上创建一个 /controller临时节点，Zookeeper会保证有且仅有一个Broker能创建成功，创建成功的Broker则成为集群的总控器Controller. Controller选举机制当Controller角色的Broker宕机时Zookeeper临时节点会消失，集群里其他Broker会一直监听/controller临时节点，发现临时节点消失则竞争再次创建/controller临时节点，这就是 Controller的选举机制. 具备控制器身份的Broker需要比其他普通Broker多一份职责： 监听Broker相关的变化，为Zookeeper中的 /brokers/ids 节点添加 BrokerChangeListener ，用来处理Broker增减变化. 监听Topic相关的变化，为Zookeeper中的 /brokers/topics 节点添加 TopicChangeListener ，用来处理Topic增减的变化；为Zookeeper中的 /admin/delete_topics 节点添加 TopicDeletionListener ，用来处理删除Topic动作. 从Zookeeper中读取当前所有与Topic、 Partition以及Broker有关信息并进行相应的管理. 对所有Topic所对应的Zookeeper中的 /brokers/topics/[topic] 节点添加 PartitionModificationsListener ，用来监听Topic中分区分配变化. 更新集群元数据信息，同步到其他普通Broker节点中. Partition副本选举Leader机制Controller会监听 /brokers/ids 节点可感知Broker是否存活，当Controller感知到分区Leader所在Broker挂了，参数 unclean.leader.election.enable=false 的前提下，Controller会从 ISR列表里挑第一个Broker作为Leader，因为第一个Broker最先放进ISR列表可能是同步数据最多的副本，若参数 unclean.leader.election.enable=true 代表在 ISR列表里所有副本都挂了时可在ISR列表以外的副本中选Leader，该设置可提高可用性，但选出的新Leader可能数据少很多. 副本进入ISR列表有两个条件：副本节点不能产生分区，必须能与Zookeeper保持会话以及跟Leader副本网络连通；副本能复制Leader上的所有写操作，且不能落后太多，超过 replica.lag.time.max.ms 时间都没跟Leader同步过一次的副本会被移出 ISR 列表； offset记录机制每个Consumer会定期将自己消费分区的offset 提交给Kafka内部名称为 __consumer_offsets 的Topic，提交过去时key为consumerGroupId+topic+分区号，value就是当前offset的值，Kafka会定期清理该Topic里的消息保留最新的那条数据，因为 __consumer_offsets可能会接收高并发的请求，Kafka默认给其分配50个分区，可通过 offsets.topic.num.partitions 设置，这样可通过加机器的方式抗大并发. 通过公式 hash(consumerGroupId) % __consumer_offsets主题的分区数可选出Consumer消费的offset 要提交到 __consumer_offsets的哪个分区. 消费者Rebalance机制 Rebalance机制：若消费组中消费者数量变化或消费分区数变化，Kafka会重新分配消费者消费分区的关系. 如Consumer Group中某个消费者挂了，此时会自动把分配给它的分区交给其它消费者，若其恢复则又会把一些分区重新交还给它. Rebalance只针对Subscribe这种不指定分区消费的情况，若通过 assign 消费方式指定了分区Kafka不会进行Rebanlance . 当消费组中Consumer增加或减少、 动态给Topic增加分区、 消费组订阅了更多的Topic 等情况可能触发消费者Rebalance. Rebalance过程中消费者无法从Kafka消费消息，对Kafka的TPS会有影响，若Kafka集群内节点较多， Rebalance重平衡可能会耗时极多，应尽量避免在系统高峰期Rebalance重平衡. 消费者Rebalance分区分配策略消费者Rebalance分区分配策略主要有 range 、 round-robin 、 sticky 三种 Rebalance策略，默认为 range分配策略. Kafka提供消费者客户端参数 partition.assignment.strategy 来设置消费者与订阅主题之间的分区分配策略. range策略：按分区序号排序，假设 n＝分区数／消费者数量， m＝分区数%消费者数量，则前m个消费者每个分配n+1个分区，消费者数量 - m个消费者每个分配n个分区. round-robin策略：轮询分配 sticky策略：初始时分配策略与round-robin类似，但在Rebalance时需要保证分区分配尽可能均匀、 分区分配尽可能与上次分配保持相同两个原则. 当两者发生冲突时，第一个目标优先于第二个目标 . 这样可以最大程度维持原来的分区分配的策略. Rebalance过程当有消费者加入消费组时，消费者、 消费组及组协调器之间会依次经历选择组协调器、 加入消费组、 SYNC GROUP 三个阶段； 选择组协调器：每个Consumer Group都会选择一个Broker作为自己的组协调器GroupCoordinator ，负责监控该消费组中所有消费者心跳，以及判断是否宕机，然后开启消费者Rebalance. Consumer Group中每个Consumer启动时会向Kafka集群中某个节点发送 FindCoordinatorRequest 请求来查找对应的组协调器GroupCoordinator ，并跟其建立网络连接. Consumer消费的offset要提交到 __consumer_offsets 的哪个分区，该分区Leader对应的Broker就是该Consumer Group的GroupCoordinator. 加入消费组：消费者会向 GroupCoordinator 发送 JoinGroupRequest 请求并处理响应. 然后GroupCoordinator从一个Consumer Group中选择第一个加入Group的Consumer作为Leader消费组协调器，把Consumer Group情况发送给该Leader，接着该 Consumer Leader 会负责制定分区方案. SYNC GROUP ： Consumer Leader 通过给GroupCoordinator发送SyncGroupRequest ，接着 GroupCoordinator把分区方案下发给各个Consumer ，具体的 Consumer 根据指定分区的Leader Broker进行网络连接以及消息消费. Producer发布消息机制Producer采用 push模式将消息发布到Broker，每条消息都被append到顺序写磁盘到 Patition 中，Producer发送消息到Broker时，会根据分区算法选择将其存储到哪一个Partition，路由机制为： 指定了Patition，则直接使用； 未指定Patition但指定了key ，通过对key的value进行hash选出一个Patition Patition和key都未指定，使用轮询选出一个Patition. Producer先从Zookeeper的 /brokers/.../state 节点找到该Partition的Leader，然后将消息发送给该Leader，Leader将消息写入本地commit log，Followers从Leader Pull消息，写入本地commit log后向Leader发送ACK，Leader收到所有ISR中的Replica的ACK后，增加最后 commit 的offset即 high watermark高水位简称 HW 并向Producer发送ACK. HW和LEO High Watermark 俗称高水位，取一个 Partition 对应的 ISR中最小的log-end-offset即LEO作为HW ，Consumer最多只能消费到HW所在的位置. 每个 Replica 都有 HW ， Leader 和 Follower 各自负责更新自己的HW状态. 对于 Leader新写入的消息Consumer不能立刻消费，Leader会等待该消息被所有ISR中的Replicas同步后更新HW ，此时消息才能被Consumer消费. 这样保证了若Leader所在Broker失效，该消息仍然可从新选举的Leader中获取. 对于来自内部Broker的读取请求没有HW的限制. ISR以及HW和LEO的流转过程： Kafka复制机制既不是完全的同步复制，也不是单纯的异步复制. 同步复制要求所有能工作的Follower都复制完，这条消息才会被commit极大影响了吞吐率. 异步复制方式下Follower异步从Leader复制数据，数据只要被Leader写入log就被认为已经commit，这种情况下若Follower还未复制完落后于Leader时，若Leader宕机则会丢失数据. Kafka使用 ISR 方式则很好均衡了确保数据不丢失以及吞吐率. acks=1 的情况: 日志分段存储Kafka一个分区的消息数据对应存储在一个文件夹下，以Topic名称+分区号命名，消息在分区内是分段存储，每个段的消息都存储在不一样的log文件里，这种特性方便过期分段文件快速被删除，Kafka规定一个段位的 log文件最大为 1G . Kafka每次往分区发 4K 消息就会记录一条当前消息的 offset 到 index文件以及记录一条当前消息的发送时间戳与对应的 offset 到 timeindex文件，若要定位消息的 offset 会先在index文件里快速定位，若需要按照时间来定位消息的offset ，会先在timeindex文件里查找，再去log文件里找具体消息，相当于一个稀疏索引； 123456# 部分消息的offset索引文件，Kafka每次往分区发4K(可配置)消息就会记录一条当前消息的offset到index文件，若要定位消息的offset会先在该文件里快速定位，再去log文件里找具体消息，相当于一个稀疏索引00000000000000000000.index# 消息存储文件，主要存offset和消息体00000000000000000000.log# 消息的发送时间索引文件，kafka每次往分区发4K(可配置)消息就会记录一条当前消息的发送时间戳与对应的offset到timeindex文件，若需要按照时间来定位消息的offset，会先在这个文件里查找00000000000000000000.timeindex 一个日志段文件满了，会自动开一个新的日志段文件来写入，避免单个文件过大，影响文件的读写性能，该过程叫做 log rolling ，正在被写入的日志段文件叫做 active log segment 实际问题:消息丢失消息发送端 acks=0 ： 表示Producer不需要等待任何Broker确认收到消息的回复，就可继续发送下一条消息. 性能最高，但是最容易丢消息. 大数据统计报表场景，对性能要求很高，对数据丢失不敏感的情况可用这种. acks=1 ： 至少要等待Leader已经成功将数据写入本地log，但不需要等待所有Follower是否成功写入. 就可继续发送下一条消息. 该情况下若Follower没有成功备份数据，而此时Leader挂掉则消息会丢失. acks=-1或all ： Leader需等待所有备份即 min.insync.replicas 配置的备份个数都成功写入日志，该策略会保证只要有一个备份存活就不会丢失数据 消息消费端若消费这边配置的是自动提交，万一消费到数据还没处理完，就自动提交offset了，但此时Consumer直接宕机了，未处理完的数据丢失了，下次也消费不到了. 消息重复消费消息发送端：发送消息若配置了重试机制，如网络抖动时间过长导致发送端发送超时，实际broker可能已经接收到消息，但发送方会重新发送消息 消息消费端：若消费这边配置的是自动提交，刚拉取了一批数据处理了一部分，但还没来得及提交，服务挂了，下次重启又会拉取相同的一批数据重复处理，一般消费端都是要做消费幂等处理. 消息乱序若发送端配置了重试机制，Kafka不会等之前那条消息完全发送成功才去发送下一条消息，可能会出现发送了1，2，3条消息，第一条超时了，后面两条发送成功，再重试发送第1条消息，这时消息在broker端的顺序就是2，3，1了，是否一定要配置重试要根据业务情况而定. 也可用同步发送的模式去发消息，当然acks不能设置为0，这样也能保证消息发送的有序. kafka保证全链路消息顺序消费，需要从发送端开始，将所有有序消息发送到同一个分区，然后用一个消费者去消费，但性能比较低，可在消费者端接收到消息后将需要保证顺序消费的几条消费发到内存队列，一个内存队列开启一个线程顺序处理消息. 消息积压线上有时因为发送方发送消息速度过快，或者消费方处理消息过慢，可能会导致Broker积压大量未消费消息. 若积压了上百万未消费消息需要紧急处理，可修改消费端程序，让其将收到的消息快速转发到其他Topic ，可设置很多分区，然后再启动多个消费者同时消费新主题的不同分区. 由于消息数据格式变动或消费者程序有bug，导致消费者一直消费不成功，也可能导致broker积压大量未消费消息. 此种情况可将这些消费不成功的消息转发到其它队列里去，类似死信队列，后面再慢慢分析死信队列里的消息处理问题. 延时队列延时队列存储的对象是延时消息. 指消息被发送以后，并不想让消费者立刻获取，而是等待特定的时间后，消费者才能获取该消息进行消费，但Kafka不支持延时队列. 实现思路：发送延时消息时先把消息按照不同的延迟时间段发送到指定的队列中如topic_1s，topic_5s，topic_10s，…topic_2h，一般不能支持任意时间段的延时，然后通过定时器进行轮训消费这些Topic，查看消息是否到期，若到期则把该消息发送到具体业务处理的Topic中，队列中消息越靠前的到期时间越早，具体来说就是定时器在一次消费过程中，对消息的发送时间做判断，看下是否延迟到对应时间了，若到了就转发，如果还没到这一次定时任务就可以提前结束了. 消息回溯若某段时间对已消费消息计算的结果觉得有问题，可能是由于程序bug导致的计算错误，当程序bug修复后，这时可能需要对之前已消费的消息重新消费，可以指定从多久之前的消息回溯消费，这种可以用Consumer的offsetsForTimes、 seek等方法指定从某个offset偏移的消息开始消费. 消息传递保障kafka生产者的幂等性，因发送端重试导致的消息重复发送问题，Kafka幂等性可保证重复发送的消息只接收一次，只需在生产者加上参数 props.put(&quot;enable.idempotence&quot;, true) 即可，默认是false不开启，Kafka每次发送消息会生成 PID 和 Sequence Number 并将这两个属性一起发送给Broker，Broker将PID和Sequence Number跟消息绑定一起存起来，若生产者重发相同消息，Broker会检查PID和Sequence Number，若相同不会再接收. 每个新的Producer在初始化时会被分配一个唯一的PID，PID对用户完全是透明的，生产者若重启则会生成新的PID，每个PID该Producer发送到每个Partition的数据都有对应的序列号即 Sequence Number ，这些序列号是从0开始单调递增的. Kafka的事务Kafka事务不同于Rocketmq，Rocketmq是保障本地事务与MQ消息发送的事务一致性，Kafka的事务主要是保障一次发送多条消息的事务一致性，一般在Kafka流式计算场景用得多一点，如kafka需要对一个Topic中的消息做不同的流式计算处理，处理完分别发到不同的Topic里，这些Topic分别被不同的下游系统消费如hbase，redis，es等，这种肯定希望系统发送到多个topic的数据保持事务一致性. 12345678910111213141516171819202122Properties props = new Properties();props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);props.put(&quot;transactional.id&quot;, &quot;my-transactional-id&quot;);Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props, new StringSerializer(), new StringSerializer());producer.initTransactions(); //初始化事务try &#123; producer.beginTransaction(); //开启事务 for (int i = 0; i &lt; 100; i++) &#123;//发到不同的主题的不同分区 producer.send(new ProducerRecord&lt;&gt;(&quot;hdfs-topic&quot;, Integer.toString(i), Integer.toString(i))); producer.send(new ProducerRecord&lt;&gt;(&quot;es-topic&quot;, Integer.toString(i), Integer.toString(i))); producer.send(new ProducerRecord&lt;&gt;(&quot;redis-topic&quot;, Integer.toString(i), Integer.toString(i))); &#125; producer.commitTransaction(); //提交事务&#125; catch (ProducerFencedException | OutOfOrderSequenceException | AuthorizationException e) &#123; producer.close();&#125; catch (KafkaException e) &#123; producer.abortTransaction(); //回滚事务&#125;producer.close();","tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://example.com/tags/Kafka/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"Kafka","slug":"工具和中间件/消息队列/Kafka","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Kafka/"}]},{"title":"RabbitMQ-direct模式","date":"2019-03-23T04:08:20.000Z","path":"blog/工具和中间件/消息队列/RabbitMQ/RabbitMQ-direct模式/","text":"pom.xml123456789101112131415161718192021&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;artifactId&gt;rabbitmq&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;rabbitmq&lt;/name&gt; &lt;description&gt;rabbitmq&lt;/description&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt; &lt;artifactId&gt;amqp-client&lt;/artifactId&gt; &lt;version&gt;3.6.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;4.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; TestDriectProducer.java1234567891011121314151617181920212223242526272829303132333435363738package cn.peach;import java.io.IOException;import java.util.concurrent.TimeoutException; import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory; /** * 消息生成者 */public class TestDriectProducer &#123; public final static String QUEUE_NAME=&quot;direct_queue&quot;; public static void main(String[] args) throws IOException, TimeoutException &#123; RabbitMQUtil.checkServer(); //创建连接工厂 ConnectionFactory factory = new ConnectionFactory(); //设置RabbitMQ相关信息 factory.setHost(&quot;localhost&quot;); //创建一个新的连接 Connection connection = factory.newConnection(); //创建一个通道 Channel channel = connection.createChannel(); for (int i = 0; i &lt; 100; i++) &#123; String message = &quot;direct 消息 &quot; +i; //发送消息到队列中 channel.basicPublish(&quot;&quot;, QUEUE_NAME, null, message.getBytes(&quot;UTF-8&quot;)); System.out.println(&quot;发送消息： &quot; + message); &#125; //关闭通道和连接 channel.close(); connection.close(); &#125;&#125; TestDriectCustomer.java12345678910111213141516171819202122232425262728293031323334353637383940414243444546package cn.peach;import java.io.IOException;import java.util.concurrent.TimeoutException; import com.rabbitmq.client.AMQP;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import com.rabbitmq.client.Consumer;import com.rabbitmq.client.DefaultConsumer;import com.rabbitmq.client.Envelope; import cn.hutool.core.util.RandomUtil; public class TestDriectCustomer &#123; private final static String QUEUE_NAME = &quot;direct_queue&quot;; public static void main(String[] args) throws IOException, TimeoutException &#123; //为当前消费者取随机名 String name = &quot;consumer-&quot;+ RandomUtil.randomString(5); // 创建连接工厂 ConnectionFactory factory = new ConnectionFactory(); //设置RabbitMQ地址 factory.setHost(&quot;localhost&quot;); //创建一个新的连接 Connection connection = factory.newConnection(); //创建一个通道 Channel channel = connection.createChannel(); //声明要关注的队列 channel.queueDeclare(QUEUE_NAME, false, false, true, null); System.out.println(name +&quot; 等待接受消息&quot;); //DefaultConsumer类实现了Consumer接口，通过传入一个频道， // 告诉服务器我们需要那个频道的消息，如果频道中有消息，就会执行回调函数handleDelivery Consumer consumer = new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; String message = new String(body, &quot;UTF-8&quot;); System.out.println(name + &quot; 接收到消息 &#x27;&quot; + message + &quot;&#x27;&quot;); &#125; &#125;; //自动回复队列应答 -- RabbitMQ中的消息确认机制 channel.basicConsume(QUEUE_NAME, true, consumer); &#125;&#125; 运行效果先运行两次 TestDriectCustomer，启动两个消费者。然后运行一次 TestDriectProducer， 启动生产者，生产100条信息。此时就可以看到如图所示两个消费者分食 这100条信息。","tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://example.com/tags/RabbitMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RabbitMQ","slug":"工具和中间件/消息队列/RabbitMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/"}]},{"title":"ActiveMQ-主题模式","date":"2019-03-23T04:08:20.000Z","path":"blog/工具和中间件/消息队列/Activemq/ActiveMQ-主题模式/","text":"主题模式主题模式就是每个订阅了的消费者，都可以获取所有的消息，而不像队列模式那样要争抢。 pom.xml导入两个包，一个是 activemq ，另一个是 hutool jar包 123456789101112131415161718192021&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;artifactId&gt;activemq&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;activemq&lt;/name&gt; &lt;description&gt;activemq&lt;/description&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-all&lt;/artifactId&gt; &lt;version&gt;5.15.9&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;4.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; TestProducer.java和队列模式的 TestProducer几乎一模一样，只有一个地方有区别:Destination destination=session.createTopic(topicName);这里是 createTopic 而 队列模式是 createQueue 12345678910111213141516171819202122232425262728293031323334353637383940414243package cn.peach; import javax.jms.Connection;import javax.jms.ConnectionFactory;import javax.jms.Destination;import javax.jms.JMSException;import javax.jms.MessageProducer;import javax.jms.Session;import javax.jms.TextMessage; import org.apache.activemq.ActiveMQConnectionFactory; public class TestProducer &#123; //服务地址，端口默认61616 private static final String url=&quot;tcp://127.0.0.1:61616&quot;; //这次发送的消息名称 private static final String topicName=&quot;topic_style&quot;; public static void main(String[] args) throws JMSException &#123; //1.创建ConnectiongFactory,绑定地址 ConnectionFactory factory=new ActiveMQConnectionFactory(url); //2.创建Connection Connection connection= factory.createConnection(); //3.启动连接 connection.start(); //4.创建会话 Session session=connection.createSession(false, Session.AUTO_ACKNOWLEDGE); //5.创建一个目标 (主题类型) Destination destination=session.createTopic(topicName); //6.创建一个生产者 MessageProducer producer=session.createProducer(destination); for (int i = 0; i &lt; 100; i++) &#123; //7.创建消息 TextMessage textMessage=session.createTextMessage(&quot;主题消息-&quot;+i); //8.发送消息 producer.send(textMessage); System.out.println(&quot;发送：&quot;+textMessage.getText()); &#125; //7. 关闭连接 connection.close(); &#125;&#125; TestConsumer.java和队列模式的 TestProducer几乎一模一样，只有一个地方有区别：Destination destination=session.createTopic(topicName);这里是 createTopic 而 队列模式是 createQueue 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package cn.peach.topic; import javax.jms.Connection;import javax.jms.ConnectionFactory;import javax.jms.Destination;import javax.jms.JMSException;import javax.jms.Message;import javax.jms.MessageConsumer;import javax.jms.MessageListener;import javax.jms.Session;import javax.jms.TextMessage; import org.apache.activemq.ActiveMQConnectionFactory;import cn.hutool.core.util.RandomUtil;/** * 订阅者 * @author root * */public class TestConsumer &#123; //服务地址，端口默认61616 private static final String url=&quot;tcp://127.0.0.1:61616&quot;; //这次消费的消息名称 private static final String topicName=&quot;topic_style&quot;; //消费者有可能是多个，为了区分不同的消费者，为其创建随机名称 private static final String consumerName=&quot;consumer-&quot; + RandomUtil.randomString(5); public static void main(String[] args) throws JMSException &#123; //1.创建ConnectiongFactory,绑定地址 ConnectionFactory factory=new ActiveMQConnectionFactory(url); //2.创建Connection Connection connection= factory.createConnection(); //3.启动连接 connection.start(); //4.创建会话 Session session=connection.createSession(false, Session.AUTO_ACKNOWLEDGE); //5.创建一个目标 （主题类型） Destination destination=session.createTopic(topicName); //6.创建一个消费者 MessageConsumer consumer=session.createConsumer(destination); //7.创建一个监听器 consumer.setMessageListener(new MessageListener() &#123; public void onMessage(Message arg0) &#123; // TODO Auto-generated method stub TextMessage textMessage=(TextMessage)arg0; try &#123; System.out.println(consumerName +&quot; 接收消息：&quot;+textMessage.getText()); &#125; catch (JMSException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; &#125;); //8. 因为不知道什么时候有，所以没法主动关闭，就不关闭了，一直处于监听状态 //connection.close(); &#125;&#125; 消费者要先启动需要注意的一点是，对于主题模式而言， 消费者要先启动。 如果在生产者生产完成之后，再启动，是看不到消息的。就如同现在才关注某个公众号，那么以前公众号发的信息，现在是看不到的。 只有以后发的，才看得到了。 运行效果 管理界面","tags":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"http://example.com/tags/ActiveMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"Activemq","slug":"工具和中间件/消息队列/Activemq","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Activemq/"}]},{"title":"RabbitMQ-fanout模式","date":"2019-03-23T03:08:20.000Z","path":"blog/工具和中间件/消息队列/RabbitMQ/RabbitMQ-fanout模式/","text":"pom.xml提供 rabbitmq和hutool的jar 1234567891011121314151617181920&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;artifactId&gt;rabbitmq&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;rabbitmq&lt;/name&gt; &lt;description&gt;rabbitmq&lt;/description&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt; &lt;artifactId&gt;amqp-client&lt;/artifactId&gt; &lt;version&gt;3.6.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;4.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; TestProducer.java12345678910111213141516171819202122232425262728293031323334353637383940package cn.peach;import java.io.IOException;import java.util.concurrent.TimeoutException; import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory; /** * 消息生成者 */public class TestProducer &#123; public final static String EXCHANGE_NAME=&quot;fanout_exchange&quot;; public static void main(String[] args) throws IOException, TimeoutException &#123; RabbitMQUtil.checkServer(); //创建连接工厂 ConnectionFactory factory = new ConnectionFactory(); //设置RabbitMQ相关信息 factory.setHost(&quot;localhost&quot;); //创建一个新的连接 Connection connection = factory.newConnection(); //创建一个通道 Channel channel = connection.createChannel(); channel.exchangeDeclare(EXCHANGE_NAME, &quot;fanout&quot;); for (int i = 0; i &lt; 100; i++) &#123; String message = &quot;direct 消息 &quot; +i; //发送消息到队列中 channel.basicPublish(EXCHANGE_NAME, &quot;&quot;, null, message.getBytes(&quot;UTF-8&quot;)); System.out.println(&quot;发送消息： &quot; + message); &#125; //关闭通道和连接 channel.close(); connection.close(); &#125;&#125; TestDriectCustomer.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package cn.peach;import java.io.IOException;import java.util.concurrent.TimeoutException; import com.rabbitmq.client.AMQP;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import com.rabbitmq.client.Consumer;import com.rabbitmq.client.DefaultConsumer;import com.rabbitmq.client.Envelope; import cn.hutool.core.util.RandomUtil; public class TestCustomer &#123; public final static String EXCHANGE_NAME=&quot;fanout_exchange&quot;; public static void main(String[] args) throws IOException, TimeoutException &#123; //为当前消费者取随机名 String name = &quot;consumer-&quot;+ RandomUtil.randomString(5); //判断服务器是否启动 RabbitMQUtil.checkServer(); // 创建连接工厂 ConnectionFactory factory = new ConnectionFactory(); //设置RabbitMQ地址 factory.setHost(&quot;localhost&quot;); //创建一个新的连接 Connection connection = factory.newConnection(); //创建一个通道 Channel channel = connection.createChannel(); //交换机声明（参数为：交换机名称；交换机类型） channel.exchangeDeclare(EXCHANGE_NAME,&quot;fanout&quot;); //获取一个临时队列 String queueName = channel.queueDeclare().getQueue(); //队列与交换机绑定（参数为：队列名称；交换机名称；routingKey忽略） channel.queueBind(queueName,EXCHANGE_NAME,&quot;&quot;); System.out.println(name +&quot; 等待接受消息&quot;); //DefaultConsumer类实现了Consumer接口，通过传入一个频道， // 告诉服务器我们需要那个频道的消息，如果频道中有消息，就会执行回调函数handleDelivery Consumer consumer = new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; String message = new String(body, &quot;UTF-8&quot;); System.out.println(name + &quot; 接收到消息 &#x27;&quot; + message + &quot;&#x27;&quot;); &#125; &#125;; //自动回复队列应答 -- RabbitMQ中的消息确认机制 channel.basicConsume(queueName, true, consumer); &#125;&#125; 运行效果先运行两次 TestCustomer，启动两个消费者。然后运行一次 TestProducer， 启动生产者，生产100条信息。此时就可以看到如图所示两个消费者都能收到 这100条信息","tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://example.com/tags/RabbitMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RabbitMQ","slug":"工具和中间件/消息队列/RabbitMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/"}]},{"title":"ActiveMQ-队列模式","date":"2019-03-23T03:08:20.000Z","path":"blog/工具和中间件/消息队列/Activemq/ActiveMQ-队列模式/","text":"pom.xml导入activemq jar包 12345678910111213141516&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.peach&lt;/groupId&gt; &lt;artifactId&gt;activemq&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;activemq&lt;/name&gt; &lt;description&gt;activemq&lt;/description&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-all&lt;/artifactId&gt; &lt;version&gt;5.15.9&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; TestProducer.java生产100条消息。注： activemq 服务器应先启动。 12345678910111213141516171819202122232425262728293031323334353637383940414243package cn.peach.queue; import javax.jms.Connection;import javax.jms.ConnectionFactory;import javax.jms.Destination;import javax.jms.JMSException;import javax.jms.MessageProducer;import javax.jms.Session;import javax.jms.TextMessage; import org.apache.activemq.ActiveMQConnectionFactory; public class TestProducer &#123; //服务地址，端口默认61616 private static final String url=&quot;tcp://127.0.0.1:61616&quot;; //这次发送的消息名称 private static final String topicName=&quot;queue_style&quot;; public static void main(String[] args) throws JMSException &#123; //1.创建ConnectionFactory,绑定地址 ConnectionFactory factory=new ActiveMQConnectionFactory(url); //2.创建Connection Connection connection= factory.createConnection(); //3.启动连接 connection.start(); //4.创建会话 Session session=connection.createSession(false, Session.AUTO_ACKNOWLEDGE); //5.创建一个目标 (队列类型) Destination destination=session.createQueue(topicName); //6.创建一个生产者 MessageProducer producer=session.createProducer(destination); for (int i = 0; i &lt; 100; i++) &#123; //7.创建消息 TextMessage textMessage=session.createTextMessage(&quot;队列消息-&quot;+i); //8.发送消息 producer.send(textMessage); System.out.println(&quot;发送：&quot;+textMessage.getText()); &#125; //7. 关闭连接 connection.close(); &#125;&#125; TestConsumer.java消费者，消费服务器上的消息。注： activemq 服务器应先启动。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package cn.peach.queue; import javax.jms.Connection;import javax.jms.ConnectionFactory;import javax.jms.Destination;import javax.jms.JMSException;import javax.jms.Message;import javax.jms.MessageConsumer;import javax.jms.MessageListener;import javax.jms.Session;import javax.jms.TextMessage; import org.apache.activemq.ActiveMQConnectionFactory; import cn.peach.util.ActiveMQUtil;import cn.hutool.core.util.RandomUtil;/** * 订阅者 * @author root * */public class TestConsumer &#123; //服务地址，端口默认61616 private static final String url=&quot;tcp://127.0.0.1:61616&quot;; //这次消费的消息名称 private static final String topicName=&quot;queue_style&quot;; //消费者有可能是多个，为了区分不同的消费者，为其创建随机名称 private static final String consumerName=&quot;consumer-&quot; + RandomUtil.randomString(5); public static void main(String[] args) throws JMSException &#123; //1.创建ConnectiongFactory,绑定地址 ConnectionFactory factory=new ActiveMQConnectionFactory(url); //2.创建Connection Connection connection= factory.createConnection(); //3.启动连接 connection.start(); //4.创建会话 Session session=connection.createSession(false, Session.AUTO_ACKNOWLEDGE); //5.创建一个目标 （队列类型） Destination destination=session.createQueue(topicName); //6.创建一个消费者 MessageConsumer consumer=session.createConsumer(destination); //7.创建一个监听器 consumer.setMessageListener(new MessageListener() &#123; public void onMessage(Message arg0) &#123; // TODO Auto-generated method stub TextMessage textMessage=(TextMessage)arg0; try &#123; System.out.println(consumerName +&quot; 接收消息：&quot;+textMessage.getText()); &#125; catch (JMSException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; &#125;); //8. 因为不知道什么时候有，所以没法主动关闭，就不关闭了，一直处于监听状态 //connection.close(); &#125;&#125; 管理界面访问地址： http://127.0.0.1:8161/admin/queues.jsp 就可以看到 刚才的消息处理情况。 queue_style 是在代码中定义的消息名称。 number Of Consumers 表示有2个消费者。 Messages Enqueued：表示收到了 100 个消息。 Messages Dequeued：表示消费了 100 个消息。","tags":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"http://example.com/tags/ActiveMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"Activemq","slug":"工具和中间件/消息队列/Activemq","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Activemq/"}]},{"title":"Kafka-基础","date":"2019-03-23T02:08:20.000Z","path":"blog/工具和中间件/消息队列/Kafka/Kafka-基础/","text":"Kafka是什么? Kafka 是 scala 语言编写的 支持partition分区、 replica多副本, 基于Zookeeper协调 的 分布式消息系统, 可 实时处理大量数据 以满足各种需求场景, 如基于hadoop批处理系统、 低延迟实时系统、 Storm&#x2F;Spark流式处理引擎, web&#x2F;nginx日志、 访问日志, 消息服务等. 名称 解释 Broker 消息中间件处理节点, 一个Kafka节点就是一个Broker, 一个或者多个Broker组成Kafka集群 Topic Kafka根据Topic对消息进行归类, 发布到Kafka集群的每条消息都需指定一个Topic Producer 消息生产者, 向Broker发送消息的客户端, 通过TCP协议来完成通信 Consumer 消息消费者, 从Broker读取消息的客户端, 通过TCP协议来完成通信 Consumer Group 每个Consumer属于一个特定Consumer Group, 一条消息可被多个不同Consumer Group消费, 但一个Consumer Group中只能有一个Consumer能消费该消息 Partition 物理上的概念, 一个Topic可分为多个Partition, 每个Partition内部消息是有序的 使用场景 日志收集：可用Kafka收集各种服务日志, 通过kafka以统一接口服务方式开放给各种Consumer, 如Hhadoop、 Hbase、 Solr等. 消息系统：解耦生产者和消费者、 缓存消息等. 用户活动跟踪：Kafka经常被用来记录Web用户或App用户的各种活动, 如浏览网页、 搜索、 点击等活动, 被各个服务器发布到kafka的Topic中, 然后订阅者通过订阅这些Topic来做实时监控分析, 或装载到Hadoop、 数据仓库中做离线分析和挖掘. 运营指标：Kafka也经常用来记录运营监控数据. 包括收集各种分布式应用数据, 生产各种操作的集中反馈, 如报警和报告. Kafka核心配置Kafka核心配置在 config/server.properties 配置文件中. 1234broker.id=0 # broker.id属性在kafka集群中必须要是唯一listeners=PLAINTEXT://localhost:9092 # kafka部署的机器ip和提供服务的端口号log.dir=/usr/local/data/kafka-logs # kafka的消息存储文件zookeeper.connect=192.168.65.60:2181 # kafka连接zookeeper的地址, 若是集群则用逗号分割 Property Default Description broker.id 0 每个Broker都可用一个唯一非负整数id进行标识 log.dirs /tmp/kafka-logs 存放数据的路径, 该路径并不唯一, 可设置多个路径之间用逗号分隔, 创建新partition时选择包含最少partitions路径下创建 listeners PLAINTEXT://192.168.65.60:9092 Server接受客户端连接的端口, ip配置kafka本机ip即可 zookeeper.connect localhost:2181 Kafka连接Zookeeper的地址, 若是集群用逗号分隔 log.retention.hours 168 每个日志文件的保存时间. 默认数据保存时间对所有topic都一样 num.partitions 1 创建Topic默认分区数 default.replication.factor 1 自动创建Topic默认副本数量, 建议设置为大于等于2 min.insync.replicas 1 写数据到repica数量达到设定值才表示Producer发送消息成功, 若Producer设置acks为-1, 则每个repica写数据都必须成功 delete.topic.enable false 是否允许删除主题 12345678910111213141516171819202122232425262728bin/kafka-server-start.sh config/server.properties # 启动kafkabin/kafka-server-stop.sh # 停止kafka# 创建名字为test的Topic, 该topic只有一个partition, 且备份因子为1bin/kafka-topics.sh --zookeeper localhost:2181 --create --replication-factor 1 --partitions 1 --topic test# 查看kafka中目前存在的topicbin/kafka-topics.sh --zookeeper localhost:2181 --list# 删除topicbin/kafka-topics.sh --zookeeper localhost:2181 --delete --topic test# 发送消息到kafka, 若是集群--broker-list参数用逗号隔开bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test# 消费kafka集群最新消息, 若是集群--bootstrap-server参数用逗号隔开bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test# 多主题消费kafka集群消息bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --whitelist &quot;test|test-2&quot;# 通过--from-beginning从开始读取kafka集群消息bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --from-beginning --topic test# 单播消费, 一条消息只能被某一个消费者消费, 让所有消费者在同一个消费组里即可bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --consumer-property group.id=testGroup --topic test# 多播消费, 同一条消息只能被同一个消费组下的某一个消费者消费的特性bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --consumer-property group.id=testGroup-2 --topic test# 查看消费组名bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list# 查看消费组的消费偏移量, current-offset当前消费组的已消费偏移量, log-end-offset主题对应分区消息结束偏移量, lag当前消费组未消费消息数bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group testGroup# 查看下topic情况bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic test# 增加topic的分区数量, 目前kafka不支持减少分区bin/kafka-topics.sh --zookeeper localhost:2181 --alter --partitions 3 --topic test 同类消息发送到同一个Topic下面, 每个Topic下面可有多个分区Partition日志文件, Partition 是一个有序的message序列, 这些message按顺序添加到 commit log文件 中. 每个Partition中消息都有一个唯一编号 offset , 用来唯一标识某个分区中的message. 每个Partition都对应一个commit log文件, 同一个Partition 中的 message 的offset都是 唯一 的, 但 不同Partition 中 message 的 offset 可能相同. 每个Partition分区中都有一个Leader副本节点和一个或多个Replicas副本以及一个 Isr 集合， Partition的Leader副本节点负责给定Partition的所有读写请求，Replicas表示某个Partition在哪几个Broker上存在备份，不管该节点是不是Leader，甚至该节点挂了也会列出. Isr 集合是Replicas的一个子集，只列出存活的备份节点，且已同步备份了该Partition的节点. Kafka一般不会删除消息，不管是否被消费. 只会根据配置的日志保留时间log.retention.hours 确认消息多久被删除，默认保留最近一周的消息. Kafka性能与保留消息数据量大小没有关系. 每个Consumer是基于commit log中消费进度即offset 来进行工作的，消费offset由Consumer来维护，一般按照顺序逐条消费commit log中的消息，可通过指定offset来重复消费某些消息或跳过某些消息. 意味Consumer对集群影响非常小，添加或减少Consumer对于集群或其他Consumer没有影响，因为每个Consumer维护各自的消费offset . 一个Topic代表逻辑上的一个业务数据集，对于大型网站来说，后端数据都是海量的，消息可能非常巨量，若把这么多数据都放在一台机器上可能会有容量限制问题，可在 Topic内部划分多个Partition 来分片存储数据，不同Partition可位于不同机器上，每台机器上都运行一个Kafka的Broker进程. 分片存储的好处，提高并行度，且 commit log 文件会受到所在机器的文件系统大小的限制，分区后可将不同分区放在不同机器上，相当于对数据做分布式存储，理论上一个Topic可处理任意数量数据. Kafka集群Kafka将很多集群关键信息记录在 Zookeeper 中，保证自己的无状态，从而在水平扩容时非常方便. commit log 的 Partitions 分布在Kafka集群中不同Broker上，每个Broker上该Partition分区的副本可请求备份其他Broker上Partition上副本的数据，Kafka集群支持配置一个Partition备份数量. 每个Partition都有一个Broker上的副本起到Leader的作用， 0个或多个其他的Broker副本作为 Follwers 作用. 作为 Leader的副本处理所有针对该Partition的读写请求，作为Followers的副本被动复制作为Leader的副本的结果，不提供读写，主要是为了保证多副本数据与消费的一致性. 若一个Partition分区中 Leader副本失效其中一个 Follower副本将自动变成新的 Leader副本. 生产者将消息发送到Topic中去，同时负责选择将message发送到 Topic的哪个Partition中. 通过 round-robin 做简单的负载均衡. 也可根据消息中某个关键字来进行区分，通常第二种方式使用更多. 对于消费者，传统的消息传递模式有队列模式和发布订阅模式，且基于这2种模式提供了一种Consumer的抽象概念 Consumer Group . Queue模式：多个Consumer从服务器中读取数据，消息只会到达一个Consumer ，所有Consumer都位于同一Consumer Group下 Publish-Subscribe模式：消息会被广播给所有Consumer，所有Consumer都有唯一的Consumer Group . 通常一个Topic会有几个Consumer Group，每个Consumer Group都是一个逻辑上的订阅者，每个Consumer Group由多个Consumer 实例组成，从而达到可扩展和容灾的功能. 一个Partition同一时刻在一个Consumer Group中只能有一个Consumer在消费， Partition分区类似于RocketMQ中的队列，从而保证消费顺序. Consumer Group中的Consumer数不能比一个Topic中Partition的数量多，否则多出来的Consumer消费不到消息. Kafka只在Partition范围内保证消息消费的局部顺序性，不能在同一个Topic中多个Partition中保证总的消费顺序性. 若有在总体上保证消费顺序的需求，则可通过将Topic的Partition数量设置为1 ，将Consumer Group中的Consumer数量也设置为1 ，但会影响性能，故Kafka顺序消费很少用. 客户端调用12345&lt;dependency&gt; &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt; &lt;version&gt;2.4.1&lt;/version&gt;&lt;/dependency&gt; 生产者包含一些关键的参数，包括发送消息持久化机制参数ProducerConfig.ACKS_CONFIG ，发送失败会重试次数 ProducerConfig.RETRIES_CONFIG ，重试时间间隔 ProducerConfig.RETRY_BACKOFF_MS_CONFIG ，以及发送时可指定Partition分区，同步发送异步发送等. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152Properties props = new Properties();props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:9092&quot;);/* 发出消息持久化机制参数（1）acks=0：表示producer不需要等待任何broker确认收到消息的回复，就可以继续发送下一条消息. 性能最高，但是最容易丢消息. （2）acks=1：至少等待leader成功将数据写入本地log，但不用等待所有followe都成功写入. 就可继续发送下一条消息. 该情况下若follower没有成功备份数据，而此时leader又挂掉，则消息会丢失. （3）acks=-1或all：需等待min.insync.replicas，默认为1，推荐配置大于等于2，该参数配置的副本个数都成功写入日志，这种策略会保证 只要有一个备份存活就不会丢失数据. 这是最强的数据保证. 一般除非是金融级别，或跟钱打交道的场景才会使用这种配置. */props.put(ProducerConfig.ACKS_CONFIG, &quot;1&quot;);// 发送失败会重试，默认重试间隔100ms，重试能保证消息发送的可靠性，但也可能造成消息重复发送，如网络抖动，故需在接收者处做好消息接收的幂等性处理props.put(ProducerConfig.RETRIES_CONFIG, 3);// 重试时间间隔设置props.put(ProducerConfig.RETRY_BACKOFF_MS_CONFIG, 300);// 设置发送消息的本地缓冲区，如果设置了该缓冲区，消息会先发送到本地缓冲区，可以提高消息发送性能，默认值是33554432，即32MBprops.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 33554432);// kafka本地线程会从缓冲区取数据，批量发送到broker，设置批量发送消息的大小，默认值是16384，即16kb，就是说一个batch满了16kb就发送出去props.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384);// 默认值是0，消息必须立即被发送，但这样会影响性能，一般设置10毫秒左右，该消息发送完后会进入本地的一个batch，// 若10毫秒内该batch满了16kb就随batch一起被发送出去，若10毫秒内batch没满，则也必须把消息发送出去，不能让消息的发送延迟时间太长props.put(ProducerConfig.LINGER_MS_CONFIG, 10);// 把发送的key从字符串序列化为字节数组props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());// 把发送消息value从字符串序列化为字节数组props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());Producer&lt;String, String&gt; producer = new KafkaProducer&lt;String, String&gt;(props);int msgNum = 5;final CountDownLatch countDownLatch = new CountDownLatch(msgNum);for (int i = 1; i &lt;= msgNum; i++) &#123; // 指定发送分区 // ProducerRecord&lt;String, String&gt; producerRecord = new ProducerRecord&lt;String, String&gt;(TOPIC_NAME , 0, order.getOrderId().toString(), JSON.toJSONString(order)); // 未指定发送分区，具体发送的分区计算公式：hash(key)%partitionNum ProducerRecord&lt;String, String&gt; producerRecord = new ProducerRecord&lt;String, String&gt;(TOPIC_NAME, String.valueOf(i), &quot;order &quot; + i); // 等待消息发送成功的同步阻塞方法 // RecordMetadata metadata = producer.send(producerRecord).get(); // System.out.println(&quot;同步方式发送消息结果：&quot; + &quot;topic-&quot; + metadata.topic() + &quot;|partition-&quot; + metadata.partition() + &quot;|offset-&quot; + metadata.offset()); //异步回调方式发送消息 producer.send(producerRecord, new Callback() &#123; @Override public void onCompletion(RecordMetadata metadata, Exception exception) &#123; if (exception != null) &#123; System.err.println(&quot;发送消息失败：&quot; + exception.getStackTrace()); &#125; if (metadata != null) &#123; System.out.println(&quot;异步方式发送消息结果：&quot; + &quot;topic-&quot; + metadata.topic() + &quot;|partition-&quot; + metadata.partition() + &quot;|offset-&quot; + metadata.offset()); &#125; countDownLatch.countDown(); &#125; &#125;);&#125;countDownLatch.await(5, TimeUnit.SECONDS);producer.close(); 消费者同样可指定消费的分区，指定消费者组名称，是否自动提交，自动提交时间间隔，心跳时间间隔等. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980String TOPIC_NAME = &quot;my-replicated-topic&quot;;String CONSUMER_GROUP_NAME = &quot;testGroup&quot;;Properties props = new Properties();props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:9092&quot;);// 消费分组名props.put(ConsumerConfig.GROUP_ID_CONFIG, CONSUMER_GROUP_NAME);// 是否自动提交offset，默认就是trueprops.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, &quot;true&quot;);// 自动提交offset的间隔时间props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, &quot;1000&quot;);//props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, &quot;false&quot;);/*当消费主题的是一个新的消费组，或指定offset的消费方式，offset不存在，则可通过以下两种方式消费消息- latest(默认) ：只消费自己启动之后发送到主题的消息- earliest：第一次从头开始消费，以后按照消费offset记录继续消费，这个需要区别于consumer.seekToBeginning(每次都从头开始消费)*///props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, &quot;earliest&quot;);// consumer给broker发送心跳的间隔时间，broker接收到心跳若此时有rebalance发生会通过心跳响应将rebalance方案下发给consumer，该时间可以稍微短一点props.put(ConsumerConfig.HEARTBEAT_INTERVAL_MS_CONFIG, 1000);// 服务端broker多久感知不到一个consumer心跳就认为他故障了，会将其踢出消费组，对应的Partition也会被重新分配给其他consumer，默认是10秒props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, 10 * 1000);// 一次poll最大拉取消息的条数，若消费者处理速度很快，可以设置大点，若处理速度一般，可以设置小点props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, 500);// 若两次poll操作间隔超过该时间，则broker认为该consumer处理能力太弱，会将其踢出消费组，将分区分配给别的consumer消费props.put(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG, 30 * 1000);props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;String, String&gt;(props);consumer.subscribe(Arrays.asList(TOPIC_NAME));// 消费指定分区//consumer.assign(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));// 消息回溯消费//consumer.seekToBeginning(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));// 指定offset消费//consumer.seek(new TopicPartition(TOPIC_NAME, 0), 10);// 从指定时间点开始消费/*List&lt;PartitionInfo&gt; topicPartitions = consumer.partitionsFor(TOPIC_NAME);//从1小时前开始消费long fetchDataTime = new Date().getTime() - 1000 * 60 * 60;Map&lt;TopicPartition, Long&gt; map = new HashMap&lt;&gt;();for (PartitionInfo par : topicPartitions) &#123; map.put(new TopicPartition(topicName, par.partition()), fetchDataTime);&#125;Map&lt;TopicPartition, OffsetAndTimestamp&gt; parMap = consumer.offsetsForTimes(map);for (Map.Entry&lt;TopicPartition, OffsetAndTimestamp&gt; entry : parMap.entrySet()) &#123; TopicPartition key = entry.getKey(); OffsetAndTimestamp value = entry.getValue(); if (key == null || value == null) continue; Long offset = value.offset(); System.out.println(&quot;partition-&quot; + key.partition() + &quot;|offset-&quot; + offset); System.out.println(); //根据消费里的timestamp确定offset if (value != null) &#123; consumer.assign(Arrays.asList(key)); consumer.seek(key, offset); &#125;&#125;*/while (true) &#123; // poll() API 是拉取消息的长轮询 ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofMillis(1000)); for (ConsumerRecord&lt;String, String&gt; record : records) &#123; System.out.printf(&quot;收到消息：partition = %d, offset = %d, key = %s, value = %s%n&quot;, record.partition(), record.offset(), record.key(), record.value()); &#125; /*if (records.count() &gt; 0) &#123; // 手动同步提交offset，当前线程会阻塞直到offset提交成功一般使用同步提交，因为提交之后一般也没有什么逻辑代码了 consumer.commitSync(); // 手动异步提交offset，当前线程提交offset不会阻塞，可以继续处理后面的程序逻辑 consumer.commitAsync(new OffsetCommitCallback() &#123; @Override public void onComplete(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets, Exception exception) &#123; if (exception != null) &#123; System.err.println(&quot;Commit failed for &quot; + offsets); System.err.println(&quot;Commit failed exception: &quot; + exception.getStackTrace()); &#125; &#125; &#125;); &#125;*/&#125;","tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://example.com/tags/Kafka/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"Kafka","slug":"工具和中间件/消息队列/Kafka","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Kafka/"}]},{"title":"RabbitMQ-基础","date":"2019-03-23T02:08:20.000Z","path":"blog/工具和中间件/消息队列/RabbitMQ/RabbitMQ-基础/","text":"介绍RabbitMQ 也是一种 消息中间件的实现。与ActiveMQ的区别在： rabbitmq 更专业，更灵活，大企业，大型高要求的应用，普遍会采用 rabbitmq 来支持。 erlangrabbitMQ 是基于 erlang 语言开发的，就如同 activemq 需要安装 java 环境一样， 为了使用 rabbitMQ 需要安装 erlang环境。 erlang 环境使用快捷键 win+r, 然后输入 cmd, 接着运行 erl。 出现如图所示的界面，就表示安装成功了。 安装 rabbitMQ官网下载rar包, 运行里面的 rabbitmq-server-3.6.5.exe，使用默认设置，下一步下一步即可。 配置插件运行如下命令 enable rabbitmq_management，可以做到对 rabbitmq的插件配置。 1C:\\Program Files\\RabbitMQ Server\\rabbitmq_server-3.6.5\\sbin\\rabbitmq-plugins.bat&quot; enable rabbitmq_management 重启 rabbitmq管理员身份运行以下命令以重启 rabbitmq： 1net stop RabbitMQ &amp;&amp; net start RabbitMQ 访问管理界面管理界面： http://127.0.0.1:15672 输入账号： guest密码： guest就可以登陆进去了。 管理界面 RabbitMQ - 模式AMQP AMQP 是 dvanced Message Queuing Protocol 的缩写。 与activemq不一样， rabbitmq 使用的是一种叫做 AMQP 的协议来通信。简单地说，通过这种协议，可以处理更为复杂的业务需求。 基于 AMQP 这种协议，可以实现的各种模式 消息路由过程与 ActiveMQ 拿到消息就直接放在队列等待消费者拿走不同， Rabbit 拿到消息之后，会先交给 交换机 （Exchange）, 然后交换机再根据预先设定的不同绑定( Bindings )策略，来确定要发给哪个队列。如图所示，比起 ActiveMQ 多了 Exchange 和 Bindings。由于有了 Exchange 和 Bindings， RabbitMQ 就可以灵活地支撑各种模式。 模式RabbitMQ提供了 四种Exchange模式： fanout, direct, topic, header。 1. fanout 模式fanout 模式就是广播模式, 消息来了，会发给所有的队列。 2. Direct 模式Direct 模式就是指定队列模式， 消息来了，只发给指定的 Queue, 其他Queue 都收不到。 3. Topic 模式主题模式，注意这里的主题模式，和 ActivityMQ 里的不一样。 ActivityMQ 里的主题，更像是广播模式。那么这里的主题模式是什么意思呢？ 如图所示消息来源有： 美国新闻，美国天气，欧洲新闻，欧洲天气。如果你想看 美国主题： 那么就会收到 美国新闻，美国天气。如果你想看 新闻主题： 那么就会收到 美国新闻，欧洲新闻。如果你想看 天气主题： 那么就会收到 美国天气，欧洲天气。如果你想看 欧洲主题： 那么就会收到 欧洲新闻，欧洲天气。 4. headers交换机 模式。headers交换机是一种比较复杂且少见的交换机，不同于direct和topic，它不关心路由key是否匹配，而只关心header中的key-value对是否匹配(这里的匹配为精确匹配，包含键和值都必须匹配)， 有点类似于http中的请求头。headers头路由模型中，消息是根据prop即请求头中key-value来匹配的。消费方指定的headers中必须包含一个”x-match”的键。 键”x-match”的值有2个：all和any。all：表示消费方指定的所有key-value都必须在消息header中出现并匹配。any：表示消费方指定的key-value至少有一个在消息header中出现并匹配即可。 headers 匹配规则：any 、allany: 只要在发布消息时携带的有一对键值对headers满足队列定义的多个参数的其中一个就能匹配上，注意这里是键值对的完全匹配，只匹配到键了，值却不一样是不行的；all：在发布消息时携带的所有Entry必须和绑定在队列上的所有Entry完全匹配。缺点：Headers 类型的交换器性能会很差","tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://example.com/tags/RabbitMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RabbitMQ","slug":"工具和中间件/消息队列/RabbitMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/"}]},{"title":"ActiveMQ-基础","date":"2019-03-23T02:08:20.000Z","path":"blog/工具和中间件/消息队列/Activemq/ActiveMQ-基础/","text":"ActiveMQ：ActiveMQ 是用 Java 语言开发的消息中间件，简单易用。只需要操作系统支持Java虚拟机，ActiveMQ便可执行。 下载并启动：apache-activemq-5.15.8-bin.rar, 解压并运行32或者64位操作系统对应的 activemq.bat 就启动 启动成功界面 访问地址启动好之后， 访问地址 http://127.0.0.1:8161/ 就可以看到如图所示的界面。这就是服务器的管理界面，在里面就可以看到都有哪些消息被创建了，哪些被消费了 管理界面点击 manage activeMQ broker, 或者直接访问地址：http://127.0.0.1:8161/admin/会弹出登录对话框，输入默认的账号和密码，都是： admin就来到了管理界面了。 观察数据这里可以观察到 队列数据和主题数据等信息，不过还没有客户端发消息来，所以也没有数据，就先不管。 模式activeMQ 有两种模式，分别是 队列模式 和 主题模式。 队列模式，其实就是分食模式。 比如生产方发了 10条消息到 activeMQ 服务器， 而此时有多个 消费方，那么这些消费方就会瓜分这些10条消息，一条消息只会被一个消费方得到。 主题模式，就是订阅模式。 比如生产方发了10条消息，而此时有多个消费方，那么多个消费方都能得到这 10条消息，就如同订阅公众号那样。","tags":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"http://example.com/tags/ActiveMQ/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"Activemq","slug":"工具和中间件/消息队列/Activemq","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Activemq/"}]},{"title":"Solr更新和删除索引","date":"2018-12-01T08:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/Solr/Solr更新和删除索引/","text":"SolrUtil.javaSolrUtil提供一个对象的增加或者更新(都是同一个方法） 1234567public static &lt;T&gt; boolean saveOrUpdate(T entity) throws SolrServerException, IOException &#123; DocumentObjectBinder binder = new DocumentObjectBinder(); SolrInputDocument doc = binder.toSolrInputDocument(entity); client.add(doc); client.commit(); return true;&#125; 根据id删除这个索引 12345678910public static boolean deleteById(String id) &#123; try &#123; client.deleteById(id); client.commit(); &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; return true;&#125; 完整代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102package cn.peach;import java.io.IOException;import java.util.List;import org.apache.solr.client.solrj.SolrClient;import org.apache.solr.client.solrj.SolrQuery;import org.apache.solr.client.solrj.SolrServerException;import org.apache.solr.client.solrj.beans.DocumentObjectBinder;import org.apache.solr.client.solrj.impl.HttpSolrClient;import org.apache.solr.client.solrj.response.QueryResponse;import org.apache.solr.common.SolrDocument;import org.apache.solr.common.SolrDocumentList;import org.apache.solr.common.SolrInputDocument;import org.apache.solr.common.util.NamedList;public class SolrUtil &#123; public static SolrClient client; private static String url; static &#123; url = &quot;http://localhost:8983/solr/howToSolr&quot;; client = new HttpSolrClient.Builder(url).build(); &#125; public static void queryHighlight(String keywords) throws SolrServerException, IOException &#123; SolrQuery q = new SolrQuery(); //开始页数 q.setStart(0); //每页显示条数 q.setRows(10); // 设置查询关键字 q.setQuery(keywords); // 开启高亮 q.setHighlight(true); // 高亮字段 q.addHighlightField(&quot;name&quot;); // 高亮单词的前缀 q.setHighlightSimplePre(&quot;&lt;span style=&#x27;color:red&#x27;&gt;&quot;); // 高亮单词的后缀 q.setHighlightSimplePost(&quot;&lt;/span&gt;&quot;); //摘要最长100个字符 q.setHighlightFragsize(100); //查询 QueryResponse query = client.query(q); //获取高亮字段name相应结果 NamedList&lt;Object&gt; response = query.getResponse(); NamedList&lt;?&gt; highlighting = (NamedList&lt;?&gt;) response.get(&quot;highlighting&quot;); for (int i = 0; i &lt; highlighting.size(); i++) &#123; System.out.println(highlighting.getName(i) + &quot;：&quot; + highlighting.getVal(i)); &#125; //获取查询结果 SolrDocumentList results = query.getResults(); for (SolrDocument result : results) &#123; System.out.println(result.toString()); &#125; &#125; public static &lt;T&gt; boolean batchSaveOrUpdate(List&lt;T&gt; entities) throws SolrServerException, IOException &#123; DocumentObjectBinder binder = new DocumentObjectBinder(); int total = entities.size(); int count=0; for (T t : entities) &#123; SolrInputDocument doc = binder.toSolrInputDocument(t); client.add(doc); System.out.printf(&quot;添加数据到索引中，总共要添加 %d 条记录，当前添加第%d条 %n&quot;,total,++count); &#125; client.commit(); return true; &#125; public static QueryResponse query(String keywords,int startOfPage, int numberOfPage) throws SolrServerException, IOException &#123; SolrQuery query = new SolrQuery(); query.setStart(startOfPage); query.setRows(numberOfPage); query.setQuery(keywords); QueryResponse rsp = client.query(query); return rsp; &#125; public static &lt;T&gt; boolean saveOrUpdate(T entity) throws SolrServerException, IOException &#123; DocumentObjectBinder binder = new DocumentObjectBinder(); SolrInputDocument doc = binder.toSolrInputDocument(entity); client.add(doc); client.commit(); return true; &#125; public static boolean deleteById(String id) &#123; try &#123; client.deleteById(id); client.commit(); &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; return true; &#125; &#125; TestSolr4j.java 修改之前查询一次 修改之后查询一次 删除之后查询一次 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package cn.peach;import java.io.IOException;import java.util.Collection;import java.util.List;import org.apache.solr.client.solrj.SolrServerException;import org.apache.solr.client.solrj.response.QueryResponse;import org.apache.solr.common.SolrDocument;import org.apache.solr.common.SolrDocumentList;public class TestSolr4j &#123; public static void main(String[] args) throws SolrServerException, IOException &#123; String keyword = &quot;name:鞭&quot;; System.out.println(&quot;修改之前&quot;); query(keyword); Product p = new Product(); p.setId(51173); p.setName(&quot;修改后的神鞭&quot;); SolrUtil.saveOrUpdate(p); System.out.println(&quot;修改之后&quot;); query(keyword); SolrUtil.deleteById(&quot;51173&quot;); System.out.println(&quot;删除之后&quot;); query(keyword); &#125; private static void query(String keyword) throws SolrServerException, IOException &#123; QueryResponse queryResponse = SolrUtil.query(keyword,0,10); SolrDocumentList documents= queryResponse.getResults(); System.out.println(&quot;累计找到的条数：&quot;+documents.getNumFound()); if(!documents.isEmpty())&#123; Collection&lt;String&gt; fieldNames = documents.get(0).getFieldNames(); for (String fieldName : fieldNames) &#123; System.out.print(fieldName+&quot;\\t&quot;); &#125; System.out.println(); &#125; for (SolrDocument solrDocument : documents) &#123; Collection&lt;String&gt; fieldNames= solrDocument.getFieldNames(); for (String fieldName : fieldNames) &#123; System.out.print(solrDocument.get(fieldName)+&quot;\\t&quot;); &#125; System.out.println(); &#125; &#125;&#125; 观察修改和删除的效果: Solr - 进一步学习:Solr官网展开学习：https://lucene.apache.org/solr/","tags":[{"name":"Solr","slug":"Solr","permalink":"http://example.com/tags/Solr/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"Solr","slug":"工具和中间件/搜索引擎技术/Solr","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/Solr/"}]},{"title":"Solr高亮显示","date":"2018-12-01T07:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/Solr/Solr高亮显示/","text":"SolrUtil.java增加queryHighlight 方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283package cn.peach;import java.io.IOException;import java.util.List; import org.apache.solr.client.solrj.SolrClient;import org.apache.solr.client.solrj.SolrQuery;import org.apache.solr.client.solrj.SolrServerException;import org.apache.solr.client.solrj.beans.DocumentObjectBinder;import org.apache.solr.client.solrj.impl.HttpSolrClient;import org.apache.solr.client.solrj.response.QueryResponse;import org.apache.solr.common.SolrDocument;import org.apache.solr.common.SolrDocumentList;import org.apache.solr.common.SolrInputDocument;import org.apache.solr.common.util.NamedList; public class SolrUtil &#123; public static SolrClient client; private static String url; static &#123; url = &quot;http://localhost:8983/solr/howToSolr&quot;; client = new HttpSolrClient.Builder(url).build(); &#125; public static void queryHighlight(String keywords) throws SolrServerException, IOException &#123; SolrQuery q = new SolrQuery(); //开始页数 q.setStart(0); //每页显示条数 q.setRows(10); // 设置查询关键字 q.setQuery(keywords); // 开启高亮 q.setHighlight(true); // 高亮字段 q.addHighlightField(&quot;name&quot;); // 高亮单词的前缀 q.setHighlightSimplePre(&quot;&lt;span style=&#x27;color:red&#x27;&gt;&quot;); // 高亮单词的后缀 q.setHighlightSimplePost(&quot;&lt;/span&gt;&quot;); //摘要最长100个字符 q.setHighlightFragsize(100); //查询 QueryResponse query = client.query(q); //获取高亮字段name相应结果 NamedList&lt;Object&gt; response = query.getResponse(); NamedList&lt;?&gt; highlighting = (NamedList&lt;?&gt;) response.get(&quot;highlighting&quot;); for (int i = 0; i &lt; highlighting.size(); i++) &#123; System.out.println(highlighting.getName(i) + &quot;：&quot; + highlighting.getVal(i)); &#125; //获取查询结果 SolrDocumentList results = query.getResults(); for (SolrDocument result : results) &#123; System.out.println(result.toString()); &#125; &#125; public static &lt;T&gt; boolean batchSaveOrUpdate(List&lt;T&gt; entities) throws SolrServerException, IOException &#123; DocumentObjectBinder binder = new DocumentObjectBinder(); int total = entities.size(); int count=0; for (T t : entities) &#123; SolrInputDocument doc = binder.toSolrInputDocument(t); client.add(doc); System.out.printf(&quot;添加数据到索引中，总共要添加 %d 条记录，当前添加第%d条 %n&quot;,total,++count); &#125; client.commit(); return true; &#125; public static QueryResponse query(String keywords,int startOfPage, int numberOfPage) throws SolrServerException, IOException &#123; SolrQuery query = new SolrQuery(); query.setStart(startOfPage); query.setRows(numberOfPage); query.setQuery(keywords); QueryResponse rsp = client.query(query); return rsp; &#125; &#125; TestSolr4j.java调用queryHighlight 方法 123456789101112131415package cn.peach; import java.io.IOException; import org.apache.solr.client.solrj.SolrServerException; public class TestSolr4j &#123; public static void main(String[] args) throws SolrServerException, IOException &#123; //高亮查询查询 SolrUtil.queryHighlight(&quot;name:手机&quot;); &#125; &#125;","tags":[{"name":"Solr","slug":"Solr","permalink":"http://example.com/tags/Solr/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"Solr","slug":"工具和中间件/搜索引擎技术/Solr","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/Solr/"}]},{"title":"Solr分页查询-Solrj","date":"2018-12-01T06:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/Solr/Solr分页查询-Solrj/","text":"SolrUtil.javaSolrUtil 增加分页查询的方法: 123456789public static QueryResponse query(String keywords,int startOfPage, int numberOfPage) throws SolrServerException, IOException &#123; SolrQuery query = new SolrQuery(); query.setStart(startOfPage); query.setRows(numberOfPage); query.setQuery(keywords); QueryResponse rsp = client.query(query); return rsp;&#125; 完整代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package cn.peach;import java.io.IOException;import java.util.List; import org.apache.solr.client.solrj.SolrClient;import org.apache.solr.client.solrj.SolrQuery;import org.apache.solr.client.solrj.SolrServerException;import org.apache.solr.client.solrj.beans.DocumentObjectBinder;import org.apache.solr.client.solrj.impl.HttpSolrClient;import org.apache.solr.client.solrj.response.QueryResponse;import org.apache.solr.common.SolrDocument;import org.apache.solr.common.SolrDocumentList;import org.apache.solr.common.SolrInputDocument;import org.apache.solr.common.util.NamedList; public class SolrUtil &#123; public static SolrClient client; private static String url; static &#123; url = &quot;http://localhost:8983/solr/howToSolr&quot;; client = new HttpSolrClient.Builder(url).build(); &#125; public static &lt;T&gt; boolean batchSaveOrUpdate(List&lt;T&gt; entities) throws SolrServerException, IOException &#123; DocumentObjectBinder binder = new DocumentObjectBinder(); int total = entities.size(); int count=0; for (T t : entities) &#123; SolrInputDocument doc = binder.toSolrInputDocument(t); client.add(doc); System.out.printf(&quot;添加数据到索引中，总共要添加 %d 条记录，当前添加第%d条 %n&quot;,total,++count); &#125; client.commit(); return true; &#125; public static QueryResponse query(String keywords,int startOfPage, int numberOfPage) throws SolrServerException, IOException &#123; SolrQuery query = new SolrQuery(); query.setStart(startOfPage); query.setRows(numberOfPage); query.setQuery(keywords); QueryResponse rsp = client.query(query); return rsp; &#125; &#125; TestSolr4j.java拿到分页查询的结果，遍历出来 12345678910111213141516171819202122232425262728293031323334353637383940package cn.peach; import java.io.IOException;import java.util.Collection; import org.apache.solr.client.solrj.SolrServerException;import org.apache.solr.client.solrj.response.QueryResponse;import org.apache.solr.common.SolrDocument;import org.apache.solr.common.SolrDocumentList; public class TestSolr4j &#123; public static void main(String[] args) throws SolrServerException, IOException &#123; //查询 QueryResponse queryResponse = SolrUtil.query(&quot;name:手机&quot;,0,10); SolrDocumentList documents= queryResponse.getResults(); System.out.println(&quot;累计找到的条数：&quot;+documents.getNumFound()); if(!documents.isEmpty())&#123; Collection&lt;String&gt; fieldNames = documents.get(0).getFieldNames(); for (String fieldName : fieldNames) &#123; System.out.print(fieldName+&quot;\\t&quot;); &#125; System.out.println(); &#125; for (SolrDocument solrDocument : documents) &#123; Collection&lt;String&gt; fieldNames= solrDocument.getFieldNames(); for (String fieldName : fieldNames) &#123; System.out.print(solrDocument.get(fieldName)+&quot;\\t&quot;); &#125; System.out.println(); &#125; &#125; &#125;","tags":[{"name":"Solr","slug":"Solr","permalink":"http://example.com/tags/Solr/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"Solr","slug":"工具和中间件/搜索引擎技术/Solr","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/Solr/"}]},{"title":"Solr创建索引","date":"2018-12-01T05:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/Solr/Solr创建索引/","text":"如何创建索引：solr 提供了一种方式向其中增加索引的界面，但是不太方便，也和实际工作环境不相符合。以下配置通过程序把数据加入到Solr 索引里。 Product.java准备实体类来存放产品信息注： 每个字段上都有@Field 注解，用来告诉Solr 这些和 howToSolr core里的字段对应 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package cn.peach; import org.apache.solr.client.solrj.beans.Field; public class Product &#123; @Field int id; @Field String name; @Field String category; @Field float price; @Field String place; @Field String code; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getCategory() &#123; return category; &#125; public void setCategory(String category) &#123; this.category = category; &#125; public float getPrice() &#123; return price; &#125; public void setPrice(float price) &#123; this.price = price; &#125; public String getPlace() &#123; return place; &#125; public void setPlace(String place) &#123; this.place = place; &#125; public String getCode() &#123; return code; &#125; public void setCode(String code) &#123; this.code = code; &#125; @Override public String toString() &#123; return &quot;Product [id=&quot; + id + &quot;, name=&quot; + name + &quot;, category=&quot; + category + &quot;, price=&quot; + price + &quot;, place=&quot; + place + &quot;, code=&quot; + code + &quot;]&quot;; &#125; &#125; ProductUtil.java工具类，把 140k_products.txt 文本文件，转换为泛型是Product的集合, 参考Lucene分页查询工具类。 SolrUtil.java工具类，用来把产品集合批量增加到Solr. 这里就用到了SolrJ第三方包里的api了。 123456789101112131415161718192021222324252627282930313233package cn.peach;import java.io.IOException;import java.util.List; import org.apache.solr.client.solrj.SolrClient;import org.apache.solr.client.solrj.SolrServerException;import org.apache.solr.client.solrj.beans.DocumentObjectBinder;import org.apache.solr.client.solrj.impl.HttpSolrClient;import org.apache.solr.common.SolrInputDocument; public class SolrUtil &#123; public static SolrClient client; private static String url; static &#123; url = &quot;http://localhost:8983/solr/howToSolr&quot;; client = new HttpSolrClient.Builder(url).build(); &#125; public static &lt;T&gt; boolean batchSaveOrUpdate(List&lt;T&gt; entities) throws SolrServerException, IOException &#123; DocumentObjectBinder binder = new DocumentObjectBinder(); int total = entities.size(); int count=0; for (T t : entities) &#123; SolrInputDocument doc = binder.toSolrInputDocument(t); client.add(doc); System.out.printf(&quot;添加数据到索引中，总共要添加 %d 条记录，当前添加第%d条 %n&quot;,total,++count); &#125; client.commit(); return true; &#125; &#125; TestSolr4j:得到14万个产品对象，然后通过SolrUtil 工具类提交到Solr 服务器。 123456789101112package cn.peach;import java.io.IOException;import java.util.List;import org.apache.solr.client.solrj.SolrServerException; public class TestSolr4j &#123; public static void main(String[] args) throws SolrServerException, IOException &#123; List&lt;Product&gt; products = ProductUtil.file2list(&quot;140k_products.txt&quot;); SolrUtil.batchSaveOrUpdate(products); &#125;&#125; 验证提交效果:","tags":[{"name":"Solr","slug":"Solr","permalink":"http://example.com/tags/Solr/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"Solr","slug":"工具和中间件/搜索引擎技术/Solr","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/Solr/"}]},{"title":"Solr设置字段","date":"2018-12-01T04:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/Solr/Solr设置字段/","text":"字段概念:创建Core 中的Core就相当于表，那么接下来就要为这个表设置字段，用于存放数据。 创建字段： 创建name字段：左边选中 howToSolr -&gt; Schema -&gt; Add Field 输入name: name， field type: text_ik, 这里一定要使用中文分词 中新创建的 text_ik类型，否则后续查询中文会失败。然后点击 Add Field按钮进行添加： 创建其他字段：按照创建name字段 的方式，继续创建如下字段： category text_ik, price pfloat, place text_ik, code text_ik注： price的类型是pfloat 关于id字段:id字段是默认就有的，无需自己创建 查看创建的字段:","tags":[{"name":"Solr","slug":"Solr","permalink":"http://example.com/tags/Solr/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"Solr","slug":"工具和中间件/搜索引擎技术/Solr","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/Solr/"}]},{"title":"Solr中文分词器IKAnalyzer","date":"2018-12-01T03:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/Solr/Solr中文分词器IKAnalyzer/","text":"中文分词默认情况下是没有中文分词的，如图所示，通过点击左边的howToSolr-&gt;Analysis 然后输入 四川省成都市动物园，得到是按照每个字的分词效果 配置中文分词下载 IKAnalyzer6.5.0.jar复制到如下目录：D:\\software\\solr-7.2.1\\server\\solr-webapp\\webapp\\WEB-INF\\lib 增加新的字段类型修改配置文件 managed-schema： 1D:\\software\\solr-7.2.1\\server\\solr\\howToSolr\\conf\\managed-schema 在line41 位置处 &lt;schema…&gt; 标签下增加如下代码: 12345&lt;schema name=&quot;default-config&quot; version=&quot;1.6&quot;&gt; &lt;fieldType name=&quot;text_ik&quot; class=&quot;solr.TextField&quot;&gt; &lt;analyzer class=&quot;org.wltea.analyzer.lucene.IKAnalyzer&quot;/&gt; &lt;/fieldType&gt; &lt;field name=&quot;text_ik&quot; type=&quot;text_ik&quot; indexed=&quot;true&quot; stored=&quot;true&quot; multiValued=&quot;false&quot; /&gt; 重启 Solr使用如下命令重启 123cd d:\\software\\solr-7.2.1\\binsolr.cmd stop -allsolr.cmd start 重新测试分词如图所示，使用中文分词后，就可以看到分词的效果了。注： FieldType 记得选增加新的字段类型 中的 text_ik","tags":[{"name":"Solr","slug":"Solr","permalink":"http://example.com/tags/Solr/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"Solr","slug":"工具和中间件/搜索引擎技术/Solr","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/Solr/"}]},{"title":"Solr基础","date":"2018-12-01T02:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/Solr/Solr基础/","text":"Solr概念：以连接数据库为类比：Lucene 就相当于JDBC，是基本的用法。Solr 就相当 Mybatis， 方便开发人员配置，访问和调用。而且Solr 被做成了 webapp形式，以tomcat的应用的方式启动，提供了可视化的配置界面 启动服务器官网(https://lucene.apache.org/solr/)下载solr并解压(我下载的是solr-7.2.1.rar), 我的解压目录在 D:\\software\\solr-7.2.1 12cd d:\\software\\solr-7.2.1\\binsolr.cmd start 如此就启动了服务器，会占用端口8983。 倘若端口被占用，会启动失败. 访问服务器:浏览器输入：http://127.0.0.1:8983/solr/#/ Core 概念：如果说Solr相当于一个数据库的话，那么Core就相当于一张表 不要通过图形界面创建Core如图所示，通过图形界面创建Core会失败，应该使用 命令行方式创建Core: 命令行方式创建Core12cd d:\\software\\solr-7.2.1\\binsolr.cmd create -c howToSolr 删除 new_core如果点击了步骤 不要通过图形界面创建Core 里的图形界面里的 Add Core,那么就会一直有错误提醒，那么按照如下方式删除 new_core 就不会再有错误提醒了 12cd d:\\software\\solr-7.2.1\\binsolr.cmd delete -c new_core","tags":[{"name":"Solr","slug":"Solr","permalink":"http://example.com/tags/Solr/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"Solr","slug":"工具和中间件/搜索引擎技术/Solr","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/Solr/"}]},{"title":"Lucene索引删除和更新","date":"2018-10-02T05:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/Lucene/Lucene索引删除和更新/","text":"索引删除和更新索引建立好了之后，还是需要维护的，比如新增，删除和维护。 新增就是建立索引的过程。索引里的数据，其实就是一个一个的Document 对象，那么本文就是介绍如何删除和更新这些Documen对象。 删除索引123456//删除id=51173的数据IndexWriterConfig config = new IndexWriterConfig(analyzer);IndexWriter indexWriter = new IndexWriter(index, config);indexWriter.deleteDocuments(new Term(&quot;id&quot;, &quot;51173&quot;));indexWriter.commit();indexWriter.close(); 更多删除还可以按照如下方法来删除索引: DeleteDocuments(Query query):根据Query条件来删除单个或多个Document DeleteDocuments(Query[] queries):根据Query条件来删除单个或多个Document DeleteDocuments(Term term):根据Term来删除单个或多个Document DeleteDocuments(Term[] terms):根据Term来删除单个或多个Document DeleteAll():删除所有的Document 更新索引12345678910111213// 更新索引IndexWriterConfig config = new IndexWriterConfig(analyzer);IndexWriter indexWriter = new IndexWriter(index, config);Document doc = new Document();doc.add(new TextField(&quot;id&quot;, &quot;51173&quot;, Field.Store.YES));doc.add(new TextField(&quot;name&quot;, &quot;神鞭，鞭没了，神还在&quot;, Field.Store.YES));doc.add(new TextField(&quot;category&quot;, &quot;道具&quot;, Field.Store.YES));doc.add(new TextField(&quot;price&quot;, &quot;998&quot;, Field.Store.YES));doc.add(new TextField(&quot;place&quot;, &quot;南海群岛&quot;, Field.Store.YES));doc.add(new TextField(&quot;code&quot;, &quot;888888&quot;, Field.Store.YES));indexWriter.updateDocument(new Term(&quot;id&quot;, &quot;51173&quot;), doc );indexWriter.commit();indexWriter.close(); LUCENE - 进一步学习:Lucene官网展开学习：https://lucene.apache.org/","tags":[{"name":"Lucene","slug":"Lucene","permalink":"http://example.com/tags/Lucene/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"Lucene","slug":"工具和中间件/搜索引擎技术/Lucene","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/Lucene/"}]},{"title":"Lucene分页查询","date":"2018-10-02T04:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/Lucene/Lucene分页查询/","text":"分页查询-两种方式:Lucene 分页通常来讲有两种方式： 第一种是把100条数据查出来，然后取最后10条。 优点是快，缺点是对内存消耗大。 第二种是把第90条查询出来，然后基于这一条，通过searchAfter方法查询10条数据。 优点是内存消耗小，缺点是比第一种更慢 准备实体类来存放产品信息12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package cn.peach;public class Product &#123; int id; String name; String category; float price; String place; String code; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getCategory() &#123; return category; &#125; public void setCategory(String category) &#123; this.category = category; &#125; public float getPrice() &#123; return price; &#125; public void setPrice(float price) &#123; this.price = price; &#125; public String getPlace() &#123; return place; &#125; public void setPlace(String place) &#123; this.place = place; &#125; public String getCode() &#123; return code; &#125; public void setCode(String code) &#123; this.code = code; &#125; @Override public String toString() &#123; return &quot;Product [id=&quot; + id + &quot;, name=&quot; + name + &quot;, category=&quot; + category + &quot;, price=&quot; + price + &quot;, place=&quot; + place + &quot;, code=&quot; + code + &quot;]&quot;; &#125;&#125; 准备工具类读取14万条数据把140k_products.txt 文本文件，转换为泛型是Product的集合 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package cn.peach;import java.awt.AWTException;import java.io.File;import java.io.IOException;import java.util.ArrayList;import java.util.HashSet;import java.util.List;import java.util.Set;import org.apache.commons.io.FileUtils; public class ProductUtil &#123; public static void main(String[] args) throws IOException, InterruptedException, AWTException &#123; String fileName = &quot;140k_products.txt&quot;; List&lt;Product&gt; products = file2list(fileName); System.out.println(products.size()); &#125; public static List&lt;Product&gt; file2list(String fileName) throws IOException &#123; File f = new File(fileName); List&lt;String&gt; lines = FileUtils.readLines(f,&quot;UTF-8&quot;); List&lt;Product&gt; products = new ArrayList&lt;&gt;(); for (String line : lines) &#123; Product p = line2product(line); products.add(p); &#125; return products; &#125; private static Product line2product(String line) &#123; Product p = new Product(); String[] fields = line.split(&quot;,&quot;); p.setId(Integer.parseInt(fields[0])); p.setName(fields[1]); p.setCategory(fields[2]); p.setPrice(Float.parseFloat(fields[3])); p.setPlace(fields[4]); p.setCode(fields[5]); return p; &#125;&#125; 第一种:一共查出 pageNow*pageSize条，然后取最后pageSize条： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142package cn.peach;import java.io.IOException;import java.io.StringReader;import java.util.ArrayList;import java.util.List;import org.apache.lucene.analysis.TokenStream;import org.apache.lucene.document.Document;import org.apache.lucene.document.Field;import org.apache.lucene.document.TextField;import org.apache.lucene.index.DirectoryReader;import org.apache.lucene.index.IndexReader;import org.apache.lucene.index.IndexWriter;import org.apache.lucene.index.IndexWriterConfig;import org.apache.lucene.index.IndexableField;import org.apache.lucene.queryparser.classic.QueryParser;import org.apache.lucene.search.IndexSearcher;import org.apache.lucene.search.Query;import org.apache.lucene.search.ScoreDoc;import org.apache.lucene.search.TopDocs;import org.apache.lucene.search.highlight.Highlighter;import org.apache.lucene.search.highlight.QueryScorer;import org.apache.lucene.search.highlight.SimpleHTMLFormatter;import org.apache.lucene.store.Directory;import org.apache.lucene.store.RAMDirectory;import org.wltea.analyzer.lucene.IKAnalyzer;public class TestLucene &#123; public static void main(String[] args) throws Exception &#123; // 1. 准备中文分词器 IKAnalyzer analyzer = new IKAnalyzer(); // 2. 索引 Directory index = createIndex(analyzer); // 3. 查询器 String keyword = &quot;手机&quot;; System.out.println(&quot;当前关键字是：&quot;+keyword); Query query = new QueryParser( &quot;name&quot;, analyzer).parse(keyword); // 4. 搜索 IndexReader reader = DirectoryReader.open(index); IndexSearcher searcher=new IndexSearcher(reader); int pageNow = 1; int pageSize = 10; ScoreDoc[] hits = pageSearch1(query, searcher, pageNow, pageSize); // 5. 显示查询结果 showSearchResults(searcher, hits,query,analyzer); // 6. 关闭查询 reader.close(); &#125; private static ScoreDoc[] pageSearch1(Query query, IndexSearcher searcher, int pageNow, int pageSize) throws IOException &#123; TopDocs topDocs = searcher.search(query, pageNow*pageSize); System.out.println(&quot;查询到的总条数\\t&quot;+topDocs.totalHits); ScoreDoc [] alllScores = topDocs.scoreDocs; List&lt;ScoreDoc&gt; hitScores = new ArrayList&lt;&gt;(); int start = (pageNow -1)*pageSize ; int end = pageSize*pageNow; for(int i=start;i&lt;end;i++) hitScores.add(alllScores[i]); ScoreDoc[] hits = hitScores.toArray(new ScoreDoc[]&#123;&#125;); return hits; &#125; private static void showSearchResults(IndexSearcher searcher, ScoreDoc[] hits, Query query, IKAnalyzer analyzer) throws Exception &#123; System.out.println(&quot;找到 &quot; + hits.length + &quot; 个命中.&quot;); SimpleHTMLFormatter simpleHTMLFormatter = new SimpleHTMLFormatter(&quot;&lt;span style=&#x27;color:red&#x27;&gt;&quot;, &quot;&lt;/span&gt;&quot;); Highlighter highlighter = new Highlighter(simpleHTMLFormatter, new QueryScorer(query)); System.out.println(&quot;找到 &quot; + hits.length + &quot; 个命中.&quot;); System.out.println(&quot;序号\\t匹配度得分\\t结果&quot;); for (int i = 0; i &lt; hits.length; ++i) &#123; ScoreDoc scoreDoc= hits[i]; int docId = scoreDoc.doc; Document d = searcher.doc(docId); List&lt;IndexableField&gt; fields= d.getFields(); System.out.print((i + 1) ); System.out.print(&quot;\\t&quot; + scoreDoc.score); for (IndexableField f : fields) &#123; if(&quot;name&quot;.equals(f.name()))&#123; TokenStream tokenStream = analyzer.tokenStream(f.name(), new StringReader(d.get(f.name()))); String fieldContent = highlighter.getBestFragment(tokenStream, d.get(f.name())); System.out.print(&quot;\\t&quot;+fieldContent); &#125; else&#123; System.out.print(&quot;\\t&quot;+d.get(f.name())); &#125; &#125; System.out.println(&quot;&lt;br&gt;&quot;); &#125; &#125; private static Directory createIndex(IKAnalyzer analyzer) throws IOException &#123; Directory index = new RAMDirectory(); IndexWriterConfig config = new IndexWriterConfig(analyzer); IndexWriter writer = new IndexWriter(index, config); String fileName = &quot;140k_products.txt&quot;; List&lt;Product&gt; products = ProductUtil.file2list(fileName); int total = products.size(); int count = 0; int per = 0; int oldPer =0; for (Product p : products) &#123; addDoc(writer, p); count++; per = count*100/total; if(per!=oldPer)&#123; oldPer = per; System.out.printf(&quot;索引中，总共要添加 %d 条记录，当前添加进度是： %d%% %n&quot;,total,per); &#125; if(per&gt;10) break; &#125; writer.close(); return index; &#125; private static void addDoc(IndexWriter w, Product p) throws IOException &#123; Document doc = new Document(); doc.add(new TextField(&quot;id&quot;, String.valueOf(p.getId()), Field.Store.YES)); doc.add(new TextField(&quot;name&quot;, p.getName(), Field.Store.YES)); doc.add(new TextField(&quot;category&quot;, p.getCategory(), Field.Store.YES)); doc.add(new TextField(&quot;price&quot;, String.valueOf(p.getPrice()), Field.Store.YES)); doc.add(new TextField(&quot;place&quot;, p.getPlace(), Field.Store.YES)); doc.add(new TextField(&quot;code&quot;, p.getCode(), Field.Store.YES)); w.addDocument(doc); &#125;&#125; 第二种首先是边界条件，如果是第一页，就直接查询了。如果不是第一页，那么就取start-1那一条，然后再根据它通过searchAfter 来查询： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162package cn.peach;import java.io.IOException;import java.io.StringReader;import java.util.ArrayList;import java.util.List;import org.apache.lucene.analysis.TokenStream;import org.apache.lucene.document.Document;import org.apache.lucene.document.Field;import org.apache.lucene.document.TextField;import org.apache.lucene.index.DirectoryReader;import org.apache.lucene.index.IndexReader;import org.apache.lucene.index.IndexWriter;import org.apache.lucene.index.IndexWriterConfig;import org.apache.lucene.index.IndexableField;import org.apache.lucene.queryparser.classic.QueryParser;import org.apache.lucene.search.IndexSearcher;import org.apache.lucene.search.Query;import org.apache.lucene.search.ScoreDoc;import org.apache.lucene.search.TopDocs;import org.apache.lucene.search.highlight.Highlighter;import org.apache.lucene.search.highlight.QueryScorer;import org.apache.lucene.search.highlight.SimpleHTMLFormatter;import org.apache.lucene.store.Directory;import org.apache.lucene.store.RAMDirectory;import org.wltea.analyzer.lucene.IKAnalyzer;public class TestLucene &#123; public static void main(String[] args) throws Exception &#123; // 1. 准备中文分词器 IKAnalyzer analyzer = new IKAnalyzer(); // 2. 索引 Directory index = createIndex(analyzer); // 3. 查询器 String keyword = &quot;手机&quot;; System.out.println(&quot;当前关键字是：&quot;+keyword); Query query = new QueryParser( &quot;name&quot;, analyzer).parse(keyword); // 4. 搜索 IndexReader reader = DirectoryReader.open(index); IndexSearcher searcher=new IndexSearcher(reader); int pageNow = 1; int pageSize = 10; ScoreDoc[] hits = pageSearch2(query, searcher, pageNow, pageSize); // 5. 显示查询结果 showSearchResults(searcher, hits,query,analyzer); // 6. 关闭查询 reader.close(); &#125; private static ScoreDoc[] pageSearch1(Query query, IndexSearcher searcher, int pageNow, int pageSize) throws IOException &#123; TopDocs topDocs = searcher.search(query, pageNow*pageSize); System.out.println(&quot;查询到的总条数\\t&quot;+topDocs.totalHits); ScoreDoc [] alllScores = topDocs.scoreDocs; List&lt;ScoreDoc&gt; hitScores = new ArrayList&lt;&gt;(); int start = (pageNow -1)*pageSize ; int end = pageSize*pageNow; for(int i=start;i&lt;end;i++) hitScores.add(alllScores[i]); ScoreDoc[] hits = hitScores.toArray(new ScoreDoc[]&#123;&#125;); return hits; &#125; private static ScoreDoc[] pageSearch2(Query query, IndexSearcher searcher, int pageNow, int pageSize) throws IOException &#123; int start = (pageNow - 1) * pageSize; if(0==start)&#123; TopDocs topDocs = searcher.search(query, pageNow*pageSize); return topDocs.scoreDocs; &#125; // 查询数据， 结束页面自前的数据都会查询到，但是只取本页的数据 TopDocs topDocs = searcher.search(query, start); //获取到上一页最后一条 ScoreDoc preScore= topDocs.scoreDocs[start-1]; //查询最后一条后的数据的一页数据 topDocs = searcher.searchAfter(preScore, query, pageSize); return topDocs.scoreDocs; &#125; private static void showSearchResults(IndexSearcher searcher, ScoreDoc[] hits, Query query, IKAnalyzer analyzer) throws Exception &#123; System.out.println(&quot;找到 &quot; + hits.length + &quot; 个命中.&quot;); SimpleHTMLFormatter simpleHTMLFormatter = new SimpleHTMLFormatter(&quot;&lt;span style=&#x27;color:red&#x27;&gt;&quot;, &quot;&lt;/span&gt;&quot;); Highlighter highlighter = new Highlighter(simpleHTMLFormatter, new QueryScorer(query)); System.out.println(&quot;找到 &quot; + hits.length + &quot; 个命中.&quot;); System.out.println(&quot;序号\\t匹配度得分\\t结果&quot;); for (int i = 0; i &lt; hits.length; ++i) &#123; ScoreDoc scoreDoc= hits[i]; int docId = scoreDoc.doc; Document d = searcher.doc(docId); List&lt;IndexableField&gt; fields= d.getFields(); System.out.print((i + 1) ); System.out.print(&quot;\\t&quot; + scoreDoc.score); for (IndexableField f : fields) &#123; if(&quot;name&quot;.equals(f.name()))&#123; TokenStream tokenStream = analyzer.tokenStream(f.name(), new StringReader(d.get(f.name()))); String fieldContent = highlighter.getBestFragment(tokenStream, d.get(f.name())); System.out.print(&quot;\\t&quot;+fieldContent); &#125; else&#123; System.out.print(&quot;\\t&quot;+d.get(f.name())); &#125; &#125; System.out.println(&quot;&lt;br&gt;&quot;); &#125; &#125; private static Directory createIndex(IKAnalyzer analyzer) throws IOException &#123; Directory index = new RAMDirectory(); IndexWriterConfig config = new IndexWriterConfig(analyzer); IndexWriter writer = new IndexWriter(index, config); String fileName = &quot;140k_products.txt&quot;; List&lt;Product&gt; products = ProductUtil.file2list(fileName); int total = products.size(); int count = 0; int per = 0; int oldPer =0; for (Product p : products) &#123; addDoc(writer, p); count++; per = count*100/total; if(per!=oldPer)&#123; oldPer = per; System.out.printf(&quot;索引中，总共要添加 %d 条记录，当前添加进度是： %d%% %n&quot;,total,per); &#125; if(per&gt;10) break; &#125; writer.close(); return index; &#125; private static void addDoc(IndexWriter w, Product p) throws IOException &#123; Document doc = new Document(); doc.add(new TextField(&quot;id&quot;, String.valueOf(p.getId()), Field.Store.YES)); doc.add(new TextField(&quot;name&quot;, p.getName(), Field.Store.YES)); doc.add(new TextField(&quot;category&quot;, p.getCategory(), Field.Store.YES)); doc.add(new TextField(&quot;price&quot;, String.valueOf(p.getPrice()), Field.Store.YES)); doc.add(new TextField(&quot;place&quot;, p.getPlace(), Field.Store.YES)); doc.add(new TextField(&quot;code&quot;, p.getCode(), Field.Store.YES)); w.addDocument(doc); &#125;&#125;","tags":[{"name":"Lucene","slug":"Lucene","permalink":"http://example.com/tags/Lucene/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"Lucene","slug":"工具和中间件/搜索引擎技术/Lucene","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/Lucene/"}]},{"title":"Lucene分词器","date":"2018-10-02T03:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/Lucene/Lucene分词器/","text":"分词器概念：分词器指的是搜索引擎如何使用关键字进行匹配，如 基础 中的关键字：护眼带光源。 如果使用like,那么%护眼带光源%，匹配出来的结果就是要么全匹配，要不都不匹配。而使用分词器，就会把这个关键字分为 护眼，带，光源 3个关键字，这样就可以找到不同相关程度的结果了。 IKAnalyzer6.5.0.jarIKAnalyzer 这个分词器很久都没有维护了，也不支持Lucene7。 代码演示 TestAnalyzer12345678910111213141516171819package cn.peach; import java.io.IOException; import org.apache.lucene.analysis.TokenStream;import org.wltea.analyzer.lucene.IKAnalyzer; public class TestAnalyzer &#123; public static void main(String[] args) throws IOException &#123; IKAnalyzer analyzer = new IKAnalyzer(); TokenStream ts= analyzer.tokenStream(&quot;name&quot;, &quot;护眼带光源&quot;); ts.reset(); while(ts.incrementToken())&#123; System.out.println(ts.reflectAsString(false)); &#125; &#125;&#125; 高亮显示:70,71行 81,82行 增加高亮显示123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106package cn.peach;import java.io.IOException;import java.io.StringReader;import java.util.ArrayList;import java.util.List;import org.apache.lucene.analysis.TokenStream;import org.apache.lucene.document.Document;import org.apache.lucene.document.Field;import org.apache.lucene.document.TextField;import org.apache.lucene.index.DirectoryReader;import org.apache.lucene.index.IndexReader;import org.apache.lucene.index.IndexWriter;import org.apache.lucene.index.IndexWriterConfig;import org.apache.lucene.index.IndexableField;import org.apache.lucene.queryparser.classic.QueryParser;import org.apache.lucene.search.IndexSearcher;import org.apache.lucene.search.Query;import org.apache.lucene.search.ScoreDoc;import org.apache.lucene.search.highlight.Highlighter;import org.apache.lucene.search.highlight.QueryScorer;import org.apache.lucene.search.highlight.SimpleHTMLFormatter;import org.apache.lucene.store.Directory;import org.apache.lucene.store.RAMDirectory;import org.wltea.analyzer.lucene.IKAnalyzer;public class TestLucene &#123; public static void main(String[] args) throws Exception &#123; // 1. 准备中文分词器 IKAnalyzer analyzer = new IKAnalyzer(); // 2. 索引 List&lt;String&gt; productNames = new ArrayList&lt;&gt;(); productNames.add(&quot;飞利浦led灯泡e27螺口暖白球泡灯家用照明超亮节能灯泡转色温灯泡&quot;); productNames.add(&quot;飞利浦led灯泡e14螺口蜡烛灯泡3W尖泡拉尾节能灯泡暖黄光源Lamp&quot;); productNames.add(&quot;雷士照明 LED灯泡 e27大螺口节能灯3W球泡灯 Lamp led节能灯泡&quot;); productNames.add(&quot;飞利浦 led灯泡 e27螺口家用3w暖白球泡灯节能灯5W灯泡LED单灯7w&quot;); productNames.add(&quot;飞利浦led小球泡e14螺口4.5w透明款led节能灯泡照明光源lamp单灯&quot;); productNames.add(&quot;飞利浦蒲公英护眼台灯工作学习阅读节能灯具30508带光源&quot;); productNames.add(&quot;欧普照明led灯泡蜡烛节能灯泡e14螺口球泡灯超亮照明单灯光源&quot;); productNames.add(&quot;欧普照明led灯泡节能灯泡超亮光源e14e27螺旋螺口小球泡暖黄家用&quot;); productNames.add(&quot;聚欧普照明led灯泡节能灯泡e27螺口球泡家用led照明单灯超亮光源&quot;); Directory index = createIndex(analyzer, productNames); // 3. 查询器 String keyword = &quot;护眼带光源&quot;; Query query = new QueryParser(&quot;name&quot;, analyzer).parse(keyword); // 4. 搜索 IndexReader reader = DirectoryReader.open(index); IndexSearcher searcher = new IndexSearcher(reader); int numberPerPage = 1000; System.out.printf(&quot;当前一共有%d条数据%n&quot;,productNames.size()); System.out.printf(&quot;查询关键字是：\\&quot;%s\\&quot;%n&quot;,keyword); ScoreDoc[] hits = searcher.search(query, numberPerPage).scoreDocs; // 5. 显示查询结果 showSearchResults(searcher, hits, query, analyzer); // 6. 关闭查询 reader.close(); &#125; private static void showSearchResults(IndexSearcher searcher, ScoreDoc[] hits, Query query, IKAnalyzer analyzer) throws Exception &#123; System.out.println(&quot;找到 &quot; + hits.length + &quot; 个命中.&quot;); System.out.println(&quot;序号\\t匹配度得分\\t结果&quot;); SimpleHTMLFormatter simpleHTMLFormatter = new SimpleHTMLFormatter(&quot;&lt;span style=&#x27;color:red&#x27;&gt;&quot;, &quot;&lt;/span&gt;&quot;); Highlighter highlighter = new Highlighter(simpleHTMLFormatter, new QueryScorer(query)); for (int i = 0; i &lt; hits.length; ++i) &#123; ScoreDoc scoreDoc= hits[i]; int docId = scoreDoc.doc; Document d = searcher.doc(docId); List&lt;IndexableField&gt; fields = d.getFields(); System.out.print((i + 1)); System.out.print(&quot;\\t&quot; + scoreDoc.score); for (IndexableField f : fields) &#123; TokenStream tokenStream = analyzer.tokenStream(f.name(), new StringReader(d.get(f.name()))); String fieldContent = highlighter.getBestFragment(tokenStream, d.get(f.name())); System.out.print(&quot;\\t&quot; + fieldContent); &#125; System.out.println(&quot;&lt;br&gt;&quot;); &#125; &#125; private static Directory createIndex(IKAnalyzer analyzer, List&lt;String&gt; products) throws IOException &#123; Directory index = new RAMDirectory(); IndexWriterConfig config = new IndexWriterConfig(analyzer); IndexWriter writer = new IndexWriter(index, config); for (String name : products) &#123; addDoc(writer, name); &#125; writer.close(); return index; &#125; private static void addDoc(IndexWriter w, String name) throws IOException &#123; Document doc = new Document(); doc.add(new TextField(&quot;name&quot;, name, Field.Store.YES)); w.addDocument(doc); &#125;&#125; 运行结果运行结果是html代码，为了正常显示，复制到一个html文件里，打开就可以看到效果了.","tags":[{"name":"Lucene","slug":"Lucene","permalink":"http://example.com/tags/Lucene/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"Lucene","slug":"工具和中间件/搜索引擎技术/Lucene","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/Lucene/"}]},{"title":"Lucene基础","date":"2018-10-02T02:08:20.000Z","path":"blog/工具和中间件/搜索引擎技术/Lucene/Lucene基础/","text":"Lucene 概念:Lucene 这个开源项目，使得 Java开发人员可以很方便地得到像搜索引擎google baidu那样的搜索效果。 Lucene是一个全文检索框架，通过程序扫描文本中每个单词，针对单词建立索引，并保存该单词在文本中的位置、以及出现次数。用户查询时通过之前建立好的索引来查询，将索引中单词对应文本位置、出现次数返给用户，有了具体文本位置，则可将具体内容读取出来。 Lucene基于倒排索引，对于使用的数据库主键索引是通过主键定位到某条数据，而倒排索引刚好相反，是通过数据对应到主键。 分词器：准备中文分词器， 12// 1. 准备中文分词器IKAnalyzer analyzer = new IKAnalyzer(); 创建索引:首先准备10条数据这10条数据都是字符串，相当于产品表里的数据 123456789101112// 索引List&lt;String&gt; productNames = new ArrayList&lt;&gt;();productNames.add(&quot;飞利浦led灯泡e27螺口暖白球泡灯家用照明超亮节能灯泡转色温灯泡&quot;);productNames.add(&quot;飞利浦led灯泡e14螺口蜡烛灯泡3W尖泡拉尾节能灯泡暖黄光源Lamp&quot;);productNames.add(&quot;雷士照明 LED灯泡 e27大螺口节能灯3W球泡灯 Lamp led节能灯泡&quot;);productNames.add(&quot;飞利浦 led灯泡 e27螺口家用3w暖白球泡灯节能灯5W灯泡LED单灯7w&quot;);productNames.add(&quot;飞利浦led小球泡e14螺口4.5w透明款led节能灯泡照明光源lamp单灯&quot;);productNames.add(&quot;飞利浦蒲公英护眼台灯工作学习阅读节能灯具30508带光源&quot;);productNames.add(&quot;欧普照明led灯泡蜡烛节能灯泡e14螺口球泡灯超亮照明单灯光源&quot;);productNames.add(&quot;欧普照明led灯泡节能灯泡超亮光源e14e27螺旋螺口小球泡暖黄家用&quot;);productNames.add(&quot;聚欧普照明led灯泡节能灯泡e27螺口球泡家用led照明单灯超亮光源&quot;); Directory index = createIndex(analyzer, productNames); 通过 createIndex 方法，把它加入到索引当中: 问题： 创建内存索引，为什么Lucene会比数据库快? 因为它是从内存里查，自然就比数据库里快多了.1234567891011121314private static Directory createIndex(IKAnalyzer analyzer, List&lt;String&gt; products) throws IOException &#123; &lt;!-- 创建内存索引 --&gt; Directory index = new RAMDirectory(); &lt;!-- 根据中文分词器创建配置对象 --&gt; IndexWriterConfig config = new IndexWriterConfig(analyzer); &lt;!-- 创建索引 writer --&gt; IndexWriter writer = new IndexWriter(index, config); &lt;!-- 遍历那10条数据，把他们挨个放进索引里 --&gt; for (String name : products) &#123; addDoc(writer, name); &#125; writer.close(); return index;&#125; 每条数据创建一个Document，并把这个Document放进索引里。 这个Document有一个字段，叫做”name”。 TestLucene.java 第49行创建查询器，就会指定查询这个字段. 12345private static void addDoc(IndexWriter w, String name) throws IOException &#123; Document doc = new Document(); doc.add(new TextField(&quot;name&quot;, name, Field.Store.YES)); w.addDocument(doc);&#125; 创建查询器根据关键字 护眼带光源，基于 “name” 字段进行查询。 这个 “name” 字段就是在创建索引步骤里每个Document的 “name” 字段，相当于表的字段名. 12String keyword = &quot;护眼带光源&quot;;Query query = new QueryParser(&quot;name&quot;, analyzer).parse(keyword); 执行搜索12345678910&lt;!-- 创建索引 reader: --&gt;IndexReader reader = DirectoryReader.open(index);&lt;!-- 基于 reader 创建搜索器： --&gt;IndexSearcher searcher = new IndexSearcher(reader);&lt;!-- 指定每页要显示多少条数据： --&gt;int numberPerPage = 1000;System.out.printf(&quot;当前一共有%d条数据%n&quot;,productNames.size());System.out.printf(&quot;查询关键字是：\\&quot;%s\\&quot;%n&quot;,keyword);&lt;!-- 执行搜索 --&gt;ScoreDoc[] hits = searcher.search(query, numberPerPage).scoreDocs; 显示查询结果12345678910111213141516171819202122private static void showSearchResults(IndexSearcher searcher, ScoreDoc[] hits, Query query, IKAnalyzer analyzer) throws Exception &#123; System.out.println(&quot;找到 &quot; + hits.length + &quot; 个命中.&quot;); System.out.println(&quot;序号\\t匹配度得分\\t结果&quot;); &lt;!-- 每一个ScoreDoc[] hits 就是一个搜索结果，首先把他遍历出来 --&gt; for (int i = 0; i &lt; hits.length; ++i) &#123; ScoreDoc scoreDoc= hits[i]; &lt;!-- 然后获取当前结果的docid, 这个docid相当于就是这个数据在索引中的主键 --&gt; int docId = scoreDoc.doc; &lt;!-- 再根据主键docid，通过搜索器从索引里把对应的Document取出来 --&gt; Document d = searcher.doc(docId); &lt;!-- 接着就打印出这个Document里面的数据。 虽然当前Document只有name一个字段，但是代码还是通过遍历所有字段的形式，打印出里面的值，这样当Docment有多个字段的时候，代码就不用修改了，兼容性更好点。scoreDoc.score 表示当前命中的匹配度得分，越高表示匹配程度越高 --&gt; List&lt;IndexableField&gt; fields = d.getFields(); System.out.print((i + 1)); System.out.print(&quot;\\t&quot; + scoreDoc.score); for (IndexableField f : fields) &#123; System.out.print(&quot;\\t&quot; + d.get(f.name())); &#125; System.out.println(); &#125;&#125; 运行结果:如图所示，一共是10条数据，通过关键字查询出来6条命中结果，不同的命中结果有不同的匹配度得分，比如第一条，命中都就很高，既有 护眼， 也有 带光源。 其他的命中度就比较低，没有护眼关键字的匹配，只有光源关键字的匹配。 思路图:整理一下做 Lucene的思路: 首先搜集数据数据可以是文件系统，数据库，网络上，手工输入的，或者像本例直接写在内存上的 通过数据创建索引 用户输入关键字 通过关键字创建查询器 根据查询器到索引里获取数据 然后把查询结果展示在用户面前 和like的区别：like 也可以进行查询，那么使用lucene 的方式有什么区别呢？ 主要是两点： 相关度:通过观察运行结果，可以看到不同相关度的结果都会查询出来，但是使用 like，就做不到这一点了 性能:数据量小的时候，like 也会有很好的表现，但是数据量一大，like 的表现就差很多了。 在接下来的教程里会演示对 14万条数据 的查询","tags":[{"name":"Lucene","slug":"Lucene","permalink":"http://example.com/tags/Lucene/"}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"Lucene","slug":"工具和中间件/搜索引擎技术/Lucene","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/Lucene/"}]},{"title":"Redis缓存及性能优化","date":"2017-12-15T07:08:20.000Z","path":"blog/Cloud/Redis/Redis缓存及性能优化/","text":"配置文件调优123456789101112131415161718192021222324252627282930313233343536373839# 列表对象listlist-max-ziplist-size -2 # 单个ziplist节点最大能存储8kb，超过则进行分裂将数据存储在新的ziplistlist-compress-depth 1 # 0表示所有节点都不压缩，1表示头结点和尾节点不压缩其他节点压缩# 哈希对象hashhash-max-ziplist-entries 512 # 元素个数超过512，将改为HashTable编码hash-max-ziplist-value 64 # 单个元素大小超过64byte，将改为HashTable编码# 集合对象setset-max-intset-entries 512 # 存储元素超过512时，使用HashTable编码# 有序集合对象zsetzset-max-ziplist-entries 128 # 元素个数超过128，将用skiplist编码zset-max-ziplist-value 64 # 单个元素大小超过64byte，将用skiplist编码# 持久化相关的save 60 1000 # 关闭RDB只需要将所有的save保存策略注释掉即可appendonly yes # 打开AOF功能appendfsync always # 每次有新命令追加到AOF文件时就执行一次fsync，非常慢也非常安全appendfsync everysec # 每秒fsync一次，足够快且在故障时只会丢失1秒钟的数据appendfsync no # 从不fsync，将数据交给操作系统来处理。更快，也更不安全的选择auto-aof-rewrite-min-size 64mb # aof文件至少达到64M才会自动重写，文件太小恢复速度本来就很快，重写意义不大auto-aof-rewrite-percentage 100 # aof文件自上一次重写后文件大小增长了100%则再次触发重写aof-use-rdb-preamble yes # 开启混合持久化，注意必须先开启aof# 集群相关的min-replicas-to-write 1 # 写数据成功最少同步的slave数量maxclients 10000 # redis支持的最大连接数maxmemory 0 # 最大可使用内存值byte，默认0不限制# volatile-lru：从已设置过期时间的key中，移出最近最少使用的key进行淘汰# volatile-ttl：从已设置过期时间的key中，根据过期时间的先后进行删除，越早过期的越先被删除# volatile-random：从已设置过期时间的key中，随机选择key淘汰# allkeys-lru：从所有key中选择最近最少使用的进行淘汰# allkeys-random：从所有key中随机选择key进行淘汰# noeviction：当内存达到阈值的时候，新写入操作报错# volatile-lfu：使用LFU算法筛选设置了过期时间的键值对删除最近一段时间被访问次数最少的数据# allkeys-lfu：使用LFU算法在所有数据中进行筛选删除最近一段时间被访问次数最少的数据maxmemory_policy noeviction # 当达到maxmemory时的淘汰策略 缓存穿透缓存穿透是指查询一个根本不存在的数据， 缓存层和存储层都不会命中， 通常出于容错的考虑， 若从存储层查不到数据则不写入缓存层。缓存穿透将导致不存在的数据每次请求都要到存储层去查询， 失去了缓存保护后端存储的意义。 缓存空对象空对象缓存过期时间设置的短一点，最长不超过5分钟 1234567891011121314151617String get(String key) &#123; // 从缓存中获取数据 String cacheValue = cache.get(key); // 缓存为空 if (StringUtils.isBlank(cacheValue)) &#123; // 从存储中获取 String storageValue = storage.get(key); cache.set(key, storageValue); // 若存储数据为空，需要设置一个过期时间(300秒) if (storageValue == null) &#123; cache.expire(key, 60 * 5); &#125; return storageValue; &#125; else &#123; return cacheValue; // 缓存非空 &#125;&#125; 布隆过滤器对于恶意攻击，向服务器请求大量不存在的数据造成的缓存穿透，可用布隆过滤器先做一次过滤，对于不存在的数据布隆过滤器一般都能够过滤掉，不让请求再往后端发送。布隆过滤器判定某个值存在时，该值可能不存在；当判定不存在时，则肯定不存在。 布隆过滤器适用于数据命中不高、 数据相对固定、 实时性低通常是数据集较大的应用场景，代码维护较为复杂，但是缓存空间占用很少。使用布隆过滤器需要把所有数据提前放入布隆过滤器，且在增加数据时也要往布隆过滤器里放。布隆过滤器不能删除数据，若要删除得重新初始化布隆过滤器。 12345&lt;dependency&gt; &lt;groupId&gt;org.redisson&lt;/groupId&gt; &lt;artifactId&gt;redisson&lt;/artifactId&gt; &lt;version&gt;3.6.5&lt;/version&gt; &lt;/dependency&gt; 1234567891011121314151617public class RedissonBloomFilter &#123; public static void main(String[] args) &#123; Config config = new Config(); config.useSingleServer().setAddress(&quot;redis://localhost:6379&quot;); // 构造Redisson RedissonClient redisson = Redisson.create(config); RBloomFilter&lt;String&gt; bloomFilter = redisson.getBloomFilter(&quot;nameList&quot;); // 初始化布隆过滤器：预计元素为100000000L，误差率为3%，根据这两个参数会计算出底层的bit数组大小 bloomFilter.tryInit(100000000L,0.03); // 将eleven插入到布隆过滤器中 bloomFilter.add(&quot;eleven&quot;); // 判断下面号码是否在布隆过滤器中 System.out.println(bloomFilter.contains(&quot;eleven&quot;)); //false System.out.println(bloomFilter.contains(&quot;张三&quot;)); //false System.out.println(bloomFilter.contains(&quot;李四&quot;)); //true &#125;&#125; 缓存失效大批量缓存在同一时间失效可能导致大量请求同时穿透缓存直达数据库，可能会造成数据库瞬间压力过大甚至挂掉，在批量增加缓存时最好将这一批数据的缓存过期时间设置为一个时间段内的不同时间。 123456789101112131415161718String get(String key) &#123; // 从缓存中获取数据 String cacheValue = cache.get(key); // 缓存为空 if (StringUtils.isBlank(cacheValue)) &#123; // 从存储中获取 String storageValue = storage.get(key); cache.set(key, storageValue); // 设置一个过期时间(300到600之间的一个随机数) int expireTime = new Random().nextInt(300) + 300; if (storageValue == null) &#123; cache.expire(key, expireTime); &#125; return storageValue; &#125; else &#123; return cacheValue; // 缓存非空 &#125;&#125; 缓存雪崩缓存雪崩是指缓存层支撑不住或宕掉后，大量请求打向后端存储层。由于缓存层承载着大量请求，有效地保护了存储层，但若缓存层由于某些原因不能提供服务，如超大并发缓存层支撑不住，或者由于缓存设计不好，类似大量请求访问**bigkey**，导致缓存能支撑的并发急剧下降，于是大量请求打到存储层，存储层调用量暴增，造成存储层也会级联宕机的情况。 预防和解决缓存雪崩问题， 可从以下三个方面进行着手。 事前：保证缓存层服务高可用性，比如使用**Redis Sentinel哨兵模式或Redis Cluster集群模式**。 事中：依赖隔离组件为后端限流熔断并降级。如使用**Sentinel或Hystrix**限流降级组件。可针对不同数据采取不同的处理方式。当业务应用访问的是非核心数据时，暂时停止从缓存中查询这些数据，而是直接返回预定义的默认降级信息、空值或是错误提示信息；当业务应用访问的是核心数据时，仍然允许查询缓存，如果缓存缺失，也可以继续通过数据库读取。 事后：开启Redis持久化机制，能尽快恢复缓存集群 提前演练。在项目上线前，演练缓存层宕掉后，应用以及后端的负载情况以及可能出现的问题，在此基础上做一些预案设定 热KEY重建优化使用缓存 + 过期时间策略既可以加速数据读写，又保证数据定期更新，这种模式基本能够满足绝大部分需求。但若当前key是一个热点key并发量非常大，或重建缓存不能在短时间完成，可能是一个复杂计算如复杂的SQL、多次IO、多个依赖等， 可能会对应用造成致命的危害。 在缓存失效的瞬间，有大量线程来重建缓存，造成后端负载加大，甚至可能会让应用崩溃，要解决该问题主要就是要避免大量线程同时重建缓存。可利用互斥锁来解决，只允许一个线程重建缓存，其他线程等待重建缓存的线程执行完，重新从缓存获取数据即可。 123456789101112131415161718192021String get(String key) &#123; // 从Redis中获取数据 String value = redis.get(key); // 如果value为空， 则开始重构缓存 if (value == null) &#123; // 只允许一个线程重建缓存， 使用nx， 并设置过期时间ex String mutexKey = &quot;mutext:key:&quot; + key; if (redis.set(mutexKey, &quot;1&quot;, &quot;ex 180&quot;, &quot;nx&quot;)) &#123; // 分布式锁 // 从数据源获取数据 value = db.get(key); // 回写Redis， 并设置过期时间 redis.setex(key, timeout, value); // 删除key_mutex redis.delete(mutexKey); &#125; else &#123; // 其他线程休息50毫秒后重试 Thread.sleep(50); get(key); &#125; &#125; return value;&#125; 缓存与数据库双写不一致在大并发下，同时操作数据库与缓存会存在数据不一致性问题 对于并发几率很小的数据，这种几乎不用考虑该问题，很少会发生缓存不一致，可给缓存数据加上过期时间，每隔一段时间触发读的主动更新即可。就算并发很高，若业务上能容忍短时间的缓存数据不一致，缓存加上过期时间依然可以解决大部分业务对于缓存的要求。 若不能容忍缓存数据不一致，可以通过加读写锁保证并发读写或写写的时候按顺序排好队，读读的时候相当于无锁。也可用阿里开源的**canal通过监听数据库的binlog日志**及时的去修改缓存，但是引入了新的中间件，增加了系统的复杂度。 以上针对的都是读多写少的情况加入缓存提高性能，若写多读多的情况又不能容忍缓存数据不一致，那就没必要加缓存了，可直接操作数据库。放入缓存的数据应该是对实时性、一致性要求不是很高的数据。切记不要为了用缓存，同时又要保证绝对的一致性做大量的过度设计和控制，增加系统复杂性。 性能优化KEY设计KEY的设计以业务名为前缀，用逗号分割，在保证语义的前提下，控制KEY的长度，不要包含空格、换行、单双引号等特殊字符。 bigkey对于value值要拒绝bigkey防止网卡流量限制以及慢查询，对于字符串类型value超过**10kb就是bigkey；非字符串类型元素个数不要超过5000；非字符串的bigkey不要使用del删除，使用hscan、sscan、zscan方式渐进式删除，同时要注意防止bigkey过期时间自动删除问题**。 bigkey会导致redis阻塞、网络拥堵等问题，每次获取要产生的网络流量较大，一般服务器会采用单机多实例的方式来部署，bigkey可能会对其他实例也造成影响。过期删除若未使用Redis 4.0的过期异步删除lazyfree-lazy-expire yes，则可能阻塞Redis。可通过bigkey拆分成几个段储存从而解决bigkey问题。 命令使用O(N)命令关注N的数量，如**hgetall、lrange、smembers、zrange、sinter等并非不能使用，但是需要明确N的值，有遍历的需求可使用hscan、sscan、zscan代替，禁止线上使用keys、flushall、flushdb**等，通过redis的rename机制禁掉命令，或者使用scan的方式渐进式处理。 redis的多数据库较弱，使用数字进行区分，很多客户端支持较差，同时多业务用多数据库实际还是单线程处理会有干扰，要合适使用数字进行分区。 过期策略惰性删除 | 被动删除当读或写key时，才对key进行检测，若已经达到过期时间，则删除。若这些过期的key没有被访问，那么他就一直无法被删除，而且一直占用内存。 定期删除 | 主动删除每隔一段时间对数据库做一次检查，删除里面的过期key。由于不可能对所有key去做轮询来删除，所以redis会每次随机取一些key去做检查和删除。 当前已用内存超过**maxmemory限定时，触发主动清理策略**。 定期+惰性都没有删除过期的key每次定期随机查询key的时候没有删掉，这些key也没有做查询的话，就会导致这些key一直保存无法被删除，这时候就会走到redis的内存淘汰机制。 volatile-lru：从已设置过期时间的key中，移出最近最少使用的key进行淘汰 volatile-ttl：从已设置过期时间的key中，根据过期时间的先后进行删除，越早过期的越先被删除 volatile-random：从已设置过期时间的key中，随机选择key淘汰 allkeys-lru：从所有key中选择最近最少使用的进行淘汰 allkeys-random：从所有key中随机选择key进行淘汰 noeviction：当内存达到阈值的时候，新写入操作报错 volatile-lfu：使用LFU算法筛选设置了过期时间的键值对删除最近一段时间被访问次数最少的数据 allkeys-lfu：使用LFU算法在所有数据中进行筛选删除最近一段时间被访问次数最少的数据 LRU &amp; LFULRU算法是以最近一次访问时间作为参考淘汰很久没被访问过的数据，LFU算法以次数作为参考淘汰最近一段时间被访问次数最少的数据。 当存在热点数据时LRU的效率很好，但偶发性、周期性的批量操作会导致LRU命中率急剧下降，缓存污染情况比较严重。这时使用LFU可能更好点。 根据自身业务类型，配置好**maxmemory-policy，默认是noeviction，推荐使用volatile-lru**。若不设置最大内存，当Redis内存超出物理内存限制时，内存数据会开始和磁盘产生频繁的交换swap，会让Redis性能急剧下降。当Redis运行在主从模式时，只有主结点才会执行过期删除策略，然后把删除操作del key同步到从结点删除数据。 连接池预热使用带有连接池的数据库，可以有效控制连接，同时提高效率 1234567891011121314151617181920212223242526List&lt;Jedis&gt; minIdleJedisList = new ArrayList&lt;Jedis&gt;(jedisPoolConfig.getMinIdle());for (int i = 0; i &lt; jedisPoolConfig.getMinIdle(); i++) &#123; Jedis jedis = null; try &#123; jedis = pool.getResource(); minIdleJedisList.add(jedis); jedis.ping(); &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; finally &#123; //注意，这里不能马上close将连接还回连接池，否则最后连接池里只会建立1个连接。。 //jedis.close(); &#125;&#125;//统一将预热的连接还回连接池for (int i = 0; i &lt; jedisPoolConfig.getMinIdle(); i++) &#123; Jedis jedis = null; try &#123; jedis = minIdleJedisList.get(i); //将连接归还回连接池 jedis.close(); &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; finally &#123; &#125;&#125;","tags":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"Redis","slug":"Cloud/Redis","permalink":"http://example.com/categories/Cloud/Redis/"}]},{"title":"Redis分布式锁实现","date":"2017-12-15T06:20:20.000Z","path":"blog/Cloud/Redis/Redis分布式锁实现/","text":"分布式锁的各种问题及优化并发情况下以下代码可能导致超买 12345678int stock = Integer.parseInt(stringRedisTemplate.opsForValue().get(&quot;stock&quot;)); // jedis.get(&quot;stock&quot;)if (stock &gt; 0) &#123; int realStock = stock - 1; stringRedisTemplate.opsForValue().set(&quot;stock&quot;, realStock + &quot;&quot;); // jedis.set(key,value) System.out.println(&quot;扣减成功，剩余库存:&quot; + realStock);&#125; else &#123; System.out.println(&quot;扣减失败，库存不足&quot;);&#125; 为了解决该问题可以通过redis加上分布式锁，该方式是解决了并发问题，但是引入了新的问题，若业务代码异常可能导致锁永远得不到释放。 1234567891011121314String lockKey = &quot;product_101&quot;;Boolean result = stringRedisTemplate.opsForValue().setIfAbsent(lockKey, &quot;product_id&quot;);if (!result) &#123; return &quot;error_code&quot;;&#125;int stock = Integer.parseInt(stringRedisTemplate.opsForValue().get(&quot;stock&quot;));if (stock &gt; 0) &#123; int realStock = stock - 1; stringRedisTemplate.opsForValue().set(&quot;stock&quot;, realStock + &quot;&quot;); System.out.println(&quot;扣减成功，剩余库存:&quot; + realStock);&#125; else &#123; System.out.println(&quot;扣减失败，库存不足&quot;);&#125;stringRedisTemplate.delete(lockKey); 可以通过finally中来释放锁来解决业务代码异常的情况，但若当锁获取成功后机器宕机了，同样锁还是不能得到释放。 1234567891011121314151617String lockKey = &quot;product_101&quot;;try &#123; Boolean result = stringRedisTemplate.opsForValue().setIfAbsent(lockKey, &quot;product_id&quot;); if (!result) &#123; return &quot;error_code&quot;; &#125; int stock = Integer.parseInt(stringRedisTemplate.opsForValue().get(&quot;stock&quot;)); if (stock &gt; 0) &#123; int realStock = stock - 1; stringRedisTemplate.opsForValue().set(&quot;stock&quot;, realStock + &quot;&quot;); System.out.println(&quot;扣减成功，剩余库存:&quot; + realStock); &#125; else &#123; System.out.println(&quot;扣减失败，库存不足&quot;); &#125;&#125; finally &#123; stringRedisTemplate.delete(lockKey);&#125; 可以通过给锁加上一个过期时间的方式来解决获取锁成功后机器宕机，导致锁不能被释放的情况，但是这种写法还是没有完全解决，因为加锁和设置缓存时间不是原子操作。 123456789101112131415161718String lockKey = &quot;product_101&quot;;try &#123; Boolean result = stringRedisTemplate.opsForValue().setIfAbsent(lockKey, &quot;product_id&quot;); stringRedisTemplate.expire(lockKey, 10, TimeUnit.SECONDS); if (!result) &#123; return &quot;error_code&quot;; &#125; int stock = Integer.parseInt(stringRedisTemplate.opsForValue().get(&quot;stock&quot;)); if (stock &gt; 0) &#123; int realStock = stock - 1; stringRedisTemplate.opsForValue().set(&quot;stock&quot;, realStock + &quot;&quot;); System.out.println(&quot;扣减成功，剩余库存:&quot; + realStock); &#125; else &#123; System.out.println(&quot;扣减失败，库存不足&quot;); &#125;&#125; finally &#123; stringRedisTemplate.delete(lockKey);&#125; 可通过在加锁的同时设置超时原子操作来解决该问题，但设置了超时时间若当前业务代码没有被执行完其本身没有释放锁，但由于过期锁被清理掉了，新的线程加锁进来后，之前执行业务代码的线程又去把新的线程的锁释放了，将导致锁完全失效。 1234567891011121314151617String lockKey = &quot;product_101&quot;;try &#123; Boolean result = stringRedisTemplate.opsForValue().setIfAbsent(lockKey, &quot;product_id&quot;, 30, TimeUnit.SECONDS); if (!result) &#123; return &quot;error_code&quot;; &#125; int stock = Integer.parseInt(stringRedisTemplate.opsForValue().get(&quot;stock&quot;)); if (stock &gt; 0) &#123; int realStock = stock - 1; stringRedisTemplate.opsForValue().set(&quot;stock&quot;, realStock + &quot;&quot;); System.out.println(&quot;扣减成功，剩余库存:&quot; + realStock); &#125; else &#123; System.out.println(&quot;扣减失败，库存不足&quot;); &#125;&#125; finally &#123; stringRedisTemplate.delete(lockKey);&#125; 可通过给锁设置唯一标识的方式来解决其他线程释放非自身设置的锁，所有线程只能释放本线程设置的锁。 1234567891011121314151617181920String lockKey = &quot;product_101&quot;;String clientId = UUID.randomUUID().toString();try &#123; Boolean result = stringRedisTemplate.opsForValue().setIfAbsent(lockKey, &quot;product_id&quot;, 30, TimeUnit.SECONDS); if (!result) &#123; return &quot;error_code&quot;; &#125; int stock = Integer.parseInt(stringRedisTemplate.opsForValue().get(&quot;stock&quot;)); if (stock &gt; 0) &#123; int realStock = stock - 1; stringRedisTemplate.opsForValue().set(&quot;stock&quot;, realStock + &quot;&quot;); System.out.println(&quot;扣减成功，剩余库存:&quot; + realStock); &#125; else &#123; System.out.println(&quot;扣减失败，库存不足&quot;); &#125;&#125; finally &#123; if (clientId.equals(stringRedisTemplate.opsForValue().get(lockKey))) &#123; stringRedisTemplate.delete(lockKey); &#125;&#125; 虽然上面的锁已经很完善了，但还是有锁因为超时时间导致的极小概率的并发问题，该问题可以通过给锁续命即判断业务代码是否执行完成，若未完成则重置超时时间的方式来解决该问题。**Redisson**就是这样做的。 1234567891011121314151617String lockKey = &quot;product_101&quot;;String clientId = UUID.randomUUID().toString();RLock redissonLock = redisson.getLock(lockKey);try &#123; //加锁 redissonLock.lock(); //setIfAbsent(lockKey, clientId, 30, TimeUnit.SECONDS); int stock = Integer.parseInt(stringRedisTemplate.opsForValue().get(&quot;stock&quot;)); // jedis.get(&quot;stock&quot;) if (stock &gt; 0) &#123; int realStock = stock - 1; stringRedisTemplate.opsForValue().set(&quot;stock&quot;, realStock + &quot;&quot;); // jedis.set(key,value) System.out.println(&quot;扣减成功，剩余库存:&quot; + realStock); &#125; else &#123; System.out.println(&quot;扣减失败，库存不足&quot;); &#125;&#125; finally &#123; redissonLock.unlock();&#125; 红锁**RedLock**是一种利用多Master对共享资源做互斥访问，基于N个完全独立的Redis节点，运行Redlock算法通过在客户端依次执行下面的步骤来完成获取锁的操作： 获取当前时间，毫秒数 按顺序依次向N个Redis节点执行获取锁操作，该获取操作跟前面基于单Redis节点获取锁过程相同，为了保证在某个Redis节点不可用的时候算法能够继续运行，该获取锁操作还有一个超时时间，几十毫秒量级，它要远小于锁的有效时间。客户端在向某个Redis节点获取锁失败后，应该立即尝试下一个Redis节点，这里的失败应该包含任何类型的失败，如该Redis节点不可用、该Redis节点上的锁已经被其它客户端持有 计算整个获取锁的过程总共消耗了多长时间，计算方法是用当前时间减去第1步记录的时间。若客户端从大多数Redis节点即**&gt;= N/2+1成功获取到了锁，且获取锁总耗时没有超过锁的有效时间**，则此时客户端才认为最终获取锁成功；否则认为最终获取锁失败 若最终获取锁成功，则该锁的有效时间应该重新计算，它等于最初的锁的有效时间减去第3步计算出来的获取锁消耗的时间 若最终获取锁失败了，可能由于获取到锁的Redis节点个数少于**N/2+1，或整个获取锁的过程耗时超过了锁的最初有效时间，则客户端应该立即向所有Redis节点发起释放锁操作** 释放锁的过程比较简单：客户端向所有Redis节点发起释放锁的操作，不管这些节点当时在获取锁时成功与否。在最后释放锁时，客户端应该向所有Redis节点发起释放锁的操作，即使当时向某个节点获取锁没有成功，在释放锁时也不应该漏掉该节点。因为若客户端发给某个Redis节点获取锁的请求成功到达了该Redis节点，该节点也成功执行了SET操作，但返回给客户端的响应包却丢失。在客户端看来，获取锁的请求由于超时而失败了，但在Redis这边看来，加锁已经成功了。因此释放锁时，客户端也应该对当时获取锁失败的那些Redis节点同样发起请求。 但由于N个Redis节点中的大多数能正常工作就能保证Redlock正常工作，因此理论上它的可用性更高。单Redis节点的分布式锁在failover的时锁失效的问题，在Redlock中不存在了，但若有节点发生崩溃重启，还是会对锁的安全性有影响，具体的影响程度跟Redis对数据的持久化程度有关。 假设一共有5个Redis节点**A、B、C、D、E，若客户端1成功锁住了A、B、C，获取锁成功， 但D和E没有锁住，节点C崩溃重启了，但客户端1在C上加的锁没有持久化下来，丢失了，节点C重启后，客户端2锁住了C、D、E， 获取锁成功，针对同一资源客户端1和客户端2同时获得了锁**。 Redis的**AOF持久化方式默认是每秒写一次磁盘，最坏情况下可能丢失1秒的数据，为了尽可能不丢数据，Redis允许设置成每次修改数据都进行fsync，但这会降低性能。当然，即使执行了fsync也仍然有可能丢失数据，这取决于系统而不是Redis的实现。故上面分析的由于节点重启引发的锁失效问题，总是有可能出现的。为了应对这一问题，可通过延迟重启，即一个节点崩溃后，先不立即重启它，而是等待一段时间再重启，该时间应该大于锁的有效时间，该节点在重启前所参与的锁都会过期**，它在重启后就不会对现有的锁造成影响。 Redisson锁原理123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119public class Redisson implements RedissonClient &#123; public RLock getLock(String name) &#123; return new RedissonLock(connectionManager.getCommandExecutor(), name); &#125;&#125;public class RedissonLock extends RedissonExpirable implements RLock &#123; public RedissonLock(CommandAsyncExecutor commandExecutor, String name) &#123; super(commandExecutor, name); this.commandExecutor = commandExecutor; this.id = commandExecutor.getConnectionManager().getId(); this.internalLockLeaseTime = commandExecutor.getConnectionManager().getCfg().getLockWatchdogTimeout(); &#125; public void lock(long leaseTime, TimeUnit unit) &#123; try &#123; lockInterruptibly(leaseTime, unit); &#125; catch (InterruptedException e) &#123; Thread.currentThread().interrupt(); &#125; &#125; public void lockInterruptibly(long leaseTime, TimeUnit unit) throws InterruptedException &#123; long threadId = Thread.currentThread().getId(); // 获取当前线程的ID Long ttl = tryAcquire(leaseTime, unit, threadId); // 尝试获取锁，并返回锁剩余持有时间 if (ttl == null) &#123; // 若锁剩余持有时间为null，表示获取锁成功 return; // 获取锁成功 &#125; RFuture&lt;RedissonLockEntry&gt; future = subscribe(threadId); commandExecutor.syncSubscription(future); try &#123; while (true) &#123; ttl = tryAcquire(leaseTime, unit, threadId); if (ttl == null) &#123; break; &#125; if (ttl &gt;= 0) &#123; getEntry(threadId).getLatch().tryAcquire(ttl, TimeUnit.MILLISECONDS); &#125; else &#123; getEntry(threadId).getLatch().acquire(); &#125; &#125; &#125; finally &#123; unsubscribe(future, threadId); &#125; &#125; private Long tryAcquire(long leaseTime, TimeUnit unit, long threadId) &#123; return get(tryAcquireAsync(leaseTime, unit, threadId)); &#125; private &lt;T&gt; RFuture&lt;Long&gt; tryAcquireAsync(long leaseTime, TimeUnit unit, final long threadId) &#123; if (leaseTime != -1) &#123; // 设置了超时时间的逻辑 return tryLockInnerAsync(leaseTime, unit, threadId, RedisCommands.EVAL_LONG); &#125; // 未设置超时时间默认设置超时时间为30s RFuture&lt;Long&gt; ttlRemainingFuture = tryLockInnerAsync(commandExecutor.getConnectionManager().getCfg().getLockWatchdogTimeout(), TimeUnit.MILLISECONDS, threadId, RedisCommands.EVAL_LONG); ttlRemainingFuture.addListener(new FutureListener&lt;Long&gt;() &#123; @Override public void operationComplete(Future&lt;Long&gt; future) throws Exception &#123; if (!future.isSuccess()) &#123; return; &#125; Long ttlRemaining = future.getNow(); if (ttlRemaining == null) &#123; // 若当前锁还没有释放，则给当前锁续超时时间 scheduleExpirationRenewal(threadId); &#125; &#125; &#125;); return ttlRemainingFuture; &#125; &lt;T&gt; RFuture&lt;T&gt; tryLockInnerAsync(long leaseTime, TimeUnit unit, long threadId, RedisStrictCommand&lt;T&gt; command) &#123; internalLockLeaseTime = unit.toMillis(leaseTime); // 异步执行lua命令获取锁，若获取锁成功返回null，否则返回剩余持有时间 return commandExecutor .evalWriteAsync(getName(), LongCodec.INSTANCE, command, &quot;if (redis.call(&#x27;exists&#x27;, KEYS[1]) == 0) then &quot; + // 判断锁是否存在 &quot;redis.call(&#x27;hset&#x27;, KEYS[1], ARGV[2], 1); &quot; + // 将锁的的状态设置为1 &quot;redis.call(&#x27;pexpire&#x27;, KEYS[1], ARGV[1]); &quot; + // 给锁加上失效时间 &quot;return nil; &quot; + &quot;end; &quot; + &quot;if (redis.call(&#x27;hexists&#x27;, KEYS[1], ARGV[2]) == 1) then &quot; + // 重入锁的处理，锁存在，且加锁对象是当前线程 &quot;redis.call(&#x27;hincrby&#x27;, KEYS[1], ARGV[2], 1); &quot; + // 将锁加一 &quot;redis.call(&#x27;pexpire&#x27;, KEYS[1], ARGV[1]); &quot; + // 重置失效时间 &quot;return nil; &quot; + &quot;end; &quot; + &quot;return redis.call(&#x27;pttl&#x27;, KEYS[1]);&quot;, // 返回锁剩余的失效时间 Collections.&lt;Object&gt;singletonList(getName()), internalLockLeaseTime, getLockName(threadId)); &#125; private void scheduleExpirationRenewal(final long threadId) &#123; if (expirationRenewalMap.containsKey(getEntryName())) &#123; return; &#125; // 每10s执行一次 Timeout task = commandExecutor.getConnectionManager().newTimeout(new TimerTask() &#123; @Override public void run(Timeout timeout) throws Exception &#123; RFuture&lt;Boolean&gt; future = commandExecutor .evalWriteAsync(getName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN, &quot;if (redis.call(&#x27;hexists&#x27;, KEYS[1], ARGV[2]) == 1) then &quot; + // 若KEY存在则返回true，否则返回false &quot;redis.call(&#x27;pexpire&#x27;, KEYS[1], ARGV[1]); &quot; + // 重置超时时间 &quot;return 1; &quot; + &quot;end; &quot; + &quot;return 0;&quot;, Collections.&lt;Object&gt;singletonList(getName()), internalLockLeaseTime, getLockName(threadId)); future.addListener(new FutureListener&lt;Boolean&gt;() &#123; @Override public void operationComplete(Future&lt;Boolean&gt; future) throws Exception &#123; expirationRenewalMap.remove(getEntryName()); if (!future.isSuccess()) &#123; return; &#125; if (future.getNow()) &#123; // 若当前锁还没有释放，则给当前锁续超时时间 scheduleExpirationRenewal(threadId); &#125; &#125; &#125;); &#125; &#125;, internalLockLeaseTime / 3, TimeUnit.MILLISECONDS); if (expirationRenewalMap.putIfAbsent(getEntryName(), task) != null) &#123; task.cancel(); &#125; &#125;&#125; LUA脚本Redis在2.6推出了脚本功能，允许开发者使用Lua语言编写脚本传到Redis中执行： 减少网络开销：本来5次网络请求的操作，可用一个请求完成，原先5次请求的逻辑放在redis服务器上完成。使用脚本，减少了网络往返时延。这点跟管道类似。 原子操作：Redis会将整个脚本作为一个整体执行，中间不会被其他命令插入。管道不是原子的，不过redis的批量操作命令是原子。 替代redis的事务功能：redis自带的事务功能很鸡肋，而redis的lua脚本几乎实现了常规的事务功能，官方推荐如果要使用redis的事务功能可以用redis lua替代。 可以使用EVAL命令对Lua脚本进行求值。EVAL命令的格式如下： 1EVAL script numkeys key [key ...] arg [arg ...] script参数是一段Lua脚本程序，它会被运行在Redis服务器上下文中，**numkeys参数用于指定键名参数的个数。键名参数key [key ...]从EVAL的第三个参数开始算起，表示在脚本中所用到的那些Redis键(key)，这些键名参数可在Lua中通过全局变量KEYS数组，用1为基址**的形式访问KEYS[1]，KEYS[2] 以此类推。 在命令的最后不是键名参数的附加参数**arg [arg ...]，可在Lua中通过全局变量ARGV数组访问，访问的形式和KEYS变量类似(ARGV[1]、ARGV[2]，在Lua脚本中，可使用redis.call()**函数来执行Redis命令： 1234567891011jedis.set(&quot;product_stock_10016&quot;, &quot;15&quot;); //初始化商品10016的库存String script = &quot; local count = redis.call(&#x27;get&#x27;, KEYS[1]) &quot; + &quot; local a = tonumber(count) &quot; + &quot; local b = tonumber(ARGV[1]) &quot; + &quot; if a &gt;= b then &quot; + &quot; redis.call(&#x27;set&#x27;, KEYS[1], a-b) &quot; + &quot; return 1 &quot; + &quot; end &quot; + &quot; return 0 &quot;;Object obj = jedis.eval(script, Arrays.asList(&quot;product_stock_10016&quot;), Arrays.asList(&quot;10&quot;));System.out.println(obj); 不要在Lua脚本中出现死循环和耗时的运算，否则redis会阻塞，将不接受其他的命令，所以使用时要注意不能出现死循环、耗时的运算。redis是单进程、单线程执行脚本。**管道不会阻塞redis**。","tags":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"Redis","slug":"Cloud/Redis","permalink":"http://example.com/categories/Cloud/Redis/"}]},{"title":"Redis实践-Java","date":"2017-12-15T06:08:20.000Z","path":"blog/Cloud/Redis/Redis实践-Java/","text":"什么是Jedis在常见命令中，使用各种Redis自带客户端的命令行方式访问Redis服务。 而在实际工作中却需要用到Java代码才能访问，使用第三方jar包 ：Jedis就能方便地访问Redis的各种服务了。 简单运用：TestJedis：12345678910111213package redis;import redis.clients.jedis.Jedis;public class TestRedis &#123; public static void main(String[] args) &#123; Jedis jedis = new Jedis(&quot;localhost&quot;); jedis.set(&quot;foo&quot;, &quot;bar&quot;); String value = jedis.get(&quot;foo&quot;); System.out.println(value); &#125;&#125; TestRedisManyCommands:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151package redis;import java.util.HashMap;import java.util.Iterator;import java.util.List;import java.util.Map; import org.junit.Before;import org.junit.Test; import redis.clients.jedis.Jedis;import redis.clients.jedis.JedisPool; public class TestRedisManyCommands &#123; JedisPool pool; Jedis jedis; @Before public void setUp() &#123; jedis = new Jedis(&quot;localhost&quot;); &#125; /** * Redis存储初级的字符串 * CRUD */ @Test public void testBasicString()&#123; //-----添加数据---------- jedis.set(&quot;name&quot;,&quot;meepo&quot;);//向key--&gt;name中放入了value--&gt;meepo System.out.println(jedis.get(&quot;name&quot;));//执行结果：meepo //-----修改数据----------- //1、在原来基础上修改 jedis.append(&quot;name&quot;,&quot;dota&quot;); //很直观，类似map 将dota append到已经有的value之后 System.out.println(jedis.get(&quot;name&quot;));//执行结果:meepodota //2、直接覆盖原来的数据 jedis.set(&quot;name&quot;,&quot;poofu&quot;); System.out.println(jedis.get(&quot;name&quot;));//执行结果：poofu //删除key对应的记录 jedis.del(&quot;name&quot;); System.out.println(jedis.get(&quot;name&quot;));//执行结果：null /** * mset相当于 * jedis.set(&quot;name&quot;,&quot;meepo&quot;); * jedis.set(&quot;dota&quot;,&quot;poofu&quot;); */ jedis.mset(&quot;name&quot;,&quot;meepo&quot;,&quot;dota&quot;,&quot;poofu&quot;); System.out.println(jedis.mget(&quot;name&quot;,&quot;dota&quot;)); &#125; /** * jedis操作Map */ @Test public void testMap()&#123; Map&lt;String,String&gt; user=new HashMap&lt;String,String&gt;(); user.put(&quot;name&quot;,&quot;meepo&quot;); user.put(&quot;pwd&quot;,&quot;password&quot;); jedis.hmset(&quot;user&quot;,user); //取出user中的name，执行结果:[meepo]--&gt;注意结果是一个泛型的List //第一个参数是存入redis中map对象的key，后面跟的是放入map中的对象的key，后面的key可以跟多个，是可变参数 List&lt;String&gt; rsmap = jedis.hmget(&quot;user&quot;, &quot;name&quot;); System.out.println(rsmap); //删除map中的某个键值 // jedis.hdel(&quot;user&quot;,&quot;pwd&quot;); System.out.println(jedis.hmget(&quot;user&quot;, &quot;pwd&quot;)); //因为删除了，所以返回的是null System.out.println(jedis.hlen(&quot;user&quot;)); //返回key为user的键中存放的值的个数1 System.out.println(jedis.exists(&quot;user&quot;));//是否存在key为user的记录 返回true System.out.println(jedis.hkeys(&quot;user&quot;));//返回map对象中的所有key [pwd, name] System.out.println(jedis.hvals(&quot;user&quot;));//返回map对象中的所有value [meepo, password] Iterator&lt;String&gt; iter=jedis.hkeys(&quot;user&quot;).iterator(); while (iter.hasNext())&#123; String key = iter.next(); System.out.println(key+&quot;:&quot;+jedis.hmget(&quot;user&quot;,key)); &#125; &#125; /** * jedis操作List */ @Test public void testList()&#123; //开始前，先移除所有的内容 jedis.del(&quot;java framework&quot;); // 第一个是key，第二个是起始位置，第三个是结束位置，jedis.llen获取长度 -1表示取得所有 System.out.println(jedis.lrange(&quot;java framework&quot;,0,-1)); //先向key java framework中存放三条数据 jedis.lpush(&quot;java framework&quot;,&quot;spring&quot;); jedis.lpush(&quot;java framework&quot;,&quot;struts&quot;); jedis.lpush(&quot;java framework&quot;,&quot;hibernate&quot;); //再取出所有数据jedis.lrange是按范围取出， // 第一个是key，第二个是起始位置，第三个是结束位置，jedis.llen获取长度 -1表示取得所有 System.out.println(jedis.lrange(&quot;java framework&quot;,0,-1)); &#125; /** * jedis操作Set */ @Test public void testSet()&#123; //添加 jedis.sadd(&quot;sname&quot;,&quot;meepo&quot;); jedis.sadd(&quot;sname&quot;,&quot;dota&quot;); jedis.sadd(&quot;sname&quot;,&quot;poofu&quot;); jedis.sadd(&quot;sname&quot;,&quot;noname&quot;); //移除noname jedis.srem(&quot;sname&quot;,&quot;noname&quot;); System.out.println(jedis.smembers(&quot;sname&quot;));//获取所有加入的value System.out.println(jedis.sismember(&quot;sname&quot;, &quot;meepo&quot;));//判断 meepo 是否是sname集合的元素 System.out.println(jedis.srandmember(&quot;sname&quot;)); System.out.println(jedis.scard(&quot;sname&quot;));//返回集合的元素个数 &#125; @Test public void test() throws InterruptedException &#123; //keys中传入的可以用通配符 System.out.println(jedis.keys(&quot;*&quot;)); //返回当前库中所有的key [sose, sanme, name, dota, foo, sname, java framework, user, braand] System.out.println(jedis.keys(&quot;*name&quot;));//返回的sname [sname, name] System.out.println(jedis.del(&quot;sanmdde&quot;));//删除key为sanmdde的对象 删除成功返回1 删除失败（或者不存在）返回 0 System.out.println(jedis.ttl(&quot;sname&quot;));//返回给定key的有效时间，如果是-1则表示永远有效 jedis.setex(&quot;timekey&quot;, 10, &quot;min&quot;);//通过此方法，可以指定key的存活（有效时间） 时间为秒 Thread.sleep(5000);//睡眠5秒后，剩余时间将为&lt;=5 System.out.println(jedis.ttl(&quot;timekey&quot;)); //输出结果为5 jedis.setex(&quot;timekey&quot;, 1, &quot;min&quot;); //设为1后，下面再看剩余时间就是1了 System.out.println(jedis.ttl(&quot;timekey&quot;)); //输出结果为1 System.out.println(jedis.exists(&quot;key&quot;));//检查key是否存在 System.out.println(jedis.rename(&quot;timekey&quot;,&quot;time&quot;)); System.out.println(jedis.get(&quot;timekey&quot;));//因为移除，返回为null System.out.println(jedis.get(&quot;time&quot;)); //因为将timekey 重命名为time 所以可以取得值 min //jedis 排序 //注意，此处的rpush和lpush是List的操作。是一个双向链表（但从表现来看的） jedis.del(&quot;a&quot;);//先清除数据，再加入数据进行测试 jedis.rpush(&quot;a&quot;, &quot;1&quot;); jedis.lpush(&quot;a&quot;,&quot;6&quot;); jedis.lpush(&quot;a&quot;,&quot;3&quot;); jedis.lpush(&quot;a&quot;,&quot;9&quot;); System.out.println(jedis.lrange(&quot;a&quot;,0,-1));// [9, 3, 6, 1] System.out.println(jedis.sort(&quot;a&quot;)); //[1, 3, 6, 9] //输入排序后结果 System.out.println(jedis.lrange(&quot;a&quot;,0,-1)); &#125; &#125;","tags":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"Redis","slug":"Cloud/Redis","permalink":"http://example.com/categories/Cloud/Redis/"}]},{"title":"Redis集群架构","date":"2017-12-15T04:08:20.000Z","path":"blog/Cloud/Redis/Redis集群架构/","text":"主从架构：12345678910111213141516171819# 复制一份redis.conf文件port 6380pidfile /var/run/redis_6380.pid # 把pid进程号写入pidfile配置的文件logfile &quot;6380.log&quot;dir /usr/local/redis-5.0.3/data/6380 # 指定数据存放目录# 需要注释掉bind# bind 127.0.0.1 绑定机器网卡ip，多块网卡可配多个ip，代表允许客户端通过机器的哪些网卡ip去访问，内网一般可不配置bind# 配置主从复制replicaof 192.168.0.60 6379 # 从本机6379的redis实例复制数据，Redis 5.0之前使用slaveofreplica-read-only yes # 配置从节点只读# 启动从节点redis-server redis.conf# 连接从节点redis-cli -p 6380# 测试在6379实例上写数据，6380实例是否能及时同步新修改数据# 可以自己再配置一个6381的从节点 若为**master主节点配置了一个slave从节点，不管该slave从节点是否是第一次连接上Master主节点，都会发送一个PSYNC**命令给master请求复制数据。 master主节点收到**PSYNC命令后，会在后台进行数据持久化，通过bgsave生成最新的rdb快照文件，持久化期间master会继续接收客户端请求，且把这些可能修改数据集的请求缓存在内存中。当持久化进行完毕以后，master主节点会把这份rdb文件数据集发送给slave从节点，slave会把接收到的数据进行持久化生成rdb，然后再加载到内存中。master主节点再将之前缓存在内存中的命令发送给slave从节点**。 当master主节点与slave从节点之间的连接由于某些原因而断开时，slave从节点能够自动重连Master主节点，若master收到了多个slave从节点并发连接请求，它只会进行一次持久化，然后把这一份持久化的数据发送给多个并发连接的slave从节点。 当master主节点和slave从节点断开重连后，一般都会对整份数据进行复制。但从**Redis 2.8开始，PSYNC命令支持部分数据复制去master同步数据，slave从节点与master主节点能够在网络连接断开重连后只进行部分数据复制即断点续传**。 若有很多从节点，多个从节点同时复制主节点导致主节点压力过大，为了缓解主从复制风暴，可让部分从节点与从节点同步数据： 哨兵模式sentinel哨兵是特殊的redis服务，不提供读写服务，主要用来监控redis实例节点，哨兵架构下**client端第一次从哨兵找出redis的主节点，后续直接访问redis主节点，不会每次都通过sentinel哨兵代理访问redis的主节点，当redis的主节点发生变化，哨兵会第一时间感知到，并且将新的redis主节点通知给client端，redis的client端一般都实现了订阅**功能，订阅sentinel哨兵发布的节点变动消息。 12345678910111213141516171819# 复制一份sentinel.conf文件cp sentinel.conf sentinel-26379.confport 26379daemonize yespidfile &quot;/var/run/redis-sentinel-26379.pid&quot;logfile &quot;26379.log&quot;dir &quot;/usr/local/redis-5.0.3/data&quot;# sentinel monitor &lt;master-redis-name&gt; &lt;master-redis-ip&gt; &lt;master-redis-port&gt; &lt;quorum&gt;# quorum是一个数字，指明当有多少个sentinel认为一个master失效时(值一般为：sentinel总数/2 + 1)，master才算真正失效sentinel monitor mmaster 192.168.0.60 6379 2 # mmaster名字随便取，客户端访问时会用到# 启动sentinel哨兵实例src/redis-sentinel sentinel-26379.conf# 查看sentinel的info信息src/redis-cli -p 26379127.0.0.1:26379&gt;info # 可以看到Sentinel的info里已经识别出了redis的主从# 可再配置两个sentinel，端口26380和26381，注意上述配置文件里的对应数字都要修改 sentinel集群都启动完毕后，会将哨兵集群的元数据信息写入所有sentinel配置文件中，追加在文件的最下面： 1234sentinel known-replica mmaster 192.168.0.60 6380 #代表redis主节点的从节点信息sentinel known-replica mmaster 192.168.0.60 6381 #代表redis主节点的从节点信息sentinel known-sentinel mmaster 192.168.0.60 26380 52d0a5d70c1f90475b4fc03b6ce7c3c56935760f # 感知到的其它哨兵节点sentinel known-sentinel mmaster 192.168.0.60 26381 e9f530d3882f8043f76ebb8e1686438ba8bd5ca6 当redis主节点如果挂了，哨兵集群会重新选举出新的**redis主节点**，同时修改所有sentinel节点配置文件的集群元数据信息，如6379的redis挂了，假设选举出的新主节点是6380： 1234sentinel known-replica mmaster 192.168.0.60 6379 # 主节点的从节点信息sentinel known-replica mmaster 192.168.0.60 6381 # 主节点的从节点信息sentinel known-sentinel mmaster 192.168.0.60 26380 52d0a5d70c1f90475b4fc03b6ce7c3c56935760f # 感知到的其它哨兵节点sentinel known-sentinel mmaster 192.168.0.60 26381 e9f530d3882f8043f76ebb8e1686438ba8bd5ca6 同时修改sentinel文件里之前配置的mmaster对应的**6379端口，改为6380，当6379的redis实例再次启动时，哨兵集群根据集群元数据信息就可以将6379端口的redis节点作为从节点**加入集群: 1sentinel monitor mmaster 192.168.0.60 6380 2 1234567891011121314151617181920212223242526272829public class JedisSentinelTest &#123; public static void main(String[] args) throws IOException &#123; JedisPoolConfig config = new JedisPoolConfig(); config.setMaxTotal(20); config.setMaxIdle(10); config.setMinIdle(5); String masterName = &quot;mmaster&quot;; Set&lt;String&gt; sentinels = new HashSet&lt;String&gt;(); sentinels.add(new HostAndPort(&quot;172.16.20.53&quot;, 26379).toString()); sentinels.add(new HostAndPort(&quot;172.16.20.53&quot;, 26380).toString()); sentinels.add(new HostAndPort(&quot;172.16.20.53&quot;, 26381).toString()); // JedisSentinelPool其实本质跟JedisPool类似，都是与redis主节点建立的连接池 // JedisSentinelPool并不是说与sentinel建立的连接池，而是通过sentinel发现redis主节点并与其建立连接 JedisSentinelPool jedisSentinelPool = new JedisSentinelPool(masterName, sentinels, config, 3000, null); Jedis jedis = null; try &#123; jedis = jedisSentinelPool.getResource(); System.out.println(jedis.set(&quot;sentinel&quot;, &quot;eleven&quot;)); System.out.println(jedis.get(&quot;sentinel&quot;)); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; // 注意这里不是关闭连接，在JedisPool模式下，Jedis会被归还给资源池。 if (jedis != null) &#123; jedis.close(); &#125; &#125; &#125;&#125; Spring Boot整合Redis哨兵模式:只需要引入如下依赖，并将哨兵的节点信息配置到配置文件中，即可通过自动注入的方式引入**StringRedisTemplate或RedisTemplate**进行使用: 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt;&lt;/dependency&gt; 12345678910111213spring: redis: database: 0 timeout: 3000 sentinel: # 哨兵模式 master: mmaster # 主服务器所在集群名称 nodes: 192.168.0.60:26379,192.168.0.60:26380,192.168.0.60:26381 lettuce: pool: max-idle: 50 min-idle: 10 max-active: 100 max-wait: 1000 12345678910111213141516171819202122232425@RestControllerpublic class IndexController &#123; private static final Logger logger = LoggerFactory.getLogger(IndexController.class); @Autowired private StringRedisTemplate stringRedisTemplate; /** * 测试节点挂了哨兵重新选举新的master节点，客户端是否能动态感知到 * 新的master选举出来后，哨兵会把消息发布出去，客户端实际上是实现了一个消息监听机制， * 当哨兵把新master的消息发布出去，客户端会立马感知到新master的信息，从而动态切换访问的masterip */ @RequestMapping(&quot;/test_sentinel&quot;) public void testSentinel() throws InterruptedException &#123; int i = 1; while (true)&#123; try &#123; stringRedisTemplate.opsForValue().set(&quot;zhuge&quot;+i, i+&quot;&quot;); System.out.println(&quot;设置key：&quot;+ &quot;zhuge&quot; + i); i++; Thread.sleep(1000); &#125;catch (Exception e)&#123; logger.error(&quot;错误：&quot;, e); &#125; &#125; &#125;&#125; 问题：Redis 3.0以前的版本要实现集群一般是借助哨兵sentinel工具来监控master节点的状态，若master节点异常则会做主从切换，将某一台slave作为master，哨兵的配置略微复杂，且性能和高可用性等各方面表现一般，且在主从切换瞬间存在访问瞬断情况，且哨兵模式只有一个主节点对外提供服务，无法支持很高的并发，且单个主节点内存也不宜设置得过大，否则会导致持久化文件过大，影响数据恢复或主从同步的效率。 集群模式： Redis集群是一个由多个主从节点群组成的分布式服务器群，具有复制、高可用和分片特性，Redis集群不需要sentinel哨兵也能完成节点移除和故障转移的功能。只需要将每个节点设置成集群模式，这种集群模式没有中心节点可水平扩展，据官方文档称可以线性扩展到上万个节点，官方推荐不超过1000个节点。Redis集群的性能和高可用性均优于之前版本的哨兵模式，且集群配置非常简单，**Redis集群需要至少三个master主节点**。 1234567891011121314151617181920212223242526272829303132333435363738# 第一步：在第一台机器的/usr/local下创建文件夹redis-cluster，然后在其下面分别创建2个文件夾如下mkdir -p /usr/local/redis-clustermkdir 8001 8004# 把之前的redis.conf配置文件copy到8001下，修改如下内容：daemonize yesport 8001 # 分别对每个机器的端口号进行设置pidfile /var/run/redis_8001.pid # 把pid进程号写入pidfile配置的文件dir /usr/local/redis-cluster/8001/（指定数据文件存放位置，必须要指定不同的目录位置，不然会丢失数据）cluster-enabled yes（启动集群模式）cluster-config-file nodes-8001.conf（集群节点信息文件，这里800x最好和port对应上）cluster-node-timeout 10000# bind 127.0.0.1 绑定机器网卡ip，若有多块网卡可配多个ip，代表允许客户端通过机器的哪些网卡ip去访问protected-mode no # 关闭保护模式appendonly yes# 如果要设置密码需要增加如下配置：requirepass eleven # 设置redis访问密码masterauth eleven # 设置集群节点间访问密码，跟上面一致# 分别启动redis实例，然后检查是否启动成功src/redis-server redis.confps -ef | grep redis # 查看是否启动成功# 首先需要确认集群机器之间redis实例能相互访问，可先把所有机器防火墙关掉，若不关闭防火墙则需打开redis服务端口和集群节点gossip通信端口16379，默认是在redis端口号上加1W# systemctl stop firewalld # 临时关闭防火墙# systemctl disable firewalld # 禁止开机启动# 用redis-cli创建整个redis集群，redis5以前版本集群依靠ruby脚本redis-trib.rb实现# 命令中的1代表为每个创建的主服务器节点创建一个从服务器节点src/redis-cli -a zhuge --cluster create --cluster-replicas 1 192.168.0.61:8001 192.168.0.62:8002 192.168.0.63:8003 192.168.0.61:8004 192.168.0.62:8005 192.168.0.63:8006# 验证集群， -a访问服务端密码，-c表示集群模式，指定ip地址和端口号src/redis-cli -a eleven -c -h 192.168.0.61 -p 8001cluster info # 查看集群信息cluster nodes # 查看节点列表# 关闭集群则需要逐个进行关闭，使用命令：src/redis-cli -a eleven -c -h 192.168.0.60 -p 8001 shutdown 集群使用:借助redis的java客户端jedis可以操作以上集群，引用jedis版本的maven如下: 12345&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt;&lt;/dependency&gt; 12345678910111213141516171819202122232425262728293031public class JedisClusterTest &#123; public static void main(String[] args) throws IOException &#123; JedisPoolConfig config = new JedisPoolConfig(); config.setMaxTotal(20); config.setMaxIdle(10); config.setMinIdle(5); Set&lt;HostAndPort&gt; jedisClusterNode = new HashSet&lt;HostAndPort&gt;(); jedisClusterNode.add(new HostAndPort(&quot;192.168.0.61&quot;, 8001)); jedisClusterNode.add(new HostAndPort(&quot;192.168.0.62&quot;, 8002)); jedisClusterNode.add(new HostAndPort(&quot;192.168.0.63&quot;, 8003)); jedisClusterNode.add(new HostAndPort(&quot;192.168.0.61&quot;, 8004)); jedisClusterNode.add(new HostAndPort(&quot;192.168.0.62&quot;, 8005)); jedisClusterNode.add(new HostAndPort(&quot;192.168.0.63&quot;, 8006)); JedisCluster jedisCluster = null; try &#123; // connectionTimeout：指的是连接一个url的连接等待时间 // soTimeout：指的是连接上一个url，获取response的返回等待时间 jedisCluster = new JedisCluster(jedisClusterNode, 6000, 5000, 10, &quot;eleven&quot;, config); System.out.println(jedisCluster.set(&quot;cluster&quot;, &quot;eleven&quot;)); System.out.println(jedisCluster.get(&quot;cluster&quot;)); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; if (jedisCluster != null) &#123; jedisCluster.close(); &#125; &#125; &#125;&#125; 集群的Spring Boot整合Redis连接12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt;&lt;/dependency&gt; 12345678910111213spring: redis: database: 0 timeout: 3000 password: root cluster: nodes: 192.168.0.61:8001,192.168.0.62:8002,192.168.0.63:8003,192.168.0.61:8004,192.168.0.62:8005,192.168.0.63:8006 lettuce: pool: max-idle: 50 min-idle: 10 max-active: 100 max-wait: 1000 1234567891011@RestControllerpublic class IndexController &#123; @Autowired private StringRedisTemplate stringRedisTemplate; @RequestMapping(&quot;/test_cluster&quot;) public void testCluster() throws InterruptedException &#123; stringRedisTemplate.opsForValue().set(&quot;eleven&quot;, &quot;666&quot;); System.out.println(stringRedisTemplate.opsForValue().get(&quot;eleven&quot;)); &#125;&#125;","tags":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"Redis","slug":"Cloud/Redis","permalink":"http://example.com/categories/Cloud/Redis/"}]},{"title":"Redis安装","date":"2017-12-15T03:08:20.000Z","path":"blog/Cloud/Redis/Redis安装/","text":"Redis官网： redis官网：http://redis.io windows版本的下载地址是： http://redis.io/download 点击进去之后会跳转到： https://github.com/mythz/redis-windows 是一个开源项目，所以从github上下载后，需要自己编译生成exe文件，但是为了编译生成exe文件，又需要用到Visual Studio一套。 启动服务端：redis-server.exe 启动客户端:redis-cli.exe 详细步骤：1234567891011121314151617181920212223242526272829303132333435# 安装gccyum install gcc# 把下载好的redis-5.0.3.tar.gz放在/usr/local文件夹下，并解压wget http://download.redis.io/releases/redis-5.0.3.tar.gztar xzf redis-5.0.3.tar.gzcd redis-5.0.3# 进入到解压好的redis-5.0.3目录下，进行编译与安装make# 修改配置daemonize yes # 后台启动protected-mode no # 关闭保护模式，若开启只有本机才可访问redis# bind 127.0.0.1 绑定机器网卡ip，若有多块网卡可配多个ip，代表允许客户端通过机器哪些网卡ip去访问，内网一般可不配置bind，注释掉即可# 启动服务src/redis-server redis.conf# 验证启动是否成功 ps -ef | grep redis # 进入redis客户端 src/redis-cli # 退出客户端quit# 退出redis服务pkill redis-server kill 进程号 src/redis-cli shutdown # 查看redis支持的最大连接数，在redis.conf文件中可修改，默认maxclients 10000CONFIG GET maxclients 简单运用:12set hero gareenget hero 就可以实现了向服务器设置 hero 这个键值，并从服务器获取hero对应的值","tags":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"Redis","slug":"Cloud/Redis","permalink":"http://example.com/categories/Cloud/Redis/"}]},{"title":"Redis基础","date":"2017-12-15T02:08:20.000Z","path":"blog/Cloud/Redis/Redis基础/","text":"什么是Redis： Redis是一个开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。 换句话说，Redis就像是一个HashMap，不过不是在JVM中运行，而是以一个独立进程的形式运行。 一般说来，会被当作缓存使用。 因为它比数据库(mysql)快，所以常用的数据，可以考虑放在这里，这样就提高了性能。 Redis是非关系型的键值对数据库，可根据键以O(1)时间复杂度取出或插入关联值，Redis数据是存在内存中，键值对中键可以是字符串、整型、浮点型等且键唯一。值的类型可以是string、list、hash、set、sorted set等。内置了复制、磁盘持久化、LUA脚本、事务、SSL、ACLs、客户端缓存、客户端代理等功能，通过哨兵模式和Cluster模式提供高可用。 Redis的速度非常的快，单机的Redis就可以支撑每秒10几万的并发，相对于MySQL来说，性能是MySQL的几十倍。 完全基于内存操作 C语言实现，优化过的数据结构，基于几种基础的数据结构，Redis做了大量的优化，性能极高 使用单线程，无上下文的切换成本 基于非阻塞的IO多路复用机制 常见命令5种数据类型： String（字符串） List（列表） Hash（字典） Set（集合） Sorted Set（有序集合） 不同的数据类型，有不同的命令方式:String 字符串： SET key value 设置key&#x3D;value GET key 获得键key对应的值 GETRANGE key start end 得到字符串的子字符串存放在一个键 GETSET key value 设置键的字符串值，并返回旧值 GETBIT key offset 返回存储在键位值的字符串值的偏移 MGET key1 [key2..] 得到所有的给定键的值 SETBIT key offset value 设置或清除该位在存储在键的字符串值偏移 SETEX key seconds value 键到期时设置值 SETNX key value 设置键的值，只有当该键不存在 SETRANGE key offset value 覆盖字符串的一部分从指定键的偏移 STRLEN key 得到存储在键的值的长度 MSET key value [key value…] 设置多个键和多个值 MSETNX key value [key value…] 设置多个键多个值，只有在当没有按键的存在时 PSETEX key milliseconds value 设置键的毫秒值和到期时间 INCR key 增加键的整数值一次 INCRBY key increment 由给定的数量递增键的整数值 INCRBYFLOAT key increment 由给定的数量递增键的浮点值 DECR key 递减键一次的整数值 DECRBY key decrement 由给定数目递减键的整数值 APPEND key value 追加值到一个键 DEL key 如果存在删除键 DUMP key 返回存储在指定键的值的序列化版本 EXISTS key 此命令检查该键是否存在 EXPIRE key seconds 指定键的过期时间 EXPIREAT key timestamp 指定的键过期时间。在这里，时间是在Unix时间戳格式 PEXPIRE key milliseconds 设置键以毫秒为单位到期 PEXPIREAT key milliseconds-timestamp 设置键在Unix时间戳指定为毫秒到期 KEYS pattern 查找与指定模式匹配的所有键 MOVE key db 移动键到另一个数据库 PERSIST key 移除过期的键 PTTL key 以毫秒为单位获取剩余时间的到期键。 TTL key 获取键到期的剩余时间。 RANDOMKEY 从Redis返回随机键 RENAME key newkey 更改键的名称 RENAMENX key newkey 重命名键，如果新的键不存在 TYPE key 返回存储在键的数据类型的值。 List 列表： BLPOP key1 [key2 ] timeout 取出并获取列表中的第一个元素，或阻塞，直到有可用 BRPOP key1 [key2 ] timeout 取出并获取列表中的最后一个元素，或阻塞，直到有可用 BRPOPLPUSH source destination timeout 从列表中弹出一个值，它推到另一个列表并返回它;或阻塞，直到有可用 LINDEX key index 从一个列表其索引获取对应的元素 LINSERT key BEFORE|AFTER pivot value 在列表中的其他元素之后或之前插入一个元素 LLEN key 获取列表的长度 LPOP key 获取并取出列表中的第一个元素 LPUSH key value1 [value2] 在前面加上一个或多个值的列表 LPUSHX key value 在前面加上一个值列表，仅当列表中存在 LRANGE key start stop 从一个列表获取各种元素 LREM key count value 从列表中删除元素 LSET key index value 在列表中的索引设置一个元素的值 LTRIM key start stop 修剪列表到指定的范围内 RPOP key 取出并获取列表中的最后一个元素 RPOPLPUSH source destination 删除最后一个元素的列表，将其附加到另一个列表并返回它 RPUSH key value1 [value2] 添加一个或多个值到列表 RPUSHX key value 添加一个值列表，仅当列表中存在 Hash 字典，哈希表： HDEL key field[field…] 删除对象的一个或几个属性域，不存在的属性将被忽略 HEXISTS key field 查看对象是否存在该属性域 HGET key field 获取对象中该field属性域的值 HGETALL key 获取对象的所有属性域和值 HINCRBY key field value 将该对象中指定域的值增加给定的value，原子自增操作，只能是integer的属性值可以使用 HINCRBYFLOAT key field increment 将该对象中指定域的值增加给定的浮点数 HKEYS key 获取对象的所有属性字段 HVALS key 获取对象的所有属性值 HLEN key 获取对象的所有属性字段的总数 HMGET key field[field…] 获取对象的一个或多个指定字段的值 HSET key field value 设置对象指定字段的值 HMSET key field value [field value …] 同时设置对象中一个或多个字段的值 HSETNX key field value 只在对象不存在指定的字段时才设置字段的值 HSTRLEN key field 返回对象指定field的value的字符串长度，如果该对象或者field不存在，返回0. HSCAN key cursor [MATCH pattern] [COUNT count] 类似SCAN命令 Set 集合： SADD key member [member …] 添加一个或者多个元素到集合(set)里 SCARD key 获取集合里面的元素数量 SDIFF key [key …] 获得队列不存在的元素 SDIFFSTORE destination key [key …] 获得队列不存在的元素，并存储在一个关键的结果集 SINTER key [key …] 获得两个集合的交集 SINTERSTORE destination key [key …] 获得两个集合的交集，并存储在一个集合中 SISMEMBER key member 确定一个给定的值是一个集合的成员 SMEMBERS key 获取集合里面的所有key SMOVE source destination member 移动集合里面的一个key到另一个集合 SPOP key [count] 获取并删除一个集合里面的元素 SRANDMEMBER key [count] 从集合里面随机获取一个元素 SREM key member [member …] 从集合里删除一个或多个元素，不存在的元素会被忽略 SUNION key [key …] 添加多个set元素 SUNIONSTORE destination key [key …] 合并set元素，并将结果存入新的set里面 SSCAN key cursor [MATCH pattern] [COUNT count] 迭代set里面的元素 Sorted Set 有序集合： ZADD key score1 member1 [score2 member2] 添加一个或多个成员到有序集合，或者如果它已经存在更新其分数 ZCARD key 得到的有序集合成员的数量 ZCOUNT key min max 计算一个有序集合成员与给定值范围内的分数 ZINCRBY key increment member 在有序集合增加成员的分数 ZINTERSTORE destination numkeys key [key …] 多重交叉排序集合，并存储生成一个新的键有序集合。 ZLEXCOUNT key min max 计算一个给定的字典范围之间的有序集合成员的数量 ZRANGE key start stop [WITHSCORES] 由索引返回一个成员范围的有序集合（从低到高） ZRANGEBYLEX key min max [LIMIT offset count]返回一个成员范围的有序集合（由字典范围） ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT] 返回有序集key中，所有 score 值介于 min 和 max 之间(包括等于 min 或 max )的成员，有序集成员按 score 值递增(从小到大)次序排列 ZRANK key member 确定成员的索引中有序集合 ZREM key member [member …] 从有序集合中删除一个或多个成员，不存在的成员将被忽略 ZREMRANGEBYLEX key min max 删除所有成员在给定的字典范围之间的有序集合 ZREMRANGEBYRANK key start stop 在给定的索引之内删除所有成员的有序集合 ZREMRANGEBYSCORE key min max 在给定的分数之内删除所有成员的有序集合 ZREVRANGE key start stop [WITHSCORES] 返回一个成员范围的有序集合，通过索引，以分数排序，从高分到低分 ZREVRANGEBYSCORE key max min [WITHSCORES] 返回一个成员范围的有序集合，以socre排序从高到低 ZREVRANK key member 确定一个有序集合成员的索引，以分数排序，从高分到低分 ZSCORE key member 获取给定成员相关联的分数在一个有序集合 ZUNIONSTORE destination numkeys key [key …] 添加多个集排序，所得排序集合存储在一个新的键 ZSCAN key cursor [MATCH pattern] [COUNT count] 增量迭代排序元素集和相关的分数 官方命令手册:如果还想查询每个命令的详细用法，请到redis官方命令手册： http://www.redis.cn/commands.html Redis备份策略 写crontab定时调度脚本，每小时都copy一份rdb或aof的备份到一个目录中去，仅仅保留最近48小时的备份； 每天都保留一份当日的数据备份到一个目录中去，可以保留最近1个月的备份，每次copy备份的时候，都把太旧的备份删除； 每天晚上将当前机器上的备份复制一份到其他机器上，以防机器损坏。 应用场景: 计数器：可对String进行自增自减运算从而实现计数器功能，这种内存型数据库读写性能非常高，很适合存储频繁读写的计数量 分布式ID生成：利用自增特性，一次请求一个大一点的步长如**incr 2000**，缓存在本地使用，用完再请求 海量数据统计：通过位图**bitmap存储是否参过某次活动，是否已读谋篇文章，用户是否为会员，日活统计** Session共享：可统一存储多台应用服务器会话信息，一个用户可请求任意一个应用服务器，从而更容易实现高可用性以及可伸缩性 分布式队列、阻塞队列：List双向链表可通过**lpush/rpush和rpop/lpop写入和读取消息，可通过使用brpop/blpop**来实现阻塞队列 分布式锁实现：使用Redis自带的**SETNX**命令实现分布式锁 热点数据存储：最新评论，最新文章列表，使用list存储，ltrim取出热点数据，删除老数据 社交类需求：可通过Set交集实现共同好友等功能，可通过Set求差集进行好友推荐、文章推荐 排行榜：**sorted_set**可实现有序性操作，从而实现排行榜等功能 延迟队列：通过**sorted_set使用当前时间戳 + 需要延迟的时长做score，消息内容作为元素，调用zadd来生产消息，消费者使用zrangbyscore获取当前时间之前的数据做轮询处理。消费完再删除任务rem key member**","tags":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"}],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"Redis","slug":"Cloud/Redis","permalink":"http://example.com/categories/Cloud/Redis/"}]},{"title":"Gateway源码分析","date":"2017-12-14T16:00:00.000Z","path":"blog/Cloud/Gateway源码分析/","text":"Gateway源码:网关作为流量的入口，常用的功能包括路由转发，权限校验，限流等，Spring Cloud Gateway是Spring Cloud官方推出的由**WebFlux + Netty + Reactor实现的响应式的第二代API网关**框架，定位于取代Netflix Zuul。 Spring Cloud Gateway的核心概念：路由Route、断言、过滤器。路由是网关中最基础的部分，路由信息包括一个ID、一个目的URI、一组断言工厂、一组Filter组成，若断言为真则说明请求的URL和配置的路由匹配；Spring Cloud Gateway中的断言函数类型是Spring5.0框架中的**ServerWebExchange，允许开发者去定义匹配Http Request中的任何信息，如请求头和参数等；Spring Cloud Gateway的过滤器分为GatewayFilIer和GlobalFilter，可对请求和响应进行处理**。 Spring Cloud Gateway工作原理跟Zuul的差不多，最大的区别就是Gateway的Filter只有**pre和post两种，客户端向Spring Cloud Gateway发出请求，若请求与网关定义的路由匹配，则该请求会被发送到网关Web处理程序，此时处理程序运行特定的请求过滤器链。过滤器之间用虚线分开的原因是过滤器可能会在发送代理请求的前后执行逻辑。所有pre过滤器逻辑先执行，然后执行代理请求；代理请求完成后执行post过滤器逻辑**。 Gateway对请求处理的核心逻辑是在**DispatcherHandler中，在DispatcherHandler中依次调用HandlerMapping、HandlerAdapter、HandlerResultHandler**三个核心接口 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class DispatcherHandler implements WebHandler, ApplicationContextAware &#123; public Mono&lt;Void&gt; handle(ServerWebExchange exchange) &#123; if (this.handlerMappings == null) &#123; return createNotFoundError(); &#125; return Flux.fromIterable(this.handlerMappings) .concatMap(mapping -&gt; mapping.getHandler(exchange)) // 获取具体的HandlerMapping，这里返回FilteringWebHandler .next() .switchIfEmpty(createNotFoundError()) // 若路由断言匹配未匹配到，则返回Empty，这里对Empty进行处理 .flatMap(handler -&gt; invokeHandler(exchange, handler)) // 调用具体的HandlerAdapter的handle .flatMap(result -&gt; handleResult(exchange, result)); &#125; private Mono&lt;HandlerResult&gt; invokeHandler(ServerWebExchange exchange, Object handler) &#123; if (this.handlerAdapters != null) &#123; for (HandlerAdapter handlerAdapter : this.handlerAdapters) &#123; if (handlerAdapter.supports(handler)) &#123; return handlerAdapter.handle(exchange, handler); &#125; &#125; &#125; return Mono.error(new IllegalStateException(&quot;No HandlerAdapter: &quot; + handler)); &#125; private Mono&lt;Void&gt; handleResult(ServerWebExchange exchange, HandlerResult result) &#123; return getResultHandler(result).handleResult(exchange, result) .checkpoint(&quot;Handler &quot; + result.getHandler() + &quot; [DispatcherHandler]&quot;) .onErrorResume(ex -&gt; result.applyExceptionHandler(ex).flatMap(exResult -&gt; &#123; String text = &quot;Exception handler &quot; + exResult.getHandler() + &quot;, error=\\&quot;&quot; + ex.getMessage() + &quot;\\&quot; [DispatcherHandler]&quot;; return getResultHandler(exResult).handleResult(exchange, exResult).checkpoint(text); &#125;)); &#125; private HandlerResultHandler getResultHandler(HandlerResult handlerResult) &#123; if (this.resultHandlers != null) &#123; for (HandlerResultHandler resultHandler : this.resultHandlers) &#123; if (resultHandler.supports(handlerResult)) &#123; return resultHandler; &#125; &#125; &#125; throw new IllegalStateException(&quot;No HandlerResultHandler for &quot; + handlerResult.getReturnValue()); &#125; private &lt;R&gt; Mono&lt;R&gt; createNotFoundError() &#123; return Mono.defer(() -&gt; &#123; Exception ex = new ResponseStatusException(HttpStatus.NOT_FOUND, &quot;No matching handler&quot;); return Mono.error(ex); &#125;); &#125;&#125; HandlerMappingHandlerMapping负责路径到Handler的映射，Gateway中RoutePredicateHandlerMapping实现了AbstractHandlerMapping，其作用是执行所有的Route的断言工厂PredicateFactory匹配路由信息，通过断言判断路由是否可用，且将路由信息绑定到请求上下文中，最终返回**FilteringWebHandler**。 也可自定义断言工厂需继承AbstractRoutePredicateFactory类重写apply方法的逻辑。在apply方法中可以通过exchange.getRequest()拿到ServerHttpRequest对象，从而可获取到请求的参数、请求方式、请求头等信息。 12345678910111213141516public abstract class AbstractHandlerMapping extends ApplicationObjectSupport implements HandlerMapping, Ordered, BeanNameAware &#123; public Mono&lt;Object&gt; getHandler(ServerWebExchange exchange) &#123; return getHandlerInternal(exchange).map(handler -&gt; &#123; ServerHttpRequest request = exchange.getRequest(); if (hasCorsConfigurationSource(handler) || CorsUtils.isPreFlightRequest(request)) &#123; // 处理跨域问题 CorsConfiguration config = (this.corsConfigurationSource != null ? this.corsConfigurationSource.getCorsConfiguration(exchange) : null); CorsConfiguration handlerConfig = getCorsConfiguration(handler, exchange); config = (config != null ? config.combine(handlerConfig) : handlerConfig); if (!this.corsProcessor.process(config, exchange) || CorsUtils.isPreFlightRequest(request)) &#123; return REQUEST_HANDLED_HANDLER; &#125; &#125; return handler; &#125;); &#125;&#125; 首先通过**lookupRoute方法找出所有与当前请求匹配的Route，在匹配之前从RouteLocator的实现类CachingRouteLocator中已经转换好的Route，在应用启动时会通过RouteLocator的实现类RouteDefinitionRouteLocator通过PropertiesRouteDefinitionLocator从GatewayProperties中读取路由配置RouteDefinition且将其转换为Route并缓存到CachingRouteLocator中。除此之外若在DiscoveryClientRouteDefinitionLocator会获取集群中所有的实例并将其构建成RouteDefinition，最终转换并合并到CachingRouteLocator**中。 在**lookupRoute中通过遍历所有的Route，并遍历调用其具体的PredicateFactory的test方法，过滤出其test方法放回true的route。然后将匹配的路由绑定到请求上下文中。最终返回FilteringWebHandler** 1234567891011121314151617181920212223242526public class RoutePredicateHandlerMapping extends AbstractHandlerMapping &#123; protected Mono&lt;?&gt; getHandlerInternal(ServerWebExchange exchange) &#123; if (this.managementPortType == DIFFERENT &amp;&amp; this.managementPort != null &amp;&amp; exchange.getRequest().getURI().getPort() == this.managementPort) &#123; return Mono.empty(); &#125; exchange.getAttributes().put(GATEWAY_HANDLER_MAPPER_ATTR, getSimpleName()); return lookupRoute(exchange).flatMap((Function&lt;Route, Mono&lt;?&gt;&gt;) r -&gt; &#123; exchange.getAttributes().remove(GATEWAY_PREDICATE_ROUTE_ATTR); exchange.getAttributes().put(GATEWAY_ROUTE_ATTR, r); // 将匹配的路由绑定到请求上下文中，以便FilteringWebHandler的handle方法中使用 return Mono.just(webHandler); // 最终返回FilteringWebHandler &#125;).switchIfEmpty(Mono.empty().then(Mono.fromRunnable(() -&gt; &#123; // 未找到匹配的路由 exchange.getAttributes().remove(GATEWAY_PREDICATE_ROUTE_ATTR); &#125;))); &#125; protected Mono&lt;Route&gt; lookupRoute(ServerWebExchange exchange) &#123; return this.routeLocator.getRoutes().concatMap(route -&gt; Mono.just(route).filterWhen(r -&gt; &#123; exchange.getAttributes().put(GATEWAY_PREDICATE_ROUTE_ATTR, r.getId()); return r.getPredicate().apply(exchange); // 调用具体的PredicateFactory的test方法，过滤出test方法放回true的route &#125;).doOnError(e -&gt; logger.error(&quot;Error applying predicate for route: &quot; + route.getId(), e)).onErrorResume(e -&gt; Mono.empty())) .next() .map(route -&gt; &#123; validateRoute(route, exchange); return route; &#125;); &#125;&#125; HandlerAdapter调用具体的**HandlerAdapter的调用，在DelegatingWebFluxConfiguration配置类的超类WebFluxConfigurationSupport中注入了SimpleHandlerAdapter。而FilteringWebHandler是WebHandler的子类。在SimpleHandlerAdapter的handle方法中调用FilteringWebHandler的handle方法。由于SimpleHandlerAdapter返回的是Mono.empty()故不会触发handleResult**方法。 123456789101112public class SimpleHandlerAdapter implements HandlerAdapter &#123; @Override public boolean supports(Object handler) &#123; return WebHandler.class.isAssignableFrom(handler.getClass()); &#125; @Override public Mono&lt;HandlerResult&gt; handle(ServerWebExchange exchange, Object handler) &#123; WebHandler webHandler = (WebHandler) handler; Mono&lt;Void&gt; mono = webHandler.handle(exchange); return mono.then(Mono.empty()); &#125;&#125; 在**GatewayAutoConfiguration配置类中注入了FilteringWebHandler，由于全局的过滤器GlobalFilter与GatewayFilter故在其构造方法中通过适配器模式将GlobalFilter转换成了GatewayFilter。然后通过责任链模式挨个调用GatewayFilter的filter**方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960@Configuration(proxyBeanMethods = false)@ConditionalOnProperty(name = &quot;spring.cloud.gateway.enabled&quot;, matchIfMissing = true)@EnableConfigurationProperties@AutoConfigureBefore(&#123; HttpHandlerAutoConfiguration.class, WebFluxAutoConfiguration.class &#125;)@AutoConfigureAfter(&#123; GatewayLoadBalancerClientAutoConfiguration.class, GatewayClassPathWarningAutoConfiguration.class &#125;)@ConditionalOnClass(DispatcherHandler.class)public class GatewayAutoConfiguration &#123; public FilteringWebHandler filteringWebHandler(List&lt;GlobalFilter&gt; globalFilters) &#123; return new FilteringWebHandler(globalFilters); &#125;&#125;public class FilteringWebHandler implements WebHandler &#123; private final List&lt;GatewayFilter&gt; globalFilters; public FilteringWebHandler(List&lt;GlobalFilter&gt; globalFilters) &#123; this.globalFilters = loadFilters(globalFilters);// 通过适配器模式将GlobalFilter转换为GatewayFilter &#125; private static List&lt;GatewayFilter&gt; loadFilters(List&lt;GlobalFilter&gt; filters) &#123; return filters.stream().map(filter -&gt; &#123; GatewayFilterAdapter gatewayFilter = new GatewayFilterAdapter(filter); if (filter instanceof Ordered) &#123; int order = ((Ordered) filter).getOrder(); return new OrderedGatewayFilter(gatewayFilter, order); &#125; return gatewayFilter; &#125;).collect(Collectors.toList()); &#125; public Mono&lt;Void&gt; handle(ServerWebExchange exchange) &#123; Route route = exchange.getRequiredAttribute(GATEWAY_ROUTE_ATTR); // 从请求上下文中取出前面绑定的Route List&lt;GatewayFilter&gt; gatewayFilters = route.getFilters(); // 获取Route中配置的filters List&lt;GatewayFilter&gt; combined = new ArrayList&lt;&gt;(this.globalFilters); combined.addAll(gatewayFilters); // 合并配置的filters和自动注入的全局的filters AnnotationAwareOrderComparator.sort(combined); // 对GatewayFilter列表排序 return new DefaultGatewayFilterChain(combined).filter(exchange); &#125;&#125;private static class DefaultGatewayFilterChain implements GatewayFilterChain &#123; private final int index; private final List&lt;GatewayFilter&gt; filters; DefaultGatewayFilterChain(List&lt;GatewayFilter&gt; filters) &#123; this.filters = filters; this.index = 0; &#125; private DefaultGatewayFilterChain(DefaultGatewayFilterChain parent, int index) &#123; this.filters = parent.getFilters(); this.index = index; &#125; public Mono&lt;Void&gt; filter(ServerWebExchange exchange) &#123; return Mono.defer(() -&gt; &#123; if (this.index &lt; filters.size()) &#123; GatewayFilter filter = filters.get(this.index); DefaultGatewayFilterChain chain = new DefaultGatewayFilterChain(this, this.index + 1); return filter.filter(exchange, chain); &#125; else &#123; return Mono.empty(); // complete &#125; &#125;); &#125;&#125; 也可自定义**GatewayFilter，自定义GatewayFilter是通过自定义过滤器工厂来完成的，自定义工厂可集成一些列的AbstractGatewayFilterFactory来完成响应的功能，还可通过实现GlobalFilter来自定义全局的过滤器。对于uri支持lb://的方式类配置目标微服务的请求地址，就是通过LoadBalancerClientFilter**过滤器来完成的。 123456789101112131415161718192021222324252627282930313233343536373839public class LoadBalancerClientFilter implements GlobalFilter, Ordered &#123; public static final int LOAD_BALANCER_CLIENT_FILTER_ORDER = 10100; protected final LoadBalancerClient loadBalancer; private LoadBalancerProperties properties; public LoadBalancerClientFilter(LoadBalancerClient loadBalancer, LoadBalancerProperties properties) &#123; this.loadBalancer = loadBalancer; this.properties = properties; &#125; public int getOrder() &#123; return LOAD_BALANCER_CLIENT_FILTER_ORDER; &#125; @Override @SuppressWarnings(&quot;Duplicates&quot;) public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; URI url = exchange.getAttribute(GATEWAY_REQUEST_URL_ATTR); String schemePrefix = exchange.getAttribute(GATEWAY_SCHEME_PREFIX_ATTR); if (url == null || (!&quot;lb&quot;.equals(url.getScheme()) &amp;&amp; !&quot;lb&quot;.equals(schemePrefix))) &#123; return chain.filter(exchange); &#125; addOriginalRequestUrl(exchange, url); final ServiceInstance instance = choose(exchange); if (instance == null) &#123; throw NotFoundException.create(properties.isUse404(), &quot;Unable to find instance for &quot; + url.getHost()); &#125; URI uri = exchange.getRequest().getURI(); String overrideScheme = instance.isSecure() ? &quot;https&quot; : &quot;http&quot;; if (schemePrefix != null) &#123; overrideScheme = url.getScheme(); &#125; URI requestUrl = loadBalancer.reconstructURI(new DelegatingServiceInstance(instance, overrideScheme), uri); exchange.getAttributes().put(GATEWAY_REQUEST_URL_ATTR, requestUrl); return chain.filter(exchange); &#125; protected ServiceInstance choose(ServerWebExchange exchange) &#123; // 通过负载均衡算法获取具体的实例对象 return loadBalancer.choose(((URI) exchange.getAttribute(GATEWAY_REQUEST_URL_ATTR)).getHost()); &#125;&#125;","tags":[],"categories":[{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"}]},{"title":"Welcome TaoLiu's Blog","date":"2016-03-24T07:21:55.000Z","path":"blog/index/","text":"Welcome TaoLiu’s Blog","tags":[],"categories":[]},{"title":"Hello hexo","date":"2016-03-12T04:08:20.000Z","path":"blog/hello-hexo/","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","tags":[],"categories":[]}],"categories":[{"name":"工具和中间件","slug":"工具和中间件","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索引擎技术","slug":"工具和中间件/搜索引擎技术","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/"},{"name":"ElasticSearch","slug":"工具和中间件/搜索引擎技术/ElasticSearch","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/ElasticSearch/"},{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/categories/Cloud/"},{"name":"SpringCloud","slug":"Cloud/SpringCloud","permalink":"http://example.com/categories/Cloud/SpringCloud/"},{"name":"数据结构和算法","slug":"数据结构和算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/"},{"name":"消息队列","slug":"工具和中间件/消息队列","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RocketMQ","slug":"工具和中间件/消息队列/RocketMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RocketMQ/"},{"name":"RabbitMQ","slug":"工具和中间件/消息队列/RabbitMQ","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/"},{"name":"Activemq","slug":"工具和中间件/消息队列/Activemq","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Activemq/"},{"name":"Kafka","slug":"工具和中间件/消息队列/Kafka","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Kafka/"},{"name":"Solr","slug":"工具和中间件/搜索引擎技术/Solr","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/Solr/"},{"name":"Lucene","slug":"工具和中间件/搜索引擎技术/Lucene","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%92%8C%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8A%80%E6%9C%AF/Lucene/"},{"name":"Redis","slug":"Cloud/Redis","permalink":"http://example.com/categories/Cloud/Redis/"}],"tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"http://example.com/tags/ElasticSearch/"},{"name":"Kibana","slug":"Kibana","permalink":"http://example.com/tags/Kibana/"},{"name":"JAVA数据结构和算法","slug":"JAVA数据结构和算法","permalink":"http://example.com/tags/JAVA%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/"},{"name":"RocketMQ","slug":"RocketMQ","permalink":"http://example.com/tags/RocketMQ/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://example.com/tags/RabbitMQ/"},{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"http://example.com/tags/ActiveMQ/"},{"name":"Kafka","slug":"Kafka","permalink":"http://example.com/tags/Kafka/"},{"name":"Solr","slug":"Solr","permalink":"http://example.com/tags/Solr/"},{"name":"Lucene","slug":"Lucene","permalink":"http://example.com/tags/Lucene/"},{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"}]}